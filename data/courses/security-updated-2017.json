{
  "description": "This series is focused on CompTIA’s Security+ certifications. Security+ is a vendor-neutral certification that is recognized worldwide as a benchmark for information system security best practices. The series is intended for aspiring IT security professionals entering into security. The series follows the CompTIA specified objectives for the SY0-501 exam.",
  "descriptionMD": "This series is focused on CompTIA’s Security+ certifications. Security+ is a vendor-neutral certification that is recognized worldwide as a benchmark for information system security best practices. The series is intended for aspiring IT security professionals entering into security. The series follows the CompTIA specified objectives for the SY0-501 exam.",
  "length": "99893",
  "name": "CompTIA Security+ 2017",
  "practiceExam": true,
  "subtitle": "Vendor-neutral IT Security",
  "tagUrl": "comptia",
  "topics": [
    {
      "episodes": [
        {
          "description": "This series is focused on CompTIA’s Security+ certifications. Security+ is a vendor-neutral certification that is recognized worldwide as a benchmark for information system security best practices. The series is intended for aspiring IT security professionals entering into security. The series follows the CompTIA specified objectives for the SY0-501 exam.",
          "length": "265",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-0-0-overview-052517-PGM.00_00_05_16.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-0-0-overview-052517-PGM.00_00_05_16.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-0-0-overview-052517-PGM.00_00_05_16.Still001-sm.jpg",
          "title": "Overview",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:05.780\n[MUSIC]\n\n2\n00:00:05.780 --> 00:00:09.594\nIn this series, we're gonna be\nlooking at CompTIA's, vendor neutral,\n\n3\n00:00:09.594 --> 00:00:11.930\ncertification exam, known as Security+.\n\n4\n00:00:11.930 --> 00:00:15.860\nWe will, in the overview,\ndive into, well what is Security+?\n\n5\n00:00:15.860 --> 00:00:18.715\nAs well as, who is this course for?\n\n6\n00:00:18.715 --> 00:00:21.510\nWe'll also be looking at some of the\ntopics that you can expect to be covered\n\n7\n00:00:21.510 --> 00:00:23.720\ninside of the Security+ series.\n\n8\n00:00:23.720 --> 00:00:26.530\nAnd, finally, we'll be looking\nat some of the exam details so\n\n9\n00:00:26.530 --> 00:00:28.940\nwhen you decide to take\nthat certification exam and\n\n10\n00:00:28.940 --> 00:00:32.620\nsit the hot seat there,\nyou'll be a little bit better prepared.\n\n11\n00:00:32.620 --> 00:00:37.350\nSo, let's go ahead, and let's talk about,\nwell, what is Security+ to begin with?\n\n12\n00:00:37.350 --> 00:00:40.400\nWell, Security+,\nI said is a worldwide accreditation.\n\n13\n00:00:40.400 --> 00:00:45.300\nIt's recognized, just by about\n126 different countries, or more,\n\n14\n00:00:45.300 --> 00:00:47.520\nacross the entire globe.\n\n15\n00:00:47.520 --> 00:00:52.393\nIt is the benchmark for the best\npractices that we see in IT security.\n\n16\n00:00:52.393 --> 00:00:56.898\nIt's also recognized by\ninternational standards bodies, so\n\n17\n00:00:56.898 --> 00:01:01.404\nthe International Organization\nof Standardization has an ISO\n\n18\n00:01:01.404 --> 00:01:04.133\naccreditation known as 17024.\n\n19\n00:01:04.133 --> 00:01:09.120\nIt's also FISMA compliant too, the Federal\nInformation Security Management Act.\n\n20\n00:01:09.120 --> 00:01:11.495\nIt's also recognized by the US Military,\nas well.\n\n21\n00:01:11.495 --> 00:01:16.524\nSo keep in mind, if this is something\nthat you want to be involved in,\n\n22\n00:01:16.524 --> 00:01:22.100\nthese are some of the things that you\ncan expect to see inside of Security+.\n\n23\n00:01:22.100 --> 00:01:25.770\nAll right, so who is Security+ for?\n\n24\n00:01:25.770 --> 00:01:28.930\nWell, anybody who is\nan aspiring IT professional.\n\n25\n00:01:28.930 --> 00:01:32.930\nIf you are looking to learn how\nto secure information systems,\n\n26\n00:01:32.930 --> 00:01:34.820\nthen Security+ is for you.\n\n27\n00:01:34.820 --> 00:01:39.430\nIf you're seeking certification, well,\nthen this is the right series for you.\n\n28\n00:01:39.430 --> 00:01:42.990\nIt could be that maybe you're just\nseeking current security techniques and\n\n29\n00:01:42.990 --> 00:01:43.940\ntechnologies.\n\n30\n00:01:43.940 --> 00:01:51.760\nAnd if that's the case, then the Security+\nSY0501 exam is going to be where it's at.\n\n31\n00:01:52.760 --> 00:01:56.137\nNext, what are we going to\ncover inside of this exam.\n\n32\n00:01:56.137 --> 00:01:58.984\nWell I kind of mentioned, briefly there,\n\n33\n00:01:58.984 --> 00:02:02.790\nthe exam code these are the new\nobjectives as of October.\n\n34\n00:02:02.790 --> 00:02:09.470\nThis is the objectives for exam SY0501.\n\n35\n00:02:09.470 --> 00:02:13.150\nWe're gonna be looking at things like\nthe fundamental IT security concepts.\n\n36\n00:02:13.150 --> 00:02:17.580\nWe'll also be taking a look at some of\nthe principle risk management concepts.\n\n37\n00:02:17.580 --> 00:02:21.300\nThings like the host based and\nnetwork based security techniques.\n\n38\n00:02:21.300 --> 00:02:25.600\nAs well as things like your introductory\ncompliance and operational concepts.\n\n39\n00:02:25.600 --> 00:02:28.930\nWe'll also be looking at different\nthings like threats and vulnerabilities.\n\n40\n00:02:28.930 --> 00:02:32.220\nWe'll be looking at, not only threats and\nvulnerabilities, but also attacks.\n\n41\n00:02:32.220 --> 00:02:34.290\nWe'll look at some of the technologies and\n\n42\n00:02:34.290 --> 00:02:39.540\ntools you can expect to see if you're\nmaking your way into an IT security field.\n\n43\n00:02:39.540 --> 00:02:41.930\nWe'll also be looking at\nthings like architecture and\n\n44\n00:02:41.930 --> 00:02:46.020\ndesign, very important in\ntoday's information systems.\n\n45\n00:02:46.020 --> 00:02:48.840\nWe'll be looking at identity and\naccess management,\n\n46\n00:02:48.840 --> 00:02:53.020\na very important concept today when we\ntalk about enterprise based networks.\n\n47\n00:02:53.020 --> 00:02:55.890\nAs well as the basics\nof risk management and\n\n48\n00:02:55.890 --> 00:03:01.640\nthen finally we'll be talking about\ncryptology and public key infrastructure.\n\n49\n00:03:01.640 --> 00:03:05.530\nNow, if you are getting into the exam,\n\n50\n00:03:05.530 --> 00:03:07.760\nthere's some things you\nmight need to know about it.\n\n51\n00:03:07.760 --> 00:03:10.420\nOne of the things that we\nwant to look at is that\n\n52\n00:03:10.420 --> 00:03:14.010\nthe exam format is 90\nquestions in 90 minutes.\n\n53\n00:03:14.010 --> 00:03:17.060\nIt's multiple choice or\nperformance-based questions.\n\n54\n00:03:17.060 --> 00:03:20.920\nWhen we look at performance-based\nquestions, understand that that does imply\n\n55\n00:03:20.920 --> 00:03:23.770\nthat there could be simulations,\nso be prepared for that.\n\n56\n00:03:23.770 --> 00:03:27.493\nNow the passing score for\nyour Security+ exam is gonna be 750 and\n\n57\n00:03:27.493 --> 00:03:30.835\nthat's a passing score out\nof a range from 100 to 900.\n\n58\n00:03:30.835 --> 00:03:35.678\nAs far as we know right now,\nthe Security+ exam\n\n59\n00:03:35.678 --> 00:03:40.620\nis going to cost you $320 U.S. dollars.\n\n60\n00:03:40.620 --> 00:03:44.560\nIt is recommended that you\nhave CompTIA's Net+ and\n\n61\n00:03:44.560 --> 00:03:47.370\ntwo year's IT administration experience.\n\n62\n00:03:47.370 --> 00:03:50.400\nHowever, keep in mind that\nthat is recommend but\n\n63\n00:03:50.400 --> 00:03:52.610\nit is not a necessity before hand.\n\n64\n00:03:52.610 --> 00:03:56.710\nIt's not a pre-requisite to you taking the\nactual exam, it's just a recommendation.\n\n65\n00:03:56.710 --> 00:03:58.720\nSo, if these are some of the concepts and\n\n66\n00:03:58.720 --> 00:04:03.884\nthese are some of the goals that you\nhave to become IT security certified and\n\n67\n00:04:03.884 --> 00:04:07.580\nprove the knowledge that\nyou have competency and\n\n68\n00:04:07.580 --> 00:04:10.810\nsecurity techniques in how to\nsecure information systems,\n\n69\n00:04:10.810 --> 00:04:15.372\nthen the CompTIA Security+ SY0501\nseries is for you.\n\n70\n00:04:15.372 --> 00:04:18.652\n[MUSIC]\n\n",
          "vimeoId": "219086818"
        },
        {
          "description": "In this show, Wes and Cherokee discuss several different types of malware. First, they explore virus variations such as boot sector, polymorphic, macro, stealth viruses and more! You will also hear them explain other associated attacks such as logic bombs and  ransomware. Tune in to learn what defines these types of attacks.",
          "length": "1679",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-1-1-determining_types_of_malware-040317-PGM.00_27_44_09.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-1-1-determining_types_of_malware-040317-PGM.00_27_44_09.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-1-1-determining_types_of_malware-040317-PGM.00_27_44_09.Still001-sm.jpg",
          "title": "Determining Types of Malware",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.180\nWelcome to IT Pro TV.\n\n2\n00:00:01.180 --> 00:00:06.463\nI'm your host [CROSSTALK]\n\n3\n00:00:06.463 --> 00:00:08.217\n[MUSIC]\n\n4\n00:00:08.217 --> 00:00:11.847\n&gt;&gt; You're watching ITPro.TV.\n\n5\n00:00:11.847 --> 00:00:14.540\n&gt;&gt; Welcome to your\nComp TIA Security+ series.\n\n6\n00:00:14.540 --> 00:00:16.660\nI'm your show host Cherokee Boose.\n\n7\n00:00:16.660 --> 00:00:19.830\nIn this episode we'll be looking at\ndifferent types of malware to be able to\n\n8\n00:00:19.830 --> 00:00:22.070\ndetermine the many various types.\n\n9\n00:00:22.070 --> 00:00:24.830\nAnd with us today, we have Mr.\nWes Bryan in studios.\n\n10\n00:00:24.830 --> 00:00:26.050\nThank you for joining us today Wes.\n\n11\n00:00:26.050 --> 00:00:27.120\n&gt;&gt; Hey thanks for having me here.\n\n12\n00:00:27.120 --> 00:00:29.930\nYeah we are gonna talk about\nwell malicious code, right?\n\n13\n00:00:29.930 --> 00:00:33.330\nThe unwanted things,\nthings you don't want on your computer.\n\n14\n00:00:33.330 --> 00:00:36.390\nSo how do we classify malware?\n\n15\n00:00:36.390 --> 00:00:40.520\nWell malware is anything that you\ndidn't install on your computer and\n\n16\n00:00:40.520 --> 00:00:42.120\nit is running unauthorized.\n\n17\n00:00:42.120 --> 00:00:46.310\nSo, very basically malware can\nbe a lot of different things.\n\n18\n00:00:46.310 --> 00:00:49.550\nWe're gonna start when we talk\nabout malware in this context,\n\n19\n00:00:49.550 --> 00:00:52.730\nunderstand that what we are really\ntalking about is an umbrella term\n\n20\n00:00:52.730 --> 00:00:55.960\nthat many different pieces of\nmalicious code fall under.\n\n21\n00:00:55.960 --> 00:00:59.797\nAnd it's important to classify it because\nhow do you take care of different pieces\n\n22\n00:00:59.797 --> 00:01:00.472\nof malwares?\n\n23\n00:01:00.472 --> 00:01:02.460\nIt's not really a one size fits all.\n\n24\n00:01:02.460 --> 00:01:05.940\nNow you might be saying, well wait I've\ngot this antivirus solution that's running\n\n25\n00:01:05.940 --> 00:01:10.730\non my computer and it helps to take\ncare of different pieces of malware for\n\n26\n00:01:10.730 --> 00:01:12.440\nme and I don't have different types,\n\n27\n00:01:12.440 --> 00:01:15.260\nso what do you mean we take care\nof them a little bit different?\n\n28\n00:01:15.260 --> 00:01:17.926\nWell, the good thing is if you’re\nrunning anti-virus software,\n\n29\n00:01:17.926 --> 00:01:19.199\nyou're letting it do the work.\n\n30\n00:01:19.199 --> 00:01:23.550\nBut sometimes ant-virus software can need\nsome help especially when you get into\n\n31\n00:01:23.550 --> 00:01:27.584\nsome of these more strategic types of\ncode that can get onto your computer and\n\n32\n00:01:27.584 --> 00:01:28.360\ncause havoc.\n\n33\n00:01:28.360 --> 00:01:30.383\nSo, that’s what we’re gonna look at today,\nand\n\n34\n00:01:30.383 --> 00:01:33.640\none of the first things that we’re\ngonna dive into are viruses.\n\n35\n00:01:33.640 --> 00:01:34.540\nNow, what is a virus?\n\n36\n00:01:35.670 --> 00:01:37.720\nA virus is just a form of malware.\n\n37\n00:01:37.720 --> 00:01:41.253\nKeep in mind it is a piece of code,\nit runs on your computer,\n\n38\n00:01:41.253 --> 00:01:43.738\nit causes some kind of undesired effect.\n\n39\n00:01:43.738 --> 00:01:48.550\nNow one thing to keep in mind about\nvirus is that viruses require a host.\n\n40\n00:01:48.550 --> 00:01:51.090\nThey need a way to get on to your system.\n\n41\n00:01:51.090 --> 00:01:56.220\nIt's one of the reasons if you ever\nhave taken any security training,\n\n42\n00:01:56.220 --> 00:01:57.660\nyou're watching this.\n\n43\n00:01:57.660 --> 00:02:00.608\nThis course right now,\nmaybe you've seen some of our\n\n44\n00:02:00.608 --> 00:02:05.145\nother courses where we tell you don't\nopen things like emails with attachments.\n\n45\n00:02:05.145 --> 00:02:07.877\nEspecially when they come from\nsources that you don't you don't know\n\n46\n00:02:07.877 --> 00:02:08.930\nwho they are.\n\n47\n00:02:08.930 --> 00:02:09.858\nRight, because think about it.\n\n48\n00:02:09.858 --> 00:02:13.040\nA virus needs a host to\nget onto your computer.\n\n49\n00:02:13.040 --> 00:02:16.947\nSo I've got a little basic diagram\nhere and let's go ahead and\n\n50\n00:02:16.947 --> 00:02:18.985\nlet's let's take a look at it.\n\n51\n00:02:18.985 --> 00:02:23.590\nAnd we'll talk a little bit about\nhow viruses get onto your computer.\n\n52\n00:02:23.590 --> 00:02:28.020\nKeep in mind that again, the big thing\nabout a virus is that it does need a host.\n\n53\n00:02:28.020 --> 00:02:30.670\nIt needs a way, it needs an entry\npoint into your computer.\n\n54\n00:02:30.670 --> 00:02:35.140\nSo it usually piggybacks off of infected\nprograms that maybe you're downloading\n\n55\n00:02:35.140 --> 00:02:36.950\nover the internet,\ncould be internet based.\n\n56\n00:02:36.950 --> 00:02:39.350\nThese could be storage based, right,\n\n57\n00:02:39.350 --> 00:02:43.920\nwe have the garage the garage\nattacks as I call them, right?\n\n58\n00:02:43.920 --> 00:02:46.490\n&gt;&gt; Kind of like a real virus, right?\n\n59\n00:02:46.490 --> 00:02:48.170\nOr a human based virus, right?\n\n60\n00:02:48.170 --> 00:02:52.700\nSo it spreads from one person to another\nand if I were to sneeze or spread my germs\n\n61\n00:02:52.700 --> 00:02:55.920\nto you, that's kind of what we're talking\nabout here is how is that malware,\n\n62\n00:02:55.920 --> 00:02:57.140\nthat virus spread.\n\n63\n00:02:57.140 --> 00:02:58.140\n&gt;&gt; Yeah, most definitely.\n\n64\n00:02:58.140 --> 00:02:59.566\n&gt;&gt; A proverbial sneezing so to speak.\n\n65\n00:02:59.566 --> 00:03:00.150\n&gt;&gt; [LAUGH] That's right\n&gt;&gt; [LAUGH]\n\n66\n00:03:00.150 --> 00:03:00.690\n&gt;&gt; So for\n\n67\n00:03:00.690 --> 00:03:02.890\ninstance things like other\ninfected systems, yeah.\n\n68\n00:03:02.890 --> 00:03:05.590\nThey most definitely\ncan be what infects it.\n\n69\n00:03:05.590 --> 00:03:09.230\nIt might be something that maybe\nsomebody else has downloaded the virus.\n\n70\n00:03:09.230 --> 00:03:12.240\nAnd if they send you\nmaybe a shared resource,\n\n71\n00:03:12.240 --> 00:03:14.910\nmaybe you connect to a shared\nfolder on their network.\n\n72\n00:03:14.910 --> 00:03:18.860\nAnd it is infected, so now it\ntransfers from one host to the next,\n\n73\n00:03:18.860 --> 00:03:21.160\njust like Cherokee,\njust like you're saying there.\n\n74\n00:03:21.160 --> 00:03:24.120\nNo different than any other kind of\nbiological virus that we're talking about.\n\n75\n00:03:24.120 --> 00:03:27.140\nAnd we were talking about\nelectronic viruses, right?\n\n76\n00:03:27.140 --> 00:03:30.380\nOne of the things I was gonna mention too,\nis they could be things like USB based.\n\n77\n00:03:30.380 --> 00:03:34.570\nThis is where attacks,\nthey're kind of simplistic.\n\n78\n00:03:34.570 --> 00:03:37.670\nAnd what they do is they prey\non things like curiosity.\n\n79\n00:03:37.670 --> 00:03:43.050\nIf I take a bunch of USB devices and I\nplug them in, we put some viruses on them,\n\n80\n00:03:43.050 --> 00:03:47.420\nwe unplug them, we throw those USB\nthumb drives out in the parking lot,\n\n81\n00:03:47.420 --> 00:03:49.560\nthat may be a company that\nwe're looking to attack.\n\n82\n00:03:49.560 --> 00:03:52.270\nIf you have the black hat on, right,\n\n83\n00:03:52.270 --> 00:03:55.810\nsomebody is going to see at\nleast one of those USB devices.\n\n84\n00:03:55.810 --> 00:04:00.480\nBut at least that's the goal, and\ncome in and say, hey what's on this thing?\n\n85\n00:04:00.480 --> 00:04:01.490\nPlug it into your system.\n\n86\n00:04:01.490 --> 00:04:05.360\nAnd now unfortunately, it's got some kind\nof malware on it, some kind of virus.\n\n87\n00:04:05.360 --> 00:04:07.080\nIt injects itself into the system.\n\n88\n00:04:07.080 --> 00:04:09.700\nAnd now you have a system that's infected.\n\n89\n00:04:09.700 --> 00:04:13.020\nIn fact, those type of attacks\nare way people get into and\n\n90\n00:04:13.020 --> 00:04:16.360\ncompromise some systems that\notherwise would be very, very safe.\n\n91\n00:04:16.360 --> 00:04:21.724\nIt's just the fact that well, if a virus\nhas physical access to your network now,\n\n92\n00:04:21.724 --> 00:04:24.081\nit could start to cause havoc, so.\n\n93\n00:04:24.081 --> 00:04:26.647\n&gt;&gt; Now as you mentioned,\nthe curiosity element,\n\n94\n00:04:26.647 --> 00:04:29.290\nwhich psychologically\nis pretty interesting.\n\n95\n00:04:29.290 --> 00:04:33.190\nI've seen studies where, even you\nspoke about the email attachments, and\n\n96\n00:04:33.190 --> 00:04:36.990\nmaybe in the subject line,\none of the biggest viruses, I think\n\n97\n00:04:36.990 --> 00:04:40.990\nit was the I Love You virus, and it just\nkinda creates that psychological element.\n\n98\n00:04:40.990 --> 00:04:42.116\nWho loves me?\n\n99\n00:04:42.116 --> 00:04:45.730\nOr hey look at these pics from\nlast night's holiday party.\n\n100\n00:04:45.730 --> 00:04:48.230\nAnd they would send it out,\nduring the holiday holiday season.\n\n101\n00:04:48.230 --> 00:04:51.070\nWhich might make sense, a lot of people\nprobably attended a holiday party.\n\n102\n00:04:51.070 --> 00:04:52.790\nSo then, yeah curiosity.\n\n103\n00:04:52.790 --> 00:04:54.220\n&gt;&gt; Playing on emotions, right.\n\n104\n00:04:54.220 --> 00:04:57.140\nAnd theat's why a lot of things like some\nof the other things that we'll talk coming\n\n105\n00:04:57.140 --> 00:04:59.190\nup in the series is like\nsocial engineering right,\n\n106\n00:04:59.190 --> 00:05:03.580\nsocial engineering plays on your emotions,\nplays on things like urgency as well.\n\n107\n00:05:03.580 --> 00:05:05.320\nSo you definitely have to be aware of it.\n\n108\n00:05:05.320 --> 00:05:07.870\nAnd that's you know, now that you've\nmentioned that, that's one good thing to\n\n109\n00:05:07.870 --> 00:05:12.060\nkeep in mind is that education and\nawareness are the things that can help.\n\n110\n00:05:12.060 --> 00:05:14.430\nNot necessarily stop\nthese in their tracks but\n\n111\n00:05:14.430 --> 00:05:17.350\nit can at least give you a little\nbit better counter measure.\n\n112\n00:05:17.350 --> 00:05:20.260\nOne of the very first counter measures\nis understanding that this happens\n\n113\n00:05:20.260 --> 00:05:23.110\nto begin with and\nthat can be one of your first layers\n\n114\n00:05:23.110 --> 00:05:25.560\nof defense when you have\na multiple layer defense system.\n\n115\n00:05:26.980 --> 00:05:29.300\nAll right, so\nlet's talk about some types of viruses.\n\n116\n00:05:29.300 --> 00:05:33.070\nThese are just some common examples here,\nI've got a little list here on the screen.\n\n117\n00:05:33.070 --> 00:05:37.480\nAnd again, you could find different ones\nhere, there are other ones that I haven't\n\n118\n00:05:37.480 --> 00:05:40.510\nput in here, things like file\noverrider viruses too, so.\n\n119\n00:05:40.510 --> 00:05:43.832\nLet's just talk about some of these\nin the list, like for instance,\n\n120\n00:05:43.832 --> 00:05:44.989\nthe boot sector virus.\n\n121\n00:05:44.989 --> 00:05:48.685\nAll right, the boot sector virus,\nit's a crafty little type of virus,\n\n122\n00:05:48.685 --> 00:05:52.501\nbecause what it seeks to do is it seeks\nto load itself in the RAM at the point of\n\n123\n00:05:52.501 --> 00:05:53.830\nthe operating system.\n\n124\n00:05:53.830 --> 00:05:57.100\nAt the point or prior to the point of the\noperating system loading up in the memory.\n\n125\n00:05:57.100 --> 00:05:59.820\nNow you might say,\nwell why is that so bad?\n\n126\n00:05:59.820 --> 00:06:01.230\nWell I want you think about it.\n\n127\n00:06:01.230 --> 00:06:03.110\nIf you got any virus technology,\n\n128\n00:06:03.110 --> 00:06:07.010\nany malware technology typically it's\nrunning inside of your operating system.\n\n129\n00:06:07.010 --> 00:06:10.928\nAnd one thing to keep in mind is no\nmatter how early the antivirus or\n\n130\n00:06:10.928 --> 00:06:15.792\nanti-malware technology runs,\nit can't beat the operating system, right?\n\n131\n00:06:15.792 --> 00:06:18.650\nThe operating system has to load first.\n\n132\n00:06:18.650 --> 00:06:21.840\nNow, if we can get a virus into\nthat boot loader, it could be for\n\n133\n00:06:21.840 --> 00:06:23.760\nthe purposes of corrupting\nthe boot loader,\n\n134\n00:06:23.760 --> 00:06:26.210\nwhich means then you've got\na denial of service attack.\n\n135\n00:06:26.210 --> 00:06:27.800\nYou can't even boot your operating system.\n\n136\n00:06:27.800 --> 00:06:29.990\nBut more so, if we can put that,\n\n137\n00:06:29.990 --> 00:06:33.710\nthat virus into memory at the time\nthat the operating system loads.\n\n138\n00:06:33.710 --> 00:06:35.340\nThen the utilities that you use\n\n139\n00:06:36.510 --> 00:06:39.870\nin order to find that virus\nmight make it a lot harder.\n\n140\n00:06:39.870 --> 00:06:42.803\nThat's one of reasons Windows\nhas something known as ELAM,\n\n141\n00:06:42.803 --> 00:06:45.282\nit's the Early Launch Anti-malware\ndetection.\n\n142\n00:06:45.282 --> 00:06:49.157\nAnd these are actually system drivers that\nload before the operating system do and\n\n143\n00:06:49.157 --> 00:06:51.797\nthey check things like\nthe integrity of the hard drive,\n\n144\n00:06:51.797 --> 00:06:54.790\nthe integrity of something like\nthe boot configuration data.\n\n145\n00:06:54.790 --> 00:06:57.930\nThey can help slow these\ntypes of viruses down.\n\n146\n00:06:57.930 --> 00:07:03.080\nHowever, keep in mind if they load\nprior to the operating system loading,\n\n147\n00:07:03.080 --> 00:07:05.900\nand some of those early system drivers\n\n148\n00:07:05.900 --> 00:07:09.450\nthen they could be a real nightmare\nto get out of your systems.\n\n149\n00:07:09.450 --> 00:07:11.150\nOne of the other ones in\nthis one I'll tell you,\n\n150\n00:07:11.150 --> 00:07:14.990\nCherokee, is really scary,\nis the polymorphic virus.\n\n151\n00:07:14.990 --> 00:07:18.390\nNow there's polymorphic on many\ndifferent types of malware.\n\n152\n00:07:18.390 --> 00:07:24.820\nSo you might hear polymorphic rootkit,\nyou might hear polymorphic worm or virus.\n\n153\n00:07:24.820 --> 00:07:27.670\nJust understand polymorphic just\nmeans exactly what it sounds like.\n\n154\n00:07:27.670 --> 00:07:29.350\nIt's gonna go through a series of changes.\n\n155\n00:07:30.370 --> 00:07:33.560\nImagine this, you've got a piece of\nantivirus software on your machine and\n\n156\n00:07:33.560 --> 00:07:36.240\nit knows exactly what\nthat virus looks like.\n\n157\n00:07:36.240 --> 00:07:39.800\nBut then the virus takes the wolves,\nit's a wolf, right?\n\n158\n00:07:39.800 --> 00:07:41.580\nAnd it puts the sheep's clothing over.\n\n159\n00:07:41.580 --> 00:07:43.760\nSays nah I'm okay, I'm benign.\n\n160\n00:07:43.760 --> 00:07:47.664\nOr even worse it encrypts itself, right.\n\n161\n00:07:47.664 --> 00:07:50.522\nSee the operating system in order\nto see encrypted files, right,\n\n162\n00:07:50.522 --> 00:07:53.083\ntypically has things like your\nencryption keys in memory.\n\n163\n00:07:53.083 --> 00:07:56.629\nAnd it can just swap them in and out and\nit can see unencrypted information,\n\n164\n00:07:56.629 --> 00:07:57.541\nit's no big deal.\n\n165\n00:07:57.541 --> 00:08:00.933\nHowever, a polymorphic\nvirus encrypts itself.\n\n166\n00:08:00.933 --> 00:08:04.550\nYou don't have the decryption keys in\norder to see what that virus looks like.\n\n167\n00:08:04.550 --> 00:08:08.260\nSo what ends up happening,\nwhen your antivirus software scans\n\n168\n00:08:08.260 --> 00:08:12.290\nthat location to that file,\nit sees a bunch of garbage, remember,\n\n169\n00:08:12.290 --> 00:08:15.940\na lot of your antivirus software\nis signature based, right?\n\n170\n00:08:15.940 --> 00:08:19.290\nIt has some kind of definition,\nit defines what the virus looks like.\n\n171\n00:08:19.290 --> 00:08:22.820\nSays it looks like a duck, it waddles like\na duck, it's got to be a duck, right?\n\n172\n00:08:22.820 --> 00:08:26.260\nBut if we encrypt it, and\nit can't tell what it looks like,\n\n173\n00:08:26.260 --> 00:08:28.340\nwell then it's hard to find.\n\n174\n00:08:28.340 --> 00:08:31.860\nThe other part about it is when\nit decrypts itself, right?\n\n175\n00:08:31.860 --> 00:08:35.840\nIt goes to the un-encryption process,\nand now it looks completely different.\n\n176\n00:08:35.840 --> 00:08:37.010\nThe semantics have changed.\n\n177\n00:08:37.010 --> 00:08:38.590\nThe output, though, is gonna be the same.\n\n178\n00:08:38.590 --> 00:08:39.530\nThe results will be the same.\n\n179\n00:08:39.530 --> 00:08:41.470\nIt will still be an infection.\n\n180\n00:08:41.470 --> 00:08:45.663\nSo the polymorphic virus is the one that\nkeeps the antivirus software on its toes\n\n181\n00:08:45.663 --> 00:08:47.446\n[LAUGH] because its very,\n\n182\n00:08:47.446 --> 00:08:51.440\nvery difficult to identify what\nkind of code that might be.\n\n183\n00:08:51.440 --> 00:08:53.900\nAnd if it's malicious, even outright.\n\n184\n00:08:53.900 --> 00:08:58.340\n&gt;&gt; So what you're saying Wes is, basically\nby changing and evolving that that\n\n185\n00:08:58.340 --> 00:09:02.920\npiece of malware can circumvent,\npotentially, our anti-malware systems?\n\n186\n00:09:02.920 --> 00:09:03.570\n&gt;&gt; Yes, definitely.\n\n187\n00:09:03.570 --> 00:09:04.850\nAnd that's where it gets real scary.\n\n188\n00:09:04.850 --> 00:09:06.250\nBecause you've got a definition.\n\n189\n00:09:06.250 --> 00:09:10.160\nYou say, well I'm very, very good at\nkeeping my definitions up to date, right?\n\n190\n00:09:10.160 --> 00:09:13.916\nJust a little database, like I said,\nit shows your anti-virus software.\n\n191\n00:09:13.916 --> 00:09:18.341\nBut hey if you find this file and\nit looks like this, it's gonna be a virus.\n\n192\n00:09:18.341 --> 00:09:21.971\nWell, if that virus is constantly\nchanging, it's very hard for\n\n193\n00:09:21.971 --> 00:09:24.240\nthat definition to stay up-to-date.\n\n194\n00:09:24.240 --> 00:09:25.780\nThat's what it can make it very,\n\n195\n00:09:25.780 --> 00:09:28.539\nvery difficult in order to get\nthese off of your systems.\n\n196\n00:09:29.680 --> 00:09:32.464\nNow, the next one that we have\nhere is a macro-virus, right?\n\n197\n00:09:32.464 --> 00:09:36.210\nNow, macro-virus, I want you to understand\nthis is, when we look at macros,\n\n198\n00:09:36.210 --> 00:09:38.640\nmacros are kinda like mini applications.\n\n199\n00:09:38.640 --> 00:09:41.720\nIt's essentially a mini application,\nmini piece of software that you could\n\n200\n00:09:41.720 --> 00:09:46.150\nstring it together to automate\nfunctionality within a larger application.\n\n201\n00:09:47.430 --> 00:09:50.008\nWhat if I can infect those\nlittle sub routines,\n\n202\n00:09:50.008 --> 00:09:54.391\nthose little mini applications and I can\nautomate a process that causes some kind\n\n203\n00:09:54.391 --> 00:09:57.687\nof undesired effect the moment\nyou launch the application?\n\n204\n00:09:57.687 --> 00:09:59.510\nThen the macros execute.\n\n205\n00:09:59.510 --> 00:10:00.920\nThat's a macro virus.\n\n206\n00:10:00.920 --> 00:10:04.290\nSome of the other ones, too,\nthey have things like resident viruses.\n\n207\n00:10:04.290 --> 00:10:08.790\nAnd when you look at a resident virus,\nright, versus a nonresident virus.\n\n208\n00:10:08.790 --> 00:10:11.120\nLet me give you the other one,\nright, the nonresident virus.\n\n209\n00:10:11.120 --> 00:10:13.200\nThis is an executable\nthat's gotta be clicked.\n\n210\n00:10:13.200 --> 00:10:14.210\nIt's gotta be initiated.\n\n211\n00:10:14.210 --> 00:10:17.580\nA resident virus, though,\nthis is a little bit different,\n\n212\n00:10:17.580 --> 00:10:21.110\nthis is one that can load itself\nautomatically without any initiation,\n\n213\n00:10:21.110 --> 00:10:23.130\ncompletely automated,\nload itself right into RAM.\n\n214\n00:10:24.240 --> 00:10:26.650\nWorse so, is that it can also load itself\n\n215\n00:10:26.650 --> 00:10:29.990\ninto RAM at the moment that\nthe operating system's booting.\n\n216\n00:10:29.990 --> 00:10:33.340\nAll right, and what that ends up happening\nis it ends up doing things like blocking\n\n217\n00:10:33.340 --> 00:10:35.980\nthe actions of the anti-virus\nsoftware that's looking to find it.\n\n218\n00:10:37.095 --> 00:10:39.100\nRootkits can act this way as well, right?\n\n219\n00:10:39.100 --> 00:10:41.710\nBut what we’re talking about\nat this point is we’re talking\n\n220\n00:10:41.710 --> 00:10:43.360\nmore of an infection, right?\n\n221\n00:10:43.360 --> 00:10:44.908\nWe’ll get to the rootkit, coming up.\n\n222\n00:10:44.908 --> 00:10:49.680\nAll right so, it loads itself in RAM, and\nhere’s another thing about the resident\n\n223\n00:10:49.680 --> 00:10:52.390\nvirus, since it is\nconstantly loaded into RAM,\n\n224\n00:10:52.390 --> 00:10:56.630\nit can infect any file or application that\nloads itself to RAM the moment you use it.\n\n225\n00:10:56.630 --> 00:10:58.850\nSo, it’s very hard to get rid of,\n\n226\n00:10:58.850 --> 00:11:03.740\nit’s a nasty little bug that we\ndefinitely want to take care of.\n\n227\n00:11:03.740 --> 00:11:07.130\nNow, another one that I kind of put\nin this list too is what's known\n\n228\n00:11:07.130 --> 00:11:08.920\nas a logic bomb.\n\n229\n00:11:08.920 --> 00:11:13.370\nLogic bombs are interesting, logic bombs,\nwhat they do is they don't initiate right\n\n230\n00:11:13.370 --> 00:11:20.370\naway, they have some kind of\ntrigger that it initiate step.\n\n231\n00:11:20.370 --> 00:11:25.620\nFor instance, a logic bomb might\nbe part of a larger botnet, right?\n\n232\n00:11:25.620 --> 00:11:29.110\nAnd a botnet is where we have multiple\ncomputers that have been infected and\n\n233\n00:11:29.110 --> 00:11:30.750\nthey are remotely controlled.\n\n234\n00:11:30.750 --> 00:11:32.040\n&gt;&gt; An orchestrated attack?\n\n235\n00:11:32.040 --> 00:11:33.100\n&gt;&gt; That's right, exactly.\n\n236\n00:11:33.100 --> 00:11:36.430\nAn orchestrated attack against\na single endpoint, right?\n\n237\n00:11:36.430 --> 00:11:38.960\nBut we don't want the botnet to\n\n238\n00:11:38.960 --> 00:11:41.990\nautomatically start taking thousands\nof computers and attacking a target.\n\n239\n00:11:41.990 --> 00:11:43.788\nWe want them to wait a little bit.\n\n240\n00:11:43.788 --> 00:11:46.579\nAnd I say we, I'm talking about\nthe malicious attacker here.\n\n241\n00:11:46.579 --> 00:11:48.300\n&gt;&gt; The bad guys. [LAUGH] Not you.\n&gt;&gt; The bad guys.\n\n242\n00:11:48.300 --> 00:11:48.844\n&gt;&gt; Not you.\n&gt;&gt; Not me.\n\n243\n00:11:48.844 --> 00:11:51.084\n[LAUGH] I'm not doing this.\n\n244\n00:11:51.084 --> 00:11:53.890\nSo what happens is that the logic\nbomb gets onto your computer.\n\n245\n00:11:53.890 --> 00:11:58.004\nAnd it could just seem as it's benign and\nit waits.\n\n246\n00:11:58.004 --> 00:12:01.023\nIt waits until some kind of\ntrigger event like for instance,\n\n247\n00:12:01.023 --> 00:12:04.750\nif it happens to be part of a larger,\nwhat's eventually gonna be a botnet,\n\n248\n00:12:04.750 --> 00:12:07.490\nthen what it does is it could\ncall out to an IRC, right?\n\n249\n00:12:07.490 --> 00:12:09.980\nThe old internet relay chatroom,\nand it can wait for\n\n250\n00:12:09.980 --> 00:12:15.800\nsome kind of execution code that\nthe attacker puts into the IRC chat and\n\n251\n00:12:15.800 --> 00:12:18.576\nessentially directs an attack\nagainst an endpoint.\n\n252\n00:12:18.576 --> 00:12:22.600\n&gt;&gt; Now Wes, you mentioned that the\npolymorphic concept kind of scares you but\n\n253\n00:12:22.600 --> 00:12:25.030\nfor me these logic bombs\nare really terrifying.\n\n254\n00:12:25.030 --> 00:12:27.450\nIf you think about different types\n\n255\n00:12:28.680 --> 00:12:33.760\nof industry systems such as our electrical\ngrid system, our transportation systems.\n\n256\n00:12:33.760 --> 00:12:38.020\nBecause if there was that orchestrated\nattack like you were talking about, and\n\n257\n00:12:38.020 --> 00:12:43.400\nthey waited for a specific baby, some\nsort of political situation to kind of\n\n258\n00:12:43.400 --> 00:12:45.780\nexpress their opinions and\nthings like that.\n\n259\n00:12:45.780 --> 00:12:48.070\nThat's kind of something we\nneed to be aware of these days.\n\n260\n00:12:48.070 --> 00:12:48.640\n&gt;&gt; Most definitely.\n\n261\n00:12:48.640 --> 00:12:50.750\nSo if you've got somebody that's\nlike a hacktivist, right?\n\n262\n00:12:50.750 --> 00:12:52.960\nThey, like you're saying,\na political gain or something like that.\n\n263\n00:12:52.960 --> 00:12:53.526\n&gt;&gt; Sure, exactly.\n\n264\n00:12:53.526 --> 00:12:56.500\n&gt;&gt; Maybe they're waiting for\na specific date, right?\n\n265\n00:12:56.500 --> 00:13:00.778\nWe had tragedy of our past here\nin America, in the United States.\n\n266\n00:13:00.778 --> 00:13:04.730\nIt's like 9/11, maybe you're in country,\nmaybe you're watching from Europe, right?\n\n267\n00:13:04.730 --> 00:13:09.120\nSomething happened that was a tragic\nmoment in time in your history, right, and\n\n268\n00:13:09.120 --> 00:13:12.560\nthey use that time frame\nmaliciously of course.\n\n269\n00:13:12.560 --> 00:13:16.330\nAnd they use that time as the trigger,\nwhatever the trigger might be.\n\n270\n00:13:16.330 --> 00:13:17.690\nThat then launches the attack.\n\n271\n00:13:17.690 --> 00:13:21.710\nSo logic bombs are very scary, because\nof the fact that they hide themselves.\n\n272\n00:13:21.710 --> 00:13:24.290\nAnd they just sit there and\nthey wait and they wait.\n\n273\n00:13:24.290 --> 00:13:27.250\nAnd whatever the intention of the attacker\nis depends on what the trigger\n\n274\n00:13:27.250 --> 00:13:27.950\nevent might be.\n\n275\n00:13:27.950 --> 00:13:30.540\nAnd again, it's not going to\nbe a one size fits all here.\n\n276\n00:13:30.540 --> 00:13:32.270\nBecause they're gonna craft them and\n\n277\n00:13:32.270 --> 00:13:36.300\ntailor make them to whatever\nthe attack is that they want.\n\n278\n00:13:36.300 --> 00:13:37.890\nA couple other ones too.\n\n279\n00:13:37.890 --> 00:13:39.890\nAnd you know what,\nI don't really have them on the screen.\n\n280\n00:13:39.890 --> 00:13:43.020\nSo let me go ahead and kinda just\ntalk about these file infectors.\n\n281\n00:13:43.020 --> 00:13:47.500\nNow this is specifically for\nthe purposes of just infecting files and\n\n282\n00:13:47.500 --> 00:13:49.260\nreplicating themselves.\n\n283\n00:13:49.260 --> 00:13:51.630\nMost viruses have this\ntype of functionality.\n\n284\n00:13:51.630 --> 00:13:54.920\nA lot of viruses have this type\nof functionality where they\n\n285\n00:13:54.920 --> 00:13:56.300\nare infecting files.\n\n286\n00:13:56.300 --> 00:14:00.070\nBut if you have one that's doing something\nlike directly attacking the file system\n\n287\n00:14:00.070 --> 00:14:04.386\nand it just seeks to corrupt any files\nthat it can, replicate itself in the tail.\n\n288\n00:14:04.386 --> 00:14:07.250\nPretty soon you'll get a hard\ndrive of infected files, and\n\n289\n00:14:07.250 --> 00:14:09.180\nnow you have to format your machine.\n\n290\n00:14:09.180 --> 00:14:13.140\nAnd unfortunately that ends up\nbeing a bad day at the office.\n\n291\n00:14:13.140 --> 00:14:14.770\nOne of the last ones I'll talk.\n\n292\n00:14:14.770 --> 00:14:16.270\nI got a couple more here.\n\n293\n00:14:16.270 --> 00:14:19.830\nStealth virus, stealth virus is\nexactly what it sounds like.\n\n294\n00:14:19.830 --> 00:14:22.040\nIt is one that just seeks to hide itself.\n\n295\n00:14:22.040 --> 00:14:24.180\nIt's not trying to propagate itself, and\n\n296\n00:14:24.180 --> 00:14:26.600\nwhen it does it tries to\ndo it under the radar.\n\n297\n00:14:26.600 --> 00:14:31.090\nAnd it can get a little bit interesting\nbecause of the fact that it can start\n\n298\n00:14:31.090 --> 00:14:34.980\ndoing things like rootkits do,\nintercepting calls from the OS.\n\n299\n00:14:34.980 --> 00:14:35.990\nAnd when we talk about that,\n\n300\n00:14:35.990 --> 00:14:39.040\nI want you to think about what\nan antivirus software is doing, right?\n\n301\n00:14:39.040 --> 00:14:41.440\nIt performs its functions,\nit looks in a location and\n\n302\n00:14:41.440 --> 00:14:44.280\nit compares back to the data\nthat it's aware of.\n\n303\n00:14:44.280 --> 00:14:48.130\nAnd it says, okay,\nthis is definitely some kind of virus.\n\n304\n00:14:48.130 --> 00:14:52.470\nWell, imagine if you put a virus right\nin the middle of that process, and\n\n305\n00:14:52.470 --> 00:14:57.430\nwhen it checks that database, it says\nnope, this is the virus saying this,\n\n306\n00:14:57.430 --> 00:15:00.450\nit says, no I am not a virus, right?\n\n307\n00:15:00.450 --> 00:15:03.192\nAnd it tells the operator,\nit intercepts that call and\n\n308\n00:15:03.192 --> 00:15:07.020\nit essentially let's the end user know\nanything that it wants, hence the stealthy\n\n309\n00:15:07.020 --> 00:15:10.200\npart of this is the fact that you're\nnot even aware that it exists.\n\n310\n00:15:11.720 --> 00:15:12.860\nAll right, what else do we have?\n\n311\n00:15:12.860 --> 00:15:17.190\n&gt;&gt; So, Wes, we're just getting started\nhere with the beginning of our list and\n\n312\n00:15:17.190 --> 00:15:18.450\nthere are so many different variants.\n\n313\n00:15:19.730 --> 00:15:24.080\nWhen I'm running my scans and\nI find these infected files,\n\n314\n00:15:24.080 --> 00:15:26.960\nhow would I know which path to go?\n\n315\n00:15:26.960 --> 00:15:28.980\nHow would I know if it was a rootkit,\n\n316\n00:15:28.980 --> 00:15:32.140\nor if I needed to perform a clean\ninstallation of my operating system, or\n\n317\n00:15:32.140 --> 00:15:35.050\nif it was something that I\ncould easily clean up myself?\n\n318\n00:15:35.050 --> 00:15:37.430\n&gt;&gt; Well I guess it depends\non the level of complexity.\n\n319\n00:15:37.430 --> 00:15:42.200\nIf you're in an enterprise level\nenvironment, you might have where you're\n\n320\n00:15:42.200 --> 00:15:45.630\ndoing things like deployment,\nyou might do image installations.\n\n321\n00:15:45.630 --> 00:15:49.642\nAnd in a situation like that where you're\ndoing image installation, if your end\n\n322\n00:15:49.642 --> 00:15:54.012\nusers aren't storing their data locally,\nthey're storing out on a share somewhere.\n\n323\n00:15:54.012 --> 00:15:56.557\nNow what I would say is,\nI'd just wipe the operating system.\n\n324\n00:15:56.557 --> 00:15:58.055\n&gt;&gt; Great topic, yeah, I mean.\n\n325\n00:15:58.055 --> 00:16:00.916\n&gt;&gt; However, if you're in a home\nenvironment where you have some, and\n\n326\n00:16:00.916 --> 00:16:01.827\nI know you have kids.\n\n327\n00:16:01.827 --> 00:16:05.511\nI have kids, I can't afford to\nlose the pictures of my family.\n\n328\n00:16:05.511 --> 00:16:09.930\nSo to me if I can get those pictures\noff of there then I'm okay.\n\n329\n00:16:09.930 --> 00:16:12.790\nAnd I'll completely just\nwipe the operating system.\n\n330\n00:16:12.790 --> 00:16:15.780\nWe've got a lot of\ntechnology advances today.\n\n331\n00:16:15.780 --> 00:16:19.610\nLike for instance in Windows\nyou can do a push button reset\n\n332\n00:16:19.610 --> 00:16:21.700\nthat basically just\nmeans reset my computer.\n\n333\n00:16:21.700 --> 00:16:24.900\nReinstall Windows and\nwipe all my files out.\n\n334\n00:16:24.900 --> 00:16:28.970\nMight be something that you could do,\nbut always keep in mind that it really\n\n335\n00:16:28.970 --> 00:16:33.180\ndepends on how crucial it is to\nnot losing your information.\n\n336\n00:16:33.180 --> 00:16:36.476\nThis is one of the things why we\nsay that maintain good backups.\n\n337\n00:16:36.476 --> 00:16:39.680\n&gt;&gt; [LAUGH]\n&gt;&gt; Maintain things like file history.\n\n338\n00:16:39.680 --> 00:16:40.260\n&gt;&gt; Be proactive.\n\n339\n00:16:40.260 --> 00:16:42.420\n&gt;&gt; Your versioning, yes exactly,\n\n340\n00:16:42.420 --> 00:16:44.910\nso that if you\n&gt;&gt; If you do come in one morning and\n\n341\n00:16:44.910 --> 00:16:49.640\nyou end up having some kind of sporadic\nissue that's happening on your computer.\n\n342\n00:16:49.640 --> 00:16:52.170\nYou will have the ability to at least\n\n343\n00:16:52.170 --> 00:16:54.560\neither revert the computer\nto an earlier point in time.\n\n344\n00:16:54.560 --> 00:16:57.430\nOr at least restore your data to a point\nin time when you didn't have the virus.\n\n345\n00:16:57.430 --> 00:16:58.210\n&gt;&gt; Okay, thank you.\n\n346\n00:16:58.210 --> 00:17:00.540\n&gt;&gt; That's one of the things\nthat I would say, yeah.\n\n347\n00:17:00.540 --> 00:17:04.857\nLast one is the multipartite virus.\n\n348\n00:17:04.857 --> 00:17:07.750\nAnd this just means that it has\nmore than one attack avenue.\n\n349\n00:17:07.750 --> 00:17:11.980\nIt could do things like file overwrites\nat the same time it's infecting files.\n\n350\n00:17:11.980 --> 00:17:15.020\nAnd at the same time it\nmight be loading itself into\n\n351\n00:17:15.020 --> 00:17:17.330\nRAM to corrupt some application.\n\n352\n00:17:17.330 --> 00:17:21.640\nAt the same time, it's turning around and\nit's writing to a boot sector.\n\n353\n00:17:21.640 --> 00:17:26.930\nSo just remember with something like that,\nwe're talking multiple attack avenues.\n\n354\n00:17:26.930 --> 00:17:31.370\nAlright, so that's really some of the\nthings I want you to know about the virus.\n\n355\n00:17:31.370 --> 00:17:35.800\nYou know, it's interesting,\nI did have a picture about a logic bomb.\n\n356\n00:17:35.800 --> 00:17:37.870\nIf we could bring this up,\nI'll go ahead and use this.\n\n357\n00:17:37.870 --> 00:17:40.420\nKeep in mind that when logic bombs happen,\nright,\n\n358\n00:17:40.420 --> 00:17:44.220\nit's some kind of trigger\naction that sets it in motion.\n\n359\n00:17:44.220 --> 00:17:47.885\nIt could be something\nlike launching an email.\n\n360\n00:17:47.885 --> 00:17:52.160\nAnti-malware scan might not even find it.\n\n361\n00:17:52.160 --> 00:17:56.020\nKeep in mind, launching, that was supposed\nto be launching a browser, right?\n\n362\n00:17:56.020 --> 00:18:01.280\nSo it really comes down to what\nthe intentions of the attacker are.\n\n363\n00:18:01.280 --> 00:18:02.610\nIt could be to collect your data.\n\n364\n00:18:02.610 --> 00:18:04.290\nIt could be to destroy your data.\n\n365\n00:18:04.290 --> 00:18:06.630\nMaybe they don't want your,\nthey don't care about your information.\n\n366\n00:18:06.630 --> 00:18:09.860\nBut what they do wanna do is they\nwanna bring your systems offline.\n\n367\n00:18:09.860 --> 00:18:10.920\nSo just eradicate the data.\n\n368\n00:18:11.960 --> 00:18:15.460\nCould be to infect, could be to spread,\ncould be to execute.\n\n369\n00:18:15.460 --> 00:18:19.890\nSo it really comes down to what\nis the intention of the hacker.\n\n370\n00:18:19.890 --> 00:18:23.780\nThe attacker will dictate what\nthe logic bomb's gonna do.\n\n371\n00:18:23.780 --> 00:18:25.580\n&gt;&gt; That's really a good\npoint to make also, Wes.\n\n372\n00:18:25.580 --> 00:18:28.770\nBecause knowing that motivation,\nthere might be some kind of action that\n\n373\n00:18:28.770 --> 00:18:31.350\nyou can take to help mitigate\nthat particular attack.\n\n374\n00:18:31.350 --> 00:18:34.190\nIf you understand\nthe attacker's motivation.\n\n375\n00:18:34.190 --> 00:18:35.580\n&gt;&gt; Most definitely.\n\n376\n00:18:35.580 --> 00:18:38.196\nSo the next thing that they talk about and\nI'm going to go ahead and\n\n377\n00:18:38.196 --> 00:18:39.921\nI'm going to kind of lump these together.\n\n378\n00:18:39.921 --> 00:18:42.850\nBecause they talk about ransom ware.\n\n379\n00:18:42.850 --> 00:18:45.250\nAnd they talk about something\nknown as crypto malware.\n\n380\n00:18:45.250 --> 00:18:50.370\nAnd I'm of the mindset that crypto\nmalware is a form of ransomware.\n\n381\n00:18:50.370 --> 00:18:54.250\nRansomware is really an umbrella\nterm when it comes down to it.\n\n382\n00:18:54.250 --> 00:18:57.030\nIt's also called,\nyou might hear it called scareware.\n\n383\n00:18:57.030 --> 00:19:00.320\nAnd it really depends on what,\nthere again,\n\n384\n00:19:00.320 --> 00:19:01.800\nwhat are the motivations of the attacker?\n\n385\n00:19:01.800 --> 00:19:07.922\nSo I want you to think about maybe a time\nwhen you visited a legitimate website.\n\n386\n00:19:07.922 --> 00:19:10.470\nYou knew it was a good website,\nthere's nothing wrong with it.\n\n387\n00:19:10.470 --> 00:19:13.360\nTrusted website, you clicked on a link and\n\n388\n00:19:13.360 --> 00:19:16.240\nall of a sudden you get one\nof these warnings right here.\n\n389\n00:19:16.240 --> 00:19:18.340\nIf wee could take a look at my screen.\n\n390\n00:19:18.340 --> 00:19:19.861\nYour computer has been locked.\n\n391\n00:19:19.861 --> 00:19:20.370\n&gt;&gt; No.\n&gt;&gt; Right?\n\n392\n00:19:20.370 --> 00:19:21.550\nThe FBI warning.\n\n393\n00:19:21.550 --> 00:19:23.430\nThis is a form of ransomware.\n\n394\n00:19:23.430 --> 00:19:24.660\nIt's also called scareware.\n\n395\n00:19:24.660 --> 00:19:25.420\nWhy?\n\n396\n00:19:25.420 --> 00:19:27.360\nJust because of Cherokees\nreaction right there.\n\n397\n00:19:27.360 --> 00:19:28.550\nMy gosh, what I'm gonna do?\n\n398\n00:19:28.550 --> 00:19:31.100\nBecause if you've ever seen these,\n\n399\n00:19:31.100 --> 00:19:34.720\nmaybe you have seen these before and\nit's not a big deal.\n\n400\n00:19:34.720 --> 00:19:39.740\nHowever, if you're not really that\nfamiliar with the computing industry.\n\n401\n00:19:39.740 --> 00:19:43.240\nOr just computing in general,\nthen you might see one of these and\n\n402\n00:19:43.240 --> 00:19:45.560\nyou might think,\nI don't know what happened.\n\n403\n00:19:45.560 --> 00:19:48.480\nBut I'd better talk to somebody\ncuz I'm in trouble right?\n\n404\n00:19:48.480 --> 00:19:51.260\nAnd that's the ransomware\nwhere it does things like for\n\n405\n00:19:51.260 --> 00:19:55.890\ninstance, it restricts the users\naccess to the computer.\n\n406\n00:19:55.890 --> 00:19:58.450\nNow, it doesn't have to\nrestrict complete access,\n\n407\n00:19:58.450 --> 00:20:00.350\nit can be a little bit more difficult.\n\n408\n00:20:00.350 --> 00:20:06.300\nSome people that might know to launch Task\nManager and close this FBI warning down.\n\n409\n00:20:06.300 --> 00:20:07.850\nBut not everybody's gonna be that savvy.\n\n410\n00:20:07.850 --> 00:20:11.850\nSo it's at least restricting at some\npoint a portion of the computer.\n\n411\n00:20:11.850 --> 00:20:14.430\nWhether it's access to\nthe applications that you use or\n\n412\n00:20:14.430 --> 00:20:17.670\naccess to the files that you\nuse the applications for.\n\n413\n00:20:17.670 --> 00:20:21.170\n&gt;&gt; Now, Wes, how often would say\nsomething like this happens?\n\n414\n00:20:21.170 --> 00:20:23.110\nI know you said, some people and\n\n415\n00:20:23.110 --> 00:20:25.870\nI've met several people who\naren't really computer savvy.\n\n416\n00:20:25.870 --> 00:20:30.950\nBut just statistically is it\nreally worth that attackers time?\n\n417\n00:20:30.950 --> 00:20:33.070\nIt can be worth attacker's time.\n\n418\n00:20:33.070 --> 00:20:35.180\nIn fact, let me give you an example.\n\n419\n00:20:35.180 --> 00:20:39.490\nI went to the United States\nComputer Emergency Response Team.\n\n420\n00:20:39.490 --> 00:20:43.000\nYou might hear US- CERT if you get\na chance, go to their website.\n\n421\n00:20:43.000 --> 00:20:46.650\nThey've got a lot of great information\nabout things like ransomware.\n\n422\n00:20:46.650 --> 00:20:50.390\nAnd they had actually a statistic going\nback, it's a little bit dated by today's.\n\n423\n00:20:50.390 --> 00:20:51.920\nYou know, we're in 2017 today.\n\n424\n00:20:51.920 --> 00:20:56.610\nSo it's about five years, but\nIt takes some time to really\n\n425\n00:20:56.610 --> 00:20:59.190\nget the statistics here and\nunderstand what's going on.\n\n426\n00:20:59.190 --> 00:21:01.290\nSo, they're still valid for today.\n\n427\n00:21:01.290 --> 00:21:03.520\nThey talk about a single CAC server.\n\n428\n00:21:03.520 --> 00:21:06.990\nLet's understand CAC,\nthat's command and control.\n\n429\n00:21:06.990 --> 00:21:09.530\nWhen we talk about things like BotNets,\n\n430\n00:21:09.530 --> 00:21:13.370\nCherokee you had mentioned a little\nbit earlier a little brief.\n\n431\n00:21:13.370 --> 00:21:17.640\nIs that when you have\na computer that gets infected,\n\n432\n00:21:17.640 --> 00:21:20.570\nwe talk about remote code exploitation.\n\n433\n00:21:20.570 --> 00:21:24.000\nEssentially what can happen to that\ncomputer is it can be listening\n\n434\n00:21:24.000 --> 00:21:27.510\nout now for an attacker to control it,\nto perform some kind of action.\n\n435\n00:21:27.510 --> 00:21:32.120\nAgain, command and control,\nyou might here the term C2 or CAC.\n\n436\n00:21:32.120 --> 00:21:37.090\nSo a single command and control server\nthat they audited after they captured it.\n\n437\n00:21:37.090 --> 00:21:39.520\nAnd this is Symantec,\nby the way, let me mention that.\n\n438\n00:21:39.520 --> 00:21:42.650\nIt compromised 5,700 computers.\n\n439\n00:21:42.650 --> 00:21:47.490\nAnd in those 5,700 computers,\n2.9% of the users paid\n\n440\n00:21:47.490 --> 00:21:52.000\na $200 ransom,\nransoms averaging around $200.\n\n441\n00:21:52.000 --> 00:21:55.100\nSo in a single day, the hacker,\noff of that one server,\n\n442\n00:21:55.100 --> 00:21:58.440\nmade $33,600 in a single day.\n\n443\n00:21:58.440 --> 00:22:01.210\n&gt;&gt; Not too shabby.\n\n444\n00:22:01.210 --> 00:22:04.170\nIn one month, just under 400 grand.\n\n445\n00:22:04.170 --> 00:22:06.980\nWe're talking 394,000, and\nthat's from a single server.\n\n446\n00:22:06.980 --> 00:22:09.570\nYou multiple that by 1000,\nyou can start to see that yes,\n\n447\n00:22:09.570 --> 00:22:13.740\nit is a very lucrative business,\nwhich is why it's one of those ones.\n\n448\n00:22:13.740 --> 00:22:14.310\n&gt;&gt; Easy money for them.\n\n449\n00:22:14.310 --> 00:22:15.870\n&gt;&gt; Yeah exactly, easy money and it just,\n\n450\n00:22:15.870 --> 00:22:19.310\nit's\n&gt;&gt; It only takes one person to pay for\n\n451\n00:22:19.310 --> 00:22:20.680\nit to be worth it in the long run.\n\n452\n00:22:20.680 --> 00:22:24.500\nSo, you can see that things like\nthe FBI virus that we talk about here,\n\n453\n00:22:24.500 --> 00:22:26.600\nthese can cause problems.\n\n454\n00:22:26.600 --> 00:22:28.760\nOther things too,\nwe have things like fake antivirus,\n\n455\n00:22:28.760 --> 00:22:31.340\nyou might hear the rogue\nantivirus suite two.\n\n456\n00:22:31.340 --> 00:22:33.730\nThis can also be a form of ransomware.\n\n457\n00:22:33.730 --> 00:22:37.000\nWhere it gives you some kind of\nfake picture that looks like\n\n458\n00:22:37.000 --> 00:22:39.645\nyou've got a gazillion\nviruses on your computer.\n\n459\n00:22:39.645 --> 00:22:41.400\n&gt;&gt; [LAUGH]\n&gt;&gt; And the only way you can get them off-\n\n460\n00:22:41.400 --> 00:22:43.470\n&gt;&gt; Like maybe an alarm, sounding an alarm.\n\n461\n00:22:43.470 --> 00:22:44.350\n&gt;&gt; Yes, yeah, definitely.\n\n462\n00:22:44.350 --> 00:22:47.880\nAnd there's that we're talking about\npreying on people, the urgency.\n\n463\n00:22:47.880 --> 00:22:49.790\n&gt;&gt; Sure.\n&gt;&gt; Their fears and\n\n464\n00:22:49.790 --> 00:22:51.940\nyou end up thinking that\nyour machine is infected.\n\n465\n00:22:51.940 --> 00:22:54.380\nWhen in reality, it's not infected.\n\n466\n00:22:54.380 --> 00:22:57.410\nIt's actually that fake antivirus\nthat is causing the problem.\n\n467\n00:22:57.410 --> 00:22:58.310\n&gt;&gt; But like you had mentioned,\n\n468\n00:22:58.310 --> 00:23:02.370\nif you have a good set of backups you\ncan kind of disregard that message.\n\n469\n00:23:02.370 --> 00:23:04.030\nAnd you don't have to pay them anything.\n\n470\n00:23:04.030 --> 00:23:08.170\n&gt;&gt; Most definitely, and that's where\nthe backups definitely come in handy.\n\n471\n00:23:08.170 --> 00:23:12.420\nSo let's go ahead, let's take a look at\nsome of the things that the ransomware.\n\n472\n00:23:12.420 --> 00:23:14.830\nI've got kind of a diagram here.\n\n473\n00:23:14.830 --> 00:23:18.160\nIt can be a fake anti-malware scan.\n\n474\n00:23:18.160 --> 00:23:21.620\nSo for instance, again,\nsome kind of fake antivirus software.\n\n475\n00:23:21.620 --> 00:23:24.530\nIt could be the FBI warning that you see,\nthat we've shown an example.\n\n476\n00:23:24.530 --> 00:23:27.810\nCould be just an all out browser hijack.\n\n477\n00:23:27.810 --> 00:23:30.850\nI've had it to where it locks\ndown all legitimate executables.\n\n478\n00:23:30.850 --> 00:23:33.910\nAnd the only thing that it would allow\nme to do is open up Internet Explorer.\n\n479\n00:23:33.910 --> 00:23:38.160\nWhich conveniently would only direct to\ntheir server where I can make a payment.\n\n480\n00:23:38.160 --> 00:23:40.900\nAgain-\n&gt;&gt; And you know Wes I've even heard people\n\n481\n00:23:40.900 --> 00:23:43.300\ntelling me about getting phone calls.\n\n482\n00:23:43.300 --> 00:23:45.290\n&gt;&gt; Yeah.\n&gt;&gt; Stating that they're from Microsoft or\n\n483\n00:23:45.290 --> 00:23:46.060\nthe IRS.\n\n484\n00:23:46.060 --> 00:23:48.466\nBut just that you know that\nIRS sends registered mail.\n\n485\n00:23:48.466 --> 00:23:51.248\nAnd Microsoft's not gonna be calling\nyou to let you know that your system\n\n486\n00:23:51.248 --> 00:23:51.801\nis infected.\n\n487\n00:23:51.801 --> 00:23:54.106\nSo just like as you've mentioned\nbefore end user awareness, right?\n\n488\n00:23:54.106 --> 00:23:55.047\n&gt;&gt; You've gotta be aware.\n\n489\n00:23:55.047 --> 00:23:56.764\nAnd that can help a lot.\n\n490\n00:23:56.764 --> 00:23:59.708\nAnd in fact, I've got a friend that's\ngoing through that problem right now.\n\n491\n00:23:59.708 --> 00:24:00.212\nTrust me,\n\n492\n00:24:00.212 --> 00:24:03.750\nMicrosoft is not gonna call you when\nyou have a problem with your computer.\n\n493\n00:24:03.750 --> 00:24:06.569\nIf they do, it's probably going\nto be some kind of hacker.\n\n494\n00:24:06.569 --> 00:24:08.456\nSo be careful with that.\n\n495\n00:24:08.456 --> 00:24:11.366\nAnd you can see for example, right?\n\n496\n00:24:11.366 --> 00:24:14.750\nIt locks the computer and\nthen doesn't allow\n\n497\n00:24:14.750 --> 00:24:17.700\nany connection other than to\nsomething like a malicious website.\n\n498\n00:24:17.700 --> 00:24:20.510\nWhere your banking information or\n\n499\n00:24:20.510 --> 00:24:24.340\nsome kind of financial gain on\nthe attacker basically can be stolen.\n\n500\n00:24:24.340 --> 00:24:29.550\nAll right, so examples, we do have\nsome examples of I don't know where,\n\n501\n00:24:29.550 --> 00:24:31.770\nI wanted to talk a little bit about them.\n\n502\n00:24:31.770 --> 00:24:35.227\nGet the right one, okay,\nI know where they are.\n\n503\n00:24:35.227 --> 00:24:37.020\nOther examples of ransomware.\n\n504\n00:24:37.020 --> 00:24:39.460\nNow this is a specific type of ransomware.\n\n505\n00:24:39.460 --> 00:24:41.540\nThis is called crypto-malware.\n\n506\n00:24:41.540 --> 00:24:43.460\nThis is where it starts\nto get real tricky.\n\n507\n00:24:43.460 --> 00:24:45.560\nThis is where we can have\nthings like blackmail.\n\n508\n00:24:45.560 --> 00:24:51.120\nYou can have things like malicious\ninsiders can perform this and\n\n509\n00:24:51.120 --> 00:24:55.110\nwhat happens is crypto-malware grabs\nahold of your files and it encrypts it.\n\n510\n00:24:55.110 --> 00:24:57.420\nAnd it basically says that if\nyou want to have your data back,\n\n511\n00:24:57.420 --> 00:25:00.130\nyou're gonna have to pay\nsome kind of attacker and\n\n512\n00:25:00.130 --> 00:25:04.490\nthey'll give you the decryption keys and\nyou can have your data back.\n\n513\n00:25:04.490 --> 00:25:06.490\nAnd it'll hopefully be safe.\n\n514\n00:25:08.460 --> 00:25:12.730\nSome examples of that CryptoLocker,\nCryptoDefense, and CryptoWall,\n\n515\n00:25:12.730 --> 00:25:15.240\nthese are just some examples of\nthese type of crypto-malware.\n\n516\n00:25:15.240 --> 00:25:21.060\nKeep in mind that backups are very,\nvery important in this instance because\n\n517\n00:25:21.060 --> 00:25:26.200\nif your data does get\nencrypted by these viruses.\n\n518\n00:25:26.200 --> 00:25:27.940\nBy these form of malware,\n\n519\n00:25:27.940 --> 00:25:31.750\nthen chances are you're most likely\nnot going to get your data back.\n\n520\n00:25:31.750 --> 00:25:34.440\nYou're not gonna be able\nto decrypt the information.\n\n521\n00:25:34.440 --> 00:25:37.680\nSo this happens to companies.\n\n522\n00:25:37.680 --> 00:25:40.870\nIt can happen to just individuals.\n\n523\n00:25:40.870 --> 00:25:44.960\nBut it can usually to happen to anybody\nthat's got important data that can't\n\n524\n00:25:44.960 --> 00:25:45.950\nafford to lose it.\n\n525\n00:25:45.950 --> 00:25:49.130\nSo make sure that you\nhave backups ready to go.\n\n526\n00:25:50.600 --> 00:25:56.080\nAll right, so let me see,\nanything else I forgot on ransomware.\n\n527\n00:25:56.080 --> 00:25:56.910\nNo, it looks like it,\n\n528\n00:25:56.910 --> 00:26:00.630\njust keep in mind that there are\ndefinitely different forms of ransomware.\n\n529\n00:26:00.630 --> 00:26:03.500\nSome could be relatively easy\nto get off of your systems and\n\n530\n00:26:03.500 --> 00:26:06.110\ntake care of like something\nlike a simple FBI warning.\n\n531\n00:26:06.110 --> 00:26:09.870\nHowever keep in mind, some of them can\nbe a little bit more sophisticated in\n\n532\n00:26:09.870 --> 00:26:12.050\nthe fact that they're gonna\nstart to encrypt your data now.\n\n533\n00:26:12.050 --> 00:26:16.690\nIt's even worse too, and I should\nmention this because when I talk about\n\n534\n00:26:16.690 --> 00:26:20.220\na crypto-malware, I'm only talking\nabout the point of a single system.\n\n535\n00:26:20.220 --> 00:26:23.910\nNow these systems can work a lot like or\nthese cryptomalware can work a lot\n\n536\n00:26:23.910 --> 00:26:27.350\nlike things like worms where they\nspread themselves to multiple machines.\n\n537\n00:26:27.350 --> 00:26:29.850\nAnd they can encrypt your entire data.\n\n538\n00:26:29.850 --> 00:26:34.430\nThey can look out for things like SMB\nshares on your networks, NFS shares,\n\n539\n00:26:34.430 --> 00:26:36.450\nnetwork file system.\n\n540\n00:26:36.450 --> 00:26:38.550\n&gt;&gt; Centralized storage locations.\n\n541\n00:26:38.550 --> 00:26:40.060\n&gt;&gt; Very good.\nCentralized storage,\n\n542\n00:26:40.060 --> 00:26:41.480\nauthentication servers.\n\n543\n00:26:41.480 --> 00:26:43.160\nAnd they can spread themselves and\n\n544\n00:26:43.160 --> 00:26:46.570\nthey can start encrypting basically\nyour network infrastructure.\n\n545\n00:26:46.570 --> 00:26:51.020\nSo don't think that these are restricted\nto just a single system when most likely,\n\n546\n00:26:51.020 --> 00:26:52.090\nthey can also spread.\n\n547\n00:26:52.090 --> 00:26:55.160\nAnd they can spread to multiple systems\nand before you know it, your entire\n\n548\n00:26:56.990 --> 00:27:00.660\nnetwork data is now encrypted and\nyou no longer have access to it.\n\n549\n00:27:00.660 --> 00:27:04.680\nAnd when you're talking like a small home\nenvironment, that might not sound so bad.\n\n550\n00:27:04.680 --> 00:27:10.040\nBut when you're talking about a company\nlike Amazon or LLB or Microsoft where\n\n551\n00:27:10.040 --> 00:27:13.690\nwith Glitter Cloud technologies,\nthey can make a million dollars an hour.\n\n552\n00:27:13.690 --> 00:27:17.910\nThat's a lot of money to be lost,\nwhen something as simple as a back up\n\n553\n00:27:17.910 --> 00:27:19.870\ncould help to mitigate\nthe risk of that happening.\n\n554\n00:27:21.400 --> 00:27:21.910\n&gt;&gt; Sounds great.\n\n555\n00:27:21.910 --> 00:27:23.150\nAnd you mentioned worm.\n\n556\n00:27:23.150 --> 00:27:26.210\nBut we're running out of time for\nthis particular episode and\n\n557\n00:27:26.210 --> 00:27:27.140\nI don't wanna cut it short.\n\n558\n00:27:27.140 --> 00:27:31.100\nSo let's go ahead and we'll have another,\na continuation, part two.\n\n559\n00:27:31.100 --> 00:27:34.180\nI wanna say two but I'm not sure how\nmany parts we'll have for this series.\n\n560\n00:27:34.180 --> 00:27:36.200\nThere's a lot of different\ntypes of malware to cover.\n\n561\n00:27:36.200 --> 00:27:39.760\nSo ladies and gentlemen, stay tuned and\nwe'll get you covered here.\n\n562\n00:27:39.760 --> 00:27:41.960\nBut for this particular show,\nwe'll go ahead and sign out.\n\n563\n00:27:41.960 --> 00:27:43.560\nRemember, I'm your host, Cherokee Boose.\n\n564\n00:27:43.560 --> 00:27:44.350\n&gt;&gt; And I'm Wes Ryan.\n\n565\n00:27:44.350 --> 00:27:47.500\n&gt;&gt; See you next time here at ITProTV.\n\n566\n00:27:47.500 --> 00:27:53.371\n[MUSIC]\n\n567\n00:27:53.371 --> 00:27:56.986\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "211740069"
        },
        {
          "description": "This is a continuation of a previous show discussion where Cherokee and Wes discuss several types of malware. They pick up explaining how a worm is different from a virus. Next, they cover trojans, rootkits, keyloggers and adware.",
          "length": "2115",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-1-2-determining_types_of_malware-040317-040317-PGM.00_35_01_04.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-1-2-determining_types_of_malware-040317-040317-PGM.00_35_01_04.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-1-2-determining_types_of_malware-040317-040317-PGM.00_35_01_04.Still001-sm.jpg",
          "title": "Determining Types of Malware Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.767\nWelcome to ITProTV,\nI'm your host, Don Pezet-\n\n2\n00:00:02.767 --> 00:00:08.038\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:08.038 --> 00:00:11.967\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.967 --> 00:00:14.680\n&gt;&gt; Welcome to your\nCompTIA Security+ Series.\n\n5\n00:00:14.680 --> 00:00:16.440\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.440 --> 00:00:17.790\nThis is actually a part two,\n\n7\n00:00:17.790 --> 00:00:21.350\na continuation of a previous\nconversation that Wes and I were having.\n\n8\n00:00:21.350 --> 00:00:23.540\nWe were looking at\ndifferent forms of malware.\n\n9\n00:00:23.540 --> 00:00:25.470\nThere's a lot of different\ntypes of malware out there, so\n\n10\n00:00:25.470 --> 00:00:26.850\nwe're gonna go ahead and pick right up.\n\n11\n00:00:26.850 --> 00:00:28.870\nSo thank you for\njoining us today in the studios, Wes.\n\n12\n00:00:28.870 --> 00:00:30.460\n&gt;&gt; Absolutely, thanks for having me back.\n\n13\n00:00:30.460 --> 00:00:33.422\nYeah, it's scary when something on\na topic like this goes into a part two,\n\n14\n00:00:33.422 --> 00:00:35.692\ncuz it means, well,\nthere's more bad to come, right?\n\n15\n00:00:35.692 --> 00:00:37.357\n[LAUGH] But that's what we're gonna do.\n\n16\n00:00:37.357 --> 00:00:38.358\n&gt;&gt; When you put it that way, but yeah.\n\n17\n00:00:38.358 --> 00:00:40.669\n[LAUGH]\n&gt;&gt; It'd be one of those things that we\n\n18\n00:00:40.669 --> 00:00:43.347\nwish we didn't have a part two on this\none because we could say there is these\n\n19\n00:00:43.347 --> 00:00:45.317\ntwo bad things and\nthat's all you have to worry about.\n\n20\n00:00:45.317 --> 00:00:47.260\nBut unfortunately-\n&gt;&gt; Unfortunately [LAUGH]\n\n21\n00:00:47.260 --> 00:00:48.320\n&gt;&gt; We've got more to go.\n\n22\n00:00:48.320 --> 00:00:51.760\nSo we're gonna be looking at some of\nthe additional malware types that they\n\n23\n00:00:51.760 --> 00:00:54.940\ncall out on the exam and we're gonna kind\nof show you some of the effects that you\n\n24\n00:00:54.940 --> 00:00:56.670\nmight see when it comes to them.\n\n25\n00:00:56.670 --> 00:00:58.970\nWe kind of set it up in\nthe lab environment and\n\n26\n00:00:58.970 --> 00:01:02.340\nlet's just let you guys know\na little disclaimer ahead of time.\n\n27\n00:01:02.340 --> 00:01:05.680\nAnytime you're working with a virus,\nif it happens to be a live virus.\n\n28\n00:01:05.680 --> 00:01:07.830\nDo it in a virtualized environment.\n\n29\n00:01:07.830 --> 00:01:10.440\nAnd one of the things that we would\nalso recommend is not giving your\n\n30\n00:01:10.440 --> 00:01:13.350\nhost in your guest machine\naccess to each other.\n\n31\n00:01:13.350 --> 00:01:16.030\nAnd don't give the virtual\nmachine access to the network.\n\n32\n00:01:16.030 --> 00:01:18.200\nSo, since we don't have that.\n\n33\n00:01:18.200 --> 00:01:20.690\nWe don't really wanna have\nto worry about all of that.\n\n34\n00:01:20.690 --> 00:01:26.108\nWe went ahead and kind of set this up so\nyou guys can see what a virus might look\n\n35\n00:01:26.108 --> 00:01:31.971\nlike if it happens to attack your system,\nas far as some of the general symptoms.\n\n36\n00:01:31.971 --> 00:01:36.359\nBecause that’s one of the things\nthe objective does call out is being able\n\n37\n00:01:36.359 --> 00:01:40.534\nto identify the malware types of\nthe indicators that you do have some of\n\n38\n00:01:40.534 --> 00:01:43.440\nthese malware types on your computer.\n\n39\n00:01:43.440 --> 00:01:46.000\nSo let's go ahead and we'll jump ahead\nright back in with the next one.\n\n40\n00:01:46.000 --> 00:01:48.824\nKeep in mind in the first one,\nwe talked about things like viruses and\n\n41\n00:01:48.824 --> 00:01:51.077\ndifferent virus types,\nwe talked about ransomware.\n\n42\n00:01:51.077 --> 00:01:54.452\nRemember ransomware comes\nin many different forms,\n\n43\n00:01:54.452 --> 00:01:58.520\nIt could be very intrusive,\nit could be moderately intrusive.\n\n44\n00:01:58.520 --> 00:02:02.610\nThe FBI warning is one that we kinda say\nsometimes is moderately intrusive because\n\n45\n00:02:02.610 --> 00:02:05.560\nof the fact that it really\njust locks up your browser.\n\n46\n00:02:05.560 --> 00:02:08.220\nNow that being said,\nsome of them go a little bit more and\n\n47\n00:02:08.220 --> 00:02:10.510\nthey actually shut down\nexecutables as well, too.\n\n48\n00:02:10.510 --> 00:02:13.850\nSo you can see the browser,\nyou can see the FBI warning, but\n\n49\n00:02:13.850 --> 00:02:15.840\nthere's really nothing you\ncan launch to stop it.\n\n50\n00:02:15.840 --> 00:02:17.790\nThat's when they start getting\na little bit more intrusive.\n\n51\n00:02:17.790 --> 00:02:20.900\nThen, finally you have things\nlike crypto malware, right?\n\n52\n00:02:20.900 --> 00:02:22.400\nAnd when we talk about crypto malware,\n\n53\n00:02:22.400 --> 00:02:25.050\nwe're talking about now it's\ngetting it's a lucrative business\n\n54\n00:02:25.050 --> 00:02:27.270\nbecause what they're gonna do is\nthey're gonna encrypt your files.\n\n55\n00:02:27.270 --> 00:02:32.060\nYou're gonna have to communicate with\nthem in order to get the other key for\n\n56\n00:02:32.060 --> 00:02:37.230\nthe unencryption and whatever charge\nthat they end up charging you with.\n\n57\n00:02:37.230 --> 00:02:39.481\nWe actually had somebody\nin the chatroom that\n\n58\n00:02:39.481 --> 00:02:40.608\nmentioned-\n&gt;&gt; Sure did.\n\n59\n00:02:40.608 --> 00:02:42.543\n&gt;&gt; A database being compromised.\n\n60\n00:02:42.543 --> 00:02:46.108\nAnd then the company saying it\nwas just easier to go ahead and\n\n61\n00:02:46.108 --> 00:02:49.333\nwork with the attackers and\nactually pay the ransom.\n\n62\n00:02:49.333 --> 00:02:54.269\nSo there's no real write or wrong way,\nwe hope it never comes to that but\n\n63\n00:02:54.269 --> 00:02:57.729\nevery company has a different\nset of standards and\n\n64\n00:02:57.729 --> 00:03:01.205\nthe way they interact with\nthese type of attacks.\n\n65\n00:03:01.205 --> 00:03:04.992\nSo now the next one is another\nthat's very scary in itself and\n\n66\n00:03:04.992 --> 00:03:10.310\nthat's something known as a worm and worms\nhave been around for a good long while.\n\n67\n00:03:10.310 --> 00:03:15.610\nAnd the big difference between a worm and\nlike viruses, right.\n\n68\n00:03:15.610 --> 00:03:17.937\nIt's still a form of malware, right.\n\n69\n00:03:17.937 --> 00:03:20.708\nIt's still a piece of\ncode that's unauthorized,\n\n70\n00:03:20.708 --> 00:03:24.720\nright, caused some kind of\nundesired effect on your machine.\n\n71\n00:03:24.720 --> 00:03:27.758\nHere's where the worms,\nthey take it a step farther.\n\n72\n00:03:27.758 --> 00:03:31.420\nAnd that's because they're fully self\nsufficient, unlike a virus, right?\n\n73\n00:03:31.420 --> 00:03:36.930\nA virus needs a host, typically,\nto make its way onto your computer.\n\n74\n00:03:36.930 --> 00:03:37.900\nMost viruses do.\n\n75\n00:03:37.900 --> 00:03:40.488\nI'm sure they're getting sophisticated\nenough to where you might have some\n\n76\n00:03:40.488 --> 00:03:41.657\nthat could just do what they want.\n\n77\n00:03:41.657 --> 00:03:45.126\nBut for the most part,\ngeneral classification of a virus is hey,\n\n78\n00:03:45.126 --> 00:03:47.778\nit needs to attach itself\nto an email attachment,\n\n79\n00:03:47.778 --> 00:03:52.133\na file that you're downloading, a piece\nof software that you're downloading,\n\n80\n00:03:52.133 --> 00:03:55.627\nif you're not downloading from\ntrusted installation sources.\n\n81\n00:03:55.627 --> 00:03:59.230\nThe worm, on the other hand,\ndoesn't need a host.\n\n82\n00:03:59.230 --> 00:04:01.400\nIn fact, it is totally self-sufficient.\n\n83\n00:04:01.400 --> 00:04:05.561\nIt is perfectly fine being a loner,\nby itself out there on the Internet.\n\n84\n00:04:05.561 --> 00:04:09.515\nIf fact, sitting outside of your router,\nyour gateway, just waiting for\n\n85\n00:04:09.515 --> 00:04:10.850\na port of entry, right?\n\n86\n00:04:10.850 --> 00:04:13.510\nWaiting for\nsomething that it can exploit so\n\n87\n00:04:13.510 --> 00:04:15.960\nthat it can make its\nway onto your network.\n\n88\n00:04:15.960 --> 00:04:16.710\nAnd then what does it do?\n\n89\n00:04:16.710 --> 00:04:19.945\nIn fact,\nI got a little diagram here, right?\n\n90\n00:04:19.945 --> 00:04:21.555\nIf we look at worms can do, right?\n\n91\n00:04:21.555 --> 00:04:23.895\nThey can be Internet based, right?\n\n92\n00:04:23.895 --> 00:04:27.365\nAgain, they can make their way on\nthe systems just like some of the other\n\n93\n00:04:27.365 --> 00:04:28.855\nviruses do, right?\n\n94\n00:04:28.855 --> 00:04:34.760\nThings like your USB based, or maybe it\nis, you put it into a USB drive, right?\n\n95\n00:04:34.760 --> 00:04:38.325\nYou throw the USB drives out in\nthe parking lot, and somebody says\n\n96\n00:04:38.325 --> 00:04:42.375\nwhat's this, this is a nice, flashy\nshiny new USB device, let’s go ahead and\n\n97\n00:04:42.375 --> 00:04:46.380\nlet’s see what’s on that thing, and\nthey plug it into their computer.\n\n98\n00:04:46.380 --> 00:04:50.470\nNow, it makes its way onto your network\nand it starts going to town, right?\n\n99\n00:04:50.470 --> 00:04:51.330\nThey can also be email based,\n\n100\n00:04:51.330 --> 00:04:55.120\nand that’s one of the reasons we say,\nin fact Cherokee and\n\n101\n00:04:55.120 --> 00:04:59.100\nI were talking about this in the first\npart, education, awareness, right.\n\n102\n00:04:59.100 --> 00:05:02.702\nDon't open up emails even if it says,\nhey, this came from your mom, or\n\n103\n00:05:02.702 --> 00:05:04.642\nthis came from your brother, right.\n\n104\n00:05:04.642 --> 00:05:06.412\nOr it came from the boss.\n\n105\n00:05:06.412 --> 00:05:08.510\nMake sure that it did right?\n\n106\n00:05:08.510 --> 00:05:13.160\nKnow who it It is that you're receiving\nemails from before you open up any\n\n107\n00:05:13.160 --> 00:05:14.400\nattachments.\n\n108\n00:05:15.660 --> 00:05:19.260\nOther infected systems, and this is\nwhere the worm starts to kind of shine.\n\n109\n00:05:19.260 --> 00:05:21.240\nAnd I say that in a bad sense.\n\n110\n00:05:21.240 --> 00:05:22.010\nThe attacker would think this, right?\n\n111\n00:05:22.010 --> 00:05:23.500\n&gt;&gt; Infamous.\n\n112\n00:05:23.500 --> 00:05:28.080\n&gt;&gt; Yes, exactly, because once it hits\nan infected system, what does it do?\n\n113\n00:05:28.080 --> 00:05:29.730\nIt replicates,right?\n\n114\n00:05:29.730 --> 00:05:32.810\nMost of your viruses, a lot of your\nviruses will replicate, right?\n\n115\n00:05:32.810 --> 00:05:37.100\nThey'll do viral replication, becomes\nvery, very hard to get rid of them.\n\n116\n00:05:37.100 --> 00:05:41.350\nHowever, a virus usually just replicates\nso that it protects itself and\n\n117\n00:05:41.350 --> 00:05:43.305\nit can stay on a system.\n\n118\n00:05:43.305 --> 00:05:48.575\nA worm will replicate itself until there\nare no resources left, no storage space,\n\n119\n00:05:48.575 --> 00:05:49.725\nall right?\n\n120\n00:05:49.725 --> 00:05:52.795\nThat's one of the telltale signs that you\ngot something like a worm is the fact that\n\n121\n00:05:52.795 --> 00:05:58.230\nmaybe you went to bed the night before and\nyou had a one terabyte hard drive, right?\n\n122\n00:05:58.230 --> 00:05:59.890\nAnd let's say that your studious,\n\n123\n00:05:59.890 --> 00:06:02.710\nyou just happened to figure out that\nyou were already using a couple\n\n124\n00:06:02.710 --> 00:06:06.910\nhundred gigs of that one terabyte\ndrive just as normal use and files.\n\n125\n00:06:07.960 --> 00:06:11.340\nWake up the next morning and\nit's one terabyte is completely consumed.\n\n126\n00:06:11.340 --> 00:06:15.260\nRight, then you might have, and\nit's kind of hard to find out, but\n\n127\n00:06:15.260 --> 00:06:17.940\nif you have another system on your\nnetwork that now is also full,\n\n128\n00:06:17.940 --> 00:06:20.680\ntoo that really is\na telltale sign of a worm.\n\n129\n00:06:20.680 --> 00:06:22.569\nBecause it's not just files.\n\n130\n00:06:22.569 --> 00:06:25.550\nI don't want you to think it's\njust storage concerns either.\n\n131\n00:06:25.550 --> 00:06:29.080\nWorms try to consume your\nnetwork bandwidth as well.\n\n132\n00:06:29.080 --> 00:06:32.040\nLiterally, they will bring\na whole network down, right?\n\n133\n00:06:32.040 --> 00:06:34.831\nJust completely crumble it,\nbring it to it's knees and cripple it.\n\n134\n00:06:34.831 --> 00:06:38.917\nBut because its also consuming all\nof your network communications.\n\n135\n00:06:38.917 --> 00:06:42.339\nLet's think of it this way,\nI've got an authentication sever,\n\n136\n00:06:42.339 --> 00:06:45.900\nI know Cherokee here worked heavily\nwith Windows Server and stuff.\n\n137\n00:06:45.900 --> 00:06:49.960\nCan you image if a worm was just gonna\nsend all this types of communications to\n\n138\n00:06:49.960 --> 00:06:51.060\nyour authentication server?\n\n139\n00:06:51.060 --> 00:06:53.070\n&gt;&gt; Preventing users from logging on.\n\n140\n00:06:53.070 --> 00:06:56.372\nWhat kind of denial of service\nwould be more disruptive?\n\n141\n00:06:56.372 --> 00:06:59.610\n&gt;&gt; Absolutely, right now no one\ncan get onto the system, and\n\n142\n00:06:59.610 --> 00:07:02.466\nyou might still have plenty\nof network bandwidth.\n\n143\n00:07:02.466 --> 00:07:07.299\nThis could just be those initial attacks,\nright, that start to happen.\n\n144\n00:07:07.299 --> 00:07:12.590\nThey start to consumer your resources,\ndisk consumption,\n\n145\n00:07:12.590 --> 00:07:14.850\nmemory resources, memory utilization.\n\n146\n00:07:16.340 --> 00:07:18.880\nAnd then also ultimately,\noops, that last one,\n\n147\n00:07:18.880 --> 00:07:21.180\nlet me go ahead and fix my slide here.\n\n148\n00:07:21.180 --> 00:07:23.760\nNetwork resources too,\nyour network bandwidth.\n\n149\n00:07:23.760 --> 00:07:27.230\nYou have things like your buffers we\ntalk about buffer overflows, right.\n\n150\n00:07:27.230 --> 00:07:30.039\nThere's a certain amount of space\non a network adapter that you\n\n151\n00:07:30.039 --> 00:07:33.168\ncan store information until we start\nthrowing information away, and\n\n152\n00:07:33.168 --> 00:07:34.930\nwe just can't process it fast enough.\n\n153\n00:07:34.930 --> 00:07:37.660\nSome worms can even cause things\nas like denial of service attacks.\n\n154\n00:07:38.690 --> 00:07:41.470\nThen what happens when they're\ndone consuming your network?\n\n155\n00:07:41.470 --> 00:07:43.730\nWell, they hop onto another network.\n\n156\n00:07:43.730 --> 00:07:46.293\nAnd then they do the same thing and\nthe same thing.\n\n157\n00:07:46.293 --> 00:07:50.296\nAnd without getting too repetitious here,\nthat's exactly what's gonna happen until\n\n158\n00:07:50.296 --> 00:07:53.119\nthey start to propagate themselves\nout across the Internet.\n\n159\n00:07:53.119 --> 00:07:56.685\nOut across multiple systems and before\nyou know it, we've got a good section and\n\n160\n00:07:56.685 --> 00:08:00.321\nportion of the Internet that if these\naren't stopped, it could really cripple.\n\n161\n00:08:00.321 --> 00:08:04.860\nSo these are some very,\nvery nasty pieces of code and\n\n162\n00:08:04.860 --> 00:08:08.180\nthat's one of the things, the big\ntakeaways that I want you to remember.\n\n163\n00:08:08.180 --> 00:08:10.119\nThe big difference between a virus and\na worm.\n\n164\n00:08:10.119 --> 00:08:13.380\nA virus typically needs\na host to propagate itself.\n\n165\n00:08:13.380 --> 00:08:13.920\nWorms do not.\n\n166\n00:08:13.920 --> 00:08:18.010\nThey're a self-sufficient,\nself-replicating piece of code.\n\n167\n00:08:18.010 --> 00:08:19.660\nAll they need is a port of entry.\n\n168\n00:08:19.660 --> 00:08:22.876\nWe've got worms that have been on\nthe backbone of the Internet now since\n\n169\n00:08:22.876 --> 00:08:23.420\nthe 90s.\n\n170\n00:08:23.420 --> 00:08:24.920\nAnd they're still there.\n\n171\n00:08:24.920 --> 00:08:26.710\nThey're never gonna go away, right?\n\n172\n00:08:26.710 --> 00:08:31.430\nMaybe some farthest, unreached,\nthe farthest reaches of the Internet with\n\n173\n00:08:31.430 --> 00:08:33.320\nunpatched systems,\nthey might still be affecting.\n\n174\n00:08:33.320 --> 00:08:36.580\nBut for the most part, they're patched,\nbut they'll never go away.\n\n175\n00:08:36.580 --> 00:08:39.710\nSo you have to keep in mind\nthat worms don't just go away.\n\n176\n00:08:39.710 --> 00:08:43.110\nThey'll be on the Internet and they'll\nbe there until the Internet is done.\n\n177\n00:08:43.110 --> 00:08:45.268\nIt's important that we patch our systems,\nso\n\n178\n00:08:45.268 --> 00:08:48.530\nthat those worms that are out\nthere don't affect us any longer.\n\n179\n00:08:48.530 --> 00:08:52.800\nSo make sure that you are constantly\nupdating your system.\n\n180\n00:08:52.800 --> 00:08:57.670\nI mentioned polymorphic virus,\none that just basically modifies itself,\n\n181\n00:08:57.670 --> 00:09:00.900\nit keeps the anti-virus software running.\n\n182\n00:09:00.900 --> 00:09:05.043\nWe also have polymorphic worms, right?\n\n183\n00:09:05.043 --> 00:09:08.970\nAnd that gets a whole\nanother layer of complexity,\n\n184\n00:09:08.970 --> 00:09:12.380\nthe fact that once you can identify the\nworm and you try to eradicate it, right.\n\n185\n00:09:12.380 --> 00:09:15.769\nThink about all these pieces that\nare replicating and now each,\n\n186\n00:09:15.769 --> 00:09:17.608\nif they were color coded, right.\n\n187\n00:09:17.608 --> 00:09:22.260\nJust for explanation,\nI got red worms, right,\n\n188\n00:09:22.260 --> 00:09:25.180\nall of a sudden, we go to eradicate them.\n\n189\n00:09:25.180 --> 00:09:29.680\nA couple of them are still left and they\nchange the color, now we got green, right?\n\n190\n00:09:29.680 --> 00:09:31.420\nNow they change, now we got blue.\n\n191\n00:09:31.420 --> 00:09:34.590\nAnd again, just for the colors don't\nmatter but understand that what it does\n\n192\n00:09:34.590 --> 00:09:38.270\nis it keeps your anti-virus software,\nyour anti-malware software guessing.\n\n193\n00:09:38.270 --> 00:09:41.170\nAnd that's why it's also\nimportant to implement things like\n\n194\n00:09:41.170 --> 00:09:43.160\nheuristics in cloud based solutions too.\n\n195\n00:09:43.160 --> 00:09:46.130\nBecause of the fact that you can\nconstantly be checking with other people,\n\n196\n00:09:46.130 --> 00:09:48.500\nthat maybe they've had\nthis problem before.\n\n197\n00:09:48.500 --> 00:09:53.010\nMaybe they've seen this type of\nbailware and can help you eradicate it.\n\n198\n00:09:53.010 --> 00:09:57.850\nAll right, so\nthat's got some of the major types.\n\n199\n00:09:57.850 --> 00:10:00.030\nWe do have a couple more that\nwe need to talk about and\n\n200\n00:10:00.030 --> 00:10:02.940\nthey are important to be aware of.\n\n201\n00:10:02.940 --> 00:10:07.240\nAs we move through the list,\nsome of these get into severity,\n\n202\n00:10:07.240 --> 00:10:09.350\nthey definitely get more severe.\n\n203\n00:10:09.350 --> 00:10:12.800\nThis one here, the next one we're gonna\ntalk about is what's known as a Trojan.\n\n204\n00:10:12.800 --> 00:10:14.350\nA Trojan is a little bit different.\n\n205\n00:10:14.350 --> 00:10:19.310\nAnd let me tell you one of the big\nmain differences with a Trojan\n\n206\n00:10:19.310 --> 00:10:22.700\nversus every other piece of malware\nthat you're gonna see in your systems,\n\n207\n00:10:22.700 --> 00:10:24.250\nwith the exception of\nmaybe the logic bomb.\n\n208\n00:10:24.250 --> 00:10:26.530\nIt does have some characteristics here.\n\n209\n00:10:26.530 --> 00:10:30.820\nAll right, a trojan does not seek to\npropagate itself, or replicate itself.\n\n210\n00:10:32.042 --> 00:10:34.940\nA trojan doesn't, it paves the way for\nother attacks and\n\n211\n00:10:34.940 --> 00:10:36.060\nthat's something to understand.\n\n212\n00:10:36.060 --> 00:10:39.530\nSo for instance,\nif we pull up my slide here.\n\n213\n00:10:39.530 --> 00:10:43.540\nA trojan horse is one of these pieces of\nsoftware that you can get while you're web\n\n214\n00:10:43.540 --> 00:10:45.900\nbrowsing, through a file transfer.\n\n215\n00:10:45.900 --> 00:10:47.260\nNotice email keeps coming up?\n\n216\n00:10:47.260 --> 00:10:49.046\nEmail attachments, right?\n\n217\n00:10:49.046 --> 00:10:51.660\nAnd it doesn't seek to propagate itself.\n\n218\n00:10:51.660 --> 00:10:54.360\nWhat it does is it just lies dormant.\n\n219\n00:10:54.360 --> 00:10:56.210\nIt waits.\n\n220\n00:10:56.210 --> 00:11:01.130\nMaybe it installs things\nlike a backdoor virus,\n\n221\n00:11:01.130 --> 00:11:04.340\na backdoor account, right.\n\n222\n00:11:04.340 --> 00:11:07.730\nSo it can do things like for\ninstance maybe it paves the way for\n\n223\n00:11:07.730 --> 00:11:09.120\na scanning attack.\n\n224\n00:11:09.120 --> 00:11:11.300\nMaybe it paves the way for\na botnet, right,\n\n225\n00:11:11.300 --> 00:11:15.070\nwe've gotta be able to get that zombie,\nthat drone software on the machine,\n\n226\n00:11:15.070 --> 00:11:17.210\nso how do you get that\nsoftware on the machine?\n\n227\n00:11:17.210 --> 00:11:19.095\nUnbeknownst to the user?\n\n228\n00:11:19.095 --> 00:11:21.230\nWel,l you put it in\nsomething that looks benign.\n\n229\n00:11:21.230 --> 00:11:22.770\n&gt;&gt; Very appealing.\n&gt;&gt; And when they click on it.\n\n230\n00:11:22.770 --> 00:11:23.930\nThere we go, appealing.\n\n231\n00:11:23.930 --> 00:11:24.570\nI like that too.\n\n232\n00:11:24.570 --> 00:11:27.020\nBecause think about I believe it\n\n233\n00:11:27.020 --> 00:11:28.830\nwas you that were mentioned\nin the first part of this.\n\n234\n00:11:28.830 --> 00:11:30.670\nWhen we look at things like cards.\n\n235\n00:11:30.670 --> 00:11:33.100\nA card comes in, you're like,\nman, somebody loves me.\n\n236\n00:11:33.100 --> 00:11:33.824\nI gotta open that.\n\n237\n00:11:33.824 --> 00:11:35.182\n&gt;&gt; [LAUGH]\n&gt;&gt; Who sent that to me?\n\n238\n00:11:35.182 --> 00:11:36.002\nThe analogy, right?\n\n239\n00:11:36.002 --> 00:11:37.078\nPlaying on your emotions.\n\n240\n00:11:37.078 --> 00:11:39.177\nNow you click that little\nglitter graphic in that.\n\n241\n00:11:40.440 --> 00:11:43.640\nAnd a little command prompt\nwhen it runs and shuts down.\n\n242\n00:11:43.640 --> 00:11:45.790\nYou go, that didn't work,\nlet me click it five more times.\n\n243\n00:11:45.790 --> 00:11:47.710\nMaybe if I click it five more\ntimes I can open it, right?\n\n244\n00:11:47.710 --> 00:11:49.940\n&gt;&gt; Yeah, Wes,\nI'm still waiting to get skinny and\n\n245\n00:11:49.940 --> 00:11:53.060\nsmarter from those advertisements\nthat we see online.\n\n246\n00:11:53.060 --> 00:11:54.210\n&gt;&gt; Well, in fairness to them,\n\n247\n00:11:54.210 --> 00:11:56.490\nthey just said you had to buy\nthe equipment to lose weight.\n\n248\n00:11:56.490 --> 00:11:57.795\nThey never told us we had to use it.\n\n249\n00:11:57.795 --> 00:11:59.390\n[LAUGH] But that's right.\n\n250\n00:11:59.390 --> 00:12:03.480\nAgain, it's preying on that hey,\nI wanna get in shape, right?\n\n251\n00:12:03.480 --> 00:12:05.780\nWell, go ahead and\nclick on this ad, right?\n\n252\n00:12:05.780 --> 00:12:10.380\nAnd again, unbeknownst to you,\nyou've now downloaded a piece of software.\n\n253\n00:12:10.380 --> 00:12:12.690\nWhere it's gonna sit\nidle on your computer.\n\n254\n00:12:12.690 --> 00:12:13.390\nMaybe it is gonna run.\n\n255\n00:12:13.390 --> 00:12:14.900\nMaybe it is a logic bomb, right?\n\n256\n00:12:14.900 --> 00:12:16.890\nMaybe it's part of an all\nout bot net attack.\n\n257\n00:12:16.890 --> 00:12:18.130\nAnd the what happens?\n\n258\n00:12:18.130 --> 00:12:21.510\nA trigger event comes on, all of your\nmachines that have been infected or\n\n259\n00:12:21.510 --> 00:12:23.440\nall the machines that have been infected,\nagain,\n\n260\n00:12:23.440 --> 00:12:26.010\nsimultaneously attack a single target.\n\n261\n00:12:26.010 --> 00:12:28.930\nSo again,\nthat's one of the things to keep in mind,\n\n262\n00:12:28.930 --> 00:12:34.340\nis that it really does differentiate\nitself a little bit, right?\n\n263\n00:12:34.340 --> 00:12:35.960\nIt doesn't propagate itself.\n\n264\n00:12:35.960 --> 00:12:38.240\nIt doesn't, like self-propagation, right?\n\n265\n00:12:38.240 --> 00:12:41.240\nEmail attachments obviously\nare propagating, right,\n\n266\n00:12:41.240 --> 00:12:43.140\nif you send them out to multiple users.\n\n267\n00:12:43.140 --> 00:12:45.500\nBut it's not built into the code itself.\n\n268\n00:12:45.500 --> 00:12:49.000\nSo there again, these are things\nthat you have to worry about,\n\n269\n00:12:49.000 --> 00:12:51.870\nbecause they can make their way\non to your computer, right?\n\n270\n00:12:51.870 --> 00:12:53.280\nThey make their way on to their computer.\n\n271\n00:12:53.280 --> 00:12:55.770\nThey install things like keyloggers,\nright?\n\n272\n00:12:55.770 --> 00:12:57.060\nWhat's the keylogger?\n\n273\n00:12:57.060 --> 00:12:59.880\nWell the keylogger can\nbe one of two things.\n\n274\n00:12:59.880 --> 00:13:03.720\nIn this aspect what we're talking about\nis a software based keylogger, all right?\n\n275\n00:13:05.030 --> 00:13:07.870\nKeyloggers, essentially what they\ndo is they report your key strokes.\n\n276\n00:13:07.870 --> 00:13:11.195\nSo when we're We're gonna see\nan example of one coming up.\n\n277\n00:13:11.195 --> 00:13:14.555\nBut again, they install things the trojans\ngets on your computer it installs\n\n278\n00:13:14.555 --> 00:13:18.165\nsomething like a key logger, and now what\nit's doing is kinda like a reverse proxy,\n\n279\n00:13:18.165 --> 00:13:21.320\nit sending information out to\nsomebody's email address out to a list.\n\n280\n00:13:21.320 --> 00:13:26.590\nServer that's waiting now has all\nthe keystrokes, has your bank account\n\n281\n00:13:26.590 --> 00:13:29.690\nemail and password, even your secret key,\nwhere you were clicking,\n\n282\n00:13:29.690 --> 00:13:34.130\nwhat browser you were using,\nwhat website you were viewing, right?\n\n283\n00:13:34.130 --> 00:13:39.010\nAnd now we go into the fact that it has\ngone from just a piece of software that's\n\n284\n00:13:39.010 --> 00:13:43.760\npaving the way to another attack To\nactually opening up that avenue and\n\n285\n00:13:43.760 --> 00:13:46.870\nthen we end with an attack.\n\n286\n00:13:46.870 --> 00:13:50.600\n&gt;&gt; So Wes, looking at a trojan it might\nmake a little more sense why system and\n\n287\n00:13:50.600 --> 00:13:53.650\nnetwork admins restrict the type\nof sites and downloads.\n\n288\n00:13:53.650 --> 00:13:57.940\nSo instead of say, or preventing if\nmy admin says I'm not allowed to\n\n289\n00:13:57.940 --> 00:14:00.840\ndownload Candy Crush and\ndifferent types of online games.\n\n290\n00:14:00.840 --> 00:14:04.400\nIt's not that they're trying to mean and\nflex their IT muscle,\n\n291\n00:14:04.400 --> 00:14:07.330\nbut it's because ultimately, that's\ntheir responsibility, so they just wanna\n\n292\n00:14:07.330 --> 00:14:11.640\nmake sure that they're reducing the amount\nof risks within that environment.\n\n293\n00:14:11.640 --> 00:14:14.430\n&gt;&gt; Most definitely, and if you think about\nit, it's just a click that can happen.\n\n294\n00:14:14.430 --> 00:14:16.490\n&gt;&gt; Sure.\n&gt;&gt; Right, I mean it's easier to,\n\n295\n00:14:16.490 --> 00:14:17.716\nI mean it's so easy.\n\n296\n00:14:17.716 --> 00:14:18.260\n&gt;&gt; [LAUGH]\n&gt;&gt; To get them\n\n297\n00:14:18.260 --> 00:14:20.030\n&gt;&gt; It off or on to your machine.\n\n298\n00:14:20.030 --> 00:14:22.670\nBut it's a lot more complex to\nget it off of your machine.\n\n299\n00:14:22.670 --> 00:14:27.610\nAnd that's one of the reasons we have to\ngo through these type of access controls,\n\n300\n00:14:27.610 --> 00:14:28.390\nsecurity in depth.\n\n301\n00:14:28.390 --> 00:14:30.570\nTo make sure that that doesn't happen.\n\n302\n00:14:30.570 --> 00:14:33.450\nThe other one that they call,\nI really don't have a slide or\n\n303\n00:14:33.450 --> 00:14:34.570\nanything like that for this one.\n\n304\n00:14:34.570 --> 00:14:35.810\nWe're gonna talk about this one.\n\n305\n00:14:35.810 --> 00:14:37.990\nAnd that It's probably one of the most,\n\n306\n00:14:37.990 --> 00:14:41.760\nI don't know they are all bad\nthere's nothing good about these.\n\n307\n00:14:41.760 --> 00:14:45.050\nBut this is a really complex attack, and\n\n308\n00:14:45.050 --> 00:14:47.680\nsometimes it's one of the most\ndifficult to get off your system.\n\n309\n00:14:47.680 --> 00:14:51.870\nAnd this what's known as a root kit,\nthe root kit is.\n\n310\n00:14:51.870 --> 00:14:53.680\nWell first of all how does\nit even get it's name.\n\n311\n00:14:53.680 --> 00:14:54.810\n&gt;&gt; It's name.\nWell,\n\n312\n00:14:54.810 --> 00:14:58.470\nit gets it's name going back to the Unix\nbased systems, when they first started.\n\n313\n00:14:58.470 --> 00:15:02.230\nYou'd say Linux as well today too but\nmore so Unix, when it first started,\n\n314\n00:15:02.230 --> 00:15:06.970\nis that this was a program that tried\nto gain a privilege escalation.\n\n315\n00:15:06.970 --> 00:15:09.320\nBasically, it\n&gt;&gt; They tried to become the root user.\n\n316\n00:15:09.320 --> 00:15:14.590\nAnd in the Unix, Linux slash world, if you\nwill, NIX systems, as I like to call them.\n\n317\n00:15:14.590 --> 00:15:16.680\nYour root user is like your\nWindows administrator, right?\n\n318\n00:15:16.680 --> 00:15:17.930\nSo highest pro list account.\n\n319\n00:15:17.930 --> 00:15:22.230\nSo if you have a piece of software\nthat can act as the route or act as a.\n\n320\n00:15:22.230 --> 00:15:26.640\nAnd those of you guys that are in Windows\nsystems administration that act as\n\n321\n00:15:26.640 --> 00:15:30.100\na Windows administrator, you now have\nfull privileges are over the system.\n\n322\n00:15:30.100 --> 00:15:33.490\nSo if a rootkit can get into your system,\nthen it can do that as well.\n\n323\n00:15:33.490 --> 00:15:36.910\nIt can act like an administrator.\n\n324\n00:15:36.910 --> 00:15:39.820\nAnd it can act like\nthe root user if you will.\n\n325\n00:15:39.820 --> 00:15:43.200\nAnd even more so,\nit can act like the system account or\n\n326\n00:15:43.200 --> 00:15:46.570\neven hide itself from\nthe entire operating system.\n\n327\n00:15:46.570 --> 00:15:51.433\nAnd ultimately can give somebody\naccess like remote control\n\n328\n00:15:51.433 --> 00:15:55.543\naccess to your machine\nCouple of different types.\n\n329\n00:15:55.543 --> 00:15:57.980\nYou have, well,\none that's an easier type to get rid of.\n\n330\n00:15:57.980 --> 00:16:00.410\nThis is called a user mode root kit.\n\n331\n00:16:01.590 --> 00:16:03.460\nWe should be worried about all of these.\n\n332\n00:16:03.460 --> 00:16:06.405\nI personally don't worry about the user\nmode cuz they're not as common as\n\n333\n00:16:06.405 --> 00:16:07.315\nthe kernel mode.\n\n334\n00:16:07.315 --> 00:16:08.040\nRoot kits,\n\n335\n00:16:08.040 --> 00:16:12.982\na user mode root kit basically means that\nit runs as a privileged it runs as a user.\n\n336\n00:16:12.982 --> 00:16:18.855\nAnd in OS architecture, you're standard\nusers, your non-super users, if you will.\n\n337\n00:16:18.855 --> 00:16:24.425\nThey don't have the privilege access\nto changing operating system drivers,\n\n338\n00:16:24.425 --> 00:16:25.455\nsecurity settings.\n\n339\n00:16:25.455 --> 00:16:29.210\nSo, if you get one of\nthese user mode root kits.\n\n340\n00:16:29.210 --> 00:16:34.490\nMost often, your anti-virus software,\nif it does catch it, can eliminate it.\n\n341\n00:16:34.490 --> 00:16:38.360\nWhere it starts to get tricky\nare the kernel mode root kits.\n\n342\n00:16:38.360 --> 00:16:41.150\nAnd these are what a lot\nof the rootkits are,\n\n343\n00:16:41.150 --> 00:16:45.410\ncuz they wanna get down to the lowest\nportions of the operating system.\n\n344\n00:16:45.410 --> 00:16:49.597\nAnd they really wanna do things like, even\nsit in between your OS drivers, right?\n\n345\n00:16:49.597 --> 00:16:51.950\nThink about what an OS driver does.\n\n346\n00:16:51.950 --> 00:16:55.020\nIt take a high level programming\nlanguage from the operating system and\n\n347\n00:16:55.020 --> 00:17:00.300\ntranslates any of the calls\ndown to a low level\n\n348\n00:17:00.300 --> 00:17:04.940\nmachine language that are hardware\nbasically responds to.\n\n349\n00:17:04.940 --> 00:17:09.296\nNow, imagine you take the driver out and\nyou put a rootkit in the middle.\n\n350\n00:17:09.296 --> 00:17:13.798\nAnd anything that the operating\nsystem's calling down to the hardware.\n\n351\n00:17:13.798 --> 00:17:18.580\nThe rootkit intercepts,\nmanipulates it anyway that it wants to,\n\n352\n00:17:18.580 --> 00:17:21.770\ntells the user and\n\n353\n00:17:21.770 --> 00:17:26.980\nthe operating system the results that the\noperating system thinks it should expect.\n\n354\n00:17:26.980 --> 00:17:29.330\nBut in reality,\ndown there in the lowest levels,\n\n355\n00:17:29.330 --> 00:17:32.450\nthe rootkit is actually\nmasquerading all of that.\n\n356\n00:17:32.450 --> 00:17:35.740\nIt can be very, very hard to get rid of.\n\n357\n00:17:35.740 --> 00:17:40.485\nAnd one of the things too, just like your\nresident viruses these load a lot of\n\n358\n00:17:40.485 --> 00:17:43.760\ntimes at the point that\nthe operating system loads.\n\n359\n00:17:43.760 --> 00:17:47.020\nWhich means your antivirus software\nisn't even engaged at that time,\n\n360\n00:17:47.020 --> 00:17:49.260\nit's not even been initiated.\n\n361\n00:17:49.260 --> 00:17:52.380\nSo it can be very,\nvery hard to tell that it's there.\n\n362\n00:17:54.190 --> 00:17:57.630\nLet's see, what are some of\nthe things that they can do?\n\n363\n00:17:57.630 --> 00:18:01.080\nHow about monitoring or\nrecording your audio and video, right?\n\n364\n00:18:01.080 --> 00:18:03.660\nDoing things like\ncapturing your screenshots,\n\n365\n00:18:03.660 --> 00:18:05.330\nsending them back to a third party.\n\n366\n00:18:05.330 --> 00:18:08.018\n&gt;&gt; Now, some people call that spyware.\n\n367\n00:18:08.018 --> 00:18:11.960\n&gt;&gt; Yes, and in the context of spyware,\nI could see that.\n\n368\n00:18:11.960 --> 00:18:15.740\nBut spyware doesn't have to sit down on a\nloaded self prior to the operating system.\n\n369\n00:18:15.740 --> 00:18:18.185\nSo still spy that is different semantics.\n\n370\n00:18:18.185 --> 00:18:19.410\n&gt;&gt; Just different variations of it.\n\n371\n00:18:19.410 --> 00:18:19.950\n&gt;&gt; Exactly.\n\n372\n00:18:19.950 --> 00:18:23.230\n&gt;&gt; It's kind of strange, Wes, when we\ntalk about these different categories.\n\n373\n00:18:23.230 --> 00:18:27.150\nAnd something I want you guys to remember\nis just keep an open mind about this.\n\n374\n00:18:27.150 --> 00:18:32.380\nBecause an attacker can code something\nto work any way it wants to.\n\n375\n00:18:32.380 --> 00:18:36.128\nSo there might even be attacks that\nwe're not aware of at this moment in\n\n376\n00:18:36.128 --> 00:18:39.442\ntime because they just haven't\nreally been discovered yet.\n\n377\n00:18:39.442 --> 00:18:42.330\n&gt;&gt; Right, and that's things like for\ninstance, your zero-day viruses.\n\n378\n00:18:42.330 --> 00:18:43.536\n&gt;&gt; Sure.\n&gt;&gt; When we talk about zero-day,\n\n379\n00:18:43.536 --> 00:18:45.431\nwhich we'll have that coming\nup in another episode.\n\n380\n00:18:45.431 --> 00:18:48.770\nBut we might as well mention here, right?\n\n381\n00:18:48.770 --> 00:18:52.070\nCuz you have zero-day exploits, it could\nbe a virus, it could be a rootkit.\n\n382\n00:18:52.070 --> 00:18:56.820\nIt could be a Trojan or a worm, right,\nthat's all in and zero-day just means that\n\n383\n00:18:56.820 --> 00:19:01.670\nit's basically started to exploit systems,\nbut they don't know what it is,\n\n384\n00:19:01.670 --> 00:19:04.440\nthey can't figure out what it is,\nit's day one, right?\n\n385\n00:19:04.440 --> 00:19:06.367\n&gt;&gt; There have been zero\ndays of a solution, right?\n\n386\n00:19:06.367 --> 00:19:11.394\n&gt;&gt; That's right, it's when your system\nis at its lowest security standpoint,\n\n387\n00:19:11.394 --> 00:19:15.214\nsecurity posture because we\ndon't know what to do with it.\n\n388\n00:19:15.214 --> 00:19:17.185\nWe're just seeing it now.\n\n389\n00:19:17.185 --> 00:19:18.535\nSo we definitely have to worry about that.\n\n390\n00:19:18.535 --> 00:19:19.247\nWhat else can it do?\n\n391\n00:19:19.247 --> 00:19:22.944\nI kinda mentioned that it can\ncapture keyboard activity.\n\n392\n00:19:22.944 --> 00:19:25.545\nCapture things like your\nnetwork activity as well.\n\n393\n00:19:25.545 --> 00:19:29.183\nHere's another one too,\nhow about a firmware rootkit?\n\n394\n00:19:29.183 --> 00:19:33.726\nNow, firmware rootkit is one that's very,\nvery tricky because when your operating\n\n395\n00:19:33.726 --> 00:19:38.270\nsystem, right, loads up, right, BIOS goes\nto a set of instructions that basically\n\n396\n00:19:38.270 --> 00:19:41.200\nkick off the hardware and\ntell the hardware what to do.\n\n397\n00:19:41.200 --> 00:19:44.020\nAnd then, it hands over control\nof the operating system.\n\n398\n00:19:44.020 --> 00:19:47.180\nImagine handing over the control of\nthe rootkit before the operating system\n\n399\n00:19:47.180 --> 00:19:51.050\neven loads, again,\nwhen you talk about your firmware,\n\n400\n00:19:51.050 --> 00:19:52.810\nyour firmware's in non-volatile memory.\n\n401\n00:19:52.810 --> 00:19:55.070\nWhich means when I reboot the computer,\nguess what?\n\n402\n00:19:55.070 --> 00:19:57.650\nThe code's that in it, is still there, so\n\n403\n00:19:57.650 --> 00:20:00.190\nthese can also be kind\nof difficult as well.\n\n404\n00:20:00.190 --> 00:20:03.650\nWhat are some of the other symptoms that\nyou can see when it comes to rootkits?\n\n405\n00:20:03.650 --> 00:20:06.440\nThings like blue screens,\nkeyboard lock-ups.\n\n406\n00:20:06.440 --> 00:20:08.100\nPermission changes, that's a big one.\n\n407\n00:20:08.100 --> 00:20:10.355\nIf you've got certain files that\nall of a sudden you're like,\n\n408\n00:20:10.355 --> 00:20:12.235\nI didn't set those permissions.\n\n409\n00:20:12.235 --> 00:20:15.613\nYou do a little security auditing and you\nrealize that there might be something on\n\n410\n00:20:15.613 --> 00:20:17.513\nyour system that's changing permissions.\n\n411\n00:20:17.513 --> 00:20:20.335\nThat could be a telltale sign\nthat you have a rootkit.\n\n412\n00:20:20.335 --> 00:20:23.827\nNetwork communication error,\nor issues, right?\n\n413\n00:20:23.827 --> 00:20:26.047\nCommunication problems\nwhere they're intermittent,\n\n414\n00:20:26.047 --> 00:20:31.167\nor it seems all of your network resources\nhave been completely utilized, yet\n\n415\n00:20:31.167 --> 00:20:32.457\nyou don't have your web browser open?\n\n416\n00:20:32.457 --> 00:20:36.472\nIt might be a sign too, so\na heavy workload as well.\n\n417\n00:20:36.472 --> 00:20:41.139\nI'll tell you what, let's go ahead And\none of the things that I wanna do,\n\n418\n00:20:41.139 --> 00:20:45.807\nis I wanna kinda of show you guys a\ncentrally what you could see when it comes\n\n419\n00:20:45.807 --> 00:20:50.970\nto some of these different pieces of\ncodes, different pieces of malware.\n\n420\n00:20:50.970 --> 00:20:54.255\nBecause one of the big things\nthat you're wanna know is that\n\n421\n00:20:54.255 --> 00:20:56.763\nI mentioned things like\nthe heavy work load.\n\n422\n00:20:56.763 --> 00:21:02.905\nIf you notice that you have a system that\nyou're not really running a lot of things,\n\n423\n00:21:02.905 --> 00:21:07.643\nmaybe you don't have a single thing\nopen at all on your system and\n\n424\n00:21:07.643 --> 00:21:13.030\nall of a sudden it just starts\nperforming absolutely horrible, right?\n\n425\n00:21:13.030 --> 00:21:17.270\nWell one of the things that you can\ndo to kind of see this in action\n\n426\n00:21:17.270 --> 00:21:21.170\nis you can open things like your\ntask manager, your resource monitor.\n\n427\n00:21:21.170 --> 00:21:25.260\nIn fact let's go ahead and do that here\nto this Windows machine that I have open.\n\n428\n00:21:25.260 --> 00:21:29.719\nI'll go ahead and I'll launch our task\nmanager, and one of the things that we're\n\n429\n00:21:29.719 --> 00:21:33.483\ngonna see is that, you see how it's\nkind of sluggish to open that up?\n\n430\n00:21:33.483 --> 00:21:38.865\nAnd one of the things I notice is that\nI have almost a 99% utilization there.\n\n431\n00:21:38.865 --> 00:21:39.865\n&gt;&gt; What you got going on Wes?\n\n432\n00:21:39.865 --> 00:21:41.530\n&gt;&gt; We've got a lot of\nstuff going on apparently.\n\n433\n00:21:41.530 --> 00:21:43.455\n&gt;&gt; [LAUGH]\n&gt;&gt; These are some of the telltale signs,\n\n434\n00:21:43.455 --> 00:21:45.950\nnow you can see that, according to me,\n\n435\n00:21:45.950 --> 00:21:48.720\nI don't have anything else\nopen on this machine.\n\n436\n00:21:48.720 --> 00:21:52.290\nHowever, I've got a 97% CPU utilization,\n\n437\n00:21:52.290 --> 00:21:55.520\nmy memory is almost pegged,\nit's not quite there.\n\n438\n00:21:55.520 --> 00:21:58.250\nAnd I also have a lot of Disk IO going on.\n\n439\n00:21:58.250 --> 00:22:02.280\nThese are some of the signs that can tell\nyou, not only that you have a root kit,\n\n440\n00:22:02.280 --> 00:22:05.950\nthat you might have a virus in play and\nit could be causing problems.\n\n441\n00:22:05.950 --> 00:22:08.850\nSo at this point,\nwhat you would wanna do is you would wanna\n\n442\n00:22:08.850 --> 00:22:11.290\nfind out what is the process\nthat's causing the problem?\n\n443\n00:22:11.290 --> 00:22:14.912\nNow remember I told you I was kinda\nsimulating this I got a Burning Test here\n\n444\n00:22:14.912 --> 00:22:16.736\nthat's running in the background.\n\n445\n00:22:16.736 --> 00:22:20.490\nIt is essentially simulating the same\nthing that you would see if you ended up\n\n446\n00:22:20.490 --> 00:22:24.361\nhaving something like a worm, something\nlike antivirus, or not antivirus,\n\n447\n00:22:24.361 --> 00:22:26.550\nbut the virus that's replicating itself.\n\n448\n00:22:26.550 --> 00:22:30.150\nYou would see things like your\ndisk activity being crazy.\n\n449\n00:22:30.150 --> 00:22:33.618\nIf it happens to be sending\nout network communications and\n\n450\n00:22:33.618 --> 00:22:35.966\nif you're not connected to anything.\n\n451\n00:22:35.966 --> 00:22:38.430\nChances are, well a couple of\nthings could be happening right?\n\n452\n00:22:38.430 --> 00:22:41.670\nI could be doing a windows update and\nthat could be happening in the background.\n\n453\n00:22:41.670 --> 00:22:44.620\nSo you wanna investigate\na little bit farther.\n\n454\n00:22:44.620 --> 00:22:46.934\n&gt;&gt; Now Wes, this is a free\nutility that's built right in\n\n455\n00:22:46.934 --> 00:22:48.435\nto the Windows Operating System.\n\n456\n00:22:48.435 --> 00:22:51.464\nSo for home or\nend user this would be a perfect solution,\n\n457\n00:22:51.464 --> 00:22:53.230\ndoes it cost you anything?\n\n458\n00:22:53.230 --> 00:22:57.500\nAs a matter of fact, Microsoft even\nalso has additional tools such as\n\n459\n00:22:57.500 --> 00:23:01.380\nthe Sysinternals that Mark Russinovich and\nhis team created.\n\n460\n00:23:01.380 --> 00:23:05.803\nAnd then, from an enterprise environment,\nyou might even be using a larger Solution,\n\n461\n00:23:05.803 --> 00:23:07.371\nmaybe a third party solution?\n\n462\n00:23:07.371 --> 00:23:10.419\n&gt;&gt; Most definitely, and I would\nalways start with what's free first.\n\n463\n00:23:10.419 --> 00:23:11.300\n&gt;&gt; [LAUGH] Right?\n\n464\n00:23:11.300 --> 00:23:13.910\n&gt;&gt; The only reason I say that is\nbecause when you're doing multiple\n\n465\n00:23:13.910 --> 00:23:15.460\nsystems they can get very expensive.\n\n466\n00:23:15.460 --> 00:23:18.810\nAnd that's one of the great things to have\nsomething like that's built in that we\n\n467\n00:23:18.810 --> 00:23:21.720\nsee, like Cherokee mentions,\nthat I don't have to pay for.\n\n468\n00:23:21.720 --> 00:23:25.350\nOrsis Internals, they've got a whole\nentire line of products that are amazing,\n\n469\n00:23:25.350 --> 00:23:26.730\nand you don't have to pay for it, right?\n\n470\n00:23:26.730 --> 00:23:28.330\nAnd it's vendor support.\n\n471\n00:23:28.330 --> 00:23:29.530\nSo if you have vendor support.\n\n472\n00:23:29.530 --> 00:23:33.524\nYou have something that they're offering\nyou that doesn't cost a lot of money.\n\n473\n00:23:33.524 --> 00:23:36.290\nIt might be in your budget that\nyou have to pay for it anyway.\n\n474\n00:23:36.290 --> 00:23:39.450\nSo just pay attention to what solution\nit is because they can get very,\n\n475\n00:23:39.450 --> 00:23:43.110\nvery expensive very quick.\n\n476\n00:23:43.110 --> 00:23:46.282\nI wanna give you kinda some examples\ntoo of some rootkits that we've seen\n\n477\n00:23:46.282 --> 00:23:48.261\nin the past or\nwe've heard about in the past.\n\n478\n00:23:48.261 --> 00:23:51.067\nZeus 2007 was one of them.\n\n479\n00:23:51.067 --> 00:23:53.370\nYou kinda mentioned this in\nthe first part of the episode.\n\n480\n00:23:53.370 --> 00:23:56.309\nYou talked about your\nindustrial control systems.\n\n481\n00:23:56.309 --> 00:23:59.503\nWe wouldn't be doing you guys any justice\nif we didn't talk about Stuxnet, right.\n\n482\n00:23:59.503 --> 00:24:00.674\n&gt;&gt; Sure.\n&gt;&gt; Stuxnet was a big one.\n\n483\n00:24:00.674 --> 00:24:03.582\n&gt;&gt; That was a pivotal particular attack,\n\n484\n00:24:03.582 --> 00:24:09.410\nbecause it really opened my eyes at least\nto the way that war is happening here.\n\n485\n00:24:09.410 --> 00:24:13.225\n&gt;&gt; Definitely, because if you think about\nit a lot of times, at least here in\n\n486\n00:24:13.225 --> 00:24:17.729\nthe United States, and you guys, I know we\nbroadcast to a lot of different countries.\n\n487\n00:24:17.729 --> 00:24:21.336\nBut, for instance, in the States one\nof the things that we were thinking\n\n488\n00:24:21.336 --> 00:24:24.670\nabout was, could terrorists\nactually bring down large systems?\n\n489\n00:24:24.670 --> 00:24:28.580\nWell, Stuxnet was one of\nthose rootkits that was\n\n490\n00:24:28.580 --> 00:24:31.190\nlooking to infect those type of systems.\n\n491\n00:24:31.190 --> 00:24:34.398\nThe industrial control systems,\nthe scada systems, right?\n\n492\n00:24:34.398 --> 00:24:38.588\nLarge systems that are used for\nautomating factory plants,\n\n493\n00:24:38.588 --> 00:24:42.540\nwater plants, if you will,\nnuclear facilities.\n\n494\n00:24:42.540 --> 00:24:45.620\nSo, when you have something like that, a\nrootkit, that can get into these systems,\n\n495\n00:24:45.620 --> 00:24:47.950\nit becomes very, very dangerous.\n\n496\n00:24:47.950 --> 00:24:51.490\nFlame was the other one that I wanted\nto mention as well just to kinda give\n\n497\n00:24:51.490 --> 00:24:53.500\nyou guys some examples.\n\n498\n00:24:54.580 --> 00:24:57.460\nAll right, so\na couple more that we need to talk about.\n\n499\n00:24:57.460 --> 00:24:59.378\nOne that we need to talk about, and\n\n500\n00:24:59.378 --> 00:25:02.302\nI know that you had mentioned\nthis as well is adware.\n\n501\n00:25:02.302 --> 00:25:06.352\nNow, they don't really mention spyware,\nso I'm gonna treat spyware and adware,\n\n502\n00:25:06.352 --> 00:25:07.503\nthey're not the same.\n\n503\n00:25:07.503 --> 00:25:10.291\nBut I'm gonna kind of talk about\nthem both, even though that spyware,\n\n504\n00:25:10.291 --> 00:25:12.293\naccording to our objectives,\nisn't on the list.\n\n505\n00:25:12.293 --> 00:25:15.578\nI'm sure it's gonna be on\nour [LAUGH] list eventually.\n\n506\n00:25:15.578 --> 00:25:17.390\nSo what is spyware?\n\n507\n00:25:17.390 --> 00:25:18.870\nAnything that's tracking your information.\n\n508\n00:25:20.010 --> 00:25:22.190\nBoils down to, that's exactly what it is.\n\n509\n00:25:22.190 --> 00:25:26.482\nYou could have unmalicious spyware built\nright into your web browser, right?\n\n510\n00:25:26.482 --> 00:25:30.055\nYour major companies\nare gathering your information.\n\n511\n00:25:30.055 --> 00:25:35.027\nThey wanna send you advertisements\njust strategically to people like\n\n512\n00:25:35.027 --> 00:25:37.899\nWes who like knives, and other things.\n\n513\n00:25:37.899 --> 00:25:39.822\nSo what happens?\n\n514\n00:25:39.822 --> 00:25:40.959\nI end up-\n&gt;&gt; Targeted marketing.\n\n515\n00:25:40.959 --> 00:25:42.611\n&gt;&gt; Targeted marketing, that's right.\n\n516\n00:25:42.611 --> 00:25:45.795\nSo I end up doing something like opening a\nweb browser and all of a sudden I've got,\n\n517\n00:25:45.795 --> 00:25:48.612\nwell hey, look at this knife sharpener,\nlook at this knife sharpener,\n\n518\n00:25:48.612 --> 00:25:49.417\nwhatever, right?\n\n519\n00:25:49.417 --> 00:25:51.304\n&gt;&gt; [LAUGH]\n&gt;&gt; Look at this computer component that\n\n520\n00:25:51.304 --> 00:25:53.166\nyou need to buy and have to have, right?\n\n521\n00:25:53.166 --> 00:25:55.050\nSome kinda new tablet.\n\n522\n00:25:55.050 --> 00:25:58.270\nBut yet, I'm not on those type\nof websites, what's happening?\n\n523\n00:25:58.270 --> 00:26:00.830\nWell, that's usually adware, right?\n\n524\n00:26:00.830 --> 00:26:03.910\nAnd I know some people say,\nwell, adware isn't spyware.\n\n525\n00:26:03.910 --> 00:26:07.890\nThat's right, I just assume that if\nit's spying on you, it's spyware.\n\n526\n00:26:07.890 --> 00:26:11.460\nSpyware, though, has a specific purpose,\nto do exactly that.\n\n527\n00:26:11.460 --> 00:26:14.820\nTo monitor and track your activities,\nto report that activity.\n\n528\n00:26:14.820 --> 00:26:19.465\nIt's basically like you going through an\nactivity audit anytime this piece of code\n\n529\n00:26:19.465 --> 00:26:20.605\nis on your machine.\n\n530\n00:26:20.605 --> 00:26:23.807\nAdware, on the other hand,\nit is strategically targeted to place\n\n531\n00:26:23.807 --> 00:26:25.866\nthings like ads along\nyour browsing path so\n\n532\n00:26:25.866 --> 00:26:29.204\nthat they can say, you sure you\ndidn't wanna come back and buy this?\n\n533\n00:26:29.204 --> 00:26:31.549\nHey, you're gonna wanna buy this.\n\n534\n00:26:31.549 --> 00:26:35.880\nSo again, as you browse you might see\nthings like your popups that happen,\n\n535\n00:26:35.880 --> 00:26:38.790\neven though we have popup protectors and\nstuff.\n\n536\n00:26:38.790 --> 00:26:42.670\nAdware usually places those\nadvertisements along that browsing path.\n\n537\n00:26:42.670 --> 00:26:45.800\n&gt;&gt; I usually hear that adware\nis a form of benign, and\n\n538\n00:26:45.800 --> 00:26:49.120\nlike Wes was explaining,\nspyware would not be benign.\n\n539\n00:26:49.120 --> 00:26:52.340\nIt might even be you see advertisements,\n\n540\n00:26:52.340 --> 00:26:55.050\ndisgruntled cheating spouses and\nthings like that.\n\n541\n00:26:55.050 --> 00:26:59.950\nPieces of software that you can even\npurchase to have screenshot captures sent\n\n542\n00:26:59.950 --> 00:27:05.310\nback to someone via email at\na particular interval, things like that.\n\n543\n00:27:05.310 --> 00:27:07.593\nSo adware, like he was saying,\nin my opinion,\n\n544\n00:27:07.593 --> 00:27:09.374\nI don't find it completely benign.\n\n545\n00:27:09.374 --> 00:27:13.840\nBecause I do think they are taking some of\nyour intellectual habits away from you.\n\n546\n00:27:13.840 --> 00:27:16.300\nBut that's just my opinion.\n\n547\n00:27:16.300 --> 00:27:18.300\n&gt;&gt; Yeah, I definitely agree.\n\n548\n00:27:18.300 --> 00:27:22.600\nIf you're watching and\ntracking activities, if you're looking,\n\n549\n00:27:22.600 --> 00:27:25.860\nyou're spying on me, if you're\npaying attention to what I'm doing.\n\n550\n00:27:25.860 --> 00:27:27.440\nI'm with you on that one.\n\n551\n00:27:27.440 --> 00:27:30.296\nNow the other one that they call out to,\nand probably the final one.\n\n552\n00:27:30.296 --> 00:27:33.058\nI know that while we're getting close\nto the end of the time on this one.\n\n553\n00:27:33.058 --> 00:27:36.254\nBut I do want to mention that's\nsomething that's known as the keylogger.\n\n554\n00:27:36.254 --> 00:27:39.420\nAnd I kinda mentioned it here,\nbut I moved past it.\n\n555\n00:27:39.420 --> 00:27:41.095\nLet's go ahead and\nlet's go back to the keylogger.\n\n556\n00:27:42.430 --> 00:27:44.130\nYou have two different\ntypes of keyloggers.\n\n557\n00:27:44.130 --> 00:27:49.600\nYou have software-based keyloggers, which\nis the context of these objectives here.\n\n558\n00:27:49.600 --> 00:27:54.088\nAnd then you also have the context\nof a hardware-based keylogger.\n\n559\n00:27:54.088 --> 00:27:57.302\nAnd a hardware-based keylogger's one\nthat you actually plug into a port.\n\n560\n00:27:57.302 --> 00:28:01.459\nAnd then somebody plugs like a USB device\ninto it, or they could just be standalone.\n\n561\n00:28:01.459 --> 00:28:03.864\nBut they plug into a USB\nport on the machine and\n\n562\n00:28:03.864 --> 00:28:07.020\nthey start capturing all\nkinds of information.\n\n563\n00:28:07.020 --> 00:28:11.406\nThe ones that we are talking about though\nhere, in this context is the software,\n\n564\n00:28:11.406 --> 00:28:13.029\nthe malicious ones, right?\n\n565\n00:28:13.029 --> 00:28:17.752\nAnd sometimes they're very hard to tell\nthat they're even there once they get into\n\n566\n00:28:17.752 --> 00:28:18.632\nyour systems.\n\n567\n00:28:18.632 --> 00:28:21.480\nIn fact, let's go ahead and\nkinda show you what they can do here.\n\n568\n00:28:21.480 --> 00:28:24.470\nSo I've got the Edge browser open here and\nI'm gonna go ahead and\n\n569\n00:28:24.470 --> 00:28:29.240\ngo to IT, if I can type, ITPro.TV.\n\n570\n00:28:29.240 --> 00:28:33.230\nI'll go up to our website here and\nyou'll see that we'll go ahead and\n\n571\n00:28:33.230 --> 00:28:34.639\nwe will get logged in.\n\n572\n00:28:36.010 --> 00:28:40.316\nAll right, and let me go ahead and\nlog into our website.\n\n573\n00:28:40.316 --> 00:28:43.620\nI'm gonna fake a login here and\nyou'll see why here.\n\n574\n00:28:43.620 --> 00:28:51.560\nBut I'll type Wes@itpro.tv and I'll\ntype my super secret password of 123456.\n\n575\n00:28:51.560 --> 00:28:54.038\nAnd of course,\nit's not gonna authenticate me, all right?\n\n576\n00:28:54.038 --> 00:28:54.791\nThat's what I want.\n\n577\n00:28:54.791 --> 00:28:56.324\nYou guys don't get to\nsee my real password.\n\n578\n00:28:56.324 --> 00:28:57.900\n&gt;&gt; [LAUGH]\n&gt;&gt; That wouldn't be any fun.\n\n579\n00:28:57.900 --> 00:29:00.740\nSo, what happens when\na keylogger's on your system?\n\n580\n00:29:00.740 --> 00:29:03.560\nWell, this one is actually\nrunning in the background and\n\n581\n00:29:03.560 --> 00:29:05.930\nwe don't even know it's here.\n\n582\n00:29:05.930 --> 00:29:08.530\nI've actually got it in a hidden mode,\nright?\n\n583\n00:29:08.530 --> 00:29:12.450\nAnd you can see there is a keylogger\npresent now on this machine.\n\n584\n00:29:12.450 --> 00:29:13.585\n&gt;&gt; I'm assuming that was free?\n\n585\n00:29:13.585 --> 00:29:15.056\n&gt;&gt; Yes.\n[LAUGH]\n\n586\n00:29:15.056 --> 00:29:15.715\n&gt;&gt; I don't know what gave it away but\n\n587\n00:29:15.715 --> 00:29:17.055\nthat's right.\n&gt;&gt; I don't know.\n\n588\n00:29:17.055 --> 00:29:18.515\n[LAUGH]\n&gt;&gt; They would love to give you\n\n589\n00:29:18.515 --> 00:29:21.080\nkeyloggers free and\nyou don't have to pay for them.\n\n590\n00:29:21.080 --> 00:29:22.850\nIt's what they take from you in the end.\n\n591\n00:29:22.850 --> 00:29:23.935\nThey'll get their money.\n\n592\n00:29:23.935 --> 00:29:26.870\n&gt;&gt; [LAUGH]\n&gt;&gt; So you can see that it has things like,\n\n593\n00:29:28.120 --> 00:29:32.070\napparently, I don't have a hidden\nkey mode here, let's try that again.\n\n594\n00:29:33.350 --> 00:29:34.130\nThere we go.\n\n595\n00:29:34.130 --> 00:29:36.580\nBut what is this thing doing here, right?\n\n596\n00:29:36.580 --> 00:29:37.280\nWhat is it doing?\n\n597\n00:29:37.280 --> 00:29:41.910\nWell, you could see that it is doing\nthings like reporting picked data.\n\n598\n00:29:41.910 --> 00:29:46.500\nThings like keystrokes and the clipboard,\napplications, websites that are visited.\n\n599\n00:29:46.500 --> 00:29:49.734\nIn fact, let's kinda see this\ninformation here, right?\n\n600\n00:29:49.734 --> 00:29:54.641\nNotice that we had some\ninformation that was typed.\n\n601\n00:29:54.641 --> 00:29:56.661\nRight here, you could see Chrome is open.\n\n602\n00:29:56.661 --> 00:30:00.441\nLook at it here,\nmy bank account information, right?\n\n603\n00:30:00.441 --> 00:30:03.689\nMy secret document that I have,\nthat I've opened.\n\n604\n00:30:03.689 --> 00:30:08.557\nLet's see, what applications, wow,\nit really tracks what is going on here,\n\n605\n00:30:08.557 --> 00:30:09.595\nright?\n\n606\n00:30:09.595 --> 00:30:13.305\nYou can see that I've used the Edge\nbrowser, the Google installer.\n\n607\n00:30:13.305 --> 00:30:15.117\nAll kinds of information, right?\n\n608\n00:30:16.117 --> 00:30:17.197\nWindows Explorer,\n\n609\n00:30:17.197 --> 00:30:20.067\nit's never been renamed even though\nwe call it File Explorer today.\n\n610\n00:30:20.067 --> 00:30:24.227\nIt's still in the background\ncalled Windows Explorer.\n\n611\n00:30:24.227 --> 00:30:25.347\nWhat else do we have here?\n\n612\n00:30:25.347 --> 00:30:27.733\nWebsites visited, all right?\n\n613\n00:30:27.733 --> 00:30:29.150\nNotice that, well,\n\n614\n00:30:29.150 --> 00:30:34.048\nwe've got a few different websites\nthat it sees that I've visited here.\n\n615\n00:30:34.048 --> 00:30:36.063\n&gt;&gt; Including your ITPro.TV logon.\n\n616\n00:30:36.063 --> 00:30:41.411\n&gt;&gt; Exactly, so that's the problem with\nall of these keyloggers is the fact\n\n617\n00:30:41.411 --> 00:30:46.944\nthat when they get on your systems,\nthey can start tracking information.\n\n618\n00:30:46.944 --> 00:30:50.620\nAnd I want you to notice this\nspot right here, email delivery.\n\n619\n00:30:51.810 --> 00:30:52.940\nSend the daily report.\n\n620\n00:30:52.940 --> 00:30:56.210\nNow this isn't part of\nthe free version here, and\n\n621\n00:30:56.210 --> 00:30:58.080\nit's gonna try to take me out to buy it.\n\n622\n00:30:58.080 --> 00:30:58.930\nLet's close that down.\n\n623\n00:31:00.170 --> 00:31:03.080\nBut I can have all this information\nsent out to me via email.\n\n624\n00:31:03.080 --> 00:31:06.960\nNow I have to tell you, I had to do\na lot of work to get this thing on here,\n\n625\n00:31:06.960 --> 00:31:12.140\nbecause keyloggers, even if they're free,\nthey're still seen as malicious software.\n\n626\n00:31:12.140 --> 00:31:14.970\nIn fact, I'll tell you what,\nCherokee, let's go ahead and\n\n627\n00:31:14.970 --> 00:31:17.580\nlet's try to install this one.\n\n628\n00:31:17.580 --> 00:31:18.868\nI had to break Windows.\n\n629\n00:31:18.868 --> 00:31:21.583\nI had to turn off the [LAUGH] The Windows\nDefender service to even get that\n\n630\n00:31:21.583 --> 00:31:22.420\nkeylogger on there.\n\n631\n00:31:22.420 --> 00:31:24.136\nLet me show you why.\n\n632\n00:31:24.136 --> 00:31:28.066\nThis is a password\nprotected extractor here.\n\n633\n00:31:28.066 --> 00:31:29.888\nLet me go ahead and do this.\n\n634\n00:31:29.888 --> 00:31:32.098\nHopefully, it'll allow it to run.\n\n635\n00:31:32.098 --> 00:31:35.480\nWe'll let it run it's file extraction, and\n\n636\n00:31:35.480 --> 00:31:40.469\nlet's see if we can go ahead and\ndo the password setup, all right?\n\n637\n00:31:41.550 --> 00:31:44.092\nYeah, sure,\nI've turned off my antivirus software.\n\n638\n00:31:44.092 --> 00:31:46.270\n&gt;&gt; Danger, Will Robinson.\n\n639\n00:31:46.270 --> 00:31:47.270\n&gt;&gt; And let's see what happens.\n\n640\n00:31:47.270 --> 00:31:49.913\nAnd notice right away,\nthis is your UAC saying, hey,\n\n641\n00:31:49.913 --> 00:31:52.159\nI have no clue who\nthe publisher is on this one.\n\n642\n00:31:52.159 --> 00:31:54.240\nAre you sure you wanna do this?\n\n643\n00:31:54.240 --> 00:31:56.614\nAnd I'm gonna say just for\nyour guys benefit.\n\n644\n00:31:56.614 --> 00:31:57.624\nYeah why not?\n\n645\n00:31:57.624 --> 00:31:59.295\nI don't care about this computer or\nsecurity,\n\n646\n00:31:59.295 --> 00:32:01.540\nor anything we've been teaching here.\n\n647\n00:32:01.540 --> 00:32:03.690\nAll right,\nnow my head's kinda covering it up but\n\n648\n00:32:03.690 --> 00:32:05.220\nwe can take a look at that right there.\n\n649\n00:32:05.220 --> 00:32:06.460\nNotice what it said.\n\n650\n00:32:06.460 --> 00:32:08.670\nPotentially harmful software is detected.\n\n651\n00:32:08.670 --> 00:32:10.720\nThis was on the installation, right?\n\n652\n00:32:11.980 --> 00:32:14.630\nWe will go ahead and we'll click that and\nwe'll see what Windows defender,\n\n653\n00:32:14.630 --> 00:32:16.580\nwe will see if Windows\ndefender is even going to let,\n\n654\n00:32:16.580 --> 00:32:19.170\nI doubt it is even going\nto let me install this.\n\n655\n00:32:19.170 --> 00:32:25.290\nIt might but it's still, like I said I\nknow my head is kinda covering it up but\n\n656\n00:32:25.290 --> 00:32:29.620\nif you can see notice it is just\ncompletely not liking this.\n\n657\n00:32:29.620 --> 00:32:32.420\nAnd it is letting us know,\nthere is problems right.\n\n658\n00:32:32.420 --> 00:32:37.720\nFails to do what it needed to do, we just\nsay ignore, and it looks like it runs.\n\n659\n00:32:37.720 --> 00:32:39.220\n&gt;&gt; Hey, I am trying to warn you here.\n\n660\n00:32:39.220 --> 00:32:39.720\n&gt;&gt; That's right\n&gt;&gt; [LAUGH]\n\n661\n00:32:39.720 --> 00:32:42.078\n&gt;&gt; Notice how it says it fails to execute.\n\n662\n00:32:42.078 --> 00:32:42.881\nI really,\n\n663\n00:32:42.881 --> 00:32:48.840\nreally had to break that Windows\nmachine to get this keylogger on here.\n\n664\n00:32:48.840 --> 00:32:50.810\nHowever be careful.\n\n665\n00:32:50.810 --> 00:32:55.020\nIf it's something life a trojan, if it's\nsomething that's built into a root kit,\n\n666\n00:32:55.020 --> 00:33:00.920\nyour antivirus software might not do\nwhat Windows Defender here is doing for\n\n667\n00:33:00.920 --> 00:33:06.400\nme which is doing it's job, telling me\nI've got some kind of issue going on here.\n\n668\n00:33:06.400 --> 00:33:09.990\nYou need to get this off your machine and\nyou need to get it off your machine quick.\n\n669\n00:33:09.990 --> 00:33:14.370\nSo for instance, if I go into\nthe history here and I view the details,\n\n670\n00:33:14.370 --> 00:33:17.400\nlooks like it's not even quarantining,\nit's applying a default action.\n\n671\n00:33:17.400 --> 00:33:22.300\nBut if I go to all detected Items,\nnotice here what we have.\n\n672\n00:33:22.300 --> 00:33:24.540\nWe've got a monitoring tool, right?\n\n673\n00:33:24.540 --> 00:33:26.370\nAnd it says that it's severe and\n\n674\n00:33:26.370 --> 00:33:29.170\nit's letting me know that\nit's quarantined, okay?\n\n675\n00:33:29.170 --> 00:33:33.770\nSo, the good thing about this one,\nas we bring this one to an end,\n\n676\n00:33:33.770 --> 00:33:36.010\nCherokee's letting me know it's\nabout time to end this one.\n\n677\n00:33:36.010 --> 00:33:38.290\nSo let me go ahead and\nwrap this one up by saying,\n\n678\n00:33:40.020 --> 00:33:43.440\nthank goodness we have some kind of\nsoftware on here that lets us know,\n\n679\n00:33:43.440 --> 00:33:47.700\nhey something's about to install itself\nwhere it can monitor you, right?\n\n680\n00:33:47.700 --> 00:33:51.380\nIf you're not running anti--virus,\nif you're doing like I did on the first\n\n681\n00:33:51.380 --> 00:33:54.770\nWindows machine and you're completely\nturning if off, which people do, right?\n\n682\n00:33:54.770 --> 00:33:57.080\nLet me give you an example\nwhere people usually do that.\n\n683\n00:33:57.080 --> 00:33:59.560\nWe're testing out an application,\nthe application's not working.\n\n684\n00:33:59.560 --> 00:34:02.740\nSo turn off the firewall and\nturn off the antivirus service.\n\n685\n00:34:02.740 --> 00:34:05.130\nNow, as a temporary fix, literally,\n\n686\n00:34:05.130 --> 00:34:09.310\nnot even a fix, a test that lasts no mare\nthan maybe five minutes, that's fine.\n\n687\n00:34:09.310 --> 00:34:11.520\nBut what happens when people keep it off?\n\n688\n00:34:12.700 --> 00:34:14.315\nYou never get these warnings, right?\n\n689\n00:34:14.315 --> 00:34:16.320\nKeylogger installs, now what is it doing?\n\n690\n00:34:17.990 --> 00:34:22.710\nIt's surveillance software\nis what it boils down to.\n\n691\n00:34:22.710 --> 00:34:26.068\nCausing you a drain of a bank account.\n\n692\n00:34:26.068 --> 00:34:31.040\nYou can end up disclosing information\non sensitive patent information.\n\n693\n00:34:32.260 --> 00:34:35.490\nThe websites that you're visiting,\nemails that you're sending.\n\n694\n00:34:35.490 --> 00:34:38.326\nAnd before you know it, you've actually\nsent a lot of information outbound and\n\n695\n00:34:38.326 --> 00:34:39.229\nyou're not aware of it.\n\n696\n00:34:39.229 --> 00:34:42.477\nSo, make sure that you have your\nantivirus software turned on, so\n\n697\n00:34:42.477 --> 00:34:46.189\nyou don't have to worry about things\nlike your key stroke loggers reporting\n\n698\n00:34:46.189 --> 00:34:48.470\nyour information to the bad guys.\n\n699\n00:34:48.470 --> 00:34:49.390\n&gt;&gt; Well thank you Wes for\n\n700\n00:34:49.390 --> 00:34:52.240\ntaking the time to cover those\nmany different forms of malware.\n\n701\n00:34:52.240 --> 00:34:54.520\nAnd thank you ladies and\ngentleman for tuning in.\n\n702\n00:34:54.520 --> 00:34:57.160\nBut we are out of time for\nthis particular episode.\n\n703\n00:34:57.160 --> 00:34:58.310\nSo I'll go ahead and sign out.\n\n704\n00:34:58.310 --> 00:35:00.070\nRemember, I'm your host, Cherokee Boose.\n\n705\n00:35:00.070 --> 00:35:00.860\n&gt;&gt; And I'm Wes Bryan.\n\n706\n00:35:00.860 --> 00:35:03.871\n&gt;&gt; See you next time here at ITProTV.\n\n707\n00:35:03.871 --> 00:35:09.899\n[MUSIC]\n\n708\n00:35:09.899 --> 00:35:12.905\nThank you for watching ITProTV.\n\n",
          "vimeoId": "211740949"
        },
        {
          "description": "In this episode Cherokee and Wes explain numerous types of attacks one should be aware of. Specifically, they begin looking at social engineering. Tune in to learn how phishing, spear phishing, whaling, vishing, tailgating, impersonation, dumpster diving, shoulder surfing, hoaxes, and watering hole attacks are all related.",
          "length": "1481",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-types_of_attacks-040317-PGM.00_24_27_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-types_of_attacks-040317-PGM.00_24_27_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-types_of_attacks-040317-PGM.00_24_27_02.Still001-sm.jpg",
          "title": "Types of Attacks",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:01.286\nWelcome to ITPRO.TV.\n\n2\n00:00:01.286 --> 00:00:06.576\nI'm your host [CROSSTALK]\n\n3\n00:00:06.576 --> 00:00:08.371\n[MUSIC]\n\n4\n00:00:08.371 --> 00:00:11.010\n&gt;&gt; You're watching ITPRO.TV.\n\n5\n00:00:12.220 --> 00:00:14.740\nWelcome to your CompTIA Security+ series.\n\n6\n00:00:14.740 --> 00:00:16.840\nI'm your show host, Cherokee Boose.\n\n7\n00:00:16.840 --> 00:00:20.190\nIn this episode, we'll be looking at\ndifferent types of attacks that may occur.\n\n8\n00:00:20.190 --> 00:00:22.890\nAnd with us today we have Mr.\nWes Bryan in studios.\n\n9\n00:00:22.890 --> 00:00:24.094\nThank you for joining us today, Wes.\n\n10\n00:00:24.094 --> 00:00:25.755\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n11\n00:00:25.755 --> 00:00:26.730\nYeah, great to be here.\n\n12\n00:00:26.730 --> 00:00:27.580\nAnd that's right,\n\n13\n00:00:27.580 --> 00:00:32.770\nwe have a laundry list of different types\nof attacks that we have to be aware of.\n\n14\n00:00:32.770 --> 00:00:37.840\nAnd not only for the exam purposes,\nbut also for real world purposes, too.\n\n15\n00:00:37.840 --> 00:00:41.920\nRemember that in any kind of security\nendeavor it really boils down to\n\n16\n00:00:41.920 --> 00:00:42.730\neducation, right?\n\n17\n00:00:42.730 --> 00:00:48.120\nMaking sure that your end users are aware\nof the type of attacks that could be out\n\n18\n00:00:48.120 --> 00:00:51.100\nthere, as well as making\nyourself aware of them so\n\n19\n00:00:51.100 --> 00:00:53.250\nthat you can pass your\nsecurity course exams.\n\n20\n00:00:53.250 --> 00:00:55.315\nSo that's what we are gonna look at.\n\n21\n00:00:55.315 --> 00:00:58.684\nWe're gonna look at different things like,\nfor instance, social engineering.\n\n22\n00:00:58.684 --> 00:01:01.757\nWe're gonna look at why is\nsocial engineering successful.\n\n23\n00:01:01.757 --> 00:01:04.707\nWe'll talk about things like\nprinciples for effectiveness.\n\n24\n00:01:04.707 --> 00:01:07.427\nAnd then we'll also talk about\nsome additional attacks.\n\n25\n00:01:07.427 --> 00:01:09.417\nThings like application and\nservice attacks.\n\n26\n00:01:09.417 --> 00:01:14.475\nSo, lot of great stuff to go though\nhere in what's probably going to\n\n27\n00:01:14.475 --> 00:01:19.889\namount to quite a few different parts\nin this subject because we do have so\n\n28\n00:01:19.889 --> 00:01:22.850\nmuch great information to talk about.\n\n29\n00:01:22.850 --> 00:01:23.630\nSo let's go ahead.\n\n30\n00:01:23.630 --> 00:01:27.010\nOne of the first things that we're\ngoing to do is we'll dive into\n\n31\n00:01:27.010 --> 00:01:28.180\nsocial engineering, right?\n\n32\n00:01:28.180 --> 00:01:29.560\nThis is a type of attack\n\n33\n00:01:30.570 --> 00:01:34.440\nthat is very prevalent today\nin today's society, all right?\n\n34\n00:01:34.440 --> 00:01:37.840\nWhen we look at things like social\nengineering attacks, let's go ahead and\n\n35\n00:01:37.840 --> 00:01:39.080\nlet's start very basic.\n\n36\n00:01:39.080 --> 00:01:41.110\nWhat is a social engineering attack?\n\n37\n00:01:41.110 --> 00:01:45.590\nWell, social engineering attack is where\nyou're trying to retrieve a certain amount\n\n38\n00:01:45.590 --> 00:01:50.730\nof sensitive information to mount another\nattack against maybe that individual, or\n\n39\n00:01:50.730 --> 00:01:53.480\nmaybe the company that\nthe individual works for, right?\n\n40\n00:01:53.480 --> 00:01:56.216\nIt's all about harvesting\nsome information, right?\n\n41\n00:01:56.216 --> 00:01:57.273\nSensitive information.\n\n42\n00:01:57.273 --> 00:02:01.400\nFor instance, things like your\nusernames and passwords, right?\n\n43\n00:02:01.400 --> 00:02:04.370\nAuthentication information,\nhow you authenticate.\n\n44\n00:02:04.370 --> 00:02:09.250\nAnd really, just trying to glean that\ninformation out of an end-user for\n\n45\n00:02:09.250 --> 00:02:11.300\nthe purposes of mounting an attack.\n\n46\n00:02:12.300 --> 00:02:16.250\nNow, there are many different\nsocial engineering attacks\n\n47\n00:02:16.250 --> 00:02:17.910\nwhen you look at them today.\n\n48\n00:02:17.910 --> 00:02:21.830\nBut we're gonna kinda go through the ones\nthat they call out for your exam.\n\n49\n00:02:22.980 --> 00:02:26.040\n&gt;&gt; Yeah, it's kind of interesting here,\nWes, when we look at our social\n\n50\n00:02:26.040 --> 00:02:29.570\nengineering because like you said we're\nplaying on that human, those emotions.\n\n51\n00:02:29.570 --> 00:02:31.350\nI think you even mentioned\nin a previous episode.\n\n52\n00:02:31.350 --> 00:02:35.150\nAnd it kind of sad because a lot of\ntimes we'll see some of the nicest\n\n53\n00:02:35.150 --> 00:02:37.160\npeople really being\ntaken advantage of here.\n\n54\n00:02:37.160 --> 00:02:42.840\nAnd the attackers are really manipulating\nindividuals to either execute attack or\n\n55\n00:02:42.840 --> 00:02:44.080\neven as a precursor.\n\n56\n00:02:44.080 --> 00:02:46.350\n&gt;&gt; And that's a great word,\nwhen it comes down to it.\n\n57\n00:02:46.350 --> 00:02:49.710\nBut that really can sum up things\nlike social engineering is it's about\n\n58\n00:02:49.710 --> 00:02:50.890\nmanipulation, right?\n\n59\n00:02:50.890 --> 00:02:53.210\nIt's preying on people\nwhen it comes down to it.\n\n60\n00:02:53.210 --> 00:02:57.190\nSo, let's go ahead and let's classify\nsome of the different social engineering\n\n61\n00:02:57.190 --> 00:02:58.370\nattacks and we'll talk about them.\n\n62\n00:02:58.370 --> 00:03:02.100\nI've got a list, and as you can see from\nthe list that I have on my machine here,\n\n63\n00:03:02.100 --> 00:03:03.680\nwe've got quite a few of them, right?\n\n64\n00:03:03.680 --> 00:03:08.180\nQuite a few different types of social\nengineering that we have to be aware of.\n\n65\n00:03:08.180 --> 00:03:11.300\nBut I want you to remember\nthat the goal is to get\n\n66\n00:03:11.300 --> 00:03:16.720\nthat information out of an end user,\nit's just the method of social engineering\n\n67\n00:03:16.720 --> 00:03:19.460\nthat they used to\naccomplish that end goal.\n\n68\n00:03:19.460 --> 00:03:22.800\nAnd we're going to start out with\none of the most common social\n\n69\n00:03:22.800 --> 00:03:27.600\nengineering types today, and that’s\nsomething know as phishing, all right?\n\n70\n00:03:27.600 --> 00:03:32.600\nNow, when we look at a phishing scam,\nthis is a very, very basic type of scam.\n\n71\n00:03:32.600 --> 00:03:35.890\nIt doesn't have a lot\nof complexity into it.\n\n72\n00:03:35.890 --> 00:03:40.790\nAnd it’s really aimed at as many\npeople as they can get to fall for\n\n73\n00:03:40.790 --> 00:03:42.610\nit as possible, right?\n\n74\n00:03:42.610 --> 00:03:48.220\nSo, for instance, it revolves around\nthings like brand trust, right?\n\n75\n00:03:48.220 --> 00:03:50.660\nIf I know that I get an e-mail\nfrom Bank of America,\n\n76\n00:03:50.660 --> 00:03:54.690\nwell, that's who I use for my bank, right?\n\n77\n00:03:54.690 --> 00:03:56.380\nWell, I recognize the brand.\n\n78\n00:03:56.380 --> 00:03:58.170\nI recognize who they are.\n\n79\n00:03:58.170 --> 00:04:02.260\nAnd if I'm not paying close enough\nattention, it might actually be\n\n80\n00:04:02.260 --> 00:04:05.540\ncoming from an unauthorized source\nthat's trying to spoof, right?\n\n81\n00:04:05.540 --> 00:04:08.900\nTrying to make it look like\nit's my bank account or\n\n82\n00:04:08.900 --> 00:04:11.640\nthe web page to get access\nto my bank account.\n\n83\n00:04:11.640 --> 00:04:14.570\nI receive that, for instance,\nin some kind of e-mail.\n\n84\n00:04:14.570 --> 00:04:20.700\nAnd it says, for instance, we've noticed\nsome suspicious activity on your account,\n\n85\n00:04:20.700 --> 00:04:25.210\nplease login and change your password in\norder to keep your account safe, right?\n\n86\n00:04:25.210 --> 00:04:28.988\nAnd I see this in an e-mail,\nagain, brand trust.\n\n87\n00:04:28.988 --> 00:04:32.219\nI think it's Bank of America and\nI enter my username and\n\n88\n00:04:32.219 --> 00:04:34.970\npassword to change my user name and\npassword.\n\n89\n00:04:34.970 --> 00:04:39.220\nWhat I'm not realizing is that\nin entering the username and\n\n90\n00:04:39.220 --> 00:04:43.910\nthe old password, that is actually nothing\nmore than a web application to just scrape\n\n91\n00:04:43.910 --> 00:04:48.650\nthat information and send it to the bad\nguys who can now log into my bank account.\n\n92\n00:04:48.650 --> 00:04:52.960\nCuz I just happily gave them\nthe information with the endeavor being to\n\n93\n00:04:52.960 --> 00:04:54.670\nkeep my account secure.\n\n94\n00:04:54.670 --> 00:04:57.950\nAnd I gave them all they needed to\ngo ahead and get into the account.\n\n95\n00:04:57.950 --> 00:05:03.410\nThings like for instance, you get\ne-mails from Walmart, Google, PayPal.\n\n96\n00:05:03.410 --> 00:05:08.921\nAnd like I said,\nit exploits that brand trust that we have.\n\n97\n00:05:08.921 --> 00:05:11.540\nAnd that becomes the avenue\nthat they use for\n\n98\n00:05:11.540 --> 00:05:14.080\nthe attack to get things\nlike your credentials.\n\n99\n00:05:14.080 --> 00:05:15.950\n&gt;&gt; Sure, especially a lot of e-commerce.\n\n100\n00:05:15.950 --> 00:05:22.320\nAnd like Wes said, companies that you\nwould assume to be of good moral standing.\n\n101\n00:05:22.320 --> 00:05:23.820\nBut things like.\n\n102\n00:05:23.820 --> 00:05:27.090\nI don't know, is that, no,\nyou haven't heard about that?\n\n103\n00:05:27.090 --> 00:05:27.660\n&gt;&gt; No, I haven't heard that.\n\n104\n00:05:27.660 --> 00:05:28.890\nYou've got to tell me about this one.\n\n105\n00:05:28.890 --> 00:05:32.879\n&gt;&gt; Okay, so this one is, I might be saying\nit wrong, but it happened a few years ago.\n\n106\n00:05:32.879 --> 00:05:38.000\nBut some pretty high profile actors and\nactresses had their accounts.\n\n107\n00:05:38.000 --> 00:05:40.390\nAnd I forget which vendor it was.\n\n108\n00:05:40.390 --> 00:05:42.720\nI want to say PayPal or\nmaybe it was iTunes.\n\n109\n00:05:42.720 --> 00:05:47.840\nBut they trusted that e-mail, and just\nlike you had said, they had authenticated,\n\n110\n00:05:47.840 --> 00:05:51.840\nthus giving their user name and\npassword to the actual attacker.\n\n111\n00:05:51.840 --> 00:05:55.210\nAnd that's where you saw a lot of\ninappropriate information being leaked\n\n112\n00:05:55.210 --> 00:05:56.020\nonline.\n\n113\n00:05:56.020 --> 00:05:59.091\nAnd now, well, it happened again.\n\n114\n00:05:59.091 --> 00:06:02.520\n2.0.\n&gt;&gt; And it's, it can't even be any worse\n\n115\n00:06:02.520 --> 00:06:06.130\nwhen you think you've just gave the\nattackers the credentials that they were\n\n116\n00:06:06.130 --> 00:06:09.292\nlooking for, and now they have access\nto your sensitive information.\n\n117\n00:06:09.292 --> 00:06:11.780\nNow that's not the only type\nof fishing attack, right?\n\n118\n00:06:11.780 --> 00:06:13.370\nThey kind of go up there.\n\n119\n00:06:13.370 --> 00:06:17.510\nPhishing basically is a term, again,\nis just remember, it's a basic scam where\n\n120\n00:06:17.510 --> 00:06:21.900\nyou have typically like an e-mail that's\nsent to you and it's misinformation.\n\n121\n00:06:21.900 --> 00:06:25.090\nAnd you think you recognize it,\nyou think you trust it,\n\n122\n00:06:25.090 --> 00:06:29.140\nwhen in reality it's just scraping\nthat authentication information, and\n\n123\n00:06:29.140 --> 00:06:30.550\nnow they're draining your bank account.\n\n124\n00:06:30.550 --> 00:06:32.010\nAgain, simplistic.\n\n125\n00:06:32.010 --> 00:06:34.280\nHowever, there's this other one,\nif we take a look here.\n\n126\n00:06:34.280 --> 00:06:36.780\nAnd this one, now,\nis not just phishing, right?\n\n127\n00:06:36.780 --> 00:06:39.640\nThis is spear phishing, all right?\n\n128\n00:06:39.640 --> 00:06:43.490\nWhen we talk about spear phishing, spear\nphishing is a little bit different, right?\n\n129\n00:06:43.490 --> 00:06:45.810\nThis is a little bit more sophisticated.\n\n130\n00:06:45.810 --> 00:06:47.430\nNot too sophisticated, but\n\n131\n00:06:47.430 --> 00:06:51.310\nit is a little bit more of\na sophisticated phishing type of attack.\n\n132\n00:06:51.310 --> 00:06:55.030\nBecause now what happens\nis I find out that, okay,\n\n133\n00:06:55.030 --> 00:06:58.670\nso I find out who Cherokee's aunt is,\nright?\n\n134\n00:06:58.670 --> 00:07:01.380\nAnd what I do is I send an e-mail that\n\n135\n00:07:01.380 --> 00:07:04.280\nlooks like it's coming from\nCherokee's aunt that says,\n\n136\n00:07:04.280 --> 00:07:09.120\nI don't know, honey, I'm gonna be going\ninto surgery, I really need some money.\n\n137\n00:07:09.120 --> 00:07:10.390\nCan you send me some money, right?\n\n138\n00:07:10.390 --> 00:07:13.709\nSo now, if you notice,\nthis is a targeted phishing attack, right?\n\n139\n00:07:13.709 --> 00:07:16.720\nIt's appearing like it's\ncoming from a relative.\n\n140\n00:07:16.720 --> 00:07:18.330\nOr, as me being a coworker.\n\n141\n00:07:18.330 --> 00:07:19.890\nI send an e-mail to Cherokee that says,\n\n142\n00:07:19.890 --> 00:07:24.107\nhey, I need some type of information or\nwhatever, and Cherokee goes,\n\n143\n00:07:24.107 --> 00:07:27.310\nI know Wes is not gonna send that\nthrough e-mail, cuz she recognizes it.\n\n144\n00:07:27.310 --> 00:07:30.710\nBut the point is, it looks like it\ncame from a relative or a coworker or\n\n145\n00:07:30.710 --> 00:07:32.190\na friend, right?\n\n146\n00:07:32.190 --> 00:07:35.530\nSo again,\nthis is a targeted phishing attack where\n\n147\n00:07:35.530 --> 00:07:38.760\na basic phishing attack is where, hey,\nif we can send out 100,000 e-mails and\n\n148\n00:07:38.760 --> 00:07:41.430\nwe get ten people that respond to them,\nthat's all we care about.\n\n149\n00:07:41.430 --> 00:07:44.060\n&gt;&gt; Very opportunistic versus the targeted.\n\n150\n00:07:44.060 --> 00:07:45.100\n&gt;&gt; Very good.\n\n151\n00:07:45.100 --> 00:07:46.740\nVery, very focused on that.\n\n152\n00:07:46.740 --> 00:07:47.852\nBut that's not the only one.\n\n153\n00:07:47.852 --> 00:07:50.924\nSo, so far we've got,\nif you take a look, we've got phishing.\n\n154\n00:07:50.924 --> 00:07:52.567\nWe've got spear phishing.\n\n155\n00:07:52.567 --> 00:07:53.921\nAnd then we've got another type.\n\n156\n00:07:53.921 --> 00:07:58.690\nAnd this is one, whaling is a probably\nmore sophisticated on the list,\n\n157\n00:07:58.690 --> 00:08:00.129\nand what is whaling?\n\n158\n00:08:00.129 --> 00:08:02.380\nWell I always think about searching for\nthe big fish,\n\n159\n00:08:02.380 --> 00:08:04.790\nthat's how I remembered it if\nI remember taking an exam.\n\n160\n00:08:05.900 --> 00:08:09.880\nBut what are you searching for\nall right, in whaling what you do\n\n161\n00:08:09.880 --> 00:08:15.330\nis the attacker is assuming\nthe identity of the C level employees.\n\n162\n00:08:15.330 --> 00:08:20.297\nI say C level employees,\nI want you to think of CIO, CEO, COOs.\n\n163\n00:08:20.297 --> 00:08:21.899\n&gt;&gt; The alphabet [LAUGH].\n\n164\n00:08:21.899 --> 00:08:25.812\n&gt;&gt; The big upper echelons,\nyes right [LAUGH] of your company, and\n\n165\n00:08:25.812 --> 00:08:30.625\nwhat it makes it look like is that hey,\nthis attack, or it's not an attack,\n\n166\n00:08:30.625 --> 00:08:34.388\nthis email, this request for\nyour user name and password,\n\n167\n00:08:34.388 --> 00:08:39.080\nwell it's coming from the CIO,\nthe Chief Information Officer.\n\n168\n00:08:39.080 --> 00:08:43.320\nSo man, I better respond to it,\nright, it's coming from the top up.\n\n169\n00:08:43.320 --> 00:08:46.030\nSo now I've got to it.\n\n170\n00:08:46.030 --> 00:08:48.840\nSo whaling again,\nthink about the big fish,\n\n171\n00:08:48.840 --> 00:08:53.970\nyou're receiving an unauthorized email\nfrom one of your C level employees.\n\n172\n00:08:53.970 --> 00:08:57.480\n&gt;&gt; And I always thought of it, Wes, as,\nI don't know if any of you play poker\n\n173\n00:08:57.480 --> 00:09:01.740\nout there or in the casinos, but\na whale is kind of your high roller, and\n\n174\n00:09:01.740 --> 00:09:06.610\nusually when they're targeting those\nFortune 500 company CEOs or like Wes said,\n\n175\n00:09:06.610 --> 00:09:11.120\nthose upper level employees, it's kinda\nlike the whales in the poker room.\n\n176\n00:09:11.120 --> 00:09:11.970\nThose big dogs.\n\n177\n00:09:11.970 --> 00:09:15.050\n&gt;&gt; Yeah, definitely, and\nthat's what I always think of whaling.\n\n178\n00:09:15.050 --> 00:09:15.760\nWhat are we doing?\n\n179\n00:09:15.760 --> 00:09:18.500\nWe're searching for\nthe biggest fish on the block for sure.\n\n180\n00:09:18.500 --> 00:09:19.040\nAll right.\nSo,\n\n181\n00:09:19.040 --> 00:09:22.095\nthat takes care of some of\nthe phishing based attacks.\n\n182\n00:09:22.095 --> 00:09:25.505\nAgain, keep in mind that these three here,\nfrom complexity,\n\n183\n00:09:25.505 --> 00:09:27.555\nlike least complex, phishing.\n\n184\n00:09:27.555 --> 00:09:30.135\nSpear phishing is a targeted attack.\n\n185\n00:09:30.135 --> 00:09:34.035\nWhaling, more sophisticated\nas now we're looking for,\n\n186\n00:09:34.035 --> 00:09:37.085\nsending out emails in the name of\nlike the CEO and stuff, if you will.\n\n187\n00:09:38.085 --> 00:09:40.385\nAll right,\nnow what else do we have here on the list?\n\n188\n00:09:40.385 --> 00:09:42.165\nGotta love some of these names here.\n\n189\n00:09:42.165 --> 00:09:44.830\nWe've got, Vishing.\n\n190\n00:09:44.830 --> 00:09:46.090\nAll right, vishing.\n\n191\n00:09:46.090 --> 00:09:46.990\nGot to love this one.\n\n192\n00:09:46.990 --> 00:09:48.240\nSo what is vishing?\n\n193\n00:09:48.240 --> 00:09:53.310\nAll right now, vishing is, this is a type\nof attack that essentially is carried\n\n194\n00:09:53.310 --> 00:09:56.290\nout via your voice technologies.\n\n195\n00:09:56.290 --> 00:10:00.250\nDoesn't necessarily have to be just these\nthings like we think of in networks today,\n\n196\n00:10:00.250 --> 00:10:02.970\nvoice over IP but we certainly could be\n\n197\n00:10:02.970 --> 00:10:06.180\nIt could be traditional things like\nyour landlines, traditional landlines.\n\n198\n00:10:06.180 --> 00:10:08.930\nIt could be things like voicemail,\nmessages.\n\n199\n00:10:08.930 --> 00:10:10.500\nI just kinda put them both.\n\n200\n00:10:10.500 --> 00:10:14.520\nYou might hear it called voicemail,\nvoice message, right?\n\n201\n00:10:14.520 --> 00:10:18.900\nThings like, for instance, cellphones, and\nthis is where you get a call, essentially,\n\n202\n00:10:18.900 --> 00:10:23.590\nfrom somebody saying reporting to\nrepresent somebody in your company,\n\n203\n00:10:23.590 --> 00:10:28.660\nmaybe your relative, if you will, but the\npoint is you're receiving this over phone\n\n204\n00:10:28.660 --> 00:10:32.060\nversus commonly when you're\nreceiving these things over email,\n\n205\n00:10:32.060 --> 00:10:34.010\nright, these messages over email.\n\n206\n00:10:34.010 --> 00:10:37.080\nNow, what we're doing is we're using\nthe phone as the avenue of attack.\n\n207\n00:10:38.140 --> 00:10:40.170\nAll right, so that's got vishing.\n\n208\n00:10:40.170 --> 00:10:44.100\nThe other one that we have here has got a\ncouple of different names, tailgaiting and\n\n209\n00:10:44.100 --> 00:10:45.580\npiggy backing.\n\n210\n00:10:45.580 --> 00:10:48.370\nSometimes you'll hear these\nused interchangeably.\n\n211\n00:10:48.370 --> 00:10:50.990\nThink about tailgaiting attack.\n\n212\n00:10:50.990 --> 00:10:55.620\nA tailgaiting attack is where you know\nsomebody within your company has like for\n\n213\n00:10:55.620 --> 00:11:01.000\ninstance, one of these RFID key fobs,\nthey swipe and authenticate a door.\n\n214\n00:11:01.000 --> 00:11:05.330\nThe door opens and\nthe person that is doing the attack walks\n\n215\n00:11:05.330 --> 00:11:10.490\nthrough that authenticated door before\nanybody has a chance to close it.\n\n216\n00:11:10.490 --> 00:11:12.050\nSo again, tailgating, I want you to think.\n\n217\n00:11:12.050 --> 00:11:13.700\nI know I live in an apartment complex.\n\n218\n00:11:13.700 --> 00:11:16.850\nIt's a gated community and\nI authenticate against the door.\n\n219\n00:11:16.850 --> 00:11:18.530\nThe gates open.\n\n220\n00:11:18.530 --> 00:11:19.430\nI move through the door.\n\n221\n00:11:19.430 --> 00:11:23.140\nWhat's supposed to happen is the\nauthenticated door's supposed to close,\n\n222\n00:11:23.140 --> 00:11:25.700\nand then the next person authenticates and\nthen they make their way through.\n\n223\n00:11:25.700 --> 00:11:30.475\nIn the tailgating attack, what happens is,\nit's one authenticated user and\n\n224\n00:11:30.475 --> 00:11:35.745\nan unauthorized user makes their way\ninto your building or into your system\n\n225\n00:11:35.745 --> 00:11:40.215\nwithout having to authenticate so,\ntailgating or the piggy back attack.\n\n226\n00:11:41.245 --> 00:11:43.265\nAll right,\nwhat else do we have on our lis?\n\n227\n00:11:43.265 --> 00:11:44.800\nLooks like we've got a few here,\n\n228\n00:11:44.800 --> 00:11:48.687\nwe've got impersonation, impersonation or\nif you will free texting.\n\n229\n00:11:48.687 --> 00:11:52.985\nNow, impersonation's a little but\ndifferent, because this could\n\n230\n00:11:52.985 --> 00:11:57.670\nbe something where this is in person,\nI don't wanna say impersonation, but\n\n231\n00:11:57.670 --> 00:12:02.200\nyou do this literally in person where you\ncould actually see and talk to the person.\n\n232\n00:12:02.200 --> 00:12:05.460\nCould be a phone call, but then it\nkinda borderlines between phishing and\n\n233\n00:12:05.460 --> 00:12:07.480\nimpersonation, but imagine this.\n\n234\n00:12:07.480 --> 00:12:11.200\nYou have somebody that shows\nup at noon at your company.\n\n235\n00:12:11.200 --> 00:12:15.195\nThey've got what looks like a work cart,\nlook like they've got their work jumpsuit,\n\n236\n00:12:15.195 --> 00:12:17.874\nand they've got a little,\nmaybe a badge or something, or\n\n237\n00:12:17.874 --> 00:12:21.267\nmaybe a fake little card hanging around\ntheir neck that identifies them as\n\n238\n00:12:21.267 --> 00:12:24.413\nbeing the computer repair guy that\nworks for such and such company.\n\n239\n00:12:24.413 --> 00:12:25.911\n&gt;&gt; Like a uniform with the name\nBob on the chest there.\n\n240\n00:12:25.911 --> 00:12:27.622\n[LAUGH]\n&gt;&gt; That's right and\n\n241\n00:12:27.622 --> 00:12:30.640\nthis actually happened too.\n\n242\n00:12:30.640 --> 00:12:33.890\nWhere, again,\nsomebody was let into the building.\n\n243\n00:12:33.890 --> 00:12:38.010\nThey were acting like they were\nthe IT repair personnel and\n\n244\n00:12:38.010 --> 00:12:40.650\nwhat they were doing was waiting for\npeople to go to lunch and\n\n245\n00:12:40.650 --> 00:12:42.760\nthey took all of the devices\nthat they could take.\n\n246\n00:12:42.760 --> 00:12:45.629\nJust putting them on the cart,\nwalking right out the building.\n\n247\n00:12:46.740 --> 00:12:48.160\nImpersonation.\n\n248\n00:12:48.160 --> 00:12:50.920\nYou're masquerading as\nsomebody that you're not.\n\n249\n00:12:50.920 --> 00:12:53.390\nWhether it be somebody of authority,\nwhether it be a vendor,\n\n250\n00:12:53.390 --> 00:12:57.790\nwhether it be a contractor\nthat is authorized you\n\n251\n00:12:57.790 --> 00:13:01.680\nmasquerade as being one of those,\nimpersonation if you will.\n\n252\n00:13:01.680 --> 00:13:04.280\nAll right, other attacks that we got.\n\n253\n00:13:04.280 --> 00:13:05.790\nThis is a simplistic attack.\n\n254\n00:13:05.790 --> 00:13:07.590\nThis is shoulder surfing.\n\n255\n00:13:07.590 --> 00:13:12.590\nSome of the things that they do to try to\nstop shoulder surfing is putting those\n\n256\n00:13:12.590 --> 00:13:17.570\nanti, well those privacy filters across\nthe monitor where you actually have to\n\n257\n00:13:17.570 --> 00:13:20.670\nbe sitting right in front of\nthe monitor to find out what's typing.\n\n258\n00:13:20.670 --> 00:13:25.030\nBut finding out,\nslow this down a little bit.\n\n259\n00:13:25.030 --> 00:13:29.370\nTo protect somebody from seeing what\nyou're typing when they are walking by\n\n260\n00:13:29.370 --> 00:13:32.630\nyour cubicle looking at your screen,\nbut they can do even more than that.\n\n261\n00:13:32.630 --> 00:13:35.790\nShoulder surfing doesn't have to be just\ngenerally looking at what you're typing.\n\n262\n00:13:35.790 --> 00:13:37.480\nThey could do things\nlike profiling you too,\n\n263\n00:13:37.480 --> 00:13:40.350\nat the same time that they're\ndoing shoulder surfing.\n\n264\n00:13:40.350 --> 00:13:42.300\nMaybe you're somebody that's into sports.\n\n265\n00:13:42.300 --> 00:13:43.810\nMaybe you got a favorite sports team.\n\n266\n00:13:43.810 --> 00:13:45.660\nMaybe you got a favorite sports player.\n\n267\n00:13:45.660 --> 00:13:49.010\nThey start doing things like password\nguessing based on what they see\n\n268\n00:13:49.010 --> 00:13:49.990\nyou doing everyday.\n\n269\n00:13:49.990 --> 00:13:52.110\nSo shoulder surfing is\nexactly what it sounds like.\n\n270\n00:13:52.110 --> 00:13:54.980\nIt's looking over somebody’s shoulder for\n\n271\n00:13:54.980 --> 00:13:58.410\nthe purposes of trying to steal\ntheir authentication information.\n\n272\n00:14:00.410 --> 00:14:02.510\nLet’s see what else, a hoax.\n\n273\n00:14:02.510 --> 00:14:03.300\nHoax is another one.\n\n274\n00:14:03.300 --> 00:14:05.972\nHoax is just some kind of\nmisleading information, and\n\n275\n00:14:05.972 --> 00:14:09.940\nit's propagated through the channels\nwithin maybe your company, maybe it's just\n\n276\n00:14:09.940 --> 00:14:13.820\nan email system that has just basically\ngiving out misleading information.\n\n277\n00:14:15.390 --> 00:14:18.170\nNext type of attack that we have here and\nboy this one,\n\n278\n00:14:18.170 --> 00:14:20.290\nthey all got great fun names.\n\n279\n00:14:20.290 --> 00:14:25.440\nThe last one here is the watering hole\nattack, and essentially what this attack\n\n280\n00:14:25.440 --> 00:14:30.940\ndoes is, it targets a group of people\nthat work together, and then what they\n\n281\n00:14:30.940 --> 00:14:36.660\ntry to do, is they try to infect a website\nthat like a group of people are using.\n\n282\n00:14:36.660 --> 00:14:40.940\nBecause remember, just like USBs,\nif we put boot sector viruses on them and\n\n283\n00:14:40.940 --> 00:14:45.460\nwe throw those USB devices through\nthe parking lot of an organization and\n\n284\n00:14:45.460 --> 00:14:48.490\none person plugs them in,\nit's all it takes.\n\n285\n00:14:48.490 --> 00:14:51.220\nIt only takes one person to\nthwart your security system.\n\n286\n00:14:51.220 --> 00:14:55.360\nJust like in a watering hole attack, if we\nknow that a group of people are going to\n\n287\n00:14:55.360 --> 00:14:59.244\nthe same website and we do some kind of\ncross-site scripting attack where you have\n\n288\n00:14:59.244 --> 00:15:04.210\nimbed some code into that website and\none of those group of employees goes\n\n289\n00:15:04.210 --> 00:15:07.880\nto that website and downloads\nthe malicious script, that's all it took.\n\n290\n00:15:08.920 --> 00:15:12.870\nSo again, keep in mind, that a watering\nhole attack is gonna be one where\n\n291\n00:15:12.870 --> 00:15:16.920\nthey're attacking a common resource\nthat's used by a group of people,\n\n292\n00:15:16.920 --> 00:15:20.810\nwith the intention of at least\ngetting one of them to be infected.\n\n293\n00:15:20.810 --> 00:15:22.300\n&gt;&gt; And it's kind of\ninteresting you mentioned that,\n\n294\n00:15:22.300 --> 00:15:26.680\nbecause sometimes their company or\ncorporate network may be extremely secure,\n\n295\n00:15:26.680 --> 00:15:31.550\nbut they have a third-party entity that\nthey do utilize maybe quite frequently.\n\n296\n00:15:31.550 --> 00:15:33.951\nMaybe even on a day-to-day basis and\n\n297\n00:15:33.951 --> 00:15:39.380\na perfect example of that would be\nMatt Honan from wired.com, a journalist.\n\n298\n00:15:39.380 --> 00:15:40.290\nCheck that out.\n\n299\n00:15:40.290 --> 00:15:42.632\nHe'll tell you all about it.\n\n300\n00:15:42.632 --> 00:15:44.090\n[LAUGH]\n&gt;&gt; [LAUGH] All right.\n\n301\n00:15:44.090 --> 00:15:47.130\nSo those are some of the ones to remember.\n\n302\n00:15:47.130 --> 00:15:49.285\nWhen it comes to social\nengineering attacks.\n\n303\n00:15:49.285 --> 00:15:53.870\nWe've got plenty more but those are\ndefinitely some of the social engineering\n\n304\n00:15:53.870 --> 00:15:56.314\nattack types that you should be aware of.\n\n305\n00:15:56.314 --> 00:16:00.069\nNow another thing that they call\nout on the exam Is they call out,\n\n306\n00:16:00.069 --> 00:16:01.679\nthey say principles, right?\n\n307\n00:16:01.679 --> 00:16:05.250\nAnd they say well,\nthe reasons for effectiveness.\n\n308\n00:16:05.250 --> 00:16:08.470\nSo what I've kinda called these,\nthe principles of social engineering.\n\n309\n00:16:08.470 --> 00:16:09.100\nYou might go out, and\n\n310\n00:16:09.100 --> 00:16:13.480\nyou might read things things like they\nsay the psychology of social engineering.\n\n311\n00:16:13.480 --> 00:16:17.170\nWhy is social engineering successful?\n\n312\n00:16:17.170 --> 00:16:18.320\nWhy is it effective?\n\n313\n00:16:18.320 --> 00:16:23.110\nAnd it usually boils down to just\na handful of about seven principles.\n\n314\n00:16:23.110 --> 00:16:25.830\nAll right, so let's go ahead and\ntalk about them.\n\n315\n00:16:25.830 --> 00:16:27.140\nI got, again, just a little list here.\n\n316\n00:16:27.140 --> 00:16:29.690\nWe can kinda go through\nthese one at a time.\n\n317\n00:16:29.690 --> 00:16:32.070\nSo when it comes to the Principles\nof Social Engineering,\n\n318\n00:16:32.070 --> 00:16:36.040\none of the first things that\nthey talk about Is authority.\n\n319\n00:16:36.040 --> 00:16:40.750\nWell, authority, what is it about\nthe concept about authority that makes\n\n320\n00:16:40.750 --> 00:16:43.290\nsocial engineering successful?\n\n321\n00:16:43.290 --> 00:16:45.450\nWell, I want you to think about it.\n\n322\n00:16:45.450 --> 00:16:49.390\nPeople are conditioned\nto respond to authority.\n\n323\n00:16:50.860 --> 00:16:52.360\nNow let's say for instance,\n\n324\n00:16:52.360 --> 00:16:55.820\nwe are going to put the black\nhead on Cherokee this time.\n\n325\n00:16:55.820 --> 00:17:00.320\nAnd let's say she gives me a call and\nshe's my supervisor.\n\n326\n00:17:00.320 --> 00:17:02.020\nAnd she needs a password changed.\n\n327\n00:17:02.020 --> 00:17:04.890\nWe've got a policy that says this\nis how passwords are changed.\n\n328\n00:17:04.890 --> 00:17:08.200\nI know what Cherokee's voice sounds like,\nbut somebody calls me and\n\n329\n00:17:08.200 --> 00:17:09.170\nthey're acting like Cherokee.\n\n330\n00:17:10.170 --> 00:17:11.090\nLet's change it.\n\n331\n00:17:11.090 --> 00:17:11.780\nWe gotta change it.\n\n332\n00:17:11.780 --> 00:17:14.060\nI'm your boss, you need to change this.\n\n333\n00:17:14.060 --> 00:17:15.430\nYou need to give me that password.\n\n334\n00:17:15.430 --> 00:17:16.710\nRemember, the authority.\n\n335\n00:17:18.430 --> 00:17:20.280\nPeople are conditioned\nto respond to authority.\n\n336\n00:17:20.280 --> 00:17:21.752\nLet me give you another case and example.\n\n337\n00:17:21.752 --> 00:17:27.910\nI was reading a story where it\nwas a retired navy veteran.\n\n338\n00:17:27.910 --> 00:17:32.820\nAnd when he was younger in the military,\none of his duties was to protect\n\n339\n00:17:32.820 --> 00:17:35.950\nthe cryptographic software\nthat was in a mobile unit.\n\n340\n00:17:35.950 --> 00:17:38.950\nThat they were using to encrypt\nsystems within the military.\n\n341\n00:17:40.080 --> 00:17:42.640\nAnd a couple of the higher ups.\n\n342\n00:17:42.640 --> 00:17:44.280\nI guess he was a private, first class.\n\n343\n00:17:44.280 --> 00:17:45.850\nBut a couple of the higher ups came in.\n\n344\n00:17:45.850 --> 00:17:48.690\nAnd they said,\nwe need access to this building.\n\n345\n00:17:48.690 --> 00:17:50.800\nAnd started threatening\nhim with court martial.\n\n346\n00:17:50.800 --> 00:17:51.300\nAuthority.\n\n347\n00:17:51.300 --> 00:17:53.980\nYou're trained to respond to authority.\n\n348\n00:17:53.980 --> 00:17:54.930\nSo they rush the van.\n\n349\n00:17:54.930 --> 00:17:58.565\nAnd he said, well,\nat that point I let my M16 do the talking.\n\n350\n00:17:58.565 --> 00:18:03.586\n[SOUND] Cocked it and put it in their,\nbasically put it to their chest.\n\n351\n00:18:03.586 --> 00:18:07.042\nTurns out that what they were doing was\nthey were stress testing the security\n\n352\n00:18:07.042 --> 00:18:09.850\nsystems and it started with the people.\n\n353\n00:18:09.850 --> 00:18:12.000\nAnd he did exactly what\nhe should have done.\n\n354\n00:18:12.000 --> 00:18:14.120\nHe did not back down to authority,\n\n355\n00:18:14.120 --> 00:18:16.800\nhe said I have standing orders\nthat this the way it is.\n\n356\n00:18:16.800 --> 00:18:19.050\nAnd I don't care if you\nare threatening me with court martial.\n\n357\n00:18:19.050 --> 00:18:20.660\nYou will go to your\nsupervising officer and\n\n358\n00:18:20.660 --> 00:18:24.250\ncome back here with something that\ntells me that you are allowed in.\n\n359\n00:18:24.250 --> 00:18:25.620\nAgain, condition to authority.\n\n360\n00:18:25.620 --> 00:18:27.130\nThey're trying to abuse their authority.\n\n361\n00:18:27.130 --> 00:18:28.626\nAnd in this case,\nit was just a dry run and\n\n362\n00:18:28.626 --> 00:18:31.540\nthey were trying to figure out who\nwould respond and who wouldn't?\n\n363\n00:18:31.540 --> 00:18:33.080\nApparently, he was doing his job.\n\n364\n00:18:33.080 --> 00:18:38.240\nSo that's an example of\nthe principle of authority.\n\n365\n00:18:38.240 --> 00:18:39.670\nWell, how about the next one here?\n\n366\n00:18:39.670 --> 00:18:42.950\nIntimidation, you might even say\nthat that same type of situation,\n\n367\n00:18:42.950 --> 00:18:43.900\nintimidation was used.\n\n368\n00:18:46.770 --> 00:18:49.380\nUsing implied authority for\na means of attack.\n\n369\n00:18:49.380 --> 00:18:53.240\nThe implied authority might be\nintimidating, higher ranking for\n\n370\n00:18:53.240 --> 00:18:59.040\ninstance than the example that we gave,\nhigher ranking military supervisor.\n\n371\n00:18:59.040 --> 00:19:00.570\nAnother one that they have is consensus.\n\n372\n00:19:01.710 --> 00:19:05.600\nNow when they talk about\nconsensus I don't know.\n\n373\n00:19:05.600 --> 00:19:09.020\nCherokee should I click on that email,\nI'm not sure.\n\n374\n00:19:09.020 --> 00:19:10.800\nWell let me find out what Cherokee thinks.\n\n375\n00:19:10.800 --> 00:19:14.390\nWell, Cherokee said don't click on it, but\nI was really looking for an answer right?\n\n376\n00:19:14.390 --> 00:19:15.750\nI wanted the right answer.\n\n377\n00:19:15.750 --> 00:19:16.710\nWhether it's right or wrong.\n\n378\n00:19:16.710 --> 00:19:18.660\nLet me ask two or three more people.\n\n379\n00:19:18.660 --> 00:19:20.360\nAll right,\nCherokee said just stay away from it,\n\n380\n00:19:20.360 --> 00:19:24.560\nyou should never click on email\nattachments that you don't know about.\n\n381\n00:19:24.560 --> 00:19:27.520\nWell, let me go figure out what\nSally wants, and what Bill wants,\n\n382\n00:19:27.520 --> 00:19:28.710\nand this person.\n\n383\n00:19:28.710 --> 00:19:31.635\nSo you look at the overall consensus.\n\n384\n00:19:31.635 --> 00:19:34.465\nAnd if everybody else is jumping off\nthe bridge it must be okay to jump off\n\n385\n00:19:34.465 --> 00:19:35.515\nthe bridge yourself?\n\n386\n00:19:35.515 --> 00:19:38.135\nNow that seems like,\nwell that's ridiculous.\n\n387\n00:19:38.135 --> 00:19:42.255\nBut that's ultimately what that proverbial\nsaying that we would tell our kids.\n\n388\n00:19:42.255 --> 00:19:44.025\nIf somebody jumps off a bridge\nare you gonna do it too?\n\n389\n00:19:44.025 --> 00:19:44.674\nWell, consensus says it's\n\n390\n00:19:44.674 --> 00:19:45.196\nsocial engineering-\n\n391\n00:19:45.196 --> 00:19:48.627\n&gt;&gt; [CROSSTALK]\n&gt;&gt; That's right.\n\n392\n00:19:48.627 --> 00:19:51.290\nSo I'm gonna ask this person,\nI'm gonna ask that person.\n\n393\n00:19:51.290 --> 00:19:53.580\nAnd if everybody agrees that yeah,\n\n394\n00:19:53.580 --> 00:19:56.180\nwe should go ahead and\nclick on that email attachment.\n\n395\n00:19:56.180 --> 00:19:59.560\nEven though we don't know who it's from,\nthen I'll go ahead and do it too.\n\n396\n00:19:59.560 --> 00:20:01.180\nWhat are my neighbors doing?\n\n397\n00:20:01.180 --> 00:20:02.410\nWhat is the person next to me doing?\n\n398\n00:20:02.410 --> 00:20:03.329\nIt's consensus.\n\n399\n00:20:04.872 --> 00:20:06.576\nAll right, let's see what else do we have?\n\n400\n00:20:06.576 --> 00:20:09.680\nScarcity all right, scarcity.\n\n401\n00:20:09.680 --> 00:20:14.130\nIf I tell you that you can\nhave this product half off but\n\n402\n00:20:14.130 --> 00:20:18.580\nyou better do it within the next\nfive minutes or the deal goes away.\n\n403\n00:20:19.700 --> 00:20:23.090\nYou most likely are going to click on\nsomething if you know that if you don't\n\n404\n00:20:23.090 --> 00:20:24.890\nclick on it soon.\n\n405\n00:20:24.890 --> 00:20:26.060\nThe chances of using or\n\n406\n00:20:26.060 --> 00:20:30.530\nutilizing whatever the offer is is\ngonna go away forever, scarcity.\n\n407\n00:20:30.530 --> 00:20:34.320\nScarcity essentially says people\nare more likely to respond to something,\n\n408\n00:20:34.320 --> 00:20:37.800\nto a scam, if there's a time or\navailability concern.\n\n409\n00:20:37.800 --> 00:20:41.920\nDownload now or you don't get to.\n\n410\n00:20:41.920 --> 00:20:47.620\nAll right, not being able to view a page\nuntil a program is able to install.\n\n411\n00:20:49.030 --> 00:20:51.840\nThis is another thing,\nyou can't view this program?\n\n412\n00:20:51.840 --> 00:20:53.350\nDownload the Adobe Flash Player,\n\n413\n00:20:53.350 --> 00:20:55.990\nhere we'll give you the button\nto click on to do it.\n\n414\n00:20:55.990 --> 00:20:58.585\nWell, I really want to view that page,\nit's gotta be something important.\n\n415\n00:20:58.585 --> 00:20:59.585\n&gt;&gt; [LAUGH]\n&gt;&gt; Let me go ahead and\n\n416\n00:20:59.585 --> 00:21:02.625\nclick on that Adobe Flash Player download.\n\n417\n00:21:02.625 --> 00:21:05.765\nAnd the download was actually\nthe infected malware.\n\n418\n00:21:05.765 --> 00:21:09.415\nSo, again, you gotta understand\nthat things like scarcity can cause\n\n419\n00:21:09.415 --> 00:21:13.155\na likelihood that you're gonna respond to\nsome kinda social engineering attempt.\n\n420\n00:21:14.695 --> 00:21:16.015\nAll right, what else do we have here?\n\n421\n00:21:16.015 --> 00:21:16.745\nFamiliarity.\n\n422\n00:21:17.765 --> 00:21:18.595\nWell, if you're\n\n423\n00:21:20.085 --> 00:21:23.840\nfamiliar with something that usually\nmeans that you're more comfortable.\n\n424\n00:21:24.970 --> 00:21:25.746\nAnd at comfort,\n\n425\n00:21:25.746 --> 00:21:29.470\npeople are gonna tend to respond to\nsomething they're more comfortable with.\n\n426\n00:21:29.470 --> 00:21:31.480\nSo that's the familiarity part.\n\n427\n00:21:33.190 --> 00:21:35.820\nTrust, the interesting\nthis is trust should\n\n428\n00:21:35.820 --> 00:21:37.420\nhave probably been first in this list.\n\n429\n00:21:38.530 --> 00:21:41.530\nIt's all part of the list, there is\nno sequential order that says, hey,\n\n430\n00:21:41.530 --> 00:21:42.460\none goes anywhere.\n\n431\n00:21:42.460 --> 00:21:44.570\nBut if you think about\na Cherokee what would you think?\n\n432\n00:21:44.570 --> 00:21:47.640\nLike in social engineering, the first\nthing I gotta do is probably establish\n\n433\n00:21:47.640 --> 00:21:49.069\nsome kind of line of trust, right?\n\n434\n00:21:49.069 --> 00:21:50.038\n&gt;&gt; Yeah.\n\n435\n00:21:50.038 --> 00:21:52.670\n&gt;&gt; And that's what trust boils down to.\n\n436\n00:21:52.670 --> 00:21:58.250\nReally is the social engineer's\na first attack vector if you will.\n\n437\n00:21:58.250 --> 00:22:00.830\nLet me go ahead and\nexploit the trust that you have.\n\n438\n00:22:00.830 --> 00:22:03.120\nWith then me as being a service personnel,\n\n439\n00:22:03.120 --> 00:22:06.330\nme being the person that\ncan fix this problem.\n\n440\n00:22:06.330 --> 00:22:09.240\nThe deal I'm gonna get, if you will.\n\n441\n00:22:09.240 --> 00:22:12.050\nIf you trust it, if you trust whatever\nis being presented to you then\n\n442\n00:22:12.050 --> 00:22:13.460\nyou're more likely to respond to it.\n\n443\n00:22:13.460 --> 00:22:16.030\n&gt;&gt; Or your boss or it might be\na mixture of more than just one\n\n444\n00:22:16.030 --> 00:22:17.840\nof these particular avenues?\n\n445\n00:22:17.840 --> 00:22:18.570\n&gt;&gt; Most definitely.\n\n446\n00:22:18.570 --> 00:22:22.480\nAnd then the last one,\nthis one really, really kicks in.\n\n447\n00:22:22.480 --> 00:22:24.840\nAll of these can prey on human emotions.\n\n448\n00:22:24.840 --> 00:22:28.050\nWhen you were talking about\njust the malicious nature, and\n\n449\n00:22:28.050 --> 00:22:30.700\nhow really evil it is on urgency.\n\n450\n00:22:32.240 --> 00:22:33.520\nYou better click this now.\n\n451\n00:22:33.520 --> 00:22:37.230\nYou better send money now or\nthe operation that your kid or\n\n452\n00:22:37.230 --> 00:22:42.230\nyour child who is now sitting on\nthe side of the road needs to survive.\n\n453\n00:22:42.230 --> 00:22:45.656\nWell, I better respond\nright away right now.\n\n454\n00:22:45.656 --> 00:22:47.221\nThe FBI warning right,\n\n455\n00:22:47.221 --> 00:22:51.457\nthe FBI warning comes out start\nbarking at you doing this alarm.\n\n456\n00:22:51.457 --> 00:22:54.037\nThe urgency is I got to get\nthis taking care of now,\n\n457\n00:22:54.037 --> 00:22:55.894\nI got to get this taking care of now.\n\n458\n00:22:55.894 --> 00:22:58.554\nRansomware, I've gonna\nget it taken care of now.\n\n459\n00:22:58.554 --> 00:22:59.937\nLet's go take care of it, right?\n\n460\n00:22:59.937 --> 00:23:04.589\nSo again urgency that nature to, I got\nto get this done now or this is gonna\n\n461\n00:23:04.589 --> 00:23:10.050\nhappen that's another thing that makes\nSocial Engineering more effective.\n\n462\n00:23:10.050 --> 00:23:12.880\nIt really is pretty bad Wes,\nbecause most likely,\n\n463\n00:23:12.880 --> 00:23:16.690\nmost humans have been in a situation where\nthey needed to be urgent with something.\n\n464\n00:23:16.690 --> 00:23:20.880\nSo it's a very relatable, and you get\nthat human connection, whenever, and\n\n465\n00:23:20.880 --> 00:23:23.210\nso yeah, it stinks, but it happens.\n\n466\n00:23:23.210 --> 00:23:28.250\n&gt;&gt; It does, so on the exam,\none of the things that I would notice,\n\n467\n00:23:28.250 --> 00:23:30.360\nis I would know these principles, right?\n\n468\n00:23:30.360 --> 00:23:33.200\nAnd just know some of the scenarios\nlike we've given you here.\n\n469\n00:23:33.200 --> 00:23:38.550\nAbout the different principles so\nthat if they ask you on the exam\n\n470\n00:23:38.550 --> 00:23:42.710\nyou'll be able to know which is this\nan example of the principles of?\n\n471\n00:23:42.710 --> 00:23:46.710\nIf they say something like you\nneed to respond right away\n\n472\n00:23:46.710 --> 00:23:50.260\nbecause if you don't respond right\naway something bad's gonna happen.\n\n473\n00:23:50.260 --> 00:23:51.190\nIt could be urgency.\n\n474\n00:23:51.190 --> 00:23:54.510\nIf you don't respond this\ndeal is gonna go away, right?\n\n475\n00:23:54.510 --> 00:23:55.970\nThat might be something like scarcity.\n\n476\n00:23:55.970 --> 00:24:00.320\nSo just know some of the scenarios when\nthey ask you what is this a principle of.\n\n477\n00:24:00.320 --> 00:24:03.130\nIf they give you a scenario on\nthe exam that sets you up for\n\n478\n00:24:03.130 --> 00:24:05.890\nrecognizing a social engineering attack.\n\n479\n00:24:05.890 --> 00:24:07.110\nWell that sounds great Wes.\n\n480\n00:24:07.110 --> 00:24:10.470\nI think we've covered a lot of different\ntypes of social engineering attacks.\n\n481\n00:24:10.470 --> 00:24:12.810\nAnd that's just a beginning\nof our types of attacks.\n\n482\n00:24:12.810 --> 00:24:17.180\nUnfortunately like we talked about before,\nthere are several different vectors and\n\n483\n00:24:17.180 --> 00:24:19.580\navenues of attacks that we\nwill cover in a later episode.\n\n484\n00:24:19.580 --> 00:24:21.020\nSo stay tune for that.\n\n485\n00:24:21.020 --> 00:24:22.850\nFor this show we'll go ahead and sign out.\n\n486\n00:24:22.850 --> 00:24:24.501\nRemember I'm your show\nhost Cherokee Boose.\n\n487\n00:24:24.501 --> 00:24:25.362\n&gt;&gt; And I'm Wes Bryan.\n\n488\n00:24:25.362 --> 00:24:28.857\n&gt;&gt; See you here next time on ITPRO.TV.\n\n489\n00:24:28.857 --> 00:24:34.912\n[MUSIC]\n\n490\n00:24:34.912 --> 00:24:37.815\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "211742045"
        },
        {
          "description": "This a continuation of a previous conversation where Cherokee and Wes discuss several types of attacks. They talk about different types of Denial of Service (DoS) and Distributed Denial of Service (DDoS), Man-in-the-Middle (MitM), Buffer overflow, injection, Cross-site Scripting (XSS) and Cross-site Request Forgery (CSRF or XSRF), Privilege Escalation and more! Tune in to get all of the details.",
          "length": "2083",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-2-types_of_attacks_pt2-040517-PGM.00_34_28_20.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-2-types_of_attacks_pt2-040517-PGM.00_34_28_20.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-2-types_of_attacks_pt2-040517-PGM.00_34_28_20.Still001-sm.jpg",
          "title": "Types of Attacks Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.655\nWelcome to ITProTV, I'm your host,\nDon Pezet, [CROSSTALK]\n\n2\n00:00:02.655 --> 00:00:07.511\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:07.511 --> 00:00:08.719\n[MUSIC]\n\n4\n00:00:08.719 --> 00:00:11.895\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.895 --> 00:00:15.220\n&gt;&gt; Welcome, ladies and gentlemen,\nto your CompTIA Security+ series.\n\n6\n00:00:15.220 --> 00:00:16.370\nI'm your show host, Cherokee Boose.\n\n7\n00:00:17.890 --> 00:00:21.232\nThis episode is a continuation of\na previous conversation where we\n\n8\n00:00:21.232 --> 00:00:23.508\nwere looking at different\ntypes of attacks.\n\n9\n00:00:23.508 --> 00:00:25.940\nAnd with us today, in studios,\nwe have Mr. Wes Bryan.\n\n10\n00:00:25.940 --> 00:00:27.110\nThank you for joining us today, Wes.\n\n11\n00:00:27.110 --> 00:00:29.860\n&gt;&gt; Thanks for having me here,\nthat's right, we are in a Part 2.\n\n12\n00:00:29.860 --> 00:00:32.770\nCuz we have a whole bunch of\ngreat topics to talk about.\n\n13\n00:00:32.770 --> 00:00:36.550\nIn the first part, we talked a little bit\nabout things like social engineering.\n\n14\n00:00:36.550 --> 00:00:37.620\nDefinitely have to worry about it.\n\n15\n00:00:37.620 --> 00:00:40.930\nWe talked about how it typically\npreys on human emotion and\n\n16\n00:00:40.930 --> 00:00:42.410\nthe principles of effectiveness.\n\n17\n00:00:42.410 --> 00:00:46.880\nKeep in mind that there are,\naccording to the CompTIA, they do call out\n\n18\n00:00:46.880 --> 00:00:51.170\nseven different principles for\nsuccess and be aware of them.\n\n19\n00:00:51.170 --> 00:00:53.490\nBut now we're gonna kind of move\n\n20\n00:00:53.490 --> 00:00:55.670\nto the different types of\nattacks that can happen.\n\n21\n00:00:55.670 --> 00:00:57.770\nAnd one of the things that they call out,\n\n22\n00:00:57.770 --> 00:01:00.330\nthey call out things like application and\nservice-based attacks.\n\n23\n00:01:00.330 --> 00:01:03.705\nSo let's kinda understand what they\nmean when they say application or\n\n24\n00:01:03.705 --> 00:01:05.520\nservice-based attack, all right?\n\n25\n00:01:05.520 --> 00:01:08.360\nWhen we look at a client/server network,\nwhich is one of the most popular\n\n26\n00:01:08.360 --> 00:01:11.910\nnetworking topologies that we use today,\nwe have our clients.\n\n27\n00:01:11.910 --> 00:01:14.390\nOur clients are typically\nrequesting some kind of service,\n\n28\n00:01:14.390 --> 00:01:15.690\nsome kind of resource, right?\n\n29\n00:01:15.690 --> 00:01:19.265\nThere's an application that's typically\nthey're probably using in order\n\n30\n00:01:19.265 --> 00:01:22.185\nto request a resource, like,\nfor instance, email, right?\n\n31\n00:01:22.185 --> 00:01:24.829\nIf I have an application,\nemail client, and\n\n32\n00:01:24.829 --> 00:01:27.410\nit's gonna send email to the email server.\n\n33\n00:01:27.410 --> 00:01:30.630\nAnd that server's listening\nout to receive the email.\n\n34\n00:01:30.630 --> 00:01:35.010\nSo when they talk about application\nattacks, it could be a program.\n\n35\n00:01:35.010 --> 00:01:38.830\nIt could be the services in the background\nthat the program uses in order to\n\n36\n00:01:38.830 --> 00:01:39.450\ncommunicate.\n\n37\n00:01:39.450 --> 00:01:43.031\nLike, for instance, a web browser, that's\na web client, that's an application.\n\n38\n00:01:43.031 --> 00:01:47.617\nBut underneath the surface, right, it's\nmaking service calls out to a web server\n\n39\n00:01:47.617 --> 00:01:49.880\nthat's gonna serve it back some HTMLs.\n\n40\n00:01:49.880 --> 00:01:53.880\nSo again, you have this relationship\nbetween the applications and\n\n41\n00:01:53.880 --> 00:01:54.680\nthe services, right?\n\n42\n00:01:54.680 --> 00:01:56.977\nThe applications are typically what\nwe see as the end user, right?\n\n43\n00:01:56.977 --> 00:02:01.240\nThe result, the data, if you will.\n\n44\n00:02:01.240 --> 00:02:04.936\nWhere the service in the background\nis what the network, if you will, or\n\n45\n00:02:04.936 --> 00:02:08.100\nthe applications used in order\nto deliver that information.\n\n46\n00:02:08.100 --> 00:02:11.560\nSo we're gonna look at some\napplication and service attacks.\n\n47\n00:02:11.560 --> 00:02:14.740\nAnd one of the first ones that they\ncall out is a pretty common one.\n\n48\n00:02:14.740 --> 00:02:16.582\nIt's one that we have to worry about, and\n\n49\n00:02:16.582 --> 00:02:19.278\nthat's something known as\na denial-of-service attack.\n\n50\n00:02:19.278 --> 00:02:23.070\nNow denial-of-service attack can\ncome in many different forms.\n\n51\n00:02:23.070 --> 00:02:25.939\nAnd it can be very complex,\nit can also be very simplistic.\n\n52\n00:02:27.270 --> 00:02:29.842\nCherokee, one of the simplistic,\nand when I say that,\n\n53\n00:02:29.842 --> 00:02:33.695\nthe simplest type of denial-of-service\nattacks I think about is power, right?\n\n54\n00:02:33.695 --> 00:02:35.855\nIf you got a server that's\nproviding a resource, and\n\n55\n00:02:35.855 --> 00:02:38.543\nif somebody does happen to have\nphysical access to your building,\n\n56\n00:02:38.543 --> 00:02:41.050\nyou probably need to think about\nyour security layers there.\n\n57\n00:02:41.050 --> 00:02:44.360\nBut they don't necessarily have to\nhave access to the building, either.\n\n58\n00:02:44.360 --> 00:02:48.110\nBut if they can manage to pull the power,\nright, maybe even outside?\n\n59\n00:02:48.110 --> 00:02:54.217\nYou don't have redundant electrical grids,\nit ends up that the server shuts down.\n\n60\n00:02:54.217 --> 00:02:57.932\nAnd whatever service that it's\nproviding is no longer being provided.\n\n61\n00:02:57.932 --> 00:03:01.710\nSo denial-of-service attacks don't really\nneed to be that complex in order to be\n\n62\n00:03:01.710 --> 00:03:02.680\nsuccessful.\n\n63\n00:03:02.680 --> 00:03:03.630\n&gt;&gt; Good point, Wes.\n\n64\n00:03:03.630 --> 00:03:06.640\nI think that it's great to encourage\npeople to really think outside\n\n65\n00:03:06.640 --> 00:03:07.350\nthe box here.\n\n66\n00:03:07.350 --> 00:03:11.100\nBecause we're not talking about just from\na technical standpoint or a physical.\n\n67\n00:03:11.100 --> 00:03:14.230\nBut really it's pretty vague,\nand it leaves the door wide open.\n\n68\n00:03:14.230 --> 00:03:17.430\n&gt;&gt; It does, one of the other security\nexperts that we've had that has\n\n69\n00:03:17.430 --> 00:03:19.540\ncome through here made a great statement.\n\n70\n00:03:19.540 --> 00:03:20.410\nI didn't even think about it.\n\n71\n00:03:20.410 --> 00:03:23.460\nIt's the fact that, you take a data\ncenter, for instance, right?\n\n72\n00:03:23.460 --> 00:03:26.110\nWhat happens if I can get up on\ntop of that data center, and\n\n73\n00:03:26.110 --> 00:03:29.550\nyou have your exhaust vents, right,\nwhere we got a climate control system.\n\n74\n00:03:29.550 --> 00:03:32.160\nWe need a certain temperature\ninside of our data centers to\n\n75\n00:03:32.160 --> 00:03:34.034\nmaintain the environment, if you will.\n\n76\n00:03:34.034 --> 00:03:37.760\nSo that our servers don't go into\nlike a critical thermal shut down.\n\n77\n00:03:37.760 --> 00:03:40.420\nWell, what if I can throw a blanket\nright over the exhaust vents?\n\n78\n00:03:40.420 --> 00:03:44.600\nWell, now all that heat is gonna start\nbuilding up in the data center and\n\n79\n00:03:44.600 --> 00:03:46.140\nstart causing shutdowns, right?\n\n80\n00:03:46.140 --> 00:03:48.390\nVery simplistic,\nit could be a denial-of-service attack.\n\n81\n00:03:48.390 --> 00:03:50.390\nNow it can be a little bit more than that,\nright?\n\n82\n00:03:51.480 --> 00:03:54.710\nThe more complex side of denial-of-service\nattacks go in things like\n\n83\n00:03:54.710 --> 00:03:55.742\npacket manipulation.\n\n84\n00:03:55.742 --> 00:03:59.090\nFor instance, a wireless, let's take a\nwireless denial-of-service attack, right?\n\n85\n00:03:59.090 --> 00:04:01.951\nIf I can craft a packet\nthat does a station,\n\n86\n00:04:01.951 --> 00:04:07.670\nthe wireless device to the access point,\nwhat they call a station to AP probe.\n\n87\n00:04:07.670 --> 00:04:09.580\nAnd what it does,\nit's an association request.\n\n88\n00:04:09.580 --> 00:04:11.630\nIt says, hey,\nI wanna join the wireless network.\n\n89\n00:04:11.630 --> 00:04:15.500\nBut if I can craft a packet that it's\nmalicious, and I couldn't care less,\n\n90\n00:04:15.500 --> 00:04:16.820\nto join your wireless network,\n\n91\n00:04:16.820 --> 00:04:20.890\nI can just flood your access point\nwith all these association requests.\n\n92\n00:04:20.890 --> 00:04:24.400\nAnd it starts denying access to\nother legitimate traffic, why?\n\n93\n00:04:24.400 --> 00:04:27.165\nBecause it's too busy to handle\nwhat I'm throwing at it, right?\n\n94\n00:04:27.165 --> 00:04:29.370\nSo they can get very complex.\n\n95\n00:04:29.370 --> 00:04:31.850\nJust keep in mind that when it comes\nto a denial-of-service attack,\n\n96\n00:04:31.850 --> 00:04:34.390\nit's typically an attack against\nthe system or a service for\n\n97\n00:04:34.390 --> 00:04:38.410\nthe purposes of shutting it down and\ncausing some kind of disruption.\n\n98\n00:04:38.410 --> 00:04:41.430\n&gt;&gt; Wes, I don't see this type of\nattack going anywhere anytime soon.\n\n99\n00:04:41.430 --> 00:04:43.477\nWhat was it, in October of 2016?\n\n100\n00:04:43.477 --> 00:04:48.939\nIt affected the entire East Coast,\nthe Internet backbone,\n\n101\n00:04:48.939 --> 00:04:52.700\nwhen they attacked the Dyn DNS provider.\n\n102\n00:04:52.700 --> 00:04:55.525\nSo by utilizing IoT in a botnet\nlike we spoke about previously,\n\n103\n00:04:55.525 --> 00:04:58.745\nthey were able to execute a distributed\ndenial-of-service attack.\n\n104\n00:04:58.745 --> 00:05:03.140\nAnd yeah, that's just kind of, I guess,\nwhat to expect moving forward.\n\n105\n00:05:03.140 --> 00:05:03.969\n&gt;&gt; And speaking of which,\n\n106\n00:05:03.969 --> 00:05:06.800\nthat's another type of denial-of-service\nattack that we need to talk about.\n\n107\n00:05:06.800 --> 00:05:11.827\nSee, cuz when we talk about just\na direct DoS attack, right,\n\n108\n00:05:11.827 --> 00:05:17.670\nwe're talking typically one\nattacker to one end point, right?\n\n109\n00:05:17.670 --> 00:05:21.050\nBut if you're flooding\na network bandwidth, right?\n\n110\n00:05:21.050 --> 00:05:22.440\nWhat if the person on the other end or\n\n111\n00:05:22.440 --> 00:05:25.030\nthe entity on the other end\nhas a lot of bandwidth?\n\n112\n00:05:25.030 --> 00:05:28.320\nWell, my little computer here's\nnot really gonna do much to that.\n\n113\n00:05:28.320 --> 00:05:30.073\nI'm gonna have to get a little\nbit more crafty in my attack.\n\n114\n00:05:30.073 --> 00:05:33.604\nAnd that's where the distributed\ndenial-of-service attack comes in,\n\n115\n00:05:33.604 --> 00:05:35.870\nlike Ms. Cherokee mentions, right?\n\n116\n00:05:35.870 --> 00:05:39.360\nThe attack that happened in 2016, they\ndidn't realize that there was a lot of\n\n117\n00:05:39.360 --> 00:05:42.970\nsecurity vulnerabilities in the Internet\nof things devices that were out there.\n\n118\n00:05:42.970 --> 00:05:48.170\nAnd a series of attackers found\nthis exploit and essentially,\n\n119\n00:05:49.190 --> 00:05:54.500\nbasically combined a whole bunch of IoT\ndevices to attack our DNS servers, right?\n\n120\n00:05:54.500 --> 00:05:56.539\nThe Dyn DNS servers, and\nit caused a disruption.\n\n121\n00:05:56.539 --> 00:05:59.100\nI got a little diagram here.\n\n122\n00:05:59.100 --> 00:06:03.980\nUsually, when you have a distributed\ndenial-of-service attack, a lot of times,\n\n123\n00:06:03.980 --> 00:06:04.890\nit's a botnet, right?\n\n124\n00:06:04.890 --> 00:06:10.060\nWhere you have a hacker that distributes\nthrough a trojan, through an attachment\n\n125\n00:06:10.060 --> 00:06:14.260\nof some sort, this drone software,\nthis zombie software, if you will.\n\n126\n00:06:14.260 --> 00:06:16.984\nAnd what it does is it gets in,\nand it could sit idly.\n\n127\n00:06:16.984 --> 00:06:21.040\nIt could be almost like a logic bomb\nwhere it just sits there, and it waits.\n\n128\n00:06:21.040 --> 00:06:28.290\nBut what it allows, it allows the attacker\nto issue a control and command command.\n\n129\n00:06:28.290 --> 00:06:29.880\nI know that's a little redundant.\n\n130\n00:06:29.880 --> 00:06:33.944\nAnd then what happens is all of\nthe infected targets in the botnet, right?\n\n131\n00:06:33.944 --> 00:06:37.820\nThey're drones, they're zombies,\nthey're gonna respond to that command.\n\n132\n00:06:37.820 --> 00:06:41.130\nAnd their gonna attack a single target,\nright?\n\n133\n00:06:41.130 --> 00:06:43.342\nSo denial-of-service attacks,\n\n134\n00:06:43.342 --> 00:06:47.322\nit's usually a single attacker\nagainst a single end point.\n\n135\n00:06:47.322 --> 00:06:50.950\nDistributed denial-of-service attacks\nis more of a collaborative effort.\n\n136\n00:06:50.950 --> 00:06:54.983\nWhether it's unintentional or\nunknown to the victims that are partaking,\n\n137\n00:06:54.983 --> 00:06:56.503\nif you will, in the botnet.\n\n138\n00:06:56.503 --> 00:07:01.298\nIt could be one of these where it's a\ndistributed denial-of-service attack, and\n\n139\n00:07:01.298 --> 00:07:02.980\nit's coordinated.\n\n140\n00:07:02.980 --> 00:07:06.960\nWhich means now the individual\ncomputers could have a mix\n\n141\n00:07:06.960 --> 00:07:09.450\nof some that are remotely exploited.\n\n142\n00:07:09.450 --> 00:07:12.270\nOr it could be a series of computers that\n\n143\n00:07:12.270 --> 00:07:15.960\nthe hackers have kinda clustered\ntogether in order to perform\n\n144\n00:07:15.960 --> 00:07:20.360\nwhatever denial-of-service attack\nthey are on the backside here.\n\n145\n00:07:20.360 --> 00:07:23.620\nSo those are things that you\ndefinitely have to worry about,\n\n146\n00:07:23.620 --> 00:07:25.220\nthe distributed denial-of-service attacks.\n\n147\n00:07:25.220 --> 00:07:27.770\nThey also have amplified attacks, too.\n\n148\n00:07:27.770 --> 00:07:30.530\nAn amplified attack is typically when\nyou're doing a denial-of-service,\n\n149\n00:07:30.530 --> 00:07:34.705\nlet's say, with the old ping\ndenial-of-service, right, ping of death.\n\n150\n00:07:36.380 --> 00:07:37.904\nPing packets,\nthey don't have a lot of data in them.\n\n151\n00:07:37.904 --> 00:07:41.440\nI think it's 32 bytes by default or\nsomewhere around there.\n\n152\n00:07:41.440 --> 00:07:46.570\nBut what happens if I bump up\nthe size of the payload, right?\n\n153\n00:07:46.570 --> 00:07:49.900\nIf I bump up the size of the payload,\nand I hand that off to a server, and\n\n154\n00:07:49.900 --> 00:07:52.980\nwe do that multiple times,\nnow we've amplified the attack.\n\n155\n00:07:52.980 --> 00:07:56.215\nSo keep in mind that an amplification\nattack is just when you increase\n\n156\n00:07:56.215 --> 00:07:56.895\nthe payload.\n\n157\n00:07:56.895 --> 00:08:03.362\nAnd you can send more data than\nis expected at the end point.\n\n158\n00:08:03.362 --> 00:08:05.552\nAll right, so that's a little\nbit about denial of service and\n\n159\n00:08:05.552 --> 00:08:07.740\ndistributed denial of service attacks.\n\n160\n00:08:07.740 --> 00:08:12.330\nKeep in mind you do need to protect\nagainst them, and like Cherokee said, as\n\n161\n00:08:12.330 --> 00:08:17.190\nrecently as 2016, it's 2017 now, we've had\nsome pretty big denial service attacks.\n\n162\n00:08:17.190 --> 00:08:20.180\nSo this isn't something\nthat's often some strange,\n\n163\n00:08:20.180 --> 00:08:24.170\nmystical voodoo land that we only\nthink theoretically talk about.\n\n164\n00:08:24.170 --> 00:08:26.890\nThis is something that you need to be\naware of in the real world today because\n\n165\n00:08:26.890 --> 00:08:28.520\nit does happen.\n\n166\n00:08:28.520 --> 00:08:31.650\nAll right, so, let's see what are some of\nthe other attacks that they talk about.\n\n167\n00:08:31.650 --> 00:08:34.680\nThe next one that they talk about\nis the man-in-the-middle attack.\n\n168\n00:08:34.680 --> 00:08:37.020\nNow the man-in-the-middle\nattack really can happen.\n\n169\n00:08:38.290 --> 00:08:41.802\nIt's really just an attacker\nin between a source and\n\n170\n00:08:41.802 --> 00:08:44.107\nthe destination that are communicating,\nright?\n\n171\n00:08:44.107 --> 00:08:48.087\nNow what they use the man-in-the-middle\nof attack for, it can usually springboard\n\n172\n00:08:48.087 --> 00:08:52.000\ninto other types of attacks like, we'll\ntalk about session hijacking and stuff.\n\n173\n00:08:52.000 --> 00:08:56.780\nBut basically, the attacker,\nunbeknownst to the endpoint,\n\n174\n00:08:56.780 --> 00:08:58.330\nsits in between the communication.\n\n175\n00:08:58.330 --> 00:09:00.770\nIt can do things like\nstart capturing your data.\n\n176\n00:09:00.770 --> 00:09:03.870\nIt can really just be nothing more\nthan like an eavesdropping attack,\n\n177\n00:09:03.870 --> 00:09:06.760\nwhere we just wanna see the information\nthat's on your network and nothing more.\n\n178\n00:09:06.760 --> 00:09:09.520\nBut a lot of times it's not that benign.\n\n179\n00:09:09.520 --> 00:09:11.980\nIt's not just about\nseeing your information.\n\n180\n00:09:11.980 --> 00:09:15.760\nIt's about storing your information, or\nmanipulation of your data, if you will, or\n\n181\n00:09:15.760 --> 00:09:17.560\neven redirecting communications.\n\n182\n00:09:17.560 --> 00:09:25.440\nAnd again, the endpoints that are in\nthe non-malicious communications,\n\n183\n00:09:25.440 --> 00:09:27.822\nthey're not aware that this is happening.\n\n184\n00:09:27.822 --> 00:09:30.959\nSo man-in-the-middle attacks, you\ndefinitely have to worry about as well,\n\n185\n00:09:30.959 --> 00:09:31.519\nkeep in mind.\n\n186\n00:09:31.519 --> 00:09:33.040\n&gt;&gt; You see that guy\nstealing your cookie there.\n\n187\n00:09:33.040 --> 00:09:34.760\n&gt;&gt; That's right,\nstealing my session cookie.\n\n188\n00:09:34.760 --> 00:09:35.680\nThat's right.\n\n189\n00:09:35.680 --> 00:09:39.640\nAnd again, it's gonna springboard into\nthis type of attack that we'll talk about\n\n190\n00:09:39.640 --> 00:09:41.699\ncoming up, known as session hijacking.\n\n191\n00:09:43.060 --> 00:09:46.520\nAll right, so, next one that they have in\nthe list that we're gonna talk about is\n\n192\n00:09:46.520 --> 00:09:47.820\nbuffer overflow attacks.\n\n193\n00:09:47.820 --> 00:09:51.980\nNow, with a buffer overflow attack,\nlet's understand things like ICMP,\n\n194\n00:09:51.980 --> 00:09:54.262\nthe Internet Control Message Protocol.\n\n195\n00:09:54.262 --> 00:09:58.240\nIt's not this bad protocol that\nwe have to worry about, right?\n\n196\n00:09:58.240 --> 00:10:01.000\nIt is constantly helping us\n\n197\n00:10:01.000 --> 00:10:03.902\ndo things like flow control\nwith the communications, right?\n\n198\n00:10:03.902 --> 00:10:08.014\nICMP, Internet Control Message Protocol,\nwhen you're sending information to an end\n\n199\n00:10:08.014 --> 00:10:11.810\npoint and the network adapter\nstarts to get about 75% full,\n\n200\n00:10:11.810 --> 00:10:17.170\nwhat happens is ICMP calls back to\nthe source and says hold on, slow down,\n\n201\n00:10:17.170 --> 00:10:20.670\nslow down,\nyou're sending information too fast.\n\n202\n00:10:20.670 --> 00:10:22.530\nAnd if you send this in for\nany more information,\n\n203\n00:10:22.530 --> 00:10:25.070\nI'm gonna start dropping it, right?\n\n204\n00:10:25.070 --> 00:10:27.500\nWell, that's the normal operation.\n\n205\n00:10:27.500 --> 00:10:31.674\nIn an attack though, the attacker\ndoesn't care about the ICMP messages.\n\n206\n00:10:31.674 --> 00:10:34.863\nAnd actually, that might actually give him\na little bit of information saying, hey,\n\n207\n00:10:34.863 --> 00:10:36.715\nI'm already 75% buffer failed here.\n\n208\n00:10:36.715 --> 00:10:38.255\nI only got about 25% more.\n\n209\n00:10:38.255 --> 00:10:39.085\n&gt;&gt; I'm reaching my goal.\n\n210\n00:10:39.085 --> 00:10:40.108\n&gt;&gt; That's right.\nWe're getting close to it.\n\n211\n00:10:40.108 --> 00:10:40.635\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n212\n00:10:40.635 --> 00:10:44.655\nnow I can start accomplishing the goal\nwhich is things like, for instance,\n\n213\n00:10:44.655 --> 00:10:46.375\nyou have memory.\n\n214\n00:10:46.375 --> 00:10:51.050\nIn your memory stack, you have different\nlocations that are reserved for\n\n215\n00:10:51.050 --> 00:10:54.870\nthe programs and the applications\nthat are working, that are using it.\n\n216\n00:10:54.870 --> 00:10:59.320\nThe problem is, when the buffer gets full,\nit can spill over into\n\n217\n00:10:59.320 --> 00:11:03.570\nthose locations that are maybe being\nused by other computers, right?\n\n218\n00:11:03.570 --> 00:11:07.070\nAnd now that we've got that rogue code,\nif you will,\n\n219\n00:11:07.070 --> 00:11:10.800\nthat malicious code,\nin an unchecked portion of the buffer,\n\n220\n00:11:10.800 --> 00:11:13.690\nit can do things like crash\nthe application, right?\n\n221\n00:11:13.690 --> 00:11:16.270\nIt can crash the entire operating system.\n\n222\n00:11:16.270 --> 00:11:20.642\nIt can override existing data that's\nall ready in that memory block,\n\n223\n00:11:20.642 --> 00:11:23.843\ncausing another application\nto corrupt its data.\n\n224\n00:11:23.843 --> 00:11:29.501\nAnd even worse, if I've got a place in the\nmemory of a system that I can store code,\n\n225\n00:11:29.501 --> 00:11:31.880\nwe can also execute that code too.\n\n226\n00:11:31.880 --> 00:11:36.200\nSo keep in mind that an overflow attack,\nspecifically a buffer overflow attack,\n\n227\n00:11:36.200 --> 00:11:41.610\nis that we fill the checked portion\nof memory, and then what happens is,\n\n228\n00:11:41.610 --> 00:11:44.860\nwe keep trying to send information\nin that same location in memory and\n\n229\n00:11:44.860 --> 00:11:48.300\nit spills over into\nan unchecked portion of memory.\n\n230\n00:11:48.300 --> 00:11:52.479\nAnd then at that point, the attacker, it's\nreally whatever their intention is to go\n\n231\n00:11:52.479 --> 00:11:55.206\nfrom there,\nif it's just simply crashing the system,\n\n232\n00:11:55.206 --> 00:11:58.765\nif it's shutting an application down,\ndenial of service, by the way.\n\n233\n00:11:58.765 --> 00:12:02.466\nIf I can't get access to that operating\nsystem to use that application,\n\n234\n00:12:02.466 --> 00:12:05.950\nthen kind of in a way you almost\nhave a denial-of-service attack.\n\n235\n00:12:05.950 --> 00:12:11.000\nBut, again, this is more for\nthe concept of the buffer overflow attack.\n\n236\n00:12:11.000 --> 00:12:13.571\nKeep in mind,\nmore information in the buffer,\n\n237\n00:12:13.571 --> 00:12:17.108\nthen it can contain spills over\nto unchecked portions of memory,\n\n238\n00:12:17.108 --> 00:12:20.674\ngiving the attacker the ability\nto maybe even execute that code.\n\n239\n00:12:20.674 --> 00:12:21.450\n&gt;&gt; Sounds good.\n\n240\n00:12:21.450 --> 00:12:26.115\nAnd, Wes, you said sometimes it may even\nlead to a type of denial of service.\n\n241\n00:12:26.115 --> 00:12:29.985\nAnd just keep in mind, I know I mentioned\nit before, but keep an open mind when\n\n242\n00:12:29.985 --> 00:12:33.266\nyou're thinking about these\ndifferent types of attacks because\n\n243\n00:12:33.266 --> 00:12:37.225\nsome of them may be kind of like hybrids\nor precursor to another type of attack.\n\n244\n00:12:37.225 --> 00:12:42.490\nSo, there aren't really any rules when\nit comes to criminals, are there?\n\n245\n00:12:42.490 --> 00:12:43.319\n&gt;&gt; And that's why they call it hacking,\nright?\n\n246\n00:12:43.319 --> 00:12:45.200\n&gt;&gt; [LAUGH]\n&gt;&gt; There aren't any rules.\n\n247\n00:12:45.200 --> 00:12:46.640\nWe're the ones that follow the rules.\n\n248\n00:12:46.640 --> 00:12:50.775\nAnd a lot of times here, the rules are the\nones that keep the honest people honest.\n\n249\n00:12:50.775 --> 00:12:51.465\nHow does that work?\n\n250\n00:12:51.465 --> 00:12:53.831\nBut that's usually what the rules do.\n\n251\n00:12:53.831 --> 00:12:57.235\nSo, you definitely keep that in mind, and\nthere are other types of overflow attacks.\n\n252\n00:12:57.235 --> 00:13:00.642\nThere's another one that we'll talk about\nin another episode called an integer\n\n253\n00:13:00.642 --> 00:13:02.354\noverflow, and we'll talk about that.\n\n254\n00:13:02.354 --> 00:13:06.080\nAnd sometimes these things\naren't done on purpose, right?\n\n255\n00:13:06.080 --> 00:13:09.190\nSometimes, it could be an application\nthat isn't acting right.\n\n256\n00:13:09.190 --> 00:13:13.250\nSo, from this standpoint of\ntalking about a malicious attack,\n\n257\n00:13:13.250 --> 00:13:14.860\nit could be a bug in the application too.\n\n258\n00:13:14.860 --> 00:13:19.769\nSo, that will be up to your\nsecurity team to find that out.\n\n259\n00:13:19.769 --> 00:13:25.260\nAll right, so a couple of other things\nthat we got here, this one's a great one.\n\n260\n00:13:25.260 --> 00:13:29.000\nI know you guys out there that are doing\nweb development probably love this one,\n\n261\n00:13:29.000 --> 00:13:29.893\njust kidding.\n\n262\n00:13:29.893 --> 00:13:33.149\nThis is the cross-site scripting attack.\n\n263\n00:13:33.149 --> 00:13:37.180\nIf you ever heard of it, you might've\neven seen an abbreviated XSS attack.\n\n264\n00:13:37.180 --> 00:13:38.819\nIf you do, just remember cross and\n\n265\n00:13:38.819 --> 00:13:41.711\nthen side scripting is what\nthey're abbreviating that to.\n\n266\n00:13:41.711 --> 00:13:45.479\n&gt;&gt; Good point because you don't\nwanna get that confused with CSS or\n\n267\n00:13:45.479 --> 00:13:49.280\nCascading Style Sheets because\nof the cross-site scripting.\n\n268\n00:13:49.280 --> 00:13:51.860\nIt starts with a C, but they do use\nthat X, so just be aware of that.\n\n269\n00:13:51.860 --> 00:13:53.004\n&gt;&gt; Most definitely, and again,\n\n270\n00:13:53.004 --> 00:13:55.556\nit's another one of those things\nwhere we just got so many acronyms.\n\n271\n00:13:55.556 --> 00:13:57.420\n&gt;&gt; [LAUGH]\n&gt;&gt; So what acronym are we talking\n\n272\n00:13:57.420 --> 00:13:58.100\nabout here?\n\n273\n00:13:58.100 --> 00:14:02.920\nSo, and I know in researching this,\nwhen I started back my first Security+\n\n274\n00:14:02.920 --> 00:14:07.740\ntraining that I went through, coming out\nand I see XSS, XSS, and I'm like, I'd\n\n275\n00:14:07.740 --> 00:14:10.665\nreally like somebody to just tell me what\nthis cross-site scripting's about now.\n\n276\n00:14:10.665 --> 00:14:12.560\n&gt;&gt; [LAUGH]\n&gt;&gt; Didn't know what the acronym is, so\n\n277\n00:14:12.560 --> 00:14:13.780\ndefinitely be aware of it.\n\n278\n00:14:13.780 --> 00:14:15.870\nNow, with a cross-site scripting attack,\n\n279\n00:14:15.870 --> 00:14:19.510\nwhat ends up happening is your clients,\nright?\n\n280\n00:14:19.510 --> 00:14:22.475\nLet's think of just\na basic web application.\n\n281\n00:14:22.475 --> 00:14:25.397\nAnd you have a client browser,\nyour web browser,\n\n282\n00:14:25.397 --> 00:14:27.900\nand it needs to connect to a web server.\n\n283\n00:14:27.900 --> 00:14:30.990\nWell, when it connects to the web server,\nwhat's going on?\n\n284\n00:14:30.990 --> 00:14:36.140\nRemember, we're using HTTP, Hypertext\nTransfer Protocol, and it is delivering\n\n285\n00:14:36.140 --> 00:14:39.477\nthe HTML down to the browser, that's\nthen rendered and you see the web page.\n\n286\n00:14:40.520 --> 00:14:44.680\nBut, what happens if there's malicious\ncode somewhere on that web page that's\n\n287\n00:14:44.680 --> 00:14:49.790\nbeen embedded, and again,\nnot known to the trusted website?\n\n288\n00:14:49.790 --> 00:14:52.460\nI'm not talking a malicious\nwebsite here too.\n\n289\n00:14:52.460 --> 00:14:53.850\nTalking about one that you trust.\n\n290\n00:14:53.850 --> 00:14:55.800\nYou know it's a good website, right?\n\n291\n00:14:55.800 --> 00:15:00.630\nBut, somewhere on that web page, there's\nbeen a malicious user that's come along,\n\n292\n00:15:00.630 --> 00:15:02.290\nand they've embedded a script.\n\n293\n00:15:02.290 --> 00:15:08.160\nAnd when you view that web page, well,\nit's still gonna give you back the HTML.\n\n294\n00:15:08.160 --> 00:15:11.260\nBut it's also gonna give you the little\nportion of that malicious script\n\n295\n00:15:11.260 --> 00:15:15.250\nthat was embedded in it too, and\nit could cause some kind of attack.\n\n296\n00:15:15.250 --> 00:15:19.901\nSo, I got a little diagram here to just\nkeep in mind that you have an attacker,\n\n297\n00:15:19.901 --> 00:15:23.060\nembeds this code into the web server,\nright?\n\n298\n00:15:23.060 --> 00:15:29.110\nAnd these two unknowing users connect to\nthe website, and then what's delivered\n\n299\n00:15:29.110 --> 00:15:34.650\nback is the malicious code as part of\nthe HTML that renders the web page.\n\n300\n00:15:34.650 --> 00:15:35.370\nSee, the thing is,\n\n301\n00:15:35.370 --> 00:15:38.590\nwhen we see the web page,\nwe don't see the code beneath, right?\n\n302\n00:15:38.590 --> 00:15:41.350\nSo, it's transparent\nto us as the end user.\n\n303\n00:15:41.350 --> 00:15:44.765\nNow, if it happened to be a web\napplication designer, they would\n\n304\n00:15:44.765 --> 00:15:48.819\nmost likely be able to look and find out\nin the code what they're looking for.\n\n305\n00:15:48.819 --> 00:15:51.815\nBut, again,\nyour end users aren't gonna be doing that.\n\n306\n00:15:51.815 --> 00:15:55.840\nWell, if you think about it, you're just\ndoing average web page browsing, right?\n\n307\n00:15:55.840 --> 00:15:58.454\nYou're not paying\nattention to any code and\n\n308\n00:15:58.454 --> 00:16:02.490\nthat's one of the things that makes\nthis a very successful attack.\n\n309\n00:16:02.490 --> 00:16:06.420\nAnd it's something that web application\ndesigners, web designers, they really have\n\n310\n00:16:06.420 --> 00:16:10.730\nto put checks and balances in order\nto ensure that this doesn't happen.\n\n311\n00:16:11.840 --> 00:16:16.214\nNow on the other side of that we have\nwhat's known as the cross side, or\n\n312\n00:16:16.214 --> 00:16:19.192\nexcuse me,\nthe cross site request forge rate.\n\n313\n00:16:19.192 --> 00:16:22.172\nAn easy way to think about this one,\nall right,\n\n314\n00:16:22.172 --> 00:16:26.345\ncompared to the cross site scripting,\nthe cross site scripting,\n\n315\n00:16:26.345 --> 00:16:29.860\nthe malicious code is sent\nback to the clients, right?\n\n316\n00:16:29.860 --> 00:16:32.670\nAnd it's executed on their systems.\n\n317\n00:16:32.670 --> 00:16:36.970\nThe cross side request forgery is\na little bit different because now\n\n318\n00:16:36.970 --> 00:16:40.590\nwhat we have is a trusted web browser,\nright?\n\n319\n00:16:40.590 --> 00:16:44.750\nAny of the trusted web browsers, and what\nhappens is that a hacker or attacker if\n\n320\n00:16:44.750 --> 00:16:50.550\nyou will will exploit the trust that\nthe server has with that web browser.\n\n321\n00:16:50.550 --> 00:16:55.130\nAnd it ends up being with the code\nis sent from the Web Client\n\n322\n00:16:55.130 --> 00:17:00.000\nback to the Web Server itself and there\nis some kind of process at a execution,\n\n323\n00:17:00.000 --> 00:17:02.490\nlike some kind of automated execution.\n\n324\n00:17:02.490 --> 00:17:05.460\nAutomated process like for\ninstance doing electronic fund transfer,\n\n325\n00:17:06.810 --> 00:17:10.460\nstealing email addresses,\ncreating or deleting things, right?\n\n326\n00:17:10.460 --> 00:17:15.520\nSo this is where we're taking the trust\nthat the web server has in the browser and\n\n327\n00:17:15.520 --> 00:17:17.760\nsending malicious code back towards it.\n\n328\n00:17:17.760 --> 00:17:22.330\nAnd again, notice the acronym,\nor not the acronym.\n\n329\n00:17:22.330 --> 00:17:24.550\nIf I get that right.\n\n330\n00:17:24.550 --> 00:17:27.156\nThe XSRF.\n\n331\n00:17:27.156 --> 00:17:28.281\nI'm not gonna try that too many times.\n\n332\n00:17:28.281 --> 00:17:29.541\nI'll probably get that one wrong.\n\n333\n00:17:29.541 --> 00:17:32.990\n&gt;&gt; No, and it's kinda funny because\neven in different contexts, For like,\n\n334\n00:17:32.990 --> 00:17:34.860\nextended for PCI and things like that.\n\n335\n00:17:34.860 --> 00:17:37.800\nThey use it for EX so go figure you know?\n\n336\n00:17:37.800 --> 00:17:38.512\nJust something else to think about.\n\n337\n00:17:38.512 --> 00:17:43.527\n&gt;&gt; Yeah, so, and if you see that again\nguys, just understand out there guys and\n\n338\n00:17:43.527 --> 00:17:47.220\ngals, that that is the cross\nsite request forgery.\n\n339\n00:17:47.220 --> 00:17:50.970\nSo a couple of different ones,\njust kind of as a real quick recap,\n\n340\n00:17:50.970 --> 00:17:55.710\nremember with the cross site scripting\nthe script execution is being sent back\n\n341\n00:17:55.710 --> 00:17:57.800\nto the web browsers of the victims.\n\n342\n00:17:57.800 --> 00:18:01.488\nWhen it comes to the Cross Site\nRequest Forgery it's the web\n\n343\n00:18:01.488 --> 00:18:04.071\nbrowser itself that is being infected and\n\n344\n00:18:04.071 --> 00:18:08.297\nsending back some kind of code to\nbe executed on the website itself.\n\n345\n00:18:08.297 --> 00:18:11.250\nAnd it's usually through\nan automated process.\n\n346\n00:18:12.290 --> 00:18:17.330\nFormed, again, something like electronic\nfund transfers, or deleting data,\n\n347\n00:18:17.330 --> 00:18:20.690\nor stealing email addresses so\nthey could launch spamming attacks.\n\n348\n00:18:20.690 --> 00:18:25.620\nAgain, whatever the intent\nis of the hacker.\n\n349\n00:18:26.920 --> 00:18:28.150\nOther things that they call out.\n\n350\n00:18:28.150 --> 00:18:32.170\nThey call out something known as\na Privilege Escalation Attack, all right?\n\n351\n00:18:32.170 --> 00:18:35.440\nPrivilege Escalation Attack, we've talked\nabout things like Root Kits, right?\n\n352\n00:18:35.440 --> 00:18:38.470\nWhen what is it that makes\na Root Kit successful?\n\n353\n00:18:38.470 --> 00:18:42.900\nIt's the fact that it tries to\nget that root access, right?\n\n354\n00:18:42.900 --> 00:18:44.333\nIt goes back from the days of Unix, right?\n\n355\n00:18:44.333 --> 00:18:48.060\nWhere it's a root user is\nlike a Windows Administrator.\n\n356\n00:18:48.060 --> 00:18:53.110\nWell, a privilege escalation attack is\nwhere the attack is trying to get those\n\n357\n00:18:53.110 --> 00:18:59.170\nsuper user, the root user access, or\nthe Windows administrator level access.\n\n358\n00:18:59.170 --> 00:19:00.550\nAgain, like a root kit does, right?\n\n359\n00:19:00.550 --> 00:19:03.240\nA root kit goes in there and\nit has the same context and\n\n360\n00:19:03.240 --> 00:19:05.400\nprivilege levels of the kernel right?\n\n361\n00:19:05.400 --> 00:19:09.650\nAnd the kernels got the highest\nlevel privileges that there is.\n\n362\n00:19:09.650 --> 00:19:14.600\nSo if I can get things like kernel mode\naccess, I can start making modifications,\n\n363\n00:19:14.600 --> 00:19:17.570\nI can start interacting\nwith system drivers, right?\n\n364\n00:19:17.570 --> 00:19:19.150\nWe can start putting things\nlike hooks in place.\n\n365\n00:19:19.150 --> 00:19:21.532\nWhere if an antivirus\nsoftware gets in there and\n\n366\n00:19:21.532 --> 00:19:24.983\ntries to take that code out well\nwe say yeah that code's taken out,\n\n367\n00:19:24.983 --> 00:19:27.740\nwe tell it whatever we want and\nthe code is still there.\n\n368\n00:19:27.740 --> 00:19:32.370\nSo, privilege escalation attack is where\nyou're basically the attack just seeks to\n\n369\n00:19:32.370 --> 00:19:37.470\nget the administrative level of the super\nuser or root user access Into a system so\n\n370\n00:19:37.470 --> 00:19:41.940\nthat they can perform various\ntasks at that privilege level.\n\n371\n00:19:43.310 --> 00:19:45.947\nAll right, so\nthat's one thing that we've got.\n\n372\n00:19:45.947 --> 00:19:49.120\nA couple of other things\nthat we are looking at.\n\n373\n00:19:49.120 --> 00:19:54.470\nThey also call out something known\nas ARP poisoning and ARP spoofing.\n\n374\n00:19:54.470 --> 00:19:56.180\nAll right,\nwhen we talk about a spoofing attack,\n\n375\n00:19:56.180 --> 00:19:58.400\nlet's just make it a little\nbit more generic, right?\n\n376\n00:19:58.400 --> 00:20:01.616\nWe're impersonating somebody or\nsomething else.\n\n377\n00:20:01.616 --> 00:20:04.871\nRight ,an entity, doesn't matter if\nyou are talking about IP spoofing or\n\n378\n00:20:04.871 --> 00:20:06.586\nif you are talking about ARP spoofing.\n\n379\n00:20:06.586 --> 00:20:10.888\nRight what we are talking about is\na different layer of the OSI model.\n\n380\n00:20:10.888 --> 00:20:15.838\nRight, in ARP spoofing it's the MAC\naddress that we are trying to masquerade\n\n381\n00:20:15.838 --> 00:20:20.830\nas our own so that for\nthe purpose of redirecting information.\n\n382\n00:20:20.830 --> 00:20:22.250\nWe talk about IP spoofing,\n\n383\n00:20:22.250 --> 00:20:25.480\nnow we're talking about layer three\nspoofing address spoofing, right.\n\n384\n00:20:25.480 --> 00:20:29.068\nAnd that logical address that we\napply to our machines to be able to\n\n385\n00:20:29.068 --> 00:20:33.195\ncommunicate on a TCP/IP network is\nthe one that's going to be exploited.\n\n386\n00:20:33.195 --> 00:20:33.940\n&gt;&gt; Usually it is conceal identity.\n\n387\n00:20:33.940 --> 00:20:37.239\n&gt;&gt; That's right, yeah for the purposes of\nnot even knowing that you're there, right?\n\n388\n00:20:37.239 --> 00:20:41.170\nVersus something like impersonation when\nwe were talking about social engineering.\n\n389\n00:20:41.170 --> 00:20:45.410\nImpersonation, I make no attempt to\ntry to hide the fact that I'm there.\n\n390\n00:20:45.410 --> 00:20:48.580\nYou can hear my voice and\nin some cases maybe even see me.\n\n391\n00:20:48.580 --> 00:20:51.750\nBut I'm not trying to conceal\nthat the fact that I'm there.\n\n392\n00:20:51.750 --> 00:20:55.440\n&gt;&gt; I might look like a service\ntechnician or delivery courier.\n\n393\n00:20:55.440 --> 00:20:58.140\n&gt;&gt; Most definitely the UPS person\nthat fumbles the box on the way in to\n\n394\n00:20:58.140 --> 00:21:00.740\nthe building and\nsomebody you know human nature says, here,\n\n395\n00:21:00.740 --> 00:21:01.760\nlet me help you out, now you're in.\n\n396\n00:21:01.760 --> 00:21:03.520\nBut you can see that person, right?\n\n397\n00:21:03.520 --> 00:21:04.390\nWith spoofing though,\n\n398\n00:21:04.390 --> 00:21:07.390\njust like Cherokee said, we're trying to\nconceal the fact that we're even there.\n\n399\n00:21:07.390 --> 00:21:09.210\nAnd with ARP spoofing, right,\n\n400\n00:21:09.210 --> 00:21:12.510\nARP spoofing is usually what\nleads to an ARP poisoning attack.\n\n401\n00:21:12.510 --> 00:21:14.860\nIn fact I've got a little diagram here.\n\n402\n00:21:14.860 --> 00:21:18.913\nSo let's understand,\nwhat is going on with ARP, right?\n\n403\n00:21:18.913 --> 00:21:22.840\nProbably gotta step back a little bit and\nlook at the address resolution protocol.\n\n404\n00:21:22.840 --> 00:21:25.830\n&gt;&gt; You really do have to understand\nthe protocol before you can understand\n\n405\n00:21:25.830 --> 00:21:26.940\nhow this attack works.\n\n406\n00:21:26.940 --> 00:21:29.494\nSo if not,\nthen I'm sure you'll explain it, right?\n\n407\n00:21:29.494 --> 00:21:30.251\n&gt;&gt; Yeah [LAUGH] most definitely.\n&gt;&gt; [LAUGH]\n\n408\n00:21:30.251 --> 00:21:31.942\n&gt;&gt; So our right address resolution\n\n409\n00:21:31.942 --> 00:21:33.060\nprotocol, right?\n\n410\n00:21:33.060 --> 00:21:35.250\nIP, it's dumb.\n\n411\n00:21:35.250 --> 00:21:36.068\nAbsolutely dumb, right?\n\n412\n00:21:36.068 --> 00:21:37.780\nYou could say, well routers are smart.\n\n413\n00:21:37.780 --> 00:21:39.880\nNo, I'm talking about IP itself.\n\n414\n00:21:39.880 --> 00:21:43.860\nIt knows nothing about Mac addresses,\nit knows nothing about physical addresses.\n\n415\n00:21:43.860 --> 00:21:47.410\nAnd that's what we use to\ndeliver traffic on a LAN, right?\n\n416\n00:21:47.410 --> 00:21:48.240\nAnd what happens?\n\n417\n00:21:48.240 --> 00:21:51.350\nWell, the router delivers that\ninformation to the local layout.\n\n418\n00:21:51.350 --> 00:21:53.080\nIt says here, I've got an IP address.\n\n419\n00:21:53.080 --> 00:21:58.670\nI have no clue what the Mac address of the\nsystem that its intended destination is.\n\n420\n00:21:58.670 --> 00:22:02.020\nSo, it says ARP address resolution\nprotocol here's the IP address can you\n\n421\n00:22:02.020 --> 00:22:02.916\nhelp me out?\n\n422\n00:22:02.916 --> 00:22:06.277\nAnd what the ARP does,\nis ARP asks a broadcast,\n\n423\n00:22:06.277 --> 00:22:12.344\nto the local broadcast address says\nhey,who has 10.10.10.10,right.\n\n424\n00:22:12.344 --> 00:22:16.118\nNow all these other machines are listening\nout, but notice they have different\n\n425\n00:22:16.118 --> 00:22:19.330\nIP addresses and\nI kinda just put these ones in here right.\n\n426\n00:22:19.330 --> 00:22:24.017\nBut there is one on this network that\ndoes have that IP address, right?\n\n427\n00:22:24.017 --> 00:22:29.580\nSo, it sends back up an ARP response or\nan ARP reply message, right?\n\n428\n00:22:29.580 --> 00:22:33.150\nThe reply says yeah you can tell\n\n429\n00:22:33.150 --> 00:22:38.500\nthe router in this case that\n10.10.10.10 is at this Mac address.\n\n430\n00:22:38.500 --> 00:22:40.350\nAll right, now what happens?\n\n431\n00:22:40.350 --> 00:22:43.620\nThis computer finds that\ninformation out now.\n\n432\n00:22:43.620 --> 00:22:47.488\nAnd it uses a cash and the cashing systems\nthat we have here are no different in\n\n433\n00:22:47.488 --> 00:22:49.550\nconcept than any other cashing system.\n\n434\n00:22:49.550 --> 00:22:54.575\nIn the fact that if I asked Cherokee\na question I write it down the answer\n\n435\n00:22:54.575 --> 00:23:00.300\nthat she's giving me now It would probably\nnot be too, would be too efficient.\n\n436\n00:23:00.300 --> 00:23:01.210\nWe'll try better English here.\n\n437\n00:23:01.210 --> 00:23:03.127\nIt wouldn't be too efficient\nif I turn around and\n\n438\n00:23:03.127 --> 00:23:04.780\nask her the same question again, right?\n\n439\n00:23:04.780 --> 00:23:05.675\nShe'd answer it for me.\n\n440\n00:23:05.675 --> 00:23:06.534\n&gt;&gt; Look at your paper, Wes.\n\n441\n00:23:06.534 --> 00:23:07.335\n&gt;&gt; Right, exactly.\n\n442\n00:23:07.335 --> 00:23:10.750\nSo I can look at the answer locally and\nnot have to ask the question.\n\n443\n00:23:10.750 --> 00:23:13.770\nThat's the purpose of the ARP Cache,\nright?\n\n444\n00:23:13.770 --> 00:23:18.689\nNext time this computer needs to send\ninformation at 10.10.10.10 It doesn't have\n\n445\n00:23:18.689 --> 00:23:19.554\nto ask anymore.\n\n446\n00:23:19.554 --> 00:23:22.060\nIt says, okay,\nI've already asked that question.\n\n447\n00:23:22.060 --> 00:23:24.590\nWe'll be a little bit more efficient\nhere and I'll look at the cache.\n\n448\n00:23:24.590 --> 00:23:26.488\nAll right so,\nthat's the basic process of ARP.\n\n449\n00:23:26.488 --> 00:23:29.660\nNow, where does ARP poisoning,\nARP spoofing come in?\n\n450\n00:23:29.660 --> 00:23:31.970\nWell, ARP spoofing is very, very easy.\n\n451\n00:23:31.970 --> 00:23:36.710\nWe do it legally on a lot of, almost all\nthe time and people don't realize it.\n\n452\n00:23:36.710 --> 00:23:39.740\nIf you're using virtualization,\nyou're doing ARP spoofing.\n\n453\n00:23:39.740 --> 00:23:41.410\nThat's what it boils down to, right?\n\n454\n00:23:41.410 --> 00:23:43.172\nHow can you have 15\nmachines on a single host,\n\n455\n00:23:43.172 --> 00:23:44.905\nall using the same\nphysical network adapter?\n\n456\n00:23:44.905 --> 00:23:47.734\nBut you go into the properties\nof each virtual machine,\n\n457\n00:23:47.734 --> 00:23:49.791\nthey all have different Mac addresses.\n\n458\n00:23:49.791 --> 00:23:53.254\n&gt;&gt; But maliciously, if I erase\nthat information on your paper and\n\n459\n00:23:53.254 --> 00:23:57.124\nwrote down some falsified info,\nThat's what we're talking about.\n\n460\n00:23:57.124 --> 00:23:59.707\n&gt;&gt; And that's where we get absolutely,\n\n461\n00:23:59.707 --> 00:24:03.750\nthat's where you get the poisoning attack,\nabsolutely.\n\n462\n00:24:03.750 --> 00:24:09.130\nSo now let's go ahead and let's try\nthis a little bit differently, right.\n\n463\n00:24:09.130 --> 00:24:12.393\nCherokee's got her black hat on today and\nshe is, well that doesn't look like a,\n\n464\n00:24:12.393 --> 00:24:13.776\nthat doesn't look like a female.\n\n465\n00:24:13.776 --> 00:24:14.795\n&gt;&gt; A gray beanie.\n\n466\n00:24:14.795 --> 00:24:16.805\n&gt;&gt; That's right,\nyou got a gray beanie on today.\n\n467\n00:24:16.805 --> 00:24:20.595\nSo what happens is now imagine\nthe same process goes on, right?\n\n468\n00:24:20.595 --> 00:24:23.875\nARP calls out and says,\nwhere is this mac address?\n\n469\n00:24:23.875 --> 00:24:25.235\nI have no clue.\n\n470\n00:24:25.235 --> 00:24:30.336\nBut instead of the computer that\nhas that IP address responding,\n\n471\n00:24:30.336 --> 00:24:33.675\nthat hacker or attacker responds first and\n\n472\n00:24:33.675 --> 00:24:38.514\nsays, yeah, that IP address,\nit's at this MAC address.\n\n473\n00:24:38.514 --> 00:24:43.720\nAnd this Mac address is not the Mac\naddress of the legitimate computer.\n\n474\n00:24:43.720 --> 00:24:45.990\nIt's the MAC address of--\n&gt;&gt; My laptop.\n\n475\n00:24:45.990 --> 00:24:48.720\n&gt;&gt; Of Cherokee's laptop in this case.\n\n476\n00:24:48.720 --> 00:24:50.350\nSo what happens now?\n\n477\n00:24:50.350 --> 00:24:54.550\nMy computer responds the same way,\nsays okay, that's you?\n\n478\n00:24:54.550 --> 00:24:56.339\nAll right, well let me go ahead and\n\n479\n00:24:56.339 --> 00:24:58.938\nwe'll put that MAC address\ndown in the ARP cache.\n\n480\n00:24:58.938 --> 00:25:00.260\nNow here's the problem.\n\n481\n00:25:00.260 --> 00:25:01.410\nRemember how the cache works.\n\n482\n00:25:01.410 --> 00:25:02.160\nThis is the poison.\n\n483\n00:25:02.160 --> 00:25:06.130\nYou've poisoned the cache and the fact\nthat you've got misinformation, right?\n\n484\n00:25:06.130 --> 00:25:10.221\nThere's a MAC address in there,\nthat shouldn't be in there, and\n\n485\n00:25:10.221 --> 00:25:12.569\nreally isn't the true destination.\n\n486\n00:25:12.569 --> 00:25:16.438\nSo now my computer's no longer gonna call\nout with ARP cuz it's got the MAC address,\n\n487\n00:25:16.438 --> 00:25:18.710\nit's already resolved that.\n\n488\n00:25:18.710 --> 00:25:23.670\nBut what happens is, now Cherokee\ncan redirect the traffic to her, or\n\n489\n00:25:23.670 --> 00:25:28.390\nanywhere else for that matter, if\nthe hacker or attacker so chooses, right?\n\n490\n00:25:28.390 --> 00:25:32.410\nSo the ARP poisoning attack is\nbasically an ARP spoof, right,\n\n491\n00:25:32.410 --> 00:25:36.530\nspoofing the MAC address,\nmakes its way into the cache, and now\n\n492\n00:25:36.530 --> 00:25:40.790\ninstead of my computer going through the\nARP process, the legitimate ARP process,\n\n493\n00:25:40.790 --> 00:25:43.200\nI'm going to look at the cache\njust like we normally do.\n\n494\n00:25:43.200 --> 00:25:44.713\nBut it's got this information in there.\n\n495\n00:25:44.713 --> 00:25:49.319\nAnd now all of those communications\nthat are going to that IP address can be\n\n496\n00:25:49.319 --> 00:25:51.186\nredirected to the attacker.\n\n497\n00:25:51.186 --> 00:25:54.497\n&gt;&gt; And it's kind of funny we talked\nearlier about having a hybrid type\n\n498\n00:25:54.497 --> 00:25:55.094\nof attack.\n\n499\n00:25:55.094 --> 00:25:59.479\nSo if I didn't wanna allow that\nredirected traffic to make it to its\n\n500\n00:25:59.479 --> 00:26:00.890\nfinal destination,\n\n501\n00:26:00.890 --> 00:26:06.160\nI could put a false IP address in there\nthat would just halt that communication.\n\n502\n00:26:06.160 --> 00:26:10.369\nThus causing a type of denial of service\nattack, so there you go, two in one deal.\n\n503\n00:26:10.369 --> 00:26:11.290\n&gt;&gt; Most definitely,\n\n504\n00:26:11.290 --> 00:26:14.590\nI mean, quite literally you just\nput any kinda bogus information.\n\n505\n00:26:14.590 --> 00:26:16.470\nIt doesn't have to be a valid MAC address.\n\n506\n00:26:16.470 --> 00:26:18.014\nLike Cherokee said,\n\n507\n00:26:18.014 --> 00:26:23.589\nyou could say I'm gonna put\n00.11.22.33 all the way to the end and\n\n508\n00:26:23.589 --> 00:26:28.930\nthen again there's no MAC address on\nyour network that exists like that.\n\n509\n00:26:28.930 --> 00:26:33.790\nSo it basically goes into electrical\nlimbo and you now have denial of service.\n\n510\n00:26:33.790 --> 00:26:36.779\nBut that's not the only type of poisoning\nattack that we have to worry about.\n\n511\n00:26:36.779 --> 00:26:39.106\nThere are other ones out\nthere too that they call out.\n\n512\n00:26:39.106 --> 00:26:43.350\nOne of the ones that they call\nout is a DNS poisoning attack.\n\n513\n00:26:43.350 --> 00:26:47.430\nThis is one that, I wanna say that that\ndistributed denial of service attack that\n\n514\n00:26:47.430 --> 00:26:51.450\nyour were mentioning at first part of this\nepisode here was what was happening to\n\n515\n00:26:51.450 --> 00:26:54.518\ndying DNS is that there was some\npoisoning that was going on.\n\n516\n00:26:54.518 --> 00:26:58.718\nAnd it was basically shutting\ndown a good portion of\n\n517\n00:26:58.718 --> 00:27:04.650\nthe DNS Servers that we had on\nthe entire northeast, I wanna say.\n\n518\n00:27:04.650 --> 00:27:06.120\nAnd what happens here?\n\n519\n00:27:06.120 --> 00:27:10.367\nWell, let's go ahead and kinda look\nat just DNS in general all right?\n\n520\n00:27:10.367 --> 00:27:12.090\nRemember the domain name system.\n\n521\n00:27:12.090 --> 00:27:15.860\nThe domain name system is responsible for\ntaking user friendly names and\n\n522\n00:27:15.860 --> 00:27:20.184\nmapping them to IP addresses, so that I\ndon't have to remember potential of 4.3\n\n523\n00:27:20.184 --> 00:27:23.429\nbillion IP addresses out there\nacross the internet, right?\n\n524\n00:27:23.429 --> 00:27:27.550\nI don't know what Google's website\naddress is, IP address is right?\n\n525\n00:27:27.550 --> 00:27:32.860\nBut, because of DNS I can\ntype in www.google.com and\n\n526\n00:27:32.860 --> 00:27:37.250\nDNS, there's a lookup that happens, it\nfinds a record that's stored in a database\n\n527\n00:27:37.250 --> 00:27:40.610\nthat Google has the authority over,\nand it says yeah,\n\n528\n00:27:40.610 --> 00:27:44.710\nyou can find www.google.com\nat this IP address.\n\n529\n00:27:44.710 --> 00:27:46.630\nNow what happens if we get misinformation.\n\n530\n00:27:46.630 --> 00:27:50.950\nAnd fact, I got a little diagram here,\nif we could check that out.\n\n531\n00:27:50.950 --> 00:27:55.120\nSo normal lookups, right?\n\n532\n00:27:55.120 --> 00:27:58.094\nIf these series of users are looking for\n\n533\n00:27:58.094 --> 00:28:02.550\nthings like Google right Microsoft or\nFacebook.\n\n534\n00:28:02.550 --> 00:28:07.596\nThey might be using a recursive DNS server\nwhich says I'm just gonna go ahead and\n\n535\n00:28:07.596 --> 00:28:10.534\nask other people for\nthe answers that I need and\n\n536\n00:28:10.534 --> 00:28:15.298\nwhat I'll do is I'll store them locally\nin a DNS cache just like ARP right.\n\n537\n00:28:15.298 --> 00:28:17.872\nSo we're looking for\nGoogle, we're looking for\n\n538\n00:28:17.872 --> 00:28:21.426\nMicrosoft they're gonna go out to\nthe authoritative DNS servers and\n\n539\n00:28:21.426 --> 00:28:24.498\nthey're gonna find out what\nthose IP addresses are right.\n\n540\n00:28:24.498 --> 00:28:28.946\nThat's the normal process without\nanything going wrong nothing's\n\n541\n00:28:28.946 --> 00:28:30.488\ndelicious here right.\n\n542\n00:28:30.488 --> 00:28:35.624\nSo our Recursive DNS server is now\nhas in its resolver cache the IP\n\n543\n00:28:35.624 --> 00:28:40.400\naddresses for Google in this\ncase Microsoft and Facebook.\n\n544\n00:28:40.400 --> 00:28:45.230\nSo now the next time any of\nthese users look for or ask for\n\n545\n00:28:45.230 --> 00:28:48.486\nGoogle, Microsoft, or Facebook,\n\n546\n00:28:48.486 --> 00:28:54.740\nthe Recursive DNS Server can say\nI already have that in my cache.\n\n547\n00:28:54.740 --> 00:28:57.669\nYou can find that right here,\nand I look locally.\n\n548\n00:28:57.669 --> 00:29:01.570\nNow, imagine if an attacker,\na hacker, an attacker if you will.\n\n549\n00:29:01.570 --> 00:29:05.208\nI try not to use hacker, cuz it's not\nreally a bad term of hacker, but attacker.\n\n550\n00:29:05.208 --> 00:29:06.578\n&gt;&gt; You just have the skill set.\n\n551\n00:29:06.578 --> 00:29:08.650\n&gt;&gt; Right, exactly.\n\n552\n00:29:08.650 --> 00:29:13.030\nNow, what happens if the attacker or\nhacker,\n\n553\n00:29:13.030 --> 00:29:18.030\nif you will, gets some false\ninformation into the cache.\n\n554\n00:29:18.030 --> 00:29:19.871\nPoisons the cache, right.\n\n555\n00:29:19.871 --> 00:29:24.791\nThen what happens is,\nnow we've got a website,\n\n556\n00:29:24.791 --> 00:29:30.170\na name,\nthat maps to a legitimate IP address.\n\n557\n00:29:30.170 --> 00:29:35.078\nBut the thing is, or the other way around,\nit's gonna redirect you to the IP address,\n\n558\n00:29:35.078 --> 00:29:36.438\nand let me backup here.\n\n559\n00:29:36.438 --> 00:29:40.948\nIt's going to, basically,\nput an entry for a bogus IP address,\n\n560\n00:29:40.948 --> 00:29:42.970\nmake sure I say that right.\n\n561\n00:29:42.970 --> 00:29:45.300\nAnd now we can redirect\nyou anywhere we want.\n\n562\n00:29:45.300 --> 00:29:49.160\nInstead of you think you're going to\nMicrosoft or you're going to Google or\n\n563\n00:29:49.160 --> 00:29:51.839\nyou're going to Facebook-\n&gt;&gt; Somebody's poisoned the water hole.\n\n564\n00:29:51.839 --> 00:29:53.920\n&gt;&gt; [LAUGH]\n&gt;&gt; That's right, now all of a sudden,\n\n565\n00:29:53.920 --> 00:29:57.687\nyou're going to youjustgothacked or\nstolenidentity or bankscams.org,\n\n566\n00:29:57.687 --> 00:30:01.280\nall fake websites, and\nif they exist out there, I apologize.\n\n567\n00:30:01.280 --> 00:30:02.629\n&gt;&gt; You're apologizing to the attacker,\nWes.\n\n568\n00:30:02.629 --> 00:30:05.403\n&gt;&gt; Yeah, to the attacker, that's right.\n\n569\n00:30:05.403 --> 00:30:10.779\nSo keep in mind if we get bogus\ninformation into the DNS records, right?\n\n570\n00:30:10.779 --> 00:30:15.391\nAnd these names, www.google.com\nactually maps to the IP address of\n\n571\n00:30:15.391 --> 00:30:19.846\na Rogue Web Application Server,\nthen essentially what you've got\n\n572\n00:30:19.846 --> 00:30:23.300\nis a redirection and\nit might be a denial of service.\n\n573\n00:30:23.300 --> 00:30:27.270\nIt might be where they redirect you\nto a server that automatically starts\n\n574\n00:30:27.270 --> 00:30:29.290\nloading stuff into your computer.\n\n575\n00:30:29.290 --> 00:30:32.460\nEither way it's going to be a bad day.\n\n576\n00:30:32.460 --> 00:30:35.960\nSo that is a little bit\nabout DNS poisoning.\n\n577\n00:30:35.960 --> 00:30:39.850\nKeep in mind that just like our poisoning,\nwhat we're trying to do is get mis,\n\n578\n00:30:39.850 --> 00:30:44.740\nor malicious information, if you will,\nor incorrect information into the cache.\n\n579\n00:30:44.740 --> 00:30:45.843\nAnd it can cause problems, right?\n\n580\n00:30:45.843 --> 00:30:49.434\nThese are the services that we rely on\nin order to do communications within our\n\n581\n00:30:49.434 --> 00:30:49.940\nnetwork.\n\n582\n00:30:49.940 --> 00:30:54.080\nSo once the services are attacked,\nwho knows what goes on from there?\n\n583\n00:30:54.080 --> 00:30:56.250\nBut these are very,\nvery coordinated attacks.\n\n584\n00:30:56.250 --> 00:30:59.540\nAnd usually, the purpose is to redirect\nyou to whatever the websites are that\n\n585\n00:30:59.540 --> 00:31:00.500\nthey want you to go to.\n\n586\n00:31:01.790 --> 00:31:06.117\n&gt;&gt; Sounds good, I know we have some\nother information that we need to cover.\n\n587\n00:31:06.117 --> 00:31:08.790\nNext on the list, we have, what is that?\n\n588\n00:31:08.790 --> 00:31:09.997\nSo domain hijacking,\n\n589\n00:31:09.997 --> 00:31:13.692\nwhich sometimes is paired when\nwe're talking about DNS poisoning.\n\n590\n00:31:13.692 --> 00:31:17.261\nBecause it's so closely intertwined,\ndo we want to try to get that in, or\n\n591\n00:31:17.261 --> 00:31:19.750\nsave that for the next show Wes,\nwhat do you think?\n\n592\n00:31:19.750 --> 00:31:20.500\n&gt;&gt; I think we can go ahead.\n\n593\n00:31:20.500 --> 00:31:22.120\nWe'll take care of that one now, yeah.\n\n594\n00:31:22.120 --> 00:31:23.410\nWith domain hijacking,\n\n595\n00:31:23.410 --> 00:31:29.510\nthink about when you are going to\ntransfer your domain between registrars.\n\n596\n00:31:29.510 --> 00:31:32.620\nYou have the Internet\nregistrars out there, and\n\n597\n00:31:32.620 --> 00:31:36.170\nyou not just the internet registrars, but\nyou would have DNS registrars, right?\n\n598\n00:31:36.170 --> 00:31:38.816\nLike GoDaddy,\nthat's one of them I can think of,\n\n599\n00:31:38.816 --> 00:31:41.343\nI can't really think of\nsome of the other ones.\n\n600\n00:31:41.343 --> 00:31:44.774\nGoDaddy's one of the ones\nI know that I use them.\n\n601\n00:31:44.774 --> 00:31:47.701\nAmazon, Amazon's their\nown authority today.\n\n602\n00:31:47.701 --> 00:31:51.582\nWhen you are transferring if you will,\na domain from the original owner or\n\n603\n00:31:51.582 --> 00:31:55.413\npurchaser, you usually have to go\nthrough a process in order to do that.\n\n604\n00:31:55.413 --> 00:32:03.150\nHowever It can happen where they can do\nthings like a who is, DNS lookup, right?\n\n605\n00:32:03.150 --> 00:32:06.750\nThey can take public information and\nthey can find out things like\n\n606\n00:32:06.750 --> 00:32:11.620\nthe email address of whoever\nthe domain owner is, if you will.\n\n607\n00:32:11.620 --> 00:32:12.980\nAnd what happens is,\n\n608\n00:32:12.980 --> 00:32:18.470\nthey maliciously transfer the domain\nover to the malicious user.\n\n609\n00:32:18.470 --> 00:32:23.862\nAnd then what happens is it's very very\nhard to get that domain back, right?\n\n610\n00:32:23.862 --> 00:32:26.678\nYou might have a domain that\nyou're sitting on because,\n\n611\n00:32:26.678 --> 00:32:30.443\nI don't know if it's that popular today\nbut I know in the dot com boom it was.\n\n612\n00:32:30.443 --> 00:32:33.443\nWhere you would have a certain\ntype of domain name and\n\n613\n00:32:33.443 --> 00:32:36.180\nit could be very valuable and\npeople want them.\n\n614\n00:32:36.180 --> 00:32:38.177\n&gt;&gt; Like kardashian.com or\nsomething like that.\n\n615\n00:32:38.177 --> 00:32:40.092\n&gt;&gt; There we go.\nSo yeah something like that.\n\n616\n00:32:40.092 --> 00:32:41.787\nSo, and people would to sit on them and\ntry to make money.\n\n617\n00:32:41.787 --> 00:32:46.299\nThere's nothing wrong with this, but what\nwould happen is attackers know that and\n\n618\n00:32:46.299 --> 00:32:48.700\nthey know that that's a common name.\n\n619\n00:32:48.700 --> 00:32:49.820\nSo, what they want to go in and\n\n620\n00:32:49.820 --> 00:32:52.990\ndo is they want to go in and\nlook at the public information.\n\n621\n00:32:52.990 --> 00:32:55.300\nThey want to find out who\nthat's registered to, and\n\n622\n00:32:55.300 --> 00:33:00.640\nwhat they do Is they transfer it to\nthemselves right, or a group of people.\n\n623\n00:33:00.640 --> 00:33:04.920\nAnd the problem here is it's\nvery very hard to reserve.\n\n624\n00:33:04.920 --> 00:33:08.959\nI can, let me just throw out\na little a bureaucracy here.\n\n625\n00:33:08.959 --> 00:33:12.720\nICAN, the Internet corporation for\nassigned names and numbers.\n\n626\n00:33:12.720 --> 00:33:16.764\nThey actually have a registrar\ntransfer dispute resolution policy.\n\n627\n00:33:16.764 --> 00:33:20.817\nAnd it's something they can seek to\nhelp you return that domain back to\n\n628\n00:33:20.817 --> 00:33:22.060\nthe original owner.\n\n629\n00:33:22.060 --> 00:33:25.270\nBut a lot of times it's so\ndifficult that they just go undisputed.\n\n630\n00:33:25.270 --> 00:33:29.490\nAnd it causes people a lot of money,\ncan lose a lot of money.\n\n631\n00:33:29.490 --> 00:33:32.091\nCan ruin things like reputation,\nespecially if you're, for\n\n632\n00:33:32.091 --> 00:33:33.032\ninstance, a lawyer.\n\n633\n00:33:33.032 --> 00:33:36.290\nYou've got like some\nkind of lawyer firm and\n\n634\n00:33:36.290 --> 00:33:41.762\nit ends up re-directing you to\nsomething like online gambling, right?\n\n635\n00:33:41.762 --> 00:33:44.244\nThat can ruin people's reputation, so\n\n636\n00:33:44.244 --> 00:33:48.916\nwhen we talk about things like your\ndomain hijacking just understand that,\n\n637\n00:33:48.916 --> 00:33:53.233\nthat's where you have an owner,\na legitimate owner of a domain name.\n\n638\n00:33:53.233 --> 00:33:57.599\nAnd it gets maliciously transferred\nwithout the authorization of the owner of\n\n639\n00:33:57.599 --> 00:34:00.780\nthat domain to a completely\ndifferent register.\n\n640\n00:34:00.780 --> 00:34:05.805\nOnce that register now has it, it's often\nreally hard to dispute the fact and\n\n641\n00:34:05.805 --> 00:34:08.447\nreturn that back to the original owner.\n\n642\n00:34:08.447 --> 00:34:10.286\n&gt;&gt; Yeah and I think we'll go ahead and\n\n643\n00:34:10.286 --> 00:34:13.530\nsave the next couple of associated\ntopics for the next show.\n\n644\n00:34:13.530 --> 00:34:18.076\nWe'll start with maybe URL hijacking and\ntypo squatting, which are closely related.\n\n645\n00:34:18.076 --> 00:34:19.901\nBut Wes,\nyou really have covered a lot so far.\n\n646\n00:34:19.901 --> 00:34:23.840\nWe do have more to cover, so\nladies and gentlemen stay tuned.\n\n647\n00:34:23.840 --> 00:34:25.790\nFor this show,\nwe'll go ahead and sign off.\n\n648\n00:34:25.790 --> 00:34:27.410\nRemember, I'm your host, Cherokee Boose.\n\n649\n00:34:27.410 --> 00:34:30.050\n&gt;&gt; And I'm Wes Brian.\n&gt;&gt; See you next time here at ITPro.TV.\n\n650\n00:34:30.050 --> 00:34:37.832\n[MUSIC]\n\n651\n00:34:37.832 --> 00:34:40.184\n&gt;&gt; Thank you for watching ITPro.TV.\n\n",
          "vimeoId": "212751261"
        },
        {
          "description": "Wes and Cherokee continue to cover many different types of attack methods. They pick up from a Previous DNS poisoning conversation and segue into the topics of hijacking and associated techniques an attacker may use. Wes explains shimming, ,spoofing, and various 802.11 type attacks.",
          "length": "1857",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-3-types_of_attacks_pt3-040517-PGM.00_30_42_28.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-3-types_of_attacks_pt3-040517-PGM.00_30_42_28.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-3-types_of_attacks_pt3-040517-PGM.00_30_42_28.Still001-sm.jpg",
          "title": "Types of Attacks Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:04.177\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:04.177 --> 00:00:08.416\n[CROSSTALK]\n\n3\n00:00:08.416 --> 00:00:12.450\n&gt;&gt; You're watching ITPRO.TV.\n\n4\n00:00:12.450 --> 00:00:14.860\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n5\n00:00:14.860 --> 00:00:16.660\nI'm your show host Cherokee Boose.\n\n6\n00:00:16.660 --> 00:00:19.170\nWe've actually made it\nto part three this is\n\n7\n00:00:19.170 --> 00:00:23.410\nof course the third episode where we're\nspeaking about different types of attacks.\n\n8\n00:00:23.410 --> 00:00:25.560\nAnd again with us today we have Mr.\nWes Bryan.\n\n9\n00:00:25.560 --> 00:00:26.540\nThank you for joining us, Wes.\n\n10\n00:00:26.540 --> 00:00:27.760\n&gt;&gt; [LAUGH] Thanks for having me here.\n\n11\n00:00:27.760 --> 00:00:29.540\nYeah, we're working on\na small mini series here.\n\n12\n00:00:29.540 --> 00:00:31.630\n&gt;&gt; [LAUGH]\n&gt;&gt; Definitely a Stephen King novel if\n\n13\n00:00:31.630 --> 00:00:32.980\nwe don't wrap it up soon.\n\n14\n00:00:32.980 --> 00:00:33.590\nJust kidding!\n\n15\n00:00:33.590 --> 00:00:35.570\n&gt;&gt; Unfortunately, there are a lot of\ndifferent types of attacks out there.\n\n16\n00:00:35.570 --> 00:00:36.610\n&gt;&gt; That's right, there are.\n\n17\n00:00:36.610 --> 00:00:38.530\nAnd we have to talk\nabout every one of them.\n\n18\n00:00:38.530 --> 00:00:40.560\nAnd we certainly want you prepared for\nthe exam.\n\n19\n00:00:40.560 --> 00:00:43.500\nSo we are back, that's right,\nwith a part three.\n\n20\n00:00:43.500 --> 00:00:46.960\nAnd some of the things that we've\ntalked about in the past episodes.\n\n21\n00:00:46.960 --> 00:00:48.080\nWe talked about a lot, right?\n\n22\n00:00:48.080 --> 00:00:50.200\nWe talked about things like\ndenial of service attacks,\n\n23\n00:00:50.200 --> 00:00:53.800\nwe've talked about just all sorts\nof different types attacks.\n\n24\n00:00:53.800 --> 00:00:58.560\nCross site scripting, cross site\nforgery request type of attacks,\n\n25\n00:00:58.560 --> 00:01:00.480\nbuffer overflow, so\nall types of good things.\n\n26\n00:01:00.480 --> 00:01:04.020\nIf those don't sound familiar\nto you we also talked about,\n\n27\n00:01:04.020 --> 00:01:08.770\nin the first part, social engineering and\nthe principles of effectiveness for\n\n28\n00:01:08.770 --> 00:01:10.950\nsocial engineering,\nif I could say that right.\n\n29\n00:01:10.950 --> 00:01:15.350\nGo back and check those episodes out,\nthe parts to this episode if you will.\n\n30\n00:01:15.350 --> 00:01:18.990\nAnd then come back and\nsee us here because we left off\n\n31\n00:01:18.990 --> 00:01:24.290\nin the last episode we were talking\nabout domain hijacking, right?\n\n32\n00:01:24.290 --> 00:01:27.690\nAnd the fact that that is\nthe transference of a domain\n\n33\n00:01:27.690 --> 00:01:31.000\nname from one registrar to another,\nbut it's unauthorized.\n\n34\n00:01:31.000 --> 00:01:35.660\nThe process that it takes to undo that,\nto reverse that change,\n\n35\n00:01:35.660 --> 00:01:39.160\nit can be so daunting that a lot\nof times these will go undisputed.\n\n36\n00:01:39.160 --> 00:01:44.130\nUnless if it's a domain name that is\nreally making some people some money.\n\n37\n00:01:44.130 --> 00:01:50.490\nI do have an instance where I mentioned\na law firm, and that actually happened.\n\n38\n00:01:50.490 --> 00:01:54.420\nWhere www.mla.com, I believe,\nI have it written down somewhere.\n\n39\n00:01:55.730 --> 00:01:57.050\nWas law associates, right?\n\n40\n00:01:57.050 --> 00:02:02.670\nAnd it had been transferred illegally,\nunauthorized, to somebody else.\n\n41\n00:02:02.670 --> 00:02:06.775\nAnd it cost this man a lot\nof lot of money, in fact so\n\n42\n00:02:06.775 --> 00:02:10.055\nmuch that it didn't think that he\nwas gonna get the domain name back.\n\n43\n00:02:10.055 --> 00:02:12.915\nThat was a few years ago.\n\n44\n00:02:12.915 --> 00:02:17.872\nI'm happy to say that domain name has\nbeen returned to its original owner but\n\n45\n00:02:17.872 --> 00:02:20.284\nit cost him like $250,000.\n\n46\n00:02:20.284 --> 00:02:22.170\nSo, we're not talking\nabout chump change here.\n\n47\n00:02:22.170 --> 00:02:27.107\nWe're talking about the legalities and\nthe process to reverse that can be very,\n\n48\n00:02:27.107 --> 00:02:28.350\nvery complicated.\n\n49\n00:02:28.350 --> 00:02:33.636\nNow, the next, kind of along that\nlines of where domain names start\n\n50\n00:02:33.636 --> 00:02:39.795\nto come into play for us and people kind\nof play on, well Wes' ability to type.\n\n51\n00:02:39.795 --> 00:02:44.460\n[LAUGH] Is hijacks and\nrelated hijacking attacks.\n\n52\n00:02:44.460 --> 00:02:49.620\nThe first two that I wanna take care\nof are what known as typo squatting.\n\n53\n00:02:49.620 --> 00:02:54.330\nIt's a form of URL hijacking In which the,\nit basically relies on\n\n54\n00:02:54.330 --> 00:02:58.250\nanybody who is using the Internet's\nability to type, right, typos.\n\n55\n00:02:58.250 --> 00:03:02.440\nYou, you want to go to Facebook, right,\nand then instead spelling it Facebook,\n\n56\n00:03:02.440 --> 00:03:06.460\nyou spell it fce ebook.com, right?\n\n57\n00:03:06.460 --> 00:03:08.980\nAnd it takes you to another website,\nright?\n\n58\n00:03:08.980 --> 00:03:13.610\nSo that's what they do,\nGoogle with too many zeros in it, right?\n\n59\n00:03:13.610 --> 00:03:16.530\nGoogle with .net-\n&gt;&gt; Transposing any letters\n\n60\n00:03:16.530 --> 00:03:17.090\n&gt;&gt; Very good,\n\n61\n00:03:17.090 --> 00:03:21.450\nyeah exactly putting a three in there\nto throw a little leet in there but\n\n62\n00:03:21.450 --> 00:03:25.650\nthe port being is that you are taken\nto a website that is not the one that\n\n63\n00:03:25.650 --> 00:03:30.520\nyou intended to go to based on some kind\nof typo, hence the term typo squatting.\n\n64\n00:03:30.520 --> 00:03:32.040\nNow, Cherokee you were talking about,\n\n65\n00:03:32.040 --> 00:03:35.270\nwe were kind of talking about\nthis before we started.\n\n66\n00:03:35.270 --> 00:03:39.740\nYou have heard of a interesting\nURL type hijacking attack, right?\n\n67\n00:03:39.740 --> 00:03:42.280\n&gt;&gt; Yeah, so if I were to go ahead and\n\n68\n00:03:42.280 --> 00:03:45.480\nregister a domain with the registrar,\nlike you had mentioned before, Go Daddy.\n\n69\n00:03:45.480 --> 00:03:48.940\nA lot of these companies\nwill give you a trial\n\n70\n00:03:48.940 --> 00:03:52.930\nperiod before you actually commit and\ncomplete that registration process.\n\n71\n00:03:52.930 --> 00:03:58.050\nSo if an attacker is using\nthis time to squat per se.\n\n72\n00:03:58.050 --> 00:04:00.540\nThey haven't paid, they haven't fully\n\n73\n00:04:00.540 --> 00:04:04.380\ncomplied with whatever authentication\nrequirements that registrar has.\n\n74\n00:04:04.380 --> 00:04:07.860\nSo they can kind of get some free\nadvertising out of the deal and\n\n75\n00:04:07.860 --> 00:04:11.640\nredirect you to that great pharmaceutical\nwebsite, or whatever it is.\n\n76\n00:04:11.640 --> 00:04:15.930\nThey kind of like hop around, they're\nsquatting without paying, if you will.\n\n77\n00:04:15.930 --> 00:04:18.590\n&gt;&gt; The perfect place to do that would\nbe like on a Black Friday here in\n\n78\n00:04:18.590 --> 00:04:19.320\nthe states, right?\n\n79\n00:04:19.320 --> 00:04:22.040\nWhere there's a lot of people just\ngrabbing onto their wallets, and\n\n80\n00:04:22.040 --> 00:04:23.120\nthey're looking for the deals.\n\n81\n00:04:23.120 --> 00:04:26.130\nBoy, if I could get some free\nadvertisement out there that I got this\n\n82\n00:04:26.130 --> 00:04:29.810\ndeal that you just can't refuse,\nthen I can probably make some money.\n\n83\n00:04:29.810 --> 00:04:32.770\nAnd then in a couple of days,\nthe site is no longer in existence,\n\n84\n00:04:32.770 --> 00:04:33.700\na great example here.\n\n85\n00:04:33.700 --> 00:04:35.530\nThe other one that they call,\nis click jacking.\n\n86\n00:04:35.530 --> 00:04:36.690\nAnd click jacking is interesting,\n\n87\n00:04:36.690 --> 00:04:42.010\nbecause what that does,\nthis is I call it dirty pool, right.\n\n88\n00:04:42.010 --> 00:04:47.750\nWhat ends up happening is you have a link\nthat says hey sign me out or continue\n\n89\n00:04:47.750 --> 00:04:52.825\nshopping or something and they put a link\njust near it just under it, that's right.\n\n90\n00:04:52.825 --> 00:04:55.570\nWere go up and click that button and\n\n91\n00:04:55.570 --> 00:04:59.990\nthat wasn't the place that you intended to\ngo, or here's another one that they'll do.\n\n92\n00:04:59.990 --> 00:05:01.420\nThey'll have an image, right?\n\n93\n00:05:01.420 --> 00:05:03.740\nAnd the image you don't realize you\nwouldn't think it's clickable and\n\n94\n00:05:03.740 --> 00:05:05.180\nyou go up there and\nyou click on it, right?\n\n95\n00:05:05.180 --> 00:05:07.970\nAnd it takes you to a completely\ndifferent location on the web page or\n\n96\n00:05:07.970 --> 00:05:10.410\nmaybe even to a completely\ndifferent website.\n\n97\n00:05:10.410 --> 00:05:11.300\nThat's click jacking.\n\n98\n00:05:11.300 --> 00:05:14.069\nAgain, just hidden links that seem legit.\n\n99\n00:05:14.069 --> 00:05:15.898\nThey're clickable and\n\n100\n00:05:15.898 --> 00:05:21.050\nthey redirect the victim to some\nkind of unintended location.\n\n101\n00:05:21.050 --> 00:05:24.800\nThe other one that they call out\nis called session hijacking.\n\n102\n00:05:25.880 --> 00:05:29.990\nThis one is interesting because this\nrelies on a man in the middle attack.\n\n103\n00:05:29.990 --> 00:05:34.460\nWe had talked about the MITM attack,\nthe man in the middle attack as being-.\n\n104\n00:05:34.460 --> 00:05:36.065\n&gt;&gt; Not monkey in the middle.\n\n105\n00:05:36.065 --> 00:05:37.362\n[LAUGH]\n&gt;&gt; That's right, not monkey in the middle,\n\n106\n00:05:37.362 --> 00:05:38.380\n[LAUGH] definitely not.\n\n107\n00:05:38.380 --> 00:05:41.910\nSo remember we have a source and\ndestination in the communication.\n\n108\n00:05:41.910 --> 00:05:43.370\nThat's what we do in networks.\n\n109\n00:05:43.370 --> 00:05:46.130\nI'm gonna send communications\nto another endpoint.\n\n110\n00:05:46.130 --> 00:05:47.810\nAnd then we have the hacker\nthat stands in the middle,\n\n111\n00:05:47.810 --> 00:05:51.240\nand they're eavesdropping on the\ncommunication, maybe capturing the data.\n\n112\n00:05:51.240 --> 00:05:52.760\nIn this place what they're going to do is,\n\n113\n00:05:52.760 --> 00:05:56.170\nthey are probably going to capture\nthat information, all right.\n\n114\n00:05:56.170 --> 00:05:58.010\nIn fact, I have kind of a diagram here.\n\n115\n00:05:58.010 --> 00:06:01.475\nSo for instance, we've a web client,\nand it can be any of the web clients.\n\n116\n00:06:01.475 --> 00:06:03.959\nI'm not picking on any one in particular.\n\n117\n00:06:03.959 --> 00:06:05.164\nThat's why I've got a few of them here.\n\n118\n00:06:05.164 --> 00:06:06.560\nI couldn't find Safari.\n\n119\n00:06:06.560 --> 00:06:08.990\nThey're all, this could happen.\n\n120\n00:06:08.990 --> 00:06:13.790\nIt's not really about the web browser,\nmore sometimes it is about, for\n\n121\n00:06:13.790 --> 00:06:15.090\ninstance, stealing a session cookie.\n\n122\n00:06:15.090 --> 00:06:18.540\nSee, the session cookie,\nHTTP is stateless,\n\n123\n00:06:18.540 --> 00:06:21.020\nit doesn't remember anything, right?\n\n124\n00:06:21.020 --> 00:06:24.450\nIt's kind of like me, can't remember\nanything, can't remember yesterday.\n\n125\n00:06:24.450 --> 00:06:27.660\nSo, what ends up happening is when\nyou connect to a website, right?\n\n126\n00:06:27.660 --> 00:06:31.660\nIf you disconnect from that website and\nthen you connect back to it.\n\n127\n00:06:31.660 --> 00:06:34.460\nHTTP says, good to see you for\nthe first time.\n\n128\n00:06:34.460 --> 00:06:36.332\nThen you disconnect and you connect again.\n\n129\n00:06:36.332 --> 00:06:39.760\nHTTP says, good to see you for\nthe first time, right?\n\n130\n00:06:39.760 --> 00:06:41.350\nSo we use things like cookies.\n\n131\n00:06:41.350 --> 00:06:44.010\nCookies contain session\ninformation that says\n\n132\n00:06:44.010 --> 00:06:45.710\nthis is where you were on the web page.\n\n133\n00:06:45.710 --> 00:06:49.680\nThis is what your shopping cart looked at\nthe time, so that when I disconnect and\n\n134\n00:06:49.680 --> 00:06:53.540\nI reconnect, you ever reconnected to\na website and still been logged in,\n\n135\n00:06:53.540 --> 00:06:56.900\nmaybe still had some of those transactions\nthat you were doing that were pending.\n\n136\n00:06:56.900 --> 00:07:00.806\nWell, imagine if I was a hacker here and\nI got in the middle, the attacker,\n\n137\n00:07:00.806 --> 00:07:02.360\nthe man in the middle attack.\n\n138\n00:07:02.360 --> 00:07:05.420\nAnd I capture it and\nI store that information, right?\n\n139\n00:07:05.420 --> 00:07:09.210\nYou have an authenticated session that\nkeeps some of that information in that\n\n140\n00:07:09.210 --> 00:07:09.910\nsession cookie.\n\n141\n00:07:09.910 --> 00:07:13.810\nAnd if I can get that session cookie,\nthen essentially what I can do\n\n142\n00:07:13.810 --> 00:07:16.570\nis I can turn around, and\nI can replay it to the server.\n\n143\n00:07:16.570 --> 00:07:18.880\nNow it could be later,\nthat would be a replay attack.\n\n144\n00:07:18.880 --> 00:07:21.150\nIt could be during\nthe authenticated session.\n\n145\n00:07:21.150 --> 00:07:24.460\nAnd now, according to the web server,\nit doesn't know.\n\n146\n00:07:24.460 --> 00:07:25.910\nIt sees the session cookie.\n\n147\n00:07:25.910 --> 00:07:28.080\nI've got the cookie now as the attacker.\n\n148\n00:07:28.080 --> 00:07:30.170\nIt thinks that I am the victim.\n\n149\n00:07:30.170 --> 00:07:35.280\nAnd essentially we take the victim\ncompletely out of the communication and\n\n150\n00:07:35.280 --> 00:07:39.410\nthey can perform whatever type of attack\nthey want to from there, whether it\n\n151\n00:07:39.410 --> 00:07:44.340\nhappens to be a log in session with your\nbanking information, maybe something\n\n152\n00:07:44.340 --> 00:07:49.340\nlike a website that you go do e-commerce\nlike Amazon.com or something like that.\n\n153\n00:07:49.340 --> 00:07:51.780\nAnd now there's no real way for\n\n154\n00:07:51.780 --> 00:07:57.050\nthe server to tell that you,\nthe attacker are not the victim, right?\n\n155\n00:07:57.050 --> 00:07:58.330\nThere's just no way for them to tell.\n\n156\n00:07:58.330 --> 00:08:01.653\nSo that's a little bit\nabout session hijacking.\n\n157\n00:08:01.653 --> 00:08:06.410\nNow a couple of the other things that they\ncall out here to, I want to talk about,\n\n158\n00:08:06.410 --> 00:08:08.970\ndon't really have A diagram for this one.\n\n159\n00:08:08.970 --> 00:08:11.657\nThis one is a newer attack.\n\n160\n00:08:11.657 --> 00:08:15.020\nAnd this is where the man\nin the browser attack.\n\n161\n00:08:15.020 --> 00:08:19.090\nSee the man in the middle attack,\nsee we can see the communications.\n\n162\n00:08:19.090 --> 00:08:21.550\nWe can see what's going on\nas we eavesdrop on them,\n\n163\n00:08:21.550 --> 00:08:25.190\nbut the man in the browser is\nusually really isn't a person.\n\n164\n00:08:25.190 --> 00:08:26.840\nIt's not a human entity, if you will.\n\n165\n00:08:28.150 --> 00:08:31.100\nIt's a piece of code that attackers\nput into the browser, right.\n\n166\n00:08:31.100 --> 00:08:33.680\nSo that they can send it\nagainst the web server,\n\n167\n00:08:33.680 --> 00:08:36.240\nand they can listen in to information,\nif they need to.\n\n168\n00:08:36.240 --> 00:08:37.270\nIt's a little bit different,\n\n169\n00:08:37.270 --> 00:08:41.640\nit doesn't necessarily mean that there's\na human element actively in the session.\n\n170\n00:08:41.640 --> 00:08:45.580\nLike a man in the middle attack,\nmore as it is a piece of code.\n\n171\n00:08:45.580 --> 00:08:49.250\nThat's embedded, into the browser, and\nagain, hence the term man in the browser.\n\n172\n00:08:51.270 --> 00:08:54.170\nZero day,\nzero day is an interesting concept.\n\n173\n00:08:54.170 --> 00:08:56.998\nZero day is really about new threats,\nall right.\n\n174\n00:08:56.998 --> 00:08:59.380\nWhen we talk about zero day,\n\n175\n00:08:59.380 --> 00:09:02.270\nthis is when your computer systems\nare at their most vulnerable state.\n\n176\n00:09:02.270 --> 00:09:06.150\nThis is when an exploit is found,\nand nobody knows about it.\n\n177\n00:09:06.150 --> 00:09:12.170\nNobody, not your anti-virus companies\nright, your security solution.\n\n178\n00:09:12.170 --> 00:09:16.440\nNobody's aware of it, McAfee,\nTrend Microsystems, Symantec,\n\n179\n00:09:16.440 --> 00:09:17.310\nall the big guys right.\n\n180\n00:09:17.310 --> 00:09:20.430\nThey're not even aware that\nthis has happened all right.\n\n181\n00:09:20.430 --> 00:09:24.350\nThat's zero day, it means it's the first\ntime that this exploit has happened.\n\n182\n00:09:24.350 --> 00:09:27.850\nAnd because nobody knows it even\nexists nobody has a patch for it,\n\n183\n00:09:27.850 --> 00:09:29.410\nnobody has a fix for it.\n\n184\n00:09:29.410 --> 00:09:32.052\nThey say that sometimes,\nit can take up to eight months.\n\n185\n00:09:32.052 --> 00:09:33.650\n&gt;&gt; I know, it's ridiculous,\n\n186\n00:09:33.650 --> 00:09:36.788\nI think Symantec came out\nwith a ridiculous statistic.\n\n187\n00:09:36.788 --> 00:09:38.240\nIt's very misleading, the name.\n\n188\n00:09:38.240 --> 00:09:41.750\nIt can go unpatched for\na very long time, or even undiscovered.\n\n189\n00:09:41.750 --> 00:09:44.590\n&gt;&gt; Yes, and\nundiscovered was up to eight months.\n\n190\n00:09:44.590 --> 00:09:46.570\nThey said it could go to a year or\n\n191\n00:09:46.570 --> 00:09:51.268\neven more than a year before it's actually\n&gt;&gt; [CROSSTALK] 300 days before a solution\n\n192\n00:09:51.268 --> 00:09:53.819\nwas found, so-\n&gt;&gt; Yes, and that's scary if you think\n\n193\n00:09:53.819 --> 00:09:57.510\nabout it, because the fact of the matter\nis, the sun doesn't set on the hackers.\n\n194\n00:09:57.510 --> 00:09:58.950\nAnd a lot of times when\nit sets on the hackers,\n\n195\n00:09:58.950 --> 00:10:00.170\nthat's when they go to work, right?\n\n196\n00:10:00.170 --> 00:10:04.020\nSo it's a revolving door, remember\nsecurity's not a destination to be\n\n197\n00:10:04.020 --> 00:10:06.390\nreached, it's a journey to\nbe traveled upon, right?\n\n198\n00:10:06.390 --> 00:10:09.600\nSo they're constantly\ncoming out with new things.\n\n199\n00:10:09.600 --> 00:10:12.860\nAnd because of that that's why\nwe need things like heuristics,\n\n200\n00:10:12.860 --> 00:10:14.620\nwe need sample submissions.\n\n201\n00:10:14.620 --> 00:10:20.330\nBut again, zero day is just when\nan attack or an exploit has happened.\n\n202\n00:10:20.330 --> 00:10:23.370\nNobody knows about it and\nnobody has a solution for\n\n203\n00:10:23.370 --> 00:10:25.490\nthe problem, so\nyou definitely have to wait.\n\n204\n00:10:25.490 --> 00:10:29.490\nYou can also think of just zero day\nas being a brand new threat that\n\n205\n00:10:29.490 --> 00:10:31.760\nnobody is aware of yet.\n\n206\n00:10:31.760 --> 00:10:34.730\nHacking conventions, right, that's why\nthey have hacking conventions, right.\n\n207\n00:10:34.730 --> 00:10:36.430\nYou have people that companies that pay.\n\n208\n00:10:36.430 --> 00:10:38.568\nGoogle, I don't know if they're\nstill doing bug bounties.\n\n209\n00:10:38.568 --> 00:10:39.710\n&gt;&gt; They are, they've actually-\n&gt;&gt; They're doing bug bounties?\n\n210\n00:10:39.710 --> 00:10:40.670\n&gt;&gt; They've actually\nrecently increased them.\n\n211\n00:10:40.670 --> 00:10:45.125\nMicrosoft and a couple of the major\ncompanies have increased to ridiculous, so\n\n212\n00:10:45.125 --> 00:10:46.930\nridiculous payouts here guys.\n\n213\n00:10:46.930 --> 00:10:51.350\n&gt;&gt; Yeah definitely, these bug bounties\nare to find out zero day exploits right?\n\n214\n00:10:51.350 --> 00:10:54.840\nMuch better to pay\na white hat if you will,\n\n215\n00:10:54.840 --> 00:10:58.700\nor it could be a black hat right,\nthat's maybe got a conscience.\n\n216\n00:10:58.700 --> 00:10:59.652\n&gt;&gt; Some gray.\n\n217\n00:10:59.652 --> 00:11:02.532\n&gt;&gt; Right, also gray,\nthat finds that exploit and\n\n218\n00:11:02.532 --> 00:11:04.880\nthen lets the company know about it.\n\n219\n00:11:04.880 --> 00:11:07.153\nAnd then the company\nimplements a solution and\n\n220\n00:11:07.153 --> 00:11:09.547\nlets the rest of the world know about it,\nright.\n\n221\n00:11:09.547 --> 00:11:10.962\nIt's one of the reasons they have those.\n\n222\n00:11:10.962 --> 00:11:15.684\nSo we can find these exploits before\nsomebody that doesn't have a conscience,\n\n223\n00:11:15.684 --> 00:11:16.606\nthe black hat.\n\n224\n00:11:16.606 --> 00:11:20.056\nWell they have a conscience about\nmaking their wallets fatter, and\n\n225\n00:11:20.056 --> 00:11:21.152\ngetting more money.\n\n226\n00:11:21.152 --> 00:11:24.761\nBefore they find it and then they exploit\nto whatever their malicious gain is,\n\n227\n00:11:24.761 --> 00:11:26.520\nwhatever their evil intent might be.\n\n228\n00:11:27.850 --> 00:11:31.450\nAll right, so I think that's got to\nthe hijacking related attacks there.\n\n229\n00:11:31.450 --> 00:11:35.050\nWe do have to talk about something that\nI really don't have a slide for as well.\n\n230\n00:11:35.050 --> 00:11:36.940\nIt's called driver manipulation.\n\n231\n00:11:38.540 --> 00:11:43.154\nDriver manipulation can happen for\nlegal purposes, for\n\n232\n00:11:43.154 --> 00:11:46.720\nknown reasons, I'll give you an example.\n\n233\n00:11:46.720 --> 00:11:52.160\nSo one of the things that they call\nout is [INAUDIBLE], all right.\n\n234\n00:11:52.160 --> 00:11:55.986\nWe actually have these where they're\nlegit right, in Microsoft right.\n\n235\n00:11:55.986 --> 00:11:59.413\nAnd Cherokee I know you're very\nfamiliar with Windows Server and\n\n236\n00:11:59.413 --> 00:12:01.040\nthe Windows Clients, right.\n\n237\n00:12:02.090 --> 00:12:04.890\nWe have what's known as the application\ncompatibility tool kit right.\n\n238\n00:12:04.890 --> 00:12:09.273\nAs you move from different versions of an\noperating system there's a potential that\n\n239\n00:12:09.273 --> 00:12:12.314\nthe drivers that are in\nthe operating system don't work.\n\n240\n00:12:12.314 --> 00:12:15.661\nWhen the new operating system is put\ninto place, or an application for\n\n241\n00:12:15.661 --> 00:12:16.870\nthat matter, right?\n\n242\n00:12:16.870 --> 00:12:19.310\nWe're focused on drivers here,\nbut applications too.\n\n243\n00:12:19.310 --> 00:12:20.530\nSo what do they do?\n\n244\n00:12:20.530 --> 00:12:24.170\nYou create a small fix called a shim.\n\n245\n00:12:24.170 --> 00:12:27.525\nOr what happens is your normal process,\nand in a driver context,\n\n246\n00:12:27.525 --> 00:12:29.538\nthink about what driver does, right?\n\n247\n00:12:29.538 --> 00:12:33.352\nA driver takes thata high-level\nprogramming language, translates it down\n\n248\n00:12:33.352 --> 00:12:37.060\ninto something, the low-level\nassembly if you will machine code.\n\n249\n00:12:37.060 --> 00:12:42.004\nThat our hardware relies on or\nwill react to.\n\n250\n00:12:42.004 --> 00:12:45.051\nIf I put a shim in the middle of it,\nright, it's a temporary fix.\n\n251\n00:12:45.051 --> 00:12:49.995\nThat says, okay now when the operating\nsystem says it's not compatible,\n\n252\n00:12:49.995 --> 00:12:53.050\ncalls down the shim, basically.\n\n253\n00:12:53.050 --> 00:12:57.965\nFormats it in a way that it can talk to\nthe driver, basically compatibility fix.\n\n254\n00:12:57.965 --> 00:13:02.162\nNow, one of the things I want\nyou to keep in mind with driver\n\n255\n00:13:02.162 --> 00:13:04.401\nmanipulation unauthorized.\n\n256\n00:13:04.401 --> 00:13:07.330\nThis is when you put a hook, right.\n\n257\n00:13:07.330 --> 00:13:11.539\nAnd what happens is when the operating\nsystem is supposed to be calling down to\n\n258\n00:13:11.539 --> 00:13:13.689\nthe driver, that shim intercepts it.\n\n259\n00:13:13.689 --> 00:13:15.766\nAnd that's a lot of\ntime what root kits do.\n\n260\n00:13:15.766 --> 00:13:19.230\nRoot kits intercept calls and\nthey redirect them back up to the user and\n\n261\n00:13:19.230 --> 00:13:21.410\nthey can say whatever they want.\n\n262\n00:13:21.410 --> 00:13:24.560\nRight, so\nit works no different than the same way\n\n263\n00:13:24.560 --> 00:13:26.780\napplications shimming works, right.\n\n264\n00:13:26.780 --> 00:13:30.410\nAnd again, as an example of a legal shim,\n\n265\n00:13:30.410 --> 00:13:34.820\nwe have those inside of the ACT\nwithin Windows deployment tools.\n\n266\n00:13:34.820 --> 00:13:36.070\nWhat else?\n\n267\n00:13:36.070 --> 00:13:38.470\nCredit card shimming,\nyou ever heard of that?\n\n268\n00:13:38.470 --> 00:13:39.920\nMaybe you haven't.\n\n269\n00:13:39.920 --> 00:13:43.390\nYou've heard of the credit\ncard skimmers right?\n\n270\n00:13:43.390 --> 00:13:44.010\n&gt;&gt; Yeah.\n\n271\n00:13:44.010 --> 00:13:45.160\n&gt;&gt; Shimming is the same thing, right?\n\n272\n00:13:45.160 --> 00:13:48.630\nIt's just an interchangeable term, they\ncall it shimming because what happens?\n\n273\n00:13:48.630 --> 00:13:54.510\nYou have that EMV, the standard for\nEuropean and American credit cards, right?\n\n274\n00:13:54.510 --> 00:13:59.030\nIt's a little chip that sits\non the card itself today.\n\n275\n00:13:59.030 --> 00:14:03.201\nWell, what happens is they\nput a little shim detector,\n\n276\n00:14:03.201 --> 00:14:07.033\na little device around what\nyou put your card into.\n\n277\n00:14:07.033 --> 00:14:10.566\nAnd it intercepts the communication\nbetween that chip and\n\n278\n00:14:10.566 --> 00:14:14.760\nwhatever the authenticating or\ndevice is that's inside of the ATM.\n\n279\n00:14:14.760 --> 00:14:16.150\nIt intercepts it, right.\n\n280\n00:14:16.150 --> 00:14:17.604\nAnd it sends it somewhere else.\n\n281\n00:14:17.604 --> 00:14:21.610\nAnd it sends it usually over a wireless\ncommunication to somebody who is waiting\n\n282\n00:14:21.610 --> 00:14:22.221\nwith a van.\n\n283\n00:14:22.221 --> 00:14:23.494\nI don't know if they have a van or\nnot, but-\n\n284\n00:14:23.494 --> 00:14:24.060\n&gt;&gt; [LAUGH] Sounds good.\n\n285\n00:14:24.060 --> 00:14:27.165\n&gt;&gt; Waiting there to\ncapture that information.\n\n286\n00:14:27.165 --> 00:14:28.682\n&gt;&gt; Creepy.\n\n287\n00:14:28.682 --> 00:14:29.550\n&gt;&gt; Has to be creepy.\n\n288\n00:14:29.550 --> 00:14:30.915\nThat means it can't have windows either.\n\n289\n00:14:30.915 --> 00:14:31.746\n&gt;&gt; [LAUGH]\n&gt;&gt; So\n\n290\n00:14:31.746 --> 00:14:35.429\nthat's essentially the way the credit card\nskimmers, they call them skimmers but\n\n291\n00:14:35.429 --> 00:14:37.440\nit's a shimming attack is what it's doing.\n\n292\n00:14:37.440 --> 00:14:39.825\n&gt;&gt; You know what I've seen,\nWes, online recently?\n\n293\n00:14:39.825 --> 00:14:44.359\nA lot of gas stations,\nprobably they were having issues.\n\n294\n00:14:44.359 --> 00:14:46.209\nOr it was a problematic location and\n\n295\n00:14:46.209 --> 00:14:49.320\nthey've had these types\nof attacks happen there.\n\n296\n00:14:49.320 --> 00:14:50.970\nThey have these stickers, and\n\n297\n00:14:50.970 --> 00:14:55.050\nit says, if this sticker has been\ndamaged in any way, please call.\n\n298\n00:14:55.050 --> 00:14:58.780\nAnd it'll have a 1-800 number,\nso those devices can't easily be\n\n299\n00:14:58.780 --> 00:15:02.830\nadded to particular ATMs,\ngas pumps, things like that.\n\n300\n00:15:02.830 --> 00:15:03.460\n&gt;&gt; Yeah, and\n\n301\n00:15:03.460 --> 00:15:09.125\none of the things that we can do with\ndriver shimming in a malicious sense.\n\n302\n00:15:09.125 --> 00:15:12.500\nCuz a lot of your operating\nsystems already do this.\n\n303\n00:15:12.500 --> 00:15:15.190\nIt's just important to never bypass it.\n\n304\n00:15:15.190 --> 00:15:17.420\nIs to do driver signature enforcement,\nright?\n\n305\n00:15:17.420 --> 00:15:20.025\nFor instance in Windows,\nyou have 64 bit drivers.\n\n306\n00:15:20.025 --> 00:15:21.755\nThey have to be digitally signed,\n\n307\n00:15:21.755 --> 00:15:25.710\nthey have to be basically hit with a\nlittle bit of electronic signature there.\n\n308\n00:15:25.710 --> 00:15:29.010\nLittle electronic information that says,\nyeah, we know what this driver is,\n\n309\n00:15:29.010 --> 00:15:30.080\nwe know what it does.\n\n310\n00:15:30.080 --> 00:15:31.190\nWe've tested it.\n\n311\n00:15:31.190 --> 00:15:35.490\nIt's gone through a rigorous process, and\nMicrosoft's got their seal of approval.\n\n312\n00:15:35.490 --> 00:15:37.750\nIn this case,\nI'm talking about Windows, right?\n\n313\n00:15:37.750 --> 00:15:41.520\nSo that when that driver executes,\nit's already trusted.\n\n314\n00:15:41.520 --> 00:15:42.960\nWe know what it is.\n\n315\n00:15:42.960 --> 00:15:48.899\nAnd if there is a refactoring, repurposing\nof the driver that we're not aware of.\n\n316\n00:15:48.899 --> 00:15:52.733\nIf there's a shimming that happens\nwe're gonna be aware of it\n\n317\n00:15:52.733 --> 00:15:56.070\nbecause the driver's\nsignature is gonna catch it.\n\n318\n00:15:56.070 --> 00:16:01.900\nSo that's one of the things that you can\ndo in order to help try to stop that.\n\n319\n00:16:01.900 --> 00:16:05.350\nA couple of other ones, I didn't\nmention one that's in the list here.\n\n320\n00:16:05.350 --> 00:16:07.911\nSo I'm gonna have to kind of\ndouble back on my notes there, and\n\n321\n00:16:07.911 --> 00:16:09.006\njump off the beaten path.\n\n322\n00:16:09.006 --> 00:16:10.847\nWas, pass the hash, all right?\n\n323\n00:16:10.847 --> 00:16:14.211\nThis is kind of an interesting\ntechnique that really revolves around\n\n324\n00:16:14.211 --> 00:16:15.432\nthings like collision.\n\n325\n00:16:15.432 --> 00:16:18.763\nAnd when we talk about collisions, we're\ntalking about hashing collisions, right?\n\n326\n00:16:18.763 --> 00:16:20.680\nThink about what a message digest is.\n\n327\n00:16:20.680 --> 00:16:24.869\nRight, a message digest is a one-way\nencryption that basically produces a fixed\n\n328\n00:16:24.869 --> 00:16:28.101\noutput regardless of what the size\nof the document is, right?\n\n329\n00:16:28.101 --> 00:16:32.305\nAnd, we can take that output, and we could\nsave it, and we could take the document,\n\n330\n00:16:32.305 --> 00:16:34.511\nI could hand the document\nover to Cherokee.\n\n331\n00:16:34.511 --> 00:16:37.948\nAnd if Cherokee wants to verify\nthat the document hasn't changed,\n\n332\n00:16:37.948 --> 00:16:41.205\nwhether malicious intent or\nnetwork communication failures,\n\n333\n00:16:41.205 --> 00:16:44.070\nshe can run the same\nmathematical operations, right?\n\n334\n00:16:44.070 --> 00:16:47.050\nThe same hushing value across\nthe top of that hopefully,\n\n335\n00:16:47.050 --> 00:16:49.470\nget the same fixed length value, right?\n\n336\n00:16:49.470 --> 00:16:53.370\nAnd she can compare what she\nknows with what she found and,\n\n337\n00:16:53.370 --> 00:16:54.360\nif the two are the same,\n\n338\n00:16:54.360 --> 00:16:58.650\nwell guess what, the integrity of\nthe document's been maintained.\n\n339\n00:16:58.650 --> 00:17:01.960\nWell, your passwords, like for\ninstance, inside of Windows.\n\n340\n00:17:01.960 --> 00:17:06.312\nYour passwords aren't really based on,\nwell in this case, here in the States,\n\n341\n00:17:06.312 --> 00:17:08.620\nhere the English keyboard, right?\n\n342\n00:17:08.620 --> 00:17:11.600\nA g isn't necessarily\na g in your password.\n\n343\n00:17:11.600 --> 00:17:14.800\nWhat it is that's stored is\na hash value of your password.\n\n344\n00:17:14.800 --> 00:17:19.060\nSo that means that,\nif I can find any random sequence,\n\n345\n00:17:19.060 --> 00:17:21.190\njust running my hands across the keyboard,\n\n346\n00:17:21.190 --> 00:17:26.240\nright, that will produce the same hash\nvalue, then I don't need your password.\n\n347\n00:17:26.240 --> 00:17:29.190\nI don't need to type in,\nI love my cats, right?\n\n348\n00:17:29.190 --> 00:17:30.930\nIf that happens to be your password.\n\n349\n00:17:30.930 --> 00:17:33.430\nAll I need is the hashed value, right?\n\n350\n00:17:33.430 --> 00:17:35.085\nThat's what a collision.\n\n351\n00:17:35.085 --> 00:17:39.465\nWe're trying to find the same type of hash\nvalues regardless of whether we knew what\n\n352\n00:17:39.465 --> 00:17:41.290\ntext was inside of that document.\n\n353\n00:17:41.290 --> 00:17:45.153\nIn this case, we find the same two\nhashed values of what a password is,\n\n354\n00:17:45.153 --> 00:17:48.377\nthen I can pass the hash off\nto the authenticating system.\n\n355\n00:17:48.377 --> 00:17:51.983\nI don't need the password, cuz it's\njust looking down in, its database for\n\n356\n00:17:51.983 --> 00:17:53.360\nthe hash value, right?\n\n357\n00:17:53.360 --> 00:17:57.050\nIt's doing the same thing that in my\nexample is sending a document to Cherokee\n\n358\n00:17:57.050 --> 00:17:58.595\nwith earlier is doing, right?\n\n359\n00:17:58.595 --> 00:18:02.319\nIt's like, okay, you typed in your\npassword, let's say normal operations,\n\n360\n00:18:02.319 --> 00:18:05.002\nyou typed in your password,\nthat hash value goes across,\n\n361\n00:18:05.002 --> 00:18:07.520\ngoes to the authenticating endpoint,\nright?\n\n362\n00:18:07.520 --> 00:18:10.840\nThat authenticating endpoint then\ntakes a database of a hash value,\n\n363\n00:18:10.840 --> 00:18:13.520\nits got your password and\ncompares the two.\n\n364\n00:18:13.520 --> 00:18:16.010\nIf the two are the same,\nthen you must've typed the right password.\n\n365\n00:18:16.010 --> 00:18:19.220\nYou must be who you say you are,\nright, authentication by assertion.\n\n366\n00:18:19.220 --> 00:18:22.202\nWell now,\nif I have the hash value as an attacker,\n\n367\n00:18:22.202 --> 00:18:26.187\nI just pass that off to the authenticating\nentity at the other end.\n\n368\n00:18:26.187 --> 00:18:29.293\nNow when it says, okay,\nsee this hash value that you just gave me,\n\n369\n00:18:29.293 --> 00:18:31.530\nnot the password, but the hash value.\n\n370\n00:18:31.530 --> 00:18:33.580\nSee the hash value that's in my database,\nthey're the same,\n\n371\n00:18:33.580 --> 00:18:37.280\nI could assert you are who you say you\nare because when I challenged you,\n\n372\n00:18:37.280 --> 00:18:39.250\nyou gave me the right information.\n\n373\n00:18:39.250 --> 00:18:43.030\nAgain, never aware that,\nit was the hacker on the other end, right?\n\n374\n00:18:43.030 --> 00:18:47.360\nSee, if you have a password to a user,\nthere's no way for\n\n375\n00:18:47.360 --> 00:18:51.010\nthe endpoint to know that it wasn't\nactually the user that was typing it in.\n\n376\n00:18:51.010 --> 00:18:53.690\nSo the pass-the-hash\nattack can cause problems.\n\n377\n00:18:53.690 --> 00:18:58.415\nAnd again, that is based on the hash\nvalue, if you will, of your password\n\n378\n00:18:58.415 --> 00:19:03.237\nbeing passed off rather than what we\nsee as the characters of the keyboard.\n\n379\n00:19:03.237 --> 00:19:05.083\nAll right, so where are we at?\n\n380\n00:19:05.083 --> 00:19:06.680\nWe talked-\n&gt;&gt; How about some wireless attacks?\n\n381\n00:19:06.680 --> 00:19:08.857\n&gt;&gt; Wireless, yeah,\nthere are plenty of wireless-\n\n382\n00:19:08.857 --> 00:19:10.052\n&gt;&gt; [LAUGH]\n\n383\n00:19:10.052 --> 00:19:11.280\n&gt;&gt; Attacks for sure, and\n\n384\n00:19:11.280 --> 00:19:14.971\nwe've got a list of them here that\nwe definitely need to go through.\n\n385\n00:19:14.971 --> 00:19:17.920\nOne of the first ones they call\nout guys is a replay attack.\n\n386\n00:19:17.920 --> 00:19:18.900\nThat's the same thing.\n\n387\n00:19:18.900 --> 00:19:23.810\nAny type of replay attack is where\nyou capture information, you wait and\n\n388\n00:19:23.810 --> 00:19:25.591\nthen you replay it later.\n\n389\n00:19:25.591 --> 00:19:30.206\nRight, this is why we have technologies\nthat do things like timestamping and\n\n390\n00:19:30.206 --> 00:19:35.042\nsequencing, integrity checks, right,\nso that time stamping alone, right?\n\n391\n00:19:35.042 --> 00:19:38.740\nIf I capture some information and\nit's 5 o'clock in the morning and\n\n392\n00:19:38.740 --> 00:19:42.944\nthen I replay it to the server at noon,\nserver looks to the timestamp, it say,\n\n393\n00:19:42.944 --> 00:19:47.395\nwait a second here, it's noon, it's not\n5 AM and discards the packet, right?\n\n394\n00:19:47.395 --> 00:19:49.420\nIt's one of the ways we\ncan stop a replay attack.\n\n395\n00:19:49.420 --> 00:19:52.850\nBut that's essentially all a replay attack\nis whether it's on wired network or\n\n396\n00:19:52.850 --> 00:19:54.170\nwhether it's on a wireless network.\n\n397\n00:19:55.270 --> 00:19:56.500\n&gt;&gt; Sorry to interject here.\n\n398\n00:19:56.500 --> 00:19:59.271\nBut just to go back someone\nhad put earlier in the chat,\n\n399\n00:19:59.271 --> 00:20:01.933\ngoing back to that even just\nhybrid style of attack.\n\n400\n00:20:01.933 --> 00:20:06.187\nIf you think about, you were just\nmentioning the Network Time Protocol,\n\n401\n00:20:06.187 --> 00:20:10.373\nif you’re using maybe like a Windows\nenvironment, like Kerberos, and\n\n402\n00:20:10.373 --> 00:20:11.832\nit has a time out period.\n\n403\n00:20:11.832 --> 00:20:15.699\nAnd you change the time of these systems,\nproviding a type of denial of service\n\n404\n00:20:15.699 --> 00:20:19.580\nattack just by manipulating that\nlower time protocol information.\n\n405\n00:20:19.580 --> 00:20:23.360\n&gt;&gt; Most definitely, in fact, given a\nclassic example where it happens a lot in,\n\n406\n00:20:23.360 --> 00:20:25.500\nit’s not malicious, right?\n\n407\n00:20:25.500 --> 00:20:28.590\nSee, in a Windows domain, your computers\nhave to be within, by default,\n\n408\n00:20:28.590 --> 00:20:31.690\nwithin five minutes of whatever\nthe master time clock is.\n\n409\n00:20:31.690 --> 00:20:34.650\nTypically, the domain controller\nis the master time clock.\n\n410\n00:20:34.650 --> 00:20:37.570\nAnd that's why,\nwhy does it have to be that way?\n\n411\n00:20:37.570 --> 00:20:42.810\nCuz Kerberos, or Kerberos, however you\nwanna say that, is a time sensitive\n\n412\n00:20:42.810 --> 00:20:46.740\nticket stamping or\nticket granting authentication mechanism.\n\n413\n00:20:46.740 --> 00:20:48.207\nAnd it means that when I login,\n\n414\n00:20:48.207 --> 00:20:52.900\nit's gonna give me what's known as a\nticket granting ticket, that's timestamps.\n\n415\n00:20:52.900 --> 00:20:57.690\nWell, if my time in my computer\nis off by the master time clock,\n\n416\n00:20:57.690 --> 00:20:59.640\nthen those timestamps don't match.\n\n417\n00:20:59.640 --> 00:21:01.840\nAnd if your computer does that and\n\n418\n00:21:01.840 --> 00:21:04.940\nit starts to vary more than five\nminutes by default off the master\n\n419\n00:21:04.940 --> 00:21:08.600\ntime clock of the domain,\nyour computer loses trust with the domain.\n\n420\n00:21:08.600 --> 00:21:10.040\nAnd one of the things\nthat you'll go in to do,\n\n421\n00:21:10.040 --> 00:21:13.000\nyou'll go in and try to login to the\ncomputer and the computer will say, nope,\n\n422\n00:21:13.000 --> 00:21:15.390\nsorry, this computer's lost\ntrust with the domain.\n\n423\n00:21:15.390 --> 00:21:16.293\nAnd what do we have to do?\n\n424\n00:21:16.293 --> 00:21:20.270\nWe gotta unjoin it from the domain,\nwe join it back to the domain.\n\n425\n00:21:20.270 --> 00:21:23.894\nAnd it talks to the domain controller and\nit synchronizes its time, right?\n\n426\n00:21:23.894 --> 00:21:28.150\nSo, timestamping is very, very important\nin combating things like replay attacks.\n\n427\n00:21:28.150 --> 00:21:32.180\nIP Sec is another one, but\nwe'll get into IP Sec a little bit later,\n\n428\n00:21:32.180 --> 00:21:34.466\nalso does timestamping, all right.\n\n429\n00:21:34.466 --> 00:21:40.642\nWhat are the other things that they call\nout is something known as an IV, okay?\n\n430\n00:21:40.642 --> 00:21:44.328\nIn your encryption method, so\nI've specifically like we're\n\n431\n00:21:44.328 --> 00:21:49.012\ntalking about wireless, you have what's\nknown as an initialization vector.\n\n432\n00:21:49.012 --> 00:21:53.956\nAll right, and I want you think about\nthis, if I have two of the same identical\n\n433\n00:21:53.956 --> 00:21:57.701\npieces of data,\nwe use the exact same encryption method.\n\n434\n00:21:57.701 --> 00:21:59.783\nCherokee, do you think\nit'd be safe to say that,\n\n435\n00:21:59.783 --> 00:22:02.050\nit's gonna produce\nthe same encrypted output?\n\n436\n00:22:02.050 --> 00:22:05.770\nAgain, identical encryption method,\nidentical data in every way.\n\n437\n00:22:05.770 --> 00:22:06.500\n&gt;&gt; It should.\n\n438\n00:22:06.500 --> 00:22:07.720\n&gt;&gt; That's right, right, it should.\n\n439\n00:22:07.720 --> 00:22:09.070\nAnd in encryption,\n\n440\n00:22:09.070 --> 00:22:14.460\nwe don't want the possibility of\nidentical frames or packets, why?\n\n441\n00:22:14.460 --> 00:22:18.594\nWell, because you could run some kinda\nprogram that does statistical analysis.\n\n442\n00:22:18.594 --> 00:22:20.950\n&gt;&gt; You start becoming,\nyeah, frequency analysis.\n\n443\n00:22:20.950 --> 00:22:22.590\nYou start becoming predictable.\n\n444\n00:22:22.590 --> 00:22:24.250\n&gt;&gt; That's it, prediction, exactly.\n\n445\n00:22:24.250 --> 00:22:26.100\nWe don't want predictability\nat encryption.\n\n446\n00:22:26.100 --> 00:22:28.390\nSo, I got a little diagram here, guys.\n\n447\n00:22:28.390 --> 00:22:31.770\nAnd, it really isn't much, but\nit kinda shows you what's going on, right?\n\n448\n00:22:31.770 --> 00:22:35.220\nWith Wired Equivalent Privacy, this is\none that's very susceptible to that.\n\n449\n00:22:35.220 --> 00:22:39.690\nIt's one of the reasons you should not be\nusing Wired Equivalent Privacy or WEP,\n\n450\n00:22:39.690 --> 00:22:41.980\non your wireless devices today.\n\n451\n00:22:41.980 --> 00:22:45.960\nAnd that's because, what they do is\nthey add an initialization factor and\n\n452\n00:22:45.960 --> 00:22:47.780\nthis is what most encryption will do.\n\n453\n00:22:47.780 --> 00:22:52.206\nThe initialization vector is always\nadded to your data, randomized,\n\n454\n00:22:52.206 --> 00:22:57.150\npseudo-randomized so that the entire\nthing is encrypted and it makes sure that\n\n455\n00:22:57.150 --> 00:23:01.524\nno two pieces of data, like we were\nsaying, ever come out identical.\n\n456\n00:23:01.524 --> 00:23:02.957\nWe don't want you to be predictive.\n\n457\n00:23:02.957 --> 00:23:04.340\n&gt;&gt; It adds confusion and diffusion.\n\n458\n00:23:04.340 --> 00:23:05.184\n&gt;&gt; That's right, that's right.\n\n459\n00:23:05.184 --> 00:23:09.990\n[LAUGH] So, here's the problem, the\ninitialization vector, I don't know if you\n\n460\n00:23:09.990 --> 00:23:15.480\nguys can see that 24 bits in a web frame,\nokay, and there's a problem with that.\n\n461\n00:23:15.480 --> 00:23:19.564\nThe problem is 24 bits in anything\nthat has to do with security,\n\n462\n00:23:19.564 --> 00:23:21.430\nisn't long enough, right?\n\n463\n00:23:21.430 --> 00:23:25.642\nWe have things like AES-256, SHA-256,\n\n464\n00:23:25.642 --> 00:23:29.820\n384, 512, 512 bits, okay?\n\n465\n00:23:29.820 --> 00:23:31.940\nSo I want you to think about this.\n\n466\n00:23:31.940 --> 00:23:35.866\nIf there's 24 bits in\nan initialization vector,\n\n467\n00:23:35.866 --> 00:23:40.071\nthat gives you 16,777,216 possibilities.\n\n468\n00:23:40.071 --> 00:23:42.026\nOkay, then the problem with that,\n\n469\n00:23:42.026 --> 00:23:46.588\nis that the statistics say that about\n50% of those 16 million possibilities,\n\n470\n00:23:46.588 --> 00:23:51.300\njust under 17 million possibilities,\nyou're gonna have a duplication, right?\n\n471\n00:23:51.300 --> 00:23:54.190\nCuz there's not a lot of bit space there,\nthere's not a lot of chance for\n\n472\n00:23:54.190 --> 00:23:54.780\npossibilities.\n\n473\n00:23:54.780 --> 00:23:57.781\nEven though that seems like a lot,\nin modern computing it's not.\n\n474\n00:23:57.781 --> 00:24:01.100\nAnd the problem is now that\nyou have the duplications,\n\n475\n00:24:01.100 --> 00:24:06.082\njust like identical data encryption\nproducing the identical encrypted output,\n\n476\n00:24:06.082 --> 00:24:09.275\nthese initialization\nvectors become the problem.\n\n477\n00:24:09.275 --> 00:24:15.190\nRight, when we moved into things like for\ninstance, WPA, Wi-Fi Protected Access.\n\n478\n00:24:15.190 --> 00:24:18.884\nIt increased the bit length of\nthe initialization vectors to 48.\n\n479\n00:24:18.884 --> 00:24:22.263\n48 bits is a lot harder to crack,\nbecause of combinations and\n\n480\n00:24:22.263 --> 00:24:24.130\nhow many possibilities they are.\n\n481\n00:24:24.130 --> 00:24:25.760\nSo that's the initialization vector.\n\n482\n00:24:25.760 --> 00:24:29.100\nIt's one of the reasons you should not\nbe running wired equivalent privacy,\n\n483\n00:24:29.100 --> 00:24:30.990\non any wireless network that you have.\n\n484\n00:24:32.920 --> 00:24:37.450\nNow, now we get to talk about some\ninteresting things, we talk about for\n\n485\n00:24:37.450 --> 00:24:42.182\ninstance Evil Twins in the,\ntalk about Rogue Access Points.\n\n486\n00:24:42.182 --> 00:24:46.944\nI'm gonna go ahead and I'm gonna basically\ntalk about them in the same context,\n\n487\n00:24:46.944 --> 00:24:51.216\nbecause a Rogue Access Point,\na Rogue Access Point point is basically,\n\n488\n00:24:51.216 --> 00:24:53.406\nwe've got a wireless network here.\n\n489\n00:24:53.406 --> 00:24:58.640\nAnd from time to time we'll fire up\na wireless access point to do study,\n\n490\n00:24:58.640 --> 00:25:01.690\nto do testing, get ready for our shows.\n\n491\n00:25:01.690 --> 00:25:04.440\nWhat happens if that wireless\naccess point, which they do,\n\n492\n00:25:04.440 --> 00:25:09.910\na lot of times by default starts giving\nout DHCP, IP addresses through DHCP?\n\n493\n00:25:09.910 --> 00:25:10.980\nNow here's the problem.\n\n494\n00:25:10.980 --> 00:25:14.310\nIf it's an open system like that,\nyou can connect to it.\n\n495\n00:25:14.310 --> 00:25:16.740\nAnd I don't have any internet connection.\n\n496\n00:25:16.740 --> 00:25:19.040\nYou're not going out to the internet\nwith that access point.\n\n497\n00:25:19.040 --> 00:25:20.390\nAnd now we have denial of service attack.\n\n498\n00:25:20.390 --> 00:25:22.410\nThat's a Rogue Access Point.\n\n499\n00:25:22.410 --> 00:25:25.430\nIt's just any unauthorized\naccess point in the proximity,\n\n500\n00:25:25.430 --> 00:25:28.400\nyour wireless network that\npeople start connecting to.\n\n501\n00:25:29.600 --> 00:25:31.834\nNow the Evil Twin is still a Rogue Access\nPoint but it goes a little bit farther.\n\n502\n00:25:31.834 --> 00:25:34.640\nNow they're trying to\nbe a little bit tricky.\n\n503\n00:25:34.640 --> 00:25:38.260\nAnd what they do is they take for\ninstance, something like your SSID.\n\n504\n00:25:38.260 --> 00:25:40.480\nThe Service Set Identifier and\nthink of it as the network name,\n\n505\n00:25:40.480 --> 00:25:43.360\nit's how I identify what\nnetworks are out there.\n\n506\n00:25:43.360 --> 00:25:45.880\nIn the little list that you have\non most of your mobile devices.\n\n507\n00:25:45.880 --> 00:25:50.010\nWell, imagine if I brought\nup a Rogue Access Point, and\n\n508\n00:25:50.010 --> 00:25:53.540\nI did an identical SSID, every way.\n\n509\n00:25:53.540 --> 00:25:54.350\nSo when that list,\n\n510\n00:25:54.350 --> 00:25:58.770\nyou look at that list you say,\nI got two, coffee spot, coffee spot.\n\n511\n00:25:59.920 --> 00:26:03.100\nI don't really wanna go in and\nask the person at the desk or\n\n512\n00:26:03.100 --> 00:26:08.360\nthe coffee shop attendant,\nwhat's your WiFi password.\n\n513\n00:26:08.360 --> 00:26:10.590\nI can see that this one over here.\n\n514\n00:26:10.590 --> 00:26:11.960\nThis one says it's open.\n\n515\n00:26:11.960 --> 00:26:13.700\nSo it's gonna make it a lot easier.\n\n516\n00:26:13.700 --> 00:26:15.220\nConvenience for me and\nI'll just connect to it.\n\n517\n00:26:16.450 --> 00:26:19.160\nUnbeknownst to you,\nthat's actually a Rogue Access Point.\n\n518\n00:26:19.160 --> 00:26:22.640\nAnd now, the attacker could be\njust simply denial of service, or\n\n519\n00:26:22.640 --> 00:26:24.580\nthey could actually be\nscraping your information.\n\n520\n00:26:24.580 --> 00:26:28.200\nSo again, Rogue Access Points and\nEvil Twins are almost one and the same.\n\n521\n00:26:28.200 --> 00:26:31.780\nRogue Access Point,\nis real no configuration.\n\n522\n00:26:31.780 --> 00:26:34.140\nPlug it into the wall,\nit starts broadcasting.\n\n523\n00:26:34.140 --> 00:26:36.940\nAnd they start sending out IP addresses.\n\n524\n00:26:36.940 --> 00:26:41.640\nEvil Twin, same thing but now we gotta go\ninto the interface of the access point and\n\n525\n00:26:41.640 --> 00:26:42.360\nmake some changes.\n\n526\n00:26:42.360 --> 00:26:46.590\nLike for instance changing the SSID to\nmatch whatever the legitimate access\n\n527\n00:26:46.590 --> 00:26:49.160\npoints network is, so that it looks or\n\n528\n00:26:49.160 --> 00:26:53.360\nit spoofs again it looks just like\nit is the legitimate access point.\n\n529\n00:26:55.570 --> 00:26:57.750\nI know we're coming up\non the end of the time.\n\n530\n00:26:57.750 --> 00:27:03.310\nSo let me go ahead and I will take care of\na couple more of these, here real quick.\n\n531\n00:27:03.310 --> 00:27:04.670\nJamming.\n\n532\n00:27:04.670 --> 00:27:07.110\nJamming is a denial of service attack.\n\n533\n00:27:07.110 --> 00:27:09.769\nJamming can happen,\nit can happen by flooding your network.\n\n534\n00:27:09.769 --> 00:27:11.715\n&gt;&gt; Cellular, 802.11 jamming.\n\n535\n00:27:11.715 --> 00:27:12.752\n&gt;&gt; That's right.\n\n536\n00:27:12.752 --> 00:27:14.494\n&gt;&gt; EMI interference.\n\n537\n00:27:14.494 --> 00:27:17.983\nSo there's a lot of different\nforms of jamming also.\n\n538\n00:27:17.983 --> 00:27:18.610\n&gt;&gt; Most definitely.\n\n539\n00:27:18.610 --> 00:27:22.190\nAn electromagnetic interference,\ndoesn't necessarily have to be malicious.\n\n540\n00:27:22.190 --> 00:27:22.908\nIt's still a jamming.\n\n541\n00:27:22.908 --> 00:27:24.180\n&gt;&gt; It could be legit, yeah.\n\n542\n00:27:24.180 --> 00:27:26.450\n&gt;&gt; So\nyou have to be careful with that one and,\n\n543\n00:27:26.450 --> 00:27:31.440\nwe could actually do things like\nreplay could jam essentially\n\n544\n00:27:31.440 --> 00:27:35.440\na network where you just constantly\nstanding those AP station probes.\n\n545\n00:27:35.440 --> 00:27:36.963\nBack to the machines, the access point.\n\n546\n00:27:36.963 --> 00:27:38.335\n&gt;&gt; Pretty good type of denial of service.\n\n547\n00:27:38.335 --> 00:27:39.536\nCreating [INAUDIBLE].\n\n548\n00:27:39.536 --> 00:27:42.799\n[CROSSTALK]\n&gt;&gt; So you guys can see how everything is\n\n549\n00:27:42.799 --> 00:27:46.110\nrelated in some strange\nfamily reunion kind of way.\n\n550\n00:27:46.110 --> 00:27:48.745\n&gt;&gt; That's right.\nAll roads lead back to Rome.\n\n551\n00:27:48.745 --> 00:27:49.580\n[LAUGH]\n&gt;&gt; That's for sure.\n\n552\n00:27:49.580 --> 00:27:53.960\nA couple of other things that they call\nout too, they call out for instance WPS,\n\n553\n00:27:53.960 --> 00:27:55.720\nWiFi Protected Setup.\n\n554\n00:27:55.720 --> 00:27:56.790\nThis should be disabled.\n\n555\n00:27:56.790 --> 00:28:03.050\nIn fact, when WiFi protect, let's talk\nabout what WiFi Protected setup is.\n\n556\n00:28:03.050 --> 00:28:05.055\nThis is convenience.\n\n557\n00:28:05.055 --> 00:28:05.854\nIt's what it boils down to.\n\n558\n00:28:05.854 --> 00:28:06.890\n&gt;&gt; Good intentions.\n\n559\n00:28:06.890 --> 00:28:10.310\n&gt;&gt; It's great intentions, but you gotta\nunderstand that in our little security\n\n560\n00:28:10.310 --> 00:28:15.280\nmetric here, convenience on one side,\nsecurity on the other.\n\n561\n00:28:15.280 --> 00:28:19.390\nAnd when we go to convenience,\nsecurity a lot of times drops.\n\n562\n00:28:19.390 --> 00:28:22.570\nAnd if we go to security,\ndid I say that right?\n\n563\n00:28:22.570 --> 00:28:23.330\nNo.\n&gt;&gt; Yeah.\n\n564\n00:28:23.330 --> 00:28:25.131\n&gt;&gt; Just make sure I say that right,\nthat's right.\n\n565\n00:28:25.131 --> 00:28:27.930\n&gt;&gt; Is security, and then we kind of have\na little bit more work to do, right?\n\n566\n00:28:27.930 --> 00:28:29.960\n&gt;&gt; That's right, and\na little bit less convenience.\n\n567\n00:28:29.960 --> 00:28:33.070\nWe increase the convenience, so\nwe can potentially have less security.\n\n568\n00:28:33.070 --> 00:28:34.700\nAnd that's what WPS is about.\n\n569\n00:28:34.700 --> 00:28:37.750\nWPS is about push button security.\n\n570\n00:28:37.750 --> 00:28:40.210\nBasically, what I do is I go\nover to the access point,\n\n571\n00:28:40.210 --> 00:28:45.000\nthere's a eight digit code,\nand I turn on WPS, and\n\n572\n00:28:45.000 --> 00:28:48.170\nthen in my properties of my wireless\ndevice I put in that eight digit code,\n\n573\n00:28:48.170 --> 00:28:51.430\nand in the background,\nit's supposed to set up security for us.\n\n574\n00:28:51.430 --> 00:28:56.730\nGreat intentions, good intentions,\nimplemented very poorly.\n\n575\n00:28:56.730 --> 00:28:59.680\nIt is a risk in the way that\nit does authentication,\n\n576\n00:28:59.680 --> 00:29:03.670\nit actually breaks those eight\nbits down into two chunks.\n\n577\n00:29:03.670 --> 00:29:07.860\nSo it really is authenticating\nfour characters at a time,\n\n578\n00:29:07.860 --> 00:29:08.970\nwhich is really, really weak.\n\n579\n00:29:08.970 --> 00:29:13.593\nSo anyways, WPS, Wi-Fi Protected Setup,\nwhen it first came out,\n\n580\n00:29:13.593 --> 00:29:17.898\nif you wanted to have\nthe Wi-Fi Alliance-type branding on it,\n\n581\n00:29:17.898 --> 00:29:21.028\nit had to support WPS and\nit had to be turned on.\n\n582\n00:29:21.028 --> 00:29:24.240\n&gt;&gt; And it's easy for\nhome users to use it, it's almost\n\n583\n00:29:24.240 --> 00:29:28.920\nlike a Yin-Yang symbol with two arrows\npointing in opposite directions.\n\n584\n00:29:28.920 --> 00:29:30.908\nSo tech support, they just say look for\nthat symbol and press it,\n\n585\n00:29:30.908 --> 00:29:31.531\nyou're good to go.\n\n586\n00:29:31.531 --> 00:29:35.200\nIt makes things convenience\nthere is super nice, but\n\n587\n00:29:35.200 --> 00:29:37.750\nnot at the risk of your security.\n\n588\n00:29:37.750 --> 00:29:40.530\n&gt;&gt; That's right, and so\nwhat ended up happening is that,\n\n589\n00:29:40.530 --> 00:29:43.330\nthey ended up doing firmware updates and\npushing out a lot of\n\n590\n00:29:43.330 --> 00:29:47.140\nthe major manufacturers, because it got\neven worst like, you would disable it in\n\n591\n00:29:47.140 --> 00:29:50.140\nthe interface of the access point but it\nwould still be running in the background.\n\n592\n00:29:50.140 --> 00:29:53.660\nIf you're doing wireless packet capture,\nor frame capture if you will,\n\n593\n00:29:53.660 --> 00:29:56.900\nyou could see that WPS was still on, even\nthough you turned it off in the setting.\n\n594\n00:29:56.900 --> 00:30:00.610\nSo, a lot of them came out with firmware\nupdates that would allow you to disable it\n\n595\n00:30:00.610 --> 00:30:03.627\ntruly, if you wanted to and\nthat's something that I recommend.\n\n596\n00:30:03.627 --> 00:30:07.609\nEspecially if you're in the Security Plus\nclass, you're not gonna be,\n\n597\n00:30:07.609 --> 00:30:11.014\ndon't take the convenience route\non this one, get in there and\n\n598\n00:30:11.014 --> 00:30:15.790\nconfigure your access points to support\nWPA2 preferably, and preferably with CCMP.\n\n599\n00:30:15.790 --> 00:30:19.980\nAnd we'll talk more about some\nof those concepts coming up.\n\n600\n00:30:19.980 --> 00:30:21.360\nWes, I think we are out of time.\n\n601\n00:30:21.360 --> 00:30:24.890\nWe've covered a lot of different types\nof wireless, well attacks in general.\n\n602\n00:30:24.890 --> 00:30:25.700\nAnd specifically,\n\n603\n00:30:25.700 --> 00:30:29.220\nthe last few we've been speaking\nabout were really focused on 802.11.\n\n604\n00:30:29.220 --> 00:30:32.360\nBut, we do have other types\nof wireless attacks to cover.\n\n605\n00:30:32.360 --> 00:30:34.330\nI think it'll be a great\nplace to pick right back up.\n\n606\n00:30:34.330 --> 00:30:35.870\nSo thank you for joining us.\n\n607\n00:30:35.870 --> 00:30:38.590\nAnd thank you ladies and gentlemen, but\nwe're gonna go ahead and sign out for\n\n608\n00:30:38.590 --> 00:30:39.390\nthis show.\n\n609\n00:30:39.390 --> 00:30:41.130\nRemember, I'm your host Cherokee Boose.\n\n610\n00:30:41.130 --> 00:30:41.900\n&gt;&gt; And I'm Wes Bryan.\n\n611\n00:30:41.900 --> 00:30:43.760\n&gt;&gt; See you next time here at ITPro.TV.\n\n612\n00:30:43.760 --> 00:30:51.140\n[MUSIC]\n\n613\n00:30:51.140 --> 00:30:54.072\n&gt;&gt; Thank you for watching ITPRO.TV\n\n",
          "vimeoId": "212753492"
        },
        {
          "description": "Cherokee and Wes continue speaking about wireless attack methods,  they specifically focus on wireless transmission attacks that may be associated with Bluetooth, RFID and NFC. Tune in to watch them round out this multi-part topic.",
          "length": "1380",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-4-types_of_attacks_pt4-040517.00_26_15_00.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-4-types_of_attacks_pt4-040517.00_26_15_00.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-2-4-types_of_attacks_pt4-040517.00_26_15_00.Still001-sm.jpg",
          "title": "Types of Attacks Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.240\nWelcome to ITProTV.\n\n2\n00:00:01.240 --> 00:00:02.499\nI'm your host, Don Pezet.\n\n3\n00:00:02.499 --> 00:00:06.286\n&gt;&gt; [CROSSTALK]\n\n4\n00:00:06.286 --> 00:00:08.321\n[MUSIC]\n\n5\n00:00:08.321 --> 00:00:12.083\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.083 --> 00:00:14.499\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n7\n00:00:14.499 --> 00:00:16.755\nI'm your show host Cherokee Boose.\n\n8\n00:00:16.755 --> 00:00:19.270\nWe've actually reached a part four of our\n\n9\n00:00:19.270 --> 00:00:21.670\nparticular topic that\nwe need to cover today.\n\n10\n00:00:21.670 --> 00:00:26.560\nAnd with us today we have Mr. Wes Bryan\nto look at additional types of attacks.\n\n11\n00:00:26.560 --> 00:00:27.850\nThank you for joining us today, Wes.\n\n12\n00:00:27.850 --> 00:00:29.270\n&gt;&gt; Hey, Cherokee thanks for\nhaving me here.\n\n13\n00:00:29.270 --> 00:00:31.140\nYep, that's right,\nlike I told you in the last one,\n\n14\n00:00:31.140 --> 00:00:34.775\nI think we are working on a small,\nshort Stephen King novel.\n\n15\n00:00:34.775 --> 00:00:37.600\n[LAUGH] But yeah,\nwe left off in the last episode,\n\n16\n00:00:37.600 --> 00:00:39.450\nwe were talking about\nwireless type of attacks.\n\n17\n00:00:39.450 --> 00:00:42.100\nSome of the things we were mentioning\nhere, if I look back to my notes,\n\n18\n00:00:42.100 --> 00:00:45.940\nwe were talking about things like,\nevil twins, rogue access points.\n\n19\n00:00:45.940 --> 00:00:50.070\nWe talked a little bit about the\ninitialization vectors, yeah, IV attacks,\n\n20\n00:00:50.070 --> 00:00:51.420\nas they call them.\n\n21\n00:00:51.420 --> 00:00:54.690\nAnd other things like WPS,\nWi-Fi protected set up.\n\n22\n00:00:54.690 --> 00:00:57.820\nKeep in mind, it should be, it is\nsomething that really should be disabled.\n\n23\n00:00:57.820 --> 00:01:03.650\nIt's more about convenience, and it kind\nof lowers the security of your systems.\n\n24\n00:01:03.650 --> 00:01:04.250\nWhat else?\n\n25\n00:01:04.250 --> 00:01:06.095\nWe talked a little bit about jamming,\n\n26\n00:01:06.095 --> 00:01:11.120\njamming being one of these things that\ncan cause denial of services as well.\n\n27\n00:01:12.230 --> 00:01:13.330\nAnd so picking back up,\n\n28\n00:01:13.330 --> 00:01:17.210\nwe still have a few more of these wireless\ntype attacks that we need to be aware of.\n\n29\n00:01:17.210 --> 00:01:20.526\nOne of the ones that they call out,\nthese are really Bluetooth attacks and\n\n30\n00:01:20.526 --> 00:01:21.338\nI love the names.\n\n31\n00:01:21.338 --> 00:01:25.850\nI've always loved the names on these,\nbluejacking and bluesnarfing.\n\n32\n00:01:25.850 --> 00:01:30.250\nWhen we look at these, again, if you\nare on the exam try to remember blue,\n\n33\n00:01:30.250 --> 00:01:32.750\nBluetooth, right,\nthe association there, and\n\n34\n00:01:32.750 --> 00:01:35.940\nit can help you out remembering\nwhat these are doing, okay.\n\n35\n00:01:35.940 --> 00:01:37.630\nA couple of different things\nthat they are doing here,\n\n36\n00:01:37.630 --> 00:01:41.100\nwhen we talk about bluejacking I want\nyou to think about hijacking, right.\n\n37\n00:01:41.100 --> 00:01:46.860\nWe talk about bluejacking, I'm gonna\nhijack your your communication for\n\n38\n00:01:46.860 --> 00:01:49.400\nthe purposes of using it, right.\n\n39\n00:01:49.400 --> 00:01:51.520\nHijack, right, bluejacking, if you will.\n\n40\n00:01:51.520 --> 00:01:53.990\nHijacking that bluetooth communication.\n\n41\n00:01:53.990 --> 00:01:55.650\nBluesnarfing, on the other hand,\n\n42\n00:01:55.650 --> 00:01:58.610\nis where I'm trying to actually\ngain access to your information.\n\n43\n00:01:58.610 --> 00:02:01.260\nSame Bluetooth attack, but\nI'm not really trying to piggyback\n\n44\n00:02:01.260 --> 00:02:04.090\noff of your Bluetooth\ncommunication to send my data.\n\n45\n00:02:04.090 --> 00:02:07.059\nI'm actually piggy backing off your\nBluetooth connection to try to scrape your\n\n46\n00:02:07.059 --> 00:02:07.642\ninformation.\n\n47\n00:02:07.642 --> 00:02:10.870\nSo, just a couple of\ndifferent Bluetooth attacks.\n\n48\n00:02:10.870 --> 00:02:17.000\nAnd it's one of the reasons it's good\nto have new Bluetooth technology.\n\n49\n00:02:17.000 --> 00:02:21.930\nBy now we should long be past the days of\nBluetooth one where it didn't have any\n\n50\n00:02:21.930 --> 00:02:23.230\nsecurity at all,\n\n51\n00:02:23.230 --> 00:02:27.170\ndid implement a little bit of more\nsecurity inside of Bluetooth version two.\n\n52\n00:02:27.170 --> 00:02:31.911\nI believe right now we're in four, four\none or so, but we're in Bluetooth four.\n\n53\n00:02:31.911 --> 00:02:36.655\nBluetooth three, this really,\nit improves security as well.\n\n54\n00:02:36.655 --> 00:02:40.523\nBut up until Bluetooth 4.0\nit was very power hungry.\n\n55\n00:02:40.523 --> 00:02:45.165\nThe Bluetooth 4.0 specification\nreally didn't do too much to change\n\n56\n00:02:45.165 --> 00:02:50.670\noverall speeds and distances as it\ndid to lower its power consumption.\n\n57\n00:02:50.670 --> 00:02:51.250\nAll right, so\n\n58\n00:02:51.250 --> 00:02:56.530\ndefinitely make sure that you are securing\nyour Bluetooth communications.\n\n59\n00:02:56.530 --> 00:02:58.755\n&gt;&gt; One thing I like to\nthink about with these two.\n\n60\n00:02:58.755 --> 00:03:02.290\nBluejacking, kind of like I remember\nreading a particular article,\n\n61\n00:03:02.290 --> 00:03:05.970\nScotland Yard was having an issue where\npeople were sending inappropriate\n\n62\n00:03:05.970 --> 00:03:08.790\nunsolicited images via Bluetooth.\n\n63\n00:03:08.790 --> 00:03:13.030\nSo sometimes you might get advertisements\nor unsolicited information,\n\n64\n00:03:13.030 --> 00:03:15.642\nwhereas bluesnarfing is\nkind of the opposite.\n\n65\n00:03:15.642 --> 00:03:20.880\nWhere they're usually looking to obtain\nyour contacts lists, your SMS messages, or\n\n66\n00:03:20.880 --> 00:03:25.300\nother information that could be relevant\nto some type of extortion, blackmail, or\n\n67\n00:03:25.300 --> 00:03:28.030\nwhatever nefarious purpose that\nthey intend to use it for.\n\n68\n00:03:28.030 --> 00:03:30.450\n&gt;&gt; Yeah Cherokee, that's one of the things\nthat helped me on the exam is just\n\n69\n00:03:30.450 --> 00:03:33.580\nremembering, okay,\nbluejacking I'm sending my information,\n\n70\n00:03:33.580 --> 00:03:36.390\nbluesnarfing I want your information.\n\n71\n00:03:36.390 --> 00:03:38.520\nSo, the direction of the attack, right.\n\n72\n00:03:38.520 --> 00:03:40.980\nSome of the other things that they\ncall out when it comes to wireless\n\n73\n00:03:40.980 --> 00:03:44.690\ncommunications, and this is definitely\nbecoming more and more prevalent today,\n\n74\n00:03:44.690 --> 00:03:47.850\nis NFC, right,\nnear-field communication, right.\n\n75\n00:03:47.850 --> 00:03:51.940\nFor instance we have things like RFID,\nradio frequency identifiers.\n\n76\n00:03:51.940 --> 00:03:55.440\nI think if I have one,\nI think cards like this right here that\n\n77\n00:03:55.440 --> 00:03:58.630\ncan have some embedded logic in them and\nstuff.\n\n78\n00:03:58.630 --> 00:04:01.280\nBasically NFC attacks,\ndifferent standards, right.\n\n79\n00:04:01.280 --> 00:04:05.230\nRFID is an example of one of them,\nproximity cards, identification cards,\n\n80\n00:04:05.230 --> 00:04:11.310\ncontact list integrated circuits as well,\nsmart cards.\n\n81\n00:04:11.310 --> 00:04:13.860\nKeep in mind that they all\nhave a standardization\n\n82\n00:04:13.860 --> 00:04:17.890\nbecause the international\ninteroperability that they want.\n\n83\n00:04:17.890 --> 00:04:21.230\nThese can stand some different\ntypes of attack, right.\n\n84\n00:04:21.230 --> 00:04:24.960\nIt could be for things like eavesdropping,\ndata modification.\n\n85\n00:04:24.960 --> 00:04:27.990\nYou look at near-field communications,\nright, what is near-field communication?\n\n86\n00:04:27.990 --> 00:04:29.980\nBut again, it's a convenience technology.\n\n87\n00:04:29.980 --> 00:04:31.040\nIt's a really good technology and\n\n88\n00:04:31.040 --> 00:04:34.510\nI don't want you to think anything out\nthere that's convenient stay away from.\n\n89\n00:04:34.510 --> 00:04:35.580\nThat's not what I mean.\n\n90\n00:04:35.580 --> 00:04:38.520\nBut think about the ability\nto take a file, right.\n\n91\n00:04:38.520 --> 00:04:40.730\nI need to figure out, okay,\nI've got this file on my phone and\n\n92\n00:04:40.730 --> 00:04:42.750\nI really need to send it to Cherokee.\n\n93\n00:04:42.750 --> 00:04:45.600\nWe just touch our phones together,\nboom, files transferred.\n\n94\n00:04:45.600 --> 00:04:47.140\nProblem is,\nif somebody can get in there and\n\n95\n00:04:47.140 --> 00:04:50.190\nthey can manipulate the convenience,\nif you will.\n\n96\n00:04:50.190 --> 00:04:53.120\nThat's when they do things like\neavesdropping, replay attacks,\n\n97\n00:04:53.120 --> 00:04:56.960\ndata modification,\nman in the middle, spoofing, and\n\n98\n00:04:56.960 --> 00:04:58.790\neven things like mobile malware, right.\n\n99\n00:04:58.790 --> 00:05:01.700\nIf it's that easy to transfer\na file between devices,\n\n100\n00:05:01.700 --> 00:05:04.970\nif people can attack this\ntype of communication,\n\n101\n00:05:04.970 --> 00:05:08.390\nhow easy would it be to transfer\nmalware right directly to your phone?\n\n102\n00:05:08.390 --> 00:05:10.140\nSo again, it is something\nthat you have to worry about.\n\n103\n00:05:10.140 --> 00:05:14.270\nAnd again, RFID is one of those\nnear-field communication types that also\n\n104\n00:05:14.270 --> 00:05:16.260\nfalls under this.\n\n105\n00:05:16.260 --> 00:05:17.470\n&gt;&gt; Short range wireless, yeah.\n\n106\n00:05:17.470 --> 00:05:21.800\n&gt;&gt; That's right, they also called out\nother things like a dissociation attack,\n\n107\n00:05:21.800 --> 00:05:24.372\nand this is another form wireless\ndenial of service attack.\n\n108\n00:05:24.372 --> 00:05:31.460\nWhen you connect to a wireless network,\nright, you're station,\n\n109\n00:05:31.460 --> 00:05:37.190\nSTA, contacts the access point within\nan association request, right.\n\n110\n00:05:37.190 --> 00:05:38.590\nThen there's authentication.\n\n111\n00:05:38.590 --> 00:05:43.550\nThen once the authentication happens,\nthere's another association process\n\n112\n00:05:43.550 --> 00:05:48.220\nthat hey we know who you are, we trust\nyou, you can join the access point.\n\n113\n00:05:48.220 --> 00:05:52.670\nNow they also have things where you have,\nfor instance, distributed access points,\n\n114\n00:05:52.670 --> 00:05:56.790\nright, if you're doing something like\nwhere you have an extended service set.\n\n115\n00:05:56.790 --> 00:06:00.010\nAnd the extended service set\nhas more than one access point.\n\n116\n00:06:00.010 --> 00:06:04.620\nWell your computer uses\na signal strength indicator,\n\n117\n00:06:04.620 --> 00:06:09.030\nand what it does is as that strength,\nI think it's called RSSI.\n\n118\n00:06:09.030 --> 00:06:13.410\nAs it moves away from one access point and\nit starts to weaken the signal strength,\n\n119\n00:06:13.410 --> 00:06:17.330\nit starts to look at the next access\npoint that's in that extended system, or\n\n120\n00:06:17.330 --> 00:06:19.750\ndistributed wireless system.\n\n121\n00:06:19.750 --> 00:06:23.909\nAnd it says okay, I'm gonna go ahead and\nI'm gonna use a dissociation signal and\n\n122\n00:06:23.909 --> 00:06:27.334\nsend it back to the access point\nthat I'm losing the strength, and\n\n123\n00:06:27.334 --> 00:06:29.799\nI'm gonna join the next access point,\nright.\n\n124\n00:06:29.799 --> 00:06:32.907\nSo it lets the other access point go,\nhey, you don't have to manage me anymore,\n\n125\n00:06:32.907 --> 00:06:34.888\nthe next access point's gonna pick it up,\nright.\n\n126\n00:06:34.888 --> 00:06:39.072\nIt gives us that seamless communication\nas we move around our location,\n\n127\n00:06:39.072 --> 00:06:41.055\nour building, if you will.\n\n128\n00:06:41.055 --> 00:06:45.850\nAnd we hop between\ndifferent access points.\n\n129\n00:06:45.850 --> 00:06:48.310\nNow imagine that dissociation request.\n\n130\n00:06:48.310 --> 00:06:51.746\nIf I can capture that, or\nif I can craft a frame, right.\n\n131\n00:06:51.746 --> 00:06:56.485\nCherokee's wireless device is connected to\nthe network, it's fine, there should be no\n\n132\n00:06:56.485 --> 00:07:01.230\ndisassociation, and I send a packet\nat it matching her MAC address.\n\n133\n00:07:01.230 --> 00:07:04.320\nI send a frame if you will at\nthe access point that says,\n\n134\n00:07:04.320 --> 00:07:06.150\nI don't wanna be associated any more.\n\n135\n00:07:06.150 --> 00:07:06.800\nSo what happens?\n\n136\n00:07:06.800 --> 00:07:11.070\nThe access point says okay,\ncheck paid, let you go.\n\n137\n00:07:11.070 --> 00:07:14.630\nNow you no longer have communications\nwith wireless access point, right.\n\n138\n00:07:14.630 --> 00:07:15.520\nThis is something you can have.\n\n139\n00:07:15.520 --> 00:07:18.400\nIt's basically a deauthentication attack.\n\n140\n00:07:18.400 --> 00:07:20.670\nI don't wanna be part of\nthe network anymore, and\n\n141\n00:07:20.670 --> 00:07:25.010\nyou can actually kick people off\nof a wireless network doing this.\n\n142\n00:07:25.010 --> 00:07:29.510\nThey do this thing with different types\nof attacks like air dump and air cracking\n\n143\n00:07:29.510 --> 00:07:35.156\ninside of your Linux based systems as\nwell, can do these disassociation attacks.\n\n144\n00:07:35.156 --> 00:07:39.470\nEssentially, it's a form of\nwireless denial of service attack.\n\n145\n00:07:39.470 --> 00:07:44.720\nNow that being said, we move into\nsome different types of attacks.\n\n146\n00:07:44.720 --> 00:07:46.718\nOne of the things that they call out,\n\n147\n00:07:46.718 --> 00:07:49.699\nis they call out things like\nthe birthday attack here.\n\n148\n00:07:49.699 --> 00:07:52.968\nBirthday attack is just based\noff the birthday paradox,\n\n149\n00:07:52.968 --> 00:07:56.917\nand it says out of a random gathering\nof a group of 23 people there's\n\n150\n00:07:56.917 --> 00:08:01.150\n50% chance that two people\nwill have the same birthday.\n\n151\n00:08:01.150 --> 00:08:05.120\nNow, This is about hashing values, right?\n\n152\n00:08:05.120 --> 00:08:07.780\nIf you look at like a hashing\ncollision attack, right?\n\n153\n00:08:07.780 --> 00:08:10.620\nWe kind of already talked about that.\n\n154\n00:08:10.620 --> 00:08:12.640\nWith this type, it says that,\n\n155\n00:08:12.640 --> 00:08:16.750\nbasically, with a given hash if\nI know what the hash value is,\n\n156\n00:08:16.750 --> 00:08:21.480\nit's harder to make a collision with\na known hash than with any random hash.\n\n157\n00:08:21.480 --> 00:08:25.510\nTwo random hashes could\nhave identical values, and\n\n158\n00:08:25.510 --> 00:08:30.730\nthat's gonna be a little bit easier to\nfind than with a specific given hash.\n\n159\n00:08:30.730 --> 00:08:34.628\nSome of the other things that they\ntalk about are known plain text and\n\n160\n00:08:34.628 --> 00:08:37.040\nknown Ciphertext attacks.\n\n161\n00:08:37.040 --> 00:08:41.095\nAgain, let me try that one more time and\nsay it in English, known plaintext and\n\n162\n00:08:41.095 --> 00:08:43.440\nknown Ciphertext attacks.\n\n163\n00:08:43.440 --> 00:08:45.200\nWhen we have known plaintext,\n\n164\n00:08:45.200 --> 00:08:48.990\nit means you know what's going\ninto the cipher sweep, so you\n\n165\n00:08:48.990 --> 00:08:53.000\ntry to manipulate it based on what you've\nalready seen inside of the plaintext.\n\n166\n00:08:53.000 --> 00:08:58.550\nKnown cipher attack is where you really\ndon't know what the plaintext is,\n\n167\n00:08:58.550 --> 00:09:00.510\nbut maybe you have limited knowledge.\n\n168\n00:09:00.510 --> 00:09:04.320\nYou might know that the person\nis typing in English, right?\n\n169\n00:09:04.320 --> 00:09:07.340\nDoesn't say that the encryption has to\nfollow that, but you might know at least\n\n170\n00:09:07.340 --> 00:09:12.130\nmaybe that much, but only two pieces\nof the Ciphertext are available,\n\n171\n00:09:12.130 --> 00:09:15.700\nand there's very little knowledge\nof the plaintext input, right?\n\n172\n00:09:15.700 --> 00:09:17.950\nWhere do we see known Ciphertext attacks?\n\n173\n00:09:17.950 --> 00:09:21.494\nRemember I was telling you about WEP,\n\n174\n00:09:21.494 --> 00:09:27.030\nWEP is a form of that\nWEP Initialization Vector attack?\n\n175\n00:09:27.030 --> 00:09:30.670\nIt could be considered a form of\na known Ciphertext attack, right?\n\n176\n00:09:30.670 --> 00:09:34.590\nWe know what the Ciphertext,\nI have the encrypted information, right?\n\n177\n00:09:34.590 --> 00:09:38.490\nBut I'm manipulating things\naround the encypher, right?\n\n178\n00:09:38.490 --> 00:09:44.200\nI'm manipulating the initialization vector\nin order to break into the communication.\n\n179\n00:09:44.200 --> 00:09:49.220\nSome other examples of where you could\nsee things like known cypher attacks\n\n180\n00:09:49.220 --> 00:09:54.020\nis in the earlier PPTP Implementations,\npoint-to-point tunneling protocol.\n\n181\n00:09:54.020 --> 00:09:57.580\nIt used a weak RC4 stream cipher.\n\n182\n00:09:57.580 --> 00:10:01.490\nAnd that stream cipher was based on\nthe same key, on both ends, right?\n\n183\n00:10:01.490 --> 00:10:05.880\nAnd so we know, if we can get a hold\nof the key, we can have the ciphertext.\n\n184\n00:10:05.880 --> 00:10:10.330\nWe don't really need to know what\nthe plaintext is, in order to attack it.\n\n185\n00:10:10.330 --> 00:10:15.050\nSome of the other things that they call\nout here are rainbow tables, all right.\n\n186\n00:10:15.050 --> 00:10:16.830\nRainbow tables is really,\n\n187\n00:10:16.830 --> 00:10:22.290\nin assisting things like\ncracking of passwords, all right.\n\n188\n00:10:22.290 --> 00:10:26.210\nIt takes a lot of computational power for\na device to crack a password.\n\n189\n00:10:26.210 --> 00:10:32.370\nEspecially if you're talking about going\nthrough large numbers of potential values.\n\n190\n00:10:32.370 --> 00:10:36.810\nSo a rainbow table is one that kinda,\nit's a pre computed table, right.\n\n191\n00:10:36.810 --> 00:10:39.880\nIt already has a series of answers in it.\n\n192\n00:10:39.880 --> 00:10:44.290\nAnd it assists the CPU processing, right,\nby just looking at the table, right,\n\n193\n00:10:44.290 --> 00:10:47.490\nrather than having to guess and\nsit here and guess and do its own logic,\n\n194\n00:10:47.490 --> 00:10:51.470\nand do its own arithmetic, it just\nlooks at that pre-computed table and\n\n195\n00:10:51.470 --> 00:10:53.519\nit tries to speed up the process.\n\n196\n00:10:54.560 --> 00:10:55.680\nOther attacks that they call out,\n\n197\n00:10:55.680 --> 00:10:58.010\nthey call out things like\ndictionary attacks, right?\n\n198\n00:10:58.010 --> 00:11:00.600\nI know you've heard of this term before.\n\n199\n00:11:00.600 --> 00:11:04.660\nThey talk about forbidden character\nstrings, right, in your passwords, right?\n\n200\n00:11:04.660 --> 00:11:09.040\nWe say no person, place,\nthing, no nouns, right?\n\n201\n00:11:09.040 --> 00:11:12.100\nNothing that could be found\nin a dictionary, why?\n\n202\n00:11:12.100 --> 00:11:14.260\nWell if we can take the entire dictionary,\nand\n\n203\n00:11:14.260 --> 00:11:18.340\nwe can load it up into a database, and\nwe can run a scan against your password,\n\n204\n00:11:18.340 --> 00:11:21.180\nagainst every known word\nin that dictionary.\n\n205\n00:11:21.180 --> 00:11:24.250\nCuz people sometimes do\nuse dictionary words,\n\n206\n00:11:24.250 --> 00:11:25.080\nright-\n&gt;&gt; They can.\n\n207\n00:11:25.080 --> 00:11:26.720\n&gt;&gt; They can,\nit's a forbidden character string, and\n\n208\n00:11:26.720 --> 00:11:28.970\nthat means you shouldn't be using it\n&gt;&gt; But\n\n209\n00:11:28.970 --> 00:11:33.100\nif somebody uses something like I love\nmy cats, that's my password, right?\n\n210\n00:11:33.100 --> 00:11:36.950\nEvery one of those words in that\npassword is part of the dictionary.\n\n211\n00:11:36.950 --> 00:11:40.640\nAnd we can potentially crack it by\nreferencing it against the database,\n\n212\n00:11:40.640 --> 00:11:41.380\na dictionary words.\n\n213\n00:11:41.380 --> 00:11:45.790\nThat's one of the reasons you never\nwant to use those, all right?\n\n214\n00:11:45.790 --> 00:11:48.320\nOther things Brute force attack all right?\n\n215\n00:11:48.320 --> 00:11:54.660\nBrute force attack is essentially\nyou're just every single combination\n\n216\n00:11:54.660 --> 00:12:00.430\nthat you could potentially put from\nthe keyboard is going to be typed.\n\n217\n00:12:00.430 --> 00:12:02.170\nYou just keep guessing and guessing and\n\n218\n00:12:02.170 --> 00:12:06.820\nguessing until hopefully you\nfinally gain access, all right?\n\n219\n00:12:08.120 --> 00:12:10.580\nCollision attacks,\nwe've also talked about collision attacks.\n\n220\n00:12:10.580 --> 00:12:14.940\nKeep in mind, collision attacks are when\nyou're trying to produce the same hash\n\n221\n00:12:14.940 --> 00:12:19.490\nvalue regardless of what\nthe input was that went into\n\n222\n00:12:19.490 --> 00:12:23.080\nthe hashing digest if you will.\n\n223\n00:12:24.210 --> 00:12:26.770\nSome of the collision attacks that or\n\n224\n00:12:26.770 --> 00:12:31.450\ntechnologies that are Susceptible\nto collision attacks NTLM.\n\n225\n00:12:31.450 --> 00:12:35.260\nThe NT Lan Manager, right,\nit would store all of your\n\n226\n00:12:35.260 --> 00:12:38.720\nhash values down in the SAM file,\nI believe it was, in the earlier days.\n\n227\n00:12:38.720 --> 00:12:40.860\nAnd if I could get access to that file,\nright.\n\n228\n00:12:40.860 --> 00:12:44.220\nI have all the hash values to your\npasswords, I didn't need your passwords.\n\n229\n00:12:44.220 --> 00:12:46.970\nA collision attack though is when\nthey're trying to find the values, or\n\n230\n00:12:46.970 --> 00:12:50.010\ntrying to find some character\nstring that they can type\n\n231\n00:12:50.010 --> 00:12:51.690\n&gt;&gt; That produces that same hash value.\n\n232\n00:12:52.760 --> 00:12:54.480\nWhen you have two\nidentical hashes like that,\n\n233\n00:12:54.480 --> 00:12:56.320\nthat's the collusion that\nthey're talking about.\n\n234\n00:12:56.320 --> 00:12:59.380\nAnd remember, anything that's been\nhashed like that, from using it for\n\n235\n00:12:59.380 --> 00:13:04.140\nauthentication, just like\nthe past hash attack, we can\n\n236\n00:13:04.140 --> 00:13:08.970\nthen present the hash value, if you will,\nafter we get the collusion performed.\n\n237\n00:13:08.970 --> 00:13:13.190\nSome of the other things that\nare collusion MD5, right?\n\n238\n00:13:13.190 --> 00:13:15.990\nMD5 is one that they say\nnot to use any more.\n\n239\n00:13:15.990 --> 00:13:17.460\nI'm gonna throw this one out there,\n\n240\n00:13:17.460 --> 00:13:22.856\nI know it's still debatable because\nit's theoretical, SHA-1, 160-bit secure\n\n241\n00:13:22.856 --> 00:13:28.140\nhashing algorithm Theoretically,\nit has been cracked, Google cracked it.\n\n242\n00:13:28.140 --> 00:13:31.410\nSo, really, if you, you know,\nif you're going to use hashing algorithms,\n\n243\n00:13:31.410 --> 00:13:34.020\nyou should be use something like Shaw 256,\nright?\n\n244\n00:13:34.020 --> 00:13:38.660\n256 bit characters, and they have them\nhigher than that, 384 and 512 as well.\n\n245\n00:13:40.040 --> 00:13:43.195\nAll right.\n&gt;&gt; Some systems [INAUDIBLE],\n\n246\n00:13:43.195 --> 00:13:46.180\nyou might just come across that in some of\n\n247\n00:13:46.180 --> 00:13:47.980\nyour configuration duties.\n\n248\n00:13:47.980 --> 00:13:48.630\n&gt;&gt; Most definitely.\n\n249\n00:13:48.630 --> 00:13:52.390\nThat actually lends itself to the next\nthing that we have to talk about,\n\n250\n00:13:52.390 --> 00:13:55.030\nbecause if they don't disable it, right?\n\n251\n00:13:55.030 --> 00:13:57.270\nThe utilization of a weaker type hash,\n\n252\n00:13:57.270 --> 00:14:00.540\nthat can what's known\nas a downgrade attack.\n\n253\n00:14:00.540 --> 00:14:01.340\nWell, it's a downgrade attack.\n\n254\n00:14:01.340 --> 00:14:04.640\nWell, I want you to think about the fact\nthat you got maybe Legacy devices\n\n255\n00:14:04.640 --> 00:14:08.280\non your systems, or\nwithin your systems, right, networks.\n\n256\n00:14:08.280 --> 00:14:11.510\nWe have a system that maybe only supports,\ndoesn't support AES,\n\n257\n00:14:11.510 --> 00:14:14.295\nonly maybe supports WP\n[INAUDIBLE] cuz maybe it's old.\n\n258\n00:14:14.295 --> 00:14:19.225\n&gt;&gt; So, Wes, a school that I used to\nwork at we had a student come in\n\n259\n00:14:19.225 --> 00:14:21.095\nwith a laptop running XP.\n\n260\n00:14:21.095 --> 00:14:24.485\nThey really enjoyed that operating system,\nhasn't been supported for\n\n261\n00:14:24.485 --> 00:14:25.335\na long while now.\n\n262\n00:14:25.335 --> 00:14:29.965\nAnd they weren't able to connect\nto our wireless access point.\n\n263\n00:14:29.965 --> 00:14:33.895\nAnd well I handed them a cable\nbecause we're not gonna take and\n\n264\n00:14:33.895 --> 00:14:38.040\nrisk The other systems within\nthat wireless access network,\n\n265\n00:14:38.040 --> 00:14:41.760\nthat wireless network, and\ndowngrade it to a lower\n\n266\n00:14:41.760 --> 00:14:46.730\nlevel to support web encryption\nbecause of one individual user.\n\n267\n00:14:46.730 --> 00:14:48.700\nSo that's an example there.\n\n268\n00:14:48.700 --> 00:14:49.270\n&gt;&gt; Most definitely.\n\n269\n00:14:49.270 --> 00:14:50.600\nThe other place that you can see this,\n\n270\n00:14:50.600 --> 00:14:55.170\ntoo, is in things like\nSSL We say SSL today but\n\n271\n00:14:55.170 --> 00:14:58.610\nlargely what we're using is TLS, transport\nlayer security, in the background.\n\n272\n00:14:58.610 --> 00:15:01.790\nBut SSL would allow the negotiation for\na weaker cyber strength.\n\n273\n00:15:01.790 --> 00:15:02.710\nRight?\n\n274\n00:15:02.710 --> 00:15:06.280\nYour browser basically tells the website,\nwell this is what I support.\n\n275\n00:15:06.280 --> 00:15:08.362\nI don't support SSL 3.0.\n\n276\n00:15:08.362 --> 00:15:10.370\nI only support 2.0.\n\n277\n00:15:10.370 --> 00:15:10.930\nRight?\n\n278\n00:15:10.930 --> 00:15:15.330\nAnd SSL would allow the for backwards\ncompatibility, that downgrading to\n\n279\n00:15:15.330 --> 00:15:20.010\na weaker cyber strength and again\nthat lends itself To a vulnerability.\n\n280\n00:15:20.010 --> 00:15:22.650\nAnd somebody can definitely\nexploit that as well.\n\n281\n00:15:24.050 --> 00:15:28.160\nAll right, so\nthey also call out replays again guys.\n\n282\n00:15:28.160 --> 00:15:33.370\nAnd I'm kinda sure we've taken care\nof replays in many cases here.\n\n283\n00:15:33.370 --> 00:15:36.510\nJust as a recap, just remember,\nif can capture information that\n\n284\n00:15:36.510 --> 00:15:41.750\nmakes it appear that as I present\nit back to the server as you.\n\n285\n00:15:41.750 --> 00:15:43.230\nThat's a replay attack.\n\n286\n00:15:43.230 --> 00:15:47.150\nWe use things like time stamping and\nnumber sequencing,\n\n287\n00:15:47.150 --> 00:15:51.430\nif you will,\nthat helps to try to mitigate it.\n\n288\n00:15:51.430 --> 00:15:55.020\nIt can't completely eliminate it, but at\nleast mitigate the risk of that happening.\n\n289\n00:15:55.020 --> 00:15:59.625\nOne of the last things that we kind\nof need to talk about are weak\n\n290\n00:15:59.625 --> 00:16:01.139\nimplementations.\n\n291\n00:16:01.139 --> 00:16:05.322\nSo, I've got some of the considerations\nthat I want us to Consider here,\n\n292\n00:16:05.322 --> 00:16:08.299\non my screen here, so,\nif we could take a look at it.\n\n293\n00:16:08.299 --> 00:16:10.912\nWhen we look at some of\nthe weak considerations,\n\n294\n00:16:10.912 --> 00:16:14.110\nI'm gonna put cipher\nconsiderations in here, all right?\n\n295\n00:16:14.110 --> 00:16:15.160\nWeak implementations,\n\n296\n00:16:15.160 --> 00:16:18.310\nI want you to think about, we've got\na whole different bunch of protocols.\n\n297\n00:16:18.310 --> 00:16:23.020\nAnd remember, as the protocol goes\nthrough a revision, you get enhancements.\n\n298\n00:16:23.020 --> 00:16:25.034\nBut a lot of times,\nwhen we're talking about cipher stream,\n\n299\n00:16:25.034 --> 00:16:26.632\nyou get a stronger level of encryption,\nright?\n\n300\n00:16:26.632 --> 00:16:30.440\nSo SSL 2.0 versus 3.0.\n\n301\n00:16:30.440 --> 00:16:34.914\nNow, I'm saying that, you really shouldn't\nbe implementing SSL on your machines\n\n302\n00:16:34.914 --> 00:16:37.790\ntoday, so\nwe really should be implementing TLS.\n\n303\n00:16:37.790 --> 00:16:40.005\nWell, TLS has different versions too,\nright?\n\n304\n00:16:40.005 --> 00:16:44.524\nTLS 1.0,\npretty much almost identical to SSL 3.0.\n\n305\n00:16:44.524 --> 00:16:48.010\nBut there was enough change in them that\nthey're not compatible with one another.\n\n306\n00:16:48.010 --> 00:16:53.020\nAnd you have to know that, that hey,\nI should be implementing TLS 1.2 if I can,\n\n307\n00:16:53.020 --> 00:16:56.919\nTransport Layer Security over 1.1 and 1.0.\n\n308\n00:16:56.919 --> 00:16:57.900\nOther things too,\n\n309\n00:16:57.900 --> 00:17:02.000\nwe've already kinda talked about this and\nwe talk about wireless, right?\n\n310\n00:17:02.000 --> 00:17:04.650\nI should not be implementing WEP, right?\n\n311\n00:17:04.650 --> 00:17:07.380\nIf anything, I should be implementing WPA.\n\n312\n00:17:07.380 --> 00:17:07.950\nAnd not even WPA,\n\n313\n00:17:07.950 --> 00:17:11.670\nbecause it's known that you could\ndo a brute force attack against it.\n\n314\n00:17:11.670 --> 00:17:16.625\nSo if we're gonna get around a weak\nimplementation, we should be using WPA2.\n\n315\n00:17:17.810 --> 00:17:21.320\nAlso, some of the options that\nyou have with both WPA and\n\n316\n00:17:21.320 --> 00:17:26.090\nWPA2, Temporal Key Integrity Protocol\nversus CCMP, right?\n\n317\n00:17:26.090 --> 00:17:28.902\nTKIP has been known to have\nits vulnerabilities today.\n\n318\n00:17:28.902 --> 00:17:33.362\nSo it's replaced, right, with the counter\nmode cipher block chaining message\n\n319\n00:17:33.362 --> 00:17:35.210\nauthentication code protocol.\n\n320\n00:17:35.210 --> 00:17:36.540\nThat one's a hard one.\n\n321\n00:17:36.540 --> 00:17:39.250\nI'm surprised we can\nremember that one there.\n\n322\n00:17:39.250 --> 00:17:44.334\nBut again, it lets you take advantage of\nthings like AES versus taking the earlier\n\n323\n00:17:44.334 --> 00:17:49.850\nRC Stream site from basically putting\na band-aid over a bullet hole, right?\n\n324\n00:17:49.850 --> 00:17:53.710\nSo TKIP is something that you\nshouldn't be using today,\n\n325\n00:17:53.710 --> 00:17:58.150\nversus using CCMP and that also\ngoes back to our downgrade attack.\n\n326\n00:17:58.150 --> 00:18:01.590\nI've had systems in the past\nthat I couldn't do a CCMP.\n\n327\n00:18:02.590 --> 00:18:05.170\nIt just wouldn't take it,\nit wouldn't even connect to the network.\n\n328\n00:18:05.170 --> 00:18:06.119\nSo what did I do?\n\n329\n00:18:06.119 --> 00:18:07.383\nWhat I'm telling you not to do.\n\n330\n00:18:07.383 --> 00:18:11.016\nWell I'll be the first one to tell you,\nbecause I had to do it to get those old\n\n331\n00:18:11.016 --> 00:18:13.745\nAndroid clients that I wanted\nto connect to my network.\n\n332\n00:18:13.745 --> 00:18:17.785\nI had to go back to TKIP,\nit wouldn't do CCMP for whatever reason.\n\n333\n00:18:17.785 --> 00:18:20.583\nToday, it's not a problem, but\nit was a problem a couple years ago.\n\n334\n00:18:20.583 --> 00:18:24.340\nI'm sure by now, that's not a problem\nanymore with most of your major operating\n\n335\n00:18:24.340 --> 00:18:27.275\nsystems and\nyour devices that are released today.\n\n336\n00:18:27.275 --> 00:18:28.465\nThere's other things too, right?\n\n337\n00:18:28.465 --> 00:18:33.300\nNow I'm not worried so much about the\ntunneling protocols here, PPTP and L2TP.\n\n338\n00:18:33.300 --> 00:18:36.870\nI'm more focused on what's on\nafter the forward slash, right?\n\n339\n00:18:36.870 --> 00:18:40.655\nPoint to point tunneling protocol,\nuses something known as MPPE for\n\n340\n00:18:40.655 --> 00:18:43.180\nits encryption,\nMicrosoft Point to Point Encryption.\n\n341\n00:18:43.180 --> 00:18:46.270\nIt uses 40 or 56-bit key links,\n\n342\n00:18:46.270 --> 00:18:50.260\nI believe somewhere right around there,\nvery weak there, right?\n\n343\n00:18:50.260 --> 00:18:51.739\nLet me think, it's 64-bit.\n\n344\n00:18:51.739 --> 00:18:53.425\nSo it's a very weak encryption, right?\n\n345\n00:18:53.425 --> 00:18:55.329\nSo yes you have a tunneling protocol,\nright?\n\n346\n00:18:55.329 --> 00:18:57.511\nYou have encrypted data going\nthrough that tunnel but\n\n347\n00:18:57.511 --> 00:19:00.187\nthe encryption protocol that\nyou're using is relatively weak.\n\n348\n00:19:00.187 --> 00:19:03.467\nAnd that's why it's important if\nyou're worried about security,\n\n349\n00:19:03.467 --> 00:19:07.154\ndon't do a weak implementation of PPTP\neven though it's widely supported.\n\n350\n00:19:07.154 --> 00:19:09.820\nYou use L2TP and I'm not worried.\n\n351\n00:19:09.820 --> 00:19:13.659\nLike I said, this isn't so much the focus\non the tunneling protocol, but this is\n\n352\n00:19:13.659 --> 00:19:17.511\nthe tunneling protocol you're gonna use so\nthat you can utilize IPSec, right?\n\n353\n00:19:17.511 --> 00:19:21.821\nIt's a much stronger implementation than\nthe earlier point to point tunneling\n\n354\n00:19:21.821 --> 00:19:25.640\nprotocol with Microsoft's\npoint to point encryption.\n\n355\n00:19:25.640 --> 00:19:27.230\nOther things, as an example, right?\n\n356\n00:19:27.230 --> 00:19:30.630\nWe talked a little bit about WEP and\nI mentioned the RC4 stream cipher.\n\n357\n00:19:30.630 --> 00:19:35.750\nIt is a vulnerable,\nI don't even know how to say it.\n\n358\n00:19:35.750 --> 00:19:37.740\nIt's an exploitable stream cipher, right?\n\n359\n00:19:37.740 --> 00:19:42.430\nToday, if you're using anything,\nyou should be using the RC5.\n\n360\n00:19:42.430 --> 00:19:43.535\nIt's a block cipher, right?\n\n361\n00:19:43.535 --> 00:19:48.320\nSo that's a Ron Rivesta,\nyou might hear this called Rivest code, or\n\n362\n00:19:48.320 --> 00:19:50.320\nRon's code, if you will.\n\n363\n00:19:50.320 --> 00:19:54.720\nBut you need to be implementing\nRC5 rather than RC4.\n\n364\n00:19:56.100 --> 00:19:58.030\nNow, some of the other ones that we got,\nright?\n\n365\n00:19:58.030 --> 00:20:01.700\nWe talked about the Data Encryption\nStandard, right, and then 3DES, right?\n\n366\n00:20:01.700 --> 00:20:03.310\nWell those are are older standards.\n\n367\n00:20:03.310 --> 00:20:05.255\nDES shouldn't even really\neven be used anymore.\n\n368\n00:20:05.255 --> 00:20:09.400\n3DES is still used in combination with\nother technologies like in IPsec,\n\n369\n00:20:09.400 --> 00:20:10.986\nthat's something that you can use.\n\n370\n00:20:10.986 --> 00:20:14.160\nBut there's a lot of other\ntechnologies that surround it\n\n371\n00:20:14.160 --> 00:20:17.920\nthat don't make it by itself vulnerable,\nif that makes sense.\n\n372\n00:20:17.920 --> 00:20:19.858\nSo you shouldn't be using 3DES.\n\n373\n00:20:19.858 --> 00:20:21.165\nYou should be using AES, right?\n\n374\n00:20:21.165 --> 00:20:24.725\nRight now AES, 256-bit,\nis the current standard for\n\n375\n00:20:24.725 --> 00:20:27.970\nthe DOD when it comes to\ntop secret documentations.\n\n376\n00:20:27.970 --> 00:20:32.050\nIf the military's using it, then\nchances are it'll be pretty strong for\n\n377\n00:20:32.050 --> 00:20:34.330\nyour home environment as well, too.\n\n378\n00:20:34.330 --> 00:20:36.200\nAnd I think that's really all I got.\n\n379\n00:20:36.200 --> 00:20:39.798\nSo those are just some examples\nof weak implementations, guys.\n\n380\n00:20:39.798 --> 00:20:43.760\nKnowing your protocols, knowing which\none it is that you're gonna implement\n\n381\n00:20:43.760 --> 00:20:47.390\nis going to make your life a lot better.\n\n382\n00:20:47.390 --> 00:20:50.169\nI didn't put some of these up here,\ntoo, so let me go ahead and\n\n383\n00:20:50.169 --> 00:20:51.409\nmention these real quick.\n\n384\n00:20:51.409 --> 00:20:54.299\nIf you're using WPA2,\nare there implementations that\n\n385\n00:20:54.299 --> 00:20:57.390\ncan make it a little bit\nstronger in a corporate network?\n\n386\n00:20:57.390 --> 00:20:58.390\nWell, yes, there is.\n\n387\n00:20:58.390 --> 00:21:01.290\nWPA2 comes in a, well, WPA as well,\n\n388\n00:21:01.290 --> 00:21:06.700\nthey come in an enterprise mode,\nand they come in a personal mode.\n\n389\n00:21:06.700 --> 00:21:09.630\nPersonal mode, you might hear\nit called PSK, pre-shared key,\n\n390\n00:21:09.630 --> 00:21:11.660\nit's basically a password.\n\n391\n00:21:11.660 --> 00:21:14.564\nIf you implement enterprise mode, then\nwhat you're doing is your authentication\n\n392\n00:21:14.564 --> 00:21:15.983\nisn't happening by the device itself.\n\n393\n00:21:15.983 --> 00:21:19.330\nIt's actually being passed off\nto a RADIUS server, right?\n\n394\n00:21:19.330 --> 00:21:21.180\nSo if you're in a corporate environment,\n\n395\n00:21:21.180 --> 00:21:24.210\na weak implementation might\nbe the personal mode.\n\n396\n00:21:24.210 --> 00:21:27.920\nYou might want to bump it\nup to enterprise mode.\n\n397\n00:21:27.920 --> 00:21:34.100\nWhat else, a couple other ones,\nMessage Digest 5.\n\n398\n00:21:34.100 --> 00:21:36.557\nAt least if you implement SHA-1,\n\n399\n00:21:36.557 --> 00:21:41.480\nit's stronger than Message Digest 5,\nbut even that can be a problem, right?\n\n400\n00:21:41.480 --> 00:21:43.740\nSHA-1 we shouldn't be implementing,\n\n401\n00:21:43.740 --> 00:21:47.270\nwe should be implementing\nat least SHA-256, 256-bit.\n\n402\n00:21:47.270 --> 00:21:50.430\nAgain, as you see the weaker\nimplementations lead you\n\n403\n00:21:50.430 --> 00:21:55.050\nto vulnerabilities where a stronger\nimplementation usually implies a greater\n\n404\n00:21:55.050 --> 00:21:57.880\ncipher strength and a larger encryption.\n\n405\n00:21:57.880 --> 00:22:01.680\nThe key links are a lot larger there too,\nso be aware.\n\n406\n00:22:01.680 --> 00:22:03.660\nBe aware that when you're\nimplementing your systems,\n\n407\n00:22:03.660 --> 00:22:05.730\nwhat technologies you're using.\n\n408\n00:22:05.730 --> 00:22:08.920\nMake sure that your clients\naren't allowed to automatically\n\n409\n00:22:08.920 --> 00:22:11.180\ndowngrade to a weaker cipher strength.\n\n410\n00:22:11.180 --> 00:22:13.270\nBut know the ciphers\nthat you're using anyway.\n\n411\n00:22:13.270 --> 00:22:17.290\nKnow the security technologies and\nmake sure that you pick the right one so\n\n412\n00:22:17.290 --> 00:22:19.580\nthat your systems can stay safe.\n\n413\n00:22:19.580 --> 00:22:23.610\n&gt;&gt; Well, I think we've finally reached\nthe end of our types of attacks list,\n\n414\n00:22:23.610 --> 00:22:25.430\nthat's what CompTIA\nspecifically calls out.\n\n415\n00:22:25.430 --> 00:22:30.640\nBut just like we had kind of alluded\nthroughout our little mini series here,\n\n416\n00:22:30.640 --> 00:22:32.745\nthat there might be some\nattacks on the forefront.\n\n417\n00:22:32.745 --> 00:22:36.590\nSo just keep an open mind, but for\nthis show, I think that's about it.\n\n418\n00:22:36.590 --> 00:22:37.890\nSo thank you for joining us Wes.\n\n419\n00:22:37.890 --> 00:22:40.380\nAnd thank you ladies and\ngentlemen for joining us as well.\n\n420\n00:22:40.380 --> 00:22:41.590\nWe're gonna go ahead and sign out.\n\n421\n00:22:41.590 --> 00:22:43.260\nRemember I'm your host, Cherokee Boose.\n\n422\n00:22:43.260 --> 00:22:47.212\n&gt;&gt; And I'm Wes Bryan.\n&gt;&gt; See you next time here at ITProTV.\n\n423\n00:22:47.212 --> 00:22:53.254\n[MUSIC]\n\n424\n00:22:53.254 --> 00:22:56.333\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213512028"
        },
        {
          "description": "In this show, Wes and Cherokee explain the different types of threat actors and vectord used to execute an attack. Attacks are not always a one size fits all, sometimes they may incorporate many techniques. Tune in to learn more.",
          "length": "1361",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-3-threat_vector_types_and_attributes-040617.00_23_18_01.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-3-threat_vector_types_and_attributes-040617.00_23_18_01.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-3-threat_vector_types_and_attributes-040617.00_23_18_01.Still001-sm.jpg",
          "title": "Threat Vector Types and Attributes",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:06.485\nWelcome to ITPRO.TV,\nI'm your host Don Pezet [CROSSTALK]\n\n2\n00:00:06.485 --> 00:00:08.384\n&gt;&gt; [MUSIC]\n\n3\n00:00:08.384 --> 00:00:10.857\n&gt;&gt; You're watching ITPRO.TV\n\n4\n00:00:10.857 --> 00:00:12.224\n[MUSIC]\n\n5\n00:00:12.224 --> 00:00:16.690\n&gt;&gt; Welcome to your CompTIA Security+\nseries, I'm your show host Cherokee Boose.\n\n6\n00:00:16.690 --> 00:00:19.480\nIn this episode we'll be looking\nat different types of threat\n\n7\n00:00:19.480 --> 00:00:20.700\nvector and attributes,\n\n8\n00:00:20.700 --> 00:00:24.320\nwhich is really important because it may\ngive us some insight into what we can do\n\n9\n00:00:24.320 --> 00:00:28.230\nto help mitigate the types of attacks that\nwe were just previously talking about.\n\n10\n00:00:28.230 --> 00:00:30.620\nWith us today we have Mr.\nWes Bryan in studios.\n\n11\n00:00:30.620 --> 00:00:31.525\nThank you for joining us Wes.\n\n12\n00:00:31.525 --> 00:00:32.870\n&gt;&gt; Hey Cherokee, always good to be here.\n\n13\n00:00:32.870 --> 00:00:36.010\nThanks for having me here, that is right,\nwe're gonna be talking about actors.\n\n14\n00:00:37.020 --> 00:00:38.730\nBad actors, good actors.\n\n15\n00:00:38.730 --> 00:00:40.230\nNo, this isn't gonna be a movie review.\n\n16\n00:00:40.230 --> 00:00:42.450\nYou are here if you\nare looking into security.\n\n17\n00:00:42.450 --> 00:00:46.390\nBut there's some different actor\ntypes that we have to be aware of.\n\n18\n00:00:46.390 --> 00:00:49.795\nAnd they've got several different\nclassifications of actor types.\n\n19\n00:00:49.795 --> 00:00:53.640\nAnd what we're talking about really\nare bad actors if you will, right?\n\n20\n00:00:53.640 --> 00:00:58.210\nThese are the different categories of the\npeople that are gonna attack our systems\n\n21\n00:00:58.210 --> 00:01:02.790\nand along with that if you\nwill is their level of skill.\n\n22\n00:01:02.790 --> 00:01:05.180\nAnd so we're gonna go ahead and\nwe're gonna talk a little bit about that.\n\n23\n00:01:05.180 --> 00:01:10.340\nWe're gonna talk about the attributes\nof these actors as well as defining\n\n24\n00:01:10.340 --> 00:01:11.170\nthem likewise.\n\n25\n00:01:11.170 --> 00:01:14.558\nSo without further ado,\nlet's go ahead and dive right in.\n\n26\n00:01:14.558 --> 00:01:16.250\nI've got a little diagram here.\n\n27\n00:01:16.250 --> 00:01:19.482\nAnd it's really just, we're gonna go\nthrough these each individually here.\n\n28\n00:01:19.482 --> 00:01:23.930\nI know I don't have any fancy or\nflashy diagrams today on this one.\n\n29\n00:01:23.930 --> 00:01:26.020\nBut we're gonna go through\nthese one at a time.\n\n30\n00:01:26.020 --> 00:01:28.520\nYou can see we have Script Kiddies, right.\n\n31\n00:01:28.520 --> 00:01:30.210\nWe have Hacktivist.\n\n32\n00:01:30.210 --> 00:01:34.754\nOrganized crime, we've got nation states\nand APT, APT, if you're not aware what\n\n33\n00:01:34.754 --> 00:01:38.530\nthat acronym is, we're never shy\nof acronyms here in Security Plus,\n\n34\n00:01:38.530 --> 00:01:40.654\nthat's Advanced Persistent Threat.\n\n35\n00:01:40.654 --> 00:01:42.490\nWe're also gonna look at insiders, right?\n\n36\n00:01:42.490 --> 00:01:45.718\nWe've kinda thrown the term out there as\nwe've been going through this series,\n\n37\n00:01:45.718 --> 00:01:47.724\nwe've talked about\nmalicious insiders before.\n\n38\n00:01:47.724 --> 00:01:51.031\nWell, this is where we're going to\ncategorize them as a type of bad actor\n\n39\n00:01:51.031 --> 00:01:53.900\nthat we have to be aware of and\nwe have to protect against.\n\n40\n00:01:53.900 --> 00:01:57.245\nWe're also going to talk\nabout competitors, right?\n\n41\n00:01:57.245 --> 00:02:01.999\nWe hear of it sometimes in\nthe news where a new prototype of\n\n42\n00:02:01.999 --> 00:02:04.978\na device comes out like the iPhone.\n\n43\n00:02:04.978 --> 00:02:07.470\nIt's been known in the past to leak.\n\n44\n00:02:07.470 --> 00:02:11.822\nThe person that's working on it sitting\ndown at the bar leaves that brand new\n\n45\n00:02:11.822 --> 00:02:15.167\nprototype nobody's ever seen\niPhone sitting at the bar.\n\n46\n00:02:15.167 --> 00:02:17.238\nAnd sure enough somebody\ngrabs five fingers,\n\n47\n00:02:17.238 --> 00:02:20.636\ntakes it walks out the building and\nthey can sell it to their competitors, so\n\n48\n00:02:20.636 --> 00:02:23.520\nthat the competitors might get\na little bit ahead in the market.\n\n49\n00:02:23.520 --> 00:02:26.395\nSo we're also gonna talk\nabout those as well.\n\n50\n00:02:26.395 --> 00:02:29.922\nAll right, so I think what we'll do,\nis we we'll start with first one here,\n\n51\n00:02:29.922 --> 00:02:33.365\nwe're gonna go ahead and we will look at,\nwell, script kiddies, right?\n\n52\n00:02:33.365 --> 00:02:35.012\nWhat is the first one here?\n\n53\n00:02:35.012 --> 00:02:36.314\nAnd it's gone.\n\n54\n00:02:36.314 --> 00:02:37.466\nScript kiddies, right?\n\n55\n00:02:37.466 --> 00:02:39.320\n&gt;&gt; So Wes,\nwe actually have a comment in chat.\n\n56\n00:02:39.320 --> 00:02:42.030\nThey said CompTIA really\ncalls them Script Kiddies.\n\n57\n00:02:42.030 --> 00:02:43.350\nAnd yes, yes they do.\n\n58\n00:02:43.350 --> 00:02:44.110\n&gt;&gt; Yes they do.\n\n59\n00:02:44.110 --> 00:02:46.610\nIt is a valid term, right?\n\n60\n00:02:46.610 --> 00:02:47.170\nScript kiddies.\n\n61\n00:02:47.170 --> 00:02:49.455\nSo what are we talking about\nwhen we say Script Kiddy?\n\n62\n00:02:49.455 --> 00:02:51.845\nWell I want you to think\nof the term Kiddy right?\n\n63\n00:02:51.845 --> 00:02:55.585\nI've got some little ones here,\nwhen I say kids, we think well,\n\n64\n00:02:55.585 --> 00:02:58.840\nmaybe not a lot of sophistication\nbehind them, right?\n\n65\n00:02:58.840 --> 00:03:01.360\nLittle kids, if you think about it,\nthey're still learning right?\n\n66\n00:03:01.360 --> 00:03:02.970\nWell, that's kinda what\na Script Kiddie is.\n\n67\n00:03:02.970 --> 00:03:03.920\nIf you look at a Script Kiddie,\n\n68\n00:03:03.920 --> 00:03:07.890\nit's really just lacking any kind of\nexpertise in their training, right?\n\n69\n00:03:07.890 --> 00:03:11.620\nWe have plenty of tools out there,\nwe have administrative tools.\n\n70\n00:03:11.620 --> 00:03:14.890\nSame type of tools that can\nbe used in administration\n\n71\n00:03:14.890 --> 00:03:17.090\ncan also be used by the bad guys, right?\n\n72\n00:03:17.090 --> 00:03:20.360\nAnd these tools have already been coded,\nthey've already been programmed by people\n\n73\n00:03:20.360 --> 00:03:22.640\nthat really do know what they're doing,\nright?\n\n74\n00:03:22.640 --> 00:03:26.520\nSo the Script Kiddies is one that doesn't\nreally have a lot of technical expertise\n\n75\n00:03:26.520 --> 00:03:29.090\nbut it's gonna go find things\nlike programs that will help\n\n76\n00:03:29.090 --> 00:03:32.990\nthem perform whatever attack it is\nthat they are trying to perform.\n\n77\n00:03:32.990 --> 00:03:36.566\n&gt;&gt; Precisely Wes, so these\nindividuals aren't really creating or\n\n78\n00:03:36.566 --> 00:03:40.402\ndeveloping the tools but\nthey are taking those pre-existing tools,\n\n79\n00:03:40.402 --> 00:03:44.187\nand using them in a way that can\ncompromise an individual or network.\n\n80\n00:03:44.187 --> 00:03:49.209\nSo the vast majority of attackers out\nthere are gonna be Script Kiddies and\n\n81\n00:03:49.209 --> 00:03:54.555\nby utilizing a concept that we've spoke\nabout in the past, defense in depth.\n\n82\n00:03:54.555 --> 00:03:59.317\nThat's going to be able to eliminate a lot\nof these types of Script Kiddies because\n\n83\n00:03:59.317 --> 00:04:01.190\nadding those multiple layers.\n\n84\n00:04:01.190 --> 00:04:05.914\nWe'll go ahead and thwart, hopefully,\nat some point, we're gonna go ahead and\n\n85\n00:04:05.914 --> 00:04:08.590\nstop those less experienced attackers.\n\n86\n00:04:08.590 --> 00:04:11.795\n&gt;&gt; Definitely and you know,\nin a chat room, we also have a person made\n\n87\n00:04:11.795 --> 00:04:15.800\na comment, man that term Script Kiddy\nthat sounds a bit derogatory.\n\n88\n00:04:15.800 --> 00:04:17.015\nAnd it is.\n\n89\n00:04:17.015 --> 00:04:19.510\nThat person is absolutely right,\nit is derogatory.\n\n90\n00:04:19.510 --> 00:04:23.310\nBecause, if you look at it they're\nusing an automated approach, right.\n\n91\n00:04:23.310 --> 00:04:26.889\nWhat I mean by automation is not\nthat they even understand scripts.\n\n92\n00:04:26.889 --> 00:04:30.701\nDon't think because we say Script Kiddies\nthat they are script intelligent, no,\n\n93\n00:04:30.701 --> 00:04:33.850\nthey take scripts from people\nwho know what they are doing.\n\n94\n00:04:33.850 --> 00:04:36.980\nAnd they say it's an automated approach I\ncan just copy and paste this in here and\n\n95\n00:04:36.980 --> 00:04:38.724\nI don't even have to know what's going on.\n\n96\n00:04:38.724 --> 00:04:41.328\nAnd I can run it and\nhopefully it does something and\n\n97\n00:04:41.328 --> 00:04:44.490\nwhat that something is they might\nnot even know that as well.\n\n98\n00:04:44.490 --> 00:04:47.350\nSo, they're gonna take an automated\napproach through scripts that somebody\n\n99\n00:04:47.350 --> 00:04:50.680\nelse has already implemented as well.\n\n100\n00:04:50.680 --> 00:04:54.970\n&gt;&gt; Now Wes it may be a derogatory term,\nbut as far as effectiveness goes,\n\n101\n00:04:54.970 --> 00:04:59.575\nlet's not underestimate the effectiveness\nof what a Script Kiddy can do.\n\n102\n00:04:59.575 --> 00:05:03.437\nYou and I were talking before this\nshow about an attacker names Gucifer.\n\n103\n00:05:03.437 --> 00:05:08.151\nI think he's based out of Romania,\nbut he really gained some traction and\n\n104\n00:05:08.151 --> 00:05:12.727\npopularity with the whole Bush family\nscandal attack with the emails.\n\n105\n00:05:12.727 --> 00:05:14.511\nAnd the Hilary Clinton emails, and\n\n106\n00:05:14.511 --> 00:05:17.210\nthat was,\nhe really was just really using guessing.\n\n107\n00:05:17.210 --> 00:05:20.840\nHe didn't use any sophisticated\ntypes of scripter coding.\n\n108\n00:05:20.840 --> 00:05:24.390\nThat techniques he used were based\noff of social engineering, and\n\n109\n00:05:24.390 --> 00:05:26.600\nusing that public information,\n\n110\n00:05:26.600 --> 00:05:32.470\nto obtain the correct security\nquestion to compromise an account.\n\n111\n00:05:32.470 --> 00:05:35.230\n&gt;&gt; So yeah, Cherokee, you can see\nhow somebody like that, I mean,\n\n112\n00:05:35.230 --> 00:05:38.840\ndidn't have a lot of experience, right,\nbut was able to cause a lot of damage.\n\n113\n00:05:38.840 --> 00:05:43.137\nAnd that's one of the things about\nthe Script Kiddy is the fact that when it\n\n114\n00:05:43.137 --> 00:05:47.364\ncomes to the hacking culture, right,\nit is more of a derogatory term cuz\n\n115\n00:05:47.364 --> 00:05:50.069\nthey're considered\nthings like immature and\n\n116\n00:05:50.069 --> 00:05:53.567\nlazy because they don't wanna\ntake the time, if you will.\n\n117\n00:05:53.567 --> 00:05:57.390\nThe effort that it takes to actually learn\nthe technologies that they're using.\n\n118\n00:05:57.390 --> 00:06:01.165\nJust using automated software programs\nthat are really built by the hackers,\n\n119\n00:06:01.165 --> 00:06:05.239\nthe people that really know what they're\ndoing, understand things like the code.\n\n120\n00:06:05.239 --> 00:06:09.857\nAnd even just underneath,\nlike the protocols and stuff as well.\n\n121\n00:06:09.857 --> 00:06:12.887\nSo Script Kiddies,\nwe definitely have to worry about them.\n\n122\n00:06:12.887 --> 00:06:16.541\nEven though it is a derogatory term,\nlike you heard Cherokee say,\n\n123\n00:06:16.541 --> 00:06:20.440\nkeep in mind that they can cause\na lot of damage within your networks.\n\n124\n00:06:20.440 --> 00:06:25.271\n&gt;&gt; Well, speaking out the connotation of\nspecific terms, if we hear the term hacker\n\n125\n00:06:25.271 --> 00:06:28.421\nit does have a lot of negative\njust kind of vibe to it and\n\n126\n00:06:28.421 --> 00:06:30.183\nthat's not always the case.\n\n127\n00:06:30.183 --> 00:06:34.461\nSo, it's important to me any ways\nto distinguish between hacker and\n\n128\n00:06:34.461 --> 00:06:38.385\nattacker because a hacker is just\nsomeone with that skill set.\n\n129\n00:06:38.385 --> 00:06:42.269\nAnd then an attacker is using\nthat skill set for a nefarious or\n\n130\n00:06:42.269 --> 00:06:44.890\nmalicious with that intent.\n\n131\n00:06:44.890 --> 00:06:45.730\n&gt;&gt; Definitely.\n\n132\n00:06:45.730 --> 00:06:49.893\nSo when you say hacker,\nhackers says well, I know what it can do.\n\n133\n00:06:49.893 --> 00:06:52.848\nI know what it's supposed to do but\nwhat can it do, right?\n\n134\n00:06:52.848 --> 00:06:54.192\nI mean, that's what hacking is.\n\n135\n00:06:54.192 --> 00:06:58.482\nIt goes back to the days of Steve Wozniak,\nco-founder of Apple,\n\n136\n00:06:58.482 --> 00:07:03.162\ntalking about jumping on the ARPANET\nas he called it, just to hack in and\n\n137\n00:07:03.162 --> 00:07:07.931\nplay solitaire or something like that\non a terminal across the country.\n\n138\n00:07:07.931 --> 00:07:12.104\nOr jumping on the old phone systems, I\ncan't remember what they would call them,\n\n139\n00:07:12.104 --> 00:07:15.307\nbut they can admit a tone,\nthey knew had to get into the system,\n\n140\n00:07:15.307 --> 00:07:17.560\nbecause they have the knowledge.\n\n141\n00:07:17.560 --> 00:07:21.530\nSo yeah, definitely the malicious nature,\nwe would be talking about attacker.\n\n142\n00:07:21.530 --> 00:07:24.745\nNow, speaking of the term hacker.\n\n143\n00:07:24.745 --> 00:07:29.042\nThis next one here, if we can look,\nthis one's the hactivist, right, and\n\n144\n00:07:29.042 --> 00:07:33.560\nwith the hactivist here, now it's,\nthey can cause a lot of problems, right.\n\n145\n00:07:33.560 --> 00:07:36.990\nThey usually have some\nkind of political stance.\n\n146\n00:07:38.020 --> 00:07:40.708\nThey could be just trying to like,\nfor instance,\n\n147\n00:07:40.708 --> 00:07:43.800\nIt ruins somebody's reputation, right.\n\n148\n00:07:43.800 --> 00:07:48.820\nDestabilizing an organization, may be\nthat they don't really like, if you will.\n\n149\n00:07:48.820 --> 00:07:51.809\nMaybe they are just trying to do\nthings like a social change, right.\n\n150\n00:07:51.809 --> 00:07:55.638\nSome kind of economical or social\nchange within their environment, and\n\n151\n00:07:55.638 --> 00:07:59.715\nthey feel that A lot of times that what\nthey're doing is not necessarily bad,\n\n152\n00:07:59.715 --> 00:08:03.340\nthey feel that they're doing good for\nthe overall good if you will.\n\n153\n00:08:03.340 --> 00:08:05.280\n&gt;&gt; They justifying their moral stands.\n\n154\n00:08:05.280 --> 00:08:08.780\nSo their actions by their moral concept.\n\n155\n00:08:08.780 --> 00:08:12.700\n&gt;&gt; Most definitely,\nI look at Groups like Anonymous,\n\n156\n00:08:12.700 --> 00:08:15.990\nLulzSec is another one, and\nagain, and they're out there.\n\n157\n00:08:15.990 --> 00:08:18.120\nWe definitely have to worry about them,\nright?\n\n158\n00:08:18.120 --> 00:08:19.035\nYou might have scenarios where\n\n159\n00:08:19.035 --> 00:08:20.733\nthey're doing things like\npublishing emails, right?\n\n160\n00:08:20.733 --> 00:08:25.738\nThere's been a lot of talk out there in\nthe media, where a hacker or this group\n\n161\n00:08:25.738 --> 00:08:30.902\nof hacktivists gets in, grabs emails,\nand and then exposes them to the world.\n\n162\n00:08:30.902 --> 00:08:36.313\nIt's one of the things that really makes\ncompanies like WikiLeaks exist today.\n\n163\n00:08:36.313 --> 00:08:39.500\n&gt;&gt; Big, big attack there, what was it?\n\n164\n00:08:39.500 --> 00:08:44.281\nThat Ashley Madison scandal, I forget\nthe name of that particular group but\n\n165\n00:08:44.281 --> 00:08:49.211\nthey gave a set time and they said look\nif you don't, they are basically saying\n\n166\n00:08:49.211 --> 00:08:53.619\nthat the company Ashley Madison was\nfalsely charging their members,\n\n167\n00:08:53.619 --> 00:08:58.207\nit was $20, to conceal or\nnot store their information in databases.\n\n168\n00:08:58.207 --> 00:09:02.995\nThey thought they were, I'm completely\nanonymous, but these attackers said no.\n\n169\n00:09:02.995 --> 00:09:07.038\nYou're over changing this individuals\nbecause you do store their information and\n\n170\n00:09:07.038 --> 00:09:10.732\nI'm gonna give you x number of days\nto remove these people's information,\n\n171\n00:09:10.732 --> 00:09:14.444\nthey didn't remove so they took that\ninformation and published it online.\n\n172\n00:09:14.444 --> 00:09:17.923\n&gt;&gt; Sure, and going and doing things\nlike even publishing passwords,\n\n173\n00:09:17.923 --> 00:09:21.708\nall right if we get skip a million\npasswords from a million users we can turn\n\n174\n00:09:21.708 --> 00:09:23.670\naround we can sell that right?\n\n175\n00:09:23.670 --> 00:09:25.840\nSell that stuff on\nthe black market as well.\n\n176\n00:09:25.840 --> 00:09:30.293\nYou hear of things like the Dark Web so\nit might be doing it for extortion,\n\n177\n00:09:30.293 --> 00:09:33.441\nblackmail of some sort like\nwas mentioned as well.\n\n178\n00:09:33.441 --> 00:09:36.540\nOther ones they have,\nthey call it organized crime.\n\n179\n00:09:36.540 --> 00:09:40.660\nWhen we look at organized crime, well,\nthere are, these can be massive attacks.\n\n180\n00:09:40.660 --> 00:09:44.170\nA lot of times we talk about\norganized crime think about funding.\n\n181\n00:09:44.170 --> 00:09:48.800\nThe complexity of the group or the actor,\n\n182\n00:09:48.800 --> 00:09:53.290\nif you will, sometimes can be\nhindered by a lack of funding.\n\n183\n00:09:53.290 --> 00:09:56.180\nWell, with organized crime again,\na lot of times-\n\n184\n00:09:56.180 --> 00:09:57.650\n&gt;&gt; Resources, connections.\n\n185\n00:09:57.650 --> 00:09:59.540\n&gt;&gt; That's right.\nAnd a lot of times with the organized\n\n186\n00:09:59.540 --> 00:10:01.680\ncrime, they're profit driven.\n\n187\n00:10:01.680 --> 00:10:02.950\nThat's the goal here.\n\n188\n00:10:02.950 --> 00:10:04.450\nIt's not so much disruption.\n\n189\n00:10:04.450 --> 00:10:08.260\nLike hactivists, if you will,\ntrying to cause some kind of social\n\n190\n00:10:08.260 --> 00:10:11.950\nchange in the world that they\nthink would be good for the world.\n\n191\n00:10:11.950 --> 00:10:14.340\nThis is more about just\ncommonly profit driven,\n\n192\n00:10:14.340 --> 00:10:17.600\nwhere we do things like\nRansomware publishers.\n\n193\n00:10:17.600 --> 00:10:21.975\nYou can go out to the dark web and there\nare a lot of attacks that people sell,\n\n194\n00:10:21.975 --> 00:10:23.308\nright, groups sell.\n\n195\n00:10:23.308 --> 00:10:25.015\nAnd this could be something, right?\n\n196\n00:10:25.015 --> 00:10:26.602\nBlack market data thieves, and\n\n197\n00:10:26.602 --> 00:10:29.549\nagain doing things like selling\nmedical records, right.\n\n198\n00:10:29.549 --> 00:10:30.474\nBut keep in mind,\n\n199\n00:10:30.474 --> 00:10:34.740\nwith the organized crime it really boils\ndown to the fact that it is profit driven.\n\n200\n00:10:35.910 --> 00:10:38.595\nAll right, so some of the other\nones that we have here, Ms.\n\n201\n00:10:38.595 --> 00:10:40.227\nCherokee, nation states and APT.\n\n202\n00:10:40.227 --> 00:10:42.360\nWell we look at nation states.\n\n203\n00:10:42.360 --> 00:10:44.470\nThis is another one that's about funding,\nright?\n\n204\n00:10:44.470 --> 00:10:49.581\nThese can be directly sponsored by\ngovernments, political bodies if you will.\n\n205\n00:10:49.581 --> 00:10:53.601\nThese type of actors now,\nyou really have to worry about because\n\n206\n00:10:53.601 --> 00:10:57.557\nthey usually have access to lots of funds,\nlots of resources.\n\n207\n00:10:57.557 --> 00:11:01.830\nUnlike some smaller groups that we've been\ntalking about they can have the financial\n\n208\n00:11:01.830 --> 00:11:05.583\nbacking to perform whatever the attack\nis that they are trying to perform.\n\n209\n00:11:05.583 --> 00:11:10.450\nFor instance, we look at things\nlike botnets like Stuxnet.\n\n210\n00:11:10.450 --> 00:11:13.941\nStuxnet was I believe they think\nit was an Uranian hacker, right?\n\n211\n00:11:13.941 --> 00:11:16.887\nVery well could be state sponsored,\nnot sure if it is or not but\n\n212\n00:11:16.887 --> 00:11:19.609\nyou can see the complexity of\nsomething like that because\n\n213\n00:11:19.609 --> 00:11:22.510\nof the fact that the funding\nis there if they need it.\n\n214\n00:11:22.510 --> 00:11:24.230\nAnd it really is about\n\n215\n00:11:25.370 --> 00:11:29.850\nwhat is that government's motivation\nbehind whatever the attack might be?\n\n216\n00:11:29.850 --> 00:11:36.460\n&gt;&gt; Well, sure, because not all governments\nhave as harsh of a penalty as it varies.\n\n217\n00:11:36.460 --> 00:11:38.901\nThe penalties depending on\nwhat government you're in.\n\n218\n00:11:38.901 --> 00:11:43.634\nAnd sometimes the government,\nhate to say this, Wes, but\n\n219\n00:11:43.634 --> 00:11:48.851\nis closely intertwined with those\norganized crime situations.\n\n220\n00:11:48.851 --> 00:11:49.675\n&gt;&gt; Yeah, it's definitely.\n\n221\n00:11:49.675 --> 00:11:54.360\n&gt;&gt; So it's not always cookie\ncutter cut and dry type scenario.\n\n222\n00:11:54.360 --> 00:11:55.240\n&gt;&gt; Most definitely.\n\n223\n00:11:55.240 --> 00:11:57.560\nThe other part of that that they\ncall other things like APT.\n\n224\n00:11:57.560 --> 00:11:59.220\nIt just advanced persistent threat.\n\n225\n00:11:59.220 --> 00:12:00.940\nAnd I want you to just\nthink about the name.\n\n226\n00:12:00.940 --> 00:12:03.004\nSo advanced, we're talking about\na sophistication here, right?\n\n227\n00:12:03.004 --> 00:12:05.220\nWe're not talking about\na script kitty anymore.\n\n228\n00:12:05.220 --> 00:12:08.820\nThe other thing is persistent\nIt's not going away right?\n\n229\n00:12:08.820 --> 00:12:13.563\nIt's an ongoing attack that seeks\nto remain undetected through things\n\n230\n00:12:13.563 --> 00:12:18.308\nlike major bank systems,\ninsurance systems, insurance companies,\n\n231\n00:12:18.308 --> 00:12:21.328\neven things like national defense systems.\n\n232\n00:12:21.328 --> 00:12:26.222\nI know that's one thing that a lot of\nmajor states or governments if you will,\n\n233\n00:12:26.222 --> 00:12:31.498\nworry about things like attacking scatter\nsystems in general are already large and\n\n234\n00:12:31.498 --> 00:12:32.628\ncomplex enough so\n\n235\n00:12:32.628 --> 00:12:37.546\nyou have to bring in people that know\nthe complexities of networks like that.\n\n236\n00:12:37.546 --> 00:12:41.508\nSo, advance persistent threat again\nusually a high value target and\n\n237\n00:12:41.508 --> 00:12:44.852\nthen keep in mind that it is\ngonna try to go undetected, and\n\n238\n00:12:44.852 --> 00:12:47.943\nthe persistence of the fact\nthat it's just ongoing.\n\n239\n00:12:47.943 --> 00:12:55.090\nAll right, now we come to the actor\nthe bad actor from within if you will.\n\n240\n00:12:55.090 --> 00:12:56.740\nAnd that's the insider, right?\n\n241\n00:12:56.740 --> 00:12:58.761\nYou've probably heard the term before,\nmalicious insider, and\n\n242\n00:12:58.761 --> 00:13:00.069\nif you haven't we'll talk about it here.\n\n243\n00:13:00.069 --> 00:13:03.790\nBut disgruntled employees, right?\n\n244\n00:13:03.790 --> 00:13:07.274\nThere are things that we need\nto keep in mind, that we have,\n\n245\n00:13:07.274 --> 00:13:10.842\nmaybe an employee who has worked for\na company for ten years.\n\n246\n00:13:10.842 --> 00:13:14.689\nBelieves they should have got a raise,\nthey're doing the job that four or\n\n247\n00:13:14.689 --> 00:13:18.041\nfive people before them have\nalready got promotions right, and\n\n248\n00:13:18.041 --> 00:13:20.416\nthey start to goes to the sour apple,\nright.\n\n249\n00:13:20.416 --> 00:13:25.010\nAnd sometimes this doesn't even\nhave to be intentional, right.\n\n250\n00:13:25.010 --> 00:13:30.020\nLeaking company data,\nexposing things like patents if you will.\n\n251\n00:13:30.020 --> 00:13:31.955\nBut it can lead to things like sabotage,\nright.\n\n252\n00:13:31.955 --> 00:13:34.428\nSabotage of your data or your systems.\n\n253\n00:13:34.428 --> 00:13:36.509\nTheft of your data, right,\n\n254\n00:13:36.509 --> 00:13:41.720\ninsiders usually have a little bit\nmore privileged access to our data.\n\n255\n00:13:41.720 --> 00:13:43.550\nAnd that doesn't mean at\nthe administrative level.\n\n256\n00:13:43.550 --> 00:13:47.000\nBut I want you to consider an outsider,\nan external person.\n\n257\n00:13:47.000 --> 00:13:50.350\nThey typically don't have any\naccess to your internal functions.\n\n258\n00:13:50.350 --> 00:13:53.072\nAn insider does,\neven if it's just a standard user,\n\n259\n00:13:53.072 --> 00:13:57.004\nthey already have a foothold through\nthe door, so that can lead to things like\n\n260\n00:13:57.004 --> 00:14:00.245\ntheft of your data,\ndestruction of your data if you will.\n\n261\n00:14:00.245 --> 00:14:04.055\nEven this word, it says like blackmail or\nencryption of your information.\n\n262\n00:14:04.055 --> 00:14:07.285\nIt says you better have the key, you\nbetter give me the, the payment I want,\n\n263\n00:14:07.285 --> 00:14:09.375\nI do not doubt you would ever\nget a raise after that fact.\n\n264\n00:14:09.375 --> 00:14:13.367\nIf they found it out, I'm sure not going\nto get a promotion unless it is to\n\n265\n00:14:13.367 --> 00:14:16.780\nthe local county jail, but\nthat is something to keep in mind.\n\n266\n00:14:16.780 --> 00:14:18.926\nThat is could even be something\nlike complete data loss.\n\n267\n00:14:18.926 --> 00:14:23.482\n&gt;&gt; Well sure, I mean they have access to\nyour, they may know your network design,\n\n268\n00:14:23.482 --> 00:14:25.862\nthey may know your company's policies,\n\n269\n00:14:25.862 --> 00:14:28.798\nyour stance on how to react\nto security incidents.\n\n270\n00:14:28.798 --> 00:14:31.727\nThey know the company's vulnerabilities so\n\n271\n00:14:31.727 --> 00:14:37.520\nthey can be pretty detrimental when you're\nlooking at the overall level of attackers.\n\n272\n00:14:37.520 --> 00:14:39.264\nDon't discount those insiders.\n\n273\n00:14:39.264 --> 00:14:42.615\n&gt;&gt; Most definitely and that sometimes run\nhand in hand with the other type of actor\n\n274\n00:14:42.615 --> 00:14:44.880\nthat they talk about, a competitor right?\n\n275\n00:14:44.880 --> 00:14:47.777\nIf a competitor knows that you have,\nlet's say a product, or\n\n276\n00:14:47.777 --> 00:14:51.476\nyou've got some information that can\nhelp them succeed if they get access to.\n\n277\n00:14:51.476 --> 00:14:54.820\nWell, a competitor can go\nto an insider and say, hey,\n\n278\n00:14:54.820 --> 00:14:58.050\nwe'll give you a lot of money\nif you give us x, y, z.\n\n279\n00:14:58.050 --> 00:15:00.245\nSo competitors we always\nhave to worry about.\n\n280\n00:15:00.245 --> 00:15:03.800\nCuz that competition, sometimes\npeople are playing dirty pool and\n\n281\n00:15:03.800 --> 00:15:07.980\nthey want to be able to get in there and\nget any information they can, or\n\n282\n00:15:07.980 --> 00:15:09.530\neven just slow the competition down.\n\n283\n00:15:09.530 --> 00:15:12.679\nI don't even have to have\naccess to your information but\n\n284\n00:15:12.679 --> 00:15:16.373\nif I can stall your success then\nI can eliminate the competition.\n\n285\n00:15:16.373 --> 00:15:18.039\nSo you think about it that way,\n\n286\n00:15:18.039 --> 00:15:22.203\ncompetitors are also that type of bad\nactor and they can work with some of these\n\n287\n00:15:22.203 --> 00:15:26.380\nother actors as well including\nthings like malicious insiders.\n\n288\n00:15:26.380 --> 00:15:31.100\nAll right, so we've talked pretty much\nabout all the actor types that they want\n\n289\n00:15:31.100 --> 00:15:32.230\nyou to be aware of.\n\n290\n00:15:32.230 --> 00:15:35.210\nThere are a few other things\nthat we need to talk about.\n\n291\n00:15:35.210 --> 00:15:37.980\nWe need to talk about the attributes\nof the actors, right?\n\n292\n00:15:37.980 --> 00:15:42.104\nOne of them we've pretty much talked\nabout in relation to the actor types,\n\n293\n00:15:42.104 --> 00:15:46.825\neach one of these, if you look they talk\nabout attributes internal versus external.\n\n294\n00:15:46.825 --> 00:15:51.886\nWe've kinda just talked about that with\nthe insider they usually have more access.\n\n295\n00:15:51.886 --> 00:15:55.446\nAccess to more information\nthat the external user.\n\n296\n00:15:55.446 --> 00:15:59.016\nThe external user might be\nUsing public information,\n\n297\n00:15:59.016 --> 00:16:03.770\nin the case of the example that you got,\nfor the emails attacks, right.\n\n298\n00:16:03.770 --> 00:16:06.060\nSo they've gotta do a lot of research,\nright?\n\n299\n00:16:06.060 --> 00:16:07.380\nA lot of reconnaissance,\n\n300\n00:16:07.380 --> 00:16:11.336\na lot more than an insider does, even if\nthat insider is just a standard user.\n\n301\n00:16:11.336 --> 00:16:13.770\nCuz, again, they've already\ngot their foot in the door.\n\n302\n00:16:13.770 --> 00:16:15.590\nSo again,\n\n303\n00:16:15.590 --> 00:16:19.960\njust think about insiders versus everyone\nelse [LAUGH] when it comes down to it.\n\n304\n00:16:19.960 --> 00:16:23.590\nLevel of sophistication, now, again, this\nis one where we've kind of talked about.\n\n305\n00:16:23.590 --> 00:16:26.980\nBut you look at like your actor types,\norganized crime,\n\n306\n00:16:26.980 --> 00:16:28.560\nyou look at nation states.\n\n307\n00:16:28.560 --> 00:16:32.360\nIf you think about that,\nthese bodies if you will,\n\n308\n00:16:32.360 --> 00:16:37.800\nthese hackers that are working with\nthese type of actors if you will.\n\n309\n00:16:37.800 --> 00:16:42.670\nThey have the resources and\nthe funding to make sure, ensure that\n\n310\n00:16:42.670 --> 00:16:46.020\nthey do have that level of sophistication,\nif that’s what’s necessary, right?\n\n311\n00:16:46.020 --> 00:16:49.913\nIf that’s what it necessitates\ngetting into a company,\n\n312\n00:16:49.913 --> 00:16:51.950\nto steal their information.\n\n313\n00:16:51.950 --> 00:16:55.810\nLet’s see, I kind of mentioned that\nresources and funding they talked about,\n\n314\n00:16:55.810 --> 00:16:58.560\nagain, as an example organized crime,\nnation state.\n\n315\n00:16:58.560 --> 00:17:00.990\nThey’ve got access to\nthe money that they need.\n\n316\n00:17:00.990 --> 00:17:05.306\nUnlike somebody that maybe is doing\nthis in complete secret and or\n\n317\n00:17:05.306 --> 00:17:06.647\nthe script kiddie.\n\n318\n00:17:06.647 --> 00:17:09.409\nWhat else, intention and motivation, well,\n\n319\n00:17:09.409 --> 00:17:12.801\nthat's pretty much every one\nof these actor types right?\n\n320\n00:17:12.801 --> 00:17:16.901\nUsually the intention is to\ncause some kind of disruption,\n\n321\n00:17:16.901 --> 00:17:19.690\ndata theft, so you have to look at that.\n\n322\n00:17:19.690 --> 00:17:24.300\nFor instance, a hacktivist,\ntheir intentions are probably gonna be\n\n323\n00:17:24.300 --> 00:17:26.820\ndifferent that somebody that's\nsponsored by nation states.\n\n324\n00:17:26.820 --> 00:17:29.420\nNation states have a specific agenda,\nthey're funding it for\n\n325\n00:17:29.420 --> 00:17:31.060\na specific endpoint.\n\n326\n00:17:31.060 --> 00:17:34.620\nThe hacktivists,\ntheir goals might change over time, right?\n\n327\n00:17:34.620 --> 00:17:38.840\nWhere if you look at the level of\nintention for organized crime or\n\n328\n00:17:38.840 --> 00:17:44.570\nthe nation states, they've got a specific\nfocus on what they're going after.\n\n329\n00:17:44.570 --> 00:17:48.250\n&gt;&gt; And it's really important to understand\nthe intent or motivation of an attacker.\n\n330\n00:17:48.250 --> 00:17:51.500\nBecause there's something that\nan organization or individual can do to\n\n331\n00:17:51.500 --> 00:17:58.245\nmodify their behavior to reduce that\nrisk or reduce themselves as a target.\n\n332\n00:17:58.245 --> 00:18:01.295\nBecause there could be so\nmany different reasons.\n\n333\n00:18:01.295 --> 00:18:07.154\nIt could be monetary purposes,\nit could be emotion, it could be revenge.\n\n334\n00:18:07.154 --> 00:18:10.405\nIt could be, what else here,\npolitics, religion.\n\n335\n00:18:10.405 --> 00:18:12.185\nOr just as like a badge of honor.\n\n336\n00:18:12.185 --> 00:18:13.645\nAnd it's kind of interesting.\n\n337\n00:18:13.645 --> 00:18:17.185\nI hate to bring up our\nfavorite reality TV star,\n\n338\n00:18:17.185 --> 00:18:21.180\nbut if you look at situations\nlike Kim Kardashian, right?\n\n339\n00:18:21.180 --> 00:18:26.340\nShe would go on social media and\nflaunt her wealth on a daily basis.\n\n340\n00:18:26.340 --> 00:18:29.940\nAnd it wasn't until she was\nheld at gun point in Paris,\n\n341\n00:18:29.940 --> 00:18:31.640\nuntil she just went on the books.\n\n342\n00:18:31.640 --> 00:18:35.710\nAnd said look, I acknowledge the fact\nthat I may have been a bit too showy.\n\n343\n00:18:35.710 --> 00:18:36.560\nAnd by doing so\n\n344\n00:18:36.560 --> 00:18:40.250\nand modifying her behaviour,\nshe's hoping to not be attacked again.\n\n345\n00:18:40.250 --> 00:18:44.050\nSo there might be something that you\ncan do to just kind of change and\n\n346\n00:18:44.050 --> 00:18:46.510\nprevent that kind of attack.\n\n347\n00:18:46.510 --> 00:18:49.650\n&gt;&gt; And it really is hard today with\nsocial media just being so prevalent.\n\n348\n00:18:49.650 --> 00:18:52.500\nI use social media, Cherokee,\nI know you use social media.\n\n349\n00:18:52.500 --> 00:18:54.810\nBut again,\nit's one of those double edged swords.\n\n350\n00:18:54.810 --> 00:18:57.400\nSo one of the last things that\nwe're gonna talk about here.\n\n351\n00:18:57.400 --> 00:19:01.210\nThey do mention is the use\nof open source intelligence.\n\n352\n00:19:01.210 --> 00:19:05.290\nOSINT if you will,\nO-S-I-N-T as you might see the acronym.\n\n353\n00:19:05.290 --> 00:19:09.270\nAnd basically if you look\nat the information and\n\n354\n00:19:09.270 --> 00:19:12.020\nthe skills gained by hackers, right?\n\n355\n00:19:12.020 --> 00:19:15.830\nA lot of times that information is\ngonna remain relatively secret, right?\n\n356\n00:19:15.830 --> 00:19:19.820\nIt's gonna be a covert operations\nwhile open source intelligence,\n\n357\n00:19:19.820 --> 00:19:21.215\nthe exact opposite of it, right?\n\n358\n00:19:21.215 --> 00:19:23.770\nIt's overt, it's undisguised, and\n\n359\n00:19:23.770 --> 00:19:27.525\nsome of the examples that we see today,\nthere is media.\n\n360\n00:19:27.525 --> 00:19:32.845\nMedia alone can be examples of public\ninformation that you can gain a hold of\n\n361\n00:19:32.845 --> 00:19:37.080\nto, if you're doing profiling, if you're\ndoing some kind of reconnaissance, right?\n\n362\n00:19:37.080 --> 00:19:38.310\nWe've got a lot of avenues.\n\n363\n00:19:38.310 --> 00:19:39.932\n&gt;&gt; A treasure trove of of information.\n\n364\n00:19:39.932 --> 00:19:41.837\n[LAUGH]\n&gt;&gt; Most definitely, yeah, and sometimes,\n\n365\n00:19:41.837 --> 00:19:44.460\nso much information that [LAUGH] it\nmight even be hard to sift through it.\n\n366\n00:19:44.460 --> 00:19:45.200\nWhat else do we got?\n\n367\n00:19:45.200 --> 00:19:46.625\nThings like Government reports,\n\n368\n00:19:46.625 --> 00:19:50.145\ngovernment reports are reported\nalmost on a daily basis.\n\n369\n00:19:50.145 --> 00:19:54.105\nThings like press conferences where\nthey release information as well.\n\n370\n00:19:54.105 --> 00:19:57.375\nSo there is just a treasure trove of\ninformation out there in the open\n\n371\n00:19:57.375 --> 00:19:58.480\nsource community.\n\n372\n00:19:58.480 --> 00:20:03.730\nAnd not so much open source in the fact\nthat we're talking about like GPL, right?\n\n373\n00:20:03.730 --> 00:20:06.270\nThe GNU Public Licensing\nopen source software.\n\n374\n00:20:06.270 --> 00:20:08.760\nBut just the fact that you can\nsee where it's coming from.\n\n375\n00:20:08.760 --> 00:20:13.180\nAgain, the open source and the fact that\nit's out there and it is undisguised.\n\n376\n00:20:13.180 --> 00:20:15.630\nSocial media,\nwe've kind of mentioned of all ready.\n\n377\n00:20:15.630 --> 00:20:20.010\nThings like your, what else,\nacademic publications, right?\n\n378\n00:20:20.010 --> 00:20:22.930\nThings like, for instance, when WPS,\n\n379\n00:20:22.930 --> 00:20:26.370\nwe talked about WPS in a previous\nepisode where we were saying.\n\n380\n00:20:26.370 --> 00:20:29.848\nHey you should disable\nWi-Fi protected setup.\n\n381\n00:20:29.848 --> 00:20:33.680\nWell, the hacker,\nI can't think of his name right now,\n\n382\n00:20:33.680 --> 00:20:39.280\nhis hacking name I think is Marlon,\nI can't think of the name.\n\n383\n00:20:39.280 --> 00:20:40.000\n&gt;&gt; I'm Googling it over here.\n\n384\n00:20:40.000 --> 00:20:43.064\n&gt;&gt; Moxie Marlinspike,\nthat's what his name, Moxie Marlinspike,\n\n385\n00:20:43.064 --> 00:20:44.800\nI think is his hacker name.\n\n386\n00:20:44.800 --> 00:20:50.380\nBut he is a white hat,\nhe has his own security team.\n\n387\n00:20:50.380 --> 00:20:54.450\nAnd what they did is, well he did,\nis he went in and he actually broke and\n\n388\n00:20:54.450 --> 00:20:57.520\ncracked WPS, but it didnt hide it, right?\n\n389\n00:20:57.520 --> 00:21:00.630\nAgain, intention like Cherokee and\nI mentioned earlier,\n\n390\n00:21:00.630 --> 00:21:03.770\nthe intention was, hey,\nthis needs to be disabled.\n\n391\n00:21:03.770 --> 00:21:07.730\nThis is vulnerable, let's publish it,\nand publish it out to the world.\n\n392\n00:21:07.730 --> 00:21:11.888\nThe proof of concept that says, hey, this\nis not theoretical here we can do this.\n\n393\n00:21:11.888 --> 00:21:16.260\nAnd then,\nthrough disclosing information like that,\n\n394\n00:21:16.260 --> 00:21:20.240\na lot of the major manufacturers were\nwilling at that point to go back and\n\n395\n00:21:20.240 --> 00:21:22.150\nsay, maybe we should rethink this WPS.\n\n396\n00:21:22.150 --> 00:21:24.520\nBut had that information\nbeen kept private,\n\n397\n00:21:25.630 --> 00:21:27.770\nhow long would it been before\nsomebody else would have found it?\n\n398\n00:21:27.770 --> 00:21:30.800\nOr how long would it have been before the\nhackers would have been able to exploit\n\n399\n00:21:30.800 --> 00:21:32.410\nit, and we wouldn't have been\nable to protect our system?\n\n400\n00:21:32.410 --> 00:21:36.350\nSo there is many good things that come\nabout with open source intelligence.\n\n401\n00:21:36.350 --> 00:21:39.820\nBut again, with anything that's open\nsource that anybody else can read,\n\n402\n00:21:39.820 --> 00:21:42.670\nthe hackers or attackers, if you will,\ncan read it likewise, too.\n\n403\n00:21:42.670 --> 00:21:47.670\nAnd then last, of course, not least\nis things like the deep web where,\n\n404\n00:21:47.670 --> 00:21:50.210\nagain, goods and bads.\n\n405\n00:21:50.210 --> 00:21:55.340\nBut this would be one of the areas that\nyou can find another bulk of information.\n\n406\n00:21:55.340 --> 00:21:59.150\nAnd this might be something to where maybe\nit's the attackers that are using this\n\n407\n00:21:59.150 --> 00:22:00.710\nmore than the legit people.\n\n408\n00:22:00.710 --> 00:22:04.610\nBut, again, I guess to catch\nan attacker you have to become one too.\n\n409\n00:22:04.610 --> 00:22:08.120\nSo a lot of different resources that\nyou have out there when you look at\n\n410\n00:22:08.120 --> 00:22:08.849\nopen source intelligence.\n\n411\n00:22:09.850 --> 00:22:12.430\n&gt;&gt; All right Wes, that covers\njust about everything from script\n\n412\n00:22:12.430 --> 00:22:14.440\nkiddies all the way up\nto those nation states.\n\n413\n00:22:14.440 --> 00:22:17.770\nBut we don't want to discount any\nof those types of skill sets.\n\n414\n00:22:17.770 --> 00:22:19.970\nSo thank you for\njoining us ladies today, but for\n\n415\n00:22:19.970 --> 00:22:22.150\nthis particular show we're\ngonna go ahead and sign out.\n\n416\n00:22:22.150 --> 00:22:23.840\nRemember, I'm your host Cherokee Boose.\n\n417\n00:22:23.840 --> 00:22:24.670\n&gt;&gt; And I'm Wes Bryan.\n\n418\n00:22:24.670 --> 00:22:27.916\n&gt;&gt; See you here next time here at ITProTV.\n\n419\n00:22:27.916 --> 00:22:34.066\n[MUSIC]\n\n420\n00:22:34.066 --> 00:22:36.863\n&gt;&gt; Thank you for watching ITPro.TV\n\n",
          "vimeoId": "212754725"
        },
        {
          "description": "In this show, Cherokee and Wes discuss concepts associates with penetration testing. They explain different levels of tests such as black, grey and white box testing. Tune in to learn additional methods used to test an organizations security.",
          "length": "1360",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-4-penetration_testing_concepts-040617-PGM.00_22_25_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-4-penetration_testing_concepts-040617-PGM.00_22_25_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-4-penetration_testing_concepts-040617-PGM.00_22_25_02.Still001-sm.jpg",
          "title": "Penetration Testing Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:01.054\nWelcome to ITProTV,\n\n2\n00:00:01.054 --> 00:00:02.001\nI'm your host Don Pezet-\n\n3\n00:00:02.001 --> 00:00:08.683\n&gt;&gt; [CROSSTALK]\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:08.683 --> 00:00:11.733\n[MUSIC]\n\n5\n00:00:11.733 --> 00:00:14.459\n&gt;&gt; Welcome to your\nCompTIA Security Plus series.\n\n6\n00:00:14.459 --> 00:00:16.615\nI'm your show host Cherokee Boose.\n\n7\n00:00:16.615 --> 00:00:17.466\nIn this episode,\n\n8\n00:00:17.466 --> 00:00:21.117\nwe'll be talking about different types\nof penetration testing concepts.\n\n9\n00:00:21.117 --> 00:00:23.365\nAnd with us today we have Mr.\nWes Bryan in studio.\n\n10\n00:00:23.365 --> 00:00:24.895\nThank you for joining us Wes.\n\n11\n00:00:24.895 --> 00:00:27.920\n&gt;&gt; Hey, Cherokee, thanks for\nhaving me back, yep, and that's right,\n\n12\n00:00:27.920 --> 00:00:29.040\nthat's what we're gonna be looking at.\n\n13\n00:00:29.040 --> 00:00:33.390\nWe're gonna be looking at some different\nconcepts that they call out on the exam.\n\n14\n00:00:33.390 --> 00:00:35.590\nAnd we want you to be aware of them so\nwhen you go and\n\n15\n00:00:35.590 --> 00:00:38.900\ntake that exam if they ask you any of\nthese questions you're gonna be aware.\n\n16\n00:00:38.900 --> 00:00:42.000\nAnd if this is the first time maybe\nyou've heard some of these concepts so\n\n17\n00:00:42.000 --> 00:00:44.130\nyou can familiarize yourself with them.\n\n18\n00:00:44.130 --> 00:00:46.280\nSome of the first things\nthat they call out,\n\n19\n00:00:46.280 --> 00:00:48.730\nthey call out things like reconnaissance.\n\n20\n00:00:48.730 --> 00:00:50.660\nIf you look at reconnaissance\nwhat are we doing?\n\n21\n00:00:50.660 --> 00:00:52.620\nWe're trying to gather information.\n\n22\n00:00:52.620 --> 00:00:56.020\nWe're trying to find out\nabout whatever the target is,\n\n23\n00:00:56.020 --> 00:00:58.930\nwhatever the endpoint is\nthat we want to exploit.\n\n24\n00:00:58.930 --> 00:01:00.920\nAnd there's well, active reconnaissance.\n\n25\n00:01:00.920 --> 00:01:02.880\nAnd there's also passive reconnaissance.\n\n26\n00:01:02.880 --> 00:01:04.880\nI'm gonna go ahead and\ngo with a passive approach first.\n\n27\n00:01:04.880 --> 00:01:08.620\nThe passive approach might be the first\ntype of reconnaissance that they do.\n\n28\n00:01:08.620 --> 00:01:11.260\nThat then leads into\nactive reconnaissance.\n\n29\n00:01:11.260 --> 00:01:15.540\nSo for instance, passive reconnaissance\nmight be just taking information from\n\n30\n00:01:15.540 --> 00:01:16.920\npublic sources, right?\n\n31\n00:01:16.920 --> 00:01:20.480\nIf you look at, for instance that\nwe've talked in a previous episode,\n\n32\n00:01:20.480 --> 00:01:22.392\nabout open source intelligence, right?\n\n33\n00:01:22.392 --> 00:01:23.860\nWhen you look at open source intelligence,\n\n34\n00:01:23.860 --> 00:01:27.970\nthere's a lot of information out there\nmaybe about a company, maybe about\n\n35\n00:01:27.970 --> 00:01:33.290\na politician if that happens to be what\nyou're looking at, a banking firm.\n\n36\n00:01:33.290 --> 00:01:36.800\nThere's a lot of information\nsometimes in the open there,\n\n37\n00:01:36.800 --> 00:01:38.320\nthat they can do reconnaissance.\n\n38\n00:01:38.320 --> 00:01:39.690\nBut they're not actively, and\n\n39\n00:01:39.690 --> 00:01:43.940\nI hate to use the term with\nthe definition all in the same sentence.\n\n40\n00:01:43.940 --> 00:01:47.230\nBut they're not actively\ngoing at a network, right?\n\n41\n00:01:47.230 --> 00:01:51.300\nThey're trying to gather information, and\nit can be a little bit difficult right?\n\n42\n00:01:51.300 --> 00:01:54.492\nSometime the only information in\nthe passive reconnaissance attack\n\n43\n00:01:54.492 --> 00:01:57.055\nthat's available could be\nthings like archive data.\n\n44\n00:01:57.055 --> 00:02:02.030\nAnd archive data sometimes can be very\nold so it might not accurately reflect\n\n45\n00:02:02.030 --> 00:02:05.040\nthe information that they\nare trying to gain currently.\n\n46\n00:02:05.040 --> 00:02:09.190\nSo they can use information,\ndifferent gathering activities.\n\n47\n00:02:09.190 --> 00:02:09.760\nBut again,\n\n48\n00:02:09.760 --> 00:02:14.520\nkeep in mind what they're using is public\nrecords more often than anything, right.\n\n49\n00:02:14.520 --> 00:02:17.920\nLet's see, there's also semi passive too.\n\n50\n00:02:17.920 --> 00:02:20.880\nAnd they can do things like just\nlooking at network traffic.\n\n51\n00:02:20.880 --> 00:02:23.810\nBeing outside of your network and just\nseeing what's coming off of your network\n\n52\n00:02:23.810 --> 00:02:25.950\nnot necessarily attacking your network.\n\n53\n00:02:25.950 --> 00:02:30.320\nOr trying to gather information about the\ninsides of your network maybe what kind of\n\n54\n00:02:30.320 --> 00:02:32.880\nresources you are using\nto connect outbound.\n\n55\n00:02:32.880 --> 00:02:36.407\nOr using cloud based resources,\ncan we see that information.\n\n56\n00:02:36.407 --> 00:02:41.350\nBut then we lead into\nactive reconnaissance.\n\n57\n00:02:41.350 --> 00:02:44.250\nAnd active reconnaissance is\ngonna go a step farther, right?\n\n58\n00:02:44.250 --> 00:02:46.670\nThis is where they're\ngoing to engage a target.\n\n59\n00:02:46.670 --> 00:02:47.740\nThey're gonna look at a target, and\n\n60\n00:02:47.740 --> 00:02:52.220\nthey're gonna say, now we're gonna do\nthings a little bit more intrusive, right?\n\n61\n00:02:52.220 --> 00:02:53.740\nThings like port scanning, right?\n\n62\n00:02:53.740 --> 00:02:59.090\nThings like ping sweeps, using things like\nNMAP, to try to do OS fingerprinting.\n\n63\n00:02:59.090 --> 00:03:02.150\nI wanna know what systems\nare on your network.\n\n64\n00:03:02.150 --> 00:03:04.050\nWell, if I can do things like port scans,\nright?\n\n65\n00:03:04.050 --> 00:03:06.760\nAnd I can find the ports\nthat are open on a machine.\n\n66\n00:03:06.760 --> 00:03:09.240\nLet's just say randomly I do\na port scan on a machine and\n\n67\n00:03:09.240 --> 00:03:14.570\nI find things like port 389 that are open,\nport 88, port 53, right.\n\n68\n00:03:14.570 --> 00:03:19.240\nI can tell that well,\nport 389, that's LDAP right?\n\n69\n00:03:19.240 --> 00:03:22.390\nPort 53, well, that's DNS.\n\n70\n00:03:22.390 --> 00:03:24.790\nPort 88 is Kerberos authentication.\n\n71\n00:03:24.790 --> 00:03:28.610\nGo a little bit farther,\nright, and I find port 139, or\n\n72\n00:03:28.610 --> 00:03:32.840\nI guess 139 and 445,\nnow we've got Microsoft specific ports.\n\n73\n00:03:32.840 --> 00:03:36.200\nAnd in reconnaissance in this nature,\njust by the port scan,\n\n74\n00:03:36.200 --> 00:03:40.210\nI can tell that you're probably running\na domain controller of some sort.\n\n75\n00:03:40.210 --> 00:03:41.270\nAnd even more so,\n\n76\n00:03:41.270 --> 00:03:46.740\na domain controller with an active\ndirectory integrated DNS zone, right?\n\n77\n00:03:46.740 --> 00:03:49.070\nAll by the ports, just the ports alone.\n\n78\n00:03:49.070 --> 00:03:51.860\nSo active can be detected.\n\n79\n00:03:51.860 --> 00:03:54.790\nAnd that's why active and passive,\nagain, two different approaches.\n\n80\n00:03:54.790 --> 00:03:57.150\nPassive is a little bit harder to detect.\n\n81\n00:03:57.150 --> 00:03:59.490\nOf course,\nit's harder on both sides, right?\n\n82\n00:03:59.490 --> 00:04:00.450\nIt's harder to detect.\n\n83\n00:04:00.450 --> 00:04:04.080\nBut it's harder to gain more relevant,\nup to date information.\n\n84\n00:04:04.080 --> 00:04:06.662\nCuz again, you might just be looking\nat things like press conferences.\n\n85\n00:04:06.662 --> 00:04:10.290\nAgain, like what we've talked about\nwith open-source intelligence, right.\n\n86\n00:04:10.290 --> 00:04:14.140\nCould be archive, backup information,\nand not backups in the way that\n\n87\n00:04:14.140 --> 00:04:17.645\nwe think of saving our information, but\nold archive data that's just out of date.\n\n88\n00:04:17.645 --> 00:04:22.305\nWhere the active reconnaissance,\nthat's gonna give you more information.\n\n89\n00:04:22.305 --> 00:04:26.285\nThat's gonna make it easier to find the\ninformation that you're looking for, but\n\n90\n00:04:26.285 --> 00:04:30.025\nit also leads to things like\nyou're tripping your IDS systems.\n\n91\n00:04:30.025 --> 00:04:33.056\nYour IPS system if they have\nintrusion prevention symptoms.\n\n92\n00:04:33.056 --> 00:04:36.274\nIf they have things like network\nbased intrusion detection systems,\n\n93\n00:04:36.274 --> 00:04:38.640\nthey might become a little\nbit more aware of this.\n\n94\n00:04:38.640 --> 00:04:43.115\nSo they might start with\nthe passive reconnaissance, and\n\n95\n00:04:43.115 --> 00:04:46.900\nthen once they gather enough information\nand maybe it's leading them to dead ends,\n\n96\n00:04:46.900 --> 00:04:48.900\nthey can only gather so much information.\n\n97\n00:04:48.900 --> 00:04:51.580\nWell now they look at\na target like your firewall.\n\n98\n00:04:51.580 --> 00:04:55.190\nIf you're in a DMZ,\nI got public facing resources in my DMZ.\n\n99\n00:04:55.190 --> 00:04:57.310\nAny of those public servers,\nare those public servers?\n\n100\n00:04:57.310 --> 00:04:59.110\nCuz everybody else can\ngain access to them,\n\n101\n00:04:59.110 --> 00:05:02.820\nbut can we leap frog off of those devices?\n\n102\n00:05:02.820 --> 00:05:07.450\nCan we attack that device and then turn\naround and go attack a next device and\n\n103\n00:05:07.450 --> 00:05:10.630\nthat actually brings us\ninto our next subject here.\n\n104\n00:05:10.630 --> 00:05:14.438\n&gt;&gt; But before we move forward, I just\nwanted to point out the fact, whether it\n\n105\n00:05:14.438 --> 00:05:18.920\nbe active, passive, semi-passive, all of\nthose techniques are pretty important.\n\n106\n00:05:18.920 --> 00:05:23.120\nBecause if you look at it from\na penetration testing standpoint or\n\n107\n00:05:23.120 --> 00:05:28.570\nan attacking standpoint or\na legitimate work standpoint.\n\n108\n00:05:28.570 --> 00:05:31.750\nEven taking it from the angle of\nbusiness side or project management.\n\n109\n00:05:31.750 --> 00:05:35.110\nIf you look at even several different\ndisciplines out there, the first few\n\n110\n00:05:35.110 --> 00:05:40.750\nstages or phases, that's where you\nspend the vast majority of your time.\n\n111\n00:05:40.750 --> 00:05:42.760\nSo this is really an important concept.\n\n112\n00:05:42.760 --> 00:05:47.380\nBecause, the more preemptive or\nplanning that you do can really\n\n113\n00:05:47.380 --> 00:05:51.370\nresult in a successful test overall.\n\n114\n00:05:51.370 --> 00:05:55.930\n&gt;&gt; Definitely, and let's also go ahead and\nI believe we should be\n\n115\n00:05:55.930 --> 00:05:59.470\ntalking about this too, because one of\nthe things looking at my notes here.\n\n116\n00:05:59.470 --> 00:06:03.740\nOne of the things that they also call out\nwhen we talk about penetration testing,\n\n117\n00:06:03.740 --> 00:06:05.370\nis knowing the difference between that.\n\n118\n00:06:05.370 --> 00:06:08.810\nAnd I'm gonna jump\naround in my notes here.\n\n119\n00:06:08.810 --> 00:06:11.620\nWhen they talk about penetration testing,\nkeep in mind,\n\n120\n00:06:11.620 --> 00:06:16.380\nthat and vulnerability scanning\nare not the same exact thing.\n\n121\n00:06:16.380 --> 00:06:19.990\nSometimes the term vulnerability\nscanning is used as pen testing and\n\n122\n00:06:19.990 --> 00:06:21.640\nthat's really not the case.\n\n123\n00:06:21.640 --> 00:06:26.280\nAnd which vulnerability scanning, what\nwe're doing was we're trying to identify\n\n124\n00:06:26.280 --> 00:06:29.020\nand quantify the vulnerabilities here.\n\n125\n00:06:29.020 --> 00:06:33.510\nWe're trying to provide\nmitigation techniques.\n\n126\n00:06:33.510 --> 00:06:36.040\nA pen test is not doing that.\n\n127\n00:06:36.040 --> 00:06:38.230\nThat might be part of a penetration test,\nbut\n\n128\n00:06:38.230 --> 00:06:43.040\nthat's only a small part of a larger type\nof test that really is doing things like\n\n129\n00:06:43.040 --> 00:06:48.700\nsimulating the same type of actions an\nattacker would take against your systems.\n\n130\n00:06:48.700 --> 00:06:53.440\nVulnerability scan again is just trying\nto identify what are the vulnerabilities.\n\n131\n00:06:53.440 --> 00:06:56.190\nWhere a penetration testing\ncould start with that, right?\n\n132\n00:06:56.190 --> 00:07:00.220\nCould run something like Nessus,\nwhere you doing vulnerability scanning.\n\n133\n00:07:00.220 --> 00:07:03.520\nBut once you find the vulnerabilities,\nthe pen test goes a little bit further and\n\n134\n00:07:03.520 --> 00:07:06.000\nit starts to exploit those\ntype of vulnerabilities.\n\n135\n00:07:06.000 --> 00:07:10.490\n&gt;&gt; So a vulnerability scan\nis a passive technique.\n\n136\n00:07:10.490 --> 00:07:15.064\nWhereas penetration may be active in\nthe sense that once that vulnerability has\n\n137\n00:07:15.064 --> 00:07:19.660\nbeen brought to light, they take\nsome type of action to act on it and\n\n138\n00:07:19.660 --> 00:07:23.590\nsee how maybe that company reacts,\nor what the outcome of acting maybe.\n\n139\n00:07:23.590 --> 00:07:24.600\n&gt;&gt; Definitely, and\n\n140\n00:07:24.600 --> 00:07:28.400\nvulnerability scanning a lot of times\nis an internal attack, not an attack.\n\n141\n00:07:28.400 --> 00:07:32.180\nAgain, it's not an attack it's a technique\nbut a vulnerability scan a lot of times is\n\n142\n00:07:32.180 --> 00:07:36.110\nfrom inside of your network Penetration\ntesting doesn't stop there.\n\n143\n00:07:36.110 --> 00:07:37.180\nIt can start there.\n\n144\n00:07:37.180 --> 00:07:38.260\nIt can be internal.\n\n145\n00:07:38.260 --> 00:07:39.480\nBut we can also do external.\n\n146\n00:07:39.480 --> 00:07:43.300\nIf you think about it in a good\npenetration test you are not only doing\n\n147\n00:07:43.300 --> 00:07:46.180\nfrom the external side, you are also\ndoing this from the internal side.\n\n148\n00:07:46.180 --> 00:07:47.000\nWhy?\n\n149\n00:07:47.000 --> 00:07:50.710\nWhy would we care about doing penetration\ntesting going out of our network?\n\n150\n00:07:50.710 --> 00:07:52.159\nWell, malicious insiders, right?\n\n151\n00:07:53.900 --> 00:07:57.465\nCan we classify that if we've got\nsensitive information, can it make it up?\n\n152\n00:07:57.465 --> 00:07:58.933\n&gt;&gt; DLP?\n&gt;&gt; There we go, data loss protection,\n\n153\n00:07:58.933 --> 00:08:00.068\ndata leak prevention, too.\n\n154\n00:08:00.068 --> 00:08:01.363\nWe were talking about this one.\n&gt;&gt; [LAUGH]\n\n155\n00:08:01.363 --> 00:08:03.006\n&gt;&gt; This is another one that you'll see\n\n156\n00:08:03.006 --> 00:08:03.943\non the exam, guys.\n\n157\n00:08:03.943 --> 00:08:07.228\nAnd I'm gonna give you two\ndifferent acronyms here.\n\n158\n00:08:07.228 --> 00:08:09.729\nWell no, same acronym,\ntwo different names, right?\n\n159\n00:08:09.729 --> 00:08:11.090\nDLP, right?\n\n160\n00:08:11.090 --> 00:08:15.190\nData Loss Prevention, and\nData Leak Prevention.\n\n161\n00:08:15.190 --> 00:08:19.260\nSo penetration testing can also do\nthe outbound nature as well, right?\n\n162\n00:08:19.260 --> 00:08:22.590\nWhat happens if we're using encryption,\nright?\n\n163\n00:08:22.590 --> 00:08:26.650\nIf we're using encryption and somebody is\nsending information out of our network,\n\n164\n00:08:26.650 --> 00:08:28.812\nhow do we know what that information is,\nright?\n\n165\n00:08:28.812 --> 00:08:33.185\nAnd that's where we get things like SSL\ndecriptors if you will, that actually it\n\n166\n00:08:33.185 --> 00:08:36.790\nkinda performs a company oriented man\nin the middle attack where they've\n\n167\n00:08:36.790 --> 00:08:41.060\ngot the certificate that was used to\nencrypt the information but they also got\n\n168\n00:08:41.060 --> 00:08:44.900\nthe key that helps to decrypt so we could\nsee what is going out of our network.\n\n169\n00:08:44.900 --> 00:08:46.940\nSo keep that in mind and\nI know I'm kind of rambling here but\n\n170\n00:08:46.940 --> 00:08:49.910\nkeep in mind that penetration\ntesting is go a lot further.\n\n171\n00:08:49.910 --> 00:08:52.170\nVulnerability scanning\ncould just be one facet.\n\n172\n00:08:52.170 --> 00:08:55.000\nOne small facet of an overall\npenetration testing and\n\n173\n00:08:55.000 --> 00:08:57.690\nit's usually done from with\ninside of your network.\n\n174\n00:08:57.690 --> 00:08:59.250\nSo we do have to keep that in mind.\n\n175\n00:08:59.250 --> 00:09:01.630\nNow that brings me to my next point,\nright?\n\n176\n00:09:01.630 --> 00:09:04.160\nOnce we have done our active\nreconnaissance, right.\n\n177\n00:09:04.160 --> 00:09:05.470\nWe've done our port scans.\n\n178\n00:09:05.470 --> 00:09:09.850\nWe've done things like finding\nout what an operating system is.\n\n179\n00:09:09.850 --> 00:09:12.434\nNow we have to make our way\ninto the network, all right.\n\n180\n00:09:12.434 --> 00:09:14.639\nNow once you make your\nway into the network,\n\n181\n00:09:14.639 --> 00:09:17.560\nthe very first system that is\ncompromised right, and when\n\n182\n00:09:17.560 --> 00:09:21.675\nwe say compromised it might be something\nlike a privilege escalation attempt, or\n\n183\n00:09:21.675 --> 00:09:24.780\nmaybe they've got administrative\nlevel access machine.\n\n184\n00:09:24.780 --> 00:09:27.320\nCould be just the fact that they got\naccess to the machine to begin with.\n\n185\n00:09:27.320 --> 00:09:30.790\nThis is called a pivot point, if you will.\n\n186\n00:09:30.790 --> 00:09:33.780\nPivoting is a technique\nessentially that allows,\n\n187\n00:09:33.780 --> 00:09:37.360\nit's the first system that's compromised,\nand\n\n188\n00:09:37.360 --> 00:09:42.030\nfrom there it allows the attacker\nto move around within the network.\n\n189\n00:09:42.030 --> 00:09:46.470\nBasically using the first compromised\nsystem to aid in the compromise of\n\n190\n00:09:46.470 --> 00:09:47.820\nother systems within the network.\n\n191\n00:09:47.820 --> 00:09:50.750\nSo, for instance,\nI've got a little diagram here, right?\n\n192\n00:09:50.750 --> 00:09:53.750\nSo if we talk about somebody coming\nin off of the internet, right, and\n\n193\n00:09:53.750 --> 00:09:55.960\nmaybe they make their way through our DMZ.\n\n194\n00:09:55.960 --> 00:09:57.860\nAnd I'm gonna go ahead,\nthis is our internal network, but\n\n195\n00:09:57.860 --> 00:10:00.340\nthis circle is gonna get in my way here.\n\n196\n00:10:00.340 --> 00:10:04.400\nThis happens to be the first server,\nright, first machine that they attack.\n\n197\n00:10:04.400 --> 00:10:05.860\nWell, what can they do for here?\n\n198\n00:10:05.860 --> 00:10:09.380\nAgain, keep in mind, when we talk about\npivoting, we're talking about what is\n\n199\n00:10:09.380 --> 00:10:11.770\nthe next system from here\nthat we can attack, right?\n\n200\n00:10:11.770 --> 00:10:13.170\nThat's your pivot point.\n\n201\n00:10:13.170 --> 00:10:14.490\nAnd then it goes farther there.\n\n202\n00:10:14.490 --> 00:10:21.146\nBasically, it's just another one\nof those arsenals of pen testing.\n\n203\n00:10:21.146 --> 00:10:25.090\nOnce the host is compromised then\nthe pen tester they're gonna look for\n\n204\n00:10:25.090 --> 00:10:28.058\nwell what's the next thing\nthat I can gain access to?\n\n205\n00:10:28.058 --> 00:10:31.052\nMaybe the system that we pivot\nfrom might lead us into,\n\n206\n00:10:31.052 --> 00:10:36.040\nmaybe your even looking at the data that's\nin the system that you are pivoting from.\n\n207\n00:10:36.040 --> 00:10:38.520\nBut a lot of times,\nthat might not be the end goal.\n\n208\n00:10:38.520 --> 00:10:42.875\nI don't know how often it happens that you\ntry to attack something you're like woah,\n\n209\n00:10:42.875 --> 00:10:43.912\nI hit the gold mine.\n\n210\n00:10:43.912 --> 00:10:45.236\nBut it could happen.\n\n211\n00:10:45.236 --> 00:10:47.090\n&gt;&gt; Final destination on the first try.\n\n212\n00:10:47.090 --> 00:10:50.470\n&gt;&gt; Let's hope not,\nbecause then you've got a lot of\n\n213\n00:10:50.470 --> 00:10:52.900\nbad problems if somebody\ncan get into your network.\n\n214\n00:10:52.900 --> 00:10:55.650\nAnd yeah, I found Fort Knox and\nI only had to get into the first system.\n\n215\n00:10:55.650 --> 00:10:58.090\nSo, that's why we always use\na layered defense system.\n\n216\n00:10:58.090 --> 00:11:00.660\nBut that's the part about pivoting.\n\n217\n00:11:00.660 --> 00:11:02.707\nCouple of other things\nthat they talked about,\n\n218\n00:11:02.707 --> 00:11:04.840\nthey talked about information plundering.\n\n219\n00:11:04.840 --> 00:11:07.910\n&gt;&gt; So I assume we're not talking\nabout Pirates of the Caribbean, Wes.\n\n220\n00:11:07.910 --> 00:11:11.070\n&gt;&gt; No, not really, but I mean I guess\nfiguratively it could be the same thing.\n\n221\n00:11:11.070 --> 00:11:15.150\nYou're trying to scrape whatever you can,\nright?\n\n222\n00:11:15.150 --> 00:11:17.590\nSome of the things of information\nplundering that they're doing.\n\n223\n00:11:17.590 --> 00:11:20.570\nYou user accounts, right,\nyour user account database.\n\n224\n00:11:20.570 --> 00:11:23.720\nCould be things like not only your user\naccounts for your internal employees, but\n\n225\n00:11:23.720 --> 00:11:25.130\nif you have things like HIPAA, right,\n\n226\n00:11:25.130 --> 00:11:28.760\nHIPAA compliance that you're trying\nto comply with, if you will.\n\n227\n00:11:28.760 --> 00:11:32.960\nYou might have things like medical\nrecords, right, sensitive information and\n\n228\n00:11:32.960 --> 00:11:36.140\nthat is probably one of the things\nthat they're gonna go out.\n\n229\n00:11:36.140 --> 00:11:38.680\nThe other thing is,\nthink about this, password hashes.\n\n230\n00:11:39.690 --> 00:11:44.500\nNormally you have a hash value of\npassword stored in maybe a directory.\n\n231\n00:11:44.500 --> 00:11:46.150\nSo maybe they try to get\ninto your directory.\n\n232\n00:11:46.150 --> 00:11:49.180\nNow, if they get, and\nlet me be specific on that.\n\n233\n00:11:49.180 --> 00:11:51.130\nThey try to get in to your\ndirectory server, right.\n\n234\n00:11:51.130 --> 00:11:53.390\nWell, why would that be such a bad thing?\n\n235\n00:11:54.760 --> 00:11:56.207\nThink about what a directory server is.\n\n236\n00:11:56.207 --> 00:11:57.320\nWhat is it do?\n\n237\n00:11:57.320 --> 00:12:03.080\nIt contains a database of every object\nthat's in your corporate domain.\n\n238\n00:12:03.080 --> 00:12:04.131\nThink about how valuable that is and\n\n239\n00:12:04.131 --> 00:12:05.751\nhow much information it could\nbe a lot of information.\n\n240\n00:12:05.751 --> 00:12:07.500\n&gt;&gt; Any network documentation.\n\n241\n00:12:07.500 --> 00:12:08.970\n&gt;&gt; That's right.\n\n242\n00:12:08.970 --> 00:12:09.880\nThere's another one.\n\n243\n00:12:09.880 --> 00:12:11.650\nThings like your IP spreadsheet, right?\n\n244\n00:12:11.650 --> 00:12:13.760\nWhere you're doing IP documentation.\n\n245\n00:12:13.760 --> 00:12:16.180\nYou need to make sure of\nwhat addresses you have.\n\n246\n00:12:16.180 --> 00:12:19.040\nIf you're doing good documentation\nyou should have this information.\n\n247\n00:12:19.040 --> 00:12:22.745\nWell, that, right there's a valuable\nsource of information, right?\n\n248\n00:12:22.745 --> 00:12:26.190\nCuz it basically, blueprints the logical\naspect of your network, right?\n\n249\n00:12:26.190 --> 00:12:30.327\nAll of your server names,\nyour FQDNs, right?\n\n250\n00:12:30.327 --> 00:12:32.280\nYour, what else?\n\n251\n00:12:32.280 --> 00:12:36.110\n&gt;&gt; Topology maps, any kind of wiring\nschematics if you think about it from\n\n252\n00:12:36.110 --> 00:12:38.080\na physical security standpoint.\n\n253\n00:12:38.080 --> 00:12:39.747\n&gt;&gt; Most definitely.\n\n254\n00:12:39.747 --> 00:12:42.750\nAnd then, what does it do after that?\n\n255\n00:12:42.750 --> 00:12:46.790\nWell, if I get things like my directory\nservices data base, if we get things\n\n256\n00:12:46.790 --> 00:12:52.560\nlike our topology maps, when that happens\nthat gives us knowledge of other systems.\n\n257\n00:12:52.560 --> 00:12:55.590\nAll right, and once we have knowledge that\nother systems exist within your networks,\n\n258\n00:12:55.590 --> 00:12:58.800\nwhich they probably already\nconsider that to be true,\n\n259\n00:12:58.800 --> 00:13:00.510\nbut they don't know\nwhat those systems are.\n\n260\n00:13:00.510 --> 00:13:03.583\nBut now that I have things like\nthe fully qualified domain names.\n\n261\n00:13:03.583 --> 00:13:04.882\n&gt;&gt; [LAUGH] I have the road map, literally.\n\n262\n00:13:04.882 --> 00:13:06.180\n[LAUGH]\n&gt;&gt; That's exactly it.\n\n263\n00:13:06.180 --> 00:13:10.290\nWhen you're talking about combination\nof your logical documentation,\n\n264\n00:13:10.290 --> 00:13:11.500\nlike IP spreadsheets.\n\n265\n00:13:11.500 --> 00:13:13.210\nYou're talking about your user accounts.\n\n266\n00:13:13.210 --> 00:13:15.760\nYou're talking about\nyour directory objects.\n\n267\n00:13:15.760 --> 00:13:18.730\nNow you've got the logical, and\nyou map that out with the physical, and\n\n268\n00:13:18.730 --> 00:13:19.710\nnow you really have a bad day.\n\n269\n00:13:19.710 --> 00:13:23.720\nAnd that could be something as simple\nas building blueprints, right?\n\n270\n00:13:23.720 --> 00:13:27.310\nNow I know what rooms, where\nthe buildings are, where exit points,\n\n271\n00:13:27.310 --> 00:13:29.680\nentry points are in your building as well.\n\n272\n00:13:29.680 --> 00:13:32.520\nSo information plundering, all right, so\n\n273\n00:13:32.520 --> 00:13:38.060\nwhat are some of the techniques that they\ncan use to do information plundering?\n\n274\n00:13:38.060 --> 00:13:43.405\nWell, they can use things like netcat\nrelays, SSH, local port forwarding,\n\n275\n00:13:43.405 --> 00:13:47.675\nSSH dynamic port forwarding are some\nof the things, things like Nmap, right?\n\n276\n00:13:47.675 --> 00:13:49.605\nNmap's one very good one for\n\n277\n00:13:49.605 --> 00:13:53.775\nsending port scans against the system\nto find out more information about it.\n\n278\n00:13:53.775 --> 00:13:55.615\nTo do the OS fingerprinting as well.\n\n279\n00:13:56.625 --> 00:14:00.863\nSo yeah keep in mind, yeah,\nwhile we are not talking about pirates,\n\n280\n00:14:00.863 --> 00:14:05.044\nin the end I don't know if the goal\nis any less devastating for sure.\n\n281\n00:14:05.044 --> 00:14:08.731\n[LAUGH] I don't know if it makes\nfive sequels of a movie though.\n\n282\n00:14:08.731 --> 00:14:13.660\n[LAUGH] Another concept that they\ntalked about is initial exploitation.\n\n283\n00:14:13.660 --> 00:14:15.080\nWhat is initial exploitation?\n\n284\n00:14:16.630 --> 00:14:21.650\nThe initial exploits gonna try to find\nsome kind of loop hole in an application\n\n285\n00:14:21.650 --> 00:14:25.090\nthat grants access to the system, right.\n\n286\n00:14:25.090 --> 00:14:28.350\nAnd a lot of times what' that's gonna\nhappen is some kind of privilege\n\n287\n00:14:28.350 --> 00:14:29.710\nescalation, right.\n\n288\n00:14:29.710 --> 00:14:33.400\nStandard users just can't move around\nthe network as they want, right.\n\n289\n00:14:33.400 --> 00:14:36.380\nThat's why we restrict\nthings through ACLs.\n\n290\n00:14:36.380 --> 00:14:38.640\nWe use the principle of least privilege,\nright.\n\n291\n00:14:38.640 --> 00:14:41.540\nOnly giving your standard users\nthe level of access that they need\n\n292\n00:14:41.540 --> 00:14:44.690\nto complete their job,\nno more no less, right?\n\n293\n00:14:44.690 --> 00:14:48.830\nWell, if I can get a privilege escalation,\nright, through that initial exploitation,\n\n294\n00:14:48.830 --> 00:14:51.760\nthen what I can do is,\nI can use my pivot point in\n\n295\n00:14:51.760 --> 00:14:56.570\nthe context of a systems administrator to\nexploit systems after that, all right.\n\n296\n00:14:56.570 --> 00:14:58.970\nSo how would that kind\nof access be gained?\n\n297\n00:14:58.970 --> 00:15:03.460\nWell some of the things that you could do,\ncommand line interpretors right.\n\n298\n00:15:03.460 --> 00:15:04.813\nYour terminals, your shells if you will,\n\n299\n00:15:04.813 --> 00:15:07.270\nI know I'm giving you some terms that\nare kind of synonymous with each other.\n\n300\n00:15:07.270 --> 00:15:09.511\nSomebody might say drop\ndown to the terminal,\n\n301\n00:15:09.511 --> 00:15:11.180\nor drop down to the shell, right.\n\n302\n00:15:11.180 --> 00:15:14.711\nThings like Windows command prompt,\nPowerShell if you will.\n\n303\n00:15:14.711 --> 00:15:19.682\nThese are ways that you can gain\nan access, other things that we talked\n\n304\n00:15:19.682 --> 00:15:24.752\nabout how about remote rogue code\nexploitation if I can say that right.\n\n305\n00:15:24.752 --> 00:15:29.651\nInjecting some code into a system that\ngives you that privilege escalation\n\n306\n00:15:29.651 --> 00:15:32.993\nnow that you want to make\nagain initially exploit so\n\n307\n00:15:32.993 --> 00:15:36.817\nyou can move on to the other systems,\ncommand objection.\n\n308\n00:15:36.817 --> 00:15:40.671\nA common one phishing, could be just\nas basic as social engineering gives me\n\n309\n00:15:40.671 --> 00:15:41.997\nprivilege level access,\n\n310\n00:15:41.997 --> 00:15:45.750\nbecause I happen to be talking to\nsomebody that does have the privileges.\n\n311\n00:15:45.750 --> 00:15:49.790\nMaybe I gained or\ngleaned their password out of them,\n\n312\n00:15:49.790 --> 00:15:53.160\nand now I have an avenue\nof attack into the system.\n\n313\n00:15:54.960 --> 00:15:58.630\nAll right a few other things that\nthey are talking about here.\n\n314\n00:15:58.630 --> 00:16:01.805\nThey talked about persistence.\n\n315\n00:16:01.805 --> 00:16:03.600\nPersistence is exactly\nwhat it sounds like.\n\n316\n00:16:03.600 --> 00:16:04.925\nNever give up, right.\n\n317\n00:16:04.925 --> 00:16:06.597\nPersistence basically,\n\n318\n00:16:06.597 --> 00:16:11.391\nthat's the approach that a lot of real\nworld attackers are gonna utilize.\n\n319\n00:16:11.391 --> 00:16:16.122\nFor instance, they're not gonna just\nlimit them The limit of an attack if\n\n320\n00:16:16.122 --> 00:16:18.803\nyou will to maybe two weeks and\nwe move on.\n\n321\n00:16:18.803 --> 00:16:22.075\nNo, we talk about things like\nadvanced persistent threats, right.\n\n322\n00:16:22.075 --> 00:16:26.274\nThis is gonna be an ongoing attack right,\nan ongoing attack were gonna keep\n\n323\n00:16:26.274 --> 00:16:29.220\ntrying when it comes to\nbreaking into that network.\n\n324\n00:16:29.220 --> 00:16:32.010\nAgain from the perspective\nof we say attackers,\n\n325\n00:16:32.010 --> 00:16:36.420\nbut keep in mind that's what penetration\ntesting is about right, we're assuming\n\n326\n00:16:36.420 --> 00:16:39.580\nthe role of the attacker and\ntrying to make our way into the system.\n\n327\n00:16:39.580 --> 00:16:43.790\nBasically what we're looking for\nis an opening to strike at.\n\n328\n00:16:43.790 --> 00:16:46.440\nAnd once we find that opening,\nwe exploit it.\n\n329\n00:16:46.440 --> 00:16:51.120\nIt could be, and persistence here\ncould be monitoring a target for\n\n330\n00:16:51.120 --> 00:16:55.150\na long time, could be a good span of time,\nwe're just monitoring, we're waiting.\n\n331\n00:16:55.150 --> 00:16:59.840\nWe're waiting patiently and when we find\nour avenue of attack, we get in there and\n\n332\n00:16:59.840 --> 00:17:00.460\nwe exploit it.\n\n333\n00:17:02.000 --> 00:17:06.050\nLet's see, some of the other\nthings that they mentioned too.\n\n334\n00:17:06.050 --> 00:17:07.190\nThey mentioned things like,\n\n335\n00:17:07.190 --> 00:17:10.730\nand we've kind of already talked\nabout this, escalation of privileges.\n\n336\n00:17:10.730 --> 00:17:14.820\nTrying to gain that root user access,\nsuper user access if you will,\n\n337\n00:17:14.820 --> 00:17:20.540\nWindows administrative access cuz keep\nin mind that administrative level access\n\n338\n00:17:20.540 --> 00:17:24.050\nallows us to do a lot more than\nstandard user access, right.\n\n339\n00:17:24.050 --> 00:17:25.790\nIf I've got administrative level access,\n\n340\n00:17:25.790 --> 00:17:28.110\nnow I can do things like\ninstall drivers in a system.\n\n341\n00:17:28.110 --> 00:17:31.380\nYou say well Wes, that's not a bad thing.\n\n342\n00:17:31.380 --> 00:17:36.790\nWell yes it is if I turn off file\ndriver signature enforcements.\n\n343\n00:17:36.790 --> 00:17:37.810\nThey use a couple of different terms.\n\n344\n00:17:37.810 --> 00:17:41.090\nThey say file signature enforcement but\nit's driver signature enforcement.\n\n345\n00:17:41.090 --> 00:17:46.140\nIf I turn that off, now I can inject any\ncode into the operating system I want.\n\n346\n00:17:46.140 --> 00:17:50.040\nAnd it's an administrator or a hacker\nthat has administrator level privileges,\n\n347\n00:17:50.040 --> 00:17:53.170\nnow we inject things like rogue code,\nright.\n\n348\n00:17:53.170 --> 00:17:55.780\nBack right out of the system and\nlet the code go to work, and\n\n349\n00:17:55.780 --> 00:17:57.940\nwe can monitor it over time and\nattack it again.\n\n350\n00:17:57.940 --> 00:18:02.470\nSo again escalation of privileges,\nthat's just an attack that seeks to get,\n\n351\n00:18:02.470 --> 00:18:06.050\nnot the standard user access, but\nthe access that administrators would have.\n\n352\n00:18:07.160 --> 00:18:10.340\n&gt;&gt; Now, Wes, we want to take a look at\ndifferent classifications of different\n\n353\n00:18:10.340 --> 00:18:11.630\ntypes of penetration tests.\n\n354\n00:18:11.630 --> 00:18:12.550\nWhere do you want to start?\n\n355\n00:18:12.550 --> 00:18:14.390\nOr what should we know about first?\n\n356\n00:18:14.390 --> 00:18:17.170\n&gt;&gt; Well, they call out, they call\nout three different types, right?\n\n357\n00:18:17.170 --> 00:18:19.910\nThey call out what's known\nas black box testing.\n\n358\n00:18:19.910 --> 00:18:21.620\nThey call out grey box testing.\n\n359\n00:18:21.620 --> 00:18:22.590\nAnd they call out white box.\n\n360\n00:18:22.590 --> 00:18:25.200\nIt's probably has to do with\na different way, order, though, so.\n\n361\n00:18:25.200 --> 00:18:27.970\nBlack box, white box,\nand gray box, all right.\n\n362\n00:18:27.970 --> 00:18:32.300\nAnd really what this boils down to,\nit's kind of a metric on how much\n\n363\n00:18:32.300 --> 00:18:36.360\nan attacker or a pen tester knows\nabout a system beforehand, right.\n\n364\n00:18:36.360 --> 00:18:40.520\nSo when we look at black box testing,\nright, also sometimes known as behavioral\n\n365\n00:18:40.520 --> 00:18:45.060\ntesting, basically what we're doing\nis the internal infrastructure,\n\n366\n00:18:45.060 --> 00:18:49.650\nthe internal architecture, the design,\nthe implementation, it's not known.\n\n367\n00:18:49.650 --> 00:18:51.100\nIt's not known to whoever's testing it.\n\n368\n00:18:51.100 --> 00:18:54.410\nIt's basically like you're going into\nthe attack with your blinders on.\n\n369\n00:18:54.410 --> 00:18:57.790\nAnd you got to figure your way out because\nyou know nothing about the system.\n\n370\n00:18:57.790 --> 00:18:59.970\nUnlike the opposite side.\n\n371\n00:18:59.970 --> 00:19:03.680\nWhite box testing you pretty\nmuch are fully aware, right.\n\n372\n00:19:03.680 --> 00:19:08.340\nThe internal infrastructure,\nthe internal design, if you will,\n\n373\n00:19:08.340 --> 00:19:11.870\nthe implementation of any of\nthe items that you're attacking.\n\n374\n00:19:11.870 --> 00:19:13.280\nHow they were implemented, right?\n\n375\n00:19:13.280 --> 00:19:17.050\nSo you're aware, fully aware, clear box\ntesting sometimes they might call it too,\n\n376\n00:19:17.050 --> 00:19:19.560\nbecause you have full\nknowledge of the information.\n\n377\n00:19:19.560 --> 00:19:22.260\nThe other one, did you have a question?\n\n378\n00:19:22.260 --> 00:19:27.100\n&gt;&gt; Well, I'm just seeing the value and\na black box type of penetration test,\n\n379\n00:19:27.100 --> 00:19:31.350\nbecause I'm not getting that biased or\nskewed perspective,\n\n380\n00:19:31.350 --> 00:19:34.660\nas if someone internal were\nperforming the penetration test.\n\n381\n00:19:34.660 --> 00:19:37.130\nBecause if they have their hand\nin designing the network or\n\n382\n00:19:37.130 --> 00:19:42.900\nimplementing a system or security system\nconfigurations, they may not be able to\n\n383\n00:19:42.900 --> 00:19:48.290\nsee all the potential vulnerabilities that\nsomeone with an outside perspective has.\n\n384\n00:19:48.290 --> 00:19:52.800\nSo having that lack of knowledge can\nreally be beneficial in many aspects.\n\n385\n00:19:52.800 --> 00:19:54.710\n&gt;&gt; And now that you mentioned that,\nthat's a good point,\n\n386\n00:19:54.710 --> 00:19:56.260\nbecause then egos get in the way, right.\n\n387\n00:19:56.260 --> 00:19:58.420\n&gt;&gt; Sure because if somebody\nis designing something.\n\n388\n00:19:58.420 --> 00:19:59.210\n&gt;&gt; It's perfect.\n&gt;&gt; Exactly.\n\n389\n00:19:59.210 --> 00:20:01.160\nThere's nothing wrong with it at all.\n\n390\n00:20:01.160 --> 00:20:02.110\nIt's an unsinkable ship.\n\n391\n00:20:03.450 --> 00:20:07.110\nWhen it comes down to it, it might skew,\nlike you said, the results.\n\n392\n00:20:07.110 --> 00:20:10.935\nIf somebody says, well I had my hands on\ndesigning that, and I know it's perfect.\n\n393\n00:20:10.935 --> 00:20:13.575\nWell we found this,\nno no it's okay, it's x, y, z.\n\n394\n00:20:13.575 --> 00:20:17.235\nAnd you take that out of the mix,\nand you can get clear results back\n\n395\n00:20:17.235 --> 00:20:20.285\nfrom whatever the test is that\nyou're implementing at the time.\n\n396\n00:20:20.285 --> 00:20:23.485\nNow grey box,\nthat's just part white, part black,\n\n397\n00:20:23.485 --> 00:20:25.225\nmix them together you got\nthe color of grey, right?\n\n398\n00:20:25.225 --> 00:20:26.115\n&gt;&gt; Somewhere in the middle, right?\n\n399\n00:20:26.115 --> 00:20:29.655\n&gt;&gt; That's right, this might be for\ninstance you're doing debugging.\n\n400\n00:20:29.655 --> 00:20:33.670\nAnd the tester might have some kind of\nknowledge if you will about design,\n\n401\n00:20:33.670 --> 00:20:35.823\nimplementation and infrastructure.\n\n402\n00:20:39.013 --> 00:20:42.650\nIt really boils down to being partially\nunderstood when it comes to the grey box.\n\n403\n00:20:42.650 --> 00:20:47.180\nSo keep in mind that looking back at\nthe different colors here black box.\n\n404\n00:20:47.180 --> 00:20:51.570\nI don't know anything about the system\nthat I am trying to attack against right?\n\n405\n00:20:51.570 --> 00:20:53.350\nI know absolutely nothing about it.\n\n406\n00:20:53.350 --> 00:20:58.010\nWhite box I probably know the majority of\nwhat you need to know about the system.\n\n407\n00:20:58.010 --> 00:21:01.400\nAnd then the grey box is\nmaybe partial knowledge.\n\n408\n00:21:01.400 --> 00:21:05.650\n&gt;&gt; And you don't have to be completely\nisolated and only use one technique.\n\n409\n00:21:05.650 --> 00:21:10.455\nFor instance if you do hire a third party\nentity to perform a penetration test and\n\n410\n00:21:10.455 --> 00:21:12.965\nlet's say, you give them a black box test.\n\n411\n00:21:12.965 --> 00:21:17.495\nAnd they come back, they execute the test,\nthey have a list, they have their report\n\n412\n00:21:17.495 --> 00:21:20.812\nof all the suggestions that you can\ndo to Improve your environment, and\n\n413\n00:21:20.812 --> 00:21:22.952\nthen maybe a few months down\nthe road your company or\n\n414\n00:21:22.952 --> 00:21:26.142\norganization has them come back and\nperform a white box\n\n415\n00:21:26.142 --> 00:21:29.432\nto see if you've actually implemented\nsome of those suggestions.\n\n416\n00:21:29.432 --> 00:21:33.242\nAnd just as a metric you know to make\nsure that you are following through,or\n\n417\n00:21:33.242 --> 00:21:33.952\nyour employees.\n\n418\n00:21:33.952 --> 00:21:36.660\nMaybe you've had to go back and\nretrain individuals.\n\n419\n00:21:36.660 --> 00:21:39.420\nAnd make sure that they're actually\nsticking to maybe a new policy that\n\n420\n00:21:39.420 --> 00:21:41.480\nyou've initiated, or\nsomething to that effect.\n\n421\n00:21:41.480 --> 00:21:44.240\n&gt;&gt; Most definitely, base lines,\nbase lines, base lines.\n\n422\n00:21:44.240 --> 00:21:47.350\nHave security base lines, because\n[LAUGH] then you know if you're steering\n\n423\n00:21:47.350 --> 00:21:49.240\nfrom whatever the best practices are.\n\n424\n00:21:49.240 --> 00:21:50.680\nSo again on the exam,\n\n425\n00:21:50.680 --> 00:21:56.460\njust if they ask you a question that\nsays testing it how much somebody knows.\n\n426\n00:21:56.460 --> 00:21:57.720\nAgain, just remember your colors.\n\n427\n00:21:57.720 --> 00:21:59.400\nBlack, we know nothing.\n\n428\n00:21:59.400 --> 00:22:01.650\nWhite, we know not necessarily everything,\nbut\n\n429\n00:22:01.650 --> 00:22:08.130\nwe know what's going on in the grey box,\nmaybe partial knowledge of the system.\n\n430\n00:22:08.130 --> 00:22:11.670\nI really think that's about it for\nthis one.\n\n431\n00:22:11.670 --> 00:22:14.350\nI know this one's a little bit\nshorter than some of the ones we have.\n\n432\n00:22:14.350 --> 00:22:16.920\n&gt;&gt; Well thank you for joining us Wes and\nthank you ladies and gentlemen for\n\n433\n00:22:16.920 --> 00:22:19.830\ntuning in, but stay tuned we have\nmore information headed your way.\n\n434\n00:22:19.830 --> 00:22:23.330\nWe are going to go ahead and sign out for\nthis show, I am your host Cherokee Boose.\n\n435\n00:22:23.330 --> 00:22:24.140\n&gt;&gt; And I m West Bryan.\n\n436\n00:22:24.140 --> 00:22:27.560\n&gt;&gt; See you next time here at ITProTV.\n\n437\n00:22:27.560 --> 00:22:33.407\n[MUSIC]\n\n438\n00:22:33.407 --> 00:22:36.874\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "212585011"
        },
        {
          "description": "This episode focuses on what the possible repercussions of one may encounter if a vulnerability is exercised. Watch Wes and Cherokee explain situations to be aware of such as Race conditions, End-of-life systems, Embedded systems, and improper input/error handling,",
          "length": "1686",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-6-1-impact_of_various_vulnerabilities-041017-PGM.00_27_51_10.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-6-1-impact_of_various_vulnerabilities-041017-PGM.00_27_51_10.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-6-1-impact_of_various_vulnerabilities-041017-PGM.00_27_51_10.Still001-sm.jpg",
          "title": "Impact of Various Vulnerabilities",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:06.044\nWelcome to ITProTV I'm your\nhost Don Pezet [CROSSTALK]\n\n2\n00:00:06.044 --> 00:00:08.223\n[MUSIC]\n\n3\n00:00:08.223 --> 00:00:12.200\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.200 --> 00:00:14.545\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n5\n00:00:14.545 --> 00:00:16.516\nI'm your show host Cherokee Boose.\n\n6\n00:00:16.516 --> 00:00:21.026\nIn the past we spoke about different types\nof vulnerabilities a network may have but\n\n7\n00:00:21.026 --> 00:00:22.321\nwhat about the impact.\n\n8\n00:00:22.321 --> 00:00:26.990\nWhat is the result of executing or\nexercising those vulnerabilities?\n\n9\n00:00:26.990 --> 00:00:28.290\nIn this show, we'll go ahead and\n\n10\n00:00:28.290 --> 00:00:32.460\nlook at some of the different situations,\nthe different outcomes that may play out.\n\n11\n00:00:32.460 --> 00:00:34.690\nWith us today we have Mr.\nWes Bryan in studios.\n\n12\n00:00:34.690 --> 00:00:35.501\nThank you for joining us Wes.\n\n13\n00:00:35.501 --> 00:00:37.190\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n14\n00:00:37.190 --> 00:00:37.800\nYeah, that's right.\n\n15\n00:00:37.800 --> 00:00:39.990\nWe've got fun episode for you today.\n\n16\n00:00:39.990 --> 00:00:44.592\nWe get to speak a little bit about\nthe darker side of security plus, right?\n\n17\n00:00:44.592 --> 00:00:47.292\nWhen we talk about the impact\nof vulnerabilities, right,\n\n18\n00:00:47.292 --> 00:00:49.128\nwe say denial of service attack, yeah.\n\n19\n00:00:49.128 --> 00:00:53.120\nIt's when a server goes down or\nyou don't have access to it.\n\n20\n00:00:53.120 --> 00:00:57.160\nWell that's the explanation but\nwhat's the impact to your business, right?\n\n21\n00:00:57.160 --> 00:00:58.515\nWell, the availability, right?\n\n22\n00:00:58.515 --> 00:01:02.900\nCIA triad as we are commonly talking\nabout as we move through Security+.\n\n23\n00:01:02.900 --> 00:01:04.690\nConfidentiality through encryption,\n\n24\n00:01:04.690 --> 00:01:08.180\nintegrity through things like messages,\nif you will.\n\n25\n00:01:08.180 --> 00:01:11.680\nAvailability, making sure legitimate\npeople have access to the information that\n\n26\n00:01:11.680 --> 00:01:12.450\nthey should, right?\n\n27\n00:01:12.450 --> 00:01:13.906\nIf they're the authorized users and\n\n28\n00:01:13.906 --> 00:01:16.600\nthe denial of service attack\ndoesn't allow them to do that.\n\n29\n00:01:16.600 --> 00:01:20.758\nSo, we're going to talk more about some of\nthe impacts like Cherokee mentioned here.\n\n30\n00:01:20.758 --> 00:01:24.530\nOne of the first things that they talk\nabout, we're off to the races, right?\n\n31\n00:01:24.530 --> 00:01:26.240\nThey talk about race conditions here.\n\n32\n00:01:26.240 --> 00:01:29.180\nAnd a race condition is\nkind of interesting.\n\n33\n00:01:29.180 --> 00:01:31.550\nIf you look at our computing today, right?\n\n34\n00:01:31.550 --> 00:01:33.803\nWe have multithreaded computers.\n\n35\n00:01:33.803 --> 00:01:38.970\nOr CPUs, right, that can handle\nmultiple inputs at the same time.\n\n36\n00:01:38.970 --> 00:01:43.850\nEspecially I've got multi cores, couple\nthat with Intel's hyperthreading, and\n\n37\n00:01:43.850 --> 00:01:47.090\nwe can pipe in a lot of\ninformation simultaneously,\n\n38\n00:01:47.090 --> 00:01:49.530\nthat these CPUs can chew off very fast.\n\n39\n00:01:49.530 --> 00:01:54.250\nNow, when we look at a race condition,\nI want you to think of a situation where\n\n40\n00:01:54.250 --> 00:01:59.190\na system, multitasking, just trying to\nperform two tasks at the same time.\n\n41\n00:02:01.120 --> 00:02:03.210\nBut, when it does,\n\n42\n00:02:03.210 --> 00:02:07.890\nmaybe these two tasks that it's\nperforming needs to be sequentially.\n\n43\n00:02:07.890 --> 00:02:11.740\nMaybe it needs to reform one,\nand then the second one.\n\n44\n00:02:11.740 --> 00:02:14.510\nWell, what happens if the second\none gets there first?\n\n45\n00:02:14.510 --> 00:02:20.110\nWell, that's where the situation if they\ndo need to be process sequentially and\n\n46\n00:02:20.110 --> 00:02:23.880\nthey're processed out of order,\nyou might get a application crash, right?\n\n47\n00:02:23.880 --> 00:02:26.850\nYou might get a blue screen,\nthis can happen.\n\n48\n00:02:26.850 --> 00:02:30.250\nI want you to think about it,\nthink about it this way, right?\n\n49\n00:02:30.250 --> 00:02:32.775\nOne of the analogies I like to think is,\nright,\n\n50\n00:02:32.775 --> 00:02:34.932\nif I put a single light switch in, okay.\n\n51\n00:02:34.932 --> 00:02:36.140\nI've got a single light switch in.\n\n52\n00:02:36.140 --> 00:02:40.690\nIt's the one light switch that\nturns the light on and off, right.\n\n53\n00:02:40.690 --> 00:02:46.160\nBut what if on that same circuit,\nI put another light switch in, right.\n\n54\n00:02:46.160 --> 00:02:49.380\nAnd that one also turns\nthe light switch on and off.\n\n55\n00:02:49.380 --> 00:02:54.000\nAll right, well, I turned the first light\nswitch on, and I turned the other one off.\n\n56\n00:02:54.000 --> 00:02:57.460\nThe original position of that first\nlight switch is now irrelevant, right?\n\n57\n00:02:57.460 --> 00:03:03.765\nAnd the more switches I add, the more\nirrelevant that very first switch will be.\n\n58\n00:03:03.765 --> 00:03:07.958\nSo think about this, if you have a\nsituation where the process is supposed to\n\n59\n00:03:07.958 --> 00:03:12.476\nbe executed first, and then the task comes\nin, and then the next one is supposed to\n\n60\n00:03:12.476 --> 00:03:15.379\nbe executed, but\nthe second task gets there first.\n\n61\n00:03:15.379 --> 00:03:16.620\nThat's what can happen.\n\n62\n00:03:16.620 --> 00:03:19.870\nIf the system receives those two\noperations on a large amount of\n\n63\n00:03:19.870 --> 00:03:23.190\ninformation, imagine if it's a lot\nof information that's supposed to be\n\n64\n00:03:23.190 --> 00:03:24.920\nsequentially processed.\n\n65\n00:03:24.920 --> 00:03:29.330\nAnd that large amount of information\ngets there first out of order.\n\n66\n00:03:29.330 --> 00:03:31.480\nAnd then that information crashes.\n\n67\n00:03:31.480 --> 00:03:34.260\nNow you've got a lot of data corruption,\npotentially.\n\n68\n00:03:34.260 --> 00:03:38.150\nOr what happens if you have old\ndata that overwriting this,\n\n69\n00:03:38.150 --> 00:03:40.770\ngets over written by new information.\n\n70\n00:03:40.770 --> 00:03:42.268\nThen we start having problems.\n\n71\n00:03:42.268 --> 00:03:46.200\nSo that's a little bit about what\nthe raise condition can happen.\n\n72\n00:03:46.200 --> 00:03:50.150\nAll right, we have other vulnerabilities\nthat we have to worry about too.\n\n73\n00:03:50.150 --> 00:03:54.290\nFor instance they call out\nthings like end of life systems.\n\n74\n00:03:54.290 --> 00:03:58.280\nNow maybe some of our viewers out there\nprobably aware, I mean we're in 2017 now,\n\n75\n00:03:58.280 --> 00:04:02.080\nso this is really three years\noutdated when I say this.\n\n76\n00:04:02.080 --> 00:04:05.970\nIt's not really something new that's just\nhappened, but I want you to think of\n\n77\n00:04:05.970 --> 00:04:09.670\na situation where, that we just\nrecently had as of a couple years ago.\n\n78\n00:04:09.670 --> 00:04:13.891\nAll right, one of the favorite\nWindows operating systems for\n\n79\n00:04:13.891 --> 00:04:15.769\na long time was XP, right?\n\n80\n00:04:15.769 --> 00:04:19.246\nIt's a very stable operating system,\ngood operating system, but\n\n81\n00:04:19.246 --> 00:04:22.330\nit's no longer supported under Microsoft,\nright?\n\n82\n00:04:22.330 --> 00:04:26.401\nSo in fact, if we could take\na look at my screen here, so\n\n83\n00:04:26.401 --> 00:04:32.792\nthis is the official EOL for documentation\nfor Microsoft when it comes to XP, right?\n\n84\n00:04:32.792 --> 00:04:35.392\nAnd one of the big things that I\nwant you to check out here is.\n\n85\n00:04:35.392 --> 00:04:39.200\nYou know they ask, they tell you,\nwhat is the end of support?\n\n86\n00:04:39.200 --> 00:04:41.147\nWell, there will be no more support.\n\n87\n00:04:41.147 --> 00:04:45.059\nRight, no more technical, no more security\nupdates, and that's a big one right here.\n\n88\n00:04:45.059 --> 00:04:48.396\nYou can see, no more security updates or\ntechnical support.\n\n89\n00:04:48.396 --> 00:04:49.019\n&gt;&gt; You say long running.\n\n90\n00:04:49.019 --> 00:04:50.147\nLook at that, 12 years, Wes.\n\n91\n00:04:50.147 --> 00:04:52.655\n&gt;&gt; 12 years, can you imagine.\n\n92\n00:04:52.655 --> 00:04:54.945\nI mean that one went a very,\nvery long time,\n\n93\n00:04:54.945 --> 00:04:57.205\nit's a popular operating system, right.\n\n94\n00:04:57.205 --> 00:05:02.295\nAnd here's something to keep in mind,\nright, is that If we have newer\n\n95\n00:05:02.295 --> 00:05:07.151\noperating systems that are constantly\nhaving security patches.\n\n96\n00:05:07.151 --> 00:05:10.855\nThese security exploits are being\nclosed off, then we're good, but\n\n97\n00:05:10.855 --> 00:05:15.270\nif you're running a system like this that\ndoesn't get security updates, right?\n\n98\n00:05:15.270 --> 00:05:16.991\nIf you don't get security updates,\n\n99\n00:05:16.991 --> 00:05:20.650\nyou might end up seeing that\nthere's a vulnerability there.\n\n100\n00:05:20.650 --> 00:05:25.040\nAnd the problem is, Microsoft 12 years\nthey supported this operating system and\n\n101\n00:05:25.040 --> 00:05:27.030\nthey're not supporting it anymore, right?\n\n102\n00:05:27.030 --> 00:05:28.110\nWell that's the client side.\n\n103\n00:05:28.110 --> 00:05:30.420\nYou could also have other things for\ninstance.\n\n104\n00:05:30.420 --> 00:05:31.775\nThis isn't the only operating system.\n\n105\n00:05:31.775 --> 00:05:34.437\nHow about Server 2003?\n\n106\n00:05:34.437 --> 00:05:39.960\nAnd Windows Server 2003, this also\nended its support as well, right?\n\n107\n00:05:39.960 --> 00:05:45.285\nAnd, we have to be careful because if you\nare running some of this older software,\n\n108\n00:05:45.285 --> 00:05:45.834\nright?\n\n109\n00:05:45.834 --> 00:05:50.110\nThey're no longer issuing\nsecurity updates.\n\n110\n00:05:50.110 --> 00:05:53.356\nSo end of life systems present\na problem too because there us no\n\n111\n00:05:53.356 --> 00:05:56.549\nfuture patch management forum\nfrom the vendor themselves.\n\n112\n00:05:56.549 --> 00:06:00.864\nAnd these could cause vulnerabilities,\nthese could cause exploits to be open,\n\n113\n00:06:00.864 --> 00:06:03.794\nall right and\nattackers could take advantage of that.\n\n114\n00:06:03.794 --> 00:06:06.490\n&gt;&gt; So you might think well why wouldn't\nyou just upgrade your systems?\n\n115\n00:06:06.490 --> 00:06:08.700\nWell number one,\nthey might not have the money to.\n\n116\n00:06:08.700 --> 00:06:12.694\nBut I worked in a situation Wes where\nit was a manufacturing company and\n\n117\n00:06:12.694 --> 00:06:17.247\nwe had these large manufacturing\nproduction, ovens on the production floor.\n\n118\n00:06:17.247 --> 00:06:20.602\nThey would actually we would put\nthe printed circuit boards into them and\n\n119\n00:06:20.602 --> 00:06:22.263\nthen they would bake them, right?\n\n120\n00:06:22.263 --> 00:06:24.664\nSo It's kind of ironic you chose XP,\n\n121\n00:06:24.664 --> 00:06:28.698\nthe operating system that was\nrunning these machines was XP.\n\n122\n00:06:28.698 --> 00:06:31.159\nAnd they had a custom\ndeveloper come in and\n\n123\n00:06:31.159 --> 00:06:35.010\ncreate an application to manage\nthese gigantic machines.\n\n124\n00:06:35.010 --> 00:06:36.768\nSo, for them to go ahead and\n\n125\n00:06:36.768 --> 00:06:40.600\nhire another developer to\nrecode the entire application.\n\n126\n00:06:40.600 --> 00:06:44.695\nI wanna say it was like a $150,000\nthat they have paid originally,\n\n127\n00:06:44.695 --> 00:06:48.400\nso who knows what a new developer\nwould be charging them.\n\n128\n00:06:48.400 --> 00:06:54.041\nSo, instead of keeping those XP systems\npart of our production network.\n\n129\n00:06:54.041 --> 00:06:57.662\nWhat we did was just completely isolate\nthem, and air-gap them, because we\n\n130\n00:06:57.662 --> 00:07:01.686\nrecognized those security risks, and we\njust didn't even want to take that chance.\n\n131\n00:07:01.686 --> 00:07:04.690\n&gt;&gt; Most definitely, keeping them off\nthe vulnerability scans for sure.\n\n132\n00:07:04.690 --> 00:07:06.650\nAnd in fact they've got\nsome good information here,\n\n133\n00:07:06.650 --> 00:07:07.870\nif we pull this back up, right?\n\n134\n00:07:07.870 --> 00:07:09.640\nThis is what we were first\nkinds looking at, right?\n\n135\n00:07:09.640 --> 00:07:12.020\nWe were looking at the stop,\nwhat is the end of support?\n\n136\n00:07:12.020 --> 00:07:14.210\nBut what I really like Cherokee\nis if we scroll down and\n\n137\n00:07:14.210 --> 00:07:18.830\nif you guys haven't seen this is\na great way to kinda learn this.\n\n138\n00:07:18.830 --> 00:07:19.900\nWhat does it mean for us?\n\n139\n00:07:19.900 --> 00:07:24.740\nWell, I want you understand it says,\nafter April 8, 2014,\n\n140\n00:07:24.740 --> 00:07:28.330\nno longer having security updates.\n\n141\n00:07:28.330 --> 00:07:33.131\nBut here's what I really like about this.\n\n142\n00:07:33.131 --> 00:07:37.653\nSecurity updates patch vulnerabilities\nthat may be exploited by malware.\n\n143\n00:07:37.653 --> 00:07:40.813\nAll right, so\nwhen these end of life systems,\n\n144\n00:07:40.813 --> 00:07:46.660\nEOL systems are no longer being updated,\nnow they could be full of vulnerabilities.\n\n145\n00:07:46.660 --> 00:07:50.310\nSo that's one of the things that we\nwanna keep in mind is that they could\n\n146\n00:07:50.310 --> 00:07:51.740\nbe exploited.\n\n147\n00:07:51.740 --> 00:07:53.653\nThe other thing that they all\nout is lack of vendor support.\n\n148\n00:07:53.653 --> 00:07:55.534\nAnd that's what you're seeing right here,\nright.\n\n149\n00:07:55.534 --> 00:07:58.408\nWithout having something like a third\nparty, like Cherokee mentioned,\n\n150\n00:07:58.408 --> 00:08:01.558\nwhere it's the developer that comes in and\nsays hey, We're going to go ahead and\n\n151\n00:08:01.558 --> 00:08:03.297\nwe're gonna do some work on these devices.\n\n152\n00:08:03.297 --> 00:08:07.859\nBut even at that, you guys were, you took\nenough, though it was enough risk that you\n\n153\n00:08:07.859 --> 00:08:11.730\nneeded to segregate them from the rest\nof your devices on your network.\n\n154\n00:08:11.730 --> 00:08:14.740\nSo, we can see that too.\n\n155\n00:08:14.740 --> 00:08:18.078\nThat also leads to another thing too,\nimbedded systems.\n\n156\n00:08:18.078 --> 00:08:20.007\nImbedded systems\nare an interesting concept,\n\n157\n00:08:20.007 --> 00:08:22.410\nbecause when we look at imbedded systems.\n\n158\n00:08:22.410 --> 00:08:24.510\nSometimes they lack software updates,\nright?\n\n159\n00:08:24.510 --> 00:08:29.470\nIn fact currently, we have a Windows\n10 operating system that's on\n\n160\n00:08:29.470 --> 00:08:31.900\nthe market now called\nLong Term Service Branching.\n\n161\n00:08:33.350 --> 00:08:34.590\nAnd what's that about, all right?\n\n162\n00:08:34.590 --> 00:08:38.750\nWell, that's a servicing model because\nthey know certain devices don't need\n\n163\n00:08:38.750 --> 00:08:43.710\nall the extra features if you will\nthat traditionally work stations,\n\n164\n00:08:43.710 --> 00:08:47.760\nlaptops and\ndesktops if you will need, all right?\n\n165\n00:08:47.760 --> 00:08:49.050\nBut here's the problem.\n\n166\n00:08:49.050 --> 00:08:50.820\nWhen we talk about embedded systems,\n\n167\n00:08:50.820 --> 00:08:54.220\nthey might not have software\nupdates at all, right?\n\n168\n00:08:54.220 --> 00:08:58.230\nThey might have brand new hardware,\nbrand new hardware, but\n\n169\n00:08:58.230 --> 00:09:00.570\nthey could be running old\noperating systems, right?\n\n170\n00:09:00.570 --> 00:09:02.950\nSo, that's where you start to run a risk,\n\n171\n00:09:02.950 --> 00:09:07.020\nright new technology with\nan old software running on it.\n\n172\n00:09:07.020 --> 00:09:10.400\nYou could run the risk of being\nsusceptible to things like code injection\n\n173\n00:09:10.400 --> 00:09:11.295\nattacks, right?\n\n174\n00:09:11.295 --> 00:09:14.100\nSon we do have to keep that in mind.\n\n175\n00:09:14.100 --> 00:09:16.740\nAnd then, especially even though\nthey don't really call it out, but\n\n176\n00:09:16.740 --> 00:09:18.730\nin embedded systems today like IoT.\n\n177\n00:09:18.730 --> 00:09:21.230\nIoT, the Internet of Things,\n\n178\n00:09:21.230 --> 00:09:24.440\nthere are thousands of different\ntypes of these devices, right?\n\n179\n00:09:24.440 --> 00:09:29.630\nAnd the software that's running on these\ndevices might not necessarily be secure.\n\n180\n00:09:29.630 --> 00:09:31.440\nYou could be a couple generations behind.\n\n181\n00:09:31.440 --> 00:09:34.115\nSo it's gonna be important\nthat when you're doing,\n\n182\n00:09:34.115 --> 00:09:35.575\nsomething like a vulnerability scan,\n\n183\n00:09:35.575 --> 00:09:38.395\nyou're doing a security audit that you\nare paying attention to the software that\n\n184\n00:09:38.395 --> 00:09:41.475\nis running on those devices to make\nsure that it is being patched.\n\n185\n00:09:41.475 --> 00:09:42.845\nAnd if it isn't being patched,\n\n186\n00:09:42.845 --> 00:09:46.265\nthen chances are you need to take\nthese devices off of your networks,\n\n187\n00:09:46.265 --> 00:09:49.970\nupgrade them or at least separate\nthem from the rest of the network.\n\n188\n00:09:49.970 --> 00:09:52.140\n&gt;&gt; You know Wes,\nI see all sorts of articles.\n\n189\n00:09:52.140 --> 00:09:56.710\nEspecially at the end or let's just say,\n2016 was a big year for these types of,\n\n190\n00:09:56.710 --> 00:10:02.100\nlike with the Mirai Botnet style attacks\nfor our distributed denial of service.\n\n191\n00:10:02.100 --> 00:10:06.590\nAnd with the influx of devices that we\nare connecting to our networks, and\n\n192\n00:10:06.590 --> 00:10:08.030\nthat call back out to the internet.\n\n193\n00:10:08.030 --> 00:10:11.660\nWe really need to be careful about\nthe security of these devices, and\n\n194\n00:10:11.660 --> 00:10:13.840\nI think it really is just a cat and\nmouse game.\n\n195\n00:10:13.840 --> 00:10:18.185\nAnd we're gonna really need to\nfocus if we plan on integrating and\n\n196\n00:10:18.185 --> 00:10:22.220\ncontinue exponentially to\nintegrate all this IOT devices.\n\n197\n00:10:22.220 --> 00:10:25.957\nTo really just focus on security because\nI think that is a department that we're\n\n198\n00:10:25.957 --> 00:10:28.370\nlacking when we talk\nabout those IOT devices.\n\n199\n00:10:28.370 --> 00:10:31.200\n&gt;&gt; For sure, especially with a lot\nof the attacks that are coming up\n\n200\n00:10:31.200 --> 00:10:33.530\ntoday because people just aren't aware.\n\n201\n00:10:33.530 --> 00:10:35.322\nThey put these devices on their networks,\n\n202\n00:10:35.322 --> 00:10:35.914\nand then-\n&gt;&gt; Lightbulbs.\n\n203\n00:10:35.914 --> 00:10:36.880\n&gt;&gt; They walk away from them.\n\n204\n00:10:36.880 --> 00:10:38.362\nYes.\n&gt;&gt; Who would've thought, really.\n\n205\n00:10:38.362 --> 00:10:41.509\n&gt;&gt; Definitely, for instance,\nthings like your smart TVs.\n\n206\n00:10:41.509 --> 00:10:44.512\nSmart TVs, they are saying there\nare all kinds of vulnerabilities,\n\n207\n00:10:44.512 --> 00:10:47.773\nwe can probably make a week show in just\nthe vulnerabilities that are in some\n\n208\n00:10:47.773 --> 00:10:48.780\nof these devices too.\n\n209\n00:10:48.780 --> 00:10:52.130\nSo, you have to be aware of it and\nyou have to take it into consideration if\n\n210\n00:10:52.130 --> 00:10:53.670\nthese devices are gonna\nbe in your network.\n\n211\n00:10:53.670 --> 00:10:55.680\nNow you might say, wait a second.\n\n212\n00:10:55.680 --> 00:10:57.670\nWe have smart TVs on\na business environment.\n\n213\n00:10:57.670 --> 00:11:01.944\nWell, we probably got 30 smart TVs if\nnot more in this building alone, right.\n\n214\n00:11:01.944 --> 00:11:04.223\nAnd everyone of those\nruns a potential risk for\n\n215\n00:11:04.223 --> 00:11:06.210\nthe embedded systems that are in them and\n\n216\n00:11:06.210 --> 00:11:10.140\nsmall operating systems that are running\non, they could be a source of attack.\n\n217\n00:11:10.140 --> 00:11:13.529\nSo, it's definitely something that\nyou have to keep in mind, as well.\n\n218\n00:11:13.529 --> 00:11:16.929\nWhen you look at smart TVs, right, they\nhave embedded systems of small little,\n\n219\n00:11:16.929 --> 00:11:19.179\na lot of times Linux based\noperating systems in them,\n\n220\n00:11:19.179 --> 00:11:20.790\nthat might need to be patched as well.\n\n221\n00:11:21.820 --> 00:11:25.800\nAll right, so what are some of the other\ntypes of [COUGH] vulnerabilities that we\n\n222\n00:11:25.800 --> 00:11:30.520\nhave to work around, or, not work around,\nbut we need to protect against\n\n223\n00:11:30.520 --> 00:11:35.430\none of the ones they call out\nis improper input handling.\n\n224\n00:11:35.430 --> 00:11:38.620\nSo, what do we mean when we\nsay improper input handling?\n\n225\n00:11:38.620 --> 00:11:40.300\nWell, think about this.\n\n226\n00:11:40.300 --> 00:11:45.260\nWhen you communicate with a web\nbrowser to a web server and\n\n227\n00:11:45.260 --> 00:11:49.100\nlet's say that you're\npresented with a data form and\n\n228\n00:11:49.100 --> 00:11:53.990\nyou need to enter information\ninto specific fields.\n\n229\n00:11:53.990 --> 00:11:58.070\nWell, a lot of times the web browser is or\nthe web server is operating for\n\n230\n00:11:58.070 --> 00:11:59.630\nthe certain level of trust, right?\n\n231\n00:11:59.630 --> 00:12:02.530\nIf I have things like Chrome,\nI have things like Firefox,\n\n232\n00:12:02.530 --> 00:12:05.381\nI have things like Safari,\nInternet explorer, right.\n\n233\n00:12:05.381 --> 00:12:09.279\nThe edge browser if you all the different\nweb browser that we have out there they do\n\n234\n00:12:09.279 --> 00:12:11.200\nassume a certain level of trust.\n\n235\n00:12:11.200 --> 00:12:14.550\nBut, we can't trust those\nexternal entities, right?\n\n236\n00:12:14.550 --> 00:12:17.380\nApplication trusting is not\nsomething that you can do.\n\n237\n00:12:17.380 --> 00:12:20.190\nBecause what you need to do if\nyou're doing web developing,\n\n238\n00:12:20.190 --> 00:12:21.820\nyou're developing a web application.\n\n239\n00:12:21.820 --> 00:12:24.970\nIf you're developing your web\nserver right, you need to make sure\n\n240\n00:12:24.970 --> 00:12:29.520\nthat every piece of information that's\nsent into that web server is validated.\n\n241\n00:12:29.520 --> 00:12:33.500\nRight, we need to make sure\nit's only the data we expect.\n\n242\n00:12:33.500 --> 00:12:37.620\nHave you ever, for instance,\nmaybe tried to create a password, and\n\n243\n00:12:37.620 --> 00:12:39.820\nit says these characters aren't allowed,\nright?\n\n244\n00:12:39.820 --> 00:12:42.910\nIt makes you try again while some of\nthose characters could be use for\n\n245\n00:12:42.910 --> 00:12:45.030\nthings like SQL injection strings, right?\n\n246\n00:12:45.030 --> 00:12:49.550\nIn fact, I got a kind of an example\nof improper input handling, right?\n\n247\n00:12:49.550 --> 00:12:53.790\nSo for instance, you guys have probably\nseen one of these username and\n\n248\n00:12:53.790 --> 00:12:55.840\npassword dialog boxes, right?\n\n249\n00:12:55.840 --> 00:13:00.520\nWell there's nothing that really says that\nthis hacker, or attacker here if you will.\n\n250\n00:13:00.520 --> 00:13:03.430\nWhat says that he or\nshe's gotta put their username and\n\n251\n00:13:03.430 --> 00:13:05.170\ntheir password in there, right?\n\n252\n00:13:05.170 --> 00:13:09.730\nWhat if we do some kind of executable\nstring, and place it in there.\n\n253\n00:13:09.730 --> 00:13:16.250\nWell if your company,\nif your developers aren't checking\n\n254\n00:13:16.250 --> 00:13:20.930\nsyntax correctness and validate,\nthey call it user imput check validations.\n\n255\n00:13:20.930 --> 00:13:25.010\nIf you're not saying that the information\nthat I expect to see in this username and\n\n256\n00:13:25.010 --> 00:13:29.000\npassword dialog box is a username or\na password.\n\n257\n00:13:29.000 --> 00:13:32.140\nThen what you do is you run\nthe risk of that information\n\n258\n00:13:32.140 --> 00:13:34.200\nbeing injected into the web server.\n\n259\n00:13:34.200 --> 00:13:35.050\nThat's the front end,\n\n260\n00:13:35.050 --> 00:13:39.980\nbut then on the back end it causes some\nattack against your SQL database, right?\n\n261\n00:13:39.980 --> 00:13:44.460\nAnd it deletes information,\nit outputs information, right?\n\n262\n00:13:44.460 --> 00:13:48.990\nIt corrupts your information and\nnow you definitely have a bad day, right?\n\n263\n00:13:48.990 --> 00:13:52.490\nWe don't have the availability of our\ninformation to the customers that should\n\n264\n00:13:52.490 --> 00:13:53.730\nhave access to it.\n\n265\n00:13:53.730 --> 00:13:55.830\n&gt;&gt; Well Wes, you just told me\nhow to fix that situation,\n\n266\n00:13:55.830 --> 00:13:59.820\nso why do we still see attacks like this\nhappening, why are we still vulnerable?\n\n267\n00:13:59.820 --> 00:14:03.290\nWell, in a perfect world we\nhave all the time that we need,\n\n268\n00:14:03.290 --> 00:14:05.900\nbut in certain situations\nwe have deadlines and\n\n269\n00:14:05.900 --> 00:14:09.620\nmaybe it's just kinda like quantity\nover quality type situation.\n\n270\n00:14:09.620 --> 00:14:13.686\nWhere the individual companies are really\nwanting to push their product,\n\n271\n00:14:13.686 --> 00:14:17.051\nfirst to market and\nbe out there right there on the forefront.\n\n272\n00:14:17.051 --> 00:14:21.190\nSo, sometimes we see that\nquality lacking a little bit.\n\n273\n00:14:21.190 --> 00:14:25.319\nAnd like you had said,\nmaybe if I know my password policy and\n\n274\n00:14:25.319 --> 00:14:28.550\nI wanna adhere to that\nmaximum character set.\n\n275\n00:14:28.550 --> 00:14:32.344\nWhy would I allow multiple characters\nto be typed into that field,\n\n276\n00:14:32.344 --> 00:14:35.400\nto allow that arbitrary\ncode from executing?\n\n277\n00:14:35.400 --> 00:14:36.700\n&gt;&gt; That's a great point too, Cherokee.\n\n278\n00:14:36.700 --> 00:14:40.140\nThe other thing that we could take a look\nat is that the larger your application\n\n279\n00:14:40.140 --> 00:14:44.108\ndeployment becomes, there's a lot\nmore data entry points, right?\n\n280\n00:14:44.108 --> 00:14:45.700\nWe might it, so for instance,\n\n281\n00:14:45.700 --> 00:14:49.660\nour example that we're given here is\njust a user name and dialogue box.\n\n282\n00:14:49.660 --> 00:14:51.585\nThe user name and password dialogue box.\n\n283\n00:14:51.585 --> 00:14:53.820\nWell that's not the only entry point.\n\n284\n00:14:53.820 --> 00:14:56.710\nLike for large deployments and\nlarge applications,\n\n285\n00:14:56.710 --> 00:14:59.840\nyou might have several locations within\nthat application deployment where they can\n\n286\n00:14:59.840 --> 00:15:02.820\nget information into your database.\n\n287\n00:15:02.820 --> 00:15:06.800\nAnd it's important not saying that\npeople are lazy, it happens, right?\n\n288\n00:15:06.800 --> 00:15:09.200\nIt's not a matter of if\nthere are bugs in software,\n\n289\n00:15:09.200 --> 00:15:12.380\nit's just a matter of finding them, right?\n\n290\n00:15:12.380 --> 00:15:15.760\nSo, it is something that you have to\nkind of batten down the hatches, right?\n\n291\n00:15:15.760 --> 00:15:17.070\nLock all the doors of the windows.\n\n292\n00:15:17.070 --> 00:15:19.740\nYou have to make sure that if you do\nhave different points of entry for\n\n293\n00:15:19.740 --> 00:15:23.890\ndata going in to some kinda database or\nrepository where that information\n\n294\n00:15:23.890 --> 00:15:26.600\nis stored, that it's only\nthe data that you're validating,\n\n295\n00:15:26.600 --> 00:15:29.500\nthat the syntax is correct and\nit's the values that you expect to see.\n\n296\n00:15:29.500 --> 00:15:31.920\nSo for example,\ngive you an example, right?\n\n297\n00:15:31.920 --> 00:15:37.000\nSo, on our site we have our\nContact Us field, right?\n\n298\n00:15:37.000 --> 00:15:41.790\nAnd you can see some Input,\nCheck validation.\n\n299\n00:15:41.790 --> 00:15:43.110\nNotice my username is here.\n\n300\n00:15:43.110 --> 00:15:46.570\nWell, what happens if I\ntake my username out?\n\n301\n00:15:46.570 --> 00:15:48.136\nWell, now it's saying,\nwell, wait a second.\n\n302\n00:15:48.136 --> 00:15:50.010\nWhat was your name again?\n\n303\n00:15:50.010 --> 00:15:53.180\nWe expect to see a username in this field.\n\n304\n00:15:53.180 --> 00:15:55.833\nI don't have an email address in that\nfield, and give it a second here,\n\n305\n00:15:55.833 --> 00:15:56.462\nand I move down.\n\n306\n00:15:56.462 --> 00:16:01.675\nWell, wait a second, we expect to\nsee your username in this field?\n\n307\n00:16:01.675 --> 00:16:04.951\nRight, well I say,\nwhat I'm just gonna put wbryan.\n\n308\n00:16:04.951 --> 00:16:06.087\nWait.\n\n309\n00:16:06.087 --> 00:16:06.969\n&gt;&gt; Where's the domain?\n\n310\n00:16:06.969 --> 00:16:08.942\n&gt;&gt; That's not a valid email, right?\n\n311\n00:16:08.942 --> 00:16:10.430\nSo this gives you an example.\n\n312\n00:16:10.430 --> 00:16:13.270\nI can't just come in here and\nsay here's my message and\n\n313\n00:16:13.270 --> 00:16:16.150\nput a SQL injection statement in there,\nright?\n\n314\n00:16:16.150 --> 00:16:19.074\nIt's not gonna make it to the back end,\nat least that's what we hope.\n\n315\n00:16:19.074 --> 00:16:23.507\n[LAUGH] But notice that there are,\nif I end up taking all these fields out,\n\n316\n00:16:23.507 --> 00:16:28.540\nnotice that each one of these fields is\ngiving me that there's some kind of error.\n\n317\n00:16:28.540 --> 00:16:31.541\nIt's expecting to see\na certain type of information.\n\n318\n00:16:31.541 --> 00:16:34.853\nAnd that's what we want,\nwe want proper input handling.\n\n319\n00:16:34.853 --> 00:16:38.948\nSo what are some of the results\nof this type of attack,\n\n320\n00:16:38.948 --> 00:16:42.777\nor this type of lack,\ndepending on how you say it?\n\n321\n00:16:42.777 --> 00:16:45.136\nAll kinds of things, right?\n\n322\n00:16:45.136 --> 00:16:47.961\nWe mentioned SQL injection attack,\ncross-site scripting,\n\n323\n00:16:47.961 --> 00:16:51.370\ndirectory traversal is something\nthat can happen, code injection.\n\n324\n00:16:51.370 --> 00:16:54.680\nDenial of service situations, right?\n\n325\n00:16:54.680 --> 00:17:03.060\nIf I can basically flood a system with\na whole bunch of unexpected information.\n\n326\n00:17:03.060 --> 00:17:04.740\nIt doesn't know how to handle it.\n\n327\n00:17:04.740 --> 00:17:07.500\nThen it performs a resource exhaustion,\nright.\n\n328\n00:17:07.500 --> 00:17:09.789\nNow I can't respond to legitimate users,\nso\n\n329\n00:17:09.789 --> 00:17:12.086\nI have a denial of service\ntype of situation.\n\n330\n00:17:12.086 --> 00:17:13.838\nSo these things can happen.\n\n331\n00:17:13.838 --> 00:17:18.474\nNow, that's improper input handling.\n\n332\n00:17:18.474 --> 00:17:21.050\nIt's not the only one, right?\n\n333\n00:17:21.050 --> 00:17:26.950\nWe also have, which is kinda interesting,\nwe have improper error handling, right?\n\n334\n00:17:26.950 --> 00:17:29.890\nSo one of the reasons we use things\nlike fuzzing techniques, right,\n\n335\n00:17:29.890 --> 00:17:33.120\nwe wanna send all this random information\n\n336\n00:17:33.120 --> 00:17:37.638\nat our website on purpose to find out what\nit's basically gonna kick back at us.\n\n337\n00:17:37.638 --> 00:17:39.770\n&gt;&gt; The reaction of what's\nbreaking that system.\n\n338\n00:17:39.770 --> 00:17:42.330\n&gt;&gt; Most definitely, we wanna make sure\nthat it's not giving us information that\n\n339\n00:17:42.330 --> 00:17:43.513\nhelps us with our attacks, right?\n\n340\n00:17:43.513 --> 00:17:47.324\nLet me give you an example of\nsome improper input handling.\n\n341\n00:17:47.324 --> 00:17:50.319\nI've got an example of a few different\ntypes up here on our screen.\n\n342\n00:17:50.319 --> 00:17:54.623\nSo I want you to think of\na situation where you go to log in,\n\n343\n00:17:54.623 --> 00:17:57.964\nyou're doing some guessing here, right?\n\n344\n00:17:57.964 --> 00:18:00.535\nAnd you log in for\nthe user, invalid password.\n\n345\n00:18:00.535 --> 00:18:03.220\nWell, thank you, you just told me\nI didn't get the password, right?\n\n346\n00:18:04.230 --> 00:18:06.300\nBut chances are,\nI got the username, right?\n\n347\n00:18:06.300 --> 00:18:09.160\nYou didn't tell me it was an invalid user,\nyou said it was an invalid password, so\n\n348\n00:18:09.160 --> 00:18:10.820\nI know I'm halfway right.\n\n349\n00:18:10.820 --> 00:18:13.736\nNow I just gonna start brute\nforcing if I want, rainbow tables,\n\n350\n00:18:13.736 --> 00:18:17.148\nall the other types of attacks,\npassword attacks, that happen, right.\n\n351\n00:18:17.148 --> 00:18:18.205\nLogin failed.\n\n352\n00:18:18.205 --> 00:18:21.460\nNow we're on the other side of the river,\nright?\n\n353\n00:18:21.460 --> 00:18:23.650\nWell, you told me that's\na invalid user ID.\n\n354\n00:18:23.650 --> 00:18:24.307\nWell, okay, so I can guess again.\n\n355\n00:18:24.307 --> 00:18:25.599\nHow about this?\n\n356\n00:18:25.599 --> 00:18:28.800\nLogin failed, account disabled.\n\n357\n00:18:28.800 --> 00:18:29.520\n&gt;&gt; There you go.\n\n358\n00:18:29.520 --> 00:18:32.474\n&gt;&gt; At least we know that it's disabled,\nso at least it's something is, you know.\n\n359\n00:18:32.474 --> 00:18:35.967\nBut again, it's giving us more\ninformation than what you need, right?\n\n360\n00:18:35.967 --> 00:18:38.260\nHere's another one.\n\n361\n00:18:38.260 --> 00:18:40.170\nLogin failed: User is not active.\n\n362\n00:18:40.170 --> 00:18:40.990\nAll right?\n\n363\n00:18:40.990 --> 00:18:44.510\nNow, the proper example would be,\nlogin failed, right?\n\n364\n00:18:44.510 --> 00:18:45.270\nSo, let's change this.\n\n365\n00:18:45.270 --> 00:18:47.180\nWhat should we see?\n\n366\n00:18:47.180 --> 00:18:47.830\nAll right?\n\n367\n00:18:47.830 --> 00:18:53.290\nThis should be something\nlike invalid username,\n\n368\n00:18:53.290 --> 00:18:59.080\nI can't even spell username, or password.\n\n369\n00:18:59.080 --> 00:19:02.820\nRight?\nWe don't want to tell me which one it is.\n\n370\n00:19:02.820 --> 00:19:05.380\nIn fact, I've seen a kind of interesting\none on a product key the other day that I\n\n371\n00:19:05.380 --> 00:19:06.180\nthought was great.\n\n372\n00:19:06.180 --> 00:19:07.799\n&gt;&gt; I love how companies get creative here.\n\n373\n00:19:07.799 --> 00:19:08.801\nLet me hear you example.\n\n374\n00:19:08.801 --> 00:19:12.131\n&gt;&gt; Yeah, I was gonna say, the other day\nI see one, and I was actually putting in\n\n375\n00:19:12.131 --> 00:19:15.160\na product key, and\nit expected to see it in a certain field.\n\n376\n00:19:15.160 --> 00:19:18.749\nAnd I didn't type it right,\nactually, I typed a different key.\n\n377\n00:19:18.749 --> 00:19:20.343\nIt wasn't the key that was\nsupposed to go into that field.\n\n378\n00:19:20.343 --> 00:19:23.730\nAnd it said, when it came back,\nit said, invalid key.\n\n379\n00:19:23.730 --> 00:19:27.630\nKeep in mind, may or\nmay not contain hyphens.\n\n380\n00:19:27.630 --> 00:19:29.150\nAll right?\nSo some people might say, well,\n\n381\n00:19:29.150 --> 00:19:30.860\nat least I know hyphens.\n\n382\n00:19:30.860 --> 00:19:31.703\nWell, technically you don't.\n\n383\n00:19:31.703 --> 00:19:34.787\nI thought that was a very creative way,\ncuz they said, may or\n\n384\n00:19:34.787 --> 00:19:36.130\nmay not contain hyphens.\n\n385\n00:19:36.130 --> 00:19:38.296\nAs I'm looking at the product key,\nand it contains hyphens.\n\n386\n00:19:38.296 --> 00:19:42.114\nBut at least they didn't say,\nthis product key contains hyphens.\n\n387\n00:19:42.114 --> 00:19:42.863\n&gt;&gt; Right.\n\n388\n00:19:42.863 --> 00:19:45.634\nYeah, I've seen some really\nclever ones out there.\n\n389\n00:19:45.634 --> 00:19:48.620\nDifferent companies just\ntake it to the extreme.\n\n390\n00:19:48.620 --> 00:19:53.100\nNike, Disney,\nI've had those types of error messages.\n\n391\n00:19:53.100 --> 00:19:55.210\nAnd they are customized,\nand just super cute.\n\n392\n00:19:55.210 --> 00:19:57.769\nAnd sometimes not only are they\nprotecting their systems, but\n\n393\n00:19:57.769 --> 00:19:59.564\nthey're adding a little\nbit of flair to it.\n\n394\n00:19:59.564 --> 00:20:01.299\n[LAUGH]\n&gt;&gt; Yeah [LAUGH].\n\n395\n00:20:01.299 --> 00:20:02.696\nAll right, so what time we got?\n\n396\n00:20:02.696 --> 00:20:05.924\nWe've got some more here\nthat I wanna talk about.\n\n397\n00:20:05.924 --> 00:20:07.700\nIt looks like we still got some time.\n\n398\n00:20:07.700 --> 00:20:12.410\nSome of the other things that they call\nout, they call out misconfiguration and\n\n399\n00:20:12.410 --> 00:20:13.710\nweak configuration.\n\n400\n00:20:13.710 --> 00:20:17.930\nNow in a previous episode, we did talk\nabout weak configurations, right,\n\n401\n00:20:17.930 --> 00:20:20.700\ndifferent cypher suites and stuff,\n\n402\n00:20:20.700 --> 00:20:25.500\nimplementing WPA when you should\nbe implementing things like WPA2.\n\n403\n00:20:25.500 --> 00:20:27.660\nWeaker cypher strengths, right.\n\n404\n00:20:27.660 --> 00:20:32.530\nOther weak implementations is,\nyou have services that are turned on and\n\n405\n00:20:32.530 --> 00:20:35.040\nyou have no use for them,\nyou're not even using them, right.\n\n406\n00:20:35.040 --> 00:20:38.400\nWell, I thought I might\nmaybe need an SMTP server.\n\n407\n00:20:38.400 --> 00:20:41.253\nI thought, maybe I needed an FTP server,\nso I'll go ahead and bring those up.\n\n408\n00:20:41.253 --> 00:20:44.003\nAnd at least I'm being studious, right?\n\n409\n00:20:44.003 --> 00:20:48.373\nAt least I'll have those ready\nto go if we need them, right?\n\n410\n00:20:48.373 --> 00:20:49.225\nThat, again,\n\n411\n00:20:49.225 --> 00:20:53.237\ncan be one of those things that leads\nyou to some kind of exploit, right?\n\n412\n00:20:53.237 --> 00:20:57.188\nEnabling things like guest accounts and\nallowing things like anonymous logons.\n\n413\n00:20:57.188 --> 00:21:02.671\nAll those are examples of weak\nconfigurations or misconfigurations.\n\n414\n00:21:05.146 --> 00:21:06.228\nLet's see, default configuration.\n\n415\n00:21:06.228 --> 00:21:10.790\nNow, this is something that we stress\na lot when it comes to security.\n\n416\n00:21:10.790 --> 00:21:14.020\nAnd that is not using default\nconfigurations, right?\n\n417\n00:21:14.020 --> 00:21:19.370\nFor instance, if you have your\nnetwork connectivity devices,\n\n418\n00:21:19.370 --> 00:21:23.610\nwhen you buy them and you get them fresh\nout of the box, a lot of times they have\n\n419\n00:21:23.610 --> 00:21:26.160\ndefault user names and passwords,\nadministrative passwords.\n\n420\n00:21:26.160 --> 00:21:28.900\nSometimes it's admin, admin, right?\n\n421\n00:21:28.900 --> 00:21:32.438\nIf I wanted to, I could go out here and\nwe could do a real quick Google search and\n\n422\n00:21:32.438 --> 00:21:36.087\nwe could find all of the default user\nnames and passwords, administrative user\n\n423\n00:21:36.087 --> 00:21:39.212\nnames and passwords, to log on to\nmany different devices, right?\n\n424\n00:21:39.212 --> 00:21:40.439\n&gt;&gt; All in about 0.02 seconds.\n\n425\n00:21:40.439 --> 00:21:41.365\n&gt;&gt; That's right.\n\n426\n00:21:41.365 --> 00:21:43.684\nOther things that happen,\nin fact, it's kinda interesting.\n\n427\n00:21:43.684 --> 00:21:46.857\nI was doing a vulnerability scan\non my network the other day and\n\n428\n00:21:46.857 --> 00:21:50.578\nfound out that even though in a previous\nepisode, I told you about WPS and\n\n429\n00:21:50.578 --> 00:21:54.787\ndisable it, I didn't realize a firmware\nupdate that I did on my machine enabled it\n\n430\n00:21:54.787 --> 00:21:56.824\nagain after I did the firmware update.\n\n431\n00:21:56.824 --> 00:21:59.800\nSo WPS was on on my network, right?\n\n432\n00:21:59.800 --> 00:22:01.750\nIt was enabled, but\nwe weren't using it, right?\n\n433\n00:22:01.750 --> 00:22:04.832\nSo, again, that's a default configuration,\nbut on that router,\n\n434\n00:22:04.832 --> 00:22:08.407\nthe firmware update basically brought\nit back to its default configurations.\n\n435\n00:22:08.407 --> 00:22:10.934\nAnd I needed to reload\nthe configuration file back\n\n436\n00:22:10.934 --> 00:22:13.109\nup to get it back to\nthe original settings.\n\n437\n00:22:13.109 --> 00:22:16.177\nBut had I not looked, had I not checked.\n\n438\n00:22:16.177 --> 00:22:20.077\n&gt;&gt; I know, I would assume that\nthe manufacturers would be up to date with\n\n439\n00:22:20.077 --> 00:22:22.647\nthese security, just with these settings.\n\n440\n00:22:22.647 --> 00:22:25.030\nBut you know what they say about assuming,\nWes.\n\n441\n00:22:25.030 --> 00:22:25.580\n&gt;&gt; Yes, that's right.\n\n442\n00:22:25.580 --> 00:22:27.143\nIt definitely,\nassumptions sink ships, for sure.\n\n443\n00:22:27.143 --> 00:22:28.389\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n444\n00:22:28.389 --> 00:22:29.485\nthat's one thing that we don't want to do.\n\n445\n00:22:29.485 --> 00:22:32.739\nAnd there, again, that's an example\nof a default configuration that I\n\n446\n00:22:32.739 --> 00:22:34.198\nshould have steered away from.\n\n447\n00:22:34.198 --> 00:22:37.980\nOpen systems, right, usually when your\nsystem comes in like that, if it's a home\n\n448\n00:22:37.980 --> 00:22:43.740\nrouter or something, it might not have\nany security configurations on it.\n\n449\n00:22:43.740 --> 00:22:45.480\nAnd you need to steer away from it.\n\n450\n00:22:45.480 --> 00:22:49.010\nDo you need to disable\nthings like SSID broadcasts?\n\n451\n00:22:49.010 --> 00:22:52.360\nThat might be something that you\nneed to do, it might not be, right?\n\n452\n00:22:52.360 --> 00:22:55.760\nSo again, default configurations,\nrenaming user accounts,\n\n453\n00:22:55.760 --> 00:22:56.980\ncommon user accounts, right?\n\n454\n00:22:56.980 --> 00:23:00.679\nIf the administrative account says admin,\nadmin for the password, and\n\n455\n00:23:00.679 --> 00:23:03.722\nyou changed the password,\nwell, you've done a good job.\n\n456\n00:23:03.722 --> 00:23:05.824\nAt least you've [LAUGH]\nchanged the password.\n\n457\n00:23:05.824 --> 00:23:09.406\nBut if the device allows you to rename\nthat user account, that's even better,\n\n458\n00:23:09.406 --> 00:23:12.826\nbecause now somebody can't go to just\na checklist on a vendor's website and\n\n459\n00:23:12.826 --> 00:23:15.499\nsay, okay, well,\nI don't know what the password is, but\n\n460\n00:23:15.499 --> 00:23:17.170\nI know what the username is, right?\n\n461\n00:23:17.170 --> 00:23:20.350\nSo if we can change both of those,\nwe're gonna be doing good, right?\n\n462\n00:23:20.350 --> 00:23:22.330\nDisabling things like\nremote administration,\n\n463\n00:23:22.330 --> 00:23:24.310\nmaybe remote administration is turned on.\n\n464\n00:23:24.310 --> 00:23:26.025\nWhy don't I want remote administration?\n\n465\n00:23:26.025 --> 00:23:30.925\nCuz that means you leave a hole open\nthat you're now giving external access\n\n466\n00:23:30.925 --> 00:23:33.569\ninto your configuration page, right,\n\n467\n00:23:33.569 --> 00:23:37.245\nfor your home device, or\neven a device on your network.\n\n468\n00:23:37.245 --> 00:23:39.921\nSo again, these are things\nthat we have to worry about.\n\n469\n00:23:39.921 --> 00:23:43.350\nThey also call out things\nlike resource exhaustion.\n\n470\n00:23:43.350 --> 00:23:45.125\nAnd we've kind of already\ntalked about that,\n\n471\n00:23:45.125 --> 00:23:47.760\nthat that can happen in things\nlike improper input handling.\n\n472\n00:23:47.760 --> 00:23:50.952\nIf I'm sending a lot of random,\nunexpected data to a machine, and\n\n473\n00:23:50.952 --> 00:23:54.040\nit doesn't know what to do with it,\nit could crash the machine.\n\n474\n00:23:54.040 --> 00:23:56.907\nIf it crashes the machine,\nobviously that's denial of service.\n\n475\n00:23:56.907 --> 00:24:00.890\nIt could do an application hang,\nwhere the application itself just freezes.\n\n476\n00:24:00.890 --> 00:24:03.328\nRight, it could do things\nlike memory leaks.\n\n477\n00:24:03.328 --> 00:24:07.374\nMemory leaks are another thing that\ncould cause resource exhaustion\n\n478\n00:24:07.374 --> 00:24:10.094\nwhere an application's\nnot properly letting\n\n479\n00:24:10.094 --> 00:24:13.449\ngo of the system memory that\nit originally called to use.\n\n480\n00:24:13.449 --> 00:24:16.387\nSo we definitely have\nto worry about those.\n\n481\n00:24:16.387 --> 00:24:19.650\nNow, I've got quite a bit more to go.\n\n482\n00:24:19.650 --> 00:24:23.197\nI'll tell you what I will,\nI do have one last thing for this one, and\n\n483\n00:24:23.197 --> 00:24:26.810\nI'm sure we're probably gonna\nhave to do a part two here.\n\n484\n00:24:26.810 --> 00:24:29.116\nThey call out untrained users, all right?\n\n485\n00:24:29.116 --> 00:24:33.499\nThis is one of the first layers of your\ndefense and debt system that you really\n\n486\n00:24:33.499 --> 00:24:37.421\nshould be implementing, and\nthat's education of your end users.\n\n487\n00:24:37.421 --> 00:24:41.360\nWe got a little triangle here guys,\nit might help you out.\n\n488\n00:24:41.360 --> 00:24:43.000\nAgain, these are just a recommendation.\n\n489\n00:24:43.000 --> 00:24:47.680\nIt's not any specific like,\npolicy that I'm following,\n\n490\n00:24:47.680 --> 00:24:49.350\njust a recommendation, right?\n\n491\n00:24:49.350 --> 00:24:51.641\nAwareness, communication and\neducation, right?\n\n492\n00:24:51.641 --> 00:24:55.345\nPeople need to be aware that\nthings are even happening, right?\n\n493\n00:24:55.345 --> 00:24:58.030\nAnd this is a cyclic process, right?\n\n494\n00:24:58.030 --> 00:25:00.430\nAnd that there isn't one that's more\nimportant than the other, right?\n\n495\n00:25:00.430 --> 00:25:03.784\nUltimately leads to education,\nawareness and the communication,\n\n496\n00:25:03.784 --> 00:25:05.185\ncontinual communication.\n\n497\n00:25:05.185 --> 00:25:09.805\nSo these are three things that when it\ncomes to untrained users that you can help\n\n498\n00:25:09.805 --> 00:25:14.705\nin order to bring them into the knowledge\nthat they need so that they're not undoing\n\n499\n00:25:14.705 --> 00:25:19.058\nall of your security implementation\njust by simply propping a door open.\n\n500\n00:25:19.058 --> 00:25:22.238\nOr writing a password down and\nsticking it on the corner of their monitor\n\n501\n00:25:22.238 --> 00:25:24.738\nbecause they don't wanna\nhave to remember it, right?\n\n502\n00:25:24.738 --> 00:25:28.302\nMaking them aware of what can happen,\ncommunicating that, and\n\n503\n00:25:28.302 --> 00:25:31.404\nthen not only making them aware and\ncommunicating, but\n\n504\n00:25:31.404 --> 00:25:34.248\nproviding users with adequate training,\nright?\n\n505\n00:25:34.248 --> 00:25:37.615\nSo that they can retain the information\nthat they're gonna be learning through\n\n506\n00:25:37.615 --> 00:25:38.980\nawareness and communication.\n\n507\n00:25:38.980 --> 00:25:42.560\nAnd then they also through education\ncan have the hands on implementation.\n\n508\n00:25:42.560 --> 00:25:46.060\nSo, you've run through this\nprocess a couple of times,\n\n509\n00:25:46.060 --> 00:25:47.830\nit's one of the reasons we do fire drills,\nright?\n\n510\n00:25:47.830 --> 00:25:50.000\nWe do fire drills in school\nbecause we can practice it,\n\n511\n00:25:50.000 --> 00:25:53.450\nwe knew exactly what we needed\nto do when the time came, right?\n\n512\n00:25:53.450 --> 00:25:57.540\nSo communication, awareness and\nthen ultimately, education so\n\n513\n00:25:57.540 --> 00:25:59.450\nthat they can get the hands-on,\nthe end users.\n\n514\n00:25:59.450 --> 00:26:03.330\nAnd you don't have to worry about\nuntrained users causing your security\n\n515\n00:26:03.330 --> 00:26:05.950\nviolations or security breaches\ninside of your organizations.\n\n516\n00:26:05.950 --> 00:26:08.930\n&gt;&gt; It's kind of interesting\nespecially if you guys are familiar.\n\n517\n00:26:08.930 --> 00:26:11.380\nMaybe you've taken other\nCompTIA exams in the past, but\n\n518\n00:26:11.380 --> 00:26:15.420\nthey wanna have that human\naspect that relatable side here.\n\n519\n00:26:15.420 --> 00:26:18.990\nBecause we're not just dealing with\nall things technical all the time.\n\n520\n00:26:18.990 --> 00:26:21.300\nYou really do have to think about\nhow you're gonna approach and\n\n521\n00:26:21.300 --> 00:26:23.170\nmassage different relationships.\n\n522\n00:26:23.170 --> 00:26:26.830\nTo make sure that people do understand\nthat they're not just seeing it as Wes and\n\n523\n00:26:26.830 --> 00:26:29.620\nCherokee, trying to bully you and\ntell you what you can and cannot do.\n\n524\n00:26:29.620 --> 00:26:31.740\nSo if you kind of put it in that\nperspective, like Wes said,\n\n525\n00:26:31.740 --> 00:26:32.960\nwith communication?\n\n526\n00:26:32.960 --> 00:26:35.420\nExplain to them why you're\nimplementing certain things?\n\n527\n00:26:35.420 --> 00:26:38.421\nThen they may be a lot more\nreceptive to the actions and\n\n528\n00:26:38.421 --> 00:26:40.099\nthe policies in that manner.\n\n529\n00:26:40.099 --> 00:26:43.055\n&gt;&gt; I'm glad you said that because one of\nthe things that I didn't mention, and\n\n530\n00:26:43.055 --> 00:26:46.260\nI have this problem myself, is that\ncommunication is a two-way street, right?\n\n531\n00:26:46.260 --> 00:26:50.390\nIf it isn't a two-way street\nthen it's called lecture, right?\n\n532\n00:26:50.390 --> 00:26:53.040\nCommunication means that you\nlisten to the end users so\n\n533\n00:26:53.040 --> 00:26:54.630\nthat you can help them out, right?\n\n534\n00:26:54.630 --> 00:26:57.190\nYou training, right?\n\n535\n00:26:57.190 --> 00:27:00.433\nYou being here at ITVProTV,\nwatching these security plus episodes.\n\n536\n00:27:00.433 --> 00:27:03.665\nMaybe going on to more advanced CSA plus,\nmaybe you're going for\n\n537\n00:27:03.665 --> 00:27:04.794\nthe cream of the crop.\n\n538\n00:27:04.794 --> 00:27:06.872\nYou're going all the way to the top,\nthe CIISP.\n\n539\n00:27:06.872 --> 00:27:10.478\nYou understand this or are understanding.\n\n540\n00:27:10.478 --> 00:27:12.044\nYou are getting educated.\n\n541\n00:27:12.044 --> 00:27:15.320\nThe average end user that might\nbe sitting up at the front desk,\n\n542\n00:27:15.320 --> 00:27:16.350\nmight not be educated.\n\n543\n00:27:16.350 --> 00:27:17.750\nSo remember that communication,\n\n544\n00:27:17.750 --> 00:27:21.060\nthat's a two-way street,\nwhich implies listening too.\n\n545\n00:27:21.060 --> 00:27:25.420\nAnd that's something that I definitely\nhave to practice on a daily basis.\n\n546\n00:27:25.420 --> 00:27:28.471\n&gt;&gt; Listening or setting up some kind\nof portal forum where they can, or\n\n547\n00:27:28.471 --> 00:27:31.952\njust letting maybe there's a particular\nemail address that's dedicated,\n\n548\n00:27:31.952 --> 00:27:34.642\nlike help@ITProTV.com or\nsomething like that, right?\n\n549\n00:27:34.642 --> 00:27:39.095\nSo I think we've covered quite a bit\nof different types of impacts that\n\n550\n00:27:39.095 --> 00:27:43.248\ndifferent vulnerabilities presents\nto our organizations, but\n\n551\n00:27:43.248 --> 00:27:44.845\nwe do have more to cover.\n\n552\n00:27:44.845 --> 00:27:47.420\nSo for this particular episode,\nwe'll go ahead and sign out.\n\n553\n00:27:47.420 --> 00:27:49.324\nRemember, I'm your show host,\nCherokee Boose.\n\n554\n00:27:49.324 --> 00:27:50.170\n&gt;&gt; And I'm Wes Bryan.\n\n555\n00:27:50.170 --> 00:27:53.270\n&gt;&gt; See you next time here at ITProTV.\n\n556\n00:27:53.270 --> 00:27:59.297\n[MUSIC]\n\n557\n00:27:59.297 --> 00:28:02.351\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213512723"
        },
        {
          "description": "In this show Cherokee and Wes continue their previous discussion by explaining how improperly configured accounts can impact an organizations security. They also talk about memory buffer vulnerabilities, architecture or design weaknesses, zero day attacks, and improper certificate and key management.",
          "length": "1757",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-6-2-mpact_of_various_vulnerabilities_pt2-041017-PGM.00_29_26_10.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-6-2-mpact_of_various_vulnerabilities_pt2-041017-PGM.00_29_26_10.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-1-6-2-mpact_of_various_vulnerabilities_pt2-041017-PGM.00_29_26_10.Still001-sm.jpg",
          "title": "Impact of Various Vulnerabilities Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:02.154\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.154 --> 00:00:08.646\n[CROSSTALK].\n[MUSIC]\n\n3\n00:00:08.646 --> 00:00:11.892\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.892 --> 00:00:14.066\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n5\n00:00:14.066 --> 00:00:15.437\nI'm your show host Cherokee Boose.\n\n6\n00:00:15.437 --> 00:00:20.071\nThis is a continuation of a previous\ndiscussion where we're looking at\n\n7\n00:00:20.071 --> 00:00:23.549\nthe impact of different\ntypes of vulnerabilities and\n\n8\n00:00:23.549 --> 00:00:28.417\nhow our organizations react and what\nwe may see as the result of individuals\n\n9\n00:00:28.417 --> 00:00:31.080\nexecuting on these vulnerabilities.\n\n10\n00:00:31.080 --> 00:00:34.620\nWith us today we have Mr Wes Bryan in\nstudios, thank you for joining us, Wes.\n\n11\n00:00:34.620 --> 00:00:36.040\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n12\n00:00:36.040 --> 00:00:39.250\nYep, that's right, part two because\nI talked a lot in the first one.\n\n13\n00:00:39.250 --> 00:00:39.760\nThat's right,\n\n14\n00:00:39.760 --> 00:00:43.620\nso we've got a few more that we want\nto tie off here in the second part.\n\n15\n00:00:43.620 --> 00:00:47.310\nIn the first part we were talking about\nvarious vulnerabilities that you should be\n\n16\n00:00:47.310 --> 00:00:51.330\naware of, things like improper error\nhandling, improper input handling.\n\n17\n00:00:51.330 --> 00:00:55.343\nWe talked about a situation in\nwhich two processes can strive and\n\n18\n00:00:55.343 --> 00:00:59.514\nrace to the CPU to be executed and\nthat was called race conditions.\n\n19\n00:00:59.514 --> 00:01:03.713\nAnd the fact that if these are supposed\nto be sequentially processed tasks,\n\n20\n00:01:03.713 --> 00:01:07.790\nwhat happens if the second one gets\nthere first or gets there out of order?\n\n21\n00:01:07.790 --> 00:01:11.027\nLarge amounts of information\ncan be overwritten,\n\n22\n00:01:11.027 --> 00:01:15.556\nold data could be overwritten by new\ndata so it can cause some problems.\n\n23\n00:01:15.556 --> 00:01:18.872\nIf you're not familiar with those\nguys I'll definitely go back and\n\n24\n00:01:18.872 --> 00:01:21.440\nwatch first part and\njoin us here in the second part.\n\n25\n00:01:21.440 --> 00:01:25.370\nNow, first thing that we're gonna\ndive into, they do call out for\n\n26\n00:01:25.370 --> 00:01:30.080\ninstance something known as\nmisconfigured accounts, right?\n\n27\n00:01:30.080 --> 00:01:31.340\nAnd this can happen.\n\n28\n00:01:31.340 --> 00:01:34.210\nI've got a little diagram here,\njust a little list of some of\n\n29\n00:01:34.210 --> 00:01:38.045\nthe account considerations that\nwe need to, well, consider.\n\n30\n00:01:38.045 --> 00:01:42.240\n[LAUGH] And the first two that I'd like\nto talk about are the guest accounts and\n\n31\n00:01:42.240 --> 00:01:43.700\nthe administrator account.\n\n32\n00:01:43.700 --> 00:01:48.090\nAll right, keep in mind that with the\nguest account, this is somebody that we're\n\n33\n00:01:48.090 --> 00:01:51.310\nnot gonna give them too many privileges or\npermissions over the machine.\n\n34\n00:01:51.310 --> 00:01:55.600\nSo these guest accounts can be\na source of vulnerability, right?\n\n35\n00:01:55.600 --> 00:01:58.590\nThey could be a source of\nattack if they are enabled.\n\n36\n00:01:58.590 --> 00:02:02.290\nThe administrative account, in fact let's\ntalk about for instance Windows, right?\n\n37\n00:02:02.290 --> 00:02:04.020\nWindows, back in the days of XP,\n\n38\n00:02:05.410 --> 00:02:10.100\nWe had a different security\nmodel than we have today.\n\n39\n00:02:10.100 --> 00:02:15.300\nIn the days of XP, you had that first\nuser that the first user account if\n\n40\n00:02:15.300 --> 00:02:18.050\nyou will that was created in an XP machine\nwould be the default administrator.\n\n41\n00:02:18.050 --> 00:02:22.620\nNow the default administrator would\nhave privileges over the entire machine.\n\n42\n00:02:22.620 --> 00:02:26.720\nAnd the problem with that was that\nany software that was downloaded\n\n43\n00:02:26.720 --> 00:02:29.840\nto the machine would now run in\nthe context of the default administrator.\n\n44\n00:02:29.840 --> 00:02:32.270\nSo they went to a new security model.\n\n45\n00:02:32.270 --> 00:02:36.460\nIn fact, I'm just gonna drop over to a\nWindows machine here and kind of show you\n\n46\n00:02:36.460 --> 00:02:42.180\nwhere, because that default administrative\naccount is so powerful, they disabled it.\n\n47\n00:02:42.180 --> 00:02:46.870\nIn fact, if I just kind of right click\non our Windows charm here, Windows icon.\n\n48\n00:02:46.870 --> 00:02:49.580\nAnd bring up Computer Management, and\n\n49\n00:02:49.580 --> 00:02:53.790\nwe can expand out the Local Users and\nGroups here.\n\n50\n00:02:53.790 --> 00:02:58.470\nI got the Users and you can see here's\na default administrator account.\n\n51\n00:02:58.470 --> 00:03:01.850\nAnd if you'll notice something\nnotice that the account is disabled.\n\n52\n00:03:01.850 --> 00:03:05.100\nThat little down arrow, little white\ncircle there with the black down arrow\n\n53\n00:03:05.100 --> 00:03:06.890\nto let me know that this is disabled.\n\n54\n00:03:06.890 --> 00:03:09.280\nAnd even the guest account are disabled.\n\n55\n00:03:09.280 --> 00:03:10.830\nNow why is that?\n\n56\n00:03:10.830 --> 00:03:15.050\nWell, that's because people know what\nthat administrative accounts looks like,\n\n57\n00:03:15.050 --> 00:03:16.680\nthey know what to look at obviously.\n\n58\n00:03:16.680 --> 00:03:23.062\nThere is in Windows,\nwe see these values as user friendly name.\n\n59\n00:03:23.062 --> 00:03:26.216\nWhat the Window subsystem actually\nsees the security subsystem,\n\n60\n00:03:26.216 --> 00:03:28.985\nsomething known as an SID,\nSID, a security identifier.\n\n61\n00:03:28.985 --> 00:03:33.098\nWell a security identifier if I remember\nright, for the default administrator,\n\n62\n00:03:33.098 --> 00:03:35.899\nstarts with I think like 500,\nand somebody can see,\n\n63\n00:03:35.899 --> 00:03:40.068\nif they've seen an SSID that started with,\nat the very first portion with 500,\n\n64\n00:03:40.068 --> 00:03:42.540\nthey'd say I don't care what it's named.\n\n65\n00:03:42.540 --> 00:03:43.670\nYou could rename it all you want.\n\n66\n00:03:43.670 --> 00:03:46.940\nYou could rename it Sally,\nyou could rename it Bob if you want.\n\n67\n00:03:46.940 --> 00:03:49.280\nBut underneath, that's the target, right?\n\n68\n00:03:49.280 --> 00:03:52.160\nSo they knew that if they could\nattack the default administrator,\n\n69\n00:03:52.160 --> 00:03:56.270\nthen that means that any code that they\ngot into the machine would now also run\n\n70\n00:03:56.270 --> 00:03:59.130\nthe privileges of\nan administrator as well.\n\n71\n00:03:59.130 --> 00:04:03.630\nWhen Vista came out, we moved to\na standard user security model.\n\n72\n00:04:03.630 --> 00:04:08.660\nWhich means all administrators actually\noperate at the level of a standard user.\n\n73\n00:04:08.660 --> 00:04:11.520\nAnd it's not until they need those\nprivileges that the privileges\n\n74\n00:04:11.520 --> 00:04:16.010\nare escalated in order to allow them\nto perform whatever the task is.\n\n75\n00:04:16.010 --> 00:04:20.190\nAnd what that helps to do along with\nmany other layered defense mechanisms,\n\n76\n00:04:20.190 --> 00:04:24.900\ndynamic security mechanisms inside of\nWindows Is to help against those privilege\n\n77\n00:04:24.900 --> 00:04:30.020\nescalation attacks that could be very\neasily executed inside of the days of XP.\n\n78\n00:04:30.020 --> 00:04:33.110\n&gt;&gt; Now Wes,\nif we're talking about domain environment,\n\n79\n00:04:33.110 --> 00:04:37.930\nthen I can just take an individual user\nand add them to an administrator's group.\n\n80\n00:04:37.930 --> 00:04:40.030\nBut who would I wanna be\nadding to that group?\n\n81\n00:04:40.030 --> 00:04:42.308\nBecause I wouldn't want to just be\nrandomly doling that out, right?\n\n82\n00:04:42.308 --> 00:04:43.238\n&gt;&gt; No, definitely not.\n\n83\n00:04:43.238 --> 00:04:47.088\nAnd that follows along with a principle\nthat we talk about sometimes,\n\n84\n00:04:47.088 --> 00:04:49.810\nthe principle of least privilege, right?\n\n85\n00:04:49.810 --> 00:04:53.360\nYou only give your end users\nexactly what they, the privileges,\n\n86\n00:04:53.360 --> 00:04:54.720\nthe level of privileges that they need,\n\n87\n00:04:54.720 --> 00:04:57.430\nand the level of access that they\nneed to accomplish their task.\n\n88\n00:04:57.430 --> 00:04:58.648\nNo more, no less, right?\n\n89\n00:04:58.648 --> 00:05:01.560\nSo I don't wanna be making somebody,\nif I'm just a standard user and\n\n90\n00:05:01.560 --> 00:05:04.360\nCherokee's the administrator,\nthere's no reason for\n\n91\n00:05:04.360 --> 00:05:07.230\nsomebody to create my account and put\nit inside of that administrative group.\n\n92\n00:05:07.230 --> 00:05:11.340\nBecause now what could happen, especially\nin a domain environment, you make\n\n93\n00:05:11.340 --> 00:05:15.430\nsomebody an enterprise administrator,\nthey can really hose up your force,\n\n94\n00:05:15.430 --> 00:05:19.270\nyour entire Active Directory force really,\nreally quick because now what they have is\n\n95\n00:05:19.270 --> 00:05:22.450\nthey have more privileges and\npermissions than they really should have.\n\n96\n00:05:22.450 --> 00:05:25.380\nSo we've gotta watch out\nwith administrator accounts,\n\n97\n00:05:25.380 --> 00:05:26.610\nadministrator groups, too.\n\n98\n00:05:26.610 --> 00:05:30.340\nBecause by association if you're\nan administrator group, guess what?\n\n99\n00:05:30.340 --> 00:05:32.690\nDoesn't matter what your username is,\ndoesn't matter if it's administrator or\n\n100\n00:05:32.690 --> 00:05:34.710\nnot, you just became an administrator, and\n\n101\n00:05:34.710 --> 00:05:37.470\nnow you have a higher level of\nprivilege than maybe you should.\n\n102\n00:05:37.470 --> 00:05:40.710\nGuest accounts, right,\nwe have to worry about those two.\n\n103\n00:05:40.710 --> 00:05:42.730\nOther accounts, shared accounts, right?\n\n104\n00:05:42.730 --> 00:05:47.440\nShared accounts are those type of accounts\nthat let's say we have one account and\n\n105\n00:05:47.440 --> 00:05:49.790\neverybody logs into the machine\nto perform that functionality.\n\n106\n00:05:49.790 --> 00:05:52.810\nIt wasn't very hard to do\na security audit, right?\n\n107\n00:05:52.810 --> 00:05:54.190\nSo if Cherokee and I, and\n\n108\n00:05:54.190 --> 00:05:57.770\nthen let's say somebody else has\naccess to this one shared account, and\n\n109\n00:05:57.770 --> 00:06:03.180\nwe do a rotation to where we randomly\nlog in as whatever the account is.\n\n110\n00:06:03.180 --> 00:06:05.700\nAnd we look at a specific service, right?\n\n111\n00:06:05.700 --> 00:06:09.770\nWell, the problem is was it Cherokee that\nlogged in, was it myself that logged in,\n\n112\n00:06:09.770 --> 00:06:11.920\nor the other person that logged in?\n\n113\n00:06:11.920 --> 00:06:13.270\nWe have no way to tell, right?\n\n114\n00:06:13.270 --> 00:06:19.570\nAt that point, we've got no way,\nwe have lost what we call non repudiation.\n\n115\n00:06:19.570 --> 00:06:23.840\n&gt;&gt; Yeah, in the previous episode I had\ntalked about those embedded systems\n\n116\n00:06:23.840 --> 00:06:26.360\nthat were running those large\novens on the production floor.\n\n117\n00:06:26.360 --> 00:06:27.530\nI don't know if you guys remember that.\n\n118\n00:06:27.530 --> 00:06:29.530\nIf not, you can go back and\ncheck that out.\n\n119\n00:06:29.530 --> 00:06:31.660\nBut for those particular machines,\n\n120\n00:06:31.660 --> 00:06:35.500\nthe operators of those ovens,\nthere was an operator account.\n\n121\n00:06:35.500 --> 00:06:39.000\nNow, like we have spoken about,\nthat particular machine was air-gapped, so\n\n122\n00:06:39.000 --> 00:06:40.490\nit wasn't connected to our network.\n\n123\n00:06:40.490 --> 00:06:44.334\nThere wasn't a whole lot that they could\ndo other than break this expensive\n\n124\n00:06:44.334 --> 00:06:44.891\nmachine.\n\n125\n00:06:44.891 --> 00:06:47.141\n[LAUGH] So\nwhen you think about non-repudiation,\n\n126\n00:06:47.141 --> 00:06:50.781\nin some situations it makes sense to have\nshared accounts, but most of the time,\n\n127\n00:06:50.781 --> 00:06:54.383\ngenerally speaking, you want to go ahead\nand have those individual accounts.\n\n128\n00:06:54.383 --> 00:06:56.541\nIt really just depends\non that environment.\n\n129\n00:06:56.541 --> 00:07:00.485\n&gt;&gt; Definitely, and give you an example of\nsome shared accounts that you might see,\n\n130\n00:07:00.485 --> 00:07:04.610\nthe other accounts that, I would say watch\nout for, are service accounts, right?\n\n131\n00:07:04.610 --> 00:07:05.235\n&gt;&gt; Sure.\n\n132\n00:07:05.235 --> 00:07:06.605\n&gt;&gt; That could be a type of shared account.\n\n133\n00:07:06.605 --> 00:07:10.505\nNow, for instance Windows today has made\nit all a lot easier, you have managed\n\n134\n00:07:10.505 --> 00:07:16.450\nservice accounts in which it can make\nthe management of it a lot easier.\n\n135\n00:07:16.450 --> 00:07:20.290\nSo let me give you an example where you\ncreate an account for a specific service.\n\n136\n00:07:20.290 --> 00:07:21.220\nSo according to,\n\n137\n00:07:21.220 --> 00:07:24.970\nlet's say, your directory, it looks no\ndifferent than Wes' account does, right?\n\n138\n00:07:24.970 --> 00:07:28.500\nBut that account connects to\na web application server, right?\n\n139\n00:07:28.500 --> 00:07:30.880\nAnd we need to change passwords on it.\n\n140\n00:07:30.880 --> 00:07:32.580\nWell, misconfiguration sometimes,\n\n141\n00:07:32.580 --> 00:07:34.890\npeople don't want to change\npasswords on a service account.\n\n142\n00:07:34.890 --> 00:07:36.110\nSo what would they do?\n\n143\n00:07:36.110 --> 00:07:39.040\nWell when they create the account,\nthey set up a password, and\n\n144\n00:07:39.040 --> 00:07:40.970\nthey set it to never expiring.\n\n145\n00:07:40.970 --> 00:07:44.979\nWell I want you to think about a brute\nforce attack against a never-expiring\n\n146\n00:07:44.979 --> 00:07:47.622\npassword, versus one\nthat expires in 30 days.\n\n147\n00:07:47.622 --> 00:07:50.531\nIf you set something like that on\nthe service accounts as you don't want\n\n148\n00:07:50.531 --> 00:07:52.907\nthe trouble of having to\nremember to change the password,\n\n149\n00:07:52.907 --> 00:07:56.220\nyou've given the hackers all the time they\nneed to perform a brute force attack.\n\n150\n00:07:56.220 --> 00:08:00.180\nSo even service accounts are things that\nwe have to worry about because they can be\n\n151\n00:08:00.180 --> 00:08:01.005\nshared as well.\n\n152\n00:08:01.005 --> 00:08:03.529\nAnd they can be a nightmare,\nwhen it comes to security vulnerabilities.\n\n153\n00:08:03.529 --> 00:08:07.290\nAnd more so, when it comes to the upkeep\nof these type of service accounts.\n\n154\n00:08:07.290 --> 00:08:11.120\nBecause, it's just administratively\neasier to say, set the password once,\n\n155\n00:08:11.120 --> 00:08:14.050\nit never expires, and\nthen we forget about it.\n\n156\n00:08:14.050 --> 00:08:17.630\nAnd it's not until we have some kind of\nvulnerability that it causes problems.\n\n157\n00:08:17.630 --> 00:08:20.560\n&gt;&gt; Well, you were just giving\na perfect example of someone\n\n158\n00:08:20.560 --> 00:08:24.180\ntaking the easy way out, or being\na little bit lazy with their work there.\n\n159\n00:08:24.180 --> 00:08:26.160\nBut we got a comment in chat,\nand they said, but\n\n160\n00:08:26.160 --> 00:08:29.450\neverything works when you just assign\neveryone in the administrator's group or\n\n161\n00:08:29.450 --> 00:08:34.610\ngive them that level, and unfortunately,\nI have seen that happen in real life.\n\n162\n00:08:34.610 --> 00:08:37.080\nBut that's not what we want\nyou guys to be doing, so.\n\n163\n00:08:37.080 --> 00:08:40.000\n&gt;&gt; I'll give you an example,\nwhere it actually happened to me.\n\n164\n00:08:40.000 --> 00:08:42.304\nOne of the places that\nI worked with before,\n\n165\n00:08:42.304 --> 00:08:44.683\nI was supposed to be\na domain administrator.\n\n166\n00:08:44.683 --> 00:08:47.028\nAnd the person that was\nsetting up the permissions,\n\n167\n00:08:47.028 --> 00:08:49.851\nI don't know if he didn't have\nhis spectacles on that day, and\n\n168\n00:08:49.851 --> 00:08:53.910\ndecided to give me permission actually\ngave me an enterprise administrator.\n\n169\n00:08:53.910 --> 00:08:58.530\nAnd then somehow whatever he had\ndone in the GPO, deleted every other\n\n170\n00:08:58.530 --> 00:09:01.250\nadministrative account within the domain,\nincluding the domain administrator.\n\n171\n00:09:01.250 --> 00:09:04.437\nSo at the end of the day, not did I\nhave the enterprise-level administrator,\n\n172\n00:09:04.437 --> 00:09:07.541\nI was the only one that could actually\nlog in and do anything so, I actually-\n\n173\n00:09:07.541 --> 00:09:08.640\n&gt;&gt; Did you get a raise?\n\n174\n00:09:08.640 --> 00:09:09.637\n&gt;&gt; I didn't get a raise.\n\n175\n00:09:09.637 --> 00:09:12.383\nWell yeah, I got a raise on\nmy blood pressure that day,\n\n176\n00:09:12.383 --> 00:09:13.834\nI can tell you that for sure.\n\n177\n00:09:13.834 --> 00:09:17.209\n[LAUGH] But you can see where\na misconfiguration like that can cause\n\n178\n00:09:17.209 --> 00:09:18.850\na lot of problems.\n\n179\n00:09:18.850 --> 00:09:23.820\nSo, definitely,\nbe careful when it comes to accounts.\n\n180\n00:09:23.820 --> 00:09:28.400\nAdministrative accounts like we've talked\nabout principle, at least privilege,\n\n181\n00:09:28.400 --> 00:09:32.030\nmake sure that you're only\ngiving the people access,\n\n182\n00:09:32.030 --> 00:09:34.250\nthe level of access that they\nneed to perform their duties.\n\n183\n00:09:35.370 --> 00:09:36.840\nAll right, so what else do we have here?\n\n184\n00:09:36.840 --> 00:09:39.770\nSome other things that they get into,\nthey talk about memory and\n\n185\n00:09:39.770 --> 00:09:41.350\nbuffer vulnerabilities.\n\n186\n00:09:41.350 --> 00:09:45.095\nAnd in other episodes we kind of\ntackle this very first one, but\n\n187\n00:09:45.095 --> 00:09:49.843\nI don't want to mention some of the other\nones here, and not kind of recap this.\n\n188\n00:09:49.843 --> 00:09:52.741\nOne of the first ones that they\ncall about is a memory leak.\n\n189\n00:09:52.741 --> 00:09:57.912\nNow, a memory leak can be a very\nbad situation in the fact that at\n\n190\n00:09:57.912 --> 00:10:04.464\nthe very least, a memory leak is when\nan application holds a portion of memory.\n\n191\n00:10:04.464 --> 00:10:09.311\nAnd when that application is no longer\nactually using the memory, it doesn't let\n\n192\n00:10:09.311 --> 00:10:14.068\nit go and give another application\naccess to that portion of memory.\n\n193\n00:10:14.068 --> 00:10:19.180\nAll right, the worst case scenario that\ncan happen is it keeps consuming memory\n\n194\n00:10:19.180 --> 00:10:22.360\nand consuming memory and consuming memory,\nand then all of a sudden,\n\n195\n00:10:22.360 --> 00:10:23.590\nyou have no more memory.\n\n196\n00:10:23.590 --> 00:10:28.260\nMemory is gone and you can no\nlonger execute other applications.\n\n197\n00:10:28.260 --> 00:10:31.725\nLet's say if it's a web server or\na server in general, and\n\n198\n00:10:31.725 --> 00:10:35.210\nall the resources are completely\nexhausted, all right?\n\n199\n00:10:35.210 --> 00:10:37.700\nMemory leaks can also cause other things.\n\n200\n00:10:37.700 --> 00:10:41.995\nThey can cause data,\nif data is where the memory's leaking,\n\n201\n00:10:41.995 --> 00:10:45.808\nto spill over and\nuncheck portions of memory, right?\n\n202\n00:10:45.808 --> 00:10:49.900\nAnd that would be for instance,\na memory or a buffer overflow attack.\n\n203\n00:10:49.900 --> 00:10:51.880\nSo for\ninstance in a buffer overflow attack,\n\n204\n00:10:51.880 --> 00:10:54.390\nlike I said this is one that\nwe've already talked about.\n\n205\n00:10:54.390 --> 00:10:56.360\nI got a little diagram here.\n\n206\n00:10:56.360 --> 00:10:59.920\nThis is where we're sending more\ninformation into whatever the buffer is.\n\n207\n00:10:59.920 --> 00:11:01.760\nFor instance, like a network adapter.\n\n208\n00:11:01.760 --> 00:11:04.230\nMore information than the buffer can hold,\nright?\n\n209\n00:11:04.230 --> 00:11:07.071\nAnd we've got these assigned\nlocations in the buffer\n\n210\n00:11:07.071 --> 00:11:09.410\nwhere data's supposed to be stored.\n\n211\n00:11:09.410 --> 00:11:14.190\nThe problem is if we end up filling up\nthat buffer and it spills over, right.\n\n212\n00:11:14.190 --> 00:11:20.380\nNow we get our information into\nunchecked portions of memory.\n\n213\n00:11:20.380 --> 00:11:21.890\nAnd here's the problem with that, right.\n\n214\n00:11:21.890 --> 00:11:27.470\nWe can overripe app data, data that's\nalready being used if you will,\n\n215\n00:11:27.470 --> 00:11:29.750\nin that memory location\nby another application.\n\n216\n00:11:29.750 --> 00:11:33.000\nIt causes a problem,\nit can crash the application.\n\n217\n00:11:33.000 --> 00:11:35.910\nIt can crash the OS,\nit can just stop the OS, right.\n\n218\n00:11:35.910 --> 00:11:39.700\nYou can get a complete system lock and\nmaybe you don't have a blue, like in\n\n219\n00:11:39.700 --> 00:11:43.000\nWindows, have a blue screen or a kernel\npanic depending on what operating system.\n\n220\n00:11:43.000 --> 00:11:44.890\nThey all have kernel panics.\n\n221\n00:11:44.890 --> 00:11:48.360\nOr last case,\nlike one of the worst scenarios,\n\n222\n00:11:48.360 --> 00:11:53.570\nit can actually execute the code, and that\nis definitely a bad day at the office.\n\n223\n00:11:53.570 --> 00:11:58.000\nSome of the other ones that they call,\nthey call an integer overflow, and\n\n224\n00:11:58.000 --> 00:12:01.380\ninteger overflows happen a lot,\nit's a bug in software.\n\n225\n00:12:01.380 --> 00:12:05.440\nAnd again,\nsometimes they're coded to handle this.\n\n226\n00:12:05.440 --> 00:12:08.310\nJust kind of give you\na basic example of where\n\n227\n00:12:08.310 --> 00:12:12.060\na potential integer overflow\ncould cause problems, right.\n\n228\n00:12:12.060 --> 00:12:15.350\nSo we've got two let's say\n\n229\n00:12:15.350 --> 00:12:18.000\npieces of information that\nneed to be calculated, right.\n\n230\n00:12:18.000 --> 00:12:20.070\nAnd if you guys are coming\nover from the network plus,\n\n231\n00:12:20.070 --> 00:12:23.630\nyou know that we as humans we read\nit in base ten, decimal system.\n\n232\n00:12:23.630 --> 00:12:26.640\nBut computers they only read in base two,\nbinary.\n\n233\n00:12:26.640 --> 00:12:31.580\nAll right, well, to store a decimal\nvalue of 155, it takes 8 bits, right?\n\n234\n00:12:31.580 --> 00:12:35.820\nTo store a decimal value of 101,\nit takes 8 bits, right?\n\n235\n00:12:35.820 --> 00:12:39.470\nSo we have an 8-bit integer,\nthat's what we have.\n\n236\n00:12:39.470 --> 00:12:43.431\nAnd we calculate these two values and\nthe value comes out to 256,\n\n237\n00:12:43.431 --> 00:12:44.900\nwell here's a problem.\n\n238\n00:12:44.900 --> 00:12:52.040\nIn an 8-bit integer, you have 256\npossibilities, but zero's included.\n\n239\n00:12:52.040 --> 00:12:55.076\nSo 0 to 255.\n\n240\n00:12:55.076 --> 00:12:56.694\nSo what happens?\n\n241\n00:12:56.694 --> 00:13:02.870\nWell if it takes 9 bits to store 256,\nwhat happens to the other bit?\n\n242\n00:13:02.870 --> 00:13:04.433\nWell, that's an integer overflow.\n\n243\n00:13:04.433 --> 00:13:07.517\nNow, there's a few things that can happen,\nright?\n\n244\n00:13:10.400 --> 00:13:18.260\nMost often what happens is just some\nkind of random unknown happening, right?\n\n245\n00:13:18.260 --> 00:13:20.310\nIt can be very mysterious,\nthey don't know what happens,\n\n246\n00:13:20.310 --> 00:13:22.406\nthe application just loses\nthe information, it goes away.\n\n247\n00:13:22.406 --> 00:13:28.570\nWorst case, is that that information\ncan actually be used to execute code.\n\n248\n00:13:28.570 --> 00:13:33.675\nSo integer overflows right,\nif you take the example where two decimal\n\n249\n00:13:33.675 --> 00:13:39.402\nvalues are added and it is, for instance,\ngive you another example, right.\n\n250\n00:13:39.402 --> 00:13:43.810\n32-bit integers versus 64-bit integers,\nright?\n\n251\n00:13:43.810 --> 00:13:47.920\nWe can't have a 64-bit application\nrun on the 32-bit system, right?\n\n252\n00:13:47.920 --> 00:13:52.280\nBecause the integer, the word size\nis 64 bits long versus 32 bits long,\n\n253\n00:13:52.280 --> 00:13:53.900\nthey're incompatible.\n\n254\n00:13:53.900 --> 00:13:57.523\nBut if you have it inside of a system\nwhere they're using different integer\n\n255\n00:13:57.523 --> 00:14:00.296\nsizes like that,\nit could cause that integer overflow.\n\n256\n00:14:00.296 --> 00:14:05.458\nWorst case scenario, you're executing\ncode or crashing the application.\n\n257\n00:14:05.458 --> 00:14:09.042\nAll right, some of the other\nones that they call out too, and\n\n258\n00:14:09.042 --> 00:14:11.090\nI don't have a slide for this one.\n\n259\n00:14:11.090 --> 00:14:16.050\nThis is just a pointer dereference,\nknown as null pointer dereference.\n\n260\n00:14:16.050 --> 00:14:20.810\nEssentially is use after free\nvulnerabilities, use this and again this\n\n261\n00:14:20.810 --> 00:14:26.830\nis where a value is pointing back to\nmemory that's not storing information.\n\n262\n00:14:26.830 --> 00:14:31.310\nWe don't want open portions\nof memory where a user or\n\n263\n00:14:31.310 --> 00:14:35.730\nan attacker can turn around and\nstore their data in it.\n\n264\n00:14:35.730 --> 00:14:39.370\nIt can cause things like\napplication crashes, right.\n\n265\n00:14:39.370 --> 00:14:42.019\nIf an application has\na higher level of privilege,\n\n266\n00:14:42.019 --> 00:14:44.890\nyou could do things like\ncode injection as well.\n\n267\n00:14:44.890 --> 00:14:46.240\nSpeaking of code injection,\n\n268\n00:14:46.240 --> 00:14:49.806\nanother type of attack we have is what's\nknown as a DLL injection, all right.\n\n269\n00:14:49.806 --> 00:14:52.802\nAnd I've got a little diagram for\nDLL injection here, so\n\n270\n00:14:52.802 --> 00:14:56.310\nI want you to think about how\nan application just in general works.\n\n271\n00:14:56.310 --> 00:14:57.380\nLet me make it a little easier for\n\n272\n00:14:57.380 --> 00:14:59.930\nyou guys to see that moving\naround on the screen here.\n\n273\n00:15:01.090 --> 00:15:02.330\nWe'll zoom in there, all right.\n\n274\n00:15:02.330 --> 00:15:04.623\nSo I want you to think about\nwhat an application does, right.\n\n275\n00:15:04.623 --> 00:15:07.150\nAn application has an executable.\n\n276\n00:15:07.150 --> 00:15:11.221\nAs an executable loads up, all right.\n\n277\n00:15:11.221 --> 00:15:15.073\nNow in order to keep the footprint\nof an application small,\n\n278\n00:15:15.073 --> 00:15:20.312\nit doesn't necessarily load every bit of\nthe functionality that an application\n\n279\n00:15:20.312 --> 00:15:25.410\ncan perform all into memory at that one\ntime that you execute the application.\n\n280\n00:15:26.750 --> 00:15:28.320\nWhen it needs those functionalities,\n\n281\n00:15:28.320 --> 00:15:32.090\nthen what it does is it could reference\nthe dynamic link libraries, right?\n\n282\n00:15:32.090 --> 00:15:35.310\nAnd these are smaller\nsubset of applications\n\n283\n00:15:35.310 --> 00:15:38.530\nthat perform a specific function,\nall right?\n\n284\n00:15:38.530 --> 00:15:41.485\nBecause they're dynamic and\nthey have a common language,\n\n285\n00:15:41.485 --> 00:15:44.853\nyou can have developers that write\none dynamic link library file for\n\n286\n00:15:44.853 --> 00:15:49.014\na multitude of applications, and then they\ncan do things like sharing it, right?\n\n287\n00:15:49.014 --> 00:15:53.168\nThey can load that single dll into memory,\nand multiple applications can share it,\n\n288\n00:15:53.168 --> 00:15:54.761\nand call on its functionality.\n\n289\n00:15:54.761 --> 00:15:57.081\nAnd extends the functionality\nof the application.\n\n290\n00:15:57.081 --> 00:15:58.937\nBut here's the problem, all right?\n\n291\n00:15:58.937 --> 00:16:02.150\nWe have with DLL injection, right?\n\n292\n00:16:02.150 --> 00:16:07.380\nThis is where an attacker tries\nto inject a malicious routine,\n\n293\n00:16:07.380 --> 00:16:09.540\na malicious DLL, right?\n\n294\n00:16:09.540 --> 00:16:11.720\nSo the DLL, the dynamic link library,\n\n295\n00:16:11.720 --> 00:16:16.530\nattaches to a process,\nit allocates the memory, it copies\n\n296\n00:16:16.530 --> 00:16:22.010\nthe dynamic link library file to\nmemory and then it executes, right.\n\n297\n00:16:22.010 --> 00:16:25.470\nSo again what it's doing is it's modifying\n\n298\n00:16:25.470 --> 00:16:30.950\nthe original intention of the application\nthe developer if you will.\n\n299\n00:16:30.950 --> 00:16:32.420\nIt just didn't intend, right.\n\n300\n00:16:32.420 --> 00:16:37.100\nSo it's an unauthorized loading of a DLL\nfile that performs some kind of function,\n\n301\n00:16:37.100 --> 00:16:41.520\nthat wasn't what the original\nprogrammer or developer had intended.\n\n302\n00:16:43.170 --> 00:16:46.110\nAll right, let's see, a couple other\nthings that they do call out here.\n\n303\n00:16:46.110 --> 00:16:49.670\nThey call out things like architecture and\ndesign weaknesses.\n\n304\n00:16:49.670 --> 00:16:52.760\nAnd again, this is going to be, I don't\nhave anything specific for this one.\n\n305\n00:16:52.760 --> 00:16:56.940\nWe talk about architecture,\nkeep in mind 32 bit and 64 bit, right?\n\n306\n00:16:56.940 --> 00:16:59.650\nIn the Windows today,\nwhen we talk about 64 bit machines,\n\n307\n00:16:59.650 --> 00:17:02.420\nwe have to have drivers digitally signed.\n\n308\n00:17:02.420 --> 00:17:04.980\nIf they're gonna be down there and\nworking with the kernel\n\n309\n00:17:04.980 --> 00:17:08.500\nportions of memory in kernel mode,\nthey have to be digitally signed, why?\n\n310\n00:17:08.500 --> 00:17:10.360\nWhy do we want digital signatures on them?\n\n311\n00:17:10.360 --> 00:17:14.460\nSo that we can verify that they are a\ntrusted application, we know the source,\n\n312\n00:17:14.460 --> 00:17:19.120\nwe know where they came from and even more\nso, we know that Microsoft has tested them\n\n313\n00:17:19.120 --> 00:17:22.900\npretty rigorously to make sure that they\ndo exactly what they should do, right?\n\n314\n00:17:23.970 --> 00:17:26.530\nWhat they shouldn't do is infect or\n\n315\n00:17:26.530 --> 00:17:30.570\noverwrite other drivers that are also\ndown there in the kernel mode.\n\n316\n00:17:30.570 --> 00:17:32.390\nAnd let's understand that too, right?\n\n317\n00:17:32.390 --> 00:17:34.020\nWe have user mode, we have kernel mode.\n\n318\n00:17:34.020 --> 00:17:35.860\nUser mode is a less privileged mode and\n\n319\n00:17:35.860 --> 00:17:40.210\nwhat that means is any kind of\napplication that runs in user mode.\n\n320\n00:17:40.210 --> 00:17:43.720\nIf it causes a problem, it typically\njust causes a problem for that user and\n\n321\n00:17:43.720 --> 00:17:44.510\nthe user data but\n\n322\n00:17:44.510 --> 00:17:48.200\nit doesn't overwrite things like\nsystem files and other users data.\n\n323\n00:17:48.200 --> 00:17:52.666\nKernel mode on the other hand is\na very very privileged mode and this,\n\n324\n00:17:52.666 --> 00:17:56.901\nin kernel mode, all your driver\nshare a common memory location,\n\n325\n00:17:56.901 --> 00:18:01.367\nwhich means that if we get a bad driver,\nright, a malicious driver,\n\n326\n00:18:01.367 --> 00:18:07.410\none that's not digitally signed, you turn\noff Driver signature enforcement, right.\n\n327\n00:18:07.410 --> 00:18:12.720\nAnd that driver, that bad driver,\ngets into that common memory space, not\n\n328\n00:18:12.720 --> 00:18:16.540\nonly can it corrupt the other drivers but\nit can also corrupt the operating system.\n\n329\n00:18:16.540 --> 00:18:18.550\nAnd a lot of times it can\ncause a kernel panic or,\n\n330\n00:18:18.550 --> 00:18:20.930\nin the case of a Windows machine,\ncause a blue screen.\n\n331\n00:18:20.930 --> 00:18:23.600\nSo there's also things like, again,\n\n332\n00:18:23.600 --> 00:18:26.890\narchitecture, design weaknesses,\nthe system itself.\n\n333\n00:18:26.890 --> 00:18:29.190\nThat we have to keep in mind.\n\n334\n00:18:29.190 --> 00:18:31.960\nZero-day threats,\nwe've talked about zero day threats and\n\n335\n00:18:31.960 --> 00:18:33.660\nnew threats in another episode.\n\n336\n00:18:33.660 --> 00:18:38.210\nBut we'll go ahead and just briefly\ntouch base with them here again.\n\n337\n00:18:38.210 --> 00:18:44.786\nKeep in mind a lot of your\nvulnerability scanners, a lot of your\n\n338\n00:18:44.786 --> 00:18:50.500\nanti-malware software, your anti-spyware\nsoftware work on a static database.\n\n339\n00:18:50.500 --> 00:18:54.000\nAnd what I mean by static database is\ntypically definitions are signatures and\n\n340\n00:18:54.000 --> 00:18:55.060\nit has to be updated, right?\n\n341\n00:18:55.060 --> 00:18:58.640\nThat database doesn't modify itself unless\nyou reach back out to the vendor and\n\n342\n00:18:58.640 --> 00:19:00.590\nyou pull it down, so it's static.\n\n343\n00:19:00.590 --> 00:19:04.220\nProblem is there are threats\nthat are happening everyday\n\n344\n00:19:04.220 --> 00:19:07.880\nthat that database does not have\ndefinition for, all right, so\n\n345\n00:19:07.880 --> 00:19:12.810\nthat can cause a problem we are only\nusing a database of known threats or\n\n346\n00:19:12.810 --> 00:19:17.600\nwhat happens if it is unknown, that's when\nyou need to implement things like anomaly\n\n347\n00:19:17.600 --> 00:19:21.330\nbehavioral base solutions\nHeuristics if you will.\n\n348\n00:19:21.330 --> 00:19:26.870\nCloud sample submissions,\ncuz they cause problems as well.\n\n349\n00:19:26.870 --> 00:19:30.850\nThe problems with zero day,\nwe have polymorphic code,\n\n350\n00:19:30.850 --> 00:19:33.350\nwe've got code morphing if you will.\n\n351\n00:19:33.350 --> 00:19:36.400\nObs, I can never say, obs,\ncan you help me with this?\n\n352\n00:19:36.400 --> 00:19:37.100\n&gt;&gt; Obfuscation.\n\n353\n00:19:37.100 --> 00:19:42.030\n&gt;&gt; Obfuscation, I can never say that word,\nright, where we're just kind of hiding it.\n\n354\n00:19:42.030 --> 00:19:48.010\nThese can all make it very, very hard to\nmaintain those databases of known threats.\n\n355\n00:19:48.010 --> 00:19:52.140\nKeep in mind that it can take\ntypically up to a year for\n\n356\n00:19:52.140 --> 00:19:55.000\nthreats to become patched if you will.\n\n357\n00:19:55.000 --> 00:19:58.720\nIt might take up a year for\nthem even be known to the public.\n\n358\n00:19:58.720 --> 00:19:59.720\nEight months to a year.\n\n359\n00:19:59.720 --> 00:20:01.490\nSo this is a very long process.\n\n360\n00:20:01.490 --> 00:20:04.870\nIt can take even longer for\nthem to be patched up,\n\n361\n00:20:04.870 --> 00:20:07.180\nso we do have to worry about that.\n\n362\n00:20:07.180 --> 00:20:11.530\nAll right, one of the last things that\nthey call out that I wanna mentioned\n\n363\n00:20:11.530 --> 00:20:16.630\nhere really briefly, they talk about\nimproper certificate and key management.\n\n364\n00:20:16.630 --> 00:20:20.770\nAll right, if we haven't already,\nwe will talk about\n\n365\n00:20:20.770 --> 00:20:25.130\npublic infrastructure in another\nepisode but we do wanna kinda mention,\n\n366\n00:20:25.130 --> 00:20:29.679\nI wanna just briefly mention what a key\nmanagement lifecycle we'd would look like,\n\n367\n00:20:29.679 --> 00:20:33.380\nso when we talk about things like\nimproper certificate and key management,\n\n368\n00:20:33.380 --> 00:20:36.930\nkeep in mind when you implement a public\nkey infrastructure you're definitely doing\n\n369\n00:20:36.930 --> 00:20:42.150\ncertificate based, security,\nand inside of those\n\n370\n00:20:42.150 --> 00:20:47.230\ncertificates typically is an asymmetric\nkey pair which means there's two keys.\n\n371\n00:20:47.230 --> 00:20:50.870\nAnd we have to be careful on\nhow we handle those keys.\n\n372\n00:20:50.870 --> 00:20:54.030\nBecause we could do things like\nunauthorized disclosure of\n\n373\n00:20:54.030 --> 00:20:55.260\nthe private key.\n\n374\n00:20:55.260 --> 00:20:58.200\nKeep in mind that when you're\ndoing the asymmetric or\n\n375\n00:20:58.200 --> 00:21:00.100\nkey pair, public key encryption.\n\n376\n00:21:00.100 --> 00:21:01.910\nYou have two keys, right.\n\n377\n00:21:01.910 --> 00:21:04.750\nThe public key I can hand to Cherokee,\nthat's no problem, right.\n\n378\n00:21:04.750 --> 00:21:07.740\nBecause she's gonna use my public\nkey to just encrypt information.\n\n379\n00:21:07.740 --> 00:21:11.190\nThat's why I don't care if\nhacker-come-lately grabs my public key and\n\n380\n00:21:11.190 --> 00:21:13.710\ntries to intercept a communication\nthat she's sending to me.\n\n381\n00:21:13.710 --> 00:21:15.070\nWhy, because he's gonna have or\n\n382\n00:21:15.070 --> 00:21:17.890\nshe's gonna have the same key that\nshe used to encrypt the data.\n\n383\n00:21:17.890 --> 00:21:20.550\nIt's gonna do absolutely\nnothing to decrypt the data.\n\n384\n00:21:20.550 --> 00:21:23.530\nBecause like two keys on the launch pad,\nthe only one that,\n\n385\n00:21:23.530 --> 00:21:28.160\nthe only key that can decrypt that\ninformation is the private key, all right?\n\n386\n00:21:28.160 --> 00:21:31.060\nSo hopefully,\nI'm the only one that has that.\n\n387\n00:21:31.060 --> 00:21:32.190\nHowever.\n\n388\n00:21:32.190 --> 00:21:37.170\nIf I disclose that to other people,\nnow they have the means in which to\n\n389\n00:21:37.170 --> 00:21:40.340\ndecrypt the information and\nnow they can eavesdrop on them.\n\n390\n00:21:40.340 --> 00:21:43.310\n&gt;&gt; Sometimes I may want to\ndisclose that information,\n\n391\n00:21:43.310 --> 00:21:47.780\nmaybe to a third-party entity to\nkind of to utilize some kind of.\n\n392\n00:21:47.780 --> 00:21:50.260\nSeparation of,\nI guess separation of duties\n\n393\n00:21:50.260 --> 00:21:53.030\nhere where I'm implementing\nsomething like the m of n control.\n\n394\n00:21:53.030 --> 00:21:57.250\nMaybe I have four different\nadmins on my IT team and\n\n395\n00:21:57.250 --> 00:22:02.130\nI want to have at least three out of\nthose four present before I you know,\n\n396\n00:22:02.130 --> 00:22:04.690\nutilize a particular key for\nmy certificates so\n\n397\n00:22:04.690 --> 00:22:08.760\nthat I don't have maybe West trying\nto have full control over my network.\n\n398\n00:22:08.760 --> 00:22:12.370\nWe even spoke about, in the previous\nepisode I think it was, the HSM,\n\n399\n00:22:12.370 --> 00:22:13.930\nhardware security module.\n\n400\n00:22:13.930 --> 00:22:17.130\nYou might have a dedicated piece of\nencryption hardware to go ahead and\n\n401\n00:22:17.130 --> 00:22:20.770\nstore and hand out those certificates\nonce they've been generated.\n\n402\n00:22:20.770 --> 00:22:25.520\nThere are a lot of different Techniques\nthat you can utilize to implement\n\n403\n00:22:25.520 --> 00:22:28.130\ndifferent types of CA infrastructures.\n\n404\n00:22:28.130 --> 00:22:30.880\nArchitecture of the network alone\ncan be pretty beneficial in\n\n405\n00:22:30.880 --> 00:22:32.680\nkeeping those certificates safe and\nsecure.\n\n406\n00:22:32.680 --> 00:22:34.320\n&gt;&gt; And that goes yeah, that's great.\n\n407\n00:22:34.320 --> 00:22:36.930\nThat goes along with things like\nkey escrow if you're key escrow,\n\n408\n00:22:36.930 --> 00:22:39.160\nyour key backups,\nyour key recovery agents or\n\n409\n00:22:39.160 --> 00:22:43.070\ndata recovery agents depending\non what the context is.\n\n410\n00:22:43.070 --> 00:22:46.480\nYou can lose access to your information,\nso it's important.\n\n411\n00:22:46.480 --> 00:22:50.590\nSo let's go ahead and just take a brief\nlook here at this diagram that I have.\n\n412\n00:22:50.590 --> 00:22:54.740\nSo the very first thing that we have when\nwe talk about key management lifecycle and\n\n413\n00:22:54.740 --> 00:22:58.340\nproper, not improper,\nproper [LAUGH] key management\n\n414\n00:22:58.340 --> 00:23:01.330\nis that first you have some\nkind of registration, right?\n\n415\n00:23:01.330 --> 00:23:04.350\nAn entity first has to be identified and\n\n416\n00:23:04.350 --> 00:23:07.400\nI should've probably put that\njust above registration, right?\n\n417\n00:23:07.400 --> 00:23:10.000\nWe have to properly identify the person,\nright?\n\n418\n00:23:10.000 --> 00:23:14.620\nThey have to know that it's Wes Bryan\nthat is going to grab this key, or\n\n419\n00:23:14.620 --> 00:23:19.110\nis going to potentially request For\na key or a certificate, right?\n\n420\n00:23:19.110 --> 00:23:22.990\nAnd then once we've identified that\nwe go through a registration process.\n\n421\n00:23:22.990 --> 00:23:26.840\nThen after the registration process, we go\ninto Key Generation, and it's important\n\n422\n00:23:26.840 --> 00:23:32.670\nthat if you are doing Key Generation,\nare you generating the right keys?\n\n423\n00:23:32.670 --> 00:23:37.120\nDo you need 1024 encryption,\nif you need 1024, okay.\n\n424\n00:23:37.120 --> 00:23:38.940\nBut do you need 2, what is it, 296?\n\n425\n00:23:38.940 --> 00:23:39.660\n248, excuse me.\n\n426\n00:23:39.660 --> 00:23:41.750\nI'll get them right here eventually.\n\n427\n00:23:41.750 --> 00:23:46.138\n124 and 220, 248, and 1496.\n\n428\n00:23:46.138 --> 00:23:48.839\nDo you need something like\n2048 encryption, right,\n\n429\n00:23:48.839 --> 00:23:50.170\na higher level encryption?\n\n430\n00:23:50.170 --> 00:23:52.960\nSo you have to make sure that\nyou're generating the right keys.\n\n431\n00:23:52.960 --> 00:23:54.896\nKey backup is important, right?\n\n432\n00:23:54.896 --> 00:23:56.963\nKey archival, you might say in a way,\n\n433\n00:23:56.963 --> 00:23:59.620\nbecause I don't want\nthe keys to get corrupted.\n\n434\n00:23:59.620 --> 00:24:01.850\nIf they get corrupted,\nthen the keys are no longer good.\n\n435\n00:24:01.850 --> 00:24:05.530\nIf I don't have a backup\ncopy to do key recovery,\n\n436\n00:24:05.530 --> 00:24:07.470\nthe last part of this isn't going to work,\nright?\n\n437\n00:24:07.470 --> 00:24:11.330\nI've gotta have key backup\nbefore I can have key recovery.\n\n438\n00:24:11.330 --> 00:24:15.240\nDistribution, how do we get that\nkey over to the endpoint, right?\n\n439\n00:24:15.240 --> 00:24:16.500\nIf I've got a key pair,\n\n440\n00:24:16.500 --> 00:24:20.352\nchances are I don't wanna send it\nover an unencrypted channel, right?\n\n441\n00:24:20.352 --> 00:24:22.713\nIt might be something that needs to be so\n\n442\n00:24:22.713 --> 00:24:27.432\nsecure that we export it to a USB thumb\ndrive, encrypt the USB thumb drive, and\n\n443\n00:24:27.432 --> 00:24:31.672\nthen sneakernet it over to the device\nthat we're gonna install it in.\n\n444\n00:24:31.672 --> 00:24:33.020\nWhich is the next portion, right?\n\n445\n00:24:33.020 --> 00:24:38.370\nInstallation, installation of the key,\nthen we have renewal or revocation, right?\n\n446\n00:24:39.780 --> 00:24:41.280\nA key has a life cycle, right?\n\n447\n00:24:41.280 --> 00:24:42.960\nOr a lifespan, if you will.\n\n448\n00:24:42.960 --> 00:24:45.020\nWell, once that key comes\nto the end of its lifespan,\n\n449\n00:24:45.020 --> 00:24:48.750\nwe've got a couple of options here, right?\n\n450\n00:24:48.750 --> 00:24:55.270\nWe can renew it Right, and then that just\nvalidates it for the continuation of time.\n\n451\n00:24:55.270 --> 00:24:58.360\nOr if it's coming to the end of its\nlifecycle, do we have to revoke it?\n\n452\n00:24:58.360 --> 00:25:01.570\nSay we're not using that certificate,\nwe're gonna deprovision that machine, but\n\n453\n00:25:01.570 --> 00:25:04.470\nwe don't want a certificate that's out\nthere on our networks that's still being\n\n454\n00:25:04.470 --> 00:25:06.550\nused when it's no longer\nattached to a system.\n\n455\n00:25:06.550 --> 00:25:09.370\nSo we also have to worry about\nthings like renewal or revocation.\n\n456\n00:25:09.370 --> 00:25:12.230\nWhen we revoke it though,\nI gotta be careful with this one.\n\n457\n00:25:12.230 --> 00:25:16.180\nBecause when you revoke a certificate,\nyou can no longer use it, right.\n\n458\n00:25:16.180 --> 00:25:17.640\nSo there's another thing you can do too,\n\n459\n00:25:17.640 --> 00:25:21.190\nis you can temporarily\nsuspend a certificate.\n\n460\n00:25:21.190 --> 00:25:22.590\nMaybe I have,\n\n461\n00:25:22.590 --> 00:25:26.425\nmaybe I have a young lady that's gonna go\non a maternity Maternity leave, right?\n\n462\n00:25:26.425 --> 00:25:28.765\nWe don't want her certificate\nbeing compromised but\n\n463\n00:25:28.765 --> 00:25:30.405\nwe certainly aren't gonna revoke it.\n\n464\n00:25:30.405 --> 00:25:33.615\nWe need her to be able to come back to\nwork after maternity leave's over, right?\n\n465\n00:25:33.615 --> 00:25:36.805\nSo we temporarily suspend it then we\ndon't have to worry about it being\n\n466\n00:25:36.805 --> 00:25:39.675\nmaliciously passed through our\nnetworks when somebody that\n\n467\n00:25:39.675 --> 00:25:42.385\nit's supposed to go to is no longer there.\n\n468\n00:25:42.385 --> 00:25:46.930\nBut when she comes back we can reinstate\nthe certificate and now we're good to go.\n\n469\n00:25:46.930 --> 00:25:47.580\nWell sure.\n\n470\n00:25:47.580 --> 00:25:48.710\nThat's a great point there Wes.\n\n471\n00:25:48.710 --> 00:25:52.100\nAlso if we think about that\nrevocation process, it can happen\n\n472\n00:25:52.100 --> 00:25:56.410\nany time prior to if we assume that\nthere's been any compromise prior to that.\n\n473\n00:25:56.410 --> 00:25:59.400\nAnd then we also have to think\nabout adding that information\n\n474\n00:25:59.400 --> 00:26:01.070\nto our certificate revocation list.\n\n475\n00:26:01.070 --> 00:26:02.300\nSo it seems like a lot of work, but\n\n476\n00:26:02.300 --> 00:26:05.260\nit's really the best way to\nkeep our end users up-to-date.\n\n477\n00:26:05.260 --> 00:26:09.110\n&gt;&gt; Most definitely and in fact that's the\nother thing is improper key utilization or\n\n478\n00:26:09.110 --> 00:26:10.280\nusage.\n\n479\n00:26:10.280 --> 00:26:11.300\nRight, we have to be careful,\n\n480\n00:26:11.300 --> 00:26:15.560\nwe've gotta make sure that we know\nwhat we're using the key for.\n\n481\n00:26:15.560 --> 00:26:17.460\nWe have to make sure\nthat if the key if for\n\n482\n00:26:17.460 --> 00:26:21.150\na digital signature,\nthat the usage isn't for something else.\n\n483\n00:26:21.150 --> 00:26:22.780\nIf fact, let me kind of show you here.\n\n484\n00:26:22.780 --> 00:26:26.970\nSo you can see that we're going to for\ninstance our Office 365 page and\n\n485\n00:26:26.970 --> 00:26:29.620\nI can see that this is from\nthe Microsoft Corporation, right?\n\n486\n00:26:29.620 --> 00:26:32.170\nKey is having certain utilizations, right?\n\n487\n00:26:32.170 --> 00:26:34.540\nAnd you have to make sure that\nyou have the right key usage.\n\n488\n00:26:34.540 --> 00:26:37.910\nSo for instance,\nyeah that's right, where is that?\n\n489\n00:26:37.910 --> 00:26:39.080\nLet's see.\n\n490\n00:26:39.080 --> 00:26:41.280\nChrome use to be able to go\na little lock button here,\n\n491\n00:26:41.280 --> 00:26:42.170\nthe little green button and you.\n\n492\n00:26:42.170 --> 00:26:44.150\nYou can show your information here.\n\n493\n00:26:44.150 --> 00:26:45.280\nI've kind of buried it here.\n\n494\n00:26:45.280 --> 00:26:46.250\nLet me go ahead and get to that.\n\n495\n00:26:46.250 --> 00:26:51.200\nWhere is that settings,\nmore tools, developer tools.\n\n496\n00:26:51.200 --> 00:26:52.580\nAnd yep, secured here.\n\n497\n00:26:52.580 --> 00:26:58.350\nSo if I choose view certificate, I can see\nthe details of the certificate, right.\n\n498\n00:26:58.350 --> 00:27:03.400\nAnd this is important, because when it\ncomes to key usage, And you generate\n\n499\n00:27:03.400 --> 00:27:09.900\nthese keys typically you have a key usage\nfield here within this certificate.\n\n500\n00:27:09.900 --> 00:27:13.370\nI can see 256 bytes,\nit's probably using a AS 256 or\n\n501\n00:27:13.370 --> 00:27:18.740\nSHA1 maybe, SHA1 probably 256 for\nits key signatures.\n\n502\n00:27:18.740 --> 00:27:21.850\nAll right, but\nhere we go extension key usage, right?\n\n503\n00:27:21.850 --> 00:27:23.360\nNotice it says digital signature.\n\n504\n00:27:24.450 --> 00:27:26.530\nAnd key encipherment, right?\n\n505\n00:27:26.530 --> 00:27:29.380\nAnd there's some extended\nkey usage utilization here.\n\n506\n00:27:29.380 --> 00:27:33.170\nWe can see that it's also used for\nserver authentication and\n\n507\n00:27:33.170 --> 00:27:35.090\nclient authentication as well.\n\n508\n00:27:35.090 --> 00:27:38.200\nSo I want you to keep in mind\nthat you have to make sure that\n\n509\n00:27:38.200 --> 00:27:39.960\nthe keys are utilized correctly and\n\n510\n00:27:39.960 --> 00:27:44.190\nthat when things like certificates maybe\ngot an internal PKI, your certificates\n\n511\n00:27:44.190 --> 00:27:48.350\nare being created, That you're creating\nthem for the right purposes too.\n\n512\n00:27:48.350 --> 00:27:52.030\nSo we can see all of that information\nright here inside of our certificate.\n\n513\n00:27:52.030 --> 00:27:54.510\nSo keep in mind that from\nbeginning to end, and you know,\n\n514\n00:27:54.510 --> 00:27:56.290\nI don't know if I finished\nthe life cycle here.\n\n515\n00:27:56.290 --> 00:27:57.920\nOkay, so recovery.\n\n516\n00:27:57.920 --> 00:27:59.230\nThis is the other thing.\n\n517\n00:27:59.230 --> 00:28:00.990\nIt's contingent on backup, right?\n\n518\n00:28:00.990 --> 00:28:03.290\nYou need a key recovery agent, all right?\n\n519\n00:28:03.290 --> 00:28:08.060\nCherokee has already mentioned like\nthe M event concept where you've got.\n\n520\n00:28:08.060 --> 00:28:11.680\nPortions of your keys, that are broken up\nand sent to so many people, that need to\n\n521\n00:28:11.680 --> 00:28:16.080\nbe present to put that key back together,\nin order to do the restoration.\n\n522\n00:28:16.080 --> 00:28:20.390\nDo you have things like a third party\nthat you're allowing to escrow the key?\n\n523\n00:28:20.390 --> 00:28:22.880\nAnd then, And finally,\nthe disposal of the keys.\n\n524\n00:28:22.880 --> 00:28:26.910\nThe disposal of the keys could be just\na certificate replication list that they\n\n525\n00:28:26.910 --> 00:28:29.580\nturn on, it could be just disabling them.\n\n526\n00:28:29.580 --> 00:28:31.520\nKeep in mind,\nonce you revoke a certificate,\n\n527\n00:28:31.520 --> 00:28:35.350\nthat's essentially what you're doing,\nit can't be used anymore.\n\n528\n00:28:35.350 --> 00:28:39.170\nAnd that is, basically,\nsome of the basics and\n\n529\n00:28:39.170 --> 00:28:44.510\nthe commonalities when it comes to\nproper certificate and key management.\n\n530\n00:28:44.510 --> 00:28:47.950\nYes, so we will take a look at that\nlike you said, if we haven't already but\n\n531\n00:28:47.950 --> 00:28:51.780\nat least you have a good idea of some of\nthese different types of vulnerabilities\n\n532\n00:28:51.780 --> 00:28:54.610\ncan impact an organization, so\nthank you for sharing that with us Wes,\n\n533\n00:28:54.610 --> 00:28:56.940\nand thank you for\njoining us ladies and gentleman, For\n\n534\n00:28:56.940 --> 00:28:59.750\nthis show we're gonna go ahead and\nsign out, remember I'm your host,\n\n535\n00:28:59.750 --> 00:29:01.155\nCherokee Boose-\n&gt;&gt; And I'm Wes Bryan.\n\n536\n00:29:01.155 --> 00:29:04.347\n&gt;&gt; See you next time here at ITProTV.\n\n537\n00:29:04.347 --> 00:29:10.349\n[MUSIC]\n\n538\n00:29:10.349 --> 00:29:16.980\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "213512998"
        }
      ],
      "title": "Threats, Attacks and Vulnerabilities"
    },
    {
      "episodes": [
        {
          "description": "In this show, Cherokee and Wes begin a discussion focused on understanding how both hardware and software impact an organizations security. They begin examining different firewalls and the importance of their configurations. They continue to cover many topics such as VPN Concentrators, Network Intrusion/Prevention Systems, and routers.",
          "length": "1646",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-1-hardware_software_organizational_sec-040717-PGM.00_27_40_18.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-1-hardware_software_organizational_sec-040717-PGM.00_27_40_18.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-1-hardware_software_organizational_sec-040717-PGM.00_27_40_18.Still001-sm.jpg",
          "title": "Hardware Software Organizational Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:03.221\nWelcome to ITProTV,\nI'm your host Don Pizet.\n\n2\n00:00:03.221 --> 00:00:05.901\n[CROSSTALK]\n\n3\n00:00:05.901 --> 00:00:08.412\n[MUSIC]\n\n4\n00:00:08.412 --> 00:00:12.202\nYou're watching ITProTV.\n\n5\n00:00:12.202 --> 00:00:14.830\nWelcome to your CompTIA Security+ series.\n\n6\n00:00:14.830 --> 00:00:16.810\nI'm your show host, Cherokee Boose.\n\n7\n00:00:16.810 --> 00:00:19.380\nIn this episode,\nwe'll be looking at how hardware and\n\n8\n00:00:19.380 --> 00:00:22.820\nsoftware both effect your\norganizational security.\n\n9\n00:00:22.820 --> 00:00:25.257\nWith us today in studios,\nwe have Mr. Wes Bryan.\n\n10\n00:00:25.257 --> 00:00:26.459\nThank you for joining us today, Wes.\n\n11\n00:00:26.459 --> 00:00:28.070\nHey, thanks Cherokee for having me back.\n\n12\n00:00:28.070 --> 00:00:29.990\nYep, we have a great episode for\nyou today.\n\n13\n00:00:29.990 --> 00:00:31.890\nWe've got a lot of different components,\n\n14\n00:00:31.890 --> 00:00:35.040\nhardware and software-based,\nthat support organizational security.\n\n15\n00:00:35.040 --> 00:00:39.267\nSo, guys, we hope you are in for\na great episode today.\n\n16\n00:00:39.267 --> 00:00:43.468\nSo we're gonna go ahead and we'll start\nwith one of the most common things\n\n17\n00:00:43.468 --> 00:00:46.786\nthat we implement today when\nit comes to securing, well,\n\n18\n00:00:46.786 --> 00:00:50.190\norganizations, home networks,\nand that's firewalls.\n\n19\n00:00:50.190 --> 00:00:52.940\nAnd they call out a couple of different\nthings when it comes to firewalls.\n\n20\n00:00:52.940 --> 00:00:55.400\nOne of the first things\nthey talk about are ACLs.\n\n21\n00:00:55.400 --> 00:00:59.460\nSo let's go ahead just very\nbasically define what a firewall is.\n\n22\n00:00:59.460 --> 00:01:01.840\nYou have a couple of different kinds,\nright.\n\n23\n00:01:01.840 --> 00:01:04.500\nYou have what are known as\nsoftware-based firewalls and\n\n24\n00:01:04.500 --> 00:01:06.780\nyou have what are known as\nhardware-based firewalls.\n\n25\n00:01:06.780 --> 00:01:10.910\nAnd these names can actually, you can\nhear a couple other names too, right.\n\n26\n00:01:10.910 --> 00:01:14.836\nSo a software-based firewall is what you\nwould consider a host-based firewall, but\n\n27\n00:01:14.836 --> 00:01:17.070\nlet me show you an example of that one.\n\n28\n00:01:17.070 --> 00:01:22.490\nI got a Windows 10 machine here and if we\njump down into the Windows 10 machine and\n\n29\n00:01:22.490 --> 00:01:25.670\nlaunch up the Windows firewall\nwith advanced security,\n\n30\n00:01:25.670 --> 00:01:28.840\nthis would be an example of\na software-based firewall.\n\n31\n00:01:28.840 --> 00:01:30.790\nNow what do I mean when I\nsay software-based firewall?\n\n32\n00:01:30.790 --> 00:01:34.650\nWell, this isn't an external device that\nhas a dedicated functionality, right?\n\n33\n00:01:34.650 --> 00:01:39.320\nIt's an added functionality already\nin the operating system, right?\n\n34\n00:01:39.320 --> 00:01:41.499\nNow what's the host-based\nfirewall side of this?\n\n35\n00:01:41.499 --> 00:01:46.378\nWell, the host-based firewall, that side\nof this means that it is only protecting\n\n36\n00:01:46.378 --> 00:01:48.440\ntraffic that's going outbound and\n\n37\n00:01:48.440 --> 00:01:52.490\ninbound to the network adapter\non this specific machine.\n\n38\n00:01:52.490 --> 00:01:54.170\nNow you have other types of firewalls too,\nand\n\n39\n00:01:54.170 --> 00:01:57.270\nthis is where the hardware-based\nfirewall comes into play.\n\n40\n00:01:57.270 --> 00:01:59.860\nNow this is a dedicated device, and\nit gets a little bit tricky too.\n\n41\n00:01:59.860 --> 00:02:03.010\nBecause if you look at it, any piece of\nhardware that you have today has STEP\n\n42\n00:02:03.010 --> 00:02:05.220\nsoftware on it in order to use it.\n\n43\n00:02:05.220 --> 00:02:09.422\nBut when they say hardware-based,\nthey usually mean a dedicated device, and\n\n44\n00:02:09.422 --> 00:02:11.929\nwhat it does is,\nit screens traffic going in and\n\n45\n00:02:11.929 --> 00:02:15.270\nout of your network to all devices\nwithin you network, right?\n\n46\n00:02:15.270 --> 00:02:17.834\nSo it's usually more expensive, right,\n\n47\n00:02:17.834 --> 00:02:22.822\nit is a device that it's dedicated to the\nfunctionality of protecting incoming and\n\n48\n00:02:22.822 --> 00:02:26.184\noutgoing traffic to every\ndevice within your network.\n\n49\n00:02:26.184 --> 00:02:29.740\nNow, when they don't mention things like\nACLs, that's an access control list.\n\n50\n00:02:29.740 --> 00:02:33.398\nAnd it doesn't matter if it's on\na firewall, if it's on a router, or\n\n51\n00:02:33.398 --> 00:02:37.056\nif it's on a switch, or even very\nbasically if it's an ACL on an object\n\n52\n00:02:37.056 --> 00:02:39.242\nwithin the operating system like a file.\n\n53\n00:02:39.242 --> 00:02:40.040\nWhat does it do?\n\n54\n00:02:40.040 --> 00:02:41.260\nWell, it governs access.\n\n55\n00:02:41.260 --> 00:02:46.290\nIt governs the access of what\ncan either access this object or\n\n56\n00:02:46.290 --> 00:02:49.290\nin this case can come in or\nout of your network.\n\n57\n00:02:49.290 --> 00:02:50.250\nIn fact, we've got a lot\n\n58\n00:02:50.250 --> 00:02:53.050\nthem built-in right here into\nthe software-based firewall.\n\n59\n00:02:53.050 --> 00:02:56.840\nIf I look over here under Windows Firewall\nwith Advanced Security, and\n\n60\n00:02:56.840 --> 00:03:01.110\nI choose inbound rules,\nthis is essentially an ACL.\n\n61\n00:03:01.110 --> 00:03:03.730\nConsider it something know as\nrule-based access control, right?\n\n62\n00:03:03.730 --> 00:03:10.130\nI have a rule that says, everything\ninbound by default is blocked, everything.\n\n63\n00:03:10.130 --> 00:03:13.800\nBut outbound, the rule says\neverything is allowed, right?\n\n64\n00:03:13.800 --> 00:03:17.597\nSo that is the general default\nnature of a firewall, right?\n\n65\n00:03:17.597 --> 00:03:19.260\nAnd that's what's known as implicit deny.\n\n66\n00:03:19.260 --> 00:03:23.360\nImplicit deny says,\nif I don't expressly or explicitly\n\n67\n00:03:23.360 --> 00:03:27.010\nallow you to perform this functionality,\nyou're gonna be denied, right?\n\n68\n00:03:27.010 --> 00:03:31.775\nImplicit deny says, we deny everything\nthat isn't on the list, right?\n\n69\n00:03:31.775 --> 00:03:37.370\nAn explicit deny is where I do something\nlike this, where I create a new rule.\n\n70\n00:03:37.370 --> 00:03:40.460\nAll right, and man,\nmaybe we do a port here, right.\n\n71\n00:03:40.460 --> 00:03:46.100\nAnd I say, TCP, let's say,\na specific port.\n\n72\n00:03:46.100 --> 00:03:49.410\nAnd I say port 80, right, and\nI create this rule, right.\n\n73\n00:03:49.410 --> 00:03:51.820\nThat's not an implicit deny anymore,\nright.\n\n74\n00:03:51.820 --> 00:03:54.270\nThat's an explicit deny\ncuz I\"m saying port 80,\n\n75\n00:03:54.270 --> 00:03:57.430\nyou can't come inbound\nthrough the firewall.\n\n76\n00:03:57.430 --> 00:04:02.380\nNow if I just leave it and\nI say I'm not gonna put any rules in here.\n\n77\n00:04:02.380 --> 00:04:07.062\nAnd if it's not in this rule list, nothing\ncomes in, that's your implicit deny.\n\n78\n00:04:07.062 --> 00:04:09.700\nThere are other types of firewalls\nthat they talk about as well.\n\n79\n00:04:09.700 --> 00:04:12.210\nThey talk about\napplication-based firewalls.\n\n80\n00:04:12.210 --> 00:04:17.830\nSee, the earlier generation firewalls\nwould primarily operate around layer two,\n\n81\n00:04:17.830 --> 00:04:19.657\nlayer three, if you will.\n\n82\n00:04:19.657 --> 00:04:22.850\nBut then, as we got the next generation,\nI believe they're fourth-generation\n\n83\n00:04:22.850 --> 00:04:25.910\nfirewalls, you might hear them\ncalled next-generation firewalls.\n\n84\n00:04:25.910 --> 00:04:29.030\nThese aren't only network-based,\noperating at things like, for instance,\n\n85\n00:04:29.030 --> 00:04:30.550\nlayer three of the OSI model.\n\n86\n00:04:30.550 --> 00:04:34.010\nThey can operate at level four,\nall the way up to the application layer.\n\n87\n00:04:34.010 --> 00:04:37.450\nWhich means, that they can do things\nlike staple packet inspection.\n\n88\n00:04:37.450 --> 00:04:40.140\nThey're aware of the connections\nthat TCP has established.\n\n89\n00:04:40.140 --> 00:04:43.580\nAnd they're also aware of whether\na connection is trying to be made\n\n90\n00:04:43.580 --> 00:04:46.620\nthat is doing things like Simplot attacks,\nright?\n\n91\n00:04:46.620 --> 00:04:49.630\nThey can see the state\nof the connection and\n\n92\n00:04:49.630 --> 00:04:52.520\nif communications come in\nthat are trying to spoof\n\n93\n00:04:52.520 --> 00:04:56.180\nthat already established connection,\nthe firewall can block it, right?\n\n94\n00:04:56.180 --> 00:04:59.290\nBut they also go a little bit farther\nthan that where they can open up and\n\n95\n00:04:59.290 --> 00:05:01.670\nthey can kinda like peel\nback the onion layers.\n\n96\n00:05:01.670 --> 00:05:03.000\nAnd they can look at ports.\n\n97\n00:05:03.000 --> 00:05:05.340\nThey can say, you know what,\nthat's HTTP traffic.\n\n98\n00:05:05.340 --> 00:05:08.234\nI don't care what port you had,\nyeah, port 8080.\n\n99\n00:05:08.234 --> 00:05:09.510\nI don't care what the port is.\n\n100\n00:05:09.510 --> 00:05:13.720\nI can see that it's an application\nlayer protocol and it can allow or\n\n101\n00:05:13.720 --> 00:05:15.450\ndeny it based on your rules.\n\n102\n00:05:15.450 --> 00:05:18.840\nNow, Wes, when we're able to take these\ndifferent types of firewalls, and kind of\n\n103\n00:05:18.840 --> 00:05:22.020\nlike that onion you just mentioned, and\nkind of stack them on top of each other.\n\n104\n00:05:22.020 --> 00:05:25.920\nMaybe we have a database, that need this\nspecific application-based type firewall.\n\n105\n00:05:25.920 --> 00:05:30.220\nThen we have our clients, our end users,\nusing their host-based firewalls.\n\n106\n00:05:30.220 --> 00:05:35.001\nAnd then the perimeter or network-based\nfirewall, it's not gonna be conflicting,\n\n107\n00:05:35.001 --> 00:05:38.550\nwe're really just adding those\nextra layers of security here.\n\n108\n00:05:38.550 --> 00:05:41.317\nMost definitely, in fact your\nnetwork-based firewalls are where we can\n\n109\n00:05:41.317 --> 00:05:42.754\nimplement things like DMZs, right?\n\n110\n00:05:42.754 --> 00:05:45.015\nThis host-based firewall that I have here,\n\n111\n00:05:45.015 --> 00:05:48.120\nit's only acting on the network\nadapter within the machine.\n\n112\n00:05:48.120 --> 00:05:51.630\nSo, I'm not gonna be able to set up a DMZ\nthat protects a screened subnet that\n\n113\n00:05:51.630 --> 00:05:56.680\nprotects internal resources, but\nallows a certain bit of external access.\n\n114\n00:05:56.680 --> 00:05:59.487\nFor instance, to a website where\nwe're doing things like e-commerce.\n\n115\n00:05:59.487 --> 00:06:03.422\nSo, keep that in mind that network-based\nfirewalls typically are gonna\n\n116\n00:06:03.422 --> 00:06:05.140\nhave a lot more functionality.\n\n117\n00:06:05.140 --> 00:06:07.540\nUnless it's something,\nsome third-party software,\n\n118\n00:06:07.540 --> 00:06:09.990\ndon't get me wrong,\nyou can have a lot of functionality.\n\n119\n00:06:09.990 --> 00:06:13.526\nFor instance, IP tables inside of Linux,\nthere's a lot of stuff you can do.\n\n120\n00:06:13.526 --> 00:06:16.320\nPF census, something that you\ncan run in a virtual machine.\n\n121\n00:06:16.320 --> 00:06:18.450\nSo there is a lot of\nflexibility out there.\n\n122\n00:06:18.450 --> 00:06:22.070\nBut, also keep in mind that,\nwhen you look at network-based firewalls\n\n123\n00:06:22.070 --> 00:06:25.560\nthe price can skyrocket very,\nvery quick for these devices.\n\n124\n00:06:26.920 --> 00:06:31.020\nAll right, so the other thing that they\ncall out are VPN concentrators, all right,\n\n125\n00:06:31.020 --> 00:06:32.240\nand- Are those still a thing?\n\n126\n00:06:32.240 --> 00:06:33.163\nThey are still a thing.\n\n127\n00:06:33.163 --> 00:06:37.676\nNow here's something interesting because\nthe VPN concentrators used to be dedicated\n\n128\n00:06:37.676 --> 00:06:38.240\ndevices.\n\n129\n00:06:38.240 --> 00:06:40.270\nI know, for instance,\nCisco still has them out.\n\n130\n00:06:40.270 --> 00:06:44.260\nThey don't really, I believe, they sell\nthem anymore, but they still support them.\n\n131\n00:06:44.260 --> 00:06:47.730\nAnd VPN concentrator,\nwhat is it actually doing for us?\n\n132\n00:06:47.730 --> 00:06:50.490\nWell, when we talk about\nthings like tunnelings, VPNs,\n\n133\n00:06:50.490 --> 00:06:53.650\nVirtual Private Networks, keep in mind\nthat what we do is we use a series of\n\n134\n00:06:53.650 --> 00:06:56.390\ntunneling protocols that\nestablish this virtual\n\n135\n00:06:56.390 --> 00:07:01.030\npoint to point connection between two\nendpoints, or between two LANs, right?\n\n136\n00:07:01.030 --> 00:07:05.040\nWell, that tunneling process and\ncoupled with encryption\n\n137\n00:07:05.040 --> 00:07:08.740\nit take some computational power for\njust one connection.\n\n138\n00:07:08.740 --> 00:07:12.150\nIf you are an organization that\nneeds hundreds of those connections,\n\n139\n00:07:12.150 --> 00:07:16.650\nthen what you can see is a bandwidth\nperformance degradation very very quickly.\n\n140\n00:07:16.650 --> 00:07:19.500\nJust due to the fact that\nthere has to be encapsulation,\n\n141\n00:07:19.500 --> 00:07:22.490\nencryption, decapsulation, decryption.\n\n142\n00:07:22.490 --> 00:07:25.610\nSo a VPN concentrator\nis a dedicated device,\n\n143\n00:07:25.610 --> 00:07:29.840\nif you will, dedicated functionality\nmore appropriately today\n\n144\n00:07:29.840 --> 00:07:34.912\nthat allows you to scale up to\nlarger simultaneous VPN connections.\n\n145\n00:07:34.912 --> 00:07:37.750\nNow what do I mean is\na logical service today, and\n\n146\n00:07:37.750 --> 00:07:39.790\nthat's because you have\nmulti-functioning devices.\n\n147\n00:07:39.790 --> 00:07:42.601\nFor instance, the Cisco ASA,\nthe Adapted Security Appliance.\n\n148\n00:07:42.601 --> 00:07:46.350\nIt's one of those ones that has VPN\nconcentrator functionality built-in.\n\n149\n00:07:46.350 --> 00:07:49.430\nYou are seeing today that VPN\nconcentrators that they are there\n\n150\n00:07:49.430 --> 00:07:50.210\nfor sure.\n\n151\n00:07:50.210 --> 00:07:52.387\nBut a lot of types,\nyou're gonna see, Cherokee,\n\n152\n00:07:52.387 --> 00:07:56.047\nwhere next generation firewalls and stuff\nhave that functionality built into them.\n\n153\n00:07:56.047 --> 00:07:59.127\nYou might even hear that term connection\nbroker in a Windows environment.\n\n154\n00:07:59.127 --> 00:08:01.509\nI was just reading some\ndocumentation yesterday.\n\n155\n00:08:01.509 --> 00:08:04.846\nThat they can support up to 10,000\nsimultaneous connections, so\n\n156\n00:08:04.846 --> 00:08:06.057\nthat's pretty cool too.\n\n157\n00:08:06.057 --> 00:08:08.956\nYeah, that's very,\nvery expensive I'm sure too.\n\n158\n00:08:08.956 --> 00:08:10.700\nWhen you talk about scaling up like that.\n\n159\n00:08:10.700 --> 00:08:16.060\nAnytime we talk about corporate based\ntechnology, it's usually very pricey too.\n\n160\n00:08:16.060 --> 00:08:19.700\nBut and you can definitely see\nthat inside of your companies.\n\n161\n00:08:19.700 --> 00:08:25.480\nNow, they call out other things too,\nlike for instance remote VPN access,\n\n162\n00:08:25.480 --> 00:08:28.160\nif you will, remote access VPN,\nsaid it a little backwards.\n\n163\n00:08:28.160 --> 00:08:29.254\nAnd they also call out site to site.\n\n164\n00:08:29.254 --> 00:08:32.950\nThey also call out things like\nsplit tunnel versus full tunnel.\n\n165\n00:08:32.950 --> 00:08:35.190\nSo let's go ahead, and\nI've got a little diagram here, and\n\n166\n00:08:35.190 --> 00:08:36.930\nlet's kinda break down each one of these.\n\n167\n00:08:36.930 --> 00:08:39.900\nI've actually put each one of\nthese in this diagram here.\n\n168\n00:08:39.900 --> 00:08:45.670\nBut let's go ahead and we'll tackle remote\naccess and site to site VPNs first.\n\n169\n00:08:45.670 --> 00:08:48.490\nIf you need one person, right,\nso we've got this young lady and\n\n170\n00:08:48.490 --> 00:08:50.650\nmaybe she works at home, right?\n\n171\n00:08:50.650 --> 00:08:53.030\nAnd she needs access into\nthe corporate network.\n\n172\n00:08:53.030 --> 00:08:57.600\nWell, a remote access VPN is\ntypically a single endpoint that uses\n\n173\n00:08:57.600 --> 00:09:03.060\nthe client side software, a client side\nagent to connect tunneling, if you will.\n\n174\n00:09:03.060 --> 00:09:06.990\nAnd keep in mind, this is, guys, it\nkind got these, like, dotted lines here.\n\n175\n00:09:06.990 --> 00:09:09.770\nIt is going through the Internet, right,\nbut we don't want this to look like\n\n176\n00:09:09.770 --> 00:09:12.160\na John Madden play by play, so\nwe're just doing it logically.\n\n177\n00:09:12.160 --> 00:09:15.120\nAnd what it's doing,\nis it's establishing the VPN communication\n\n178\n00:09:15.120 --> 00:09:19.390\nfrom the client software on her\ncomputer and a gateway type router.\n\n179\n00:09:19.390 --> 00:09:24.280\nAnd this gives her that protected\nvirtual private network communication\n\n180\n00:09:24.280 --> 00:09:28.300\ninto the resources inside of\nthe LAN over a public network.\n\n181\n00:09:29.870 --> 00:09:31.960\nThe other one that they call out is\nwhat's known as a site-to-site VPN.\n\n182\n00:09:31.960 --> 00:09:33.766\nSite-to-site VPNs are little\nbit different and\n\n183\n00:09:33.766 --> 00:09:36.305\nthis is what you commonly find in\nyour corporate businesses, right?\n\n184\n00:09:36.305 --> 00:09:39.679\nThis is when you might hear\nthem called other things too,\n\n185\n00:09:39.679 --> 00:09:42.020\nlike gateway-to-gateway VPNs too.\n\n186\n00:09:42.020 --> 00:09:43.922\nSo don't let that term confuse you.\n\n187\n00:09:43.922 --> 00:09:45.799\nSite-to-site, gateway-to-gateway.\n\n188\n00:09:45.799 --> 00:09:49.100\nWhat do they mean when they\nsay gateway-to-gateway?\n\n189\n00:09:49.100 --> 00:09:50.190\nRouter to router.\n\n190\n00:09:50.190 --> 00:09:53.570\nIt typically connects two LANs together,\nright?\n\n191\n00:09:53.570 --> 00:09:58.060\nAnd it allows you this private\nencrypted communication across\n\n192\n00:09:58.060 --> 00:10:03.068\nthe public network between,\nlike in this example, LAN 1 and LAN 2.\n\n193\n00:10:03.068 --> 00:10:05.235\nNow, here's something that can happen.\n\n194\n00:10:05.235 --> 00:10:10.295\nThis would be an example, if all traffic\nwas going from gateway to gateway.\n\n195\n00:10:10.295 --> 00:10:13.729\nAll traffic, didn't matter if it's\nInternet traffic, or if it's traffic that\n\n196\n00:10:13.729 --> 00:10:17.120\nis really bound for maybe one of\nthe servers here inside of the LAN.\n\n197\n00:10:17.120 --> 00:10:18.700\nThat's called a full tunnel, all right?\n\n198\n00:10:18.700 --> 00:10:20.410\nAnd when we talk about full tunnels,\nagain,\n\n199\n00:10:20.410 --> 00:10:24.360\nkeep in mind that all of the traffic\ngoes through the corporate network,\n\n200\n00:10:24.360 --> 00:10:27.390\nincluding traffic that isn't bound for\n\n201\n00:10:27.390 --> 00:10:31.370\nthe internal corporate network, the\ntraffic that is bound for the Internet.\n\n202\n00:10:31.370 --> 00:10:35.680\nSo imagine this, that if you're in LAN 1,\nyou've got a VPN tunnel.\n\n203\n00:10:35.680 --> 00:10:39.570\nYou send corporate traffic over the VPN\ntunnel, but then you turn around and\n\n204\n00:10:39.570 --> 00:10:40.800\nyou browse the Internet.\n\n205\n00:10:40.800 --> 00:10:44.320\nWell, that information's going\nthrough the same tunnel.\n\n206\n00:10:44.320 --> 00:10:46.810\nThe problem here is,\nthat becomes a performance degradation.\n\n207\n00:10:46.810 --> 00:10:50.725\nTransmitting all of that traffic,\nall right, whether it's bound for\n\n208\n00:10:50.725 --> 00:10:54.917\nthe corporate network or if it's bound for\nthe external networks, right?\n\n209\n00:10:54.917 --> 00:10:58.842\nIt could be bandwidth consuming,\nand it can cause bandwidth,\n\n210\n00:10:58.842 --> 00:11:02.225\nbasically the performance slows down.\n\n211\n00:11:02.225 --> 00:11:05.685\nSo that's why you can implement something\nknown as a split tunnel, all right?\n\n212\n00:11:05.685 --> 00:11:08.235\nNotice that the split tunnel's\na little bit different.\n\n213\n00:11:08.235 --> 00:11:12.995\nA split tunnel says, any traffic\nthat's not specifically bound for\n\n214\n00:11:12.995 --> 00:11:16.270\nthe corporate network is\ngonna go to the Internet.\n\n215\n00:11:16.270 --> 00:11:20.687\nHowever, if I have to access a resource\nthat's on the corporate network,\n\n216\n00:11:20.687 --> 00:11:24.136\nwe're gonna send that\ninformation that way, all right?\n\n217\n00:11:24.136 --> 00:11:28.939\nSo keep in mind, split tunnel can increase\nthe performance of the communication,\n\n218\n00:11:28.939 --> 00:11:32.713\nbecause it says just send the corporate\ntraffic over the tunneled\n\n219\n00:11:32.713 --> 00:11:34.376\nencrypted communication.\n\n220\n00:11:34.376 --> 00:11:39.219\nBut anything that's bound for the public\nnetwork, which is typically the Internet,\n\n221\n00:11:39.219 --> 00:11:40.820\nsend that traffic that way.\n\n222\n00:11:40.820 --> 00:11:43.797\nWe don't wanna have to burden\nour gateway routers, right?\n\n223\n00:11:43.797 --> 00:11:47.933\nWith encapsulation,\ndecapsulation, encryption and\n\n224\n00:11:47.933 --> 00:11:53.480\ndecryption of information that\ndoesn't need confidentiality, right?\n\n225\n00:11:53.480 --> 00:11:58.020\nSo that can end up increasing\nthe performance of the overall VPN tunnel.\n\n226\n00:11:58.020 --> 00:12:01.005\nAll right, you can, basically,\nyou can help accelerate the communication.\n\n227\n00:12:01.005 --> 00:12:04.330\nNow, you typically do this with\nthings like certificate base.\n\n228\n00:12:04.330 --> 00:12:07.330\nThey talk about Transport Layer Security,\nTLS, right?\n\n229\n00:12:07.330 --> 00:12:11.660\nTransport Layer Security really\nis the successor to SSL and\n\n230\n00:12:11.660 --> 00:12:17.050\nTransport Layer Security 1.0,\nand SSL 3.0 were a lot a like.\n\n231\n00:12:17.050 --> 00:12:19.900\nBut there was just enough differences\nbetween the two that they're not\n\n232\n00:12:19.900 --> 00:12:21.570\ncompatible with each other.\n\n233\n00:12:21.570 --> 00:12:24.280\nTransport Layer Security is where\nyou can do certificate-based\n\n234\n00:12:24.280 --> 00:12:26.300\nauthentication, right?\n\n235\n00:12:26.300 --> 00:12:29.389\nAnd it also adds a higher\nlevel of encryption.\n\n236\n00:12:29.389 --> 00:12:32.709\nOne of the big differences between TLS and\nSSL,\n\n237\n00:12:32.709 --> 00:12:37.550\nis TLS doesn't allow for\na negotiation of a weaker cipher strength.\n\n238\n00:12:37.550 --> 00:12:41.195\nIn the days when we were using SSL,\nif a browser said,\n\n239\n00:12:41.195 --> 00:12:45.166\nhey I don't support SSL 3.0,\nbut I do support 2.0.\n\n240\n00:12:45.166 --> 00:12:48.432\nWell that negotiation,\nit could be negotiated, and\n\n241\n00:12:48.432 --> 00:12:51.350\nyou could downgrade to\na lower cipher suite.\n\n242\n00:12:51.350 --> 00:12:55.640\nAnd any time we do a downgrade to a lower\ncipher strength, I guess should say.\n\n243\n00:12:55.640 --> 00:12:58.550\nWe have a potential for vulnerability.\n\n244\n00:12:58.550 --> 00:13:01.210\nThe other thing they have with VPNs\nthat they call out is something known as\n\n245\n00:13:01.210 --> 00:13:03.480\nan always on VPN, all right?\n\n246\n00:13:03.480 --> 00:13:08.267\nAlways on VPNs help to eliminate some of\nthe complexities of setting up a VLAN,\n\n247\n00:13:08.267 --> 00:13:13.010\nexcuse me on VPN for\nyour customers, right?\n\n248\n00:13:13.010 --> 00:13:16.490\nWe have things like connection profiles\nthat we can kind of automate this.\n\n249\n00:13:16.490 --> 00:13:20.604\nI know in windows server they have CMAK,\nConnection Manager Administration Kit,\n\n250\n00:13:20.604 --> 00:13:24.189\nthat allows you to basically create\nthese executables that you could put\n\n251\n00:13:24.189 --> 00:13:25.440\non the user's desktop.\n\n252\n00:13:25.440 --> 00:13:28.620\nAnd they click on it and\nit sets up the VPN for them, but\n\n253\n00:13:28.620 --> 00:13:31.400\nit's not completely automated, all right?\n\n254\n00:13:31.400 --> 00:13:33.134\nAnd troubleshooting it\ncan be a nightmare too,\n\n255\n00:13:33.134 --> 00:13:34.878\nespecially if you've got\na remote access VPN.\n\n256\n00:13:34.878 --> 00:13:38.990\nYou've got some poor user that's on the\nother side, that knows nothing about them.\n\n257\n00:13:38.990 --> 00:13:41.055\nSo matching it,\nI'm gonna use a technology that the VPN,\n\n258\n00:13:41.055 --> 00:13:43.665\nyou're always connected to\nthe corporate network, right?\n\n259\n00:13:43.665 --> 00:13:45.875\nIt makes it a lot,\nseamless communications.\n\n260\n00:13:45.875 --> 00:13:50.575\nAnd again, transparent to the end user and\nit alleviates the burden, right?\n\n261\n00:13:50.575 --> 00:13:52.665\nOn the user and\nreally on the administrator.\n\n262\n00:13:52.665 --> 00:13:53.945\nSome examples of that technology,\n\n263\n00:13:53.945 --> 00:13:56.525\nthe first one that comes\nto mind is direct access.\n\n264\n00:13:56.525 --> 00:14:01.085\nDirect access inside of Windows Server\nis an always on type VPN communication.\n\n265\n00:14:01.085 --> 00:14:04.910\nIt means when I need to communicate\nwith the corporate resource,\n\n266\n00:14:04.910 --> 00:14:06.110\nthe VPN's triggered.\n\n267\n00:14:06.110 --> 00:14:09.320\nBut when I need to communicate with\nthe Internet, I'm not going over the VPN.\n\n268\n00:14:09.320 --> 00:14:12.455\nAnd I don't have to worry about\nI need to dial into the VPN,\n\n269\n00:14:12.455 --> 00:14:16.096\nlet me push this executable,\nbring up the VPN, wait for it to connec.\n\n270\n00:14:16.096 --> 00:14:19.740\nAnd then it connects, hopefully [LAUGH],\nright, if we've got it configured right.\n\n271\n00:14:19.740 --> 00:14:23.219\nRight, and it's also a pretty cool feature\nbecause you're able to really restrict\n\n272\n00:14:23.219 --> 00:14:26.211\naccess based on if you are utilizing\nthat Internet-based connection.\n\n273\n00:14:26.211 --> 00:14:29.831\nOr if you're accessing the VPN and\nwhere you are located and\n\n274\n00:14:29.831 --> 00:14:34.310\njust kind of helps with that concept\nof utilizing access control.\n\n275\n00:14:34.310 --> 00:14:37.590\nDefinitely, so some of the other\nthings that they call out.\n\n276\n00:14:37.590 --> 00:14:41.910\nThey call out things like, for\ninstance, and I love these acronyms,\n\n277\n00:14:41.910 --> 00:14:42.814\nNIPS and NIDS, right?\n\n278\n00:14:42.814 --> 00:14:47.207\n[LAUGH] All right, we call out something\nknown as network- [CROSSTALK] Yes,\n\n279\n00:14:47.207 --> 00:14:47.990\nexactly.\n\n280\n00:14:47.990 --> 00:14:51.800\nWe call out things, for instance,\nNetwork Intrusion Prevention Systems, and\n\n281\n00:14:51.800 --> 00:14:54.250\nNetwork Intrusion Detection Systems.\n\n282\n00:14:54.250 --> 00:14:55.580\nWhat is the difference, right?\n\n283\n00:14:55.580 --> 00:14:57.860\nWell, they have some commonalities.\n\n284\n00:14:57.860 --> 00:15:00.860\nAnd a lot of times,\nthe terms are used interchangeably today.\n\n285\n00:15:00.860 --> 00:15:04.394\nBut let's kinda see if we can\nkinda differentiate, right?\n\n286\n00:15:04.394 --> 00:15:07.160\nNDS, or an NIDS.\n\n287\n00:15:07.160 --> 00:15:10.230\nA network-based intrusion\ndetection system.\n\n288\n00:15:10.230 --> 00:15:14.542\nThis is a passive system that sits on your\nnetwork, and can be connected to a port on\n\n289\n00:15:14.542 --> 00:15:18.427\na switch, monitoring traffic across\nyour network, but it's passive.\n\n290\n00:15:18.427 --> 00:15:23.228\nOr an IPS a network based\nintrusion prevention system is\n\n291\n00:15:23.228 --> 00:15:25.380\nan inline device right.\n\n292\n00:15:25.380 --> 00:15:29.045\nIt could be a functionality like we're\ntalking about the integration of\n\n293\n00:15:29.045 --> 00:15:32.030\nVPN concentrators into like a firewall.\n\n294\n00:15:32.030 --> 00:15:36.890\nWell your firewall can also be a network\nbased firewall can also be an IPS.\n\n295\n00:15:36.890 --> 00:15:40.880\nAnd remember what's going on\nwith a network based firewall.\n\n296\n00:15:40.880 --> 00:15:43.960\nIt's screening all traffic\nthat's coming into the network,\n\n297\n00:15:43.960 --> 00:15:47.460\nnot passively just one device sitting on\nyour network listening out saying, hey,\n\n298\n00:15:47.460 --> 00:15:49.550\nis there an intrusion happening?\n\n299\n00:15:49.550 --> 00:15:53.080\nNo, this is screening all traffic\ncoming into your network and\n\n300\n00:15:53.080 --> 00:15:56.210\ngoing out of your network for\nsigns of an intrusion.\n\n301\n00:15:56.210 --> 00:15:57.908\nNow, that's one of\nthe distinctions between the two.\n\n302\n00:15:57.908 --> 00:16:02.263\nThe other distinction is,\nagain an IDS is passive, right?\n\n303\n00:16:02.263 --> 00:16:05.858\nIt monitors It detects,\nif you will, and it alerts.\n\n304\n00:16:05.858 --> 00:16:07.553\nWell, what's the difference?\n\n305\n00:16:07.553 --> 00:16:11.633\nBecause guess what, the IPS, the intrusion\nprevention system does the same thing.\n\n306\n00:16:11.633 --> 00:16:15.930\nIt monitors, it detects, and it alerts.\n\n307\n00:16:15.930 --> 00:16:17.370\nSo what are the differences?\n\n308\n00:16:17.370 --> 00:16:19.910\nThe IPS also implements countermeasures.\n\n309\n00:16:19.910 --> 00:16:22.700\nThat's the big difference\nbetween an IDS and an IPS.\n\n310\n00:16:22.700 --> 00:16:23.590\nIDS is passive.\n\n311\n00:16:23.590 --> 00:16:25.400\nIt says, hey, there's something going on.\n\n312\n00:16:25.400 --> 00:16:29.058\nLet me send Cherokee as the systems\nadministrator, gotta send her an email\n\n313\n00:16:29.058 --> 00:16:32.264\nthat says something's going on,\nshe can check the log, right?\n\n314\n00:16:32.264 --> 00:16:34.580\nThe IPS though says let\nme do that same thing.\n\n315\n00:16:34.580 --> 00:16:36.140\nLet me make her aware and\n\n316\n00:16:36.140 --> 00:16:38.825\nwhile she's reading the logs,\nI'm gonna do something to try to stop it,\n\n317\n00:16:38.825 --> 00:16:43.350\nthe countermeasures that actively try\nto shut down whatever the attack is.\n\n318\n00:16:43.350 --> 00:16:45.600\nAnd there are different ones out there,\nright?\n\n319\n00:16:45.600 --> 00:16:48.295\nWe have different ones like in band and\nout of band, right?.\n\n320\n00:16:48.295 --> 00:16:52.135\nIn band means I'm inside of the network,\nI have access to the network.\n\n321\n00:16:52.135 --> 00:16:55.850\nThat device is inside of your network and\ncan actively detect.\n\n322\n00:16:56.910 --> 00:16:59.494\nOut of band is things like for instance,\n\n323\n00:16:59.494 --> 00:17:03.680\nthe servers they have boards in\nthem like the iLo boards, right?\n\n324\n00:17:03.680 --> 00:17:04.280\nThe iDRACs, right?\n\n325\n00:17:04.280 --> 00:17:05.860\nThe remote access controller so\n\n326\n00:17:05.860 --> 00:17:10.040\nthat I can monitor things like\nBIOS when I'm not in the network.\n\n327\n00:17:10.040 --> 00:17:11.730\nThat's what we call\nout-of-band management.\n\n328\n00:17:11.730 --> 00:17:15.480\nSo if we say out-of-band IPS,\nit's one that's not\n\n329\n00:17:15.480 --> 00:17:20.170\ndirectly attached to our network and\nit can detect, monitor, and alert, too.\n\n330\n00:17:20.170 --> 00:17:21.723\nYou also have cloud-based solutions,\nright?\n\n331\n00:17:21.723 --> 00:17:24.953\nThe cloud-based solutions aren't\ninside of your network, right?\n\n332\n00:17:24.953 --> 00:17:28.036\nBut they can do things like actively\nmonitor your network when you're not\n\n333\n00:17:28.036 --> 00:17:29.650\ninside of the network.\n\n334\n00:17:29.650 --> 00:17:31.470\nWe also have things like signature based.\n\n335\n00:17:31.470 --> 00:17:33.070\nWe have things like heuristics based.\n\n336\n00:17:33.070 --> 00:17:37.960\nNow heuristics based is one that can kinda\nimplement a lot of false positives like\n\n337\n00:17:37.960 --> 00:17:41.920\nwe talked about in other episodes and\nreally even in the anomaly base, right?\n\n338\n00:17:43.090 --> 00:17:46.860\nHeuristics based and behavioral based,\nwe have a set of patterns, right?\n\n339\n00:17:46.860 --> 00:17:47.700\nThat we can reference.\n\n340\n00:17:47.700 --> 00:17:50.250\nAnomaly based has to go through\nthings like learning process.\n\n341\n00:17:50.250 --> 00:17:53.739\nAnd any kind of learning process you\nrun the risk of false positives.\n\n342\n00:17:53.739 --> 00:17:55.362\nAnd what does that mean?\n\n343\n00:17:55.362 --> 00:17:57.630\nAll right, well, if you don't know\nthose scan results, go back and\n\n344\n00:17:57.630 --> 00:17:58.530\ncheck out that episode.\n\n345\n00:17:58.530 --> 00:18:00.780\nBut a false positive means that it is\n\n346\n00:18:01.840 --> 00:18:06.140\nincorrectly identified\nsomething as malicious, right?\n\n347\n00:18:06.140 --> 00:18:11.790\nNow, the problem with that is, what if\neverything is marked as a false positive?\n\n348\n00:18:11.790 --> 00:18:13.880\nThat means everything is\nattacking our networks.\n\n349\n00:18:13.880 --> 00:18:15.510\nAnd as they go through\nthe learning process,\n\n350\n00:18:15.510 --> 00:18:19.372\nyou start to reduce the false\npositives because it starts to learn.\n\n351\n00:18:19.372 --> 00:18:21.207\nOkay, I see you got secure FTP.\n\n352\n00:18:21.207 --> 00:18:22.810\nI see you got Kerberos on your network.\n\n353\n00:18:22.810 --> 00:18:26.419\nThese are okay and then we don't\nhave to worry about that next time.\n\n354\n00:18:26.419 --> 00:18:29.917\nExactly Wes, for\nthose different types of analysis engines,\n\n355\n00:18:29.917 --> 00:18:32.228\nyou may have a particular tuning period or\n\n356\n00:18:32.228 --> 00:18:37.220\noptimization period where you're getting\na lot of false positives, false negatives.\n\n357\n00:18:37.220 --> 00:18:40.830\nAnd you just really have to allow\nthat time to really work itself out.\n\n358\n00:18:40.830 --> 00:18:43.630\nIt might be a little extra work at first,\nbut\n\n359\n00:18:43.630 --> 00:18:46.990\neach one of those types of analysis\nengines have a little bit of drawbacks.\n\n360\n00:18:46.990 --> 00:18:50.340\nFor instance, if you look at maybe,\nsignature based,\n\n361\n00:18:50.340 --> 00:18:53.330\nyou have to keep your signatures\nup to date or it's not gonna help.\n\n362\n00:18:53.330 --> 00:18:57.780\nAnd especially for those zero day\nattacks like we had spoke about.\n\n363\n00:18:57.780 --> 00:19:00.480\nIf we're not aware of\nthose types of attacks and\n\n364\n00:19:00.480 --> 00:19:04.440\nwe're looking at a database to compare\nthose signatures, then we're not really\n\n365\n00:19:04.440 --> 00:19:07.710\nable to defend against those types of\nzero day attacks with signature base.\n\n366\n00:19:07.710 --> 00:19:10.234\nMost definitely and\nthey do call out analytics, right?\n\n367\n00:19:10.234 --> 00:19:12.960\nThey do talk about the false positive and\nthe false negative here.\n\n368\n00:19:12.960 --> 00:19:15.603\nSo again, like we had talked about in\nanother episodes, and we'll go ahead and\n\n369\n00:19:15.603 --> 00:19:16.122\nmention here.\n\n370\n00:19:16.122 --> 00:19:19.539\nBut the false negative, that's actually\none that's got a little bit worse,\n\n371\n00:19:19.539 --> 00:19:21.420\nright, than the false positive, right?\n\n372\n00:19:21.420 --> 00:19:24.398\nBecause the false negative says,\nno, it's legit.\n\n373\n00:19:24.398 --> 00:19:28.060\nAnd now you got some kind of malware,\nworm, or trojan on your network, right?\n\n374\n00:19:28.060 --> 00:19:32.270\nAnd according to the IPS or\nthe IDS, it said, no, it's okay.\n\n375\n00:19:32.270 --> 00:19:33.740\nAll right, so\nyou do have to worry about that.\n\n376\n00:19:33.740 --> 00:19:36.160\nFalse positives happen a lot at first.\n\n377\n00:19:36.160 --> 00:19:38.260\nBut as it goes through\nthe learning process, right?\n\n378\n00:19:38.260 --> 00:19:43.245\nIf it's not using like statically defined\nsignatures that it's referencing, right?\n\n379\n00:19:43.245 --> 00:19:46.330\nIt'll go through the process of learning,\nyou get a lot of false positives and\n\n380\n00:19:46.330 --> 00:19:49.150\nover time you should see that\nthose start to diminish.\n\n381\n00:19:50.180 --> 00:19:53.840\nAll right, let's see, the IPS and IDS.\n\n382\n00:19:53.840 --> 00:19:54.390\nRouters.\n\n383\n00:19:54.390 --> 00:19:58.185\nAll right, routers, yes,\nthat's our next big friend.\n\n384\n00:19:58.185 --> 00:19:59.395\nAnd again, routers,\n\n385\n00:19:59.395 --> 00:20:03.484\none of the things that you can do to\nsecure your routers are ACLs, all right.\n\n386\n00:20:03.484 --> 00:20:05.130\nACLs are a big thing.\n\n387\n00:20:05.130 --> 00:20:07.000\nAccess control lists, right?\n\n388\n00:20:07.000 --> 00:20:09.350\nYou also have things like port\nsecurity that we need to worry about.\n\n389\n00:20:09.350 --> 00:20:13.071\nNow you say, well, wait a second, Wes,\nport security, isn't that a switch?\n\n390\n00:20:13.071 --> 00:20:14.690\nWell, not necessarily today, right?\n\n391\n00:20:14.690 --> 00:20:17.210\nBecause we have layer two and\nlayer three switches.\n\n392\n00:20:17.210 --> 00:20:20.610\nRemember layer two switch,\nall switching happens at layer two.\n\n393\n00:20:20.610 --> 00:20:22.940\nDoesn't matter if it's\na layer three switch.\n\n394\n00:20:22.940 --> 00:20:24.640\nSwitching still happens at layer two.\n\n395\n00:20:24.640 --> 00:20:28.740\nBut what it means is that the switch has\nenough logic in it, enough intelligence,\n\n396\n00:20:28.740 --> 00:20:33.050\nif you will,\nto also understand IP and routing.\n\n397\n00:20:33.050 --> 00:20:35.480\nAll happening at layer three.\n\n398\n00:20:35.480 --> 00:20:38.582\nSo, routers, with that in mind, right?\n\n399\n00:20:38.582 --> 00:20:42.550\nRouters can do things like that\ncould be an anti-spoofing switch.\n\n400\n00:20:42.550 --> 00:20:44.950\nNow you say, okay Wes, now you're\nreally throwing a curve ball at me.\n\n401\n00:20:44.950 --> 00:20:45.830\nWhat do you mean?\n\n402\n00:20:45.830 --> 00:20:47.150\nI thought a router isn't a switch.\n\n403\n00:20:47.150 --> 00:20:50.148\nBut remember,\nif we talk about a layer three switch,\n\n404\n00:20:50.148 --> 00:20:52.157\nit is one that can perform routing.\n\n405\n00:20:52.157 --> 00:20:56.657\nSo how would they do anti spoofing\nif we're in-between the layers?\n\n406\n00:20:56.657 --> 00:20:59.921\nWell, you gotta keep in mind that we've\ngot spoofing attacks that happen at layer\n\n407\n00:20:59.921 --> 00:21:02.770\ntwo, and spoofing attacks\nthat happen at layer three.\n\n408\n00:21:02.770 --> 00:21:05.630\nSo how convenient if you\nhave a switch in your\n\n409\n00:21:05.630 --> 00:21:08.530\nserver closet that understands\nboth those layers, right?\n\n410\n00:21:08.530 --> 00:21:09.774\nThen it can communicate, and\n\n411\n00:21:09.774 --> 00:21:12.177\nit can make some logical\ndecisions between both layers.\n\n412\n00:21:12.177 --> 00:21:14.610\nSo for instance, layer three, we use ACLs.\n\n413\n00:21:15.720 --> 00:21:19.230\nACLs are what we prevent\nthings like IP spoofing.\n\n414\n00:21:19.230 --> 00:21:21.909\nWe got an ACL that says anything\nthat comes off the WAN link,\n\n415\n00:21:21.909 --> 00:21:22.881\nif I see one of those.\n\n416\n00:21:22.881 --> 00:21:29.090\nWhat is it, RFC 1918,\nthe private IP addresses, block it.\n\n417\n00:21:29.090 --> 00:21:33.330\nI shouldn't have a private IP address\ncoming in a WAN interface, right?\n\n418\n00:21:33.330 --> 00:21:34.012\nExactly.\n\n419\n00:21:34.012 --> 00:21:35.180\nIt's not routable.\n\n420\n00:21:35.180 --> 00:21:39.049\nThe other thing is if you have public IP\naddresses, maybe a public IP address and\n\n421\n00:21:39.049 --> 00:21:42.740\nyou have a router that's controlling\ncommunications from there.\n\n422\n00:21:42.740 --> 00:21:46.380\nI shouldn't have a private IP\naddress be able to go out to\n\n423\n00:21:46.380 --> 00:21:47.800\na public interface, right?\n\n424\n00:21:47.800 --> 00:21:50.260\nAnd that's one of the things\nwe can control with ACLs.\n\n425\n00:21:51.340 --> 00:21:55.490\nSo, with a layer two switch, how is it\nthat we control spoofing at that layer?\n\n426\n00:21:55.490 --> 00:21:59.630\nWell, that's where things like\nDHCP snooping come in play.\n\n427\n00:21:59.630 --> 00:22:01.060\nAnd I always get this acronym wrong.\n\n428\n00:22:01.060 --> 00:22:04.940\nI always wanna see DIA,\nit's DAI, Dynamic AR Inspection.\n\n429\n00:22:04.940 --> 00:22:05.500\nSo let's go ahead and\n\n430\n00:22:05.500 --> 00:22:08.740\njust briefly talk about what\nare those two things doing, right?\n\n431\n00:22:08.740 --> 00:22:11.872\nWell, imagine the ability for\nDHCP service, right?\n\n432\n00:22:11.872 --> 00:22:14.850\nIt's a server,\nit's a service running in on the switch.\n\n433\n00:22:14.850 --> 00:22:20.651\nImagine the ability for\nthe switch to use DHCP to have a mapping,\n\n434\n00:22:20.651 --> 00:22:23.766\nan IP address to a MAC address of all\n\n435\n00:22:23.766 --> 00:22:28.721\nthe IP addresses that it's\nallocated to the network.\n\n436\n00:22:28.721 --> 00:22:32.492\nAnd if it hears an ARP request\ncome in on another port, saying,\n\n437\n00:22:32.492 --> 00:22:37.189\nthat's my MAC address, this switch says,\nno, not according to my records,\n\n438\n00:22:37.189 --> 00:22:39.203\nthat MAC address is on port 33.\n\n439\n00:22:39.203 --> 00:22:42.002\nAnd this came in off a port 2,\nso that's an invalid,\n\n440\n00:22:42.002 --> 00:22:44.610\nprobably an ARP spoofing attack, right?\n\n441\n00:22:44.610 --> 00:22:46.440\nAnd it invalidates it and it discards it.\n\n442\n00:22:47.590 --> 00:22:50.260\nThat's part of the DHCP\nsnooping side of it.\n\n443\n00:22:50.260 --> 00:22:52.930\nWell, how about Dynamic ARP inspection?\n\n444\n00:22:52.930 --> 00:22:57.240\nDynamic ARP inspection says, okay,\nI know I've got a series of MAC addresses.\n\n445\n00:22:57.240 --> 00:23:00.360\nAnd I know which MAC\naddresses are on each port.\n\n446\n00:23:00.360 --> 00:23:03.120\nAnd the only MAC address,\ncuz it's MAC filtering, right?\n\n447\n00:23:03.120 --> 00:23:06.800\nThe only MAC address that I'm gonna\nallow to communicate on this port\n\n448\n00:23:06.800 --> 00:23:08.340\nis the one that's in the list.\n\n449\n00:23:08.340 --> 00:23:12.550\nAnd if I hear that same MAC address being\ncalled out with the address resolution\n\n450\n00:23:12.550 --> 00:23:16.980\nprotocol on another port,\nit's invalidated and it's discarded.\n\n451\n00:23:16.980 --> 00:23:19.990\nSo keep in mind that that's one of\nthe benefits of having a layer three\n\n452\n00:23:19.990 --> 00:23:20.750\nswitch, right?\n\n453\n00:23:20.750 --> 00:23:24.115\nIf I have a layer three switch,\nit understands layer two and\n\n454\n00:23:24.115 --> 00:23:27.221\nwe can do both of these things\nat the same time, right?\n\n455\n00:23:27.221 --> 00:23:29.430\nWhat are some of the other\nthings that we have here too?\n\n456\n00:23:29.430 --> 00:23:31.340\nThings like loop prevention, right?\n\n457\n00:23:31.340 --> 00:23:35.510\nAnd they're talking about routers,\nbut since I mentioned layer two and\n\n458\n00:23:35.510 --> 00:23:37.354\nlayer three, let me go ahead and\n\n459\n00:23:37.354 --> 00:23:42.152\njust briefly talk about both of the loop\nprevention techniques that we implement.\n\n460\n00:23:42.152 --> 00:23:46.852\nIn IP, we use things like poison reverse\nand we use things like split horizons,\n\n461\n00:23:46.852 --> 00:23:47.354\nright?\n\n462\n00:23:47.354 --> 00:23:51.248\nAnd this basically says that in\nthe routing information protocol,\n\n463\n00:23:51.248 --> 00:23:54.663\nthe disinfector protocols,\nthese are ones that are very,\n\n464\n00:23:54.663 --> 00:23:57.413\nvery susceptible to routing loops, right?.\n\n465\n00:23:57.413 --> 00:24:00.751\nBecause they can get misinformation\nin the routing table.\n\n466\n00:24:00.751 --> 00:24:01.287\nRight?\n\n467\n00:24:01.287 --> 00:24:05.341\nAnd what ends up happening is that\nwith split horizons, it says,\n\n468\n00:24:05.341 --> 00:24:10.218\nif you told me about a route and I need to\nbroadcast my routing table back to you.\n\n469\n00:24:10.218 --> 00:24:13.020\nI'm not gonna tell you about a route\nyou already told me about, right?\n\n470\n00:24:13.020 --> 00:24:15.210\nSo it tries to stop that.\n\n471\n00:24:15.210 --> 00:24:18.941\nWe add poison reverse and then what it\ndoes is, when you tell me about that\n\n472\n00:24:18.941 --> 00:24:22.565\nroute, rather than tell you about\na route that you just told me about.\n\n473\n00:24:22.565 --> 00:24:25.597\nI'm gonna broadcast it back to\nyou with a hop count of 16.\n\n474\n00:24:25.597 --> 00:24:29.210\nAnd that means that\nthe route isn't accessible.\n\n475\n00:24:29.210 --> 00:24:32.670\nAnd then what the router that is\nreceiving that broadcast back will say,\n\n476\n00:24:32.670 --> 00:24:33.910\nlet me go ahead and remove that.\n\n477\n00:24:33.910 --> 00:24:35.330\nYou don't need to know about that.\n\n478\n00:24:35.330 --> 00:24:38.030\nIt doesn't add it to its routing table.\n\n479\n00:24:38.030 --> 00:24:39.860\nIt already has the route\nin its routing table.\n\n480\n00:24:39.860 --> 00:24:41.390\nIt doesn't need a duplicate entry.\n\n481\n00:24:41.390 --> 00:24:43.390\nLet's see.\n\n482\n00:24:43.390 --> 00:24:46.923\nSo that's a little bit about layer three,\nloop prevention.\n\n483\n00:24:46.923 --> 00:24:51.808\nLayer two, we have a nice little\nalgorithm out there, right, that's called\n\n484\n00:24:51.808 --> 00:24:57.700\nthe spanning tree algorithm, STA,\nthat's part of the spanning tree protocol.\n\n485\n00:24:57.700 --> 00:25:03.570\nAnd what this does is layer two route up\nswitching loop prevention, if you will.\n\n486\n00:25:03.570 --> 00:25:05.846\nPrevents against things like\nbroadcast storms, right?\n\n487\n00:25:05.846 --> 00:25:10.050\nAnd it just goes through\nan election process.\n\n488\n00:25:10.050 --> 00:25:13.080\nAnd it creates this logical\ntree topology if you will,\n\n489\n00:25:13.080 --> 00:25:14.910\nwhere you have root bridge election.\n\n490\n00:25:14.910 --> 00:25:18.860\nIt says only one switch, excuse me, and\n\n491\n00:25:18.860 --> 00:25:21.280\nthen the entire network is\ngoing to be the master.\n\n492\n00:25:21.280 --> 00:25:24.280\nAnd then it goes through a process\nof shutting down the ports that\n\n493\n00:25:24.280 --> 00:25:26.870\ncould cause a loop and\nwe have forwarding ports, and\n\n494\n00:25:26.870 --> 00:25:30.390\nwe have ports that are not\ngoing to be allowed to forward.\n\n495\n00:25:30.390 --> 00:25:33.050\nThus preventing one of\nthose switching loops.\n\n496\n00:25:33.050 --> 00:25:36.370\nYeah, and the reason that we would\neven get those loops to begin with is\n\n497\n00:25:36.370 --> 00:25:38.110\nby utilizing redundancy.\n\n498\n00:25:38.110 --> 00:25:41.590\nSo having those redundant\nlinks on your switches and\n\n499\n00:25:41.590 --> 00:25:43.530\nwe're kind of just\npreventing that confusion.\n\n500\n00:25:43.530 --> 00:25:45.540\nSo by blocking one particular port.\n\n501\n00:25:45.540 --> 00:25:49.020\nLet's say we had two links for redundancy.\n\n502\n00:25:49.020 --> 00:25:50.890\nAnd then on one particular port,\nwe block it.\n\n503\n00:25:50.890 --> 00:25:54.720\nWe're kind of breaking that circle,\nto prevent those loops from occurring.\n\n504\n00:25:54.720 --> 00:25:56.189\nYes, most definitely.\n\n505\n00:25:56.189 --> 00:25:57.855\nAnd so, keep that in mind when it comes,\n\n506\n00:25:57.855 --> 00:26:00.364\nthe other thing too that they\nhave are flood guards, right?\n\n507\n00:26:00.364 --> 00:26:00.961\nAnd again,\n\n508\n00:26:00.961 --> 00:26:04.680\nflood guards help to stop things like\ndenial of service attacks, right?\n\n509\n00:26:05.700 --> 00:26:09.440\nWhen you talk about like basic,\nlegitimate, not legitimate traffic,\n\n510\n00:26:09.440 --> 00:26:14.350\nbut basic excessive traffic like ICMP,\nthe ping of death and stuff.\n\n511\n00:26:14.350 --> 00:26:16.700\nRouters can just filter\nthat information out.\n\n512\n00:26:16.700 --> 00:26:18.740\nI don't need that excessive information,\njust block it.\n\n513\n00:26:18.740 --> 00:26:20.530\nSo that's already built into the switch.\n\n514\n00:26:20.530 --> 00:26:23.827\nBut what about traffic that's legitimate.\n\n515\n00:26:23.827 --> 00:26:28.245\nIf I see a synchronization request come\nin to start up a staple TCP session,\n\n516\n00:26:28.245 --> 00:26:29.658\nwhat happens, right?\n\n517\n00:26:29.658 --> 00:26:31.396\nThat's a legitimate request.\n\n518\n00:26:31.396 --> 00:26:34.193\nWell, we're gonna allow the first\none through but remember,\n\n519\n00:26:34.193 --> 00:26:35.469\nstaple packet inspection.\n\n520\n00:26:35.469 --> 00:26:39.438\nWe can look at the traffic and\nwe can see another SYN packet come in for\n\n521\n00:26:39.438 --> 00:26:40.489\nthe same source.\n\n522\n00:26:40.489 --> 00:26:44.848\nAnd say, well, wait a second, you already\nasked for a synchronization request.\n\n523\n00:26:44.848 --> 00:26:48.070\nI'm not gonna allow you to ask for\na second one, and it drops the packet, so\n\n524\n00:26:48.070 --> 00:26:51.440\nit can protect against some of\nthose denial of service attacks.\n\n525\n00:26:51.440 --> 00:26:55.160\nSo, that is a little bit about your\nrouting, and your routers in general.\n\n526\n00:26:55.160 --> 00:26:56.840\nI will tell you though.\n\n527\n00:26:56.840 --> 00:26:59.419\nLooks like we're out of time, and\nI've got a lot more to talk about.\n\n528\n00:26:59.419 --> 00:27:02.121\nAll right, Wes, we have covered\na lot in this particular episode.\n\n529\n00:27:02.121 --> 00:27:04.430\nBut like you said,\nwe have a lot more to cover.\n\n530\n00:27:04.430 --> 00:27:06.130\nSo ladies and gentlemen, stay tuned.\n\n531\n00:27:06.130 --> 00:27:08.070\nFor this show,\nwe'll go ahead and sign off.\n\n532\n00:27:08.070 --> 00:27:09.900\nRemember, I'm your host, Cherokee Boose.\n\n533\n00:27:09.900 --> 00:27:10.810\nAnd I'm Wes Bryan.\n\n534\n00:27:10.810 --> 00:27:14.418\nSee you next time, here at ITProTV.\n\n535\n00:27:14.418 --> 00:27:20.053\n[MUSIC]\n\n536\n00:27:20.053 --> 00:27:23.051\nThank you for watching ITProTV.\n\n",
          "vimeoId": "213510722"
        },
        {
          "description": "In this episode, Wes and Cherokee take a look at IPSec and how it can be used for transmitting information. They also discuss what a proxy is and how it may offer different functionalities based upon how it is implemented.",
          "length": "1719",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-2-hardware_software_organizational_sec_pt2-040717-PGM.00_28_25_11.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-2-hardware_software_organizational_sec_pt2-040717-PGM.00_28_25_11.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-2-hardware_software_organizational_sec_pt2-040717-PGM.00_28_25_11.Still001-sm.jpg",
          "title": "Hardware Software Organizational Security Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.190\nWelcome to ITProTV.\n\n2\n00:00:01.190 --> 00:00:02.072\nI'm your host.\n\n3\n00:00:02.072 --> 00:00:06.488\n&gt;&gt; [CROSSTALK]\n\n4\n00:00:06.488 --> 00:00:08.358\n[MUSIC]\n\n5\n00:00:08.358 --> 00:00:10.566\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:10.566 --> 00:00:14.730\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n7\n00:00:14.730 --> 00:00:16.730\nI'm your show host, Cherokee Boose..\n\n8\n00:00:16.730 --> 00:00:19.110\nSo, this is actually\na continuation of part two,\n\n9\n00:00:19.110 --> 00:00:23.330\nwhere we will continue to look at how\ndifferent components of hardware and\n\n10\n00:00:23.330 --> 00:00:26.900\nsoftware both affect\nan organization's security.\n\n11\n00:00:26.900 --> 00:00:29.390\nAnd with us today, we have Mr.\nWes Bryan back in studio.\n\n12\n00:00:29.390 --> 00:00:30.230\nThank you for joining us Wes.\n\n13\n00:00:30.230 --> 00:00:31.080\n&gt;&gt; Absolutely, Cherokee.\n\n14\n00:00:31.080 --> 00:00:31.980\nThanks for having me back.\n\n15\n00:00:31.980 --> 00:00:36.000\nThat's right, we've got a lot more to\ntalk about in the first part, guys,\n\n16\n00:00:36.000 --> 00:00:37.340\nwe talked about a bunch already.\n\n17\n00:00:37.340 --> 00:00:40.540\nWe talked about things like firewalls,\nthe different types of firewalls that\n\n18\n00:00:40.540 --> 00:00:44.090\nyou can see, things like\napplication-based and network-based.\n\n19\n00:00:44.090 --> 00:00:47.550\nI will tell you though, one thing I did\nnot talk about with the firewalls that I\n\n20\n00:00:47.550 --> 00:00:52.660\nwanna make sure that I mention here,\nis the term stateful and stateless.\n\n21\n00:00:52.660 --> 00:00:55.910\nRemember, stateless, any time they\ntalk about stateless, a lot of times\n\n22\n00:00:55.910 --> 00:01:00.210\nwhat we're talking about is configuration\nversus not having to configure it.\n\n23\n00:01:00.210 --> 00:01:01.350\nThis is a little bit different.\n\n24\n00:01:01.350 --> 00:01:03.350\nWhen we say a stateful firewall,\n\n25\n00:01:03.350 --> 00:01:07.835\nwhat we're doing is it knows\nthe connection state, right?\n\n26\n00:01:07.835 --> 00:01:11.735\nVersus stateless where it isn't really\npaying attention to the connections.\n\n27\n00:01:11.735 --> 00:01:14.095\nLike for instance when we talk\nabout things like stateless and\n\n28\n00:01:14.095 --> 00:01:19.635\nstateful DHCP, stateful means we're gonna\ndo some configurations like in IPv6.\n\n29\n00:01:19.635 --> 00:01:24.015\nStateless means that we don't have\nto configure those IP addresses.\n\n30\n00:01:24.015 --> 00:01:26.775\nIf we want to we can just\nconfigure the option.\n\n31\n00:01:26.775 --> 00:01:28.305\nSo again, keep in mind that stateful and\n\n32\n00:01:28.305 --> 00:01:32.000\nstateless mean a little bit different\nwhen you're talking about firewalls.\n\n33\n00:01:32.000 --> 00:01:34.207\n&gt;&gt; Okay, so I was just thinking,\none way that I try to remember,\n\n34\n00:01:34.207 --> 00:01:36.548\nthat I don't know if it'll help\nyou guys when you're studying.\n\n35\n00:01:36.548 --> 00:01:40.652\nBut when I think about state lists,\nI usually relate it to like,\n\n36\n00:01:40.652 --> 00:01:42.860\nless configuration or less work.\n\n37\n00:01:42.860 --> 00:01:43.463\nWhat do you think, Wes?\n\n38\n00:01:43.463 --> 00:01:45.370\n&gt;&gt; That's what I do.\n\n39\n00:01:45.370 --> 00:01:47.530\nI always state full is full of work.\n\n40\n00:01:47.530 --> 00:01:48.287\nState lists-\n&gt;&gt; There you go.\n\n41\n00:01:48.287 --> 00:01:48.793\n&gt;&gt; Less work.\n\n42\n00:01:48.793 --> 00:01:49.734\n&gt;&gt; Yeah.\nYeah, absolutely.\n\n43\n00:01:49.734 --> 00:01:50.794\nSo, I did wanna make but\n\n44\n00:01:50.794 --> 00:01:53.878\njust make sure that I mention that\ncuz we want you guys to be prepared.\n\n45\n00:01:53.878 --> 00:01:57.018\nThe other thing we talked about,\nthings like VPN concentrators,\n\n46\n00:01:57.018 --> 00:01:58.991\ndifferent types of VPN communications.\n\n47\n00:01:58.991 --> 00:02:02.428\nAnd there again, one of the things that\nI kind of wanna double back on, and\n\n48\n00:02:02.428 --> 00:02:03.771\nwanna kind of show you guys.\n\n49\n00:02:03.771 --> 00:02:07.810\nBecause I didn't get to fit it\nall in in the last episode,\n\n50\n00:02:07.810 --> 00:02:10.600\nwas something known as IPsec, right?\n\n51\n00:02:11.870 --> 00:02:15.250\nWhen you're implementing\nVPN communications,\n\n52\n00:02:15.250 --> 00:02:17.190\nyou can implement old technologies.\n\n53\n00:02:17.190 --> 00:02:21.300\nLike for instance, point-to-point\ntunneling protocol with MPPE.\n\n54\n00:02:21.300 --> 00:02:25.350\nHowever, that doesn't give you\nthe encryption levels that IPsec does.\n\n55\n00:02:25.350 --> 00:02:28.730\nIPsec isn't one specific technology,\n\n56\n00:02:28.730 --> 00:02:33.270\nit's actually a bunch of technologies, all\nworking together in order to secure your\n\n57\n00:02:33.270 --> 00:02:36.520\nIP Communications over at\nTCP/IP based networks.\n\n58\n00:02:36.520 --> 00:02:39.890\nSo, I do wanna kind of\ndouble back on that and\n\n59\n00:02:39.890 --> 00:02:42.910\nmake sure that we do talk\na little bit about that.\n\n60\n00:02:42.910 --> 00:02:48.570\nSo, when it comes to IPsec, there are\nIPsec has a couple of protocols that it\n\n61\n00:02:48.570 --> 00:02:54.860\nuses, amongst other things, it has what's\nknown as Which is Authentication Header.\n\n62\n00:02:54.860 --> 00:02:57.003\nIt also has what is known as ESP.\n\n63\n00:02:57.003 --> 00:03:01.250\nAnd ESP is\nthe Encapsulating Security Payload.\n\n64\n00:03:01.250 --> 00:03:04.880\nNow, why you use either one really\n\n65\n00:03:04.880 --> 00:03:07.690\ndepends on the level of security you need,\nall right?\n\n66\n00:03:07.690 --> 00:03:11.050\nWe have what's known as the security\ntriad, confidentiality, integrity and\n\n67\n00:03:11.050 --> 00:03:12.970\navailability, all right?\n\n68\n00:03:12.970 --> 00:03:15.750\nConfidentiality is making\nsure that you can't,\n\n69\n00:03:15.750 --> 00:03:19.550\nan unauthorized entity can't\neavesdrop on your data.\n\n70\n00:03:19.550 --> 00:03:21.910\nSo, we take care of that with encryption,\nright?\n\n71\n00:03:21.910 --> 00:03:26.470\nIntegrity, though, we use things like\nmessage digest to ensure that if I send\n\n72\n00:03:26.470 --> 00:03:29.940\na piece of data from myself to Miss\nCherokee, she can check it on her end.\n\n73\n00:03:29.940 --> 00:03:33.560\nAnd make sure that not a single\npunctuation mark has been modified.\n\n74\n00:03:33.560 --> 00:03:38.980\nNot even extra space has been put in that\ndata, it hasn't been altered in any way.\n\n75\n00:03:38.980 --> 00:03:41.850\nAnd then last thing is availability,\nand obviously availability is making\n\n76\n00:03:41.850 --> 00:03:44.790\nsure that authorized users have\naccess to their information.\n\n77\n00:03:44.790 --> 00:03:46.820\nSo, which one are we gonna chose?\n\n78\n00:03:46.820 --> 00:03:51.000\nAuthentication Header or\nEncapsulating Security Payload?\n\n79\n00:03:51.000 --> 00:03:55.710\nWell, Authentication Header allows you\nthe ability to do things like, for\n\n80\n00:03:55.710 --> 00:03:57.920\ninstance, integrity, right.\n\n81\n00:03:57.920 --> 00:03:59.052\nWe can use things like triple DES.\n\n82\n00:03:59.052 --> 00:04:03.200\nTriple DES being the data\nencryption standard.\n\n83\n00:04:03.200 --> 00:04:04.763\nA triple encryption of triple DES.\n\n84\n00:04:04.763 --> 00:04:09.380\nYou can also use things like, for\ninstance, the older message digest five.\n\n85\n00:04:09.380 --> 00:04:11.300\nProbably should stay away from that one.\n\n86\n00:04:11.300 --> 00:04:16.590\nBut, what it doesn't do is it lacks\nthe ability to do encryption.\n\n87\n00:04:16.590 --> 00:04:21.420\nIt will make sure that by data maintains\nits integrity, but it won't do is make\n\n88\n00:04:21.420 --> 00:04:26.530\nsure that hacker come lately,\ncan't eavesdrop on that information.\n\n89\n00:04:26.530 --> 00:04:27.600\nAnd you have to keep that in mind.\n\n90\n00:04:27.600 --> 00:04:31.550\nIf you want the encryption level,\nthen what you're gonna have to use is ESP.\n\n91\n00:04:31.550 --> 00:04:34.404\nNow, be careful with this one\nbecause ESP also does integrity.\n\n92\n00:04:34.404 --> 00:04:38.264\nYou can actually implement ESP and I've\nactually done this on accident on myself.\n\n93\n00:04:38.264 --> 00:04:44.250\nWhere you could implement ESP and\nyou think, well I got encryption.\n\n94\n00:04:44.250 --> 00:04:47.360\nAnd the only thing that you've\ndone is you've done encryption in\n\n95\n00:04:47.360 --> 00:04:52.020\na main mode communication and\nall that does is it does integrity checks.\n\n96\n00:04:52.020 --> 00:04:54.140\nIt doesn't actually add encryption,\nall right?\n\n97\n00:04:54.140 --> 00:04:56.972\nSo let's go ahead, and what I'd like to\ndo is I'd like to show you guys kind of\n\n98\n00:04:56.972 --> 00:05:00.460\na IPsec communication, so\nyou can see some of these protocols.\n\n99\n00:05:00.460 --> 00:05:03.380\nAnd I'll talk a little bit more about what\nI mentioned, main mode and quick mode.\n\n100\n00:05:03.380 --> 00:05:05.318\nSo you can actually kind of see it.\n\n101\n00:05:05.318 --> 00:05:10.758\nBecause in IPsec we've got two different\nphases of establishing a communication,\n\n102\n00:05:10.758 --> 00:05:11.299\nright.\n\n103\n00:05:11.299 --> 00:05:16.232\nA trust relationship that we've\nestablished between two computers using\n\n104\n00:05:16.232 --> 00:05:16.810\nIPsec.\n\n105\n00:05:16.810 --> 00:05:18.327\nAnd they don't really call it out here,\nbut I want to mention it.\n\n106\n00:05:18.327 --> 00:05:21.510\nWhat's known as a security association,\nright.\n\n107\n00:05:21.510 --> 00:05:25.696\nThat means that if I wanna send an IPsec\nencryption to Miss Cherokee's computer,\n\n108\n00:05:25.696 --> 00:05:29.048\nher computer and my computer,\nwe have to kinda pre-negotiate.\n\n109\n00:05:29.048 --> 00:05:32.949\nWhat is the key exchange, what's gonna\nhappen, what's the authentication\n\n110\n00:05:32.949 --> 00:05:36.900\nmechanism, what's the level of\nencryption that's gonna happen?\n\n111\n00:05:36.900 --> 00:05:40.420\nAnd that happens in what's known as\na phase one security association,\n\n112\n00:05:40.420 --> 00:05:42.390\nalso known as quick mode.\n\n113\n00:05:42.390 --> 00:05:45.730\nAll right, and let me make sure.\n\n114\n00:05:45.730 --> 00:05:46.590\nMain mode, I'm sorry.\n\n115\n00:05:46.590 --> 00:05:48.070\nMain mode is the phase one.\n\n116\n00:05:48.070 --> 00:05:51.510\nGet that, gotta get that right,\ndon't switch that around.\n\n117\n00:05:51.510 --> 00:05:54.650\nHowever, you also go through\na phase two security association.\n\n118\n00:05:54.650 --> 00:05:58.610\nNow, this is actually two unidirectional\nsecurity associations that\n\n119\n00:05:58.610 --> 00:05:59.980\nare established, right?\n\n120\n00:05:59.980 --> 00:06:02.823\nSo, when you have two computers that\nare doing IPsec communications and\n\n121\n00:06:02.823 --> 00:06:04.883\nthey go into their phase\ntwo security association.\n\n122\n00:06:04.883 --> 00:06:07.565\nI have an outbound security association,\n\n123\n00:06:07.565 --> 00:06:12.350\nsending traffic from my computer\nin this example to Cherokee.\n\n124\n00:06:12.350 --> 00:06:16.440\nShe has a one way outbound\nfrom her computer,\n\n125\n00:06:16.440 --> 00:06:19.610\nsecurity association back to my machine,\nall right.\n\n126\n00:06:19.610 --> 00:06:23.720\nAnd then, that's where we actually\nstart sending encrypted information.\n\n127\n00:06:23.720 --> 00:06:26.460\nBut you gotta be careful\nbecause you can set up ESP.\n\n128\n00:06:27.680 --> 00:06:31.110\nIn a way,\nthat it doesn't provide encryption.\n\n129\n00:06:31.110 --> 00:06:32.490\nLet me go and show you what I mean.\n\n130\n00:06:32.490 --> 00:06:34.750\nI'm on a couple of\nWindows 10 machines here.\n\n131\n00:06:34.750 --> 00:06:38.630\nAnd I've actually got the Windows Firewall\nwith Advanced Security setup.\n\n132\n00:06:38.630 --> 00:06:43.920\nAnd you can actually force communication\nbetween two computers using IPSEC.\n\n133\n00:06:43.920 --> 00:06:45.590\nRight here,\nwith your host based fire wall.\n\n134\n00:06:45.590 --> 00:06:48.680\nSo for instance, we're under\nconnection security rules, right.\n\n135\n00:06:48.680 --> 00:06:51.960\nI can set up and by default,\nwe don't have any security rules.\n\n136\n00:06:51.960 --> 00:06:53.990\nAnd you can see endpoints here.\n\n137\n00:06:53.990 --> 00:06:56.610\nA lot of other things that are in here,\nauthentication mode.\n\n138\n00:06:56.610 --> 00:06:59.740\nAnd I believe there's more under here,\nit's just hidden.\n\n139\n00:06:59.740 --> 00:07:01.230\nYeah, like authentication method.\n\n140\n00:07:01.230 --> 00:07:01.910\nYou can see there's a lot.\n\n141\n00:07:01.910 --> 00:07:04.410\nWe'll go ahead and set up one of these,\nand show you what I mean.\n\n142\n00:07:04.410 --> 00:07:09.620\nSo, I'm gonna create a new IPsec, or\nconnection security rule, all right.\n\n143\n00:07:09.620 --> 00:07:12.610\nAnd we've got some different types\nof rules that we can use, and\n\n144\n00:07:12.610 --> 00:07:13.460\nwe can create here.\n\n145\n00:07:13.460 --> 00:07:16.449\nWhat I'm gonna use is a server-to-server\nconnection security rule,\n\n146\n00:07:16.449 --> 00:07:18.070\nbecause that's just gonna be from me.\n\n147\n00:07:18.070 --> 00:07:20.609\nI use the example of talking\nto Cherokee's computer,\n\n148\n00:07:20.609 --> 00:07:25.050\nthis'll be the example of communication\nbetween just those two computers.\n\n149\n00:07:25.050 --> 00:07:28.915\nSo, we're gonna go ahead and\nwe'll set up that server-to-server.\n\n150\n00:07:28.915 --> 00:07:31.070\nServer-to-server doesn't mean\nit actually has to be a server,\n\n151\n00:07:31.070 --> 00:07:37.120\nit just means it's gonna be two endpoints\nthat require the IPsec communication.\n\n152\n00:07:37.120 --> 00:07:38.790\nAnd you can get very granular.\n\n153\n00:07:38.790 --> 00:07:42.194\nI can say that I only want its to be\nthe IP address Cherokee's computer,\n\n154\n00:07:42.194 --> 00:07:44.087\nI don't wanna let any IP address here.\n\n155\n00:07:44.087 --> 00:07:46.892\nBut I'm gonna go ahead and\nmake it a little bit more simple for\n\n156\n00:07:46.892 --> 00:07:50.206\ndemonstration purposes and\nI'll just say any IP address, all right.\n\n157\n00:07:50.206 --> 00:07:54.858\nAnd now look what we get here, we get\nrequest authentication for inbound and\n\n158\n00:07:54.858 --> 00:07:59.875\noutbound connections, require inbound\nconnections but request for outbound,\n\n159\n00:07:59.875 --> 00:08:04.236\nthat's middle level secure if you will But\nthe most secure says require\n\n160\n00:08:04.236 --> 00:08:08.835\nauthentication for both inbound and\noutbound, and that's what we want.\n\n161\n00:08:08.835 --> 00:08:09.812\nAnd let me kinda show you this.\n\n162\n00:08:09.812 --> 00:08:12.905\nI'm gonna jump over to another\nmachine here that's gonna be part\n\n163\n00:08:12.905 --> 00:08:14.260\nthis IPsec communication.\n\n164\n00:08:14.260 --> 00:08:17.799\nAnd we'll fire up our command prompt,\nand I'm gonna ping it's IP address.\n\n165\n00:08:17.799 --> 00:08:21.574\nSo we'll ping 10.10.10.20.\n\n166\n00:08:21.574 --> 00:08:25.730\nAnd you might notice that we've\ngot replies back, all right?\n\n167\n00:08:25.730 --> 00:08:27.550\nHere's the thing that you've\ngotta remember, right?\n\n168\n00:08:27.550 --> 00:08:30.700\nNow I don't have IPsec set\nup on these machines yet.\n\n169\n00:08:30.700 --> 00:08:35.522\nBut when I set up IPsec this machine,\nI'm going to have to set up IPsec\n\n170\n00:08:35.522 --> 00:08:39.385\nconnection security rules\non the other machine.\n\n171\n00:08:39.385 --> 00:08:40.575\nOr it won't be able to communicate.\n\n172\n00:08:40.575 --> 00:08:41.375\nLet me show you what I mean.\n\n173\n00:08:41.375 --> 00:08:45.705\nSo I'm gonna require authentication for\ninbound and outbound connections, and\n\n174\n00:08:45.705 --> 00:08:47.355\nwe'll choose Next.\n\n175\n00:08:47.355 --> 00:08:53.160\nProbably one of the best and strongest\nways to do this is a computer certificate.\n\n176\n00:08:53.160 --> 00:08:55.250\nI'm not setting up a public key\ninfrastructure for this one,\n\n177\n00:08:55.250 --> 00:08:56.550\nso I'm gonna do Advanced.\n\n178\n00:08:56.550 --> 00:08:57.727\nAnd it's kind of advanced,\n\n179\n00:08:57.727 --> 00:09:00.188\nyou really shouldn't be using\nthe method that I'm doing.\n\n180\n00:09:00.188 --> 00:09:03.049\nBut you can see the Customize option here.\n\n181\n00:09:03.049 --> 00:09:05.186\nAnd here's where we can set\nthings like your First and\n\n182\n00:09:05.186 --> 00:09:06.480\nSecond authentication rules.\n\n183\n00:09:06.480 --> 00:09:09.452\nI'm gonna go ahead and\nadd one just to the First authentication.\n\n184\n00:09:09.452 --> 00:09:12.240\nAnd you can kinda see we've got\ndifferent authentication methods.\n\n185\n00:09:12.240 --> 00:09:16.150\nKerberos, if you're in a Windows domain,\nyou can use the Kerberos protocol.\n\n186\n00:09:16.150 --> 00:09:18.050\nAgain, you can see certificates.\n\n187\n00:09:18.050 --> 00:09:21.030\nI'm gonna use one that's not recommended,\ncuz it's relatively weak.\n\n188\n00:09:21.030 --> 00:09:23.125\nBut it will show you the traffic,\nnonetheless.\n\n189\n00:09:23.125 --> 00:09:27.402\nAnd we'll go ahead and do a super\nsecret password of, well, Pass1234.\n\n190\n00:09:27.402 --> 00:09:29.254\nAll right, and we'll choose OK to this.\n\n191\n00:09:29.254 --> 00:09:31.138\nOkay, and we'll choose Next.\n\n192\n00:09:31.138 --> 00:09:35.065\nAnd we're gonna apply this to all\nprofiles, right, our domain, private, and\n\n193\n00:09:35.065 --> 00:09:35.950\npublic profile.\n\n194\n00:09:37.400 --> 00:09:38.900\nAll right, and we'll choose Next.\n\n195\n00:09:38.900 --> 00:09:44.499\nNow because I can even type Rule,\nI'll call this just Rule 1 for now.\n\n196\n00:09:44.499 --> 00:09:49.224\nAll right, and we'll call this Ipsec com,\n\n197\n00:09:49.224 --> 00:09:53.573\nall right, for IPsec communications.\n\n198\n00:09:53.573 --> 00:09:55.020\nAnd we'll choose Finish.\n\n199\n00:09:55.020 --> 00:09:58.040\nAll right, so\nnow I have a rule that says if you're\n\n200\n00:09:58.040 --> 00:10:01.190\ngonna communicate with this computer,\nyou have to authenticate first.\n\n201\n00:10:01.190 --> 00:10:05.202\nNow you've just seen on the other machine,\nI ran a ping, right?\n\n202\n00:10:05.202 --> 00:10:09.846\nAnd I said go ahead, or the computer said,\nwithout the IPsec communication, yeah,\n\n203\n00:10:09.846 --> 00:10:11.760\nI'll respond back to you.\n\n204\n00:10:11.760 --> 00:10:13.381\nLet's see if it responds back now.\n\n205\n00:10:15.476 --> 00:10:17.000\nAnd it's not responding.\n\n206\n00:10:17.000 --> 00:10:17.720\nWhy?\n\n207\n00:10:17.720 --> 00:10:20.940\nIt's because of the IPsec\nrule that we set up.\n\n208\n00:10:20.940 --> 00:10:25.720\nIt says you have to have authentication\nfor an inbound communication.\n\n209\n00:10:25.720 --> 00:10:29.087\nSo let's go ahead, and let's configure\nthat here on this machine, as well.\n\n210\n00:10:29.087 --> 00:10:33.909\nWe're gonna drop down to our little\nCortana search run feature here, and\n\n211\n00:10:33.909 --> 00:10:35.400\nwe'll type wf.msc.\n\n212\n00:10:35.400 --> 00:10:39.620\nI love that, it's one of those smallest\nMicrosoft Management Console commands.\n\n213\n00:10:39.620 --> 00:10:43.489\nAnd that brings up the Windows Firewall\nwith Advanced Security.\n\n214\n00:10:43.489 --> 00:10:45.549\nAnd you know,\nlet me just double-check something,\n\n215\n00:10:45.549 --> 00:10:48.908\ncuz it's telling me that some of these are\nconfigured by your systems administrator.\n\n216\n00:10:48.908 --> 00:10:51.110\nI wanna make sure I don't\nhave a group policy in place.\n\n217\n00:10:51.110 --> 00:10:55.117\nReal quick fix here, guys,\njust make sure that I don't.\n\n218\n00:10:55.117 --> 00:10:56.429\nUsually that's what you'll do,\n\n219\n00:10:56.429 --> 00:10:58.787\nyou'll set this up with a GPO\ninside of a domain environment.\n\n220\n00:10:58.787 --> 00:11:01.899\nJust wanna double check something here and\nmake sure I don't still have a rule in\n\n221\n00:11:01.899 --> 00:11:04.180\nplace that might be getting-\n&gt;&gt; From a previous lab [LAUGH].\n\n222\n00:11:04.180 --> 00:11:07.090\n&gt;&gt; That's right, yeah, okay,\nso there we go, and thank you.\n\n223\n00:11:07.090 --> 00:11:10.808\nThat's from practicing on another lab.\n\n224\n00:11:10.808 --> 00:11:12.820\nAll right, so\nwe're gonna do the same thing here, guys.\n\n225\n00:11:12.820 --> 00:11:13.860\nWe're not gonna do anything different.\n\n226\n00:11:13.860 --> 00:11:15.460\nYou'll notice I don't\nhave any rules in here.\n\n227\n00:11:15.460 --> 00:11:18.310\nI just had to double check, cuz I was\ngetting that group policy warning.\n\n228\n00:11:18.310 --> 00:11:20.708\nAnd I'm gonna choose New Rule.\n\n229\n00:11:20.708 --> 00:11:23.680\nAll right, we'll do the same thing,\nand that's the interesting thing.\n\n230\n00:11:23.680 --> 00:11:26.410\nThe authentication mechanisms, and\nthey need to be the same on each side.\n\n231\n00:11:26.410 --> 00:11:29.540\nRemember, when we're gonna negotiate what\nauthentication is gonna be, I told you in\n\n232\n00:11:29.540 --> 00:11:33.950\nthat Phase 1 security association,\nwe've gotta negotiate the same thing.\n\n233\n00:11:33.950 --> 00:11:35.939\nI can't tell you I'm gonna negotiate\nwith a computer certificate but\n\n234\n00:11:35.939 --> 00:11:37.703\nyou're gonna use a password,\nright, it's not gonna work.\n\n235\n00:11:37.703 --> 00:11:39.702\n&gt;&gt; [LAUGH] They'll just\ndrop that communication.\n\n236\n00:11:39.702 --> 00:11:40.657\n&gt;&gt; Most definitely.\n\n237\n00:11:40.657 --> 00:11:42.624\nSo we'll go ahead and choose Next on this.\n\n238\n00:11:42.624 --> 00:11:46.382\nAnd again, we're going to require\ninbound and outbound authentication.\n\n239\n00:11:46.382 --> 00:11:48.796\nAnd we'll choose Next,\nI'm gonna choose Advanced.\n\n240\n00:11:48.796 --> 00:11:52.942\nAnd again, keep in mind guys, if you're\ndoing this, Transport Layer Security,\n\n241\n00:11:52.942 --> 00:11:55.845\nlike we mentioned in the previous\nepisode there, right,\n\n242\n00:11:55.845 --> 00:11:58.831\nyou should be using\ncertificate-based authentication.\n\n243\n00:11:58.831 --> 00:12:01.680\nBut this'll at least shows you\nthe communications that happened.\n\n244\n00:12:01.680 --> 00:12:05.328\nWe'll go ahead and choose Add, and\nI'm gonna choose that pre-shared key.\n\n245\n00:12:05.328 --> 00:12:10.910\nAgain, it's not recommended, again,\ncuz it is a weaker form of security.\n\n246\n00:12:10.910 --> 00:12:14.210\nAny time you have something\nthat a human needs to remember,\n\n247\n00:12:14.210 --> 00:12:17.116\nyou run the possibility of human error,\nall right?\n\n248\n00:12:17.116 --> 00:12:19.820\n[LAUGH] And we'll choose OK to this,\nand we'll choose Next.\n\n249\n00:12:19.820 --> 00:12:23.681\nI'm gonna apply it to all the profiles\non the network locations.\n\n250\n00:12:23.681 --> 00:12:29.486\nAnd I'll call this Rule1, and\nwe'll say IPsec Comm again.\n\n251\n00:12:29.486 --> 00:12:33.794\nAgain that's just a friendly description\nso that people like Wes can remember it.\n\n252\n00:12:33.794 --> 00:12:37.182\n[LAUGH] And I'll go ahead and\nI'll close down the firewall.\n\n253\n00:12:37.182 --> 00:12:41.289\nNow let's see if we can\nactually ping that machine now.\n\n254\n00:12:41.289 --> 00:12:43.317\nI'm gonna go ahead and\nI'm gonna run that same ping.\n\n255\n00:12:45.462 --> 00:12:51.751\n10.10.10.20, and look at that,\nwe get communications.\n\n256\n00:12:51.751 --> 00:12:56.443\nNow, I want you to understand, so I'm\ngonna go ahead and run a persistent ping,\n\n257\n00:12:56.443 --> 00:12:58.190\nso it keeps going.\n\n258\n00:12:58.190 --> 00:12:59.929\nAnd again guys, I've done nothing else.\n\n259\n00:12:59.929 --> 00:13:03.123\nI added a switch t here, so\nno smoke and mirrors here.\n\n260\n00:13:03.123 --> 00:13:04.490\nNow we're gonna go ahead and\nwe're gonna close this.\n\n261\n00:13:04.490 --> 00:13:05.769\nAnd we're gonna let it run,\n\n262\n00:13:05.769 --> 00:13:08.819\nbecause now what I can do is I can\nshow you the monitoring abilities.\n\n263\n00:13:08.819 --> 00:13:10.767\nAnd we can talk more about the Phase 1 and\n\n264\n00:13:10.767 --> 00:13:13.480\nthe Phase 2 Security Associations\nunder Monitoring.\n\n265\n00:13:13.480 --> 00:13:14.800\nAnd we have Security Associations,\n\n266\n00:13:14.800 --> 00:13:17.550\nthat's that trust relationship\nwe were talking about, right?\n\n267\n00:13:17.550 --> 00:13:21.380\nIf I open up Security Associations, here's\nour Main Mode, Main Mode is Phase 1.\n\n268\n00:13:21.380 --> 00:13:23.890\nThat says we're gonna\nnegotiate authentication,\n\n269\n00:13:23.890 --> 00:13:27.460\nthe encryption level,\nbefore we even start sending information.\n\n270\n00:13:27.460 --> 00:13:30.321\nSo I can go in here and I can go into, and\n\n271\n00:13:30.321 --> 00:13:35.613\nyou can see whatever the local\naddress is of the other entity, right?\n\n272\n00:13:35.613 --> 00:13:36.790\nOop, the remote address, excuse me.\n\n273\n00:13:36.790 --> 00:13:39.960\nThis is the local computer versus\nthe remote entity that you're\n\n274\n00:13:39.960 --> 00:13:41.500\ncommunicating with.\n\n275\n00:13:41.500 --> 00:13:44.464\nNotice that we didn't do\na second level of authentication.\n\n276\n00:13:44.464 --> 00:13:48.660\nAnd we're using Integrity, right?\n\n277\n00:13:48.660 --> 00:13:53.123\nEncryption here is through the negotiation\nprocess, and notice it says key exchange.\n\n278\n00:13:53.123 --> 00:13:55.800\nThis is through the IKE,\nif you will, Internet key exchange.\n\n279\n00:13:55.800 --> 00:14:00.755\nAnd what it's using is the Diffie-Hellman\npublic key exchange protocol, if you will,\n\n280\n00:14:00.755 --> 00:14:04.257\ninternet key exchange,\nmade by old Whitfield Diffie there and\n\n281\n00:14:04.257 --> 00:14:06.398\nMarty Hellman back in the late 70s.\n\n282\n00:14:06.398 --> 00:14:10.070\nThat's Phase 1, all right?\n\n283\n00:14:10.070 --> 00:14:15.270\nPhase 2 is where we actually start\nsending encrypted information, or\n\n284\n00:14:15.270 --> 00:14:16.710\nat least we hope so.\n\n285\n00:14:16.710 --> 00:14:22.567\nBut one of the things I notice is that I\ndon't have Integrity, but I do have ESP.\n\n286\n00:14:22.567 --> 00:14:24.747\nAnd remember what I told you,\nyou have to be careful.\n\n287\n00:14:24.747 --> 00:14:28.468\nJust because I have ESP and\nwe told you that allows for encryption,\n\n288\n00:14:28.468 --> 00:14:31.480\nI want you to see what happens if I go to.\n\n289\n00:14:31.480 --> 00:14:33.350\nAnd it is, it's forcing encryption, okay.\n\n290\n00:14:34.550 --> 00:14:39.510\nThis is actually forcing encryption,\nand that's where that GPO setting\n\n291\n00:14:39.510 --> 00:14:43.315\nis coming into place is because it-\n&gt;&gt; For the authentication header,\n\n292\n00:14:43.315 --> 00:14:45.600\nthough, you don't have\nthat check self-enabled.\n\n293\n00:14:45.600 --> 00:14:48.680\n&gt;&gt; That's right, let me go ahead and\nshow you where, I believe,\n\n294\n00:14:48.680 --> 00:14:49.854\nthat was manipulated.\n\n295\n00:14:49.854 --> 00:14:53.760\nWe can actually control whether\nwe require authentication or not.\n\n296\n00:14:53.760 --> 00:14:56.380\nAnd that's one of the reasons\nthe GPO was giving me a warning,\n\n297\n00:14:56.380 --> 00:14:57.960\nsaying that some these settings, and\n\n298\n00:14:57.960 --> 00:15:01.440\ntypically these settings are gonna be\nmodified by your systems administrator.\n\n299\n00:15:01.440 --> 00:15:04.410\nWe go down into security settings.\n\n300\n00:15:04.410 --> 00:15:08.893\nAnd if we open up Windows Security,\nI believe I know what this is.\n\n301\n00:15:08.893 --> 00:15:12.564\nAnd I believe if we right-click on\nthe Firewall, and yes, here we go.\n\n302\n00:15:12.564 --> 00:15:16.420\nRight here, if you right-click in the GPO\non Firewall and you choose Properties.\n\n303\n00:15:17.590 --> 00:15:20.756\nAll right, notice that we have this\nsetting here, and these are really for\n\n304\n00:15:20.756 --> 00:15:23.590\nthe Domain Profile,\nPrivate Profile, Public Profile.\n\n305\n00:15:23.590 --> 00:15:27.480\nBut if you look I also have\nan IPsec setting here.\n\n306\n00:15:27.480 --> 00:15:32.385\nAnd I can almost guarantee you\nthat the setting's probably\n\n307\n00:15:32.385 --> 00:15:36.908\ngoing to require encryption for\nall communications.\n\n308\n00:15:36.908 --> 00:15:42.076\nAnd if I choose Customize here,\nI'm probably gonna guess that\n\n309\n00:15:42.076 --> 00:15:47.254\nthat's why this is forcing cyber\nblock chaining encryption.\n\n310\n00:15:47.254 --> 00:15:53.230\nAnd if I choose Customize, notice it says,\ndata protection in Quick Mode.\n\n311\n00:15:53.230 --> 00:15:55.834\nIf I choose Customize here I can\nalmost bet, yep, sure enough.\n\n312\n00:15:55.834 --> 00:15:59.217\nLook at that check mark right there,\nthat's why it's doing that, see?\n\n313\n00:15:59.217 --> 00:16:02.805\nRequire encryption for all connection\nsecurity rules using these settings.\n\n314\n00:16:02.805 --> 00:16:08.679\nSo Normally, had I not done due diligence,\n[LAUGH] I swear that's what it was,\n\n315\n00:16:08.679 --> 00:16:14.160\nand checked this off,\nESP would've said no encryption, right?\n\n316\n00:16:14.160 --> 00:16:15.820\nAnd what does that mean, all right?\n\n317\n00:16:15.820 --> 00:16:21.010\nThat means if I come down here and\nI fire up things like Wireshark, right,\n\n318\n00:16:21.010 --> 00:16:23.300\nI could potentially see the information.\n\n319\n00:16:23.300 --> 00:16:25.570\nSo let's go ahead and\nlet's capture a little bit of traffic.\n\n320\n00:16:25.570 --> 00:16:27.315\nLet me double check and\nsee if we're still pinging away here.\n\n321\n00:16:27.315 --> 00:16:28.120\n[LAUGH] There we go.\n\n322\n00:16:28.120 --> 00:16:31.635\nAnd let's go ahead and\nbring up Wire Shark and, yes,\n\n323\n00:16:31.635 --> 00:16:34.890\nI will allow it to go\ninto Promiscuous Mode.\n\n324\n00:16:34.890 --> 00:16:39.210\nAnd sure enough, notice that if we\npick up any one of these packets.\n\n325\n00:16:39.210 --> 00:16:41.520\nYou're gonna notice some\ninteresting information here.\n\n326\n00:16:41.520 --> 00:16:43.550\nNotice it says the ESP protocol?\n\n327\n00:16:43.550 --> 00:16:45.610\nAnd I can see\nEncapsulating Security Payload.\n\n328\n00:16:45.610 --> 00:16:48.220\nAnd interestingly enough,\nSPI, what does that mean?\n\n329\n00:16:48.220 --> 00:16:52.110\nThat's actually what's known as\na Security Parameter Index, okay?\n\n330\n00:16:52.110 --> 00:16:56.452\nWith a security association,\nyou have a this SPI and\n\n331\n00:16:56.452 --> 00:17:00.800\nit identifies that security association,\nright?\n\n332\n00:17:00.800 --> 00:17:04.090\nIt's what identifies it but\nyou also have sequencing.\n\n333\n00:17:04.090 --> 00:17:05.690\nSo what is the great thing about this?\n\n334\n00:17:05.690 --> 00:17:11.860\nWhat is the benefit of IP on top of things\nlike encryptions and confidentiality?\n\n335\n00:17:11.860 --> 00:17:16.120\nRight, Cherokee's mentioned this in\nanother episode, nonrepudiation, right?\n\n336\n00:17:16.120 --> 00:17:18.770\nI can't later say no that\nwasn't my communications,\n\n337\n00:17:18.770 --> 00:17:22.010\nright, because I have an SPI right here.\n\n338\n00:17:22.010 --> 00:17:25.780\nAnd if we're capturing or monitoring\ntraffic I can see what the outbound source\n\n339\n00:17:25.780 --> 00:17:28.960\nis and there's no way I can deny\nthat this wasn't my communication.\n\n340\n00:17:28.960 --> 00:17:31.280\nI had to initiate it through IP sec for\nit to even go on.\n\n341\n00:17:31.280 --> 00:17:34.040\nWell, what's the sequencing?\n\n342\n00:17:34.040 --> 00:17:38.033\nThe sequencing is so that the order of the\npacket is rebuilt in the right order and\n\n343\n00:17:38.033 --> 00:17:40.963\nwe don't have to worry about\nthings like replay attacks.\n\n344\n00:17:40.963 --> 00:17:45.660\nThese two settings really defend\nagainst replay attacks, because what\n\n345\n00:17:45.660 --> 00:17:51.050\nthey're saying is it has to be a part of\nthat SPI so we know who the endpoint is.\n\n346\n00:17:51.050 --> 00:17:53.546\nThe other thing says the sequencing\nin there says you know what\n\n347\n00:17:53.546 --> 00:17:54.363\nthe next packet is.\n\n348\n00:17:54.363 --> 00:17:58.253\nSo I can't steal a packet and\nthrow it back at somebody during an IPsec\n\n349\n00:17:58.253 --> 00:18:00.947\ncommunication because\nit's gonna look at it.\n\n350\n00:18:00.947 --> 00:18:02.726\nIt's gonna look at this information and\n\n351\n00:18:02.726 --> 00:18:05.140\nsay I don't know what the heck\nyou're talking about.\n\n352\n00:18:05.140 --> 00:18:07.340\nIt has none of this\ninformation that we need.\n\n353\n00:18:07.340 --> 00:18:09.789\nAnd if it does,\nthe sequence is way off, right?\n\n354\n00:18:09.789 --> 00:18:11.746\nWe moved on in the conversation.\n\n355\n00:18:11.746 --> 00:18:14.280\nDon't live in the yesterday.\n\n356\n00:18:14.280 --> 00:18:15.440\nLive in the now man.\n[LAUGH] So\n\n357\n00:18:15.440 --> 00:18:21.170\ngreat things that you can see here,\nand all of this communication.\n\n358\n00:18:21.170 --> 00:18:23.360\nYeah, you can see it's\nstill going on here, right.\n\n359\n00:18:23.360 --> 00:18:26.980\nWe've got our basic ARP communications\nthat are going on and stuff.\n\n360\n00:18:26.980 --> 00:18:29.690\nBut I've got all of that information\n\n361\n00:18:29.690 --> 00:18:33.060\njust firing away there over\nan IPsec Communication.\n\n362\n00:18:33.060 --> 00:18:35.950\nSo it's one of the things that I\nreally wanted to double back on,\n\n363\n00:18:35.950 --> 00:18:37.920\nI didn't wanna just kind\nof move on without it.\n\n364\n00:18:37.920 --> 00:18:42.780\nIt is something that you should be aware\nof, know the difference between as well.\n\n365\n00:18:42.780 --> 00:18:44.750\nTunnel mode and transport mode.\n\n366\n00:18:44.750 --> 00:18:47.989\nIP sec comes in two different modes and\nif you're using Gateway to Gateway\n\n367\n00:18:47.989 --> 00:18:51.766\ncommunications, you have two dedicated\nrouters that are providing the tunneling.\n\n368\n00:18:51.766 --> 00:18:55.215\nAll right, so that's what you're\ngonna use, you'll use tunnel mode,\n\n369\n00:18:55.215 --> 00:18:58.060\nyou'll use Gateway Way to\nGateway communications.\n\n370\n00:18:58.060 --> 00:19:00.060\nIf you have a remote\naccess communication or\n\n371\n00:19:00.060 --> 00:19:04.640\nin this case you've got two machines\nthat aren't gateway routers,\n\n372\n00:19:04.640 --> 00:19:07.830\nthen what they are going to use is\nthey are going to use transport mode.\n\n373\n00:19:07.830 --> 00:19:09.980\nRight, that's end point to\nend point communication.\n\n374\n00:19:09.980 --> 00:19:13.772\nSo couple things that we definitely\nneeded to look at there.\n\n375\n00:19:13.772 --> 00:19:17.020\nAll right so IP set communications\nas a wrap up on that one.\n\n376\n00:19:17.020 --> 00:19:20.640\nJust remember it's not one technology\nthat allows you to encrypt and\n\n377\n00:19:20.640 --> 00:19:22.420\nsecure your communications.\n\n378\n00:19:22.420 --> 00:19:26.710\nIt's actually a whole bunch of security\nprotocols that are all holding hands,\n\n379\n00:19:26.710 --> 00:19:29.570\nhelping you protect your communications.\n\n380\n00:19:29.570 --> 00:19:32.500\n&gt;&gt; All right Wes, so what particular\ntopic are we gonna look at next?\n\n381\n00:19:32.500 --> 00:19:34.930\n&gt;&gt; The next one we're gonna\nlook at are proxies, and\n\n382\n00:19:34.930 --> 00:19:38.000\nproxies can sometimes be\na little confusing we gotta say.\n\n383\n00:19:38.000 --> 00:19:40.560\nSo what is a proxy, all right?\n\n384\n00:19:40.560 --> 00:19:43.330\nA proxy is a middle man.\n\n385\n00:19:43.330 --> 00:19:45.230\nThat's what a proxy is, essentially.\n\n386\n00:19:45.230 --> 00:19:48.200\nIt is something, it is an entity or\n\n387\n00:19:48.200 --> 00:19:54.260\na component that makes a request for\na resource on behalf of another endpoint.\n\n388\n00:19:54.260 --> 00:19:55.950\nAll right, and\nthey can help us with security.\n\n389\n00:19:55.950 --> 00:19:59.990\nIn fact I've got they call out a couple of\ndifferent kinds, of proxy's, they call out\n\n390\n00:19:59.990 --> 00:20:03.750\nwhat's known as a forward proxy and what's\nknown as a reverse proxy, all right.\n\n391\n00:20:03.750 --> 00:20:04.420\nLet's go ahead and\n\n392\n00:20:04.420 --> 00:20:07.450\nthe first one I've got here is what's\nknown as a forward proxy, all right?\n\n393\n00:20:07.450 --> 00:20:11.890\nThese are really good in the fact that it\ngives the administrator the ability to\n\n394\n00:20:11.890 --> 00:20:16.620\ncontrol what level of access people have\nat out bound to the Internet, right?\n\n395\n00:20:16.620 --> 00:20:18.920\nIt also allows them to\ndo things like auditing,\n\n396\n00:20:20.160 --> 00:20:22.540\ncaching to improve performance as well.\n\n397\n00:20:22.540 --> 00:20:25.750\nBut notice that we've got a bunch\nof internal clients, right?\n\n398\n00:20:25.750 --> 00:20:29.991\nAnd they're all communicating with\nthe proxy making web requests, right?\n\n399\n00:20:29.991 --> 00:20:34.350\nI need to go to www.anysite.com.\n\n400\n00:20:34.350 --> 00:20:37.030\nSo what the proxy does is it sits inline.\n\n401\n00:20:37.030 --> 00:20:39.724\nIt doesn't really intercept but\nit takes the request.\n\n402\n00:20:39.724 --> 00:20:41.340\n&gt;&gt; It's not replacing.\n\n403\n00:20:41.340 --> 00:20:42.610\n&gt;&gt; That's right, it doesn't replace.\n\n404\n00:20:42.610 --> 00:20:44.400\nGood point, doesn't replace.\n\n405\n00:20:44.400 --> 00:20:48.260\nIt takes the request,\nit kind of caches it, it bookmarks it,\n\n406\n00:20:48.260 --> 00:20:49.960\nputs it in a little database.\n\n407\n00:20:49.960 --> 00:20:55.100\nIt generates a completely new request\nsends it through your firewall\n\n408\n00:20:55.100 --> 00:21:00.030\nout across the Internet to whatever it is,\nwww.anysite.org.\n\n409\n00:21:00.030 --> 00:21:03.980\nAll right,\nnow when this web server responds back,\n\n410\n00:21:03.980 --> 00:21:08.140\nit only sees the IP address of the proxy.\n\n411\n00:21:08.140 --> 00:21:12.299\nAll right, so just like in network address\ntranslation we talked about another,\n\n412\n00:21:12.299 --> 00:21:15.021\nit's security through,\n&gt;&gt; Obscurity.\n\n413\n00:21:15.021 --> 00:21:16.300\n&gt;&gt; Obscurity, thank you.\n\n414\n00:21:16.300 --> 00:21:18.330\nMy gosh I can never get that word right.\n\n415\n00:21:19.580 --> 00:21:21.923\nThe reason we say that is because\nyou could peel back the layers and\n\n416\n00:21:21.923 --> 00:21:24.231\ntechnically see the IP address\nif somebody was really looking.\n\n417\n00:21:24.231 --> 00:21:28.760\nBut what this does it doesn't even look\nlike the internal client even made\n\n418\n00:21:28.760 --> 00:21:30.440\nthe request, right?\n\n419\n00:21:30.440 --> 00:21:32.230\nTo the outbound world, right?\n\n420\n00:21:32.230 --> 00:21:36.267\nTo the outside world these inside\ncomputers they don't even exist.\n\n421\n00:21:36.267 --> 00:21:40.330\nLet's see what the heck is going on\nwith my, there we go, there it is.\n\n422\n00:21:41.950 --> 00:21:44.910\nI am moving the world one\nfinger at a time there.\n\n423\n00:21:44.910 --> 00:21:48.870\nOkay, so internal clients don't\neven exist to the outside world.\n\n424\n00:21:48.870 --> 00:21:54.230\nAnd again keep in mind that the forward\nproxy allows for us to do auditing, right?\n\n425\n00:21:54.230 --> 00:21:58.360\nSo, if your system administrator says no,\n\n426\n00:21:58.360 --> 00:22:01.480\nI don't want this internal client\nbeing able to access the Internet.\n\n427\n00:22:01.480 --> 00:22:05.170\nAnd more specifically, maybe I don't want\nsomebody just going up to this computer,\n\n428\n00:22:05.170 --> 00:22:08.020\nand then sending an Internet request,\nor a web request outside.\n\n429\n00:22:08.020 --> 00:22:09.340\nSo what do we do, right?\n\n430\n00:22:09.340 --> 00:22:10.350\nYou can do blocking, right?\n\n431\n00:22:10.350 --> 00:22:11.276\nWe can do content filtering.\n\n432\n00:22:11.276 --> 00:22:12.358\n&gt;&gt; Sure.\n&gt;&gt; There are-\n\n433\n00:22:12.358 --> 00:22:13.299\n&gt;&gt; Especially schools.\n\n434\n00:22:13.299 --> 00:22:15.390\n&gt;&gt; Yes, most definitely.\n\n435\n00:22:15.390 --> 00:22:17.410\nSo for instance,\nthings like online gambling.\n\n436\n00:22:17.410 --> 00:22:20.220\nAll right In some sates,\nI don't know what states, but\n\n437\n00:22:20.220 --> 00:22:21.640\nin some states I know that it's illegal.\n\n438\n00:22:21.640 --> 00:22:23.073\nYou can't even visit those sites.\n\n439\n00:22:23.073 --> 00:22:26.960\nBut those sites might not be in that\nstate, they might be in another state.\n\n440\n00:22:26.960 --> 00:22:30.170\nSo you have web access to it and that\ngives the administrator the ability to do\n\n441\n00:22:30.170 --> 00:22:34.310\nthings like URL filtering, content\nfiltering, all on the proxy itself.\n\n442\n00:22:35.310 --> 00:22:39.460\nSo if that's a forward proxy,\nwhat's a reverse proxy?\n\n443\n00:22:39.460 --> 00:22:41.260\nThis is where it gets a little tricky.\n\n444\n00:22:41.260 --> 00:22:43.860\nAll right, I want you to notice\nthe direction here, all right?\n\n445\n00:22:43.860 --> 00:22:46.414\nNotice where the firewall is, and\nnotice where the communications are going.\n\n446\n00:22:46.414 --> 00:22:50.210\n&gt;&gt; Where that flow of traffic\ninitiated internally, last time.\n\n447\n00:22:50.210 --> 00:22:53.050\nWe're kind of reversing that,\nhence, reverse proxy?\n\n448\n00:22:53.050 --> 00:22:56.270\n&gt;&gt; Yes, ma'am, absolutely, and\nit's one that you might have to look at.\n\n449\n00:22:56.270 --> 00:22:58.670\nI'm not trying to get you\nguys motion sick out here.\n\n450\n00:22:58.670 --> 00:23:00.360\nBut look where we're at, right?\n\n451\n00:23:00.360 --> 00:23:04.030\nThe forward proxy is on the inside\nof our firewall, right?\n\n452\n00:23:04.030 --> 00:23:05.480\nRestricting communication, or\n\n453\n00:23:05.480 --> 00:23:09.430\njust intercepting communication\nfrom everybody inside.\n\n454\n00:23:09.430 --> 00:23:13.069\nThe reverse proxy is the way we can do,\nkind of like poor-man's load balancing,\n\n455\n00:23:13.069 --> 00:23:13.610\nif we want.\n\n456\n00:23:13.610 --> 00:23:16.100\nRemember, notice that we\nhave external clients.\n\n457\n00:23:16.100 --> 00:23:19.880\nThey're all communicating, and they're\ncommunicating with the reverse proxy.\n\n458\n00:23:19.880 --> 00:23:23.360\nAnd then it can dictate which\nserver you're going to.\n\n459\n00:23:23.360 --> 00:23:24.950\nMaybe you have a cluster of servers,\nright?\n\n460\n00:23:24.950 --> 00:23:27.620\nThat are doing some kind\nof web communication, or\n\n461\n00:23:27.620 --> 00:23:29.660\na service on the inside of your network.\n\n462\n00:23:29.660 --> 00:23:32.990\nSo notice that the reverse proxy,\njust like Cherokee said,\n\n463\n00:23:32.990 --> 00:23:36.390\nthe flow of the communication\nhas been reversed.\n\n464\n00:23:36.390 --> 00:23:39.040\nNow, there are other types of\nproxies out there as well.\n\n465\n00:23:39.040 --> 00:23:41.770\nThere are proxies like\ntransparent proxies.\n\n466\n00:23:41.770 --> 00:23:44.950\nNow transparent proxy is one\nyou'll never know about.\n\n467\n00:23:44.950 --> 00:23:45.870\nCase dismissed.\n\n468\n00:23:45.870 --> 00:23:47.334\nNo, not technically.\n\n469\n00:23:47.334 --> 00:23:49.436\nI want you to think of a situation.\n\n470\n00:23:49.436 --> 00:23:53.712\nIn fact, I can probably force you guys\nto kind of see it on these machines.\n\n471\n00:23:53.712 --> 00:23:57.698\nIn fact let me go ahead, I'm gonna\nstroll off the beaten path here and\n\n472\n00:23:57.698 --> 00:24:01.221\nLast minute change of plans\nalways works straight, right?\n\n473\n00:24:01.221 --> 00:24:04.700\n[LAUGH] So let me go ahead and\nI wanna give this machine public access.\n\n474\n00:24:04.700 --> 00:24:07.970\nBecause one of the things I know that\nthis Windows 10 machine probably gonna\n\n475\n00:24:07.970 --> 00:24:12.450\ndo the moment I give a Internet access,\nis it's gonna check Windows Updates.\n\n476\n00:24:12.450 --> 00:24:15.845\nNow, normally I'm might not\nwant that to happen [LAUGH] in\n\n477\n00:24:15.845 --> 00:24:20.655\nthe middle of a show because of the fact\nthat well, anytime you update a machine,\n\n478\n00:24:20.655 --> 00:24:23.435\nit could cause some\nperformance delay there.\n\n479\n00:24:23.435 --> 00:24:25.040\nBut we're gonna go ahead and\nwe're gonna do this.\n\n480\n00:24:25.040 --> 00:24:28.220\nWhat I wanna do is do a NS lookup.\n\n481\n00:24:28.220 --> 00:24:32.380\nOr excuse me, lets go ahead and do CMD and\n\n482\n00:24:32.380 --> 00:24:35.080\nwe're gonna look at our\nlocal resolver cache.\n\n483\n00:24:35.080 --> 00:24:40.977\nI'm gonna do a ipconfig\nforward/display DNS.\n\n484\n00:24:40.977 --> 00:24:42.240\nAnd you know it's not doing that.\n\n485\n00:24:42.240 --> 00:24:48.390\nLet me make sure, then I have\nthat set up right, one more time.\n\n486\n00:24:50.430 --> 00:24:54.540\nSee, and again, this is why you\ndon't do things on the fly, but\n\n487\n00:24:54.540 --> 00:24:59.770\nmaybe I can salvage it here, all right.\n\n488\n00:24:59.770 --> 00:25:00.660\nI'll tell you what?\n\n489\n00:25:00.660 --> 00:25:01.630\nI know how I can do this.\n\n490\n00:25:01.630 --> 00:25:04.390\nI wanna show you guys because,\nsee, content, and\n\n491\n00:25:04.390 --> 00:25:06.060\nwhile I'm setting this up\nlet me go ahead and explain.\n\n492\n00:25:06.060 --> 00:25:11.226\nSee things like content distribution\nnetworks, when you do a Windows update,\n\n493\n00:25:11.226 --> 00:25:16.639\nthere you go, we'll check for updates,\nthat should force the cache, all right.\n\n494\n00:25:16.639 --> 00:25:19.415\n&gt;&gt; All right, Wes, you mentioned\ncontent distributed network, but\n\n495\n00:25:19.415 --> 00:25:20.750\nwhat does that mean?\n\n496\n00:25:20.750 --> 00:25:25.410\n&gt;&gt; Well, if you think about it,\ncompanies can have the need, if you will,\n\n497\n00:25:25.410 --> 00:25:30.380\nthe necessity to deliver a lot\nof traffic to endpoints, right?\n\n498\n00:25:30.380 --> 00:25:34.291\nBut maybe they don't want their\ncustomers to go all the way across or\n\n499\n00:25:34.291 --> 00:25:38.347\naround the world to their network\nto get things like updates, right?\n\n500\n00:25:38.347 --> 00:25:40.233\nWindows updates is an example, right?\n\n501\n00:25:40.233 --> 00:25:41.406\nThey use Acome.\n\n502\n00:25:41.406 --> 00:25:44.988\nAcome is a Content Distributed Network,\nCDN if you will,\n\n503\n00:25:44.988 --> 00:25:49.313\nthat you're really pulling a lot\nof your updates from Acome, right?\n\n504\n00:25:49.313 --> 00:25:52.919\nAnd that's because Microsoft knows that\nall of these millions of computers,\n\n505\n00:25:52.919 --> 00:25:56.688\nhundreds of millions of computers around\nthe world are gonna have to do updates and\n\n506\n00:25:56.688 --> 00:25:59.710\nthey certainly don't want them\nhitting their network, right?\n\n507\n00:25:59.710 --> 00:26:01.590\nThe performance would be horrible.\n\n508\n00:26:01.590 --> 00:26:05.946\nSo, what they do is they have content\ndistribution networks that sit closer to\n\n509\n00:26:05.946 --> 00:26:10.376\nthe body of computers that are gonna need\nupdated, and you actually go to them.\n\n510\n00:26:10.376 --> 00:26:12.260\nAnd you're not even aware\nthat it's happening.\n\n511\n00:26:12.260 --> 00:26:16.950\nAnd that's an example of where\na transparent proxy comes in, right?\n\n512\n00:26:16.950 --> 00:26:20.240\nYou're hitting Windows update, but\nyou're not going to their servers.\n\n513\n00:26:20.240 --> 00:26:23.860\nYou're going to a proxy that is\nnow giving you the updates and\n\n514\n00:26:23.860 --> 00:26:25.830\nit is transparent to you.\n\n515\n00:26:25.830 --> 00:26:29.980\nSo let me see if I can give\nyou an example of this here.\n\n516\n00:26:29.980 --> 00:26:35.960\nSo on my computer here, I'm gonna do\nan IP config will do a display DNS again.\n\n517\n00:26:37.560 --> 00:26:41.980\nAnd it looks like, yeah it doesn't look\nlike it's actually in the cache right now.\n\n518\n00:26:41.980 --> 00:26:45.501\nLet me try this one more time,\nlet's see if we can force an update here\n\n519\n00:26:47.606 --> 00:26:50.440\nAll right, so\nit looks like it's checking for updates.\n\n520\n00:26:50.440 --> 00:26:51.670\nWe'll find out here in a second.\n\n521\n00:26:51.670 --> 00:26:55.710\nLet me rerun that display DNS and\nshould take there we go.\n\n522\n00:26:55.710 --> 00:26:58.720\nAll right, notice that we have\nthese computers right here and\n\n523\n00:26:58.720 --> 00:27:02.700\nnow what's first happening is I'm actually\nhitting Microsoft's website, right?\n\n524\n00:27:02.700 --> 00:27:05.137\nYou pull down a little meta data and\nit compares.\n\n525\n00:27:05.137 --> 00:27:07.890\nWell, are you up to date or not?\n\n526\n00:27:07.890 --> 00:27:12.340\nAnd then essentially or eventually what\nit should do is throw me over to, and\n\n527\n00:27:12.340 --> 00:27:16.370\nit's not doing it right now, so\nwe'll have to save that for another time.\n\n528\n00:27:16.370 --> 00:27:21.585\nYeah, it doesn't look like it's actually\ndoing it, but if you did an ipconfig /\n\n529\n00:27:21.585 --> 00:27:26.743\ndisplay DNS after you run this, you would\nsee a whole bunch of websites in there.\n\n530\n00:27:26.743 --> 00:27:29.810\nThat or\nhost names in there that aren't Microsoft.\n\n531\n00:27:29.810 --> 00:27:33.000\nAnd what it's doing it's transparently\nsending you to that proxy\n\n532\n00:27:33.000 --> 00:27:34.800\nof the content distribution network so\n\n533\n00:27:34.800 --> 00:27:38.410\nthat you can download your\nupdates closer to where you are.\n\n534\n00:27:38.410 --> 00:27:41.500\nRather than having to say, let's go all\nthe way out to Washington, out to Redmond,\n\n535\n00:27:41.500 --> 00:27:44.060\nand pull them down,\neven if that is where they're located.\n\n536\n00:27:44.060 --> 00:27:46.990\nBut it looks like we're up to date,\nso this machine isn't really\n\n537\n00:27:46.990 --> 00:27:51.480\ngonna help us out there, so that's\na little bit about the transparent proxy.\n\n538\n00:27:51.480 --> 00:27:53.300\nI know we're running short on time here.\n\n539\n00:27:53.300 --> 00:27:55.370\nBut there is a couple other things.\n\n540\n00:27:55.370 --> 00:27:57.680\nOne other thing that I wanna make sure\nthat I mention here when it comes to\n\n541\n00:27:57.680 --> 00:27:58.580\nproxies.\n\n542\n00:27:58.580 --> 00:28:02.180\nAnd you also have multipurpose proxies and\napplication proxies too.\n\n543\n00:28:02.180 --> 00:28:04.760\nIf you have some kind of\ndedicated application and\n\n544\n00:28:04.760 --> 00:28:07.700\nyou want users to not have to go into\nyour internal network to get it,\n\n545\n00:28:07.700 --> 00:28:10.180\nyou can use things like\napplication Proxies.\n\n546\n00:28:10.180 --> 00:28:12.680\n&gt;&gt; Alright, that is a lot of\ninformation just focusing at\n\n547\n00:28:12.680 --> 00:28:15.490\naround one particular piece of hardware.\n\n548\n00:28:15.490 --> 00:28:17.640\nHere, in this situation, proxy servers.\n\n549\n00:28:17.640 --> 00:28:20.160\nBut stay tuned, we do have more\ninformation heading your way.\n\n550\n00:28:20.160 --> 00:28:22.180\nFor this show,\nwe'll go ahead and sign out.\n\n551\n00:28:22.180 --> 00:28:23.750\nRemember, I'm your host, Cherokee Booze.\n\n552\n00:28:23.750 --> 00:28:24.440\n&gt;&gt; And I'm Wes Bryan.\n\n553\n00:28:24.440 --> 00:28:26.461\n&gt;&gt; See you next time here at ITProTV.\n\n554\n00:28:27.649 --> 00:28:33.540\n[MUSIC]\n\n555\n00:28:33.540 --> 00:28:36.725\nThank you for watching ITProTV.\n\n",
          "vimeoId": "213513313"
        },
        {
          "description": "In this episode, Cherokee and Wes begin discussing why one may want to use load balancing and the many ways it can be implemented. They also cover topics such as access points, Security Information and Event Management systems (SIEM), and Data Loss/Leakage Prevention (DLP) techniques.",
          "length": "1800",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-3-hardware_software_organizational_sec_pt3-040717-PGM.00_29_45_26.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-3-hardware_software_organizational_sec_pt3-040717-PGM.00_29_45_26.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-3-hardware_software_organizational_sec_pt3-040717-PGM.00_29_45_26.Still001-sm.jpg",
          "title": "Hardware Software Organizational Security Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:02.680\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.680 --> 00:00:06.368\n[CROSSTALK]\n\n3\n00:00:06.368 --> 00:00:12.148\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.148 --> 00:00:14.770\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n5\n00:00:14.770 --> 00:00:16.630\nI'm your show host Cherokee Boose.\n\n6\n00:00:16.630 --> 00:00:18.370\nThis is a continuation of part three,\n\n7\n00:00:18.370 --> 00:00:22.890\nwhere we are examining the relationship\nbetween hardware and software, well,\n\n8\n00:00:22.890 --> 00:00:26.250\nreally between the organization and\nhow it affects overall security.\n\n9\n00:00:26.250 --> 00:00:28.730\nAnd with us today, we have Mr.\nWes Bryan in studios.\n\n10\n00:00:28.730 --> 00:00:29.840\nThank you for joining us, Wes.\n\n11\n00:00:29.840 --> 00:00:31.320\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n12\n00:00:31.320 --> 00:00:35.810\nYeah, this has been a fun mini series\nwe're working on right now, because there\n\n13\n00:00:35.810 --> 00:00:40.050\nare a lot of components that really do\nhelp the overall organizational security.\n\n14\n00:00:40.050 --> 00:00:44.090\nSo we're just gonna continue on here and\ncontinue on the beaten path.\n\n15\n00:00:44.090 --> 00:00:47.780\nAnd hopefully it'll bring you a little bit\ncloser to clarity and understanding for\n\n16\n00:00:47.780 --> 00:00:50.230\nthe Security+ exam.\n\n17\n00:00:50.230 --> 00:00:52.820\nNow the last thing we left off with.\n\n18\n00:00:52.820 --> 00:00:54.530\nWe've been talking about\nmany different things.\n\n19\n00:00:54.530 --> 00:00:57.140\nWe've been talking about things\nlike VPN communications,\n\n20\n00:00:57.140 --> 00:01:01.140\nfirewalls, IPSEC communications as well.\n\n21\n00:01:01.140 --> 00:01:04.880\nWe're gonna go ahead and one of the first\nthings that we're gonna talk about in this\n\n22\n00:01:04.880 --> 00:01:08.260\nepisode is we're gonna\ntalk about load balancers.\n\n23\n00:01:08.260 --> 00:01:11.570\nBecause load balancers\nare a very important part\n\n24\n00:01:11.570 --> 00:01:13.870\nof our organizational\ncommunications today.\n\n25\n00:01:13.870 --> 00:01:18.210\nSo I got a diagram here,\n\n26\n00:01:18.210 --> 00:01:21.920\nlet's talk about what's going on\nwhen we talk about load balancers.\n\n27\n00:01:21.920 --> 00:01:26.210\nA load balancer, what it does is\nit distributes the workload of\n\n28\n00:01:26.210 --> 00:01:29.230\nproviding services between\nmultiple machines.\n\n29\n00:01:29.230 --> 00:01:31.880\nYou can have things like web clusters,\nif you will.\n\n30\n00:01:31.880 --> 00:01:34.922\nYou can have things like for instance,\nmultiple services on your network,\n\n31\n00:01:34.922 --> 00:01:37.690\nyou might only have a single\npipeline into your network.\n\n32\n00:01:38.780 --> 00:01:44.160\nIf that be the case then, one system\nmight get overloaded a little bit.\n\n33\n00:01:44.160 --> 00:01:48.290\nYou might want things like for instance\nredundancy as well, and the load balancer\n\n34\n00:01:48.290 --> 00:01:54.140\ncan help to distribute the workload\nthat's coming in across multiple devices.\n\n35\n00:01:54.140 --> 00:01:59.190\nNow, there are some techniques that\nthey implement in order to perform this.\n\n36\n00:01:59.190 --> 00:02:02.060\nFor instance, they have scheduling.\n\n37\n00:02:02.060 --> 00:02:07.270\nScheduling is, how is the host,\nthe person, or the endpoint\n\n38\n00:02:07.270 --> 00:02:10.870\nthat you're trying to communicate with,\nhow is it gonna be chosen?\n\n39\n00:02:10.870 --> 00:02:15.680\nWe also have things like affinity,\nalso known as server affinity,\n\n40\n00:02:15.680 --> 00:02:18.550\nsession affinity as well.\n\n41\n00:02:18.550 --> 00:02:21.020\nAnd we have things like for\ninstance virtual IP.\n\n42\n00:02:21.020 --> 00:02:24.150\nSo it's kinda interesting that when\nyou look at a network load balancer,\n\n43\n00:02:24.150 --> 00:02:28.740\nthis virtual IP address is what\neverybody else is communicating with.\n\n44\n00:02:28.740 --> 00:02:33.100\nIf we do something like a DNS request,\nit's really the service request that\n\n45\n00:02:33.100 --> 00:02:36.990\nare gonna get attached to\nthe end this public IP address.\n\n46\n00:02:36.990 --> 00:02:40.680\nAnd then it's up to\nthe load balancer to choose\n\n47\n00:02:40.680 --> 00:02:43.230\non the internal network where\nthat information is sent.\n\n48\n00:02:43.230 --> 00:02:48.360\nSo notice that we have the same exact IP\naddress, this is a virtual IP address.\n\n49\n00:02:48.360 --> 00:02:52.220\nNotice that the public IP address\nof the network load balancer\n\n50\n00:02:52.220 --> 00:02:53.210\nis completely different.\n\n51\n00:02:54.240 --> 00:02:59.190\nWell, this is a technique that allows us\nto have this virtualized, if you will,\n\n52\n00:02:59.190 --> 00:03:04.120\nIP address that everybody communicate with\nthat isn't tied to a specific network\n\n53\n00:03:04.120 --> 00:03:08.420\nload balancer or even for that matter,\ntied to any internal host.\n\n54\n00:03:08.420 --> 00:03:11.350\nAnd this is a great thing because\nwhat happens if this network load\n\n55\n00:03:11.350 --> 00:03:13.260\nbalancer goes offline?\n\n56\n00:03:13.260 --> 00:03:16.930\nWell, if I was using\nthis public IP address,\n\n57\n00:03:16.930 --> 00:03:18.770\nno more communications would happen.\n\n58\n00:03:18.770 --> 00:03:20.820\nAll of these service requests up here,\n\n59\n00:03:20.820 --> 00:03:26.140\nif it happened to be 0.20 at the end, no\nlonger could they provide the resources.\n\n60\n00:03:26.140 --> 00:03:28.200\nAnd remember, in security,\nwell, you might say, well,\n\n61\n00:03:28.200 --> 00:03:30.220\nwhy is a load balancer about security?\n\n62\n00:03:30.220 --> 00:03:33.630\nWell, don't forget the A in the CIA triad,\nright, it's about availability.\n\n63\n00:03:33.630 --> 00:03:36.790\nAuthorized users must have\naccess to the services that\n\n64\n00:03:36.790 --> 00:03:39.354\nthey are supposed to have access to.\n\n65\n00:03:39.354 --> 00:03:44.230\nSo by implementing\na virtual IP address this\n\n66\n00:03:44.230 --> 00:03:48.910\nkind of masks what the actual addresses\nof the network load balancer are.\n\n67\n00:03:48.910 --> 00:03:50.981\nAnd let's say I need to\ndo servicing on one, or\n\n68\n00:03:50.981 --> 00:03:54.430\nlet's say we decide that we're gonna\nput a better load balancer in here.\n\n69\n00:03:54.430 --> 00:03:58.220\nWell, guess what, I can bring\nthis machine completely off line,\n\n70\n00:03:58.220 --> 00:04:00.960\nbreak half of my slide in the process,\nright.\n\n71\n00:04:00.960 --> 00:04:05.260\nBut I'm not worried about this IP address\nbecause they're still communicating.\n\n72\n00:04:05.260 --> 00:04:09.110\nThe outside world is still\ncommunicating with this IP address.\n\n73\n00:04:09.110 --> 00:04:13.000\nAnd once that network load\nbalancer is brought back online,\n\n74\n00:04:13.000 --> 00:04:15.630\nyour end users were none the wiser.\n\n75\n00:04:15.630 --> 00:04:19.140\nSo that's another good thing is\nthe fact that you have transparency.\n\n76\n00:04:19.140 --> 00:04:21.940\nSo understand what\nthe virtual IP address is.\n\n77\n00:04:21.940 --> 00:04:25.600\nThe virtual IP address is an IP address\nthat they're gonna communicate with,\n\n78\n00:04:25.600 --> 00:04:28.400\nthe outside world will communicate\nwith in order to get to\n\n79\n00:04:28.400 --> 00:04:29.830\nthe resources that they need.\n\n80\n00:04:29.830 --> 00:04:34.680\nAnd then it's up to the configuration\nof the network load balancer\n\n81\n00:04:34.680 --> 00:04:39.010\non how that is actually\nchosen on the inside network.\n\n82\n00:04:39.010 --> 00:04:41.790\nNow, there's also some other\nconfigurations that I want you to be aware\n\n83\n00:04:41.790 --> 00:04:43.420\nof when it comes to\nnetwork load balancers.\n\n84\n00:04:43.420 --> 00:04:50.810\nThey talk about things like active and\npassive, and active active.\n\n85\n00:04:50.810 --> 00:04:54.340\nThis is a technique that is not just used\non things like network load balancers,\n\n86\n00:04:54.340 --> 00:04:57.350\nit's also used when you\nhave things like clusters.\n\n87\n00:04:57.350 --> 00:05:01.139\nLike we have a web application,\nand it is that application and\n\n88\n00:05:01.139 --> 00:05:04.970\nits workload is spread out\nacross multiple servers, well,\n\n89\n00:05:04.970 --> 00:05:08.300\nwe don't need the IP address to\nevery single individual server.\n\n90\n00:05:08.300 --> 00:05:12.540\nBut what we need to make sure is that\nthe network cards if you will, that are in\n\n91\n00:05:12.540 --> 00:05:16.930\nthe cluster that are responding, which\nones are gonna be performing the work.\n\n92\n00:05:16.930 --> 00:05:20.310\nSo let me go ahead and\nkinda show you more visually here.\n\n93\n00:05:20.310 --> 00:05:24.120\nLet's take our network load balancers and\nfor instance,\n\n94\n00:05:24.120 --> 00:05:25.950\nin web clustering it\ncould be network adapter,\n\n95\n00:05:25.950 --> 00:05:29.470\njust the network adapters,\nthat you have that are active or passive.\n\n96\n00:05:29.470 --> 00:05:33.650\nIn this instance what we are talking\nabout is, do you have two load balancers?\n\n97\n00:05:33.650 --> 00:05:34.410\nAnd if you have two or\n\n98\n00:05:34.410 --> 00:05:37.040\nmore load balancers,\nwhich ones are performing the workload?\n\n99\n00:05:37.040 --> 00:05:38.008\n&gt;&gt; Are they gonna react and\n\n100\n00:05:38.008 --> 00:05:40.290\nit really boils down to those\nquorum settings, right?\n\n101\n00:05:40.290 --> 00:05:41.170\n&gt;&gt; That's right.\n\n102\n00:05:41.170 --> 00:05:46.250\nSo if we look at things like\nactive-passive, that means that a 100% of\n\n103\n00:05:46.250 --> 00:05:51.890\nthe workload is in this case being\nhandled by network load balancer 1.\n\n104\n00:05:51.890 --> 00:05:53.480\nNotice that in a passive setting,\n\n105\n00:05:53.480 --> 00:05:57.675\nright, you're network load balancer 2,\nit's just standing by waiting.\n\n106\n00:05:57.675 --> 00:05:59.390\nNow, that's for\n\n107\n00:05:59.390 --> 00:06:03.700\na little bit of fault tolerance versus\nsomething that is like active, active.\n\n108\n00:06:03.700 --> 00:06:07.890\nNow we have 50% of the workload,\nnow these numbers can be adjusted too.\n\n109\n00:06:07.890 --> 00:06:12.140\nI'm just kinda using this just for\nexplanation.\n\n110\n00:06:12.140 --> 00:06:15.691\nBecause maybe I want one to\nsupport 80% of the workload, and\n\n111\n00:06:15.691 --> 00:06:18.400\none does an 80/20 configuration.\n\n112\n00:06:18.400 --> 00:06:23.040\nBut notice that in active, active,\nwe got 50% of the work load on\n\n113\n00:06:23.040 --> 00:06:27.920\nnetwork load balancer 1, and we got 50% of\nthe work load on network load balancer 2.\n\n114\n00:06:29.010 --> 00:06:30.760\nNow there's a problem with this,\n\n115\n00:06:30.760 --> 00:06:35.610\nif one of these fails, it's-\n&gt;&gt; May the other device be able to\n\n116\n00:06:35.610 --> 00:06:37.000\npick up the slack for the other one?\n\n117\n00:06:37.000 --> 00:06:38.938\nThat's the question that\nyou kind of wonder about.\n\n118\n00:06:38.938 --> 00:06:42.520\nSo if stability is more\nof an important issue for\n\n119\n00:06:42.520 --> 00:06:45.660\nyour organization,\nyou might wanna go with active passive so\n\n120\n00:06:45.660 --> 00:06:49.320\nthat if one of those devices were\nto fail the other one picks up.\n\n121\n00:06:49.320 --> 00:06:52.520\nAnd it's just kind of seamless,\nyou might notice the little blip.\n\n122\n00:06:52.520 --> 00:06:55.860\nBut you're not gonna have\nany noticeable outcome.\n\n123\n00:06:55.860 --> 00:06:57.990\n&gt;&gt; Most definitely,\nbecause just like Cherokee said,\n\n124\n00:06:57.990 --> 00:07:01.554\nwhat happens if one of these\ngoes to 100% workload?\n\n125\n00:07:01.554 --> 00:07:03.550\nCan it perform the way you want?\n\n126\n00:07:03.550 --> 00:07:07.270\nWell, maybe, maybe it can't, so that's\nsomething that you have to consider.\n\n127\n00:07:07.270 --> 00:07:10.430\nNow, when we talk about\nthings like active standby or\n\n128\n00:07:10.430 --> 00:07:14.430\nactive passive, now we talk about\na little bit more redundancy.\n\n129\n00:07:14.430 --> 00:07:15.640\nBecause what happens here,\n\n130\n00:07:15.640 --> 00:07:20.450\nis that when network load balancer 1\nfails, we have a complete failure.\n\n131\n00:07:20.450 --> 00:07:22.860\nThen the one that's on\nstandby comes online and\n\n132\n00:07:22.860 --> 00:07:24.850\nit takes over 100% of the workload.\n\n133\n00:07:24.850 --> 00:07:29.510\nNow, there again, that's gonna take some\nresearch on your part to understand then,\n\n134\n00:07:29.510 --> 00:07:34.930\ncan a single load balancer perform\nthe task that you need it to perform?\n\n135\n00:07:34.930 --> 00:07:37.620\nMaybe it can, maybe it can't, maybe it\ndoesn't have that computational power,\n\n136\n00:07:37.620 --> 00:07:39.160\nthe resources inside of it.\n\n137\n00:07:39.160 --> 00:07:42.110\nAnd you might notice the performance\ndegradation, or maybe you don't.\n\n138\n00:07:42.110 --> 00:07:46.482\nSo it is up to you to do the research\nto ensure that if you do\n\n139\n00:07:46.482 --> 00:07:50.299\ngo to an active-active or\nan active-passive,\n\n140\n00:07:50.299 --> 00:07:55.805\nthat one machine can do the workload\nif needed in a failure situation.\n\n141\n00:07:55.805 --> 00:07:58.262\nSo some of the other\nthings that they call out,\n\n142\n00:07:58.262 --> 00:08:02.483\nwe couldn't go anywhere in organizational\nsecurity if we didn't talk a little\n\n143\n00:08:02.483 --> 00:08:05.322\nbit about Things like our\nwireless communications.\n\n144\n00:08:05.322 --> 00:08:07.225\nNow wireless communications,\n\n145\n00:08:07.225 --> 00:08:12.190\nwe wanna kind of understand the individual\npieces of our wireless networks.\n\n146\n00:08:12.190 --> 00:08:14.530\nSo I've got a little diagram here, and\n\n147\n00:08:14.530 --> 00:08:17.880\nI'll kind of talk about\nthe individual pieces here.\n\n148\n00:08:17.880 --> 00:08:22.163\nYou have wireless devices, and\nif you're not familiar with Network+,\n\n149\n00:08:22.163 --> 00:08:26.108\nwe have a pretty good demonstration\nof the individual components.\n\n150\n00:08:26.108 --> 00:08:28.081\nBut I do want to kind of recap it here for\n\n151\n00:08:28.081 --> 00:08:31.520\nSecurity+ because maybe you\naren't taking that plus.\n\n152\n00:08:31.520 --> 00:08:37.510\nWireless devices inside of a wireless\ninfrastructure are also known as STAs,\n\n153\n00:08:37.510 --> 00:08:39.150\nright, stations.\n\n154\n00:08:39.150 --> 00:08:43.400\nYour access points are just known as APs,\nwhich makes it kind of easy, access point.\n\n155\n00:08:43.400 --> 00:08:45.310\nSo what's the difference?\n\n156\n00:08:45.310 --> 00:08:49.010\nThe difference is the AP\nis a managing device.\n\n157\n00:08:49.010 --> 00:08:51.500\nThe station or\nwireless device, in this case,\n\n158\n00:08:51.500 --> 00:08:55.210\nthat is connecting to the network,\nit is a managed device.\n\n159\n00:08:55.210 --> 00:08:58.550\nYou also have things like, for\ninstance, you have what's known as,\n\n160\n00:08:58.550 --> 00:09:01.650\nwe commonly just call it a network name.\n\n161\n00:09:03.090 --> 00:09:05.309\nAnd I want you to think of a network name.\n\n162\n00:09:05.309 --> 00:09:09.828\nThe technical term for\nit would be something known as an SSID.\n\n163\n00:09:09.828 --> 00:09:12.616\nThat's a Service Set Identifier.\n\n164\n00:09:12.616 --> 00:09:16.756\nIt's a 32-bit alphanumeric string that\nessentially identifies the wireless\n\n165\n00:09:16.756 --> 00:09:20.301\naccess point, the network and\nall devices connected to the network.\n\n166\n00:09:20.301 --> 00:09:25.185\nIf we have a single access point then what\nwe end up having is a basic service set\n\n167\n00:09:25.185 --> 00:09:26.096\nidentifier.\n\n168\n00:09:26.096 --> 00:09:28.880\nIt means one access point\nmanaging all the devices.\n\n169\n00:09:28.880 --> 00:09:32.350\nIf we have two access points both\nmanaging one larger network,\n\n170\n00:09:32.350 --> 00:09:35.164\nwe have what's known as\nan extended service set and\n\n171\n00:09:35.164 --> 00:09:37.991\nthat becomes an extended\nservice set identifier.\n\n172\n00:09:37.991 --> 00:09:43.120\nIt basically means more than one access\npoint responding to a single network name.\n\n173\n00:09:43.120 --> 00:09:48.268\nAll right, so, definitely know what\nthe SSID is, that is important, and\n\n174\n00:09:48.268 --> 00:09:53.684\nalso know, understand what stations\nare and the difference between the two.\n\n175\n00:09:53.684 --> 00:09:57.278\nNow some of the things that we also have\nto worry about inside of our networks\n\n176\n00:09:57.278 --> 00:09:59.555\nare things like signal strength.\n\n177\n00:09:59.555 --> 00:10:03.855\nSignal strength, again, understand that\nsignal strength is very important.\n\n178\n00:10:03.855 --> 00:10:06.125\nAnd one of the things people\nsometimes say is, well,\n\n179\n00:10:06.125 --> 00:10:08.185\njust boost your signal strength and\nyou'll get better reception.\n\n180\n00:10:09.305 --> 00:10:10.715\nAnd that's not the case.\n\n181\n00:10:10.715 --> 00:10:15.100\nYou have to understand that when you\nboost signal strength, what does it do?\n\n182\n00:10:15.100 --> 00:10:18.910\nIt boosts the access point\nability to talk to you.\n\n183\n00:10:18.910 --> 00:10:20.930\nIt does nothing for your wireless device.\n\n184\n00:10:20.930 --> 00:10:23.925\nIt didn't increase the signal strength\nof the device communicating back to\n\n185\n00:10:23.925 --> 00:10:24.683\nthe access point.\n\n186\n00:10:24.683 --> 00:10:28.344\nAnd in fact by increasing the signal\nstrength you might introduce things like\n\n187\n00:10:28.344 --> 00:10:30.045\nradio frequency interference.\n\n188\n00:10:30.045 --> 00:10:31.989\nSo it's a fine line.\n\n189\n00:10:31.989 --> 00:10:32.713\nIt's a balance and\n\n190\n00:10:32.713 --> 00:10:35.391\nI don't know where the fine line,\nwhere the line in the sand is drawn.\n\n191\n00:10:35.391 --> 00:10:39.065\nBut you have to do your research to\nmake sure, do things like wireless site\n\n192\n00:10:39.065 --> 00:10:43.440\nsurveys, to make sure your access points\nare covering and getting a heat map.\n\n193\n00:10:43.440 --> 00:10:44.701\nIt's not thermal infrared or\nanything like that.\n\n194\n00:10:44.701 --> 00:10:46.098\n&gt;&gt; [INAUDIBLE] the placement of those\naccess points that we're talking about?\n\n195\n00:10:46.098 --> 00:10:46.989\n&gt;&gt; That's right.\n\n196\n00:10:46.989 --> 00:10:48.055\n&gt;&gt; Yeah.\n&gt;&gt; Absolutely, so\n\n197\n00:10:48.055 --> 00:10:51.750\ndefinitely pay attention to\nthings like bandwidth selection.\n\n198\n00:10:51.750 --> 00:10:54.645\nWe talk about bandwidth selection,\nwell, or\n\n199\n00:10:54.645 --> 00:10:57.623\nband selection in general and\nthen bandwidth.\n\n200\n00:10:57.623 --> 00:10:59.760\nWell, band selection, what am I gonna use?\n\n201\n00:10:59.760 --> 00:11:02.540\nAm I gonna use 2.4 gigahertz or\nam I gonna use 5 gigahertz?\n\n202\n00:11:02.540 --> 00:11:04.739\nThose frequencies and\nthose decisions matter, right?\n\n203\n00:11:04.739 --> 00:11:09.170\n2.4 is the industrial, scientifical,\nand medical band, the ISM.\n\n204\n00:11:09.170 --> 00:11:12.320\nAnd this is a completely long used,\n\n205\n00:11:12.320 --> 00:11:17.467\nover saturated unlicensed\nportion of a larger spectrum.\n\n206\n00:11:17.467 --> 00:11:19.009\nIt's 2.4 gigahertz.\n\n207\n00:11:19.009 --> 00:11:22.260\nNow when run in 2.4 gigahertz mode,\nyou've got to keep in mind that you have\n\n208\n00:11:22.260 --> 00:11:25.280\ncontention with other devices,\npotentially, within your networks.\n\n209\n00:11:25.280 --> 00:11:27.810\nIncluding things like\nelectrical interference, and\n\n210\n00:11:27.810 --> 00:11:31.055\nradio frequency interference from\nother devices like microwaves and\n\n211\n00:11:31.055 --> 00:11:33.154\nstuff like this, cell phones, if you will.\n\n212\n00:11:33.154 --> 00:11:35.210\nBut you also have the five\ngigahertz spectrum.\n\n213\n00:11:35.210 --> 00:11:39.311\nAnd the five gigahertz spectrum,\nas of right now, isn't used.\n\n214\n00:11:39.311 --> 00:11:45.230\nIt isn't over saturated, if you will,\nlike 2.4, 2.4's been around for awhile.\n\n215\n00:11:45.230 --> 00:11:47.534\nBut with five gigahertz,\n\n216\n00:11:47.534 --> 00:11:53.613\nwhat we do is we get a set of channels\nthat allow us greater bandwidth.\n\n217\n00:11:53.613 --> 00:11:58.210\nLike, for instance,\nin the newer 802.11AC technologies.\n\n218\n00:11:58.210 --> 00:12:02.915\nPrior technologies would give\nus 20 Megahertz bandwidth, and\n\n219\n00:12:02.915 --> 00:12:07.287\nwhen we moved into N we would\nhave 40 Megahertz bandwidth.\n\n220\n00:12:07.287 --> 00:12:11.966\nNow, when we get into things like AC\nusing the five gigahertz spectrum,\n\n221\n00:12:11.966 --> 00:12:14.720\nwe get 40 megahertz bandwidth.\n\n222\n00:12:14.720 --> 00:12:20.789\nWe get 80 megahertz bandwidth, and also\nall the way up to 160 megahertz bandwidth.\n\n223\n00:12:20.789 --> 00:12:24.376\nSo you could see that we could\nmove a lot more data at one time.\n\n224\n00:12:24.376 --> 00:12:26.909\nSo the five gigahertz\nspectrum is very good too and\n\n225\n00:12:26.909 --> 00:12:29.395\nit is being used a lot by\nthe newer technologies.\n\n226\n00:12:29.395 --> 00:12:31.057\nAnd we need it.\n\n227\n00:12:31.057 --> 00:12:33.633\nWe've got a lot of things\nthat go over wireless today,\n\n228\n00:12:33.633 --> 00:12:35.580\nthat can consume a lot of bandwidth.\n\n229\n00:12:35.580 --> 00:12:37.698\nWe have high definition traffic,\n\n230\n00:12:37.698 --> 00:12:41.357\nwe got real-time traffic that\nwe need to get it there fast.\n\n231\n00:12:41.357 --> 00:12:45.758\nWe have multiple devices on our networks\nwith BYOD, a lot of mobility, mobile\n\n232\n00:12:45.758 --> 00:12:50.240\ndevices that just need access to larger\namounts of bandwidth simultaneously.\n\n233\n00:12:50.240 --> 00:12:53.900\nSo you need to pay attention to\nthe technologies you use, bandwidth and\n\n234\n00:12:53.900 --> 00:12:55.548\nsignal strength is important.\n\n235\n00:12:55.548 --> 00:12:57.774\n&gt;&gt; I know and who knows what’s going\nto be happening in the future.\n\n236\n00:12:57.774 --> 00:13:00.851\nThere are so many exciting\nprojects on the horizon there.\n\n237\n00:13:00.851 --> 00:13:01.882\n&gt;&gt; Most definitely and\n\n238\n00:13:01.882 --> 00:13:06.063\nsome of the other things that they talk\nabout in the wireless communications are,\n\n239\n00:13:06.063 --> 00:13:09.520\nfor instance,\nlike antenna types and placement.\n\n240\n00:13:09.520 --> 00:13:13.786\nNow from the security standpoint there's\na couple of things that we might need to\n\n241\n00:13:13.786 --> 00:13:16.436\nconsider, confidentiality and\navailability.\n\n242\n00:13:16.436 --> 00:13:19.589\nIntegrity, we always wanna maintain\nthe integrity of our data,\n\n243\n00:13:19.589 --> 00:13:22.330\nbut what do I mean when\nI say confidentiality?\n\n244\n00:13:22.330 --> 00:13:26.167\nWell with confidentiality, if you\nincorrectly place your antennas to where\n\n245\n00:13:26.167 --> 00:13:29.246\nthe majority of your signal is\nbleeding over the parking lot.\n\n246\n00:13:29.246 --> 00:13:30.942\nOr it doesn't have to be the parking lot,\n\n247\n00:13:30.942 --> 00:13:33.810\nit could be the fact that you're\na building in maybe a shopping plaza.\n\n248\n00:13:33.810 --> 00:13:34.652\n&gt;&gt; Like a strip mall or something.\n\n249\n00:13:34.652 --> 00:13:36.554\n&gt;&gt; Strip mall, great example.\n\n250\n00:13:36.554 --> 00:13:41.300\nWhere you don't want that signal bleeding\nover two or three buildings down.\n\n251\n00:13:41.300 --> 00:13:45.160\nSo what you have to do is you have to get\nthings like highly directional antennas\n\n252\n00:13:45.160 --> 00:13:47.741\nand you point them towards\ninside of your building.\n\n253\n00:13:47.741 --> 00:13:52.684\nYou place an omnidirectional that\nradiates a pattern out in all directions\n\n254\n00:13:52.684 --> 00:13:57.235\nin the center of your building so\nit spreads out evenly, if you will,\n\n255\n00:13:57.235 --> 00:14:00.200\nto the outer edges of your building.\n\n256\n00:14:00.200 --> 00:14:03.250\nOn the outer edges of your building,\nhighly directional back in.\n\n257\n00:14:03.250 --> 00:14:07.234\nRemember that signal strength, and\nwhen we talk about antenna types and\n\n258\n00:14:07.234 --> 00:14:10.510\nsignal strength,\nremember that is measured in decibels.\n\n259\n00:14:11.540 --> 00:14:13.077\nAll right, what else do we have?\n\n260\n00:14:13.077 --> 00:14:18.150\nWell they [LAUGH] I love this,\nthey also call out fat And thin APs.\n\n261\n00:14:18.150 --> 00:14:20.401\nSo a fat AP is one that\nneeds to go on a diet and\n\n262\n00:14:20.401 --> 00:14:22.479\na thin one is one that needs to eat more.\n\n263\n00:14:22.479 --> 00:14:23.981\n&gt;&gt; And not to mention, the acronyms.\n\n264\n00:14:23.981 --> 00:14:25.764\nWe were joking about this the CATHLAP.\n\n265\n00:14:25.764 --> 00:14:26.723\n&gt;&gt; Yes, yeah.\n\n266\n00:14:26.723 --> 00:14:32.000\nSo what are we talking about when we say,\nyeah that's a funny acronym for sure.\n\n267\n00:14:32.000 --> 00:14:33.324\nSo fat and thin, what do we mean?\n\n268\n00:14:33.324 --> 00:14:36.310\nAll right,\nwell when we talk about a fat AP.\n\n269\n00:14:36.310 --> 00:14:39.398\nThis is one that can manage\nall the devices on a network.\n\n270\n00:14:39.398 --> 00:14:40.970\nLet me give you an example.\n\n271\n00:14:40.970 --> 00:14:44.552\nIf you got a wireless network at your\nhouse, you got a fat wireless AP.\n\n272\n00:14:44.552 --> 00:14:47.418\nNow, don't take that as an insult that it\nneeds to go on Jenny Craig or anything,\n\n273\n00:14:47.418 --> 00:14:48.685\nthat's not what I mean.\n\n274\n00:14:48.685 --> 00:14:53.434\nWhat I mean is that device is fully\ncapable of managing every wireless device\n\n275\n00:14:53.434 --> 00:14:58.496\nwithin that network, including doing\nthings like Mac filtering, if you will.\n\n276\n00:14:58.496 --> 00:15:02.335\nYou can set up the encryption on\nthe wireless network, it manages that.\n\n277\n00:15:02.335 --> 00:15:04.669\nSo that's what they mean\nwhen they say that.\n\n278\n00:15:04.669 --> 00:15:09.260\nA thin access point, it's more like\na dumb access point, just kidding guys.\n\n279\n00:15:09.260 --> 00:15:13.815\nIt's one that doesn't have all\nof the logic needed to manage\n\n280\n00:15:13.815 --> 00:15:15.614\nthe wireless network.\n\n281\n00:15:15.614 --> 00:15:19.880\nIt is in the truest\nnature an access point.\n\n282\n00:15:19.880 --> 00:15:25.065\nIt allows you wireless\naccess to a wired network.\n\n283\n00:15:25.065 --> 00:15:29.810\nAnd it, itself,\nis managed by things like a controller.\n\n284\n00:15:29.810 --> 00:15:32.049\nThey talk about things like\ncontroller base versus standalone.\n\n285\n00:15:32.049 --> 00:15:36.160\nA standalone access point\nis a fat access point.\n\n286\n00:15:36.160 --> 00:15:40.014\nA controller based access point is\na thin access point that's relying\n\n287\n00:15:40.014 --> 00:15:42.700\non the wireless local\narea network controller.\n\n288\n00:15:42.700 --> 00:15:44.916\nIn fact, let me go ahead and\nshow you what I mean here.\n\n289\n00:15:44.916 --> 00:15:50.232\nSo for instance, if you have, and\nlet's talk about these acronyms too,\n\n290\n00:15:50.232 --> 00:15:55.307\nbecause the first one here is\nthe lightweight access point protocol.\n\n291\n00:15:55.307 --> 00:15:59.868\nWhat it allows, it allows a centralized\nwireless controller to push out\n\n292\n00:15:59.868 --> 00:16:03.996\nconfigurations to each one of\nthe access points that it manages.\n\n293\n00:16:03.996 --> 00:16:06.704\nSo your wireless device connects\nto the access Access point and\n\n294\n00:16:06.704 --> 00:16:09.002\nit sends its communications\nback to the controller,\n\n295\n00:16:09.002 --> 00:16:12.450\nand it's the controller that\nmakes the decisions, right.\n\n296\n00:16:12.450 --> 00:16:18.090\nAnd that is done from a lightweight\naccess point protocol compliant AP.\n\n297\n00:16:18.090 --> 00:16:19.280\nNow CAPWAP which,\n\n298\n00:16:19.280 --> 00:16:23.200\nagain, we're hard-pressed not to\nstart laughing with this acronym.\n\n299\n00:16:23.200 --> 00:16:24.091\nIt is a real acronym.\n\n300\n00:16:24.091 --> 00:16:26.960\nIt stands for control and\nprovisioning of wireless access points.\n\n301\n00:16:26.960 --> 00:16:30.066\nAnd it's actually built\noff of the LWAPP protocol.\n\n302\n00:16:30.066 --> 00:16:35.890\nAnd again, it's just another protocol for\ncontrolling these thin access points.\n\n303\n00:16:35.890 --> 00:16:41.510\nSo that's really what we're talking\nabout when we say thin versus fat AP.\n\n304\n00:16:41.510 --> 00:16:46.680\nIs it controlled by another,\nby a wireless LAN controller?\n\n305\n00:16:46.680 --> 00:16:49.210\nOr is it one that's standalone,\nand it can manage its own devices?\n\n306\n00:16:49.210 --> 00:16:52.990\nSo that's something that I want you to\nkeep in mind when it comes to the exam.\n\n307\n00:16:52.990 --> 00:16:56.519\nKnow your access point types and\nknow your communication technologies.\n\n308\n00:16:57.870 --> 00:17:01.023\nAll right, so\nspeaking of communication technologies,\n\n309\n00:17:01.023 --> 00:17:03.840\nthis one's kind of interesting.\n\n310\n00:17:03.840 --> 00:17:08.248\nThe next concept is really about\ncollection of security event information,\n\n311\n00:17:08.248 --> 00:17:10.502\nright, SIEM products if we will.\n\n312\n00:17:10.502 --> 00:17:13.834\n&gt;&gt; We see that happening more often now,\njust to simplify and\n\n313\n00:17:13.834 --> 00:17:16.550\njust kind of unify our management systems.\n\n314\n00:17:16.550 --> 00:17:19.865\n&gt;&gt; That's right, so it's security\nincident and event management software.\n\n315\n00:17:19.865 --> 00:17:21.140\n&gt;&gt; [LAUGH]\n&gt;&gt; Not a big one, right?\n\n316\n00:17:21.140 --> 00:17:23.695\nBut let's go ahead and\nkinda look at what this is doing for us.\n\n317\n00:17:23.695 --> 00:17:24.700\nGot a little diagram here.\n\n318\n00:17:24.700 --> 00:17:30.050\nYou have various system inputs around\nyour entire organization, right?\n\n319\n00:17:30.050 --> 00:17:34.200\n&gt;&gt; You have things like event information,\noperating systems, different applications,\n\n320\n00:17:34.200 --> 00:17:35.010\nnetworking device.\n\n321\n00:17:35.010 --> 00:17:37.835\nIt's one of the reasons we\nuse things like SNMP, right?\n\n322\n00:17:37.835 --> 00:17:40.600\nYou have, for instance,\ndata bases, all different things,\n\n323\n00:17:40.600 --> 00:17:43.410\nperimeter, some more security\ninformation as well.\n\n324\n00:17:43.410 --> 00:17:48.530\nYou have things like vulnerability scans,\nassessment information, patch management.\n\n325\n00:17:48.530 --> 00:17:50.640\nThat's a lot of different information.\n\n326\n00:17:50.640 --> 00:17:54.530\nCould you imagine being the one that's\nsitting at the proverbial mailbox for\n\n327\n00:17:54.530 --> 00:17:57.850\nall of this information coming in,\nand try to make some sense out of it?\n\n328\n00:17:57.850 --> 00:18:01.250\nWell that's why they talk\nabout SIEM aggregation.\n\n329\n00:18:01.250 --> 00:18:03.940\nWhen we talk about aggregation,\nit's the fact that the SIEM systems,\n\n330\n00:18:03.940 --> 00:18:08.270\nthey collect a lot of information from\na lot of different event sources, right?\n\n331\n00:18:08.270 --> 00:18:09.940\nFrom multiple event sources.\n\n332\n00:18:09.940 --> 00:18:11.010\nAnd with the aggregation,\n\n333\n00:18:11.010 --> 00:18:15.700\nthe goal is to consolidate all of these\ndifferent event source data into a single\n\n334\n00:18:15.700 --> 00:18:20.836\nrepository, making log management\na little bit more feasible.\n\n335\n00:18:20.836 --> 00:18:24.644\nBut it doesn't stop there too,\nbecause although not called out,\n\n336\n00:18:24.644 --> 00:18:26.690\nI do wanna kinda make mention of it.\n\n337\n00:18:26.690 --> 00:18:29.926\nBut what if we've collected,\nwe've aggregated all that information?\n\n338\n00:18:29.926 --> 00:18:31.409\nIs it readable?\n\n339\n00:18:31.409 --> 00:18:34.211\nWell if you've ever actually\nlooked at an OID from and\n\n340\n00:18:34.211 --> 00:18:36.776\nSMP, there's nothing\nuser friendly about it.\n\n341\n00:18:36.776 --> 00:18:40.920\nSo it also does what's known\nas data normalization, right.\n\n342\n00:18:40.920 --> 00:18:44.910\nData normalization is that it collects\nthis, aggregates into a single location,\n\n343\n00:18:44.910 --> 00:18:48.540\nand the output is something\nthat's human readable, right.\n\n344\n00:18:48.540 --> 00:18:52.540\nData event analysis, event and\nincident reports and real-time monitoring.\n\n345\n00:18:52.540 --> 00:18:54.680\nBut it's something that's human readable,\nright.\n\n346\n00:18:54.680 --> 00:18:58.597\nIf I look at a string of OIDs,\nobject identifiers,\n\n347\n00:18:58.597 --> 00:19:02.887\nthat's part of an SMP trap,\nI have no clue what that is.\n\n348\n00:19:02.887 --> 00:19:04.390\nIt's just a string of numbers.\n\n349\n00:19:04.390 --> 00:19:07.380\nBut with data normalization and\ncollecting this information,\n\n350\n00:19:07.380 --> 00:19:10.690\nwe can put it in a human readable\nformat so that we know what it is.\n\n351\n00:19:11.880 --> 00:19:13.230\nHow about correlation?\n\n352\n00:19:13.230 --> 00:19:18.080\nHow about applying an intelligence,\na logic, to the data collection?\n\n353\n00:19:19.300 --> 00:19:24.470\nBasically just to make it possible to\neven discover an event has happened.\n\n354\n00:19:24.470 --> 00:19:28.450\nAnd a lot of times, what it does\nis it applies an if then logic.\n\n355\n00:19:28.450 --> 00:19:31.250\nIf this happens, then do this.\n\n356\n00:19:31.250 --> 00:19:32.970\nDon't just collect the information.\n\n357\n00:19:32.970 --> 00:19:36.730\nIf something happens, I want you to\nperform this type of functionality.\n\n358\n00:19:36.730 --> 00:19:38.250\nSo we also have correlation\nthat applies to logic-\n\n359\n00:19:38.250 --> 00:19:39.903\n&gt;&gt; Super helpful when we're dealing with\n\n360\n00:19:39.903 --> 00:19:41.080\na lot of inromation.\n\n361\n00:19:41.080 --> 00:19:43.240\n&gt;&gt; Most definitely.\n&gt;&gt; More than a uman can understand, right?\n\n362\n00:19:43.240 --> 00:19:45.848\n&gt;&gt; Yeah definitely, because this could\nbe in something like a SCADA system.\n\n363\n00:19:45.848 --> 00:19:48.060\nAnd you could have\nhundreds of moving parts,\n\n364\n00:19:48.060 --> 00:19:51.110\nnot to mention all the moving\nparts within your network as well.\n\n365\n00:19:51.110 --> 00:19:53.310\nSo it's great to have this.\n\n366\n00:19:53.310 --> 00:19:57.259\nAlso we have things like our\nintrusion detection systems do this.\n\n367\n00:19:57.259 --> 00:20:00.079\nBut within SIEM, wouldn't it be nice\nto have alerting and monitoring?\n\n368\n00:20:00.079 --> 00:20:01.539\nAnd that's one of the things we get.\n\n369\n00:20:01.539 --> 00:20:03.966\nWe get the benefit of\nthe real time monitoring, and\n\n370\n00:20:03.966 --> 00:20:06.640\nwe can do automated alerting and\ntriggering, right?\n\n371\n00:20:06.640 --> 00:20:09.600\nIf this, then this.\n\n372\n00:20:09.600 --> 00:20:11.320\nWe also need time synchronization.\n\n373\n00:20:11.320 --> 00:20:14.480\nTime synchronization is very, very\nimportant to our logs and our information.\n\n374\n00:20:14.480 --> 00:20:17.204\nAnd let alone,\nthat if you're in a domain environment and\n\n375\n00:20:17.204 --> 00:20:18.960\nyou have to be time-synchronized.\n\n376\n00:20:18.960 --> 00:20:22.260\nBut time synchronization is very,\nvery important for these systems, so\n\n377\n00:20:22.260 --> 00:20:25.670\nwe do have to make sure\nthat we have that as well.\n\n378\n00:20:25.670 --> 00:20:29.000\nThe other thing is event deduplication.\n\n379\n00:20:29.000 --> 00:20:34.520\nI don't wanna have maybe 100 log events\nthat are all the exact same thing.\n\n380\n00:20:34.520 --> 00:20:38.181\nSo event deduplication just makes\nsure that it's kind of event source\n\n381\n00:20:38.181 --> 00:20:42.402\naggregation, that it It basically helps\nto reduce or eliminate those recurring\n\n382\n00:20:42.402 --> 00:20:46.394\n[CROSSTALK] multiple events being\nreported, that are the same exact event.\n\n383\n00:20:46.394 --> 00:20:52.360\nAnd then you'll also have your logs again,\nthat you have to be aware of as well.\n\n384\n00:20:53.670 --> 00:20:55.580\nAll right, so\na couple other things that we're.\n\n385\n00:20:55.580 --> 00:20:57.780\nWell we've still got quite a few\nthings that we need to talk about.\n\n386\n00:20:57.780 --> 00:21:00.880\nOne of the other things that they\ntalk about are things like DLP,\n\n387\n00:21:00.880 --> 00:21:02.660\ndata loss prevention.\n\n388\n00:21:02.660 --> 00:21:06.400\nThere's another acronym that\nis data leak prevention.\n\n389\n00:21:06.400 --> 00:21:10.330\nFrom this standpoint, they're\ntalking about data loss prevention.\n\n390\n00:21:10.330 --> 00:21:12.120\nAnd really,\nwhen you look at some of the concepts,\n\n391\n00:21:12.120 --> 00:21:16.490\nit would also almost carry over to data\nleak prevention, and you'll see why.\n\n392\n00:21:16.490 --> 00:21:18.560\nThey call out three things.\n\n393\n00:21:18.560 --> 00:21:19.540\nUSB blocking.\n\n394\n00:21:19.540 --> 00:21:23.570\nThey call out cloud-based and\nthey call out email based, okay.\n\n395\n00:21:23.570 --> 00:21:24.990\nLet's talk about each one.\n\n396\n00:21:24.990 --> 00:21:28.030\nI'll save USB blocking for\nlast, all right.\n\n397\n00:21:28.030 --> 00:21:30.850\nLet's talk about cloud-based.\n\n398\n00:21:30.850 --> 00:21:37.450\nIf I have data that's leaving my network,\ndo I want it going into basically\n\n399\n00:21:37.450 --> 00:21:42.020\nunsanctioned cloud-based solutions,\nsolutions that haven't been tested?\n\n400\n00:21:42.020 --> 00:21:42.610\nNow, Cherokee,\n\n401\n00:21:42.610 --> 00:21:45.740\nI know you know a lot [LAUGH] about\nthose security policies and stuff.\n\n402\n00:21:45.740 --> 00:21:48.785\nWe wouldn't want information\nthat's supposed to remain FISA or\n\n403\n00:21:48.785 --> 00:21:53.560\nHIPAA-compliant going into an unsanctioned\ncloud environment where we don't know\n\n404\n00:21:53.560 --> 00:21:57.510\nif that level of security is achieved,\nright?\n\n405\n00:21:57.510 --> 00:21:58.240\n&gt;&gt; Compliant, yeah.\n\n406\n00:21:58.240 --> 00:22:00.150\nIt has to be compliant\nwith those regulations.\n\n407\n00:22:00.150 --> 00:22:00.800\n&gt;&gt; Most definitely.\n\n408\n00:22:00.800 --> 00:22:03.800\nSo that's one of the reasons you\ndon't wanna use cloud-based, right?\n\n409\n00:22:03.800 --> 00:22:07.230\nAnd one of the things that we can do, is\nwe can implement things like policies that\n\n410\n00:22:07.230 --> 00:22:11.360\nwill basically allow or\nnot allow that to happen.\n\n411\n00:22:11.360 --> 00:22:14.860\nAnd it's becoming increasingly\nchallenging, if you will,\n\n412\n00:22:14.860 --> 00:22:16.240\nto monitor and control.\n\n413\n00:22:16.240 --> 00:22:20.020\nEspecially when you have the additional\nof things like nontraditional devices,\n\n414\n00:22:20.020 --> 00:22:23.230\ndevices that can't be managed through\ntraditional mechanisms like BYOD.\n\n415\n00:22:24.260 --> 00:22:28.790\nI can control the communications on\na work station within my Windows domain\n\n416\n00:22:28.790 --> 00:22:33.500\nthrough a group policy and other network\naccess control type control technologies.\n\n417\n00:22:33.500 --> 00:22:34.188\nWhat about my phone?\n\n418\n00:22:34.188 --> 00:22:37.010\nWhat about our end user's phone?\n\n419\n00:22:37.010 --> 00:22:41.340\nCan I control the information, the data,\nthat goes onto that phone and then\n\n420\n00:22:41.340 --> 00:22:44.680\nthe data that leaves the network after\nthe phone goes home with the end user?\n\n421\n00:22:44.680 --> 00:22:46.080\nAnd we can through things like, for\n\n422\n00:22:46.080 --> 00:22:49.450\ninstance, mobile device\nmanagement technologies.\n\n423\n00:22:49.450 --> 00:22:52.000\nUse an OpenMDM-based solutions.\n\n424\n00:22:52.000 --> 00:22:53.400\nSo that is one of the things, too.\n\n425\n00:22:53.400 --> 00:22:55.720\nHow about things like emails?\n\n426\n00:22:58.020 --> 00:22:59.598\nEmail's a big problem, right?\n\n427\n00:22:59.598 --> 00:23:03.923\nEmails, a lot of times we can control what\nis done with intellectual property when\n\n428\n00:23:03.923 --> 00:23:05.580\nit's on our network.\n\n429\n00:23:05.580 --> 00:23:08.050\nHow do we control it when\nit gets off of our network?\n\n430\n00:23:08.050 --> 00:23:12.090\nAnd email is also a very,\nvery critical threat vector\n\n431\n00:23:12.090 --> 00:23:15.850\nthat we need to keep in mind\nbecause outbound data loss.\n\n432\n00:23:15.850 --> 00:23:19.031\nPrivate patents, something that\nshouldn't be leaked to the public.\n\n433\n00:23:19.031 --> 00:23:21.381\nBoy it sent an email,\nsent over those public channels, and\n\n434\n00:23:21.381 --> 00:23:24.347\nnow it's out there for the rest of\nthe world, hopefully not to intercept.\n\n435\n00:23:24.347 --> 00:23:26.427\n&gt;&gt; Or even if you think about\nthings like contact lists.\n\n436\n00:23:26.427 --> 00:23:30.657\nI don't know if you've ever fell victim to\none of those types of attacks where they\n\n437\n00:23:30.657 --> 00:23:32.940\njust propagate through your contact list.\n\n438\n00:23:32.940 --> 00:23:38.170\nBut imagine if you had sensitive\nclients that had private businesses\n\n439\n00:23:38.170 --> 00:23:41.780\nhappening with you, and they didn't want\ntheir information exposed like that.\n\n440\n00:23:41.780 --> 00:23:42.810\n&gt;&gt; Most definitely.\n\n441\n00:23:42.810 --> 00:23:43.550\nAnd how about this?\n\n442\n00:23:43.550 --> 00:23:46.660\nWe've talked about social engineering\nwhen we did our social engineering.\n\n443\n00:23:46.660 --> 00:23:48.660\nWe wanna protect against phishing attacks.\n\n444\n00:23:49.710 --> 00:23:53.480\nThey call it BEC-based attacks,\nBusiness Email Compromise-based attacks.\n\n445\n00:23:53.480 --> 00:23:56.760\nWhat if somebody has access\nto our corporate email?\n\n446\n00:23:56.760 --> 00:23:58.820\nA whaling attack is on the way.\n\n447\n00:23:58.820 --> 00:24:00.665\nIt's gonna look like it's\ncome through the CEO, but\n\n448\n00:24:00.665 --> 00:24:02.061\nit really hasn't come through the CEO.\n\n449\n00:24:02.061 --> 00:24:06.002\nAnd that's why we really need\nto enforce security policies,\n\n450\n00:24:06.002 --> 00:24:11.102\nto make sure that these email-based\nattacks don't stop our networks as well.\n\n451\n00:24:11.102 --> 00:24:14.602\nAnd one of the things that we can do is\nwe can implement things like fine base\n\n452\n00:24:14.602 --> 00:24:17.256\ngranular policies for\nautomatic identification, and\n\n453\n00:24:17.256 --> 00:24:19.070\nclassification of your data.\n\n454\n00:24:19.070 --> 00:24:22.160\nSo we know what the data is,\nwe know is it confidential?\n\n455\n00:24:22.160 --> 00:24:22.837\nIs it secret?\n\n456\n00:24:22.837 --> 00:24:24.780\nIs it public knowledge?\n\n457\n00:24:24.780 --> 00:24:28.050\nIs it only for internal use only?\n\n458\n00:24:28.050 --> 00:24:30.990\nFiltering data streams for privacy.\n\n459\n00:24:30.990 --> 00:24:35.592\nAs well as being context and\ncontent aware likewise.\n\n460\n00:24:35.592 --> 00:24:40.430\nNow, the other one that I said I'd save\nfor last is USB blocking, all right.\n\n461\n00:24:40.430 --> 00:24:43.700\nNow, USB blocking, removable media.\n\n462\n00:24:43.700 --> 00:24:44.830\nIt's not just USB.\n\n463\n00:24:44.830 --> 00:24:47.780\nThey call out USB, but\nlet's be honest, right?\n\n464\n00:24:47.780 --> 00:24:50.902\nI know that optical treasure kinda\nbecoming a thing of the past and\n\n465\n00:24:50.902 --> 00:24:52.505\nsome of our work stations today.\n\n466\n00:24:52.505 --> 00:24:55.265\nI am not saying that they\nare gonna disappear forever, but\n\n467\n00:24:55.265 --> 00:24:57.474\nsomebody could also just pop a dvd in,\nright.\n\n468\n00:24:57.474 --> 00:25:01.022\nA writable dvd into the system and\nthen throw and write that pro,\n\n469\n00:25:01.022 --> 00:25:04.600\nwrite that company data,\nwrite to the dvd as well, right.\n\n470\n00:25:04.600 --> 00:25:05.710\n&gt;&gt; Any kind of preferals, West,\n\n471\n00:25:05.710 --> 00:25:10.650\nI have seen tools out there that\nare registered as even keyboards.\n\n472\n00:25:10.650 --> 00:25:14.660\nSo, you plug in a device that registers\nas a keyboard although it's not but\n\n473\n00:25:14.660 --> 00:25:16.710\nsome systems might trust it\nthinking it's just keyboard.\n\n474\n00:25:16.710 --> 00:25:20.100\nIt's just a keyboard, but you wanna\nmake sure those aren't on lock down.\n\n475\n00:25:20.100 --> 00:25:21.987\n&gt;&gt; Most definitely.\nSo, what can we do to do that?\n\n476\n00:25:21.987 --> 00:25:24.310\nWe can implement things\nlike business policies.\n\n477\n00:25:24.310 --> 00:25:27.860\nIf you will that ensure employees\nhandle confidential data\n\n478\n00:25:27.860 --> 00:25:29.310\nin an appropriate manner.\n\n479\n00:25:29.310 --> 00:25:33.690\nOr we can go as far as just like they're\nmentioning here doing USB blocking.\n\n480\n00:25:33.690 --> 00:25:37.230\nIn fact, I've got a Windows machine here,\nlet's go ahead and\n\n481\n00:25:37.230 --> 00:25:39.570\nlet's pull up this Windows machine here.\n\n482\n00:25:39.570 --> 00:25:42.750\nAnd I don't think this is a domain\ncontroller but that's okay.\n\n483\n00:25:42.750 --> 00:25:46.700\nWe can use, I'm gonna show you guys where\nwe can control this, cuz we do have\n\n484\n00:25:46.700 --> 00:25:50.240\nmethods that even on a Windows Active\nDirectory Domain we can do this.\n\n485\n00:25:50.240 --> 00:25:53.590\nIf this doesn't happen to be an Active\nDirectory Domain or a domain controller,\n\n486\n00:25:53.590 --> 00:25:56.890\nthat's okay cuz I can use the local\ngroup policies to show you.\n\n487\n00:25:56.890 --> 00:26:00.850\nJust keep in mind, you're probably not\ngonna use theLocal Group Policy, you're\n\n488\n00:26:00.850 --> 00:26:05.050\ngonna be using a Corporate Group Policy\ninside of a domain environment here.\n\n489\n00:26:05.050 --> 00:26:07.470\nAnd for whatever reason,\nthat's taking a long time.\n\n490\n00:26:07.470 --> 00:26:08.940\nSo let's see here.\n\n491\n00:26:08.940 --> 00:26:09.950\nLet's get into this machine.\n\n492\n00:26:09.950 --> 00:26:11.998\nOkay, I'll just go into\nthe Windows 10 machine here.\n\n493\n00:26:11.998 --> 00:26:15.450\nWe'll do agpedit.msc.\n\n494\n00:26:15.450 --> 00:26:18.035\nNow, keep in mind that if you're on\na windows domain controller the settings\n\n495\n00:26:18.035 --> 00:26:19.207\nare gonna be the same pretty much.\n\n496\n00:26:19.207 --> 00:26:22.313\nThe only difference is you'll have\npolicies and preferences here,\n\n497\n00:26:22.313 --> 00:26:24.390\ninside a local group policy we don't.\n\n498\n00:26:24.390 --> 00:26:27.170\nSo, if I get down here and\nI go to things like,\n\n499\n00:26:27.170 --> 00:26:31.600\nWindows Settings or excuse me,\nComputer Configuration.\n\n500\n00:26:31.600 --> 00:26:35.050\nAnd then, I believe this is\nunder Administrative Templates.\n\n501\n00:26:35.050 --> 00:26:36.220\nWe're gonna go into system.\n\n502\n00:26:37.680 --> 00:26:40.241\nThen if we scroll down here\nsomewhere in this list,\n\n503\n00:26:40.241 --> 00:26:44.473\nI believe there's removable storage, there\nwe go now right so let me kind of back out\n\n504\n00:26:44.473 --> 00:26:47.868\nhere to show you guys there and\njust to double check if you guys want,\n\n505\n00:26:47.868 --> 00:26:51.894\nif you're in our labs their practice\nlabs.com you guys can find this, right.\n\n506\n00:26:51.894 --> 00:26:58.610\nSo, this is Computer Configuration,\nAdministrative Templates, and System.\n\n507\n00:26:58.610 --> 00:27:02.440\nIf you're in a GPO that's in the domain,\nthe difference would be it would be\n\n508\n00:27:02.440 --> 00:27:06.960\nPolicies, Computer Configuration,\nAdministrative Templates, System.\n\n509\n00:27:06.960 --> 00:27:10.638\nJust a little bit different\nstructure there inside of your\n\n510\n00:27:10.638 --> 00:27:12.460\nDomain-Based Group Policies.\n\n511\n00:27:12.460 --> 00:27:14.890\nAnd then, if you scroll down all\nthe way to the bottom, right?\n\n512\n00:27:14.890 --> 00:27:19.470\nWe have things like for instance,\nRemovable Storage Access, right?\n\n513\n00:27:19.470 --> 00:27:22.567\nAnd then what I can do is\nI can come over here, and\n\n514\n00:27:22.567 --> 00:27:25.130\nlet me go ahead and just maximize this.\n\n515\n00:27:25.130 --> 00:27:27.380\nMake it a little easier for\nyou guys to see.\n\n516\n00:27:27.380 --> 00:27:31.210\nAll right, notice that I can Deny access.\n\n517\n00:27:31.210 --> 00:27:33.370\nLook at all of these different\nsettings that we have here.\n\n518\n00:27:33.370 --> 00:27:36.475\nFor instance, CD and DVD, right.\n\n519\n00:27:36.475 --> 00:27:41.246\nRemovable Disks, USB drives,\nall removable storages.\n\n520\n00:27:41.246 --> 00:27:44.760\nI could said here and all removable\nstorage classes Deny all access.\n\n521\n00:27:44.760 --> 00:27:51.249\nI can go ahead and if I wanted to, I could\nenable this and notice what this does.\n\n522\n00:27:51.249 --> 00:27:56.036\nThis is a business policy that if you\nenable this policy setting no access\n\n523\n00:27:56.036 --> 00:27:59.060\nallowed to any removable storage medium.\n\n524\n00:27:59.060 --> 00:28:03.160\nIf this might be too restrictive on your\nend, it doesn't have to be so restrictive.\n\n525\n00:28:04.300 --> 00:28:07.210\nThis might be something you do if you\njust don't wanna configure any other\n\n526\n00:28:07.210 --> 00:28:10.080\nsetting just say remove it all but\nthat might not be appropriate.\n\n527\n00:28:10.080 --> 00:28:13.190\nRemember availability,\nwe con go so confidential\n\n528\n00:28:13.190 --> 00:28:17.410\nthat even our legitimate users don't\ngain access to what they need access to.\n\n529\n00:28:17.410 --> 00:28:21.250\nSo, it might be something where\nmaybe you just do Removable Disk, or\n\n530\n00:28:21.250 --> 00:28:22.592\nmaybe you just say, you know what?\n\n531\n00:28:22.592 --> 00:28:25.850\nI wanna Deny write and execute access.\n\n532\n00:28:25.850 --> 00:28:27.610\nNow, that's a good one, why?\n\n533\n00:28:27.610 --> 00:28:28.880\nWhy not just the write access?\n\n534\n00:28:28.880 --> 00:28:30.810\nWhy execute access, right?\n\n535\n00:28:30.810 --> 00:28:33.737\nWell, we've talked a couple\nof times in this series,\n\n536\n00:28:33.737 --> 00:28:37.186\nthe attack where somebody puts\na bootable virus on a USB device.\n\n537\n00:28:37.186 --> 00:28:40.390\nAnd throws a whole bunch of those\ninto the garage there, and somebody\n\n538\n00:28:40.390 --> 00:28:44.490\nwalking through the parking lot grabs one\nof these and says, brand new USB device.\n\n539\n00:28:44.490 --> 00:28:45.760\nLet me see what's on it.\n\n540\n00:28:45.760 --> 00:28:46.900\nSticks it on the machine and\n\n541\n00:28:46.900 --> 00:28:50.810\nnow you got a malware running rampid\nthrough your machines on your network that\n\n542\n00:28:50.810 --> 00:28:54.240\nthey're doing things like cryptolocker\nif you will or cryptomalware.\n\n543\n00:28:54.240 --> 00:28:58.929\nSo, you might wanna do Deny write\naccess as well as execute access.\n\n544\n00:28:58.929 --> 00:29:02.100\nI don't really think we're gonna see\ntoo many floppy disk drives already.\n\n545\n00:29:02.100 --> 00:29:05.745\nAnd if you're running a floppy disk drive\non Windows 10, chances are your machine\n\n546\n00:29:05.745 --> 00:29:09.000\nneeds to be updated so, but it is in\nthere, and you do have the capability.\n\n547\n00:29:09.000 --> 00:29:15.550\nSo, to help with data loss prevention, one\nof the things you can do is USB blocking,\n\n548\n00:29:15.550 --> 00:29:19.010\nand you can go a little bit farther than\nthat too, and it could just be in general.\n\n549\n00:29:19.010 --> 00:29:20.360\nRemovable Storage Access.\n\n550\n00:29:20.360 --> 00:29:22.310\nSo, keep in mind those\nare a few things and\n\n551\n00:29:22.310 --> 00:29:24.600\na few of the scenarios that you might see.\n\n552\n00:29:24.600 --> 00:29:28.530\nAnd the technologies and the way we\ncan implement it to stop data loss.\n\n553\n00:29:28.530 --> 00:29:31.885\nWell, you don't wanna stop data\nloss prevention, to stop data loss.\n\n554\n00:29:31.885 --> 00:29:33.700\n&gt;&gt; [LAUGH] and guess what?\n\n555\n00:29:33.700 --> 00:29:35.080\nWe are not completely finished,\n\n556\n00:29:35.080 --> 00:29:37.800\nalthough we have covered a lot\nof information in this episode.\n\n557\n00:29:37.800 --> 00:29:38.890\nWe still have more to go.\n\n558\n00:29:38.890 --> 00:29:40.910\nSo please stay tuned,\nladies and gentleman.\n\n559\n00:29:40.910 --> 00:29:42.720\nFor this show we'll go ahead and sign out.\n\n560\n00:29:42.720 --> 00:29:44.390\nRemember, I'm your host, Cherokee Boose.\n\n561\n00:29:44.390 --> 00:29:44.954\n&gt;&gt; And I'm Wes Bryan.\n\n562\n00:29:44.954 --> 00:29:47.520\n&gt;&gt; See you next time here at ITProTV.\n\n563\n00:29:47.520 --> 00:29:54.327\n[MUSIC]\n\n564\n00:29:54.327 --> 00:29:59.919\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "212752461"
        },
        {
          "description": "Cherokee and Wes continue to examine how both hardware and software can impact security. In this episode they discuss several concepts such as Network Access Control (NAC), Mail Gateway, Bridges, SSL/TLS accelerators, SSL decryptors, Mail Gateways and Hardware Security Modules (HSM's).",
          "length": "1799",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-4-hardware_software_organizational_sec_pt4-041017-PGM.00_29_43_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-4-hardware_software_organizational_sec_pt4-041017-PGM.00_29_43_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-1-4-hardware_software_organizational_sec_pt4-041017-PGM.00_29_43_23.Still001-sm.jpg",
          "title": "Hardware Software Organizational Security Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:03.749\nWelcome to ITProTV,\n\n2\n00:00:03.749 --> 00:00:08.336\nI'm your host Don Pezet.\n\n3\n00:00:08.336 --> 00:00:11.658\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.658 --> 00:00:16.710\n&gt;&gt; Welcome to your CompTIA Security+\nseries, I'm your show host Cherokee Boose.\n\n5\n00:00:16.710 --> 00:00:20.490\nIn this episode we'll continue talking\nabout hardware and software, and\n\n6\n00:00:20.490 --> 00:00:23.740\nhow it affects the overall\nsecurity of an organization.\n\n7\n00:00:23.740 --> 00:00:25.880\nWith us today we have\nMr Wes Bryan in studios.\n\n8\n00:00:25.880 --> 00:00:26.940\nThank you for joining us Wes.\n\n9\n00:00:26.940 --> 00:00:28.440\n&gt;&gt; Hey Cherokee thanks for having me back.\n\n10\n00:00:28.440 --> 00:00:32.160\nYeah we are definitely working on a small\nmini series here, we're back with a part\n\n11\n00:00:32.160 --> 00:00:35.640\nfour because, well we just couldn't\nfit everything in the last episode.\n\n12\n00:00:35.640 --> 00:00:39.230\nSo we're got a few loss ends that\nwe wanna tie off in this episode.\n\n13\n00:00:39.230 --> 00:00:42.278\nOne of the things that we left off in the\nlast episode, we were talking about data\n\n14\n00:00:42.278 --> 00:00:44.795\nloss prevention and some of\nthe things that you need to consider.\n\n15\n00:00:44.795 --> 00:00:47.745\nThings like USB blocking, and\nI really called out things\n\n16\n00:00:47.745 --> 00:00:51.270\nlike any kind of removable media and\nhow you can lock that down.\n\n17\n00:00:51.270 --> 00:00:53.820\nAlso using things like\ncloud based solutions.\n\n18\n00:00:53.820 --> 00:00:55.240\nThat's very, very popular today.\n\n19\n00:00:55.240 --> 00:00:58.090\nWe wanna make sure that we don't\nhave any unsanctioned cloud\n\n20\n00:00:58.090 --> 00:01:00.630\nbased solutions that we're\nstoring our information in\n\n21\n00:01:00.630 --> 00:01:03.570\nbecause it might not have\nthe compliance that maybe we need.\n\n22\n00:01:03.570 --> 00:01:06.830\nSo that was another thing\nthat we had to look at.\n\n23\n00:01:06.830 --> 00:01:09.000\nOne of the last things was well,\nemail, right?\n\n24\n00:01:09.000 --> 00:01:12.850\nEmail could definitely be a source\nof data loss if you will, or\n\n25\n00:01:12.850 --> 00:01:17.580\ndata leakage, so it's definitely\nsomething we have to be aware of.\n\n26\n00:01:17.580 --> 00:01:21.730\nHowever in this episode, we're gonna\ntalk about a few different concepts.\n\n27\n00:01:21.730 --> 00:01:25.125\nOne of the first things that we're gonna\ntalk about as what's known as a mail\n\n28\n00:01:25.125 --> 00:01:25.995\ngateway.\n\n29\n00:01:25.995 --> 00:01:30.435\nAnd when we talk about email, right,\nwe've kind of mention the gateway in\n\n30\n00:01:30.435 --> 00:01:34.625\nsome other episodes but in the context\nto this episode, keep in mind that we're\n\n31\n00:01:34.625 --> 00:01:38.675\ntalking about things like\npreventing data leakage, data loss.\n\n32\n00:01:38.675 --> 00:01:42.680\nSo they talk about implementing\nthings like encryption, right?\n\n33\n00:01:42.680 --> 00:01:45.560\nSo we can implement encryption of our\nemails through things like the secure\n\n34\n00:01:45.560 --> 00:01:48.395\nmultimedia Internet mail extensions.\n\n35\n00:01:48.395 --> 00:01:50.070\nS/MIME, if I can remember\nthe acronym there,\n\n36\n00:01:50.070 --> 00:01:52.620\nand then implementing\nthings like spam filters.\n\n37\n00:01:52.620 --> 00:01:55.890\nKeep in mind,\nthat when we talk about spam filters,\n\n38\n00:01:55.890 --> 00:01:58.960\nyou could have things like a Barracuda\nserver that's sitting on your network and\n\n39\n00:01:58.960 --> 00:02:01.660\nit's screening all of your\ntraffic coming inline.\n\n40\n00:02:01.660 --> 00:02:04.060\nYou could have things like\nspam filters built in,\n\n41\n00:02:04.060 --> 00:02:07.480\nor baked in to the operating system,\nif you will.\n\n42\n00:02:07.480 --> 00:02:09.560\nOr maybe installed,\nnot necessarily baked in.\n\n43\n00:02:09.560 --> 00:02:14.120\nBut installed, in the operating system,\nthat your email server's running.\n\n44\n00:02:14.120 --> 00:02:18.190\nYou could also have things,\nlike host based spam filters too.\n\n45\n00:02:18.190 --> 00:02:22.000\nSo keep in mind, that we're not talking\nabout just a single technology, right?\n\n46\n00:02:22.000 --> 00:02:25.160\nWhen we talk about things like spam\nfilters, a layer defense system,\n\n47\n00:02:25.160 --> 00:02:29.150\nit can be screening all the traffic\nyou typically are with your firewalls.\n\n48\n00:02:29.150 --> 00:02:32.150\nScreening all of the emails that\nare coming into your network and\n\n49\n00:02:32.150 --> 00:02:33.240\ngetting them flagged.\n\n50\n00:02:33.240 --> 00:02:36.865\nIf it happens to be maybe\nit's identified as spam.\n\n51\n00:02:36.865 --> 00:02:39.565\nAnd maybe it doesn't make it to\nthe inbox of your end users.\n\n52\n00:02:39.565 --> 00:02:43.835\nAnd then, on top of that, you have the one\nthat's on the mail server itself too.\n\n53\n00:02:43.835 --> 00:02:45.095\nSo another layer of protection.\n\n54\n00:02:45.095 --> 00:02:47.720\nAnd then, finally,\nprotecting the host as well.\n\n55\n00:02:47.720 --> 00:02:52.120\nSo keep in mind, mail gateways,\nit is something that we have to lock down,\n\n56\n00:02:52.120 --> 00:02:53.640\nwe definitely have to secure.\n\n57\n00:02:53.640 --> 00:02:57.195\n&gt;&gt; Definitely not a one size fits all\nsolution and if you think back to our\n\n58\n00:02:57.195 --> 00:03:02.180\nCIA Triad, not only are we talking about\npreventing any kind of malware from\n\n59\n00:03:02.180 --> 00:03:05.970\napproaching on a network, and if you think\nabout just from the spam portion alone.\n\n60\n00:03:05.970 --> 00:03:08.770\nAnd the availability like\nnot to discount waste,\n\n61\n00:03:08.770 --> 00:03:12.020\nbecause that can definitely take\na lot of human resource as well.\n\n62\n00:03:12.020 --> 00:03:13.110\n&gt;&gt; Absolutely,\n\n63\n00:03:13.110 --> 00:03:16.200\nespecially when it comes to things like\ntrying to redo logs and everything.\n\n64\n00:03:16.200 --> 00:03:20.010\nSo it can get very, very complex.\n\n65\n00:03:20.010 --> 00:03:22.530\nAnother thing that they call out, they\ncall out, and this is kind of interesting,\n\n66\n00:03:22.530 --> 00:03:24.640\nI look at this when they call out bridges,\nright?\n\n67\n00:03:24.640 --> 00:03:25.930\nWell [LAUGH] when we look at bridges,\n\n68\n00:03:25.930 --> 00:03:28.820\nguys, today we have typically\nmulti-port bridges.\n\n69\n00:03:28.820 --> 00:03:30.900\nIf you're coming over from your Network+,\n\n70\n00:03:30.900 --> 00:03:35.510\nwe've talked about devices that help to,\nour redistribution points, right?\n\n71\n00:03:35.510 --> 00:03:39.860\nIn the earlier days, we might have\ntwo segments that we needed to, or\n\n72\n00:03:39.860 --> 00:03:42.390\nmaybe a physical bus,\nif I can get it right.\n\n73\n00:03:42.390 --> 00:03:45.000\nA physical bus that we\nneed to segment out, so\n\n74\n00:03:45.000 --> 00:03:48.790\nwe put a bridge into the middle of\nthat bus, and then what would it do?\n\n75\n00:03:48.790 --> 00:03:53.570\nIt would divide up that one contention\ndomain into two separate segments.\n\n76\n00:03:53.570 --> 00:03:57.710\nAnd those segments would become their\nown Individual contention domains for\n\n77\n00:03:57.710 --> 00:03:59.930\nthings like performance, if you will.\n\n78\n00:03:59.930 --> 00:04:03.020\nAll right, today, we typically\nhave multi-port bridges, right?\n\n79\n00:04:03.020 --> 00:04:06.670\nFor the longest time our switches\nare multi-port bridges, right?\n\n80\n00:04:06.670 --> 00:04:10.270\nSo today when you see wired bridging,\nI got a little diagram here.\n\n81\n00:04:10.270 --> 00:04:14.338\nWired bridging is really just\nagain having switches today.\n\n82\n00:04:14.338 --> 00:04:17.040\nBut the older bridges, again you'd\nhave a couple of network adapters and\n\n83\n00:04:17.040 --> 00:04:19.554\nagain they would make\na couple of segments here.\n\n84\n00:04:19.554 --> 00:04:23.030\nAnd this segment right here here\nwould be it's own collision and\n\n85\n00:04:23.030 --> 00:04:26.570\ncontention domain, and then you have\ncollision and contention domain over here.\n\n86\n00:04:26.570 --> 00:04:29.460\nHowever, I will say that you\nwill see things like for\n\n87\n00:04:29.460 --> 00:04:31.660\ninstance today still wireless bridges.\n\n88\n00:04:31.660 --> 00:04:33.760\nIf we've got two wired networks, and\n\n89\n00:04:33.760 --> 00:04:36.880\nmaybe we need to bridge between\nthe two networks as well.\n\n90\n00:04:36.880 --> 00:04:38.550\nYou can see things like wireless bridges.\n\n91\n00:04:38.550 --> 00:04:41.250\nBut again, for the most part today\n\n92\n00:04:41.250 --> 00:04:43.810\nWe're gonna be implementing what\nthey call multi-port bridges, right.\n\n93\n00:04:43.810 --> 00:04:45.260\nIt's essentially what a switch is and\n\n94\n00:04:45.260 --> 00:04:49.350\nwe can apply things like port security,\nMAC filtering if you will.\n\n95\n00:04:49.350 --> 00:04:55.490\nThings like 802.1X to these\ndevices in order to secure them.\n\n96\n00:04:55.490 --> 00:04:59.450\nLet's see what else there Miss Cherokee,\nthey call out.\n\n97\n00:04:59.450 --> 00:05:01.740\nThey call out something\nthat's kind of interesting.\n\n98\n00:05:01.740 --> 00:05:06.410\nNow we're gonna go shopping but this time\nI'm wanna protect Cherokee's card on this\n\n99\n00:05:06.410 --> 00:05:11.700\none because I may call it whats known\nas an SSL or TLS aggregator, all right?\n\n100\n00:05:11.700 --> 00:05:15.266\nAnd for the most part today,\nwe're using TLS.\n\n101\n00:05:15.266 --> 00:05:18.619\nI mean I guess you would probably still\nsee sites out there that are using SSL,\n\n102\n00:05:18.619 --> 00:05:21.470\nbut for the most part,\nyou wanna be using TLS today.\n\n103\n00:05:21.470 --> 00:05:26.080\nSo what is it when they talk about\nthese SSL and TLS aggregators?\n\n104\n00:05:26.080 --> 00:05:27.970\nWell, I want you to think of, and\n\n105\n00:05:27.970 --> 00:05:31.490\nthey do this in a lot of\ndifferent occasions, right?\n\n106\n00:05:31.490 --> 00:05:35.490\nImagine you have a website that\neverybody's going to, or a lot of people,\n\n107\n00:05:35.490 --> 00:05:39.880\nhigh volume of traffic, not say everybody,\ngenerically but a high volume of traffic.\n\n108\n00:05:39.880 --> 00:05:42.690\nAnd there's a lot of SSL or\nTLS communications, right?\n\n109\n00:05:42.690 --> 00:05:44.590\nThat's encryption and decryption.\n\n110\n00:05:44.590 --> 00:05:48.500\nWell, if the server or whatever the device\nis has to perform that encryption,\n\n111\n00:05:48.500 --> 00:05:52.370\nthen what you're gonna do is you're\ngonna be robbing other users of\n\n112\n00:05:52.370 --> 00:05:55.070\nmaybe valuable CPU cycles.\n\n113\n00:05:55.070 --> 00:05:58.900\nSo imagine that a way to do hardware\nacceleration where we could\n\n114\n00:05:58.900 --> 00:06:01.600\nfree up the CPUs that\nare within that machine.\n\n115\n00:06:01.600 --> 00:06:05.030\nAnd we can offload that to\na special dedicated device\n\n116\n00:06:05.030 --> 00:06:08.440\nthat does all the encryption and\nthe decryption for us.\n\n117\n00:06:08.440 --> 00:06:11.030\nAnd it can help to give the end\nuser a better experience,\n\n118\n00:06:11.030 --> 00:06:13.340\nespecially when you\nneed high availability.\n\n119\n00:06:13.340 --> 00:06:15.620\nAnd again you start to see things like for\ninstance,\n\n120\n00:06:15.620 --> 00:06:18.660\ntraffic spikes where maybe\nyou've got Black Friday, right?\n\n121\n00:06:18.660 --> 00:06:20.710\nAnd everybody's buying that one product.\n\n122\n00:06:20.710 --> 00:06:22.890\nSo a lot of those SSL communications or\n\n123\n00:06:22.890 --> 00:06:26.640\nTLS communications can really hinder\nthe performance of the server.\n\n124\n00:06:26.640 --> 00:06:31.731\nAnd if you think about it again, Cherokee\nmentioned the CIA Triad, availability\n\n125\n00:06:31.731 --> 00:06:36.549\nis important for just one or two extra\nseconds that people might have to wait.\n\n126\n00:06:36.549 --> 00:06:39.919\nIt might discourage people from continuing\non in their experience of buying your\n\n127\n00:06:39.919 --> 00:06:41.510\nproduct, so they go somewhere else.\n\n128\n00:06:41.510 --> 00:06:43.960\nNow, these are not cheap.\n\n129\n00:06:43.960 --> 00:06:46.250\nExcuse me, let's try a little\nbit better English then.\n\n130\n00:06:46.250 --> 00:06:47.220\nThese aren't cheap.\n\n131\n00:06:47.220 --> 00:06:48.360\nThey're very, very expensive.\n\n132\n00:06:48.360 --> 00:06:52.330\nIn fact I've got like a Google search up\nhere and you can kinda see that if we\n\n133\n00:06:52.330 --> 00:06:56.880\nweren't shopping here,\nwe've got some very, very expensive ones.\n\n134\n00:06:56.880 --> 00:06:57.923\nYou can see they can get\nvery very expensive.\n\n135\n00:06:57.923 --> 00:07:01.440\n&gt;&gt; Glad you're not putting this on\nmy budget or my account here Wes.\n\n136\n00:07:01.440 --> 00:07:03.160\n[LAUGH]\n&gt;&gt; No, I saved your card on this one.\n\n137\n00:07:03.160 --> 00:07:06.190\nUsually I pick on Cherokee and I'll say\nyeah we're gonna go shopping with her\n\n138\n00:07:06.190 --> 00:07:10.670\ncard, but this one right here, I mean you\ncan get a house for that price, okay.\n\n139\n00:07:10.670 --> 00:07:14.420\nSo again, keep in mind that these\nare very, very large companies.\n\n140\n00:07:14.420 --> 00:07:18.090\nYou do have the ability that\nsome cloud providers allow,\n\n141\n00:07:18.090 --> 00:07:22.090\nthings like TLS and SSL acceleration.\n\n142\n00:07:22.090 --> 00:07:26.300\nBut it is important to keep in\nmind what the purpose is, right?\n\n143\n00:07:26.300 --> 00:07:29.920\nSo for instance if we also\ntalk about having things like\n\n144\n00:07:29.920 --> 00:07:31.550\nTCP offload engines, right?\n\n145\n00:07:31.550 --> 00:07:34.550\nWell why would we want\na TCP offload engine?\n\n146\n00:07:34.550 --> 00:07:38.940\nWell you have to think about it, TCP is\nvery, very processor intensive, right?\n\n147\n00:07:38.940 --> 00:07:42.685\nBecause it's a staple connection protocol\nand it's constantly calling back to\n\n148\n00:07:42.685 --> 00:07:46.537\nthe source saying, hey, I didn't get\nthe next packet or this packet's not good,\n\n149\n00:07:46.537 --> 00:07:49.307\nsend me back the next packet\nin the communication, right?\n\n150\n00:07:49.307 --> 00:07:55.002\nWell, that's a lot of staple information,\na lot of sequencing, if you will,\n\n151\n00:07:55.002 --> 00:08:00.620\nand segmenting, and rebuilding of the\ninformation that has to go off To go on.\n\n152\n00:08:00.620 --> 00:08:04.647\nSo if we can take that, and\nwe have a dedicated board, within for\n\n153\n00:08:04.647 --> 00:08:08.302\ninstance the server,\njust like in SSL or TLS aggregator,\n\n154\n00:08:08.302 --> 00:08:13.390\nwe can take those TCP stateful connections\nand we can offload that to that board.\n\n155\n00:08:13.390 --> 00:08:15.960\nAnd then that board,\nit's hardware acceleration.\n\n156\n00:08:15.960 --> 00:08:20.360\nNow, if you're coming from A+ and Net+,\nyou probably heard about this term but\n\n157\n00:08:20.360 --> 00:08:21.980\nif you haven't let's just go ahead and\nrecap.\n\n158\n00:08:21.980 --> 00:08:25.283\nRemember that when you talk\nabout software acceleration,\n\n159\n00:08:25.283 --> 00:08:27.670\nI think of like a RAID arrays or\nRAID types.\n\n160\n00:08:27.670 --> 00:08:31.910\nIf I software based RAID then that means\nthat the operating system is having to\n\n161\n00:08:31.910 --> 00:08:35.290\nperform the RAID communications.\n\n162\n00:08:35.290 --> 00:08:38.330\nAnd that's wasting CPU cycles, right?\n\n163\n00:08:38.330 --> 00:08:40.800\nAnd I say wasting it, but\njust keep in mind it's not efficient.\n\n164\n00:08:40.800 --> 00:08:43.470\nHowever if I can get a dedicated\nRAID controller card,\n\n165\n00:08:43.470 --> 00:08:48.650\nwe're offloading that to the hardware, now\nI've got a card that all of its resources,\n\n166\n00:08:48.650 --> 00:08:52.825\nits CPU, its computation power,\nany memory that it has in its cache.\n\n167\n00:08:52.825 --> 00:08:56.475\nIt's all dedicated to that one device,\nrather than a CPU that's in an operating\n\n168\n00:08:56.475 --> 00:09:00.695\nsystem that could be doing multiple tasks,\nnot just that one.\n\n169\n00:09:00.695 --> 00:09:05.753\nSo back to the SSL and the TLS aggregator\nmuch like your RAID cards if you will,\n\n170\n00:09:05.753 --> 00:09:10.995\nhardware-based RAID cards,\nmuch like your TCP offload engines.\n\n171\n00:09:10.995 --> 00:09:13.910\nThese are dedicated hardware acceleration.\n\n172\n00:09:13.910 --> 00:09:17.290\nThat takes that out of the operating\nsystem, and puts that into the hands of\n\n173\n00:09:17.290 --> 00:09:22.020\nanother dedicated device, so that\nthe performance doesn't degrade at all.\n\n174\n00:09:22.020 --> 00:09:23.660\nNow-\n&gt;&gt; Wes, we see a lot of manufacturers\n\n175\n00:09:23.660 --> 00:09:28.495\ndoing that, trying to offset that stress\nfrom the CPU and a lot of our pieces of\n\n176\n00:09:28.495 --> 00:09:33.265\nhardware have dedicated, like with our\nGPUs and a lot of different components.\n\n177\n00:09:33.265 --> 00:09:34.845\n&gt;&gt; Most definitely, you go and\n\n178\n00:09:34.845 --> 00:09:37.965\nthink about things that the whole\npurpose of the GPU being invented right?\n\n179\n00:09:37.965 --> 00:09:41.690\nWe wanted to take those computations\nhappening in the graphics, and\n\n180\n00:09:41.690 --> 00:09:44.080\nwe wanted to move it to a dedicated card,\nright?\n\n181\n00:09:44.080 --> 00:09:45.800\nThe video card, really,\n\n182\n00:09:45.800 --> 00:09:50.380\nis one of the most basic analogies\nto hardware acceleration, right?\n\n183\n00:09:50.380 --> 00:09:54.986\nAnd it's one of the reasons you\nhave [LAUGH] these video cards that\n\n184\n00:09:54.986 --> 00:09:57.284\nlook like they could launch\nthe space shuttle, right?\n\n185\n00:09:57.284 --> 00:09:59.101\nIt's almost its own dedicated computer,\n\n186\n00:09:59.101 --> 00:10:01.533\nanother dedicated motherboard\nwithin a motherboard.\n\n187\n00:10:01.533 --> 00:10:04.820\nSo hardware acceleration\nis typically the way to go.\n\n188\n00:10:04.820 --> 00:10:09.220\nNow I wanna kinda zoom back if we\ncould here to my machine here.\n\n189\n00:10:09.220 --> 00:10:11.430\nThey call out something else on the exam.\n\n190\n00:10:11.430 --> 00:10:13.460\nAnd it's called an SSL decryptor.\n\n191\n00:10:13.460 --> 00:10:15.900\nAnd I want you to know that depending\non what company you talk to,\n\n192\n00:10:15.900 --> 00:10:17.660\nyou might hear a more generic term.\n\n193\n00:10:17.660 --> 00:10:19.000\nThat's a generic term.\n\n194\n00:10:19.000 --> 00:10:22.950\nYou might hear things like SSL\ninspection capabilities, all right.\n\n195\n00:10:22.950 --> 00:10:25.170\nAnd I want you to be aware\nof what that is, okay?\n\n196\n00:10:25.170 --> 00:10:29.280\nSo if you think about it, if I send an\nencrypted communication from my computer\n\n197\n00:10:29.280 --> 00:10:31.340\nto Ms. Cherokee's computer, right?\n\n198\n00:10:31.340 --> 00:10:34.550\nWe both have to have the encryption keys,\nbut really we're the only ones\n\n199\n00:10:34.550 --> 00:10:36.880\nthat are gonna be able to encrypt and\ndecrypt that information.\n\n200\n00:10:36.880 --> 00:10:40.150\nNow imagine if a company has a security\npolicy that they wanna be aware of\n\n201\n00:10:40.150 --> 00:10:42.760\nthe communications that\nare leaving their network.\n\n202\n00:10:42.760 --> 00:10:46.020\nIt's very, very hard to tell\nwhen you have encrypted traffic,\n\n203\n00:10:46.020 --> 00:10:47.620\nexactly what's leaving your network.\n\n204\n00:10:47.620 --> 00:10:51.600\nSo in that encrypted information\nthat I'm sending from myself to Ms.\n\n205\n00:10:51.600 --> 00:10:54.580\nCherokee, do I have things like\nintellectual property stored in there?\n\n206\n00:10:54.580 --> 00:10:58.280\nDo I have things like HIPAA compliance,\npatient records, right?\n\n207\n00:10:58.280 --> 00:11:00.440\nWell, how does a company know?\n\n208\n00:11:00.440 --> 00:11:01.810\nWell the company doesn't know.\n\n209\n00:11:01.810 --> 00:11:06.500\nSo with SSL inspection or an SSL decryptor\nI want you to think about it as a way for\n\n210\n00:11:06.500 --> 00:11:09.460\nthe company to perform their\nown man in the middle attack.\n\n211\n00:11:09.460 --> 00:11:10.340\nThat's really what it is.\n\n212\n00:11:10.340 --> 00:11:16.630\nIt takes the valid SSL or TLS key\nthat's used to decrypt the information.\n\n213\n00:11:16.630 --> 00:11:18.300\nEncrypting was with a public key, right?\n\n214\n00:11:18.300 --> 00:11:19.490\nEverybody has access to that.\n\n215\n00:11:19.490 --> 00:11:23.440\nBut it takes the private key\nthat does the decryption, right.\n\n216\n00:11:23.440 --> 00:11:28.120\nIt basically allows you to decrypt it,\nopen the information up, and\n\n217\n00:11:28.120 --> 00:11:31.765\nlook to see what's in that\ninformation to make sure.\n\n218\n00:11:31.765 --> 00:11:34.720\nThen you don't have a violation\nof security policy going on.\n\n219\n00:11:34.720 --> 00:11:37.000\nWe talk about security breaches.\n\n220\n00:11:37.000 --> 00:11:39.870\nVery basically, a security breach\nis nothing more than a violation of\n\n221\n00:11:39.870 --> 00:11:43.220\nthe security policy and it could be\nthe unacceptable use of somebody's\n\n222\n00:11:43.220 --> 00:11:45.130\nintellectual property\nwithin their business.\n\n223\n00:11:45.130 --> 00:11:49.750\n&gt;&gt; Sure, we focus a lot on that incoming\ntraffic, but also keep in mind, we spoke\n\n224\n00:11:49.750 --> 00:11:53.652\nearlier about our malicious insiders\n&gt;&gt; The outgoing traffic is just as\n\n225\n00:11:53.652 --> 00:11:57.306\nimportant when you're talking\nabout data leakage or data loss.\n\n226\n00:11:57.306 --> 00:12:01.010\n&gt;&gt; Definitely, so it's interesting,\nthey call out a few gateways here.\n\n227\n00:12:01.010 --> 00:12:04.810\nMight as well call out one of the other\ngateways too, and that's a media gateway.\n\n228\n00:12:04.810 --> 00:12:06.870\nWhen we talk about media gateways guys,\n\n229\n00:12:06.870 --> 00:12:10.580\nagain, remember what\nthe basic term gateway is.\n\n230\n00:12:10.580 --> 00:12:12.710\nGateway leads off of your network, right?\n\n231\n00:12:12.710 --> 00:12:15.870\nBut you might say well wait a second,\nWes, that's just a default gateway.\n\n232\n00:12:15.870 --> 00:12:19.746\nWell technically, but in a gateway in\nthe strictest sense of what we're talking\n\n233\n00:12:19.746 --> 00:12:22.432\nhere, we're talking about\nwhen we say media gateway.\n\n234\n00:12:22.432 --> 00:12:26.478\nI want you to know that we're going\nback to that concept of dissimilar\n\n235\n00:12:26.478 --> 00:12:28.380\ncommunication types, right?\n\n236\n00:12:28.380 --> 00:12:31.930\nImagine I've got real\ntime transport protocol,\n\n237\n00:12:31.930 --> 00:12:36.140\nRTMP real-time media transport\nprotocol information.\n\n238\n00:12:36.140 --> 00:12:40.630\nIf I've got H323 type information,\n\n239\n00:12:40.630 --> 00:12:44.570\nand I need to send that information\nonto a circuit switching network.\n\n240\n00:12:44.570 --> 00:12:48.890\nWell most LAN-based communications today\nour packet switching networks, right.\n\n241\n00:12:48.890 --> 00:12:52.440\nSo how is it that I get that information\nfrom a packet switching network out on to\n\n242\n00:12:52.440 --> 00:12:53.410\na circuit switching network?\n\n243\n00:12:53.410 --> 00:12:55.740\nWell, that's where your\nmedia gateway comes in.\n\n244\n00:12:55.740 --> 00:12:59.680\nKeep in mind, the gateway in this aspect\n\n245\n00:12:59.680 --> 00:13:02.750\nmost likely is gonna be an Edge\ndevice leading out of your network.\n\n246\n00:13:02.750 --> 00:13:06.730\nBut it's gonna be about transmitting or,\nexcuse me, transforming or\n\n247\n00:13:06.730 --> 00:13:09.420\nconverting that information\ninto a format that can be\n\n248\n00:13:09.420 --> 00:13:12.950\nplaced on a completely different\ncommunication technology.\n\n249\n00:13:12.950 --> 00:13:17.030\nSo for instance you might have a media\ngateway that is doing the conversion\n\n250\n00:13:17.030 --> 00:13:20.940\nbetween your traditional circuits\nwhich like PSTN lines versus\n\n251\n00:13:20.940 --> 00:13:24.630\nsomething that's going out over\nan Ethernet based communication or\n\n252\n00:13:24.630 --> 00:13:27.130\nsonnet if that happens to\nbe your WAN communication.\n\n253\n00:13:27.130 --> 00:13:31.900\nSo again, the communication protocols\nwouldn't be, they wouldn't happen,\n\n254\n00:13:31.900 --> 00:13:36.490\nthere wouldn't be an interoperability\nwith without these media type gateways.\n\n255\n00:13:36.490 --> 00:13:39.740\nSo basically just converting media\nstreams into different formats.\n\n256\n00:13:39.740 --> 00:13:45.020\nSo that kinda media stream\nis interoperable across\n\n257\n00:13:45.020 --> 00:13:49.470\ndifferent dissimilar communication types.\n\n258\n00:13:50.640 --> 00:13:53.020\nAll right,\nlet's see what else do they call out here?\n\n259\n00:13:53.020 --> 00:13:54.580\nThey also-\n&gt;&gt; HSM.\n\n260\n00:13:54.580 --> 00:13:56.690\n&gt;&gt; HSM, here's another acronym\nwe're gonna throw at you.\n\n261\n00:13:56.690 --> 00:14:01.160\nWe're not shy of any alphabet\nsoup in this series, for sure.\n\n262\n00:14:01.160 --> 00:14:04.680\nHSM is a hardware security model,\nor module, excuse me.\n\n263\n00:14:04.680 --> 00:14:10.070\nAnd basically this is a hardware based\ncryptographic processor, if you will.\n\n264\n00:14:10.070 --> 00:14:15.200\nTo give you an example\nof other processors,\n\n265\n00:14:15.200 --> 00:14:17.840\nthat maybe you're aware of,\nthat store cryptographic information.\n\n266\n00:14:17.840 --> 00:14:20.630\nTPM, inside of Windows-based\ncommunications.\n\n267\n00:14:20.630 --> 00:14:24.110\nIt's not an HSM, but it is a little chip\nthat's dedicated to the motherboard,\n\n268\n00:14:24.110 --> 00:14:28.000\nthat stores, essentially,\ncryptographic information.\n\n269\n00:14:28.000 --> 00:14:33.000\nAnd hardware security module goes\na little bit farther than just the TPM in\n\n270\n00:14:33.000 --> 00:14:37.090\nthe fact that what it's gonna do is it's\ngonna store your cryptographic keys for\n\n271\n00:14:37.090 --> 00:14:37.950\nyour network.\n\n272\n00:14:37.950 --> 00:14:40.450\nIt's going to ensure\nthat they are protected.\n\n273\n00:14:40.450 --> 00:14:44.030\nIt does things like, for instance,\nif you have code that's trying to\n\n274\n00:14:45.260 --> 00:14:48.080\nexecute on one of your machines\nfrom an external source and\n\n275\n00:14:48.080 --> 00:14:52.250\nHSM can actually block that\ntype of communication.\n\n276\n00:14:52.250 --> 00:14:57.780\nSo hardware security modules, these\ncould be an external dedicated device.\n\n277\n00:14:57.780 --> 00:15:00.800\nAnd if it's an external dedicated device,\nchances are it's gonna be very,\n\n278\n00:15:00.800 --> 00:15:01.621\nvery expensive.\n\n279\n00:15:01.621 --> 00:15:03.670\n&gt;&gt; [LAUGH] We're seeing\nthat big price tag again.\n\n280\n00:15:03.670 --> 00:15:04.870\n&gt;&gt; That's right, that's right.\n\n281\n00:15:04.870 --> 00:15:08.248\nSo just like, for instance,\nthe SSL accelerators or\n\n282\n00:15:08.248 --> 00:15:10.810\ninspections, inspectors if you will.\n\n283\n00:15:10.810 --> 00:15:13.190\nThese can also get very, very expensive.\n\n284\n00:15:13.190 --> 00:15:17.800\nLike I said an example of a hardware based\ndevice that does something like this is\n\n285\n00:15:17.800 --> 00:15:19.070\na trusted platform module.\n\n286\n00:15:21.290 --> 00:15:24.300\nHSMs, again they don't just\nhave to be an external device,\n\n287\n00:15:24.300 --> 00:15:27.500\nthey could be a plugin card\nlike an adapter card as well.\n\n288\n00:15:27.500 --> 00:15:29.930\nSo you could see that too.\n\n289\n00:15:29.930 --> 00:15:32.980\n&gt;&gt; Yeah, and the more we look at security,\nwe definitely have to see sometimes,\n\n290\n00:15:32.980 --> 00:15:35.930\nit's a little more expensive than\nwhat we might want to go ahead and\n\n291\n00:15:35.930 --> 00:15:40.770\nshell out the dollars, or wherever you\nare in the country, or in the world.\n\n292\n00:15:42.120 --> 00:15:44.570\nSometimes we need that, though.\n\n293\n00:15:44.570 --> 00:15:47.960\nWe just have to kinda look at that and\nmake sure that our outweigh the pros and\n\n294\n00:15:47.960 --> 00:15:50.190\ncons of a particular device or protocol.\n\n295\n00:15:50.190 --> 00:15:54.790\nSometimes we're talking about forfeiting\nspeed or forfeiting that money there,\n\n296\n00:15:54.790 --> 00:15:58.730\nbut it's all relative to what's\nimportant to you in your organization.\n\n297\n00:15:58.730 --> 00:15:59.817\n&gt;&gt; Most definitely, so for\n\n298\n00:15:59.817 --> 00:16:03.460\ninstance in an organization like us we're\nnot a very big organization right here.\n\n299\n00:16:03.460 --> 00:16:07.497\nWe Probably couldn't justify the cost\nof spending 80 to $150,000 on one of\n\n300\n00:16:07.497 --> 00:16:08.287\nthose devices.\n\n301\n00:16:08.287 --> 00:16:12.593\nBut if you're a place like Amazon\nthat stands to lose a million,\n\n302\n00:16:12.593 --> 00:16:17.410\ncouple million dollars an hour for\nsome kinda loss or like that.\n\n303\n00:16:17.410 --> 00:16:22.210\nYour company can probably justify spending\nthat kind of money to make sure that you\n\n304\n00:16:22.210 --> 00:16:25.310\nhave that high availability\nin the confidentiality and\n\n305\n00:16:25.310 --> 00:16:27.510\nthe integrity of your information, too.\n\n306\n00:16:28.590 --> 00:16:30.760\n&gt;&gt; You know Wes,\nthat brings us to the end of our list.\n\n307\n00:16:30.760 --> 00:16:33.720\nI know it's been quite a little\nminiseries like you had mentioned.\n\n308\n00:16:33.720 --> 00:16:36.730\nA lot of different shows within\nthis particular topic, but\n\n309\n00:16:36.730 --> 00:16:39.030\nI think that's about it for this one,\ndo you have any final thoughts?\n\n310\n00:16:39.030 --> 00:16:42.601\n&gt;&gt; Well, there is one last thing that I\ndo wanna kind of include in here, and\n\n311\n00:16:42.601 --> 00:16:44.017\nit is one that they call out.\n\n312\n00:16:44.017 --> 00:16:46.749\nAnd it's kind of weird because,\nwell that's not really weird but,\n\n313\n00:16:46.749 --> 00:16:48.634\nthis essentially a suite of technologies,\nand\n\n314\n00:16:48.634 --> 00:16:50.726\nthis is something known as\nnetwork access control.\n\n315\n00:16:50.726 --> 00:16:53.214\nAnd when we look at\nnetwork access control,\n\n316\n00:16:53.214 --> 00:16:58.180\nit's not about a single technology,\nit's actually about multiple technologies.\n\n317\n00:16:58.180 --> 00:17:02.990\nFor instance, and I know today it's\nkind of being tossed to the side,\n\n318\n00:17:02.990 --> 00:17:05.550\nbut Microsoft for\nawhile has had Network Access Protection.\n\n319\n00:17:06.970 --> 00:17:10.450\nToday we also have things like\nCisco's Network Admission Control.\n\n320\n00:17:10.450 --> 00:17:13.750\nAnd again,\nit's a group of technologies and\n\n321\n00:17:13.750 --> 00:17:18.300\npolicies that govern what devices and\nusers have access to your network.\n\n322\n00:17:18.300 --> 00:17:24.740\nIn fact, I've got kind of a NPS server\nup here, so we can kinda look at this.\n\n323\n00:17:24.740 --> 00:17:26.330\nThis is a network policy server.\n\n324\n00:17:26.330 --> 00:17:29.659\nSome of the things that they call out are,\nfor instance, host health checks.\n\n325\n00:17:30.720 --> 00:17:32.150\nWhat's a host health check?\n\n326\n00:17:32.150 --> 00:17:35.150\nWell, I want you to think about\na situation where a computer joins your\n\n327\n00:17:35.150 --> 00:17:36.160\nnetwork, right?\n\n328\n00:17:36.160 --> 00:17:39.560\nAnd when this computer joins your network,\nit doesn't have its firewall turned on,\n\n329\n00:17:39.560 --> 00:17:44.040\nit hasn't been up to date, doesn't have\nany malware software on it, or if it does,\n\n330\n00:17:44.040 --> 00:17:45.800\nit's been disabled.\n\n331\n00:17:45.800 --> 00:17:49.420\nIs that a computer that you potentially\nwant connecting to your network?\n\n332\n00:17:49.420 --> 00:17:51.640\nAnd the answer would probably be no.\n\n333\n00:17:51.640 --> 00:17:54.890\nSo one of the good things that we have\nis with network access control we have\n\n334\n00:17:54.890 --> 00:17:58.840\ntechnologies in which we can actually\nimplement something known as\n\n335\n00:17:58.840 --> 00:18:01.120\nConnection Request Policies,\nNetwork Policies.\n\n336\n00:18:01.120 --> 00:18:02.372\nAnd more importantly for\n\n337\n00:18:02.372 --> 00:18:05.480\none of the things that they call\nout here are Health Policies.\n\n338\n00:18:05.480 --> 00:18:09.293\nAnd a health policy just basically can,\n\n339\n00:18:09.293 --> 00:18:13.270\nin this case in Windows Health Policies.\n\n340\n00:18:13.270 --> 00:18:17.405\nIt works with Network Access Protection,\nSystem Health Validators, all right.\n\n341\n00:18:17.405 --> 00:18:20.490\nAnd the System Health Validator that\nwe have inside of Windows, is called\n\n342\n00:18:20.490 --> 00:18:24.330\na Security Health Validator, and I'll\nkind of show you what it's doing here.\n\n343\n00:18:24.330 --> 00:18:26.870\nIf we get down and\nwe kind of peer into its settings,\n\n344\n00:18:27.880 --> 00:18:30.820\nyou'll see what it's going to require,\nright?\n\n345\n00:18:30.820 --> 00:18:34.420\nSome of the things that we can require for\na computer that's joining our networks for\n\n346\n00:18:34.420 --> 00:18:36.650\ninstance, the firewall is enabled.\n\n347\n00:18:36.650 --> 00:18:38.930\nNotice it says Antivirus settings, right?\n\n348\n00:18:38.930 --> 00:18:41.906\nAntivirus application is on, and\neven more so that it's up to date.\n\n349\n00:18:41.906 --> 00:18:47.043\nFor this demonstration I'm gonna go\nahead and just show you the firewall and\n\n350\n00:18:47.043 --> 00:18:50.655\nhow that would react according\nto the health policy,\n\n351\n00:18:50.655 --> 00:18:55.030\nif we need to require that or\nif we disable it what happens.\n\n352\n00:18:55.030 --> 00:18:56.325\nIt makes it a little bit easier.\n\n353\n00:18:56.325 --> 00:18:59.035\nNow we also got, let me scroll down here,\n\n354\n00:18:59.035 --> 00:19:01.775\nwe got some additional things\nthat you can do, for instance.\n\n355\n00:19:01.775 --> 00:19:04.705\nLike making sure that Windows Updates\nare turned on, right,\n\n356\n00:19:04.705 --> 00:19:06.705\nand that we are up to date.\n\n357\n00:19:06.705 --> 00:19:08.220\nThings like spyware protection as well.\n\n358\n00:19:08.220 --> 00:19:10.938\nAnd not only is it on,\nbut is it up to date.\n\n359\n00:19:10.938 --> 00:19:15.825\nSo you can start to see we can really\ncontrol what we require a machine to have\n\n360\n00:19:15.825 --> 00:19:21.280\nturned on before we can give it access to\nthe network hence network access control.\n\n361\n00:19:21.280 --> 00:19:22.440\nAnd that's a very good thing.\n\n362\n00:19:22.440 --> 00:19:25.250\nNow what happens is when this computer,\nand let me go ahead,\n\n363\n00:19:25.250 --> 00:19:28.580\nwhat I'll do is I'll switch over to,\nI've got a client over here.\n\n364\n00:19:28.580 --> 00:19:29.790\nDid you have something?\n\n365\n00:19:29.790 --> 00:19:30.450\n&gt;&gt; Yeah, just,\n\n366\n00:19:30.450 --> 00:19:34.040\nI wanted to stress the importance of\nknowing those three components there.\n\n367\n00:19:34.040 --> 00:19:38.590\nThey really focus on knowing that\nyour anti-malware is up to date,\n\n368\n00:19:38.590 --> 00:19:41.630\nyour operating system is up to date.\n\n369\n00:19:41.630 --> 00:19:42.479\nAnd also, what was the third thing?\n\n370\n00:19:42.479 --> 00:19:43.672\nYour firewall is enabled.\n\n371\n00:19:43.672 --> 00:19:45.765\nSo those are three really\nimportant keys there.\n\n372\n00:19:45.765 --> 00:19:46.554\n&gt;&gt; And you know what?\n\n373\n00:19:46.554 --> 00:19:49.240\nThat does happen sometimes\nwith configurations.\n\n374\n00:19:49.240 --> 00:19:51.430\nPeople are like,\nI'll just disable a firewall, and\n\n375\n00:19:51.430 --> 00:19:53.220\nthat application starts to work again.\n\n376\n00:19:53.220 --> 00:19:54.177\nAnd it's like, okay, problem solved.\n\n377\n00:19:54.177 --> 00:19:56.600\n&gt;&gt; I actually saw that on a video\nI was watching the other day.\n\n378\n00:19:56.600 --> 00:19:59.530\nHe's like, yeah, we'll just disable that.\n\n379\n00:19:59.530 --> 00:20:02.516\n&gt;&gt; Believe it or not, I've seen it\nas a recommendation in a forum for\n\n380\n00:20:02.516 --> 00:20:03.450\ntroubleshooting.\n\n381\n00:20:03.450 --> 00:20:04.840\nI can't remember what application.\n\n382\n00:20:04.840 --> 00:20:06.410\nI worked for a company,\nwe were troubleshooting and\n\n383\n00:20:06.410 --> 00:20:09.130\nthey said disable the firewall,\nthat works for us.\n\n384\n00:20:09.130 --> 00:20:14.216\nAnd I said, okay, well I'm aware of that\nas a, not even a fix, but a temporary-\n\n385\n00:20:14.216 --> 00:20:14.901\n&gt;&gt; Work around?\n\n386\n00:20:14.901 --> 00:20:17.825\n&gt;&gt; Diagnostic,\njust to see if that's causing the problem.\n\n387\n00:20:17.825 --> 00:20:21.425\nBut no, no, they plainly said,\njust disable the firewall and\n\n388\n00:20:21.425 --> 00:20:22.945\nwalk away and call it a day.\n\n389\n00:20:22.945 --> 00:20:24.825\nAnd the problem with that is, well,\n\n390\n00:20:24.825 --> 00:20:27.385\nthen that leaves our systems open\nto some kind of attack, right?\n\n391\n00:20:27.385 --> 00:20:28.235\nThat's a vulnerability,\n\n392\n00:20:28.235 --> 00:20:31.615\nand it's certainly something we don't\nwant to allow inside of our networks.\n\n393\n00:20:31.615 --> 00:20:33.685\nNow, so how does this affect the client?\n\n394\n00:20:33.685 --> 00:20:37.955\nWell, if I go over to the client here,\nthe client has inside of it a service.\n\n395\n00:20:37.955 --> 00:20:39.759\nLet me go ahead and bring up our services.\n\n396\n00:20:42.150 --> 00:20:46.365\nAnd there is a service in here,\nif I can find it.\n\n397\n00:20:46.365 --> 00:20:48.840\nYep, Network Access Protection, right.\n\n398\n00:20:48.840 --> 00:20:50.685\nI wanna talk about this here, all right.\n\n399\n00:20:50.685 --> 00:20:52.600\nCuz this is also called out on the exam.\n\n400\n00:20:52.600 --> 00:20:56.964\nNotice it says Network Access Protection\nAgent Properties, and the agent is here.\n\n401\n00:20:56.964 --> 00:21:00.340\nYou can automatically start,\nmanually disable it.\n\n402\n00:21:00.340 --> 00:21:03.390\nAnd it's actually running right now cuz\nI can tell, cuz Start is grayed out.\n\n403\n00:21:03.390 --> 00:21:08.670\nNow, this agent is what's known\nas a permanent agent, all right?\n\n404\n00:21:08.670 --> 00:21:12.590\nIf you will, permanent agent is one\nthat's going to stay on the machine.\n\n405\n00:21:12.590 --> 00:21:16.950\nIt is something that I can't uninstall,\nnow, let me be careful with that,\n\n406\n00:21:16.950 --> 00:21:20.230\nbecause it could be a third\nparty agent that you install.\n\n407\n00:21:20.230 --> 00:21:22.130\nBut the thing is,\nwhen I reboot the computer,\n\n408\n00:21:22.130 --> 00:21:25.690\nit's still an application that's running\non the machine, the application is, right?\n\n409\n00:21:25.690 --> 00:21:29.640\nAnd you can see that this actually has,\nit built into the operating system, so\n\n410\n00:21:29.640 --> 00:21:33.460\nthis is a truly permanent\nagent if you will.\n\n411\n00:21:33.460 --> 00:21:36.140\nUnlike something that's known\nas a dissolvable agent, right?\n\n412\n00:21:36.140 --> 00:21:39.690\nI might wanna control and\ngovern access to a machine, or\n\n413\n00:21:39.690 --> 00:21:41.990\nthat machine's ability to\nconnect to my network.\n\n414\n00:21:41.990 --> 00:21:45.260\nSo what I do is I set up,\nfor instance, a website.\n\n415\n00:21:45.260 --> 00:21:48.230\nAnd a website has a small,\nlittle program that it runs.\n\n416\n00:21:48.230 --> 00:21:50.700\nAnd all you do is you\nauthenticate against the website.\n\n417\n00:21:50.700 --> 00:21:53.890\nIt runs, it checks your computer,\nand it sends your\n\n418\n00:21:53.890 --> 00:21:58.718\nhealth attestation report out to\nwhatever the registration authority is.\n\n419\n00:21:58.718 --> 00:22:02.790\nThey inspect it, and if you meet\nthe compliance, you join the network.\n\n420\n00:22:02.790 --> 00:22:07.110\nBut then, it's never, it didn't, it just\nran once, right, it doesn't install.\n\n421\n00:22:07.110 --> 00:22:11.870\nThat's a dissolvable agent, like an agent\nlike this, which is actually persistent.\n\n422\n00:22:11.870 --> 00:22:13.950\nAnd we've got more to show than just this.\n\n423\n00:22:13.950 --> 00:22:17.530\nLike, for instance,\nI could drop down to a command line,\n\n424\n00:22:17.530 --> 00:22:23.390\nand I can run napclcfg.,\nI believe it's an msc.\n\n425\n00:22:23.390 --> 00:22:24.640\nYeah, and here we go.\n\n426\n00:22:24.640 --> 00:22:28.400\nYou can see that we have our\nNAP Client Configuration.\n\n427\n00:22:28.400 --> 00:22:30.650\nAnd again,\nwe have our Enforcement Clients.\n\n428\n00:22:30.650 --> 00:22:36.130\nAnd you can see, in this case, this client\nis doing DHCP Quarantine, all right.\n\n429\n00:22:36.130 --> 00:22:41.130\nAnd let's see, let me do an ipconfig here,\nsee what my current IP address is.\n\n430\n00:22:42.320 --> 00:22:44.740\nAll right, so\nit looks like we can connect.\n\n431\n00:22:44.740 --> 00:22:45.630\nLet's do a ping.\n\n432\n00:22:45.630 --> 00:22:49.985\nAll right, I'm gonna ping the default\ngateway within this network, oops,\n\n433\n00:22:49.985 --> 00:22:51.067\nclose enough Wes.\n\n434\n00:22:51.067 --> 00:22:53.179\nYou don't have to get the IP address,\nright?\n\n435\n00:22:53.179 --> 00:22:56.640\n[LAUGH] And you can see that yeah,\nI can communicate-\n\n436\n00:22:56.640 --> 00:22:57.680\n&gt;&gt; Only if you want it to work.\n\n437\n00:22:57.680 --> 00:22:59.080\n&gt;&gt; That's right,\nonly if you want it to work.\n\n438\n00:22:59.080 --> 00:23:01.610\nYou could do it that way,\nand you'd be wrong.\n\n439\n00:23:01.610 --> 00:23:05.710\nSo I can ping the default gateway,\nyou notice that I have communications.\n\n440\n00:23:05.710 --> 00:23:10.260\nLet's see, I could ping the NPS server,\nall right, so\n\n441\n00:23:10.260 --> 00:23:12.560\nI've got communications\nwithin this network.\n\n442\n00:23:12.560 --> 00:23:15.800\nAll right, now let's go ahead and let's\ncheck out the state of the firewall here,\n\n443\n00:23:15.800 --> 00:23:19.220\nso I'm gonna drop down to the Control\nPanel, I'm gonna go to System and\n\n444\n00:23:19.220 --> 00:23:22.580\nSecurity, and then I'm gonna\nopen up the Windows Firewall.\n\n445\n00:23:23.910 --> 00:23:26.980\nAll right, now I want you to notice\nsomething, notice that the firewall is on,\n\n446\n00:23:26.980 --> 00:23:31.430\nit tells me that I've got green check\nmarks all the way down the board.\n\n447\n00:23:31.430 --> 00:23:33.520\nAnd I am connected to the public network.\n\n448\n00:23:33.520 --> 00:23:38.860\nHowever, if I turn around here, I can\nactually turn off the firewall again.\n\n449\n00:23:38.860 --> 00:23:42.290\nAssimilating like maybe\na misconfiguration on the user's part or\n\n450\n00:23:42.290 --> 00:23:47.920\nsomebody paying attention to the wrong\nforums to troubleshoot their applications.\n\n451\n00:23:47.920 --> 00:23:50.240\nWe'll choose okay to this.\n\n452\n00:23:50.240 --> 00:23:54.026\nAnd notice it says Turn on the Windows\nFirewall, it's letting me know,\n\n453\n00:23:54.026 --> 00:23:56.862\nwell wait a second, what happened?\n\n454\n00:23:56.862 --> 00:24:01.420\nIt said Network Access Protection,\nnetwork access might be limited here.\n\n455\n00:24:01.420 --> 00:24:03.592\nAnd it kicked the firewall right back on.\n\n456\n00:24:03.592 --> 00:24:05.020\nSo what happened?\n\n457\n00:24:05.020 --> 00:24:08.701\nWell, I want you to understand that it's\ndoing what's known as auto-remediation.\n\n458\n00:24:08.701 --> 00:24:12.133\nAnd that's one good thing about\na centralized network access\n\n459\n00:24:12.133 --> 00:24:15.631\ncontrol solution, is the moment\nthat I turn the firewall off,\n\n460\n00:24:15.631 --> 00:24:18.825\nit sent a health report out\nto the network policy server.\n\n461\n00:24:18.825 --> 00:24:22.370\nThe network policy servers says no,\nyou turn that thing back on,\n\n462\n00:24:22.370 --> 00:24:24.245\nthat's the health requirement.\n\n463\n00:24:24.245 --> 00:24:28.613\nSo we can go a little bit farther here,\nand I can, let see,\n\n464\n00:24:28.613 --> 00:24:31.505\nI could actually tell it, you know what?\n\n465\n00:24:31.505 --> 00:24:35.008\nI don't care what the network\npolicy server says,\n\n466\n00:24:35.008 --> 00:24:37.375\nwe're gonna kinda break it here.\n\n467\n00:24:37.375 --> 00:24:42.218\nAll right and I'll go down to the Windows\nFirewall service in the background\n\n468\n00:24:42.218 --> 00:24:45.637\nbecause that's what's\nallowing it to kick back on.\n\n469\n00:24:45.637 --> 00:24:49.685\nWe've got this Firewall service here,\nso I'm gonna go ahead and\n\n470\n00:24:49.685 --> 00:24:53.600\nI wanna change it to Disabled\nbefore it tries to kick it back on.\n\n471\n00:24:53.600 --> 00:24:54.953\nAnd we'll go ahead and Apply this.\n\n472\n00:24:54.953 --> 00:24:58.009\nNow I want you to pay attention,\nmy head's kind of covering it up,\n\n473\n00:24:58.009 --> 00:25:01.440\nbut watch what happens to\nthis bubble here in a second.\n\n474\n00:25:01.440 --> 00:25:04.706\nNotice it says Network Access Protection\nmight be limited.\n\n475\n00:25:04.706 --> 00:25:10.000\nLet's go ahead and what we'll do is,\nlet's rerun our IP config, oops.\n\n476\n00:25:10.000 --> 00:25:13.770\nIf I can spell IP config, all right.\n\n477\n00:25:13.770 --> 00:25:18.440\nI want you to notice something here,\nnotice our connection specific DNS suffix.\n\n478\n00:25:18.440 --> 00:25:19.710\nI've actually been quarantined.\n\n479\n00:25:19.710 --> 00:25:24.710\nI'm now on the demo.ITProTV\nquarantine network, right.\n\n480\n00:25:24.710 --> 00:25:28.790\nAnd what would happen was, I'd get\nkicked off to the quarantine network,\n\n481\n00:25:28.790 --> 00:25:29.711\nit remediates.\n\n482\n00:25:29.711 --> 00:25:33.160\nAnd immediately sends me back over to\nthe network that I'm supposed to be on.\n\n483\n00:25:33.160 --> 00:25:38.330\nLet's try to ping some of those IP\naddresses that we could ping earlier,\n\n484\n00:25:38.330 --> 00:25:39.610\nin that demonstration.\n\n485\n00:25:39.610 --> 00:25:44.520\nLet's go ahead and see if we can\nping the default gateway here, 1.1.\n\n486\n00:25:44.520 --> 00:25:46.470\nAnd notice we get our transmit failed,\nright?\n\n487\n00:25:46.470 --> 00:25:50.300\nIt knows where it is, it knows it has a\nroute, it's looking at its routing table.\n\n488\n00:25:50.300 --> 00:25:53.560\nIt says, I know how to talk to it,\nbut I can't communicate with it.\n\n489\n00:25:53.560 --> 00:25:56.640\nSo let's go ahead and\nlet's go ahead and ping the NPS server.\n\n490\n00:25:57.770 --> 00:26:01.390\nNow, why is it that I'm getting\nreplies from the NPS server?\n\n491\n00:26:01.390 --> 00:26:04.138\nWell when we do a remediation,\nwe can't lock you out completely.\n\n492\n00:26:04.138 --> 00:26:05.681\nWe want-\n&gt;&gt; We still have to know those policies.\n\n493\n00:26:05.681 --> 00:26:06.747\n[LAUGH]\n&gt;&gt; That's right, exactly.\n\n494\n00:26:06.747 --> 00:26:12.020\nAnd we got to be able to talk to the NPS\nserver to say, hey, you know what?\n\n495\n00:26:12.020 --> 00:26:15.195\nWe fixed the problem here and\nhere's my health certificate.\n\n496\n00:26:15.195 --> 00:26:18.500\nHere's what my services\ncurrently look like.\n\n497\n00:26:18.500 --> 00:26:20.440\nSo let's go ahead and let's do that.\n\n498\n00:26:20.440 --> 00:26:23.750\nLet's go back to System and\n\n499\n00:26:23.750 --> 00:26:27.740\nwe'll see if we can come back\ninto compliance with the policy.\n\n500\n00:26:27.740 --> 00:26:30.430\nChoose Apply, we'll choose Start.\n\n501\n00:26:30.430 --> 00:26:31.790\nAnd I would almost be willing to bet,\n\n502\n00:26:31.790 --> 00:26:35.920\nbut by the time I can get back to\nthis command prompt and hit Ping.\n\n503\n00:26:35.920 --> 00:26:39.608\nThere we go,\nI can ping the default gateway again.\n\n504\n00:26:39.608 --> 00:26:41.745\nAnd if I rerun my IP config option,\n\n505\n00:26:41.745 --> 00:26:45.443\nyou'll notice that my\nconnection-specific DNS Suffix.\n\n506\n00:26:45.443 --> 00:26:46.177\n&gt;&gt; Yay.\n\n507\n00:26:46.177 --> 00:26:47.288\n[LAUGH]\n&gt;&gt; That's right,\n\n508\n00:26:47.288 --> 00:26:52.520\nhas us back on the main network, I have\nan IP address that isn't masked out.\n\n509\n00:26:52.520 --> 00:26:57.422\nAnd I can now communicate\nwith the default gateway.\n\n510\n00:26:57.422 --> 00:27:01.820\nI'll get it right eventually,\nnow that we are in compliance.\n\n511\n00:27:01.820 --> 00:27:05.130\nSo that's a little about\nnetwork access control.\n\n512\n00:27:05.130 --> 00:27:09.220\nKind of shows you, again, keep in mind\npermanent versus persistent agents.\n\n513\n00:27:09.220 --> 00:27:16.830\nAnd it's permanent or persistent,\nsometimes they're used synonymously.\n\n514\n00:27:16.830 --> 00:27:18.660\nIt just means the agent stays on the host.\n\n515\n00:27:18.660 --> 00:27:20.230\nIf I reboot the computer, guess what?\n\n516\n00:27:20.230 --> 00:27:21.640\nThat service is still gonna be there.\n\n517\n00:27:21.640 --> 00:27:25.500\nThat client agent is still gonna be there,\nversus something that's dissolvable.\n\n518\n00:27:25.500 --> 00:27:27.830\nI log into a website, it runs a check,\n\n519\n00:27:27.830 --> 00:27:31.388\nif I reboot the computer anything that\nwas in memory is scrubbed, right?\n\n520\n00:27:31.388 --> 00:27:36.260\nSo I'd have to go back to that website\nagain, run that check one more time, and\n\n521\n00:27:36.260 --> 00:27:38.880\nthen I get access to the network.\n\n522\n00:27:38.880 --> 00:27:43.500\nThat's the dissolveable,\nor non-persistent, agent.\n\n523\n00:27:43.500 --> 00:27:46.090\nThey do call out one last one there,\nCherokee.\n\n524\n00:27:46.090 --> 00:27:47.460\nI know we're running out of time.\n\n525\n00:27:47.460 --> 00:27:50.850\nThey do call one last one,\nthey call agentless, completely agent.\n\n526\n00:27:50.850 --> 00:27:54.220\nIt doesn't say dissolveable,\nbut agentless, all right?\n\n527\n00:27:54.220 --> 00:27:58.260\nLet me give you an example of an agentless\nnetwork access control technology.\n\n528\n00:27:58.260 --> 00:28:01.280\nFor instance, active directory,\ndirectory services.\n\n529\n00:28:01.280 --> 00:28:04.880\nRight, when we talk about ADDS,\nif you want your computer to be able to\n\n530\n00:28:04.880 --> 00:28:08.314\ncommunicate within the domain environment,\nwhat do I have to do?\n\n531\n00:28:08.314 --> 00:28:09.049\nI have to join the computer to the domain.\n\n532\n00:28:09.049 --> 00:28:10.207\n&gt;&gt; Follow those rules.\n\n533\n00:28:10.207 --> 00:28:12.520\n&gt;&gt; That's right,\nhave to follow those rules.\n\n534\n00:28:12.520 --> 00:28:15.720\nBut there's nothing that I\nhave to install to do that.\n\n535\n00:28:15.720 --> 00:28:18.790\nI just have to make sure I have the right\nedition of Windows in order to do\n\n536\n00:28:18.790 --> 00:28:19.510\nthat, right.\n\n537\n00:28:19.510 --> 00:28:21.660\nThe Professional and\nthe Business editions.\n\n538\n00:28:21.660 --> 00:28:25.760\nNow, I didn't have to install anything,\nright, that's agentless.\n\n539\n00:28:25.760 --> 00:28:29.680\nAnd then once I join the domain,\nnow my computer has a trust relationship.\n\n540\n00:28:29.680 --> 00:28:32.903\nAnd I can log in if I\nhave a domain account.\n\n541\n00:28:32.903 --> 00:28:36.507\nAnd then a systems administrator can\ngovern what level of access I have to\n\n542\n00:28:36.507 --> 00:28:39.230\nthe resources or\nthe objects within the domain.\n\n543\n00:28:39.230 --> 00:28:43.400\nBut the one thing that the systems\nadministrator didn't have to do is setup\n\n544\n00:28:43.400 --> 00:28:45.994\na website that I click\non to download an agent.\n\n545\n00:28:45.994 --> 00:28:49.782\nOr was there any agent required to be on\nthe machine in order to gain access to\n\n546\n00:28:49.782 --> 00:28:51.660\nthe Active Directory environment?\n\n547\n00:28:51.660 --> 00:28:54.050\nI just have to have the permissions and\nthe privileges to do that.\n\n548\n00:28:55.800 --> 00:28:57.750\nWhat's an example of another one?\n\n549\n00:28:57.750 --> 00:29:01.231\n&gt;&gt; Yeah, Wes, if we look at different\ntechnologies like different pieces of\n\n550\n00:29:01.231 --> 00:29:04.281\nCisco equipment that are able to\nenforce these policies as well.\n\n551\n00:29:04.281 --> 00:29:08.680\n&gt;&gt; Definitely, with the 802.1x,\nbeing a port based authentication.\n\n552\n00:29:08.680 --> 00:29:12.489\nAgain, it's something, it could require an\nagent, but it doesn't have to be, right?\n\n553\n00:29:12.489 --> 00:29:16.783\nAgain, shut down the port, you hand that\nauthentication off to a radius server.\n\n554\n00:29:16.783 --> 00:29:20.448\nAnd it becomes transparent to the end user\nwithout having to do the install of any\n\n555\n00:29:20.448 --> 00:29:21.280\nextra software.\n\n556\n00:29:21.280 --> 00:29:25.544\nSo we do have the agent list technologies\nout there when it comes to network access\n\n557\n00:29:25.544 --> 00:29:26.118\ncontrol.\n\n558\n00:29:26.118 --> 00:29:27.991\n&gt;&gt; Yes, it's been a long journey, but\n\n559\n00:29:27.991 --> 00:29:31.497\nwe have covered several different\ntopics looking at the hardware and\n\n560\n00:29:31.497 --> 00:29:35.250\nthe software aspects to improve our\noverall organizational security.\n\n561\n00:29:35.250 --> 00:29:38.250\nSo thank you for joining us Wes and\nthank you ladies and gentleman.\n\n562\n00:29:38.250 --> 00:29:39.990\nFor this show,\nwe'll go ahead and sign off.\n\n563\n00:29:39.990 --> 00:29:41.630\nRemember, I'm your host, Cherokee Boose.\n\n564\n00:29:41.630 --> 00:29:42.488\n&gt;&gt; And I'm Wes Bryan.\n\n565\n00:29:42.488 --> 00:29:44.542\n&gt;&gt; See you next time, here at ITProTV.\n\n566\n00:29:44.542 --> 00:29:51.803\n[MUSIC]\n\n567\n00:29:51.803 --> 00:29:53.580\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213512478"
        },
        {
          "description": "In this show, Cherokee and Wes begin a discussion focused on software-based utilities that can assist in remaining compliant with an organizations security posture. Wes demonstrates several tools such as Wireshark, Nexpose and other wireless scanners.",
          "length": "1407",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-1-security_posture_assessment-041117-PGM.00_25_42_11.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-1-security_posture_assessment-041117-PGM.00_25_42_11.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-1-security_posture_assessment-041117-PGM.00_25_42_11.Still001-sm.jpg",
          "title": "Security Posture Assessment",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:06.001\nWelcome to ITProTV, I'm your host,\nDon Pezet [CROSSTALK]\n\n2\n00:00:06.001 --> 00:00:08.428\n[MUSIC]\n\n3\n00:00:08.428 --> 00:00:12.157\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.157 --> 00:00:14.650\n&gt;&gt; Welcome to your\nComp TIA Security+ series.\n\n5\n00:00:14.650 --> 00:00:16.590\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.590 --> 00:00:20.550\nIn this episode we'll look at software\nbased security posture assessments.\n\n7\n00:00:20.550 --> 00:00:23.060\nWith us today we have\nMister Wes Bryan in studios.\n\n8\n00:00:23.060 --> 00:00:24.080\nThank you for joining us, Wes.\n\n9\n00:00:24.080 --> 00:00:25.460\n&gt;&gt; Hey, thanks for\nhaving me back Cherokee.\n\n10\n00:00:25.460 --> 00:00:29.210\nThat's right, we're going to be looking at\nvarious software utilities that you can\n\n11\n00:00:29.210 --> 00:00:33.400\nuse in order to assess the overall\nsecurity posture of your organization.\n\n12\n00:00:33.400 --> 00:00:37.850\nSo, what is security posture, but security\nposture is really your overall stance on\n\n13\n00:00:37.850 --> 00:00:41.610\nwhat security means to your company and\nhow it's implemented with in your company.\n\n14\n00:00:41.610 --> 00:00:44.910\nIt could be it's typically a combination\nof a lot of different things,\n\n15\n00:00:44.910 --> 00:00:48.218\nwhether it be policies, the technologies,\nthings like encryption.\n\n16\n00:00:48.218 --> 00:00:51.947\nThe encryption protocols that you\nimplement inside of your organization.\n\n17\n00:00:51.947 --> 00:00:56.379\nSo It is important to understand some\nof the utilities that you can utilize,\n\n18\n00:00:56.379 --> 00:01:00.200\nif you will,\nin order to make this type of assessment.\n\n19\n00:01:00.200 --> 00:01:01.940\nThen they call out many different ones.\n\n20\n00:01:01.940 --> 00:01:03.305\nSome of them we'll talk about and\n\n21\n00:01:03.305 --> 00:01:06.104\nsome of them we'll try to give you\na little bit of demostration too.\n\n22\n00:01:06.104 --> 00:01:09.780\nOne of the first ones they call out\nare what are known as network scanners.\n\n23\n00:01:09.780 --> 00:01:14.510\nAnd when it comes to a network scanner,\ndon't think of this as protocol analyzers,\n\n24\n00:01:14.510 --> 00:01:15.140\nright.\n\n25\n00:01:15.140 --> 00:01:16.840\nThey do call out protocol analyzers.\n\n26\n00:01:16.840 --> 00:01:19.449\nAnd we'll look at a protocol\nanalyzer here coming up.\n\n27\n00:01:19.449 --> 00:01:25.000\nBut with a network monitor, these type of\ndevices, they can be very powerful, right.\n\n28\n00:01:25.000 --> 00:01:30.220\nThey can do things like rogue device\ndetection, network mapping, things like,\n\n29\n00:01:30.220 --> 00:01:36.160\nfor instance, IP the IPs that are within\nyour architecture, if you will.\n\n30\n00:01:36.160 --> 00:01:37.980\nWhat are you live hosts that you have?\n\n31\n00:01:37.980 --> 00:01:41.160\nWhat are the roles that are performed\ninside of your networks?\n\n32\n00:01:41.160 --> 00:01:43.890\nReal time traffic flow, if you will.\n\n33\n00:01:43.890 --> 00:01:45.030\nTraffic monitoring.\n\n34\n00:01:45.030 --> 00:01:48.925\nSo very, very powerful devices and\nor pieces of software.\n\n35\n00:01:48.925 --> 00:01:52.023\nAnd it's a little bit different\nthan a protocol analyzer cuz,\n\n36\n00:01:52.023 --> 00:01:55.884\na protocol analyzer is something that we\nuse to kind of eavesdrop on the traffic\n\n37\n00:01:55.884 --> 00:01:58.943\nto get an idea of the traffic\nthat is going across our network.\n\n38\n00:01:58.943 --> 00:02:02.882\nAnd It depends on where we implement them,\non how much traffic we're actually\n\n39\n00:02:02.882 --> 00:02:06.357\ngonna see if we do something like\nport mirroring on a switch, right?\n\n40\n00:02:06.357 --> 00:02:09.000\nAnd we plug into a switch and\nwe have all of that traffic,\n\n41\n00:02:09.000 --> 00:02:11.750\nbasically just mirrored\nover to that one port.\n\n42\n00:02:11.750 --> 00:02:15.100\nThen what we can do is we can actually\ncapture all the traffic on our network.\n\n43\n00:02:15.100 --> 00:02:18.700\nHowever, if we're gonna\nuse this wire shark or\n\n44\n00:02:18.700 --> 00:02:20.870\nmessage analyzer that\nMicrosoft has out there.\n\n45\n00:02:20.870 --> 00:02:25.323\nThey're basically the successor\nto the earlier network monitor.\n\n46\n00:02:25.323 --> 00:02:28.668\nIf we're running this on a laptop\nthen what we're really only seeing\n\n47\n00:02:28.668 --> 00:02:32.494\nis things like your broadcast\ncommunications, multicast communications.\n\n48\n00:02:32.494 --> 00:02:35.435\nAnd then the unicast communications\nthat are coming to and\n\n49\n00:02:35.435 --> 00:02:37.660\nfrom the device that its running on.\n\n50\n00:02:37.660 --> 00:02:41.229\nBut that can give you some information,\ntoo, about a specific device as well.\n\n51\n00:02:41.229 --> 00:02:45.440\nIf it, let's say for instance your\ncorporate policy says that certain\n\n52\n00:02:45.440 --> 00:02:48.460\nmachines need to have\nencrypted communications,\n\n53\n00:02:48.460 --> 00:02:51.003\nthey require encrypted communications.\n\n54\n00:02:51.003 --> 00:02:54.688\nWell, I most certainly can run something\nlike a protocol analyzer on that device\n\n55\n00:02:54.688 --> 00:02:57.080\nand then send a communication\nto another Endpoint.\n\n56\n00:02:57.080 --> 00:03:00.880\nAnd then we can kinda see, well,\nis it encrypted traffic, right?\n\n57\n00:03:00.880 --> 00:03:02.680\nAgain, that might be part\nof our corporate policy.\n\n58\n00:03:02.680 --> 00:03:06.360\nIn fact,\nlet me give you a little example here.\n\n59\n00:03:06.360 --> 00:03:11.220\nSo on this Windows machine, what I have\nis I have a Windows 10 machine here.\n\n60\n00:03:11.220 --> 00:03:14.550\nAnd we actually have\nWireshark installed on it.\n\n61\n00:03:14.550 --> 00:03:18.450\nSo I can go ahead and\nI'll bring up Wireshark here and\n\n62\n00:03:18.450 --> 00:03:21.720\nwhat we're gonna do is we're gonna just\nkind of start a little ping, right?\n\n63\n00:03:21.720 --> 00:03:25.810\nWe'll ping another device and then we're\ngonna run a little packet capture here and\n\n64\n00:03:25.810 --> 00:03:29.870\nsee if we do have encrypted\ntraffic running on this machine.\n\n65\n00:03:29.870 --> 00:03:34.264\nAnd so let me go ahead and\nbring up this command prompt real quick.\n\n66\n00:03:34.264 --> 00:03:37.065\n&gt;&gt; Sure, so Wireshark isn't specifically,\n\n67\n00:03:37.065 --> 00:03:40.405\nwe might not be asks specific\nquestions on the exam.\n\n68\n00:03:40.405 --> 00:03:46.321\nBut it's such a common networking tool\nthat it's an industry wide recognized,\n\n69\n00:03:46.321 --> 00:03:48.600\nthat it's a good tool to know.\n\n70\n00:03:48.600 --> 00:03:49.950\n&gt;&gt; It's really the go-to, yeah,\n\n71\n00:03:49.950 --> 00:03:54.640\nfor a lot of your wireless packet\ncapturing, necessities, right?\n\n72\n00:03:54.640 --> 00:03:57.770\nThey even have entire\nWireshark schools behind it,\n\n73\n00:03:57.770 --> 00:04:01.530\nbecause the lady that invented this,\nabsolutely brilliant professor,\n\n74\n00:04:01.530 --> 00:04:05.850\nshe has different kinds of tutorials and\nstuff.\n\n75\n00:04:05.850 --> 00:04:11.083\nSo definitely a good\nprotocol analyzer to have.\n\n76\n00:04:11.083 --> 00:04:12.279\nSo I'm going to go ahead and\n\n77\n00:04:12.279 --> 00:04:14.886\nI'm going to run a ping between\na couple of computers here.\n\n78\n00:04:14.886 --> 00:04:16.132\nAnd then what we're going to do,\n\n79\n00:04:16.132 --> 00:04:18.860\nessentially what I'm using is this\ncomputer to ping another computer.\n\n80\n00:04:18.860 --> 00:04:22.557\nAnd let's see what we find out\nwith our packet capture utility.\n\n81\n00:04:22.557 --> 00:04:26.936\nAnd I brought it up, it's important to\npay attention to which interface you\n\n82\n00:04:26.936 --> 00:04:31.400\nare utilizing this on, if you have\nmultiple interfaces, some machines do.\n\n83\n00:04:31.400 --> 00:04:34.149\nIf you're in a virtualized environment\nthere's a good potential that\n\n84\n00:04:34.149 --> 00:04:36.730\nyou could have a multi home device\nthrough multiple connections.\n\n85\n00:04:36.730 --> 00:04:38.510\nWhether it be private\nconnections between VMs,\n\n86\n00:04:38.510 --> 00:04:41.770\nwhether it be connections to the host\nmachine that it's running on.\n\n87\n00:04:41.770 --> 00:04:44.290\nOr maybe even an external\nadaptor where you allow\n\n88\n00:04:44.290 --> 00:04:47.070\ncommunications across your network,\njust like any other physical machine.\n\n89\n00:04:47.070 --> 00:04:49.930\nSo make sure that If you are gonna\ndo a protocol analyzer or\n\n90\n00:04:49.930 --> 00:04:53.600\npacket analysis, you wanna make sure\nthat you're picking the right interface.\n\n91\n00:04:53.600 --> 00:04:57.670\nAnd I'm gonna go ahead and\npick Ethernet0 and it's asking me for\n\n92\n00:04:57.670 --> 00:05:00.900\nsome privileges here because it\nwants to capture that traffic.\n\n93\n00:05:02.010 --> 00:05:07.540\nAll right, and I can see, well we do\nhave some information in here, right?\n\n94\n00:05:07.540 --> 00:05:11.572\nI could see that I have ICMP traffic,\nthe ping packet that's going here.\n\n95\n00:05:11.572 --> 00:05:16.053\nAnd we could just pick any one of\nthese packets of information out and\n\n96\n00:05:16.053 --> 00:05:17.240\nkinda look at it.\n\n97\n00:05:17.240 --> 00:05:19.760\nOne of the things that I can see is that\n\n98\n00:05:19.760 --> 00:05:22.180\nI've got IPSec communications\ngoing on here, right?\n\n99\n00:05:22.180 --> 00:05:25.010\nWe can see that the Internet Control\nMessage protocol, that's one of the great\n\n100\n00:05:25.010 --> 00:05:29.570\nthings about these wire or the protocol\nanalyzers wire shark, in this case.\n\n101\n00:05:29.570 --> 00:05:34.210\nIs that you can see pretty much the OSI\nmodel here, right, and I can see\n\n102\n00:05:34.210 --> 00:05:39.416\nInternet Control Message Protocol,\nright, is up above IP there if you will.\n\n103\n00:05:39.416 --> 00:05:44.313\nBut what's kind of interesting is I have\nthis authentication header here, and\n\n104\n00:05:44.313 --> 00:05:47.895\nauthentication header is a part\nof the IPsec protocol, or\n\n105\n00:05:47.895 --> 00:05:49.665\nsecurity suite if you will.\n\n106\n00:05:49.665 --> 00:05:53.620\nI can see things like security\nparameter index here.\n\n107\n00:05:53.620 --> 00:05:59.010\nWe can see things like ICVs for\ninstance, the security parameter index.\n\n108\n00:05:59.010 --> 00:06:03.000\nThis is essentially an identifier\nthat identifies it as being part of\n\n109\n00:06:03.000 --> 00:06:04.525\na security association.\n\n110\n00:06:04.525 --> 00:06:08.808\nYou can see sequencing information to make\nsure that we don't have things like replay\n\n111\n00:06:08.808 --> 00:06:09.767\nattacks going on.\n\n112\n00:06:09.767 --> 00:06:11.665\nIf somebody was to capture\nthis information and\n\n113\n00:06:11.665 --> 00:06:13.590\ntry to send it back to this machine later.\n\n114\n00:06:13.590 --> 00:06:17.560\nThe sequence, well, first of all,\nthe SPI might be valid,\n\n115\n00:06:17.560 --> 00:06:19.890\nthe security parameter index.\n\n116\n00:06:19.890 --> 00:06:22.510\nBut the sequencing information,\nthe time stamps aren't gonna match.\n\n117\n00:06:22.510 --> 00:06:24.710\nSo it's gonna be rejected.\n\n118\n00:06:24.710 --> 00:06:28.110\nI can also see ICV information,\nthat ICV here.\n\n119\n00:06:28.110 --> 00:06:32.340\nThat's authentication header, right,\nfor our integrity, message digest, but\n\n120\n00:06:32.340 --> 00:06:36.900\nthe ICV is actually the message digest\npart, that's an integrity check value.\n\n121\n00:06:36.900 --> 00:06:39.990\nAnd what it's showing me here is that I\n\n122\n00:06:39.990 --> 00:06:43.565\ndo have a message digest that if I send\nthat information to the next computer,\n\n123\n00:06:43.565 --> 00:06:47.490\nit can compare that digest,\ncompare the two values if they're same.\n\n124\n00:06:47.490 --> 00:06:49.181\nIt processes the information.\n\n125\n00:06:49.181 --> 00:06:50.033\nIf they're not the same,\n\n126\n00:06:50.033 --> 00:06:52.500\nthen what it's gonna do is it's\ngonna discard the information.\n\n127\n00:06:52.500 --> 00:06:56.640\n&gt;&gt; Okay, Wes, so I know ICMP's kind of an\nunderestimated protocol when we're talking\n\n128\n00:06:56.640 --> 00:06:57.730\nabout network analysis.\n\n129\n00:06:57.730 --> 00:07:00.740\nFor example, when you were just\npinging that particular machine\n\n130\n00:07:00.740 --> 00:07:03.610\nI can look at that TTL and\nnotice it was a Windows machine.\n\n131\n00:07:03.610 --> 00:07:07.960\nSo just by utilizing Wire Shark is\nthere a way that I can analyze or\n\n132\n00:07:07.960 --> 00:07:11.930\ndetermine if we're in compliance with\nour network posture or security posture?\n\n133\n00:07:11.930 --> 00:07:13.410\n&gt;&gt; Well, you know,\nthat's a great question.\n\n134\n00:07:13.410 --> 00:07:17.160\nIf we had maybe a security policy\nthat said, hey, we require integrity.\n\n135\n00:07:17.160 --> 00:07:18.960\nThen if we take a look at my machine here.\n\n136\n00:07:18.960 --> 00:07:20.800\nThen we've got the integrity that we need.\n\n137\n00:07:20.800 --> 00:07:23.100\nWe want to make sure that\nour data hasn't changed.\n\n138\n00:07:23.100 --> 00:07:27.110\nBut there is kind of a problem with this,\nbecause I do see authentication header.\n\n139\n00:07:27.110 --> 00:07:30.029\nWhich, it does give me\nthe integrity that we need, right?\n\n140\n00:07:30.029 --> 00:07:32.760\nThat's integrity and availability, right?\n\n141\n00:07:32.760 --> 00:07:35.560\nBut the problem is it doesn't\ngive me the confidentiality.\n\n142\n00:07:35.560 --> 00:07:39.400\nSo if I was to look at the security policy\nfrom this right here, and let's say that\n\n143\n00:07:39.400 --> 00:07:43.730\nit required encryption, then I could see\nthat we're not actually in compliance.\n\n144\n00:07:43.730 --> 00:07:45.240\nEven though you would\nthink going out the gate,\n\n145\n00:07:45.240 --> 00:07:47.340\nwell, we've got IP set\ncommunications going on here.\n\n146\n00:07:47.340 --> 00:07:48.584\nWe have to be secure.\n\n147\n00:07:48.584 --> 00:07:52.000\nAnd this could be a misconfiguration or\njust an oversight on our part.\n\n148\n00:07:52.000 --> 00:07:57.873\nSo for instance, let's go ahead and\nstop this packet capture utility here.\n\n149\n00:07:57.873 --> 00:08:00.996\nAnd we'll quit this without saving,\nand I'll go ahead and\n\n150\n00:08:00.996 --> 00:08:03.470\nclose down my command prompt here.\n\n151\n00:08:03.470 --> 00:08:05.001\nIf I get down into the firewall,\n\n152\n00:08:05.001 --> 00:08:09.277\nmaybe our corporate secure Security policy\nsaid that we do require encryption, right?\n\n153\n00:08:09.277 --> 00:08:13.455\nWell, the problem here is if I look at\nour connection security associations,\n\n154\n00:08:13.455 --> 00:08:15.900\nand I think, yeah, there we go.\n\n155\n00:08:15.900 --> 00:08:20.190\nI can see that in the Phase\n1 security association\n\n156\n00:08:20.190 --> 00:08:21.730\nthat we have encryption, right?\n\n157\n00:08:21.730 --> 00:08:25.998\nWe have AES and\nthe Cypher Block Chaining 128.\n\n158\n00:08:25.998 --> 00:08:28.250\nAnd I could see SHA-1 for integrity.\n\n159\n00:08:28.250 --> 00:08:35.460\nBut if we look at quick mode, notice\nthat I can see, I'm using Integrity.\n\n160\n00:08:35.460 --> 00:08:38.900\nI'm not using ESP integrity,\nwhich is okay because I've got the.\n\n161\n00:08:40.070 --> 00:08:43.340\nBut notice that I've got zero encryption,\nright?\n\n162\n00:08:43.340 --> 00:08:44.810\nMaybe there's an another situation or\n\n163\n00:08:44.810 --> 00:08:47.700\nscenario where maybe we have\nnetwork address translation.\n\n164\n00:08:47.700 --> 00:08:49.930\nIf I'm using network address translation,\n\n165\n00:08:49.930 --> 00:08:54.570\nthen authentication header doesn't\ndo well at all with NAT traversal.\n\n166\n00:08:54.570 --> 00:08:55.920\nHowever, ESP does.\n\n167\n00:08:55.920 --> 00:08:58.720\nSo that might be something\nthat we have to adjust\n\n168\n00:08:58.720 --> 00:09:00.890\naccording to whatever\nour security policy is.\n\n169\n00:09:00.890 --> 00:09:02.690\nAs part of the assessment we realize that,\n\n170\n00:09:02.690 --> 00:09:05.100\nhey, I don't have\nencryption going on here.\n\n171\n00:09:05.100 --> 00:09:09.700\nSo I might have to do something\nlike maybe change the policy.\n\n172\n00:09:09.700 --> 00:09:13.810\nSo, with using something like\nWireshark like this, showing me that,\n\n173\n00:09:13.810 --> 00:09:17.330\nfirst of all, I can identify\nthe protocol that I'm using,\n\n174\n00:09:17.330 --> 00:09:19.840\nI can also see that\nthere's a protocol LAC.\n\n175\n00:09:19.840 --> 00:09:25.780\nThen I can get in here and maybe make the\nadjustments to these security settings and\n\n176\n00:09:25.780 --> 00:09:28.680\nkind of force a compliance\nwith that policy.\n\n177\n00:09:28.680 --> 00:09:32.020\nSo I'm just gonna get in here to the\nWindows Firewall with Advanced Security.\n\n178\n00:09:32.020 --> 00:09:34.140\nWe'll go ahead and\nbring up the properties.\n\n179\n00:09:34.140 --> 00:09:38.320\nAnd if I kinda skip on over\nto the IPsec settings here,\n\n180\n00:09:38.320 --> 00:09:40.810\nyou'll see that there are some\nthings that we can do.\n\n181\n00:09:40.810 --> 00:09:42.080\nLike the defaults.\n\n182\n00:09:42.080 --> 00:09:46.180\nIf I choose customize,\nI can go to the Advanced.\n\n183\n00:09:46.180 --> 00:09:52.870\nAnd here I see that, sure enough,\nit's requiring For the integrity protocol.\n\n184\n00:09:52.870 --> 00:09:55.760\nBut I might wanna go a little\nbit farther than this.\n\n185\n00:09:55.760 --> 00:10:00.170\nIf our security policy does, say, require\nencryption for all security rules, right?\n\n186\n00:10:00.170 --> 00:10:02.310\nWe need encrypted information.\n\n187\n00:10:02.310 --> 00:10:04.750\nThen what I can do is I can\nessentially force this.\n\n188\n00:10:04.750 --> 00:10:07.620\nAnd you can see it kinda grays the first\n\n189\n00:10:07.620 --> 00:10:10.080\ndata integrity area out\nbecause it's saying, hey,\n\n190\n00:10:10.080 --> 00:10:14.050\nno longer do we just care about integrity,\nour Corporate Security Policy says\n\n191\n00:10:14.050 --> 00:10:16.895\nthat we need to make sure that\nthe data's encrypted, right?\n\n192\n00:10:16.895 --> 00:10:19.955\nAnd the Wireshark kinda showed us that\n\n193\n00:10:19.955 --> 00:10:22.535\nwe weren't in compliance with\nour security police here.\n\n194\n00:10:22.535 --> 00:10:25.475\nSo I'll go ahead, and we will run that.\n\n195\n00:10:25.475 --> 00:10:29.965\nLet's bump on to our next machine here,\nand we'll do the same thing.\n\n196\n00:10:29.965 --> 00:10:34.705\nAnd I will change the security\nsettings here, too.\n\n197\n00:10:34.705 --> 00:10:40.140\nSo we're gonna launch up our\ngroup policy editor here.\n\n198\n00:10:40.140 --> 00:10:41.720\nAnd we'll do the same thing over here.\n\n199\n00:10:41.720 --> 00:10:48.270\nWe'll kind of jump down into our Windows\nsettings and our security settings.\n\n200\n00:10:48.270 --> 00:10:50.470\nWe'll get into the Windows Firewall again.\n\n201\n00:10:50.470 --> 00:10:53.800\nAnd what we're gonna do is\nright-click on it, choose Properties.\n\n202\n00:10:54.810 --> 00:10:59.190\nAnd again, like we've done before, you'll\nsee that we have these IPsec settings.\n\n203\n00:10:59.190 --> 00:10:59.880\nThat's what we want.\n\n204\n00:10:59.880 --> 00:11:02.340\nAnd again, it's very easy to think, hey,\n\n205\n00:11:02.340 --> 00:11:06.120\nbecause I'm running IPsec\nthat I should be okay, right?\n\n206\n00:11:06.120 --> 00:11:08.380\nI've got security,\nI've done my due diligence.\n\n207\n00:11:08.380 --> 00:11:13.860\nBut in this example,\nwhen we ran the protocol analyzer,\n\n208\n00:11:13.860 --> 00:11:17.290\nwe found out that, hey,\nwhile we were running integrity, it\n\n209\n00:11:17.290 --> 00:11:21.670\nwas giving us availability, it certainly\nwasn't giving us the confidentiality.\n\n210\n00:11:21.670 --> 00:11:24.200\nNow, if we kind of jump\nback over to this machine,\n\n211\n00:11:24.200 --> 00:11:26.870\nwe're going to launch up\nour command prompt again.\n\n212\n00:11:26.870 --> 00:11:28.150\nAnd we'll fire off a ping,\n\n213\n00:11:28.150 --> 00:11:32.910\nif I could spell ping [LAUGH]\nto that machine one more time.\n\n214\n00:11:32.910 --> 00:11:35.250\nAnd we can see we've\ngot communication here.\n\n215\n00:11:35.250 --> 00:11:36.600\nBut now let's go ahead.\n\n216\n00:11:36.600 --> 00:11:39.490\nYou know what,\nI forgot we're not in Linux here.\n\n217\n00:11:40.940 --> 00:11:42.890\nLet's make sure it's a persistent ping.\n\n218\n00:11:42.890 --> 00:11:45.520\n&gt;&gt; All right, Wes, now that you've\nmade those configuration changes,\n\n219\n00:11:45.520 --> 00:11:47.650\nwill we be able to detect\nthat through WireShark?\n\n220\n00:11:47.650 --> 00:11:49.100\n&gt;&gt; Man, I tell you what, I hope so.\n\n221\n00:11:49.100 --> 00:11:50.890\nIf not, we're not doing really good.\n\n222\n00:11:50.890 --> 00:11:52.210\n&gt;&gt; [LAUGH]\n&gt;&gt; Good job, that's for sure.\n\n223\n00:11:52.210 --> 00:11:54.080\nBut let's go ahead, and\nnow that we've got it configured,\n\n224\n00:11:54.080 --> 00:11:57.810\nlet's bump back on over to the machine,\nthe first machine that we were on here.\n\n225\n00:11:57.810 --> 00:11:59.340\nAnd we'll go ahead, and\n\n226\n00:11:59.340 --> 00:12:03.270\nfirst thing that we gotta do is we gotta\nfire up the good old command prompt here.\n\n227\n00:12:03.270 --> 00:12:07.080\nAnd we'll ping that machine just\nlike we did before, guys, so\n\n228\n00:12:07.080 --> 00:12:08.220\nnothing's really changed.\n\n229\n00:12:08.220 --> 00:12:09.970\nWe're gonna ping 10.10.10.20, right?\n\n230\n00:12:09.970 --> 00:12:13.750\nAnd that's the machine that we were\npinging earlier when we'd seen\n\n231\n00:12:13.750 --> 00:12:16.480\nthe authentication header protocol there.\n\n232\n00:12:16.480 --> 00:12:17.110\nWe'll go ahead.\n\n233\n00:12:17.110 --> 00:12:21.260\nIt looks like so far we've got things\nconfigured correctly because If I didn't\n\n234\n00:12:21.260 --> 00:12:24.770\nhave things configured correctly, remember\nif you're using something like IPsec,\n\n235\n00:12:24.770 --> 00:12:29.500\nthe rules have to match on both sides, or\nyou're not going to get any communication.\n\n236\n00:12:29.500 --> 00:12:34.036\nSo let's go ahead and, again, I'm not\nin Linux, let's make this persistent.\n\n237\n00:12:34.036 --> 00:12:37.730\nAnd then, we will go ahead and\ndive back down into WireShark, and\n\n238\n00:12:37.730 --> 00:12:39.400\nwe'll see what we can see here.\n\n239\n00:12:39.400 --> 00:12:41.413\nWe'll see,\nin answer to Cherokee's question here,\n\n240\n00:12:41.413 --> 00:12:43.620\nwe'll see if the protocols have changed.\n\n241\n00:12:43.620 --> 00:12:45.000\nAt least, that's what we're hoping.\n\n242\n00:12:45.000 --> 00:12:48.310\nOkay, so\nI see some identity protection here.\n\n243\n00:12:48.310 --> 00:12:49.020\nMain mode, right?\n\n244\n00:12:49.020 --> 00:12:51.290\nThat is definitely something that we want.\n\n245\n00:12:51.290 --> 00:12:53.910\nBut I can also see that now, if I was to,\n\n246\n00:12:53.910 --> 00:12:57.800\nlet's just say,\nany of these protocols, all right?\n\n247\n00:12:57.800 --> 00:12:59.150\nI want you to know something.\n\n248\n00:12:59.150 --> 00:13:00.880\nDo you notice something here?\n\n249\n00:13:00.880 --> 00:13:05.900\nIn the first one,\nwhen we were doing ICMP echo requests,\n\n250\n00:13:05.900 --> 00:13:09.360\nit let me know in the protocol,\nwas ICMP, right?\n\n251\n00:13:09.360 --> 00:13:11.820\nBecause we were doing integrity checks.\n\n252\n00:13:11.820 --> 00:13:14.140\nWe weren't doing confidentiality.\n\n253\n00:13:14.140 --> 00:13:18.260\nBut now that we're running\nthe encapsulated security payload,\n\n254\n00:13:18.260 --> 00:13:21.450\nESP is encapsulating the entire payload.\n\n255\n00:13:21.450 --> 00:13:26.210\nSo the only thing we see is,\nif you will, the wrapper around ICMP.\n\n256\n00:13:26.210 --> 00:13:29.136\nSo let's find that out.\n\n257\n00:13:29.136 --> 00:13:32.440\n&gt;&gt; So we're kind of moving from Integrity\nto Confidentiality if we're thinking\n\n258\n00:13:32.440 --> 00:13:33.950\nabout it maybe in the CIA Triad?\n\n259\n00:13:33.950 --> 00:13:34.940\n&gt;&gt; That's right, that's right.\n\n260\n00:13:34.940 --> 00:13:36.080\nWe just fulfilled the C.\n\n261\n00:13:36.080 --> 00:13:39.578\nWe have the I and we had the A in\nthe first part, but we are missing the C.\n\n262\n00:13:39.578 --> 00:13:42.750\nMan, this is an alphabet soup episode for\nsure.\n\n263\n00:13:42.750 --> 00:13:48.520\nBut if I get down in here, I can see a lot\nof the same concepts that we seen, right?\n\n264\n00:13:48.520 --> 00:13:50.950\nIn authentication header, right?\n\n265\n00:13:50.950 --> 00:13:52.700\nI can still see that security parameter,\nand\n\n266\n00:13:52.700 --> 00:13:55.990\nactually again just establishes what\nsecurity association this is a part of.\n\n267\n00:13:55.990 --> 00:13:58.730\nBecause keep it in mind, I don't\nknow if I mentioned this before, but\n\n268\n00:13:58.730 --> 00:14:01.330\nwe could have multiple security\nassociations going on, right?\n\n269\n00:14:01.330 --> 00:14:04.940\nI could be talking to a server at the same\ntime I'm talking to Cherokee's computer.\n\n270\n00:14:04.940 --> 00:14:09.170\nThose are two distinct,\ndifferent trust relationships.\n\n271\n00:14:09.170 --> 00:14:12.363\nAnd these identifiers help to\nidentify which one it belongs to.\n\n272\n00:14:12.363 --> 00:14:14.100\nAnd we can see the sequencing information.\n\n273\n00:14:14.100 --> 00:14:18.570\nSo I can see with the protocol analyzer,\nif we are doing some\n\n274\n00:14:18.570 --> 00:14:22.680\nkind of security posture assessment like\nthis, how we've turned around and maybe\n\n275\n00:14:22.680 --> 00:14:26.620\ncompared it back to our security policy\nthat says traffic needs to be encrypted.\n\n276\n00:14:26.620 --> 00:14:28.220\nWe can't just maintain the integrity.\n\n277\n00:14:28.220 --> 00:14:30.910\nWe gotta make sure that nobody can\neavesdrop on the communication.\n\n278\n00:14:32.822 --> 00:14:39.810\nAll right, so that is one of the software\nbased utilities that they talk about.\n\n279\n00:14:39.810 --> 00:14:43.420\nAnother one that they talk about, we've\nkinda talked about the network scanners\n\n280\n00:14:43.420 --> 00:14:45.080\nbeing able to do things a lot more,\n\n281\n00:14:45.080 --> 00:14:49.640\na lot more verbose information including\nanalyzing traffic flow patterns,\n\n282\n00:14:49.640 --> 00:14:54.450\ntrending analysis if you will, rogue\ndevice detection, network mapping, right?\n\n283\n00:14:54.450 --> 00:14:57.660\nI can find out all of the live\nhosts that are on my networks.\n\n284\n00:14:57.660 --> 00:15:01.550\nMaybe compare that back to a spreadsheet\nof IP addresses that we have if we're\n\n285\n00:15:01.550 --> 00:15:03.580\njust looking at our overall architecture,\ntoo.\n\n286\n00:15:03.580 --> 00:15:07.430\nThe other thing that they call out are,\nwell,\n\n287\n00:15:07.430 --> 00:15:12.087\nthey call them wireless scanners and\ncrackers, okay?\n\n288\n00:15:12.087 --> 00:15:14.990\nLet's go ahead and get the wireless\ncracking out of the way, right?\n\n289\n00:15:14.990 --> 00:15:20.270\nIf I'm going to do some kind\nof penetration testing, right?\n\n290\n00:15:20.270 --> 00:15:23.180\nI'm gonna use something like a wireless\nscanner, where we can craft packets,\n\n291\n00:15:23.180 --> 00:15:26.945\nwe can craft probes, like air-cracking,\naircrack-ng, if you will,\n\n292\n00:15:26.945 --> 00:15:30.405\ninside of Linux where I can\nactually do replay attacks,\n\n293\n00:15:30.405 --> 00:15:35.195\nand I can kinda test out is the security\nof my wireless network, is it secure?\n\n294\n00:15:35.195 --> 00:15:37.275\nBut they also call out wi-fi scanners,\ntoo.\n\n295\n00:15:37.275 --> 00:15:38.955\nWireless scanners, if you will.\n\n296\n00:15:38.955 --> 00:15:42.240\nAnd these can be the same thing\nas protocol analyzers, but\n\n297\n00:15:42.240 --> 00:15:44.950\nthey go a lot farther than just doing it.\n\n298\n00:15:44.950 --> 00:15:48.080\nThey don't necessarily have to do\npacket analysis or protocol analysis.\n\n299\n00:15:48.080 --> 00:15:52.147\nIn fact, I've got a really,\nreally cool wi-fi scanner up here.\n\n300\n00:15:52.147 --> 00:15:56.137\nAnd this is actually\na Mac piece of software.\n\n301\n00:15:56.137 --> 00:16:01.002\nYou can see that it's scanning all of the\nwireless networks within our range Right,\n\n302\n00:16:01.002 --> 00:16:02.658\nwe can see ITProTV, right?\n\n303\n00:16:02.658 --> 00:16:05.414\nAnd we can see things like the basic\nservice set identifier and\n\n304\n00:16:05.414 --> 00:16:07.487\nMac address if you will,\nof the access point.\n\n305\n00:16:07.487 --> 00:16:09.674\nWe could see things like signal strength,\nright?\n\n306\n00:16:09.674 --> 00:16:12.324\nSo you start to get a lot of information,\nand we'll look at some more\n\n307\n00:16:12.324 --> 00:16:14.479\nof this information when\nit comes to wi-fi scanners.\n\n308\n00:16:14.479 --> 00:16:19.487\n&gt;&gt; Now Wes, I know we're really focusing\nhere on software-based technologies.\n\n309\n00:16:19.487 --> 00:16:21.079\nAnd so that's not to be confused with,\n\n310\n00:16:21.079 --> 00:16:24.266\nsometimes you might hear the term a\nwireless scanner or wireless sniffer, and\n\n311\n00:16:24.266 --> 00:16:27.617\nthey're actually talking about a little\npiece of hardware, like an alpha card.\n\n312\n00:16:27.617 --> 00:16:31.085\nBut here we're predominantly looking\nat those software-based technologies.\n\n313\n00:16:31.085 --> 00:16:34.603\n&gt;&gt; Most definitely, and to run right along\nwith that analogy or that explanation,\n\n314\n00:16:34.603 --> 00:16:37.253\ntoo, is things like wireless\nspectrum analyzers, right?\n\n315\n00:16:37.253 --> 00:16:39.751\nThat's an actual hardware device,\nlike Cherokee's mentioned,\n\n316\n00:16:39.751 --> 00:16:42.834\nwhere you're essentially getting a heat\nmap, and you're getting the strength.\n\n317\n00:16:42.834 --> 00:16:47.223\nAnd then possible interference points of\nyour access site survey type software that\n\n318\n00:16:47.223 --> 00:16:49.648\nworked in combination\nwith hardware as well.\n\n319\n00:16:49.648 --> 00:16:54.296\nSo yeah, we're just specifically talking\nabout the software-based assessment tools.\n\n320\n00:16:54.296 --> 00:16:57.294\nSo you could see some\nadditional information, right?\n\n321\n00:16:57.294 --> 00:17:01.330\nSo if we look here, maybe we can see\nthe different channels, that tells me that\n\n322\n00:17:01.330 --> 00:17:05.367\nwhen it comes to the channels I can tell\nright away that it's operating in the 5\n\n323\n00:17:05.367 --> 00:17:09.428\nGHz spectrum, without the fact that\nit's staring me right there in the face.\n\n324\n00:17:09.428 --> 00:17:12.264\nBut if you know your wireless channels,\nright?\n\n325\n00:17:12.264 --> 00:17:16.825\nI would be looking for\nthings in the 2.412 MHz location if I was\n\n326\n00:17:16.825 --> 00:17:21.076\nlooking at different channels,\nor bandwidth, if you will.\n\n327\n00:17:21.076 --> 00:17:24.603\nChannel-wise, let me get my channels\nright here, one through 13.\n\n328\n00:17:24.603 --> 00:17:25.447\nSo one through 13?\n\n329\n00:17:25.447 --> 00:17:29.546\nNo, one through 11, excuse me,\nhere in the United States, 12, 13,\n\n330\n00:17:29.546 --> 00:17:31.329\nand 14 being Europe and Japan.\n\n331\n00:17:31.329 --> 00:17:32.561\nI can see the bandwidth, right?\n\n332\n00:17:32.561 --> 00:17:33.977\nThat might be something that's important.\n\n333\n00:17:33.977 --> 00:17:38.637\nWe can see 40 MHz bandwidth which tells\nme that it's probably running backwards\n\n334\n00:17:38.637 --> 00:17:39.659\ncompatibility.\n\n335\n00:17:39.659 --> 00:17:43.114\nAnd I can even see the mode,\nrate, and the security, right?\n\n336\n00:17:43.114 --> 00:17:49.261\nBut that is basically all of the wireless\naccess points around our current network.\n\n337\n00:17:49.261 --> 00:17:52.607\nLet's just focus in on ITProTV's, right?\n\n338\n00:17:52.607 --> 00:17:56.538\nI can see beaconing information here, we\ncan see things like your signal quality.\n\n339\n00:17:56.538 --> 00:18:00.145\nOver here, you've got your SNR,\nthat's the signal to noise ratio.\n\n340\n00:18:00.145 --> 00:18:02.666\nThe higher the number on that one,\nthe better you're doing, right?\n\n341\n00:18:02.666 --> 00:18:04.903\nSignal strength, right?\n\n342\n00:18:04.903 --> 00:18:06.773\nVersus the noise that you save.\n\n343\n00:18:06.773 --> 00:18:08.784\nBasic rate, signal strength, right?\n\n344\n00:18:08.784 --> 00:18:10.479\nThis might be important, right?\n\n345\n00:18:10.479 --> 00:18:11.788\nFrom a security standpoint.\n\n346\n00:18:11.788 --> 00:18:15.676\nMaybe we're sending a little bit too\nmuch information out into the parking\n\n347\n00:18:15.676 --> 00:18:18.589\nlot where somebody could\nmaybe be eavesdropping on it.\n\n348\n00:18:18.589 --> 00:18:22.475\nMaybe you're in a shopping plaza and\nyou're building next to a building next\n\n349\n00:18:22.475 --> 00:18:26.123\nto another building, and you realize\nthrough something like this maybe\n\n350\n00:18:26.123 --> 00:18:29.320\nyour signal strength is too great\non one side of your building.\n\n351\n00:18:29.320 --> 00:18:33.015\nMaybe you need to reduce the strengths\non your antennas, right?\n\n352\n00:18:33.015 --> 00:18:34.385\n&gt;&gt; Replace those antennas?\n\n353\n00:18:34.385 --> 00:18:35.250\n&gt;&gt; That's right.\n\n354\n00:18:35.250 --> 00:18:37.719\n&gt;&gt; Not replace them but relocate them.\n\n355\n00:18:37.719 --> 00:18:38.692\n&gt;&gt; Position them.\n\n356\n00:18:38.692 --> 00:18:39.950\nYes, definitely, definitely.\n\n357\n00:18:39.950 --> 00:18:43.157\nWell, and honestly it might be something\nwhere you need a highly directional\n\n358\n00:18:43.157 --> 00:18:44.134\nantenna-\n&gt;&gt; Sure, great.\n\n359\n00:18:44.134 --> 00:18:46.564\n&gt;&gt; And you got a semi and\ndirectional like a dipole antennae.\n\n360\n00:18:46.564 --> 00:18:49.633\nMaybe you do need a change,\nmaybe the signals,\n\n361\n00:18:49.633 --> 00:18:54.316\nmaybe you've got one that's got\na crazy amount of signal strength, and\n\n362\n00:18:54.316 --> 00:18:59.635\nyou need the one that's maybe not gonna\ngive you all of that reach and visibility.\n\n363\n00:18:59.635 --> 00:19:02.413\nOther things that you can see here\nis things like the spectrums, right?\n\n364\n00:19:02.413 --> 00:19:04.728\nSpectrums are important.\n\n365\n00:19:04.728 --> 00:19:07.744\nThe other thing that I really like\nabout this, too, and you know what?\n\n366\n00:19:07.744 --> 00:19:08.645\nLet's see here.\n\n367\n00:19:08.645 --> 00:19:11.757\nYes, this is another\none I like to look at.\n\n368\n00:19:11.757 --> 00:19:13.394\nYou see the type, Infrastructure mode.\n\n369\n00:19:13.394 --> 00:19:16.569\nThat means it's a managed network, right?\n\n370\n00:19:16.569 --> 00:19:18.453\nWhere the AP is managing it.\n\n371\n00:19:18.453 --> 00:19:20.740\nI can see that it's WPA Personal.\n\n372\n00:19:20.740 --> 00:19:23.154\nI can see that it's AES,\nAdvanced Encryption Standard.\n\n373\n00:19:23.154 --> 00:19:25.204\nBut more importantly for\nme, I actually run this,\n\n374\n00:19:25.204 --> 00:19:26.976\nI think we'd said this in another episode.\n\n375\n00:19:26.976 --> 00:19:30.063\nI actually ran this on my network,\nand after a firmware update,\n\n376\n00:19:30.063 --> 00:19:32.536\nit actually re-enabled\nwi-fi protected setup.\n\n377\n00:19:32.536 --> 00:19:36.922\nSo this is good for me and good for\nsecurity posture assessment.\n\n378\n00:19:36.922 --> 00:19:39.655\nIf we know,\nour company knows that WPS is crackable,\n\n379\n00:19:39.655 --> 00:19:42.653\nit's something that has\nvulnerabilities in it, right?\n\n380\n00:19:42.653 --> 00:19:46.901\nAnd it says according to our company's\nsecurity policy and our configuration\n\n381\n00:19:46.901 --> 00:19:50.520\nmanagement documentation,\nit says we need to have WPS disabled.\n\n382\n00:19:50.520 --> 00:19:54.927\nI can use one of these wireless scanners\nlike this to determine if we're meeting\n\n383\n00:19:54.927 --> 00:19:57.175\nthat attribute or that configuration.\n\n384\n00:19:57.175 --> 00:19:58.416\n&gt;&gt; Well, that's it exactly, Wes.\n\n385\n00:19:58.416 --> 00:20:01.684\nI mean, that's what we're really looking\nat here is just to make sure that when you\n\n386\n00:20:01.684 --> 00:20:04.674\nthink about the term posture,\nsecurity posture, it's just the stance and\n\n387\n00:20:04.674 --> 00:20:06.752\nthe way that your company\napproaches the security.\n\n388\n00:20:06.752 --> 00:20:09.985\nAnd if you're not adhering to that,\nthen that's, you know,\n\n389\n00:20:09.985 --> 00:20:11.455\na violation of that policy.\n\n390\n00:20:11.455 --> 00:20:15.245\n&gt;&gt; It really is, and you know it can\nhappen really simplistically, right?\n\n391\n00:20:15.245 --> 00:20:19.312\nIf you're troubleshooting a situation and\nyou're not following good proper\n\n392\n00:20:19.312 --> 00:20:22.766\nconfiguration management,\nchange management documentation,\n\n393\n00:20:22.766 --> 00:20:26.661\nsomebody could say all I did was tweak\nthe power on one of the antennas.\n\n394\n00:20:26.661 --> 00:20:29.321\nAnd now we've increased\nthe signal strength, right?\n\n395\n00:20:29.321 --> 00:20:31.509\nBut that has done absolutely nothing for\n\n396\n00:20:31.509 --> 00:20:34.545\ngetting us better quality\nperformance on our network.\n\n397\n00:20:34.545 --> 00:20:38.854\nSo it is good, especially from\na configuration management side.\n\n398\n00:20:38.854 --> 00:20:42.830\nAnother thing that I like about these\ntype of wi-fi scanners is, for instance,\n\n399\n00:20:42.830 --> 00:20:46.705\nwe have things like your Advanced Details,\nand this is really, really cool.\n\n400\n00:20:46.705 --> 00:20:49.011\nI like this because this tells me,\n\n401\n00:20:49.011 --> 00:20:52.523\none of the things I like is\nthe Supported Rates here.\n\n402\n00:20:52.523 --> 00:20:56.578\nAnd you can see what the Supported Rates\nare, you'd even see the modulization or\n\n403\n00:20:56.578 --> 00:20:57.895\nModulation techniques.\n\n404\n00:20:57.895 --> 00:21:01.904\nThis is using orthogonal\nfrequency divisional multiplexing.\n\n405\n00:21:01.904 --> 00:21:04.162\nWhat was the other one\nin here that I want?\n\n406\n00:21:04.162 --> 00:21:07.551\nAnd this is really cool too cuz\nit shows you the spatial streams.\n\n407\n00:21:07.551 --> 00:21:10.659\nWhen we look at for\ninstance, 802.11n, right?\n\n408\n00:21:10.659 --> 00:21:14.140\nIt supports four memos\nstreams simultaneously.\n\n409\n00:21:14.140 --> 00:21:17.739\nOne of those is typically used for\nquality control.\n\n410\n00:21:17.739 --> 00:21:20.880\nThen you'll have the other three that\nare used for actually sending and\n\n411\n00:21:20.880 --> 00:21:22.196\ntransmitting information.\n\n412\n00:21:22.196 --> 00:21:24.862\nI can actually see how\nthey are being utilized.\n\n413\n00:21:24.862 --> 00:21:27.236\nI can a 24:40 pattern here.\n\n414\n00:21:27.236 --> 00:21:32.012\nSo, what that tells me is that we're\ndoing backwards compatibility with\n\n415\n00:21:32.012 --> 00:21:33.252\nearlier devices.\n\n416\n00:21:33.252 --> 00:21:35.604\nCould that lead you to a downgrade attack?\n\n417\n00:21:35.604 --> 00:21:37.193\nPotentially, I don't know if it is.\n\n418\n00:21:37.193 --> 00:21:40.377\nMaybe you do have older devices\nthat you need to support, but\n\n419\n00:21:40.377 --> 00:21:44.508\nI can also see how many spatial streams\nare currently running on this machine.\n\n420\n00:21:44.508 --> 00:21:50.243\nSo, really, really good information, you\ncan see the group cypher is AES, right?\n\n421\n00:21:50.243 --> 00:21:53.492\nAnd you can see the kind of encryption\nmethods that they're using here,\n\n422\n00:21:53.492 --> 00:21:56.486\nas well as things like we've mentioned,\nchannel widths before.\n\n423\n00:21:56.486 --> 00:21:58.808\nSo a lot of good, advanced information.\n\n424\n00:21:58.808 --> 00:22:01.269\nI don't expect them to-\n&gt;&gt; Pretty cool,\n\n425\n00:22:01.269 --> 00:22:02.339\nwhat was the name of this tool?\n\n426\n00:22:02.339 --> 00:22:03.669\n&gt;&gt; This was Wi-Fi Explorer.\n\n427\n00:22:03.669 --> 00:22:04.345\n&gt;&gt; Wi-Fi Explorer.\n\n428\n00:22:04.345 --> 00:22:05.375\n&gt;&gt; And it's not a free tool.\n\n429\n00:22:05.375 --> 00:22:08.784\nA lot of times I like open sourced tools,\nlike Wire Shark is open source, it's free.\n\n430\n00:22:08.784 --> 00:22:10.806\nIt's one of the best ones\nyou've got out there and\n\n431\n00:22:10.806 --> 00:22:12.262\nyou don't have to pay a dime for it.\n\n432\n00:22:12.262 --> 00:22:16.142\nThis one is a little bit pricey, and\nI say pricey because I'm frugal.\n\n433\n00:22:16.142 --> 00:22:21.277\nIt's about 15 bucks, but it's been worth\nevery single penny that I paid for it.\n\n434\n00:22:21.277 --> 00:22:23.671\nYou don't have to spend\nmoney by any means.\n\n435\n00:22:23.671 --> 00:22:27.965\nIf you wanna try it, Wi-Fi analyzer is one\nthat I use on my mobile devices and stuff.\n\n436\n00:22:27.965 --> 00:22:32.549\nIt's one that's available for iOS,\nit's one that's available for Android,\n\n437\n00:22:32.549 --> 00:22:36.002\nWindows, I don't know if it's\navailable for Linux or Mac.\n\n438\n00:22:36.002 --> 00:22:39.187\nBut for the most part on your mobile\ndevices so you can use these.\n\n439\n00:22:39.187 --> 00:22:41.922\nI've used that for a good long while now.\n\n440\n00:22:41.922 --> 00:22:44.604\nSo that's a little bit\nabout wireless scanners.\n\n441\n00:22:44.604 --> 00:22:48.599\nWe've talked about the protocol analyzer,\na little bit about network scanners, guys.\n\n442\n00:22:48.599 --> 00:22:52.655\nKeep in mind the role and the\nfunctionality that these software-based\n\n443\n00:22:52.655 --> 00:22:56.450\nutilities play in doing any kind\nof security posture assessment.\n\n444\n00:22:56.450 --> 00:22:59.989\nBut I do believe we're out of time and\nI got a lot more to talk about.\n\n445\n00:22:59.989 --> 00:23:00.901\n&gt;&gt; You really do.\n\n446\n00:23:00.901 --> 00:23:03.627\nSo ladies and gentlemen,\nstay tuned because like Wes said,\n\n447\n00:23:03.627 --> 00:23:05.556\nwe have a lot of more\ninformation to cover.\n\n448\n00:23:05.556 --> 00:23:08.572\nSo we're gonna go ahead and\nwrap it up for this particular episode.\n\n449\n00:23:08.572 --> 00:23:10.155\nRemember, I'm your host Cherokee Boose.\n\n450\n00:23:10.155 --> 00:23:10.923\n&gt;&gt; And I'm Wes Bryan.\n\n451\n00:23:10.923 --> 00:23:14.297\n&gt;&gt; See you next time, here at ITProTV.\n\n452\n00:23:14.297 --> 00:23:20.330\n[MUSIC]\n\n453\n00:23:20.330 --> 00:23:23.424\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213513525"
        },
        {
          "description": "In this show, Cherokee and Wes continue a conversation about tools that can be used to assist posture assessment compliance. Wes shows chow to use and navigate through a vulnerability scanner.",
          "length": "1741",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-2-security_posture_assessment_pt2-041117-PGM.00_28_47_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-2-security_posture_assessment_pt2-041117-PGM.00_28_47_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-2-security_posture_assessment_pt2-041117-PGM.00_28_47_07.Still001-sm.jpg",
          "title": "Security Posture Assessment Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.003 --> 00:00:06.124\nWelcome to ITProTV,\nI'm your host Don Pezet- [CROSSTALK]\n\n2\n00:00:06.124 --> 00:00:08.432\n[MUSIC]\n\n3\n00:00:08.432 --> 00:00:14.572\nYou're watching ITProTV Welcome\nto your CompTIA Security+ series.\n\n4\n00:00:14.572 --> 00:00:16.740\nI'm your show host Cherokee Boose.\n\n5\n00:00:16.740 --> 00:00:20.190\nThis episode is a continuation of a\nprevious discussion where we we're really\n\n6\n00:00:20.190 --> 00:00:24.190\nlooking at software-based\nposture assessment utilities.\n\n7\n00:00:24.190 --> 00:00:26.540\nAnd with us today, we have Mr.\nWes Bryan in studios.\n\n8\n00:00:26.540 --> 00:00:27.640\nThank you for joining us, Wes.\n\n9\n00:00:27.640 --> 00:00:28.990\nHey, Cherokee, thanks for having me back.\n\n10\n00:00:28.990 --> 00:00:33.137\nThat's right, part two, we are back,\nthe sequel, if you will.\n\n11\n00:00:33.137 --> 00:00:36.961\n[LAUGH] We're gonna be looking at\nsome additional technologies when\n\n12\n00:00:36.961 --> 00:00:40.730\nit comes to performing some kind\nof security posture assessment.\n\n13\n00:00:40.730 --> 00:00:45.280\nAgain, keep in mind security posture\nis just your overall security plan.\n\n14\n00:00:45.280 --> 00:00:49.290\nWhat does security mean to your\norganization, how is it implemented,\n\n15\n00:00:49.290 --> 00:00:50.450\nwhat are the techniques,\n\n16\n00:00:50.450 --> 00:00:55.010\ntechnologies that we use to secure\nthe environments within our organization?\n\n17\n00:00:55.010 --> 00:00:59.140\nSo in the first part, we looked at\nthings like protocol analyzers.\n\n18\n00:00:59.140 --> 00:01:03.155\nAnd we looked pretty extensively at\nprotocol analyzers and wireless scanners.\n\n19\n00:01:03.155 --> 00:01:06.317\nAnd we also talked a little bit\nabout network scanners too.\n\n20\n00:01:06.317 --> 00:01:09.271\nNow the next thing that they call out\nare what are known as password crackers.\n\n21\n00:01:09.271 --> 00:01:12.240\nAnd there are various different types,\nand techniques, and methods,\n\n22\n00:01:12.240 --> 00:01:14.680\nwhen it comes to password cracking.\n\n23\n00:01:14.680 --> 00:01:17.850\nOne of the ones that we can use is just\nthings like social engineering attacks and\n\n24\n00:01:17.850 --> 00:01:18.680\nguessing if you will.\n\n25\n00:01:18.680 --> 00:01:24.510\nHowever, that is not going to be,\nthat's a very manual process.\n\n26\n00:01:24.510 --> 00:01:30.085\nPassword crackers help to, for the most\npart, help to automate the guessing.\n\n27\n00:01:30.085 --> 00:01:33.141\nAnd again, there's different\ntechniques like brute force,\n\n28\n00:01:33.141 --> 00:01:36.197\nwhere you just try to guess every\nrandom alphanumeric string,\n\n29\n00:01:36.197 --> 00:01:39.980\nwhatever keyboard sequence you\ncould push on the keyboard, right?\n\n30\n00:01:39.980 --> 00:01:44.351\nWe have things like rainbow tables,\nright, for instance, that you load up,\n\n31\n00:01:44.351 --> 00:01:48.789\na database, it's already precomputed\nhashes and it just kind of sits there and\n\n32\n00:01:48.789 --> 00:01:50.311\nit tries to guess through,\n\n33\n00:01:50.311 --> 00:01:54.830\nbasically assisting the CPU when it\ncomes to doing password cracking.\n\n34\n00:01:54.830 --> 00:01:57.600\nWe got different types out there,\ndifferent kinds if you will.\n\n35\n00:01:57.600 --> 00:02:01.210\nFor instance, we got Cain and\nAbel's one that's been out for a while.\n\n36\n00:02:01.210 --> 00:02:03.435\nI don't know if LoftCrack\nis still out there.\n\n37\n00:02:03.435 --> 00:02:04.205\nOphcrack.\n\n38\n00:02:04.205 --> 00:02:06.799\nOphcrack, yeah, so many different ones.\n\n39\n00:02:06.799 --> 00:02:09.140\nWhat's the one, the play on the ripper,\nJohn the Ripper?\n\n40\n00:02:09.140 --> 00:02:11.120\nJohn the Ripper, yeah, so very good.\n\n41\n00:02:11.120 --> 00:02:14.610\nSo we can see that there a few out there.\n\n42\n00:02:14.610 --> 00:02:17.910\nKeep in mind that when it\ncomes to cracking a password,\n\n43\n00:02:17.910 --> 00:02:20.850\nit's computational-wise,\ncould take a very long time.\n\n44\n00:02:20.850 --> 00:02:23.530\nSo we're not gonna really demonstrate\nany of those here because,\n\n45\n00:02:23.530 --> 00:02:25.610\nwell, it's really only\na 30 minute episode.\n\n46\n00:02:25.610 --> 00:02:29.290\nAnd keep in mind, even with using\nsomething like big rainbow tables,\n\n47\n00:02:29.290 --> 00:02:34.040\nthat seeks to help the computational\neffort that it takes,\n\n48\n00:02:34.040 --> 00:02:35.720\ncould still take a long time.\n\n49\n00:02:35.720 --> 00:02:39.590\nI will tell you, though, in fact,\nwe kind of look at my Windows machine,\n\n50\n00:02:39.590 --> 00:02:42.860\nit used to be in the in the olden days,\nright?\n\n51\n00:02:42.860 --> 00:02:47.490\nIf I could get down in here, and\nI could get to a couple of these files\n\n52\n00:02:47.490 --> 00:02:50.564\nthat are on your computer\nin your registry.\n\n53\n00:02:50.564 --> 00:02:57.066\nSo if we dig down in here into Windows,\nI believe it's, what is it, System 32.\n\n54\n00:02:57.066 --> 00:03:00.815\nAnd there's an ETC folder down\nin here somewhere, I believe.\n\n55\n00:03:00.815 --> 00:03:02.404\nIs it config?\n\n56\n00:03:02.404 --> 00:03:05.470\nNo, it's System 32- It's config.\n\n57\n00:03:05.470 --> 00:03:09.523\nAll right, that's the file I'm\nlooking for, config file, right?\n\n58\n00:03:09.523 --> 00:03:10.771\nI'm thinking of the host file,\nnot the registry, unfortunately.\n\n59\n00:03:10.771 --> 00:03:12.960\nUnder the drivers and then, etc.?\n\n60\n00:03:12.960 --> 00:03:15.820\nYeah, yeah, so wrong location.\n\n61\n00:03:15.820 --> 00:03:17.570\nI was thinking of the location for\nthe host file,\n\n62\n00:03:17.570 --> 00:03:20.830\nwhere we're looking for\nthe location of the registry files.\n\n63\n00:03:20.830 --> 00:03:23.523\nAnd this, oops,\nnow that we found it, I hid it.\n\n64\n00:03:23.523 --> 00:03:24.970\nYou've got a little click happy here.\n\n65\n00:03:24.970 --> 00:03:26.050\nThat's right.\n\n66\n00:03:26.050 --> 00:03:29.130\nIn the SAM file, right, that's your\nsecurity accounts manager file and\n\n67\n00:03:29.130 --> 00:03:33.710\nthat's, essentially, where you're\npassword hash values are stored.\n\n68\n00:03:33.710 --> 00:03:36.640\nAnd it used to be that if somebody\ncould get this file, right,\n\n69\n00:03:36.640 --> 00:03:39.460\nthey could run it through one\nof these password crackers and\n\n70\n00:03:39.460 --> 00:03:41.770\nwould try to perform a hashing\ncollision attack on it.\n\n71\n00:03:41.770 --> 00:03:47.080\nToday, this file is encrypted\nwith a technology called Sys Key.\n\n72\n00:03:47.080 --> 00:03:51.970\nDoesn't mean by any means that you can't\nget, you can't break a Windows password.\n\n73\n00:03:51.970 --> 00:03:53.590\nThere's many different techniques.\n\n74\n00:03:53.590 --> 00:03:58.451\nThey have live, like memory resident\noperating system-type live CDs,\n\n75\n00:03:58.451 --> 00:04:02.730\nif you will, that you can boot to, and\nyou can reset local passwords and stuff.\n\n76\n00:04:02.730 --> 00:04:06.618\nI know Windows has password recover\nutilities that allow you to reset\n\n77\n00:04:06.618 --> 00:04:07.362\npasswords.\n\n78\n00:04:07.362 --> 00:04:08.396\nWhat's with the air quotes?\n\n79\n00:04:08.396 --> 00:04:09.244\nThose are legit, those are legit.\n\n80\n00:04:09.244 --> 00:04:10.887\nI said reset, absolutely.\n\n81\n00:04:10.887 --> 00:04:13.540\nWell, they are legit,\nit's just the intent behind them.\n\n82\n00:04:13.540 --> 00:04:16.354\nAnd like I said,\nI have done password recovery before, and\n\n83\n00:04:16.354 --> 00:04:18.070\nwe'll just kinda leave it at that.\n\n84\n00:04:18.070 --> 00:04:20.520\n[CROSSTALK] That's really with\nanything you've even showed so far,\n\n85\n00:04:20.520 --> 00:04:23.593\nthere's always a legitimate purpose, but\nthen a lot of these tools that you're\n\n86\n00:04:23.593 --> 00:04:26.270\nexplaining to us are the same\ntools that attackers are using.\n\n87\n00:04:26.270 --> 00:04:30.497\nAnd really, I could say that when it comes\nto password recovery that's a legitimate\n\n88\n00:04:30.497 --> 00:04:34.620\ntechnique, because of the fact that\navailability, if it is an authorized user.\n\n89\n00:04:34.620 --> 00:04:38.407\nNow, if you're in an active directory or\ndomain environment, just go into\n\n90\n00:04:38.407 --> 00:04:42.333\nthe database, the directory database,\nand you reset the user's password.\n\n91\n00:04:42.333 --> 00:04:44.199\nIt might not be so\neasy if you're in a workgroup or\n\n92\n00:04:44.199 --> 00:04:47.490\nif you're helping assist some home user\n[CROSSTALK]- If you un-join a computer\n\n93\n00:04:47.490 --> 00:04:51.380\nfrom a domain without having a local\nadministrative account and password known.\n\n94\n00:04:51.380 --> 00:04:52.512\nSounds like you've done that once or\ntwice.\n\n95\n00:04:52.512 --> 00:04:55.604\n[LAUGH] I've actually done that,\nI'm picking on Cherokee, but\n\n96\n00:04:55.604 --> 00:04:59.396\nI've done that before and it ended up\nbeing a time to reinstall the operating\n\n97\n00:04:59.396 --> 00:05:04.400\nsystem because I didn't have a password\ncracking or password recovery techniques.\n\n98\n00:05:04.400 --> 00:05:07.210\nSo that's a little bit\nabout password recovery.\n\n99\n00:05:07.210 --> 00:05:10.400\nThe other thing that they call\nout are vulnerabilities scanners.\n\n100\n00:05:10.400 --> 00:05:13.380\nAnd vulnerability scanners\ncan get very expensive.\n\n101\n00:05:13.380 --> 00:05:15.564\nThey can be very complex to set up.\n\n102\n00:05:15.564 --> 00:05:17.560\nThere's quite a few\ndifferent type out there.\n\n103\n00:05:17.560 --> 00:05:18.702\nNMAP is one of them, right?\n\n104\n00:05:18.702 --> 00:05:21.668\nIt can do things like port scans and\nstuff.\n\n105\n00:05:21.668 --> 00:05:25.030\nNessus, Nessus is a very popular one.\n\n106\n00:05:25.030 --> 00:05:28.100\nIt used to be open source for\na while, but it's not anymore.\n\n107\n00:05:28.100 --> 00:05:30.470\nIt is closed source,\nand you do have to pay.\n\n108\n00:05:30.470 --> 00:05:33.800\nHowever, there are other ones out there\nlike for instance, if you're doing web\n\n109\n00:05:33.800 --> 00:05:39.260\napplication vulnerability testing,\nthere's the Burp Suite, OpenVAS.\n\n110\n00:05:39.260 --> 00:05:43.290\nI've actually got one here\ncalled Rapid7 Nexpose, and\n\n111\n00:05:43.290 --> 00:05:45.530\nthis is one that we can\nactually kind of see here.\n\n112\n00:05:45.530 --> 00:05:48.207\nIn fact, let's go ahead and\ntake a look at my computer.\n\n113\n00:05:48.207 --> 00:05:53.000\nI've got Nexpose, I said Nexposay,\nbut Nexpose vulnerability scanner.\n\n114\n00:05:53.000 --> 00:05:55.150\nAnd this one is actually free.\n\n115\n00:05:55.150 --> 00:05:59.310\nSo if you get a chance, keep in mind, they\nhave got an enterprise license, right?\n\n116\n00:05:59.310 --> 00:06:02.160\nThey also got a free edition,\ntoo, that for the most part\n\n117\n00:06:02.160 --> 00:06:06.010\nhas a lot of the same functionality\nthat their enterprise versions do.\n\n118\n00:06:06.010 --> 00:06:09.440\nKeep in mind, that an enterprise\nversion is a little bit more modular,\n\n119\n00:06:09.440 --> 00:06:10.620\nyou can add more stuff to it.\n\n120\n00:06:10.620 --> 00:06:13.020\nSo let's go ahead, and\nlet's get logged in here, and\n\n121\n00:06:13.020 --> 00:06:18.450\nkinda see what the vulnerability\nscanner kinda looks like.\n\n122\n00:06:18.450 --> 00:06:21.730\nAll right, no,\nI'm not going to save this site.\n\n123\n00:06:21.730 --> 00:06:26.290\nAll right, so I went ahead and\nI did a vulnerability scan prior to this.\n\n124\n00:06:26.290 --> 00:06:29.130\nKeep in mind that these scans\ncan take a very very long time,\n\n125\n00:06:29.130 --> 00:06:31.800\nthere's different types of\nscans that you can set up.\n\n126\n00:06:31.800 --> 00:06:36.580\nFor me, in fact, I've got a site that I've\nkind of set up here, and we ran a scan.\n\n127\n00:06:36.580 --> 00:06:39.880\nYou can do host-specific scans, or\nyou can scan an entire range, and\n\n128\n00:06:39.880 --> 00:06:41.350\nthat's what I did here.\n\n129\n00:06:41.350 --> 00:06:43.670\nAnd I actually set up some\nvulnerabilities on my network.\n\n130\n00:06:43.670 --> 00:06:46.840\nAnd what I mean by vulnerabilities is\nsetting up things like where you don't\n\n131\n00:06:46.840 --> 00:06:49.420\nhave to do authenticated SMB\nfile transfer and stuff, and\n\n132\n00:06:49.420 --> 00:06:53.930\nobviously, no authentication\nis not a good security stance.\n\n133\n00:06:53.930 --> 00:06:55.880\nAnd not a very good security\nposture [LAUGH], if you will.\n\n134\n00:06:55.880 --> 00:06:58.320\nBy some, do you mean over 13,000?\n\n135\n00:06:58.320 --> 00:07:01.110\nYes, and you can see that the Risk Score,\n\n136\n00:07:01.110 --> 00:07:04.140\nit basically has a couple\nof things that it uses.\n\n137\n00:07:04.140 --> 00:07:05.660\nAnd these are some\ncommonalities out there,\n\n138\n00:07:05.660 --> 00:07:07.100\nI'm not sure if they're\ngonna be on the exam, but\n\n139\n00:07:07.100 --> 00:07:09.300\nthese are some common terms\nto vulnerability scanners.\n\n140\n00:07:09.300 --> 00:07:12.100\nYou have what's known as a CVSS.\n\n141\n00:07:12.100 --> 00:07:15.710\nWe're not talking about your local\ndrugstore here, CVS, when we say that.\n\n142\n00:07:15.710 --> 00:07:18.750\nWhat we're talking about is\nCommon Vulnerability Scoring System.\n\n143\n00:07:18.750 --> 00:07:22.720\nAnd depending on the level\nof the vulnerability,\n\n144\n00:07:22.720 --> 00:07:24.900\nit can increase the overall risk, right?\n\n145\n00:07:24.900 --> 00:07:27.010\nThat's what we're trying\nto do in this case.\n\n146\n00:07:27.010 --> 00:07:29.500\nWe're trying to find out what\n\n147\n00:07:29.500 --> 00:07:32.350\nvulnerabilities do we have\ninside of our systems.\n\n148\n00:07:32.350 --> 00:07:35.954\nIt doesn't mean that it found 13,239.\n\n149\n00:07:35.954 --> 00:07:39.039\nGotcha.\nIt just means that based on that CVSS, of\n\n150\n00:07:39.039 --> 00:07:44.486\nsome of the vulnerabilities that it found,\nit ranks that score a little bit higher.\n\n151\n00:07:44.486 --> 00:07:49.032\nAnd then it tells me, well,\nwhich is the highest risk asset?\n\n152\n00:07:49.032 --> 00:07:52.487\nKinda interesting for me,\nthe way I configured the router before I\n\n153\n00:07:52.487 --> 00:07:55.214\nran this one,\nthis is actually my default gateway.\n\n154\n00:07:55.214 --> 00:07:59.113\nAnd I turned all kinds of\nthings on that shouldn't be on,\n\n155\n00:07:59.113 --> 00:08:04.620\nRemote Management Again,\nthings like PPTP, anonymous log on, FTP.\n\n156\n00:08:04.620 --> 00:08:07.660\nSo all things that you really shouldn't\nbe running on your wireless access point.\n\n157\n00:08:07.660 --> 00:08:09.810\nI basically just opened it right up.\n\n158\n00:08:09.810 --> 00:08:13.920\nAnd you can see that it alone had a 7,900.\n\n159\n00:08:13.920 --> 00:08:14.730\nRisk score.\n\n160\n00:08:14.730 --> 00:08:17.190\nBut let's go ahead,\nlet's kinda dive in here and\n\n161\n00:08:17.190 --> 00:08:21.690\nlet's see what this vulnerability scanning\nreport kinda shows us, all right?\n\n162\n00:08:21.690 --> 00:08:27.190\nSo it shows me trends, if you will,\nI can see the different kinds of trends.\n\n163\n00:08:27.190 --> 00:08:30.460\nWhat I like about this is it shows\nme the assets that I have and\n\n164\n00:08:30.460 --> 00:08:32.710\nwhich ones were higher risk.\n\n165\n00:08:32.710 --> 00:08:35.030\nThese low risk ones, you can see,\n\n166\n00:08:35.030 --> 00:08:38.630\nthese are a couple of, I believe these are\ntwo cellphones that were on my network.\n\n167\n00:08:40.480 --> 00:08:42.650\nThese two, kinda interesting,\nI can just tell,\n\n168\n00:08:42.650 --> 00:08:45.980\nbecause I can kinda remember the IP\naddresses that are assigned to them.\n\n169\n00:08:45.980 --> 00:08:47.750\nThese are two raspberry pies.\n\n170\n00:08:47.750 --> 00:08:51.490\nAnd you can see there, kind of risky.\n\n171\n00:08:51.490 --> 00:08:53.770\nBut then you can see one here,\nand this is my home computer and\n\n172\n00:08:53.770 --> 00:08:56.730\nI opened up a lot of stuff on it, and\nits risk score by itself is 3818.\n\n173\n00:08:56.730 --> 00:08:57.350\n&gt;&gt; The Beast?\n\n174\n00:08:57.350 --> 00:08:59.390\n&gt;&gt; Yeah, it's called The Beast.\n\n175\n00:08:59.390 --> 00:09:04.445\nIt was a beast at the time that I\nbuilt it, now it is not so beast.\n\n176\n00:09:04.445 --> 00:09:10.690\n[LAUGH] And then the highest risk device\non my network was my default gateway.\n\n177\n00:09:10.690 --> 00:09:15.880\nI've since changed the configurations,\nbut again you can see that the risk score\n\n178\n00:09:15.880 --> 00:09:21.217\nalone, just that single device was 7,900,\nover 7,900, right.\n\n179\n00:09:21.217 --> 00:09:25.610\nWe can initiate scans that tells me some\nof the devices that are on my network and\n\n180\n00:09:25.610 --> 00:09:29.950\neven goes as far as doing things\nlike OS discovery, Right,\n\n181\n00:09:29.950 --> 00:09:34.910\nand again, you can see Raspbian,\nI'm running that, couple Ras Pis, right?\n\n182\n00:09:34.910 --> 00:09:41.880\nMy router is running Linux, and it's\nbehind, I believe, on a firmware update.\n\n183\n00:09:41.880 --> 00:09:44.260\nSo again, that Is classified as a risk.\n\n184\n00:09:44.260 --> 00:09:46.200\nBut now, I can go over here.\n\n185\n00:09:46.200 --> 00:09:50.050\nAnd again, remember, vulnerability\nscanners, that's what we're looking at.\n\n186\n00:09:50.050 --> 00:09:51.740\nAnd we're looking at vulnerabilities.\n\n187\n00:09:51.740 --> 00:09:54.580\nThe other acronym that I\nwant you to know is CVEs.\n\n188\n00:09:54.580 --> 00:10:00.785\nThat's common vulnerabilities and\nexposures.\n\n189\n00:10:00.785 --> 00:10:04.190\nAnd And that's what this is looking\nat when we look at vulnerabilities.\n\n190\n00:10:04.190 --> 00:10:06.450\nIt's looking at common vulnerability.\n\n191\n00:10:06.450 --> 00:10:08.760\nAnd you could see the CVSS score here.\n\n192\n00:10:08.760 --> 00:10:10.470\nAnd then what is the skill level, right?\n\n193\n00:10:10.470 --> 00:10:13.580\nWhat would be the skill level\nin order to crack some of these.\n\n194\n00:10:13.580 --> 00:10:14.390\n&gt;&gt; That's pretty cool.\n\n195\n00:10:14.390 --> 00:10:16.860\n&gt;&gt; Or attack some of these\nvulnerabilities, yeah.\n\n196\n00:10:16.860 --> 00:10:20.190\nAnd you can see, right, you can see some\nof the things that it detected, right.\n\n197\n00:10:20.190 --> 00:10:23.310\nVulnerabilities that are on my network,\nyour comment internet file system,\n\n198\n00:10:23.310 --> 00:10:26.780\nNull session permitted,\nwhat's a null session mean?\n\n199\n00:10:26.780 --> 00:10:28.770\nIt's not authenticated, no session, right?\n\n200\n00:10:28.770 --> 00:10:29.910\nThat is a problem.\n\n201\n00:10:29.910 --> 00:10:33.000\nSMB I told you I dont have\nit locked down right, so\n\n202\n00:10:33.000 --> 00:10:37.630\nwe're not doing digital signatures\non server message blog.\n\n203\n00:10:37.630 --> 00:10:40.810\nLet's say, invalid, log ins permitted.\n\n204\n00:10:40.810 --> 00:10:42.660\nSo you don't even have\nto be a valid login.\n\n205\n00:10:42.660 --> 00:10:43.400\n&gt;&gt; You don't have to, yeah.\n\n206\n00:10:43.400 --> 00:10:45.230\n&gt;&gt; Just go ahead and log in.\n\n207\n00:10:45.230 --> 00:10:47.540\nWeak LAN manager, hashing permitted.\n\n208\n00:10:47.540 --> 00:10:50.810\nYou can see, untrusted SSL certificates.\n\n209\n00:10:50.810 --> 00:10:53.115\n&gt;&gt; Taking it back all the way back to LAN,\nman.\n\n210\n00:10:53.115 --> 00:10:53.920\n&gt;&gt; [LAUGH] Absolutely.\n\n211\n00:10:53.920 --> 00:10:55.140\nAnd you know it's kind of interesting.\n\n212\n00:10:55.140 --> 00:10:56.400\nThis is what we were talking about.\n\n213\n00:10:56.400 --> 00:10:58.420\nYou know,\nwhen we talk about password cracking.\n\n214\n00:10:58.420 --> 00:10:59.400\nAnd I've said.\n\n215\n00:10:59.400 --> 00:11:01.150\nGoing back to the old days, right?\n\n216\n00:11:01.150 --> 00:11:05.730\nYour LAN man hashing a task that would be\ngrabbing that file that same file, right?\n\n217\n00:11:05.730 --> 00:11:10.570\nAnd throwing it into password cracking\nutility that will try to perform hashing\n\n218\n00:11:10.570 --> 00:11:16.350\ncollisions on it, In order to\nturn around and exploit a system.\n\n219\n00:11:16.350 --> 00:11:18.310\nDNS server allows cache snooping.\n\n220\n00:11:18.310 --> 00:11:19.300\nSo you can see a lot of things.\n\n221\n00:11:19.300 --> 00:11:23.326\nAnonymous users can obtain\nthe Windows password policy.\n\n222\n00:11:23.326 --> 00:11:29.950\nLet's see, TLS/SSL servers is\nenabling the BEAST attack,\n\n223\n00:11:29.950 --> 00:11:34.070\nand that's not the attack of my machine\nnamed BEAST I promise you that.\n\n224\n00:11:34.070 --> 00:11:35.840\nSo if you have an attack\nout there called Beast,\n\n225\n00:11:35.840 --> 00:11:38.710\nit didnt' come from my machine, I promise.\n\n226\n00:11:38.710 --> 00:11:43.490\nBut you could see things like\nlower cipher suites, right?\n\n227\n00:11:43.490 --> 00:11:47.380\nWe've talked about that weak cipher\nsuite implementations, right?\n\n228\n00:11:47.380 --> 00:11:52.370\nWe should be running TLS 1.2 today,\n1.3 I know is in draft right now.\n\n229\n00:11:52.370 --> 00:11:55.050\nIt's not out but\nwe should be running at least 1.2, and\n\n230\n00:11:55.050 --> 00:11:56.730\nI can see all kinds of errors.\n\n231\n00:11:56.730 --> 00:11:57.580\nNow.\n\n232\n00:11:57.580 --> 00:11:59.030\nSo what are these doing?\n\n233\n00:11:59.030 --> 00:12:01.440\nRemember when I told you the CVE,\nall right?\n\n234\n00:12:01.440 --> 00:12:04.580\nThe Common Vulnerability and Exposures?\n\n235\n00:12:04.580 --> 00:12:09.700\nThey come with what our known\nas CVE identifiers, right?\n\n236\n00:12:09.700 --> 00:12:10.870\nYou could see one right here this.\n\n237\n00:12:10.870 --> 00:12:14.170\nThis is an example of\na common vulnerability and\n\n238\n00:12:14.170 --> 00:12:16.000\nexposure identifier, right?\n\n239\n00:12:16.000 --> 00:12:18.980\nIt could tell you the year\nthat it was discovered, and\n\n240\n00:12:18.980 --> 00:12:22.990\nthen whatever kind of information, I'm not\nsure what that information is behind it.\n\n241\n00:12:22.990 --> 00:12:31.130\nBut notice that it says TLS/SSL Server\nSupports RC4 Cipher Algorithms, right?\n\n242\n00:12:31.130 --> 00:12:33.370\nSo why is that a vulnerability?\n\n243\n00:12:33.370 --> 00:12:34.500\nWell, I want you think about this,\n\n244\n00:12:34.500 --> 00:12:38.635\nif you know that weapons are\nvulnerability, refuse RC4 Stream Cipher.\n\n245\n00:12:38.635 --> 00:12:42.770\nRC4 Stream Cipher is not a what\nyou should be using today,\n\n246\n00:12:42.770 --> 00:12:45.750\nat the very minimum you\nshould be using RC5, right?\n\n247\n00:12:45.750 --> 00:12:48.140\nBut let see if we can get a little\nbit more information about this.\n\n248\n00:12:48.140 --> 00:12:51.590\nI'm not sure, I think this gonna\ngo to an outside database.\n\n249\n00:12:51.590 --> 00:12:54.340\nNo okay so it's internal,\nokay which is really, really even better.\n\n250\n00:12:55.480 --> 00:12:57.340\nAll right, so\nlook at what's going on here, right.\n\n251\n00:12:57.340 --> 00:13:01.800\nIt tells you what the vulnerability is,\nright.\n\n252\n00:13:01.800 --> 00:13:06.637\nRecent cryptoanalysis results\nin exploit bias in the RC4 key\n\n253\n00:13:06.637 --> 00:13:11.480\nstream to recover repeatedly\nencrypted plaintext, right.\n\n254\n00:13:11.480 --> 00:13:15.330\nSo they can do a statistical analysis and\nfind commonalities, right?\n\n255\n00:13:15.330 --> 00:13:18.400\nAnd in encryption, you never want\na commonality because anything that's\n\n256\n00:13:18.400 --> 00:13:21.580\npredictable, well,\nanything that's common is predictable.\n\n257\n00:13:21.580 --> 00:13:26.522\nAnd any kind of algorithm that's\npredictable can be reverse engineered,\n\n258\n00:13:26.522 --> 00:13:30.992\nand that's [CROSSTALK] So\nyou could see, that's again, right, so\n\n259\n00:13:30.992 --> 00:13:33.204\nit shows you what the CVE is to it.\n\n260\n00:13:33.204 --> 00:13:37.266\nAnd again, guys, I'm not sure if they're\ngonna call these specifics out, but\n\n261\n00:13:37.266 --> 00:13:40.150\nI want you to be aware of them\njust in case they do, right?\n\n262\n00:13:40.150 --> 00:13:44.880\nBe aware of what a CVSS score is,\nknow what a CVE is, and\n\n263\n00:13:44.880 --> 00:13:49.510\nknow what the CVE ID is, cause they\ncan be important as well, right?\n\n264\n00:13:49.510 --> 00:13:53.320\nSo you can see, like I said,\n\n265\n00:13:53.320 --> 00:13:56.000\nvulnerabilities like\nwe've been looking at.\n\n266\n00:13:56.000 --> 00:13:57.290\nAnd there are many of them.\n\n267\n00:13:57.290 --> 00:14:01.410\nAnd if you're not aware of what the\nvulnerabilities are, this is a great piece\n\n268\n00:14:01.410 --> 00:14:06.430\nof software because it actually\nallows you to not only categorize,\n\n269\n00:14:06.430 --> 00:14:08.580\nright, the severity of them.\n\n270\n00:14:08.580 --> 00:14:12.620\nBut find out when it was published,\nhow long has this been out, right?\n\n271\n00:14:12.620 --> 00:14:14.170\nWhen did they find out about this?\n\n272\n00:14:14.170 --> 00:14:17.690\nAnd you can see things like the RC,\nlet's see.\n\n273\n00:14:17.690 --> 00:14:22.620\nI believe you'll notice that RC4\nstream cypher is probably an old one.\n\n274\n00:14:22.620 --> 00:14:23.580\nIf I had to guess.\n\n275\n00:14:23.580 --> 00:14:25.840\nLet's see if we can navigate back there.\n\n276\n00:14:27.990 --> 00:14:31.060\nNo, actually, that's a relatively new one.\n\n277\n00:14:31.060 --> 00:14:32.580\nLooks like I went a little\nbit too far here.\n\n278\n00:14:32.580 --> 00:14:35.940\nLet's back up just one more.\n\n279\n00:14:35.940 --> 00:14:38.114\nBecause that one was actually on 2016.\n\n280\n00:14:39.640 --> 00:14:42.520\nAll right, yeah, so this one here\nis already four years old, 2013,\n\n281\n00:14:42.520 --> 00:14:45.070\nyou can see when it was published.\n\n282\n00:14:45.070 --> 00:14:48.920\nAnd remember,\nwe were talking about a risk, right?\n\n283\n00:14:48.920 --> 00:14:53.570\nAnd these are, this is how it's adding\nup that risk calculation, right?\n\n284\n00:14:53.570 --> 00:14:56.780\nYou can see that the default\ngateway was 7900.\n\n285\n00:14:56.780 --> 00:14:58.210\nIt's adding these up.\n\n286\n00:14:58.210 --> 00:15:01.920\nYour CVSS that I told you about,\nthat calculation, that score.\n\n287\n00:15:01.920 --> 00:15:04.640\nAnd you can see that in this column here,\nas well.\n\n288\n00:15:04.640 --> 00:15:08.160\nAnd then, if you want to exclude these,\nif you wanna make an exception.\n\n289\n00:15:08.160 --> 00:15:11.290\nEssentially, what that does is it says,\nI don't care if it's a vulnerability,\n\n290\n00:15:11.290 --> 00:15:13.040\nI wanna turn a blind eye to it.\n\n291\n00:15:13.040 --> 00:15:14.260\n&gt;&gt; Acknowledging the risk.\n\n292\n00:15:14.260 --> 00:15:15.300\n&gt;&gt; Yeah, exactly.\n\n293\n00:15:15.300 --> 00:15:19.590\nI'll acknowledge the risk cuz maybe I\ndon't wanna implement $10,000 to save 50,\n\n294\n00:15:19.590 --> 00:15:20.090\nright?\n\n295\n00:15:20.090 --> 00:15:23.430\nSo maybe that is something\nthat is an acceptable risk.\n\n296\n00:15:23.430 --> 00:15:27.060\nThat is up to whatever your\ncompany's security posture is.\n\n297\n00:15:27.060 --> 00:15:31.380\nSo that gives you an example of\nsome of the different technologies,\n\n298\n00:15:31.380 --> 00:15:35.550\nyou can see when it comes to things like\nfor instance your vulnerability scanner,\n\n299\n00:15:35.550 --> 00:15:39.930\nkeep in mind things like Nmap\nare out there, Nessus are out there,\n\n300\n00:15:39.930 --> 00:15:42.000\nopen vars, and\nI'm just giving you some examples.\n\n301\n00:15:42.000 --> 00:15:44.140\nThere are tons of them out there.\n\n302\n00:15:44.140 --> 00:15:47.210\nAnd this is for the most part\na vendor neutral certification,\n\n303\n00:15:47.210 --> 00:15:50.350\nI say vendor neutral because they're gonna\nask you about common technologies that\n\n304\n00:15:50.350 --> 00:15:53.280\nwell, vendors implement, right?\n\n305\n00:15:53.280 --> 00:15:53.829\nSo know some of the commonalities.\n\n306\n00:15:53.829 --> 00:15:59.375\nI'm not sure that you're gonna have to\nknow each individual specific technique,\n\n307\n00:15:59.375 --> 00:16:02.541\nbut if you think about\nthings like Nmap Nmap is so\n\n308\n00:16:02.541 --> 00:16:07.310\nwidely recommended that you might\nhave to know, what is Nmap, right?\n\n309\n00:16:07.310 --> 00:16:09.580\nAnd keep in mind that\nit is a port scanner,\n\n310\n00:16:09.580 --> 00:16:11.730\nalso does vulnerability scanning as well.\n\n311\n00:16:11.730 --> 00:16:15.420\n&gt;&gt; Now, Wes, earlier when we were\nlooking at the output for Wireshark,\n\n312\n00:16:15.420 --> 00:16:18.510\nwe were able to detect if we were\nin compliance with our policies.\n\n313\n00:16:18.510 --> 00:16:22.590\nBut is there a specific tool that\nwe can use to help enforce that?\n\n314\n00:16:22.590 --> 00:16:23.530\n&gt;&gt; There are.\n\n315\n00:16:23.530 --> 00:16:25.446\nYou have many different tools out there.\n\n316\n00:16:25.446 --> 00:16:28.986\nA couple of them that come\nto mind right away is,\n\n317\n00:16:28.986 --> 00:16:31.560\nMicrosoft has had for a long time.\n\n318\n00:16:31.560 --> 00:16:34.940\nThey've had what's known as\nthe Security Configuration Wizard.\n\n319\n00:16:34.940 --> 00:16:38.990\nAnd what this would do is this would\nallow me to create a security baseline,\n\n320\n00:16:38.990 --> 00:16:40.920\nagain according to the security posture,\n\n321\n00:16:40.920 --> 00:16:43.420\naccording to whatever\nour security policy is.\n\n322\n00:16:43.420 --> 00:16:47.776\nAnd then we could turn around, and we\ncould find out, is our server that we're\n\n323\n00:16:47.776 --> 00:16:51.953\nabout to deploy, is it in compliance\nwith the policy that we've created?\n\n324\n00:16:51.953 --> 00:16:55.589\nI will tell you that as of Server 2016,\n\n325\n00:16:55.589 --> 00:17:02.660\nthe Security Configuration Wizard is no\nlonger included in the operating system.\n\n326\n00:17:02.660 --> 00:17:05.170\nToday, they're using something known\nas the Security Compliance Manager.\n\n327\n00:17:06.260 --> 00:17:09.390\nSo, you'll have to download it\nseparately as a separate install.\n\n328\n00:17:09.390 --> 00:17:11.851\nIn fact, let's go ahead,\nI've got a 2012 machine here.\n\n329\n00:17:11.851 --> 00:17:15.660\nWe'll go ahead and show you what the\nSecurity Configuration Wizard looks like.\n\n330\n00:17:15.660 --> 00:17:18.700\nAnd if you just go I'm at\nthe Server Manager here.\n\n331\n00:17:18.700 --> 00:17:20.330\nAnd we're just using Tools.\n\n332\n00:17:20.330 --> 00:17:22.160\nAnd you can see about\nhalfway down the page,\n\n333\n00:17:22.160 --> 00:17:25.550\nyou can see this\nSecurity Configuration Wizard right there.\n\n334\n00:17:25.550 --> 00:17:27.450\nAnd we'll go ahead and launch this up.\n\n335\n00:17:27.450 --> 00:17:32.260\nAll right, now, again, what this allows us\nto do, create a security policy that you\n\n336\n00:17:32.260 --> 00:17:34.360\ncan apply to any server on your network,\nright?\n\n337\n00:17:34.360 --> 00:17:38.459\nNotice that the security policy configures\nservices and network security based on\n\n338\n00:17:38.459 --> 00:17:42.101\nthe server's role, as well as auditing and\nregistry settings, right?\n\n339\n00:17:42.101 --> 00:17:42.782\n&gt;&gt; Well, there's my answer.\n\n340\n00:17:42.782 --> 00:17:43.437\n&gt;&gt; There we go.\n\n341\n00:17:43.437 --> 00:17:48.940\nAnd that's what I love about some of these\nsummary panes and the wizards there.\n\n342\n00:17:48.940 --> 00:17:52.310\nIf you haven't worked in server,\ntake the time to read them.\n\n343\n00:17:52.310 --> 00:17:54.650\nThere is a lot of good information.\n\n344\n00:17:54.650 --> 00:17:57.298\nThe help documentation, I really like.\n\n345\n00:17:57.298 --> 00:18:02.420\nThe CHM files or the HLP files that are\nbuilt in the server are pretty exhaustive.\n\n346\n00:18:02.420 --> 00:18:04.740\nSo you've got a lot of information,\n\n347\n00:18:04.740 --> 00:18:08.460\neven if you certainly don't want to be\nbrowsing the Internet from your server.\n\n348\n00:18:08.460 --> 00:18:09.420\nAll right, let's go ahead.\n\n349\n00:18:09.420 --> 00:18:13.060\nAnd we'll create a new policy here, right?\n\n350\n00:18:13.060 --> 00:18:15.690\nAnd we'll create it on our server here.\n\n351\n00:18:15.690 --> 00:18:16.680\nWe'll chose Next.\n\n352\n00:18:18.030 --> 00:18:21.830\nMaybe it's thinking about it, and\nit's giving me a configuration database.\n\n353\n00:18:21.830 --> 00:18:25.650\nNow, this configuration database kinda\ntells me what it's gonna look through, and\n\n354\n00:18:25.650 --> 00:18:28.260\nin fact, I think it's an XML active XGR.\n\n355\n00:18:28.260 --> 00:18:32.790\nSo, I've got to go against\nsecurity just to even see this\n\n356\n00:18:32.790 --> 00:18:38.090\nconfiguration database, cuz ActiveX\ncontrols we know are safe, right?\n\n357\n00:18:38.090 --> 00:18:41.010\nBut I can look, and I can see all\nof the different things, right?\n\n358\n00:18:41.010 --> 00:18:42.490\nThe configuration database,\n\n359\n00:18:42.490 --> 00:18:47.000\nit contains information about\nevery one of these roles.\n\n360\n00:18:47.000 --> 00:18:50.270\nAnd then likewise, we don't have to\nlook at every one by client features and\n\n361\n00:18:50.270 --> 00:18:51.530\nstuff, and you can see.\n\n362\n00:18:51.530 --> 00:18:54.940\nSo it knows a lot of information, right?\n\n363\n00:18:54.940 --> 00:18:58.180\nAnd that's what it's gonna do when\nit makes it's decisions, all right.\n\n364\n00:18:58.180 --> 00:19:01.920\nIt's gonna look at what roles are\ncurrently installed on this machine and\n\n365\n00:19:01.920 --> 00:19:06.140\nhow should we configure it\naccording to best practices.\n\n366\n00:19:06.140 --> 00:19:08.650\nSo we'll go ahead, and we'll choose Next.\n\n367\n00:19:09.860 --> 00:19:13.120\nAnd one of the things to keep\nin mind is it's gonna look\n\n368\n00:19:13.120 --> 00:19:14.420\nat the current configuration,\n\n369\n00:19:14.420 --> 00:19:18.390\nand it's going to make exceptions based\non the current configuration that it has.\n\n370\n00:19:18.390 --> 00:19:21.530\nI will tell you that you have to pay\nattention to your security policy because,\n\n371\n00:19:21.530 --> 00:19:25.760\nfor instance, maybe you need things\nlike remote administration, right?\n\n372\n00:19:25.760 --> 00:19:28.270\nWell, if remote administration\nisn't turned on on this machine,\n\n373\n00:19:28.270 --> 00:19:33.280\nyou know you need that, and you run\nthe policy later after it's turned on,\n\n374\n00:19:33.280 --> 00:19:36.250\nit very well could disable\nWindows Remote Management, right?\n\n375\n00:19:36.250 --> 00:19:42.900\nSo that's one thing to keep in mind,\nthat this becomes your security baseline\n\n376\n00:19:42.900 --> 00:19:47.390\nthat hopefully gets you within compliance\nof whatever your security policy is.\n\n377\n00:19:47.390 --> 00:19:48.460\nAll right, we'll choose Next.\n\n378\n00:19:49.880 --> 00:19:52.050\nAnd some of the features\nyou can see here as well.\n\n379\n00:19:52.050 --> 00:19:53.470\nWe'll choose Next on that.\n\n380\n00:19:53.470 --> 00:19:58.370\nAnd any of the installed options here,\nwe'll choose Next, Next.\n\n381\n00:19:59.390 --> 00:20:04.750\nAnd it's asking any unhandled or\nany unspecified services.\n\n382\n00:20:04.750 --> 00:20:07.170\nI'm just gonna say don't change those.\n\n383\n00:20:07.170 --> 00:20:09.750\nAnd here's the services\nthat it's gonna change.\n\n384\n00:20:09.750 --> 00:20:13.030\nAnd you know what, I'm gonna try to keep\nan eye on a couple of these services cuz I\n\n385\n00:20:13.030 --> 00:20:15.370\nwanna show you what it's gonna do.\n\n386\n00:20:15.370 --> 00:20:16.825\nNotice the first three here.\n\n387\n00:20:16.825 --> 00:20:17.670\nOops.\n\n388\n00:20:17.670 --> 00:20:22.270\nNow notice the first three, Application\nExperience, Application Layer at Gateway,\n\n389\n00:20:22.270 --> 00:20:23.930\nand Application Management.\n\n390\n00:20:23.930 --> 00:20:25.834\nNotice what it's telling\nme that it's gonna do.\n\n391\n00:20:25.834 --> 00:20:30.220\nCurrent Startup Mode is Manual.\n\n392\n00:20:30.220 --> 00:20:32.609\nNotice that it's changing it to Disabled,\nright?\n\n393\n00:20:34.000 --> 00:20:36.710\nAnd I wanna pay attention to these\nthree cuz we're gonna run this and\n\n394\n00:20:36.710 --> 00:20:38.510\nwe're gonna do some configuration changes.\n\n395\n00:20:38.510 --> 00:20:40.454\nAnd we're gonna go against\nour configuration management.\n\n396\n00:20:40.454 --> 00:20:43.223\nWe're gonna go against\nour security policy,\n\n397\n00:20:43.223 --> 00:20:45.820\nand we'll see what this will do for us.\n\n398\n00:20:45.820 --> 00:20:48.609\nAll right, so we'll go ahead,\nand I gotta remember those.\n\n399\n00:20:48.609 --> 00:20:53.540\nWell, I'll pick two of them, Application\nExperience and Application Management.\n\n400\n00:20:53.540 --> 00:20:57.210\nWe'll choose Next, and I just kinda\nwanna keep an eye on those, right?\n\n401\n00:20:57.210 --> 00:21:01.780\nIf I want, I could configure\ndifferent security settings here.\n\n402\n00:21:01.780 --> 00:21:05.150\nIn fact,\nall rules will be kinda scroll down.\n\n403\n00:21:05.150 --> 00:21:11.830\nAnd I believe in here somewhere, you'll\nsee things like remote communications.\n\n404\n00:21:11.830 --> 00:21:15.560\nRight, for instance,\nmaybe I'm not running Telnet Server.\n\n405\n00:21:15.560 --> 00:21:16.890\nThis way, it's turned on.\n\n406\n00:21:16.890 --> 00:21:20.120\nI have it on just for\nthe purposes of demonstration later.\n\n407\n00:21:20.120 --> 00:21:26.290\nBut if I didn't have that on, it wouldn't\nallow the service to continue, right?\n\n408\n00:21:26.290 --> 00:21:29.310\nThat's the purpose of this\nSecurity Configuration Wizard.\n\n409\n00:21:29.310 --> 00:21:30.711\nWe'll go ahead and choose Next.\n\n410\n00:21:30.711 --> 00:21:32.790\nI'm gonna go ahead and\nskip Registry Settings.\n\n411\n00:21:32.790 --> 00:21:35.173\nSo we don't need to make any registry\nmodifications, maybe you do.\n\n412\n00:21:35.173 --> 00:21:37.227\nAudit policy, I'll go ahead and skip that.\n\n413\n00:21:37.227 --> 00:21:42.258\nAnd we're gonna save this policy, and\n\n414\n00:21:42.258 --> 00:21:48.059\nwe'll call it demo-security-baseline.\n\n415\n00:21:48.059 --> 00:21:52.904\nAll right, and we will choose Next.\n\n416\n00:21:52.904 --> 00:21:59.214\nAnd we're gonna go ahead, and we're gonna\nto let it apply itself now, all right.\n\n417\n00:21:59.214 --> 00:22:01.236\n&gt;&gt; I think we had changed\nthe radio button there.\n\n418\n00:22:01.236 --> 00:22:02.010\n&gt;&gt; Did I?\n\n419\n00:22:02.010 --> 00:22:03.720\nOkay, well, that's okay, great.\n\n420\n00:22:03.720 --> 00:22:05.260\nIf I didn't apply it now,\n\n421\n00:22:05.260 --> 00:22:09.410\nthat is perfectly fine because we can\nalways go back down into Windows.\n\n422\n00:22:09.410 --> 00:22:10.855\nWe can go to Local Disk (C:).\n\n423\n00:22:12.830 --> 00:22:13.920\nWhere is it?\n\n424\n00:22:13.920 --> 00:22:17.480\nWindows, and I believe it's security.\n\n425\n00:22:17.480 --> 00:22:20.580\nFind security, and\nright there in front of me.\n\n426\n00:22:20.580 --> 00:22:24.162\nSecurity and then the Microsoft,\nI know that little acronym there,\n\n427\n00:22:24.162 --> 00:22:27.290\nMicrosoft Security Configuration Wizard.\n\n428\n00:22:27.290 --> 00:22:29.030\nAnd I believe policies are right here.\n\n429\n00:22:29.030 --> 00:22:31.380\nAnd there is our demo baseline.\n\n430\n00:22:31.380 --> 00:22:32.700\nNow, what is the demo baseline?\n\n431\n00:22:32.700 --> 00:22:36.710\nBut if you open it up, it's really\njust nothing more than XML settings,\n\n432\n00:22:36.710 --> 00:22:37.645\nXML in general.\n\n433\n00:22:41.192 --> 00:22:47.180\nAll right, okay, Windows, we will\nuse your recommended settings, okay?\n\n434\n00:22:47.180 --> 00:22:49.760\nSo you can see just a whole\nbunch of XML settings, right?\n\n435\n00:22:49.760 --> 00:22:53.819\nMost of the configurations that are done\ndynamically inside of Windows when you're\n\n436\n00:22:53.819 --> 00:22:56.860\nsupporting configurations are XML based,\nthings like USMT.\n\n437\n00:22:56.860 --> 00:23:02.790\nA lot of your configurations are XML\nbased, but we can still run this policy.\n\n438\n00:23:02.790 --> 00:23:05.720\nThe great thing is,\nif you didn't run the policy,\n\n439\n00:23:05.720 --> 00:23:08.780\nstart the Security Configuration Wizard\none more time, choose Yes.\n\n440\n00:23:08.780 --> 00:23:12.510\nBut this time, we're gonna choose\nApply an existing security policy.\n\n441\n00:23:12.510 --> 00:23:13.430\n&gt;&gt; Just point to that one.\n\n442\n00:23:13.430 --> 00:23:15.480\n&gt;&gt; And point it right to that,\nyes, ma'am, absolutely.\n\n443\n00:23:15.480 --> 00:23:16.810\nSo we'll go ahead and we'll do that.\n\n444\n00:23:16.810 --> 00:23:19.860\nWe'll point it to our\ndemo-security-baseline.\n\n445\n00:23:19.860 --> 00:23:20.628\nWe'll go ahead and choose Open.\n\n446\n00:23:20.628 --> 00:23:22.800\nWe'll choose Next, Next.\n\n447\n00:23:24.210 --> 00:23:26.240\nAnd we'll go ahead and apply the policy.\n\n448\n00:23:27.620 --> 00:23:31.120\nAll right, now it could take a second\ndepending on how many settings you have.\n\n449\n00:23:31.120 --> 00:23:32.450\nIt could take a second to apply this.\n\n450\n00:23:32.450 --> 00:23:37.310\nBut once this gets done, what we're gonna\ndo is we're gonna see how it will work.\n\n451\n00:23:37.310 --> 00:23:39.400\nWe're gonna go ahead and\nwe're gonna open up our services.\n\n452\n00:23:39.400 --> 00:23:43.325\nAnd remember, we had a couple of those\nservices that it changed from a manual\n\n453\n00:23:43.325 --> 00:23:45.970\nstartup type, and it disabled them.\n\n454\n00:23:45.970 --> 00:23:49.236\nSo what we're gonna do is Wes is gonna\nplay the role of somebody who isn't paying\n\n455\n00:23:49.236 --> 00:23:51.353\nattention to configuration management,\nright?\n\n456\n00:23:51.353 --> 00:23:55.456\nAnd he's gonna come in here and change\nthese configurations, and then we're gonna\n\n457\n00:23:55.456 --> 00:23:59.291\nrerun our security policy here and see\nif it can bring us back into compliance.\n\n458\n00:23:59.291 --> 00:24:01.027\nWith what the policy says.\n\n459\n00:24:01.027 --> 00:24:05.400\nAll right, so we'll go ahead and\nwe'll let this run.\n\n460\n00:24:05.400 --> 00:24:08.164\nAll right,\ndoes look like it has completed.\n\n461\n00:24:08.164 --> 00:24:11.549\nSo we'll go ahead and\nlet that finish that up.\n\n462\n00:24:11.549 --> 00:24:16.329\nAnd next thing we're gonna do is we will,\nlet's go ahead and\n\n463\n00:24:16.329 --> 00:24:20.600\ngo to our Tools, and\nwe'll launch our Services.\n\n464\n00:24:20.600 --> 00:24:24.320\nAnd remember, some of those services\nthat we were looking at, right.\n\n465\n00:24:24.320 --> 00:24:28.080\nWe looked at the Application Experience,\n\n466\n00:24:28.080 --> 00:24:32.210\nright, Application Identity, and\nthe Application Layer Gateway.\n\n467\n00:24:32.210 --> 00:24:39.150\nNotice that Application Experience,\nright, the service has been disabled.\n\n468\n00:24:39.150 --> 00:24:41.430\nStartup type, and it is stopped, right?\n\n469\n00:24:41.430 --> 00:24:43.220\nThis is an unnecessary service, right?\n\n470\n00:24:43.220 --> 00:24:45.960\nWe're reducing our attack surface by\n\n471\n00:24:45.960 --> 00:24:49.640\ndisabling unnecessary services like that,\nright?\n\n472\n00:24:49.640 --> 00:24:52.550\nI'm gonna go ahead and\nrub against the grain,\n\n473\n00:24:52.550 --> 00:24:54.610\nsand against the grain right here, right?\n\n474\n00:24:54.610 --> 00:24:59.060\nWe're gonna go ahead and I'm gonna change\nthis to an automatic startup type.\n\n475\n00:25:00.530 --> 00:25:05.061\nAnd I'm gonna go ahead and\nstart the service, living dangerously.\n\n476\n00:25:05.061 --> 00:25:08.450\n[LAUGH] All right, and\nwe'll go and close that now.\n\n477\n00:25:08.450 --> 00:25:10.670\nNext thing that we looked at was what?\n\n478\n00:25:10.670 --> 00:25:13.720\nWe looked at the application\nlayer gateway.\n\n479\n00:25:13.720 --> 00:25:18.300\nNotice that when we ran our\nsecurity baseline it disabled it.\n\n480\n00:25:18.300 --> 00:25:20.807\nI'm gonna change it to Automatic.\n\n481\n00:25:20.807 --> 00:25:23.695\nAnd this time, I'll choose Apply, so I\ndon't have to re-open the dialog box, and\n\n482\n00:25:23.695 --> 00:25:24.440\nI'll choose Start.\n\n483\n00:25:25.550 --> 00:25:27.310\nAll right, there's our other one.\n\n484\n00:25:27.310 --> 00:25:31.640\nAgain, evilness going on here, we are not\nfollowing our security compliance, right?\n\n485\n00:25:31.640 --> 00:25:32.467\n&gt;&gt; Uh-oh!\n\n486\n00:25:32.467 --> 00:25:33.338\n&gt;&gt; That's right.\n\n487\n00:25:33.338 --> 00:25:37.360\n[LAUGH] So we'll go ahead and change that\nthird one, there, Application Management.\n\n488\n00:25:37.360 --> 00:25:40.060\nAnd we'll change it to\nan Automatic Startup type.\n\n489\n00:25:40.060 --> 00:25:44.510\nWe'll choose Apply and we'll choose Start,\nwe'll let that service start and\n\n490\n00:25:44.510 --> 00:25:45.720\nwe'll say OK.\n\n491\n00:25:45.720 --> 00:25:48.511\nNow Cherokee, if you can maybe verify for\n\n492\n00:25:48.511 --> 00:25:52.993\neverybody out there\nApplication Experience is running, right?\n\n493\n00:25:52.993 --> 00:25:53.617\n&gt;&gt; Yeah.\n&gt;&gt; And\n\n494\n00:25:53.617 --> 00:25:56.378\nManagement is running and\nthen that Layer Gateway is running too.\n\n495\n00:25:56.378 --> 00:26:02.051\nIt's just the three I can\nremember from the top of that\n\n496\n00:26:02.051 --> 00:26:02.720\n&gt;&gt; The list we were-\n\n497\n00:26:02.720 --> 00:26:03.610\n&gt;&gt; The list, thank you.\n\n498\n00:26:03.610 --> 00:26:06.917\nAll right, so let me go ahead and\nwhat we'll do is we'll close down this.\n\n499\n00:26:06.917 --> 00:26:11.260\nAnd we're gonna rerun our\napparently Internet Explorer.\n\n500\n00:26:11.260 --> 00:26:15.200\nLet's try that again, we're gonna rerun\nour Security Configuration Wizard.\n\n501\n00:26:15.200 --> 00:26:20.500\nAnd we're going to do the same thing, and\nwe will apply an existing security policy.\n\n502\n00:26:20.500 --> 00:26:22.890\nWe're gonna Browse to that same location.\n\n503\n00:26:22.890 --> 00:26:25.320\nRemember this is our security baseline.\n\n504\n00:26:25.320 --> 00:26:29.990\nAnd we do wanna make sure that we\nare in configuration compliance.\n\n505\n00:26:29.990 --> 00:26:32.530\nWe'll choose Next, we'll let it run.\n\n506\n00:26:32.530 --> 00:26:35.120\nAnd it is going to do the same\nthing that it did before.\n\n507\n00:26:35.120 --> 00:26:37.340\nAnd it could take the same amount of time.\n\n508\n00:26:37.340 --> 00:26:40.690\nThe one and great thing is,\nit's probably a little bit faster.\n\n509\n00:26:40.690 --> 00:26:41.910\nAnd as you can see it's already done.\n\n510\n00:26:41.910 --> 00:26:44.690\nBecause most of those services,\nit didn't need to change anything.\n\n511\n00:26:44.690 --> 00:26:49.400\nSo let's go ahead and\nchoose Next, and finished.\n\n512\n00:26:49.400 --> 00:26:53.990\nAnd then last little bit here, let's\nbring back up our Services console, and\n\n513\n00:26:53.990 --> 00:26:55.190\nlet's see what it did.\n\n514\n00:26:55.190 --> 00:26:57.482\nAll right, Cherokee,\nnow I need your help on this one.\n\n515\n00:26:57.482 --> 00:26:59.143\nDid it bring us back into compliance?\n\n516\n00:26:59.143 --> 00:27:02.109\nWe've got Application Experience,\nIt is not running,\n\n517\n00:27:02.109 --> 00:27:04.810\nis it running better\nEnglish here on my part.\n\n518\n00:27:04.810 --> 00:27:10.070\nAnd it is a Disabled type, right,\nApplication Layer Gateway.\n\n519\n00:27:10.070 --> 00:27:12.420\n&gt;&gt; Disabled.\n&gt;&gt; Disabled and it isn't running.\n\n520\n00:27:12.420 --> 00:27:16.550\nAnd then the last one Application\nManagement, Disabled and it isn't running.\n\n521\n00:27:16.550 --> 00:27:21.002\nRight, so that is one of the things that\nyou can do by using these configuration\n\n522\n00:27:21.002 --> 00:27:22.835\ncompliance scanners, right?\n\n523\n00:27:22.835 --> 00:27:27.376\nAnd the Security Configuration Wizard is\nthe one that can allow you to do that.\n\n524\n00:27:27.376 --> 00:27:29.413\nLike I said this is a great program,\n\n525\n00:27:29.413 --> 00:27:33.750\nMicrosoft must have seen that it didn't\nhave a lot of popularity if you will.\n\n526\n00:27:33.750 --> 00:27:37.893\nAnd they tend to remove things, that if\nthey've gathered a lot of information and\n\n527\n00:27:37.893 --> 00:27:41.015\nover the last ten years,\nit doesn't get a lot of attraction,\n\n528\n00:27:41.015 --> 00:27:42.592\nit doesn't get a lot of usage.\n\n529\n00:27:42.592 --> 00:27:43.600\nThen what they do is they'll take\nit out of their operating system.\n\n530\n00:27:43.600 --> 00:27:45.325\n&gt;&gt; Paying attention to that feedback.\n\n531\n00:27:45.325 --> 00:27:46.920\n&gt;&gt; Most definitely, and why is that?\n\n532\n00:27:46.920 --> 00:27:49.620\nBecause it's extra stuff that people\naren't using, so they take it out of\n\n533\n00:27:49.620 --> 00:27:52.890\nthe operating system because you\ndon't need extra baggage with you.\n\n534\n00:27:52.890 --> 00:27:56.180\nAnd today what you'll do is you can\ndownload a third, well it's still\n\n535\n00:27:56.180 --> 00:28:01.090\nMicrosoft but it isn't, it is software\nthat you add to the server after that.\n\n536\n00:28:01.090 --> 00:28:05.280\nAnd that's called the Microsoft Security\nCompliance Manager, if you will.\n\n537\n00:28:05.280 --> 00:28:06.950\nAnd then you can still run it.\n\n538\n00:28:06.950 --> 00:28:10.230\nSo you still get the same kind of\nfunctionality and features, but again,\n\n539\n00:28:10.230 --> 00:28:12.820\nit's not baked into the operating\nsystem like it has been for\n\n540\n00:28:12.820 --> 00:28:14.420\npretty much quite a few years there.\n\n541\n00:28:14.420 --> 00:28:17.190\nSo that gives you the example of some\n\n542\n00:28:17.190 --> 00:28:19.910\ntypes of configuration\ncompliance scanners.\n\n543\n00:28:19.910 --> 00:28:23.713\nAnd how you can bring yourself back\ninto compliance by first of all,\n\n544\n00:28:23.713 --> 00:28:25.455\nsetting a security baseline.\n\n545\n00:28:25.455 --> 00:28:28.208\nAnd then checking the configurations\nof your devices and\n\n546\n00:28:28.208 --> 00:28:32.395\nmaking sure that you're re-running those\ncompliance policies to bring you back into\n\n547\n00:28:32.395 --> 00:28:35.287\ncompliance with whatever your\nsecurity posture might be.\n\n548\n00:28:35.287 --> 00:28:38.464\n&gt;&gt; Well, you've put a big dent in the\ndifferent types of software based tools\n\n549\n00:28:38.464 --> 00:28:40.590\nthat we can use here, but\nwe still have a lot to go.\n\n550\n00:28:40.590 --> 00:28:42.110\nSo stay tuned, ladies and gentlemen.\n\n551\n00:28:42.110 --> 00:28:44.280\nFor this show,\nwe're going to go ahead and sign out.\n\n552\n00:28:44.280 --> 00:28:45.470\nI'm your host, Cherokee Boose.\n\n553\n00:28:45.470 --> 00:28:46.300\n&gt;&gt; And I'm Wes Bryan.\n\n554\n00:28:46.300 --> 00:28:48.487\n&gt;&gt; See you next time here at ITProTV.\n\n555\n00:28:48.487 --> 00:28:55.410\n[MUSIC]\n\n556\n00:28:55.410 --> 00:28:58.597\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213514047"
        },
        {
          "description": "In this show, Wes and Cherokee continue to share tools to assist in assist posture assessment compliance. First,  they suggest how to sanitize drives by overwriting at a bit a bit level depending on different regulatory compliance. Next, they discuss steganography tools to be aware of. Lastly, they explain the benefits of setting up a honeypot or honeynet.",
          "length": "1101",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-3-security_posture_assessment_pt3-041117.00_18_05_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-3-security_posture_assessment_pt3-041117.00_18_05_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-3-security_posture_assessment_pt3-041117.00_18_05_07.Still001-sm.jpg",
          "title": "Security Posture Assessment Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:03.066\nWelcome to ITPRO.TV,\nI'm your host Don Perez.\n\n2\n00:00:03.066 --> 00:00:06.326\n[CROSSTALK]\n\n3\n00:00:06.326 --> 00:00:08.471\n[MUSIC]\n\n4\n00:00:08.471 --> 00:00:11.103\n&gt;&gt; You're watching ITPRO.TV.\n\n5\n00:00:11.103 --> 00:00:12.168\n[MUSIC]\n\n6\n00:00:12.168 --> 00:00:14.650\nWelcome to your CompTIA Security+ series.\n\n7\n00:00:14.650 --> 00:00:16.550\nI'm your show host, Cherokee Boose.\n\n8\n00:00:16.550 --> 00:00:19.430\nWe've actually made it to part three,\nwhere we will continue to\n\n9\n00:00:19.430 --> 00:00:23.320\nexamine different software-based types\nof posture assessment utilities.\n\n10\n00:00:23.320 --> 00:00:26.433\nAnd with us today, again, back in studio,\nis we have Mr. Wes Bryan.\n\n11\n00:00:26.433 --> 00:00:27.442\nThank you for joining us, Wes.\n\n12\n00:00:27.442 --> 00:00:28.710\n&gt;&gt; Yeah, Cherokee,\nthanks for having me here.\n\n13\n00:00:28.710 --> 00:00:32.750\nThat's right, we are coming back to\na part, how many parts have we done now?\n\n14\n00:00:32.750 --> 00:00:34.270\nPart two, is it part two or part three?\n\n15\n00:00:34.270 --> 00:00:35.096\n&gt;&gt; We're in three, Wes.\n\n16\n00:00:35.096 --> 00:00:36.526\n[LAUGH]\n&gt;&gt; My gosh, before we know it,\n\n17\n00:00:36.526 --> 00:00:39.700\nwe're gonna end up having a whole\nentire miniseries on this one.\n\n18\n00:00:39.700 --> 00:00:43.093\nBut a lot of important\ninformation to take care of.\n\n19\n00:00:43.093 --> 00:00:47.170\nIn the last one, we kinda left off with\nconfiguration compliance managers.\n\n20\n00:00:47.170 --> 00:00:52.150\nWe looked at the security configuration\nwizard inside of Windows Server.\n\n21\n00:00:52.150 --> 00:00:56.030\nWe talked a little bit about\nMicrosoft's Compliance Manager as well as\n\n22\n00:00:56.030 --> 00:00:58.949\nSecurity Compliance Manager\nin the newer software.\n\n23\n00:00:58.949 --> 00:01:02.426\nThe next thing we're gonna talk about\nare what are known as exploitation\n\n24\n00:01:02.426 --> 00:01:03.515\nframeworks, right?\n\n25\n00:01:03.515 --> 00:01:07.381\nSo I want you to think of a scenario in\nwhich you need to test vulnerabilities and\n\n26\n00:01:07.381 --> 00:01:09.560\nyou need to bring up\nan application server.\n\n27\n00:01:09.560 --> 00:01:11.820\nYou need to get\nthe utilities that you need.\n\n28\n00:01:11.820 --> 00:01:13.970\nMaybe the virtual machines that you need.\n\n29\n00:01:13.970 --> 00:01:17.480\nYou have to put all this\ntogether in order to make sure\n\n30\n00:01:17.480 --> 00:01:21.660\nof whether your web application or\nyour systems are safe.\n\n31\n00:01:21.660 --> 00:01:26.490\nWouldn't it be nice if somebody has all\nthose tools, that framework, if you will,\n\n32\n00:01:26.490 --> 00:01:29.730\nalready ready to go for you and\nall you have to do is download it.\n\n33\n00:01:29.730 --> 00:01:34.250\nAnd you can go to town right\naway testing your networks.\n\n34\n00:01:34.250 --> 00:01:36.970\nThere are a few of them\nthat are out there.\n\n35\n00:01:36.970 --> 00:01:40.120\nThey just kinda mention in\nthe objectives exploitation frameworks.\n\n36\n00:01:40.120 --> 00:01:42.370\nBut let's go ahead and\ntalk about a couple of them.\n\n37\n00:01:42.370 --> 00:01:45.710\nIn fact, I've got one of the most\npopular pulled up on my screen already.\n\n38\n00:01:45.710 --> 00:01:46.640\nAnd that is metasploit.\n\n39\n00:01:46.640 --> 00:01:50.740\nMetasploit is one in fact we use this,\nI know people like Mike Rodrick,\n\n40\n00:01:50.740 --> 00:01:55.040\nAdam Gordon,\nDan Lowrie on our other host here\n\n41\n00:01:55.040 --> 00:01:58.190\nhave used this extensively on\nour other courses that we have.\n\n42\n00:01:58.190 --> 00:02:02.140\nBut you can see that it is a free\ndownload, so it doesn't cost anything and\n\n43\n00:02:02.140 --> 00:02:04.800\nthat is a great utility to have.\n\n44\n00:02:04.800 --> 00:02:09.700\nIf you're doing web application\nvulnerability testing there's also w3af.\n\n45\n00:02:09.700 --> 00:02:12.960\nThis is another one that's out there, and\nagain, it's already got the framework and\n\n46\n00:02:12.960 --> 00:02:14.670\nit's got a graphical user interface.\n\n47\n00:02:14.670 --> 00:02:19.011\nAnd again, and you can see it's\nalready ready to go for you.\n\n48\n00:02:19.011 --> 00:02:20.000\nYou can download it.\n\n49\n00:02:20.000 --> 00:02:23.040\nYou've got the community involvement,\nwhich is really nice,\n\n50\n00:02:23.040 --> 00:02:26.890\nwhen you have other people that\nhave already been using a product.\n\n51\n00:02:26.890 --> 00:02:29.920\nAnd they can give you a lot of feedback,\ngive you advice.\n\n52\n00:02:29.920 --> 00:02:31.010\nMaybe you visit a Wiki and\n\n53\n00:02:31.010 --> 00:02:36.300\nyou can gain some knowledge, and it'll\nhelp you get up and running even faster.\n\n54\n00:02:36.300 --> 00:02:39.380\n&gt;&gt; Another one that's out there\nis called Canvas, all right?\n\n55\n00:02:39.380 --> 00:02:44.440\nCanvas is another one of these,\nif you will, exploitation frameworks, and\n\n56\n00:02:44.440 --> 00:02:49.363\nyou can see it makes available hundreds\nof exploits, right, even automation.\n\n57\n00:02:49.363 --> 00:02:52.808\nAnd it just makes it easier\nto test your systems, right?\n\n58\n00:02:52.808 --> 00:02:56.031\nWithout having to go through\nthe process of sitting down,\n\n59\n00:02:56.031 --> 00:02:59.975\ntrying to write an exploit, and\nthen sending and bounce it of like, for\n\n60\n00:02:59.975 --> 00:03:02.360\ninstance, your web application server.\n\n61\n00:03:02.360 --> 00:03:06.740\nSo nice to have these frameworks\nready to go for you, so\n\n62\n00:03:06.740 --> 00:03:09.040\nthat you don't have to put them together.\n\n63\n00:03:09.040 --> 00:03:13.225\n&gt;&gt; Wesley, we really have to think about\nthis, because depending on what industry\n\n64\n00:03:13.225 --> 00:03:17.163\nwe were in, we need to consider any\nkind of data retention policies that, or\n\n65\n00:03:17.163 --> 00:03:20.262\nany kind of regulatory compliances\nthat we must adhere to.\n\n66\n00:03:20.262 --> 00:03:21.158\n&gt;&gt; Yeah, that's right Cherokee.\n\n67\n00:03:21.158 --> 00:03:25.347\nSo one of the standards that\ncomes to mind is, for instance,\n\n68\n00:03:25.347 --> 00:03:29.140\nDODs 5220.22-M,\nmake sure I say that right.\n\n69\n00:03:29.140 --> 00:03:31.290\nA lot of numbers in there for that one.\n\n70\n00:03:31.290 --> 00:03:34.630\nAnd then again, this is the Department\nof Defense standard for sanitation,\n\n71\n00:03:34.630 --> 00:03:36.620\nit's actually a cyber security.\n\n72\n00:03:36.620 --> 00:03:38.440\nA standard if you will, and\n\n73\n00:03:38.440 --> 00:03:42.645\nin it it does define how drives\nare gonna be sanitized, right.\n\n74\n00:03:42.645 --> 00:03:47.623\nAgain, how is it gonna go through what is\nknown as it's overwriting process, right.\n\n75\n00:03:47.623 --> 00:03:49.406\nIt means, for instance,\n\n76\n00:03:49.406 --> 00:03:54.429\nevery little location on that media is\ngoing to have a zero written to it and\n\n77\n00:03:54.429 --> 00:03:59.190\nthen a verification of the zero\nbeing written to that location.\n\n78\n00:03:59.190 --> 00:04:02.910\nA verification that a one has now\nbeen written to it after that.\n\n79\n00:04:02.910 --> 00:04:05.320\nAnd then a random character\napplied to it as well.\n\n80\n00:04:05.320 --> 00:04:09.860\nSo It's important that if we do\nhave a necessity for compliance of\n\n81\n00:04:09.860 --> 00:04:14.130\nthese standards, that we're using a\nutility that'll allow us to adhere to it.\n\n82\n00:04:14.130 --> 00:04:17.400\nIt doesn't just mean that you\nhave to adhere to the standards.\n\n83\n00:04:17.400 --> 00:04:22.001\nMaybe you wanna be rest assured that your\ninformation isn't going to be recoverable\n\n84\n00:04:22.001 --> 00:04:25.126\nin a fact when you are getting\nrid of drives, if you will.\n\n85\n00:04:25.126 --> 00:04:27.300\nMaybe you're recycling them.\n\n86\n00:04:27.300 --> 00:04:29.370\nSo there are some technologies out there,\n\n87\n00:04:29.370 --> 00:04:32.710\nlike for instance Darik's Boot and\nNuke, right?\n\n88\n00:04:32.710 --> 00:04:36.420\nDBAN, I've actually got an example\nof this right here on our screen.\n\n89\n00:04:36.420 --> 00:04:38.177\nIt's kind of like a Linux Live CD, right?\n\n90\n00:04:38.177 --> 00:04:42.254\nAnd what you do is you boot,\nyou burn it to disk if you will or\n\n91\n00:04:42.254 --> 00:04:45.290\nUSB if you've got a bootable USB device.\n\n92\n00:04:45.290 --> 00:04:47.730\nAnd you stick it in the media,\nyou boot to it, and\n\n93\n00:04:47.730 --> 00:04:51.680\nthen you can point it to the drives\nthat you want to, you want to erase.\n\n94\n00:04:51.680 --> 00:04:53.000\nRight, you want to sanitize.\n\n95\n00:04:53.000 --> 00:04:55.990\nAnd it also follows standards too,\nhere as well.\n\n96\n00:04:55.990 --> 00:05:00.880\nSo for instance, we can see some examples\nif you want to learn about DBAN.\n\n97\n00:05:00.880 --> 00:05:02.832\nIt tells you to do, choose F2.\n\n98\n00:05:02.832 --> 00:05:05.200\nFor me, I wanna show you some\nof these quick commands.\n\n99\n00:05:05.200 --> 00:05:07.950\nCuz the quick commands actually\ntell you a little bit about\n\n100\n00:05:07.950 --> 00:05:10.600\nwhat kind of standards it's gonna follow.\n\n101\n00:05:10.600 --> 00:05:13.528\nSo for instance,\nif I wanted to from the command prompt,\n\n102\n00:05:13.528 --> 00:05:15.115\nI could just type DoD, right.\n\n103\n00:05:15.115 --> 00:05:16.101\nAnd if I type DoD and\n\n104\n00:05:16.101 --> 00:05:20.440\nhit Enter, then what that's gonna do is\nthat's gonna follow along with this DoD.\n\n105\n00:05:20.440 --> 00:05:25.470\nAnd here you could see it,\nthe DoD 5220.22-M method, right.\n\n106\n00:05:25.470 --> 00:05:29.406\nAnd it makes it to where if we\nare going to do drive sanitation,\n\n107\n00:05:29.406 --> 00:05:34.266\nthis software is letting us know that\nit does follow along those standards.\n\n108\n00:05:34.266 --> 00:05:36.790\nBut it's not the only thing\nthat you've got out there.\n\n109\n00:05:36.790 --> 00:05:38.940\nFor instance,\nyou've got some other GUI-driven ones,\n\n110\n00:05:38.940 --> 00:05:40.910\nand I'm just giving you\nan example of one here.\n\n111\n00:05:40.910 --> 00:05:42.930\nActive kill disk is one.\n\n112\n00:05:42.930 --> 00:05:46.720\nWe also have some that utility\nthat's in our Linux system.\n\n113\n00:05:46.720 --> 00:05:49.770\nSo for instance,\nif I jump over to my sent box,\n\n114\n00:05:49.770 --> 00:05:52.840\nthere's something known as scrub, right?\n\n115\n00:05:52.840 --> 00:05:57.600\nAnd if we look at the help for\nscrub, and we run this,\n\n116\n00:05:57.600 --> 00:06:01.780\nyou can see that it also has some\nstandards that it follows as well, right?\n\n117\n00:06:01.780 --> 00:06:03.850\nSo we can find out the version, right?\n\n118\n00:06:03.850 --> 00:06:05.670\nWe can select the pattern, right?\n\n119\n00:06:05.670 --> 00:06:10.134\nHow do we wanna do the overwrite's,\nwhat's the level of sanitization,\n\n120\n00:06:10.134 --> 00:06:14.816\nI'll get it right eventually I'm\nmissing some syllables in there, right?\n\n121\n00:06:14.816 --> 00:06:17.338\nThat's why I always say disc sanitizing.\n\n122\n00:06:17.338 --> 00:06:20.710\n[LAUGH] We can see what pattern it is, and\n\n123\n00:06:20.710 --> 00:06:22.870\nnotice it says select\nthe scrub pattern sequence.\n\n124\n00:06:22.870 --> 00:06:25.650\nWell, these are the available\npatterns in scrub, right?\n\n125\n00:06:25.650 --> 00:06:28.790\nAnd you can see different standards here,\nand\n\n126\n00:06:28.790 --> 00:06:32.780\nspecifically the one that we're kinda\nlooking at here, is the DoD standard.\n\n127\n00:06:32.780 --> 00:06:36.030\nSo I can see a couple of different\ntechnologies that we wanna,\n\n128\n00:06:36.030 --> 00:06:39.970\nif we do wanna completely\neradicate the information or\n\n129\n00:06:39.970 --> 00:06:43.070\nnot make it most likely\nunrecoverable right.\n\n130\n00:06:43.070 --> 00:06:46.440\nThe only way to eradicate the data is\nto incinerate the media that it's on.\n\n131\n00:06:46.440 --> 00:06:48.768\nThat's true data eradication.\n\n132\n00:06:48.768 --> 00:06:53.037\nAnd by the way, in that standard,\nthe 5220 cyber security standard,\n\n133\n00:06:53.037 --> 00:06:55.830\nthey do have classifications\nthat go that high.\n\n134\n00:06:55.830 --> 00:07:00.793\nAs incineration, that went just complete\nelimination of the drive, right,\n\n135\n00:07:00.793 --> 00:07:05.471\nat two steps from a settlling torch and\njust melting into a puddle of ooze.\n\n136\n00:07:05.471 --> 00:07:09.114\nBut again, just make sure that if\nyou do have a piece of software and\n\n137\n00:07:09.114 --> 00:07:11.130\nyou wanna find out is it compliant?\n\n138\n00:07:11.130 --> 00:07:12.620\nDo you know if it's compliant?\n\n139\n00:07:12.620 --> 00:07:16.120\nWell, check the help documentation in\nthe software itself, because there's so\n\n140\n00:07:16.120 --> 00:07:20.950\nmany different applications, so many\ndifferent pieces of software out there.\n\n141\n00:07:20.950 --> 00:07:22.600\nI can't tell you if one's compliant or\nnot.\n\n142\n00:07:22.600 --> 00:07:26.032\nThe best thing you can do is\ncontact the vendor themselves,\n\n143\n00:07:26.032 --> 00:07:28.373\nlook at any Wiki information they have.\n\n144\n00:07:28.373 --> 00:07:29.500\n&gt;&gt; Support information.\n\n145\n00:07:29.500 --> 00:07:33.110\n&gt;&gt; Support information, frequently\nasked questions, community sources.\n\n146\n00:07:33.110 --> 00:07:37.181\nCommunity sources are great because\nyou'll have some people that say, yeah,\n\n147\n00:07:37.181 --> 00:07:39.547\nI've been using DBAN now for\nten years and XYZ.\n\n148\n00:07:39.547 --> 00:07:42.165\nAnd that information is just\ninvaluable is the fact that\n\n149\n00:07:42.165 --> 00:07:45.284\nyou can use somebody's experience\nthat has used the software, or\n\n150\n00:07:45.284 --> 00:07:47.910\nthese types of softwares\nprior to you ever using them.\n\n151\n00:07:47.910 --> 00:07:52.775\nSo, keep in mind, examples just being\nscrubbed like we've seen inside of Linux,\n\n152\n00:07:52.775 --> 00:07:53.520\nDBAN.\n\n153\n00:07:53.520 --> 00:07:57.510\nAgain, DBAN kinda like a live\nCD that you just boot to and\n\n154\n00:07:57.510 --> 00:07:58.890\nyou can scrub the drive from there.\n\n155\n00:07:59.940 --> 00:08:02.688\nNow the next thing that they call\nout is kinda an interesting concept.\n\n156\n00:08:02.688 --> 00:08:07.361\nThey talk about steganography tools and\nI have to be careful with this one because\n\n157\n00:08:07.361 --> 00:08:12.550\nas you can see I can't even say the,\nwhat is it, the sanitization that well.\n\n158\n00:08:12.550 --> 00:08:19.016\nSo I have to make sure I'm saying\nsteganography and stenography.\n\n159\n00:08:19.016 --> 00:08:21.900\nShorthand, we're not talking shorthand,\nright?\n\n160\n00:08:21.900 --> 00:08:25.100\nWhat we're talking about is\na cryptographic technique that takes\n\n161\n00:08:25.100 --> 00:08:27.760\ninformation and hides it in plain sight.\n\n162\n00:08:27.760 --> 00:08:30.090\nAll right, it's a little bit\ndifferent than encryption, right?\n\n163\n00:08:30.090 --> 00:08:32.770\nIn encryption,\nyou know there's a message there, right?\n\n164\n00:08:32.770 --> 00:08:34.720\nYou could see the fact that\nthere's a message there,\n\n165\n00:08:34.720 --> 00:08:35.710\nyou just can't read it, right?\n\n166\n00:08:35.710 --> 00:08:38.720\nIt's been scrambled in a way\nthat's producing cypher text.\n\n167\n00:08:38.720 --> 00:08:40.850\nWith steganography, it's in plain sight.\n\n168\n00:08:40.850 --> 00:08:44.190\nWe don't even know [LAUGH] that\nthe message is actually there.\n\n169\n00:08:44.190 --> 00:08:47.790\nSo there are tools that you can use\nas well, and I've actually got one.\n\n170\n00:08:47.790 --> 00:08:52.714\nIn fact, let me show you one,\nI've got one here on my Mac called iSteg.\n\n171\n00:08:52.714 --> 00:08:58.180\nAnd if I go ahead and just load this\nup it asks me for a password, right?\n\n172\n00:08:58.180 --> 00:09:01.240\nAnd I'll go ahead and do a,\nI'll let it generate the password here and\n\n173\n00:09:01.240 --> 00:09:02.470\nthen I'll just kind of copy it, right?\n\n174\n00:09:02.470 --> 00:09:05.200\nSo what we're gonna do is we're\ngonna take a picture, right?\n\n175\n00:09:05.200 --> 00:09:08.312\nAnd we're gonna hide a file\ninside of that picture.\n\n176\n00:09:08.312 --> 00:09:10.524\nAll right, so let me go ahead and select.\n\n177\n00:09:10.524 --> 00:09:14.760\nI've got a picture of\nmy lovely horse here.\n\n178\n00:09:14.760 --> 00:09:15.754\nWe'll go ahead and chose that.\n\n179\n00:09:15.754 --> 00:09:16.840\n&gt;&gt; You're lovely horse?\n\n180\n00:09:16.840 --> 00:09:17.881\n&gt;&gt; Yeah, my lovely horse.\n\n181\n00:09:17.881 --> 00:09:21.420\nThey've told me that he's special and\nwe'll see that here in a second.\n\n182\n00:09:21.420 --> 00:09:24.080\nBut then I've got this\nsecret file if you want.\n\n183\n00:09:24.080 --> 00:09:26.509\nAnd I want to embed it in the photo.\n\n184\n00:09:26.509 --> 00:09:27.630\nWell, what's it doing?\n\n185\n00:09:27.630 --> 00:09:30.660\nIt's doing something known as\ntaking the least significant bit.\n\n186\n00:09:30.660 --> 00:09:35.360\nAnd it's using those least significant\nbits in order to store the information.\n\n187\n00:09:35.360 --> 00:09:41.750\nSo let's go ahead and\nhere is my secret-stuff.txt document.\n\n188\n00:09:41.750 --> 00:09:43.710\nWe'll go ahead and choose that.\n\n189\n00:09:43.710 --> 00:09:48.390\nAll right, and then it's asking me,\nwhat is the output quality I want.\n\n190\n00:09:48.390 --> 00:09:50.780\nAnd that's just in case,\nyou don't want it to drop too low.\n\n191\n00:09:50.780 --> 00:09:53.240\nSomebody might say,\nwhat's wrong with that picture?\n\n192\n00:09:53.240 --> 00:09:55.510\nWe'll go ahead and we'll let this process.\n\n193\n00:09:55.510 --> 00:09:58.500\nAnd I'll do the output,\nlet's do the output right to the desktop.\n\n194\n00:09:58.500 --> 00:10:01.050\nAnd I'll just call it output.jpg.\n\n195\n00:10:01.050 --> 00:10:03.580\nAnd we'll go ahead, and\nwe'll let this run, right?\n\n196\n00:10:03.580 --> 00:10:05.460\nAnd you'll notice,\nit's going through its process.\n\n197\n00:10:05.460 --> 00:10:06.580\nNotice what it's doing here.\n\n198\n00:10:06.580 --> 00:10:09.170\nIt's compressing,\nit is extracting the usable bits.\n\n199\n00:10:09.170 --> 00:10:11.430\nThose are the least significant bits.\n\n200\n00:10:11.430 --> 00:10:14.600\nIt said, let me see if I can find\nthese least significant bits,\n\n201\n00:10:14.600 --> 00:10:16.080\ninside of this JPEG, right?\n\n202\n00:10:16.080 --> 00:10:18.350\nAnd it found, what is it,\n\n203\n00:10:18.350 --> 00:10:23.740\nit found 626,469 bits that it can use,\nthat we wouldn't be\n\n204\n00:10:23.740 --> 00:10:27.150\nable to perceive with the human eye that\nthose have been slightly adjusted, right?\n\n205\n00:10:27.150 --> 00:10:29.580\nIt won't pick up on the slight variations,\nbut\n\n206\n00:10:29.580 --> 00:10:32.440\nit's gonna use those bits\nto store the information.\n\n207\n00:10:32.440 --> 00:10:38.280\nAll right, let's go ahead and\nlet's see this picture of my lovely horse.\n\n208\n00:10:38.280 --> 00:10:40.889\nAll right, now, we're gonna go ahead and\nuse the first one.\n\n209\n00:10:41.920 --> 00:10:43.350\nYeah I told you he-\n&gt;&gt; [LAUGH]\n\n210\n00:10:43.350 --> 00:10:44.665\n&gt;&gt; Is kinda special,\n\n211\n00:10:44.665 --> 00:10:48.340\nand so here's the original picture, right?\n\n212\n00:10:48.340 --> 00:10:54.303\nAnd here is the second picture and\nto our natural human eye, I mean crazy.\n\n213\n00:10:54.303 --> 00:10:55.669\n&gt;&gt; I can't tell.\n&gt;&gt; Horse looks just\n\n214\n00:10:55.669 --> 00:10:59.389\nas crazy as before after the fact\nthat he did before, right?\n\n215\n00:10:59.389 --> 00:11:02.451\nBut here's the thing and\nthis is the beauty of steganography,\n\n216\n00:11:02.451 --> 00:11:05.610\nnotice that we're not,\nyou could see that it's a horse.\n\n217\n00:11:05.610 --> 00:11:07.220\nHowever, special he might be.\n\n218\n00:11:07.220 --> 00:11:10.330\nAll right, but\nI'm not encrypting the information.\n\n219\n00:11:10.330 --> 00:11:11.660\nI can see the picture.\n\n220\n00:11:11.660 --> 00:11:14.770\nWhat I can't see though is\nhiding the text in plain sight.\n\n221\n00:11:14.770 --> 00:11:17.090\nAnd that's one of the beauties\nof stenography, right?\n\n222\n00:11:17.090 --> 00:11:19.707\nSteganography, make sure I get that right.\n\n223\n00:11:19.707 --> 00:11:22.260\nAll right, so now let's see if\nwe can reverse the process.\n\n224\n00:11:22.260 --> 00:11:24.602\nLet's see if we can take the-\n&gt;&gt; Step analysis.\n\n225\n00:11:24.602 --> 00:11:25.700\n&gt;&gt; That's right, that's right.\n\n226\n00:11:25.700 --> 00:11:30.030\nLet's see if we can remove,\nif you will, that secret file.\n\n227\n00:11:30.030 --> 00:11:34.060\nSo now, what we're gonna do is,\nwe're gonna change iSteg from encode,\n\n228\n00:11:34.060 --> 00:11:34.907\nuncheck that.\n\n229\n00:11:34.907 --> 00:11:37.010\nYou can probably see\nwhat it would be decode.\n\n230\n00:11:37.010 --> 00:11:38.860\nAnd our source file's going\nto change a little bit.\n\n231\n00:11:38.860 --> 00:11:41.070\nWe're gonna go ahead and\ntake that output file.\n\n232\n00:11:41.070 --> 00:11:44.720\n&gt;&gt; All right,\nof our super special horse here.\n\n233\n00:11:44.720 --> 00:11:47.560\nAnd then we're gonna go and\nprocess it, all right.\n\n234\n00:11:47.560 --> 00:11:50.890\nAnd it's gonna ask me, well,\nwhere do you want to put this, all right?\n\n235\n00:11:50.890 --> 00:11:56.415\nSo we'll processes it, and I'll change\nthis to, let's just call this secret\n\n236\n00:11:56.415 --> 00:12:01.570\ntext.txt and\nhopefully it won't error out on me.\n\n237\n00:12:01.570 --> 00:12:04.940\nSometimes it doesn't like my names and\nit errors out.\n\n238\n00:12:04.940 --> 00:12:08.040\nIt looks like it did it and\nit did it just fine too.\n\n239\n00:12:08.040 --> 00:12:10.690\nIt also has some ECC going on.\n\n240\n00:12:10.690 --> 00:12:11.914\nSome what is that?\n\n241\n00:12:11.914 --> 00:12:12.468\n&gt;&gt; Error correcting code.\n\n242\n00:12:12.468 --> 00:12:14.640\n&gt;&gt; Error correcting code,\nthank you there, Cherokee.\n\n243\n00:12:14.640 --> 00:12:16.550\nGot my back today on that one, awesome.\n\n244\n00:12:16.550 --> 00:12:19.311\nOkay, so here's my secret text and and\n\n245\n00:12:19.311 --> 00:12:24.010\nlet's see if we can read what\nthat secret text says now.\n\n246\n00:12:24.010 --> 00:12:28.780\nAll right, now we have our\nSuper Secret Banna Bread Recipe, right?\n\n247\n00:12:28.780 --> 00:12:32.345\nNow this would probably be something that\nwould be a little bit more serious if\n\n248\n00:12:32.345 --> 00:12:34.335\nit comes to using these technologies.\n\n249\n00:12:34.335 --> 00:12:37.115\nBut you can see the fact that\nwe can take information,\n\n250\n00:12:37.115 --> 00:12:41.675\nwe can embed it into a picture, right,\nusing those least significant bits, and\n\n251\n00:12:41.675 --> 00:12:47.810\nthen turn and take something like\nsteganography, or steganalysis utility.\n\n252\n00:12:47.810 --> 00:12:50.710\nWhich they might do both, and\nwe can pull that information out, and\n\n253\n00:12:50.710 --> 00:12:52.750\nwe can see what the hidden\ntext actually is.\n\n254\n00:12:52.750 --> 00:12:59.440\nSo great little utility to have if you\nare doing security posture assessment.\n\n255\n00:12:59.440 --> 00:13:02.040\n&gt;&gt; Hence the importance, like you\nhad mentioned before for integrity,\n\n256\n00:13:02.040 --> 00:13:03.810\nwhen you were talking about hash values.\n\n257\n00:13:03.810 --> 00:13:08.700\nBecause although we can't tell the\ndifference that those pictures have been\n\n258\n00:13:08.700 --> 00:13:14.770\nmodified, if you run a particular\nhashing algorithm on that image.\n\n259\n00:13:14.770 --> 00:13:17.310\nAnd I transmit it to Wes,\nand tell him hey,\n\n260\n00:13:17.310 --> 00:13:20.940\nI used whatever hash algorithm\nthat I chose to use.\n\n261\n00:13:20.940 --> 00:13:25.543\nHe should also receive the same hash value\nto verify that original image had not been\n\n262\n00:13:25.543 --> 00:13:26.736\nmodified in any way.\n\n263\n00:13:26.736 --> 00:13:30.571\n&gt;&gt; Most definitely, and so\nthe next thing that they talk about, and\n\n264\n00:13:30.571 --> 00:13:35.760\nI don't really have a diagram for this is\nwhat are known as honey pots, all right?\n\n265\n00:13:35.760 --> 00:13:37.630\nI'm gonna go ahead and\ncall out a couple of things, right?\n\n266\n00:13:37.630 --> 00:13:40.230\nI'm gonna call out honey pot and\na honey net, all right?\n\n267\n00:13:40.230 --> 00:13:42.800\nEven though they don't call out the honey\nnet right here I'm sure we're gonna\n\n268\n00:13:42.800 --> 00:13:43.360\ntalk about it.\n\n269\n00:13:43.360 --> 00:13:45.930\nWe haven't already, we'll talk\nabout it in the future episodes,\n\n270\n00:13:45.930 --> 00:13:47.920\nbut they should really go together, right?\n\n271\n00:13:47.920 --> 00:13:49.320\nWell, what is a honey pot?\n\n272\n00:13:49.320 --> 00:13:51.420\nA honey pot is a single resource, right?\n\n273\n00:13:51.420 --> 00:13:54.961\nThat we set maybe in a DMZ and\nwe make it publicly available for\n\n274\n00:13:54.961 --> 00:13:58.095\nthe purposes of gathering information,\nall right?\n\n275\n00:13:58.095 --> 00:14:00.381\nNow what kind of information\nwe're gathering, all right?\n\n276\n00:14:00.381 --> 00:14:01.940\nWe're gathering information.\n\n277\n00:14:01.940 --> 00:14:03.620\nIt could be something non-malicious.\n\n278\n00:14:03.620 --> 00:14:05.392\nRight, a honey pot could be used for\nsomething non-malicious.\n\n279\n00:14:05.392 --> 00:14:07.440\nWe wanna see how people\nare utilizing our web server.\n\n280\n00:14:08.510 --> 00:14:09.290\nSo what do we do?\n\n281\n00:14:09.290 --> 00:14:13.210\nWe make an identical clone of our web\nserver and we put it into a location and\n\n282\n00:14:13.210 --> 00:14:15.790\nlet people access it and\nwe perform an audit on it.\n\n283\n00:14:15.790 --> 00:14:19.700\nWe say, okay well,\nmaybe we didn't take into consideration,\n\n284\n00:14:19.700 --> 00:14:22.930\nwe look at our log of events, we didn't\ntake into consideration this certain\n\n285\n00:14:22.930 --> 00:14:25.480\nfunctionality that we need to support.\n\n286\n00:14:25.480 --> 00:14:28.642\nNow we know that the main resource,\nnot the dummy resource,\n\n287\n00:14:28.642 --> 00:14:31.441\nmaybe needs to be reconfigured\na little bit, right?\n\n288\n00:14:31.441 --> 00:14:34.440\nTo maybe give a better user experience.\n\n289\n00:14:34.440 --> 00:14:37.030\nHowever, they can be done\n\n290\n00:14:37.030 --> 00:14:41.550\nto track how malicious users\nare accessing that resource.\n\n291\n00:14:41.550 --> 00:14:45.010\n&gt;&gt; For sure, and\nI know we spoke a lot in this episode,\n\n292\n00:14:45.010 --> 00:14:48.120\nin the previous episodes about words and\ncontext.\n\n293\n00:14:48.120 --> 00:14:53.540\nAnd a synonym for that honey pot there\nwould be bastion host and really\n\n294\n00:14:53.540 --> 00:14:56.890\nin this like Wes just would say, that\ndecoy is what we're talking about here.\n\n295\n00:14:56.890 --> 00:14:59.680\n&gt;&gt; Most definitely, and\nyou can gain information.\n\n296\n00:14:59.680 --> 00:15:02.650\nRight now, a decoy,\nI like the term decoy that you use.\n\n297\n00:15:02.650 --> 00:15:07.140\nIt might be that might be the whole\npurpose of your honey pot.\n\n298\n00:15:07.140 --> 00:15:11.430\nA resource that you wanna make look\nenticing so the attackers attack it and\n\n299\n00:15:11.430 --> 00:15:15.080\nthey stay away from your resources\nthat are legitimate, right.\n\n300\n00:15:15.080 --> 00:15:17.280\nOr it could be for\ngathering information, right.\n\n301\n00:15:17.280 --> 00:15:19.530\nWe wanna know,\nwhat tricks are they using, right?\n\n302\n00:15:19.530 --> 00:15:22.763\nWe had a web application server\nthat went down two months ago but\n\n303\n00:15:22.763 --> 00:15:25.272\nwe have no clue what brought it down,\nall right?\n\n304\n00:15:25.272 --> 00:15:29.813\nWell, wouldn't it be nice\nto put a live active clone,\n\n305\n00:15:29.813 --> 00:15:35.580\na replica of that original web\nserver to entice them back.\n\n306\n00:15:35.580 --> 00:15:37.380\nLet's see how you attack that server.\n\n307\n00:15:37.380 --> 00:15:38.560\nSo that we can turn around and\n\n308\n00:15:38.560 --> 00:15:43.390\nwe can harden the web application server\nthat is a legitimate resource, right.\n\n309\n00:15:43.390 --> 00:15:45.478\nBut that's a single resource,\nthat's a honey pot.\n\n310\n00:15:45.478 --> 00:15:49.610\nA honey net on the other hand is\nan entire dummy network, right?\n\n311\n00:15:49.610 --> 00:15:50.730\nNow, the complexities and\n\n312\n00:15:50.730 --> 00:15:53.510\namount of devices on that network\nare really up to the people that\n\n313\n00:15:53.510 --> 00:15:57.560\nare behind the architectural design of it,\nbut it's an entire network.\n\n314\n00:15:57.560 --> 00:16:00.338\nAll right, and\nthe entire network could be multiple.\n\n315\n00:16:00.338 --> 00:16:02.693\nWe could be gathering information\nbecause we wanna know,\n\n316\n00:16:02.693 --> 00:16:04.510\nwe've got a layered defense system.\n\n317\n00:16:04.510 --> 00:16:07.390\nIt's not just an application\nserver that we wanna check out.\n\n318\n00:16:07.390 --> 00:16:12.701\nWe wanna know is our network-based\nintrusion detection system working.\n\n319\n00:16:12.701 --> 00:16:13.803\nIs our firewall working?\n\n320\n00:16:13.803 --> 00:16:15.810\nAre ACLs working?\n\n321\n00:16:15.810 --> 00:16:17.750\nCan they get into our networks at all?\n\n322\n00:16:17.750 --> 00:16:20.960\nSo we have an entire network\nthat looks enticing.\n\n323\n00:16:20.960 --> 00:16:22.670\nLooks enticing to the bad actors, right?\n\n324\n00:16:22.670 --> 00:16:25.670\nThe threat actors that we've\ntalked about to try to lure them\n\n325\n00:16:25.670 --> 00:16:29.100\nin to attack these different vectors so\n\n326\n00:16:29.100 --> 00:16:32.220\nthat we can gain additional information,\nwe can do our research.\n\n327\n00:16:32.220 --> 00:16:35.376\nAnd then we can harden the systems\nthat are legitimate systems so\n\n328\n00:16:35.376 --> 00:16:36.844\nthat we can keep them secure.\n\n329\n00:16:36.844 --> 00:16:38.802\n&gt;&gt; And Wes,\nI'm sorry to keep interjecting here,\n\n330\n00:16:38.802 --> 00:16:40.858\nit's just when I remember\noriginally studying and\n\n331\n00:16:40.858 --> 00:16:44.208\nreading these different technologies some\nvendors use different terminology and\n\n332\n00:16:44.208 --> 00:16:47.750\nthey can become confusing, especially\nif you haven't heard them before.\n\n333\n00:16:47.750 --> 00:16:52.343\nAnd really what Wes is talking about\nhere is that perimeter, right?\n\n334\n00:16:52.343 --> 00:16:55.630\nWe're talking about when we think\nabout the logical design of a network.\n\n335\n00:16:55.630 --> 00:16:59.160\nSo sometimes you may hear the term DMZ for\ndemilitarized zone.\n\n336\n00:16:59.160 --> 00:17:01.840\nSo you can put your honey net in your DMZ.\n\n337\n00:17:01.840 --> 00:17:05.170\nOr sometimes you even hear\nthe term screened subnet.\n\n338\n00:17:05.170 --> 00:17:07.110\nSo just to give you an idea,\n\n339\n00:17:07.110 --> 00:17:09.630\ndon't get hung up on the minutiae\nof the terminology there.\n\n340\n00:17:09.630 --> 00:17:12.950\n&gt;&gt; Most definitely,\nthat term actually confused\n\n341\n00:17:12.950 --> 00:17:15.890\nthe heck out of me as I started\nas a security plus student.\n\n342\n00:17:15.890 --> 00:17:18.690\nBack when I first started\nstudying security plus was\n\n343\n00:17:18.690 --> 00:17:20.750\nwhat did they mean when they\nsaid perimeter network?\n\n344\n00:17:20.750 --> 00:17:21.781\nWhat is this difference?\n\n345\n00:17:21.781 --> 00:17:24.840\nAnd then Microsoft, like you said,\nthey like Edge Network, perimeter network.\n\n346\n00:17:24.840 --> 00:17:27.910\nThey use the screened subnet a lot, so.\n\n347\n00:17:27.910 --> 00:17:31.612\nRemember, we wanna place it in an area\nthat the attackers can get to, but\n\n348\n00:17:31.612 --> 00:17:34.908\n[LAUGH] we don't want them going\nback into our internal network.\n\n349\n00:17:34.908 --> 00:17:38.747\nCuz there's no real reason to have a honey\nnet if they can actually attack the true\n\n350\n00:17:38.747 --> 00:17:39.260\nnetwork.\n\n351\n00:17:39.260 --> 00:17:44.380\nSo those are some things that we\ndefinitely have to look at now,\n\n352\n00:17:44.380 --> 00:17:47.850\nCherokee, I know that I've\ngot a lot more to talk about.\n\n353\n00:17:47.850 --> 00:17:49.640\nBut I'm looking at the episode,\nI'm looking at the time.\n\n354\n00:17:49.640 --> 00:17:53.020\nAnd it does look like I think we\nmight have to wrap this one up.\n\n355\n00:17:53.020 --> 00:17:54.160\n&gt;&gt; Sounds great, Wes.\n\n356\n00:17:54.160 --> 00:17:56.390\nIt's okay, we'll shoot for\nanother part four here.\n\n357\n00:17:56.390 --> 00:17:57.890\nSo, ladies and gentlemen, stay tuned.\n\n358\n00:17:57.890 --> 00:17:59.660\nWe do have more information\nheaded your way.\n\n359\n00:17:59.660 --> 00:18:01.930\nFor this episode,\nwe'll go ahead and sign out.\n\n360\n00:18:01.930 --> 00:18:03.610\nRemember, I'm your host, Cherokee Boose.\n\n361\n00:18:03.610 --> 00:18:04.377\n&gt;&gt; And I'm Wes Bryan.\n\n362\n00:18:04.377 --> 00:18:06.288\n&gt;&gt; See you next time here at ITPRO.TV.\n\n363\n00:18:07.791 --> 00:18:13.764\n[MUSIC]\n\n364\n00:18:13.764 --> 00:18:16.866\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "213513750"
        },
        {
          "description": "In this episode, Cherokee and Wes round off a discussion centered around software-based solutions that assist organization adhere to their security posture. Specifically, they begin looking at different backup options. With the advent of cloud-based solutions we see an expansion of redundancy options which Wes covers. Lastly, they look at command line utilities to assist in both Windows and Nix-based systems.",
          "length": "2127",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-4-security_posture_assessment_pt4-041217-PGM.00_00_11_22.Still002.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-4-security_posture_assessment_pt4-041217-PGM.00_00_11_22.Still002-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-2-4-security_posture_assessment_pt4-041217-PGM.00_00_11_22.Still002-sm.jpg",
          "title": "Security Posture Assessment Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.200 --> 00:00:01.435\nWelcome to ITProTV.\n\n2\n00:00:01.435 --> 00:00:02.591\nI'm your host Don Pezet.\n\n3\n00:00:02.591 --> 00:00:06.651\n&gt;&gt; [CROSSTALK]\n\n4\n00:00:06.651 --> 00:00:08.389\n[MUSIC]\n\n5\n00:00:08.389 --> 00:00:12.153\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.153 --> 00:00:14.731\n&gt;&gt; Welcome to your\nCompTIA Security+ Series.\n\n7\n00:00:14.731 --> 00:00:16.840\nI'm your show host, Cherokee Boose.\n\n8\n00:00:16.840 --> 00:00:21.159\nThis is actually a part four continuation\nof a discussion that we were having\n\n9\n00:00:21.159 --> 00:00:25.139\npreviously where we were looking at\ndifferent types of software based\n\n10\n00:00:25.139 --> 00:00:29.727\nutilities that could help us remain\ncompliant with their organization security\n\n11\n00:00:29.727 --> 00:00:30.351\nposture.\n\n12\n00:00:30.351 --> 00:00:33.779\nWith us today we have Mr. Wes Bryan in\nstudios, thank you for joining us Wes.\n\n13\n00:00:33.779 --> 00:00:35.137\n&gt;&gt; And thanks for having me back Cherokee.\n\n14\n00:00:35.137 --> 00:00:37.181\nYep, that's right, a part four,\n\n15\n00:00:37.181 --> 00:00:41.203\nI believe we will finish everything\n[LAUGH] up in this part four as we work\n\n16\n00:00:41.203 --> 00:00:45.719\nthrough our Steven King novel here on\nthe [LAUGH] security posture assessment.\n\n17\n00:00:45.719 --> 00:00:49.023\nYeah, there are a few extra things\nthat we have to take care of, and\n\n18\n00:00:49.023 --> 00:00:51.507\nwe're gonna take care of\nthings like back-ups.\n\n19\n00:00:51.507 --> 00:00:54.816\nWe're gonna talk a little bit\nabout some command line tools and\n\n20\n00:00:54.816 --> 00:00:57.576\na couple of other topics\nthat we have to get through.\n\n21\n00:00:57.576 --> 00:01:02.488\nThe first thing that we're gonna talk\nabout are, well, back-up utilities, and\n\n22\n00:01:02.488 --> 00:01:06.208\nback-up utilities today,\nwhen it comes to a backup utility,\n\n23\n00:01:06.208 --> 00:01:08.266\nkeep in mind why we use back-ups.\n\n24\n00:01:08.266 --> 00:01:13.377\nBack-ups are a part of normal system\nmaintenance, at least they should be.\n\n25\n00:01:13.377 --> 00:01:16.544\nRemember when we have disasters,\nwe need to recover from those disasters.\n\n26\n00:01:16.544 --> 00:01:19.260\nIf we don't have back-ups,\nthen well guess what,\n\n27\n00:01:19.260 --> 00:01:22.670\nyour disaster recovery process\nmight not be a recovery process.\n\n28\n00:01:22.670 --> 00:01:24.700\nIt might be, what do they call it,\n\n29\n00:01:24.700 --> 00:01:27.715\na business ending event on\nthat one there for sure.\n\n30\n00:01:27.715 --> 00:01:30.540\nSo, we have to be aware of some of\nthe offerings that we have out there.\n\n31\n00:01:30.540 --> 00:01:31.700\nSome of the solutions and\n\n32\n00:01:31.700 --> 00:01:36.206\nI've really kind of broken these down\ninto a couple of different types.\n\n33\n00:01:36.206 --> 00:01:40.822\nBecause of cloud-based technologies today,\nthe way we think of where we\n\n34\n00:01:40.822 --> 00:01:44.775\nback-up our data today,\nhas changed over the past few years.\n\n35\n00:01:44.775 --> 00:01:48.603\nSome of the traditional on-premise type\nbackup software that you have, well,\n\n36\n00:01:48.603 --> 00:01:51.248\nwe have inside of Windows-based\nmachines if you will,\n\n37\n00:01:51.248 --> 00:01:53.858\nwe have things like\nWindows Server Back-up, right?\n\n38\n00:01:53.858 --> 00:01:57.936\nWe have other utilities for the clients\ntoday for things like file history,\n\n39\n00:01:57.936 --> 00:02:00.101\nif you will, things like OneDrive, but\n\n40\n00:02:00.101 --> 00:02:03.942\nwe also have other enterprise level\nsoftware that's out there, too.\n\n41\n00:02:03.942 --> 00:02:08.552\nSometimes you have these utilities\ninside of the operating system already.\n\n42\n00:02:08.552 --> 00:02:11.848\nSometimes they're features that are there\nthat you just kind of have to, like,\n\n43\n00:02:11.848 --> 00:02:14.609\nthe light switch is already there,\nyou just have to make use of it and\n\n44\n00:02:14.609 --> 00:02:17.286\nturn it on, right, so, for\ninstance, Windows Server Backup.\n\n45\n00:02:17.286 --> 00:02:20.590\nIt is something that's in\nthe server operating system, but\n\n46\n00:02:20.590 --> 00:02:24.022\nit's not turned on by default and\nI credit Microsoft on that and\n\n47\n00:02:24.022 --> 00:02:28.103\nthe fact that they wanna keep their\nserver footprint as small as possible,\n\n48\n00:02:28.103 --> 00:02:32.290\nbecause they know that there are a lot\nof good back-up utilities out there.\n\n49\n00:02:32.290 --> 00:02:36.022\nFor instance like, Barracuda,\nAcronis is one of them,\n\n50\n00:02:36.022 --> 00:02:39.855\nSymantec is out there, like for\ninstance, Backup Exec.\n\n51\n00:02:39.855 --> 00:02:40.924\nWhat else?\n\n52\n00:02:40.924 --> 00:02:43.510\nWe have things like for instance,\ninside of Linux as well,\n\n53\n00:02:43.510 --> 00:02:45.383\ntoo, where you have things like Our Sake.\n\n54\n00:02:45.383 --> 00:02:48.936\nIn fact, let me kinda show you here\nwhat I mean when I say, for instance,\n\n55\n00:02:48.936 --> 00:02:50.352\nour Windows Server Backup.\n\n56\n00:02:50.352 --> 00:02:52.581\nLet me go ahead and\nshow you how to log into a server.\n\n57\n00:02:52.581 --> 00:02:54.708\nSorry I didn't do [LAUGH]\nthat ahead of time.\n\n58\n00:02:54.708 --> 00:02:59.688\nBut if I open up Server Manager, right,\nwe can see that if I go to Tools,\n\n59\n00:02:59.688 --> 00:03:02.676\nand I scroll all the way\ndown to the bottom,\n\n60\n00:03:02.676 --> 00:03:07.081\nI know my head's probably gonna\nkind of cover this one up here.\n\n61\n00:03:07.081 --> 00:03:07.860\nLet me try that again.\n\n62\n00:03:07.860 --> 00:03:09.846\nScroll all the way down to the bottom,\n\n63\n00:03:09.846 --> 00:03:12.462\nyou'll notice that there\nis this Server Backup.\n\n64\n00:03:12.462 --> 00:03:17.090\nNow keep in mind, if you haven't installed\nthe feature prior to running this,\n\n65\n00:03:17.090 --> 00:03:19.453\nthen you're not gonna get this screen.\n\n66\n00:03:19.453 --> 00:03:21.397\nYou'll get a little bit of\na different screen here.\n\n67\n00:03:21.397 --> 00:03:23.798\nIt'll say that this feature\nisn't currently installed, and\n\n68\n00:03:23.798 --> 00:03:24.891\nyou can always turn that on.\n\n69\n00:03:24.891 --> 00:03:26.463\nI'll go ahead and\nminimize this for a second.\n\n70\n00:03:26.463 --> 00:03:29.662\nWe can always go back to our\nserver manager if we want, and\n\n71\n00:03:29.662 --> 00:03:34.129\nwe'd choose the Add Roles and Features\nwizard, and then from here, we can just\n\n72\n00:03:34.129 --> 00:03:39.130\nkinda walk through the installation, role\nbased or feature based installation, which\n\n73\n00:03:39.130 --> 00:03:44.020\nserver it is that we're gonna install this\non, and then, what is the role or feature.\n\n74\n00:03:44.020 --> 00:03:48.220\nIn this case, the Windows Server Backup,\nit isn't a role, you're gonna kinda go\n\n75\n00:03:48.220 --> 00:03:52.420\nright pass the roles and you're gonna go\ninto feature, and if we scroll pretty much\n\n76\n00:03:52.420 --> 00:03:56.440\nall the way down to the bottom you could\nsee I've pretty much all ready taken care\n\n77\n00:03:56.440 --> 00:04:00.420\nof this so that you guys didn't have to\nsee just the installation of a feature.\n\n78\n00:04:00.420 --> 00:04:05.432\nWe've seen in some past episodes where we\ncan enable things like TelNet if you will,\n\n79\n00:04:05.432 --> 00:04:10.173\nif you're using it for testing purposes\nand stuff on the machine if necessary.\n\n80\n00:04:10.173 --> 00:04:14.250\nBut, again, keep in mind that,\nby default, it isn't installed.\n\n81\n00:04:14.250 --> 00:04:16.985\nI'll go ahead and\ncancel this wizard out, and\n\n82\n00:04:16.985 --> 00:04:19.662\nwe'll get back to our\nWindow Server Backup.\n\n83\n00:04:19.662 --> 00:04:22.370\nNow, what you back-up is really up to you,\nand\n\n84\n00:04:22.370 --> 00:04:27.045\nwhere the location of the back-up is,\nis up to what you have available to you.\n\n85\n00:04:27.045 --> 00:04:31.205\nYou can do things like for instance,\none of the things like a Backup Schedule.\n\n86\n00:04:31.205 --> 00:04:34.885\nWe can do a Backup Once where we're just\ngonna backup information right now, and\n\n87\n00:04:34.885 --> 00:04:39.030\nwe can also do the Recovery process, and\nthat's something important to remember.\n\n88\n00:04:39.030 --> 00:04:43.110\nWhen we talk about back-up utilities is\nthe recovery process is just as important\n\n89\n00:04:43.110 --> 00:04:46.910\nas the back-up process, but I will tell\nyou, if you do run your back-ups, like for\n\n90\n00:04:46.910 --> 00:04:52.370\ninstance, running the run once here as\nwe walk through the wizard to back-up\n\n91\n00:04:52.370 --> 00:04:56.180\ndifferent things, you're gonna wanna\nbe sure that you test these back-ups.\n\n92\n00:04:56.180 --> 00:04:59.494\nDon't wait until you need\nyour back-ups to find out if\n\n93\n00:04:59.494 --> 00:05:02.522\nthe back-up job has finished successfully,\nand\n\n94\n00:05:02.522 --> 00:05:07.439\nwhat I mean is not that the software tells\nyou that it's finished successfully.\n\n95\n00:05:07.439 --> 00:05:11.439\nWhat I mean is you kinda stage a recovery\nbefore you actually need this and\n\n96\n00:05:11.439 --> 00:05:13.945\nkinda restore it maybe\nto a virtual machine.\n\n97\n00:05:13.945 --> 00:05:14.768\n&gt;&gt; Proper testing.\n\n98\n00:05:14.768 --> 00:05:17.655\n&gt;&gt; That's right, and\nmaking sure, great words there,\n\n99\n00:05:17.655 --> 00:05:21.440\nthat you test whether the back-ups\nhave maintained their integrity.\n\n100\n00:05:21.440 --> 00:05:24.370\nLike I said, you don't wanna wait until\nyou need a back-up to find out if\n\n101\n00:05:24.370 --> 00:05:27.170\nthe back-ups are actually gonna work for\nyou.\n\n102\n00:05:27.170 --> 00:05:28.688\n&gt;&gt; And that's something that,\n\n103\n00:05:28.688 --> 00:05:32.881\nI mean people understand things happen\nwithin our networks and our environment,\n\n104\n00:05:32.881 --> 00:05:36.949\nbut you talked about a business ending\nevent, it may also be a job ending event,\n\n105\n00:05:36.949 --> 00:05:40.923\nbecause that's totally preventable,\nso it's really you can excuse that.\n\n106\n00:05:40.923 --> 00:05:41.423\n&gt;&gt; It is.\n\n107\n00:05:41.423 --> 00:05:44.676\nIt's one of those things that if you\ndidn't test it, make sure you do have\n\n108\n00:05:44.676 --> 00:05:47.984\na printer working in your networks,\nbecause when everything else fails,\n\n109\n00:05:47.984 --> 00:05:51.183\nas long as you got one printer to print\nyour resume on the way out the door,\n\n110\n00:05:51.183 --> 00:05:51.990\nyou'll be okay.\n\n111\n00:05:51.990 --> 00:05:53.399\nNo, just kidding, don't do it that way.\n\n112\n00:05:53.399 --> 00:05:56.229\nMake sure [LAUGH] that\nyou test before hand, and\n\n113\n00:05:56.229 --> 00:06:00.874\nkeep in mind that maybe if it's the first\ntime you back up your server you're\n\n114\n00:06:00.874 --> 00:06:03.870\nprobably gonna wanna do\na full server back-up.\n\n115\n00:06:03.870 --> 00:06:08.087\nAfter that it depends on how fast\nyou want the back-up to happen and\n\n116\n00:06:08.087 --> 00:06:09.830\nhow you wanna optimize it.\n\n117\n00:06:09.830 --> 00:06:14.359\nSo for instance, let's see here,\nyou can do things like configuring\n\n118\n00:06:14.359 --> 00:06:19.197\nperformance settings, and this is\nimportant when it comes to back-ups,\n\n119\n00:06:19.197 --> 00:06:23.453\nhow long do you have that your data\nis gonna stay in a static state?\n\n120\n00:06:23.453 --> 00:06:28.299\nSit at rest, if you're doing e-commerce\nchances are your data is never gonna be in\n\n121\n00:06:28.299 --> 00:06:30.375\nsome kind of data at rest position,\n\n122\n00:06:30.375 --> 00:06:33.165\nbecause e-commerce can\ngo on 24 hours a day.\n\n123\n00:06:33.165 --> 00:06:36.278\nSo it depends on how you wanna\noptimize the back up right, so\n\n124\n00:06:36.278 --> 00:06:37.870\nyou can do faster back-ups.\n\n125\n00:06:37.870 --> 00:06:41.486\nIf you don't have a lot of downtime\nthat you can afford waiting for\n\n126\n00:06:41.486 --> 00:06:45.036\nthis back-up job to complete,\nyou can do a faster back-up, or\n\n127\n00:06:45.036 --> 00:06:47.635\nyou can just do a normalized\nback-up as well.\n\n128\n00:06:47.635 --> 00:06:49.625\nYou can also do customized back-ups too.\n\n129\n00:06:49.625 --> 00:06:53.670\nSo, you also have to keep in mind how\nlong it's gonna take to back-up, and\n\n130\n00:06:53.670 --> 00:06:58.229\nthen on top of it, when we get to recovery\nprocess, how much information are we gonna\n\n131\n00:06:58.229 --> 00:07:02.600\nneed to perform the recovery,\nback-up sets, and that what have you.\n\n132\n00:07:02.600 --> 00:07:07.780\nBut we'll go ahead, and we'll just\nkinda start this back-up process again,\n\n133\n00:07:07.780 --> 00:07:11.020\nand choose next, and\nI could do a full back-up, but\n\n134\n00:07:11.020 --> 00:07:14.110\n12 gigs, we don't really have that\nmuch time here in this episode, so\n\n135\n00:07:14.110 --> 00:07:16.810\nwhat I'm gonna do is I'm gonna\ndo a customized back-up.\n\n136\n00:07:16.810 --> 00:07:20.182\nI'll do Next, and\nthen I'm gonna add some items here, and\n\n137\n00:07:20.182 --> 00:07:24.379\nit tells me what I can add, and, for\nme, I'm just gonna do system state.\n\n138\n00:07:24.379 --> 00:07:26.940\nKeep in mind it's just the current\nconfigurations of this server.\n\n139\n00:07:26.940 --> 00:07:31.274\nWe'll go ahead and back that up, cuz\ntypically when you do a back-up like that,\n\n140\n00:07:31.274 --> 00:07:34.143\njust system state,\nit shouldn't take too long, and\n\n141\n00:07:34.143 --> 00:07:37.552\nit'll show you where the process goes,\nor how the process is.\n\n142\n00:07:37.552 --> 00:07:40.397\nWell, it looks like we don't\nhave a good file system on here.\n\n143\n00:07:40.397 --> 00:07:43.050\nI'll tell you what,\nlet me go ahead and do something here.\n\n144\n00:07:43.050 --> 00:07:46.570\nNotice that the back-up,\nit doesn't want FAT32,\n\n145\n00:07:46.570 --> 00:07:51.140\nit needs to be NTFS, but that's something\nthat we can change here real quick.\n\n146\n00:07:51.140 --> 00:07:55.195\n&gt;&gt; Now Wes, earlier we were talking\nabout our key management, and\n\n147\n00:07:55.195 --> 00:07:57.309\nyou mentioned the N of N concept.\n\n148\n00:07:57.309 --> 00:08:00.548\nWhen it comes to back-ups of\nthat restoration process,\n\n149\n00:08:00.548 --> 00:08:04.731\nis that something that we may see within\nour networks or our organizations\n\n150\n00:08:04.731 --> 00:08:08.657\nwhere they want at least two people or\nkind of a separation of duties?\n\n151\n00:08:08.657 --> 00:08:12.579\nSo, That the IT department\nisn't really blamed for\n\n152\n00:08:12.579 --> 00:08:16.961\nany kind of coverup or\nmodification of that information.\n\n153\n00:08:16.961 --> 00:08:20.906\nThat's being brought back in in\nthe situation of a restoration.\n\n154\n00:08:20.906 --> 00:08:25.433\n&gt;&gt; Most definitely, most definitely,\njob separation is key.\n\n155\n00:08:25.433 --> 00:08:27.113\nYou don't want, necessarily,\n\n156\n00:08:27.113 --> 00:08:30.120\nthe person that has access to\nyour information backing up.\n\n157\n00:08:30.120 --> 00:08:34.181\nThe same person that backs up your\ninformation doing the recovery, right, and\n\n158\n00:08:34.181 --> 00:08:34.857\nwhy is that?\n\n159\n00:08:34.857 --> 00:08:36.395\nWell, I want you to think about it.\n\n160\n00:08:36.395 --> 00:08:40.072\nIf you are the backup operator and\nyou do the backup of that data, right,\n\n161\n00:08:40.072 --> 00:08:41.352\nwhat are you backing up?\n\n162\n00:08:41.352 --> 00:08:44.535\nYou're backing up the very crucial\ninformation the company needs to survive.\n\n163\n00:08:44.535 --> 00:08:45.899\nSo I want you to think about that.\n\n164\n00:08:45.899 --> 00:08:48.875\nIf you also have the privileges\nto do the recovery, well,\n\n165\n00:08:48.875 --> 00:08:50.529\nI could just take your backups.\n\n166\n00:08:50.529 --> 00:08:52.472\nAnd if I have both of those job roles,\nright,\n\n167\n00:08:52.472 --> 00:08:55.603\nthat are assigned to me I now have\naccess to your sensitive information.\n\n168\n00:08:55.603 --> 00:08:59.193\nSo, just like you've mentioned,\nthere might be a role separation of that.\n\n169\n00:08:59.193 --> 00:09:02.229\nTo make sure that not one person holds,\nif you will,\n\n170\n00:09:02.229 --> 00:09:05.197\nall the keys to the different\ngates of the company.\n\n171\n00:09:05.197 --> 00:09:06.316\n&gt;&gt; All the power [LAUGH].\n\n172\n00:09:06.316 --> 00:09:08.814\n&gt;&gt; That's right, all right,\nso let's go ahead.\n\n173\n00:09:08.814 --> 00:09:14.881\nAnd I went ahead and I changed, again,\nthe external drive count B FAT32.\n\n174\n00:09:14.881 --> 00:09:18.245\nAnd I actually had it leftover from\nshowing some compliance issues,\n\n175\n00:09:18.245 --> 00:09:22.084\nsecurity issues, that we would have\nwith FAT32 and I never changed it back.\n\n176\n00:09:22.084 --> 00:09:24.612\nSo, hopefully,\nthis changes it up a little bit.\n\n177\n00:09:24.612 --> 00:09:29.043\nWe'll go ahead and do Next here and\nwe'll do the System state backup.\n\n178\n00:09:29.043 --> 00:09:30.737\nWe'll go ahead and run that.\n\n179\n00:09:30.737 --> 00:09:36.798\nAnd we'll choose OK, choose Next,\nNext one more time, and there we go.\n\n180\n00:09:36.798 --> 00:09:41.316\nI can use the Local Disk now\nthat it is configured to NTFS,\n\n181\n00:09:41.316 --> 00:09:45.846\nthat's what it's looking for,\nand we'll do a backup.\n\n182\n00:09:45.846 --> 00:09:48.245\nAnd we'll go ahead and\nwe'll let this run a backup.\n\n183\n00:09:48.245 --> 00:09:50.240\nLet me go ahead and\nwhat I'd like to do is,\n\n184\n00:09:50.240 --> 00:09:53.505\nlet me jump down to a terminal here and\nI'll show you in our Cent box.\n\n185\n00:09:53.505 --> 00:09:57.270\nLet me go ahead and\nget into my Cent Operating System here.\n\n186\n00:09:57.270 --> 00:10:03.087\nI'll go ahead and just do a quick ssh\nhere into it and we will dive into rsync.\n\n187\n00:10:03.087 --> 00:10:06.143\n&gt;&gt; So, Wes, I'm a little more\nversed with Microsoft products and\n\n188\n00:10:06.143 --> 00:10:09.720\ntheir backup solutions, what is it that\nLinux and rsync do provide for us?\n\n189\n00:10:09.720 --> 00:10:12.709\nWell, rsync is not really for\nthe faint of heart, for\n\n190\n00:10:12.709 --> 00:10:16.979\nsure, I would prefer to be in the Windows\nbackup because we got the nice GUI.\n\n191\n00:10:16.979 --> 00:10:20.562\nBut if you need to do things\nlike complex syncing options.\n\n192\n00:10:20.562 --> 00:10:24.549\nIf you need to perform things like\nunattended backups where you want it\n\n193\n00:10:24.549 --> 00:10:26.720\nmore automated rsync is the way to go.\n\n194\n00:10:26.720 --> 00:10:30.078\nKeep in mind there are other solutions\nthat are GUI driven, if you will.\n\n195\n00:10:30.078 --> 00:10:33.588\nIf you have things like Ubuntu, and\nstuff, you can use things like Dropbox,\n\n196\n00:10:33.588 --> 00:10:36.023\nif you will, so\nthere are other solutions out there.\n\n197\n00:10:36.023 --> 00:10:38.480\nBut let me go ahead and show you,\n\n198\n00:10:38.480 --> 00:10:42.485\nlet me get logged into my\nCentOS box here real quick.\n\n199\n00:10:42.485 --> 00:10:46.195\nAnd we'll show you just some\nof the options here for\n\n200\n00:10:46.195 --> 00:10:52.078\nrsync while our system state data's being\nbacked up on the Windows Server here.\n\n201\n00:10:52.078 --> 00:10:55.440\nSo go ahead and\nget logged in, oops, clear.\n\n202\n00:10:55.440 --> 00:11:00.375\nAnd then if we run just, for instance,\nrsync and you run your- -help you\n\n203\n00:11:00.375 --> 00:11:04.845\ncan see some of the various options\nthat are in here that you can do.\n\n204\n00:11:04.845 --> 00:11:08.399\nAnd, again, you can see you can\ndo things like one-file-system,\n\n205\n00:11:08.399 --> 00:11:12.392\nyou can do the whole-file, a lot of\ndifferent options in here, if you will.\n\n206\n00:11:12.392 --> 00:11:17.852\nBut, like I said, if it's not available\nin your Linux distro that you're using,\n\n207\n00:11:17.852 --> 00:11:22.454\nfor instance, I believe it's\nthe Fedora brands, they like the Yum,\n\n208\n00:11:22.454 --> 00:11:24.254\nyou could do a Yum install.\n\n209\n00:11:24.254 --> 00:11:30.774\nAnd you can just do rsync here and\nit's already installed so,\n\n210\n00:11:30.774 --> 00:11:35.558\nand it'll reach out to\nthe repositories there.\n\n211\n00:11:35.558 --> 00:11:39.167\nGotta sudo that and it'll try to\ndownload it, it's gonna tell us hey,\n\n212\n00:11:39.167 --> 00:11:42.192\nyou already got it installed and\nit's the latest version.\n\n213\n00:11:42.192 --> 00:11:47.100\nSo if it isn't installed on your Linux\nmachine keep in mind you can always just\n\n214\n00:11:47.100 --> 00:11:50.510\ndo a Yum update or an app-get and\nyou can update that.\n\n215\n00:11:50.510 --> 00:11:52.868\nSo that's a little bit about the rsync,\nagain,\n\n216\n00:11:52.868 --> 00:11:55.293\nkeep in mind there are other\nsolutions out there.\n\n217\n00:11:55.293 --> 00:11:57.920\nBut if you're a Nix based systems\nyou can definitely use that.\n\n218\n00:11:57.920 --> 00:12:01.773\nLet's go ahead and let's see how\nour Windows Server backup has done,\n\n219\n00:12:01.773 --> 00:12:05.835\nfigure out which machine we're on here,\nit looks like it canceled.\n\n220\n00:12:05.835 --> 00:12:11.522\nI don't know why it canceled, let's get\nthat started again and then we'll move on.\n\n221\n00:12:11.522 --> 00:12:14.546\nAll right, one more time we're\njust gonna try to rerun this,\n\n222\n00:12:14.546 --> 00:12:17.524\nmaybe, I got a little click happy\nhere when I was doing this.\n\n223\n00:12:19.895 --> 00:12:25.286\nWe'll go ahead and choose the Local Drive,\nagain, and we will Backup.\n\n224\n00:12:25.286 --> 00:12:27.369\nMaybe I didn't hit Backup,\nmaybe I hit Cancel.\n\n225\n00:12:27.369 --> 00:12:29.942\nAll right, so some of the other\nthings that I wanna talk about.\n\n226\n00:12:29.942 --> 00:12:33.087\nWe've mentioned a little bit about\nthe on-premise type backups, right,\n\n227\n00:12:33.087 --> 00:12:34.865\nthey're gonna back your data up locally.\n\n228\n00:12:34.865 --> 00:12:38.576\nI do wanna mention some of the cloud based\nsolutions that are out there too, like for\n\n229\n00:12:38.576 --> 00:12:41.347\ninstance, Carbonite is one\nthat's been around for a while.\n\n230\n00:12:41.347 --> 00:12:44.509\nAnd, again, keep in mind that this\nisn't gonna be on premise, it could be\n\n231\n00:12:44.509 --> 00:12:47.394\na combination of both depending on how,\nwhat their SLA is with you.\n\n232\n00:12:47.394 --> 00:12:50.980\nBut this is taking that information and\nit's placing it in somebody else's\n\n233\n00:12:50.980 --> 00:12:55.029\nnetwork and then you get things like high\navailability, access to your data as well.\n\n234\n00:12:55.029 --> 00:12:57.319\nThis is the Carbonite for\nhome here though.\n\n235\n00:12:57.319 --> 00:13:01.958\nBut if you go up to For Office you'll\nsee it'll pretty much change the whole\n\n236\n00:13:01.958 --> 00:13:04.546\nlayout there and another color, right.\n\n237\n00:13:04.546 --> 00:13:07.922\nThen you can see this\nis the backup business.\n\n238\n00:13:07.922 --> 00:13:12.062\nAnd, again, keep in mind the difference\nbetween the home implementations and\n\n239\n00:13:12.062 --> 00:13:15.956\nthe business implementations usually\nare lots of money [LAUGH] when it comes\n\n240\n00:13:15.956 --> 00:13:16.598\ndown to it.\n\n241\n00:13:16.598 --> 00:13:21.317\nThere are other options in here too,\nfor instance you have Amazon's S3.\n\n242\n00:13:21.317 --> 00:13:24.559\nAnd they even mention that you\ncan use as a primary storage for\n\n243\n00:13:24.559 --> 00:13:28.195\ncloud native applications, but\nyou can go even farther than that.\n\n244\n00:13:28.195 --> 00:13:30.959\nAnd the one I really like here is\nyou can use it as a target for\n\n245\n00:13:30.959 --> 00:13:32.046\nbackup and recovery.\n\n246\n00:13:32.046 --> 00:13:36.281\nAnd that's something that's,\nagain, it's subscription based so\n\n247\n00:13:36.281 --> 00:13:40.385\nyou are gonna pay a fee for the storage\nas well so do keep that in mind.\n\n248\n00:13:40.385 --> 00:13:44.443\nOther solutions that we have\nout here we have, for instance,\n\n249\n00:13:44.443 --> 00:13:47.808\nMicrosoft's cloud-based\nsolution Azure here.\n\n250\n00:13:47.808 --> 00:13:49.388\nOne offs, if you will,\n\n251\n00:13:49.388 --> 00:13:54.223\nif you don't wanna go through\nthe whole entire cloud-based platform.\n\n252\n00:13:54.223 --> 00:13:57.485\nYou can use things like OneDrive for\nBusiness is out there as well,\n\n253\n00:13:57.485 --> 00:13:59.882\nyou also have things like Dropbox for\nBusiness.\n\n254\n00:13:59.882 --> 00:14:03.331\nSo we do have a lot of options when\nit comes to cloud-based solutions.\n\n255\n00:14:03.331 --> 00:14:07.814\nKeep in mind that you just have to\nknow your data, do you need compliance\n\n256\n00:14:07.814 --> 00:14:13.292\nrequirements, right, and pay attention to\nwhether these will support those or not.\n\n257\n00:14:13.292 --> 00:14:17.560\nI know that things like Amazon and\nAzure are fully compliant with a lot\n\n258\n00:14:17.560 --> 00:14:21.399\nof the major data retention\nstandards that we have out there.\n\n259\n00:14:21.399 --> 00:14:26.232\nBut do your research because don't just\nassume, like we've mentioned before.\n\n260\n00:14:26.232 --> 00:14:28.172\nMake sure that it does\nhave the compliance and\n\n261\n00:14:28.172 --> 00:14:30.637\nit also gives the offering\nthat's your business needs.\n\n262\n00:14:30.637 --> 00:14:34.882\n&gt;&gt; Good point, Wes, because a lot of\norganizations might have extremely\n\n263\n00:14:34.882 --> 00:14:39.992\nsensitive information that they really\njust can't trust to a third-party entity.\n\n264\n00:14:39.992 --> 00:14:43.577\nBut some organizations are really\nlooking more for that,\n\n265\n00:14:43.577 --> 00:14:46.878\nhey, I've got my plan B and\nthen, maybe, my plan C.\n\n266\n00:14:46.878 --> 00:14:49.599\nAnd things go really out\nin left field there so\n\n267\n00:14:49.599 --> 00:14:52.400\nit just really depends\non your organization.\n\n268\n00:14:52.400 --> 00:14:56.037\n&gt;&gt; All right, let's go ahead,\nwe'll jump back to our Windows machine.\n\n269\n00:14:56.037 --> 00:14:57.887\nAnd I did have a couple of failures and\n\n270\n00:14:57.887 --> 00:15:00.465\ngotta pay attention\nsometimes to these failures.\n\n271\n00:15:00.465 --> 00:15:04.089\nI'll go ahead and kinda show you,\nI've decided to leave these in here.\n\n272\n00:15:04.089 --> 00:15:06.693\nActually that one's successful,\nthat's not the one I want.\n\n273\n00:15:08.114 --> 00:15:12.175\nLet's see, okay, so kinda wanted to\nshow you guys what was going on here and\n\n274\n00:15:12.175 --> 00:15:14.662\nit's a good thing to see and\nleave in the show.\n\n275\n00:15:14.662 --> 00:15:19.157\nAs you do, not everything in IT\nalways completes successfully,\n\n276\n00:15:19.157 --> 00:15:21.455\nincluding things like backups.\n\n277\n00:15:21.455 --> 00:15:23.498\n[LAUGH] So that's why we say, test them.\n\n278\n00:15:23.498 --> 00:15:26.980\nBut you can see that it says that\nthe volume was too small to accommodate\n\n279\n00:15:26.980 --> 00:15:28.817\nthe restore point and the metadata.\n\n280\n00:15:28.817 --> 00:15:35.080\nAs the VSS, Volume Shadow Copy Service,\nwas trying to do a partial backup there.\n\n281\n00:15:35.080 --> 00:15:39.184\nBut I do have one here that we did have\nthat is a successful backup here so\n\n282\n00:15:39.184 --> 00:15:43.310\nyou can see not a lot of information\non there so we can kinda speed it up.\n\n283\n00:15:43.310 --> 00:15:47.580\nKeep in mind, however, these backup jobs\nthat you perform could take a long time,\n\n284\n00:15:47.580 --> 00:15:51.486\nright, especially if you're talking\nabout backing up terabytes of data.\n\n285\n00:15:51.486 --> 00:15:54.140\nIt is important to remember that and\n\n286\n00:15:54.140 --> 00:15:58.835\nwhen you fire off these backup\njobs that It could be overnight.\n\n287\n00:15:58.835 --> 00:16:01.204\n&gt;&gt; Okay, so what's next, banner grabbing?\n\n288\n00:16:01.204 --> 00:16:04.302\n&gt;&gt; Yeah, that's gonna be the next\none we need to talk about.\n\n289\n00:16:04.302 --> 00:16:06.670\nAnd if we look at what banner grabbing is,\n\n290\n00:16:06.670 --> 00:16:10.609\nthis is about gleaning information\nfrom a service or off of a server.\n\n291\n00:16:10.609 --> 00:16:12.876\nWhen you do things like\nOS finger printing,\n\n292\n00:16:12.876 --> 00:16:15.511\nwith Nmap,\nNmap does different banner grabbing to\n\n293\n00:16:15.511 --> 00:16:19.700\ntry to find out what kind of information\nit can to do operating system discovery.\n\n294\n00:16:19.700 --> 00:16:24.056\nBut we can actually use things like\nTelnet for instance, you might well,\n\n295\n00:16:24.056 --> 00:16:27.509\nwait a second Wes,\nTelnet's unencrypted remote log on.\n\n296\n00:16:27.509 --> 00:16:30.976\nWell, Telnet and\nactually helps us do a lot of things.\n\n297\n00:16:30.976 --> 00:16:34.872\nAnd one of the things that we can do is,\nwe can test whether ports are open.\n\n298\n00:16:34.872 --> 00:16:38.874\nBut even more so that they do have banner\ngrabbing software that allows you to glean\n\n299\n00:16:38.874 --> 00:16:39.860\na lot information.\n\n300\n00:16:39.860 --> 00:16:43.619\nBut Telnet client inside of Windows\ncan also glean some information to.\n\n301\n00:16:43.619 --> 00:16:46.055\nSo that we can kinda find out\nwhat's going on in the server,\n\n302\n00:16:46.055 --> 00:16:48.543\neven though we're not directly\nlogged into that server, or\n\n303\n00:16:48.543 --> 00:16:50.962\nmaybe we're not even authorized\nto log into that server.\n\n304\n00:16:50.962 --> 00:16:51.840\nLet me show you what I mean.\n\n305\n00:16:51.840 --> 00:16:55.921\nSo I'm on a Windows 10 machine here,\nand I'll go ahead, and\n\n306\n00:16:55.921 --> 00:16:58.705\nlet's launch up our command prompt here.\n\n307\n00:16:58.705 --> 00:17:02.038\nAnd when we launch up our command prompt,\nI've got a server,\n\n308\n00:17:02.038 --> 00:17:04.805\nmy Windows server that we\nwere doing the backup on.\n\n309\n00:17:04.805 --> 00:17:06.897\nI got a couple of things that are running,\nright?\n\n310\n00:17:06.897 --> 00:17:10.560\nBut lets find out and\nwe'll see what exactly is running and\n\n311\n00:17:10.560 --> 00:17:13.867\nthat's the purpose of doing a banner grab,\nright?\n\n312\n00:17:13.867 --> 00:17:17.320\nLet me go ahead and give us a little bit\nmore real estate here on the screen.\n\n313\n00:17:19.609 --> 00:17:22.254\nAnd, oops, as I get rid of the screen.\n\n314\n00:17:22.254 --> 00:17:24.719\nThere we go.\n\n315\n00:17:24.719 --> 00:17:25.654\nWe'll clear it up here.\n\n316\n00:17:25.654 --> 00:17:27.468\nAnd let's go ahead and use Telnet.\n\n317\n00:17:27.468 --> 00:17:28.532\nLet's do a banner grab, all right?\n\n318\n00:17:28.532 --> 00:17:29.951\nSo we'll do a Telnet here, and\n\n319\n00:17:29.951 --> 00:17:32.580\nI'm gonna point it over to\nthe IP address of that server.\n\n320\n00:17:32.580 --> 00:17:34.096\nAnd I want you to notice\nwhat I'm gonna do here.\n\n321\n00:17:34.096 --> 00:17:37.971\nI'm gonna tell it what port I\nwant it to connect to, all right?\n\n322\n00:17:37.971 --> 00:17:40.680\nAnd if that port is open,\nwe might get a little information.\n\n323\n00:17:40.680 --> 00:17:42.370\nSometimes, we don't get any information.\n\n324\n00:17:42.370 --> 00:17:43.154\nLet me show you what I mean.\n\n325\n00:17:43.154 --> 00:17:44.367\nSo port 25, right?\n\n326\n00:17:44.367 --> 00:17:49.594\nThat is for listening out, the server\nis listening out to receive SMTP,\n\n327\n00:17:49.594 --> 00:17:52.602\nSimple Mail Transfer Protocol, right?\n\n328\n00:17:52.602 --> 00:17:53.907\nListening out for email.\n\n329\n00:17:53.907 --> 00:17:56.788\nWell, if I do a Telnet on that same port,\nand I run it,\n\n330\n00:17:56.788 --> 00:18:00.007\nnotice I get some information\nright away about the server.\n\n331\n00:18:00.007 --> 00:18:04.225\nI can see that this is running\nMicrosoft's enhanced or\n\n332\n00:18:04.225 --> 00:18:07.166\nextended SMTP MAIL Service, right?\n\n333\n00:18:07.166 --> 00:18:09.167\nI can even see the version, right?\n\n334\n00:18:09.167 --> 00:18:10.024\nThat it's running.\n\n335\n00:18:10.024 --> 00:18:11.448\nAnd that it is open, it's waiting.\n\n336\n00:18:11.448 --> 00:18:16.135\nSo we gleaned a little bit of\ninformation about the SMTP,\n\n337\n00:18:16.135 --> 00:18:21.325\nI'm gonna wanna call that SNMP for\nsome reason, SMTP server.\n\n338\n00:18:21.325 --> 00:18:23.709\nAnd I'm not even authorized\nto connect to it, right?\n\n339\n00:18:23.709 --> 00:18:25.300\nI don't even have a user account.\n\n340\n00:18:25.300 --> 00:18:26.921\nBut I can gain some information, right?\n\n341\n00:18:26.921 --> 00:18:30.890\nIf I wanna find out well,\nare you running things like FTP, right?\n\n342\n00:18:30.890 --> 00:18:32.944\nWell, I can also do that,\nthere's a couple different ways.\n\n343\n00:18:32.944 --> 00:18:37.041\nYou can actually use, let's see if\nI can get out of here real quick.\n\n344\n00:18:37.041 --> 00:18:41.225\nSometimes you just have to close\nthe command prompt down, walk away and\n\n345\n00:18:41.225 --> 00:18:42.629\nre open it, all right?\n\n346\n00:18:42.629 --> 00:18:47.460\nSo like for instance we can also\ndo the same thing with Telnet.\n\n347\n00:18:47.460 --> 00:18:50.518\nNow, I could go a little bit\nfurther could just use FTP but\n\n348\n00:18:50.518 --> 00:18:53.347\nwe maybe we don't know if FTP is open or\nnot, right?\n\n349\n00:18:53.347 --> 00:18:56.959\nSo I can do the same thing and\nI could go port 21 this time, right?\n\n350\n00:18:56.959 --> 00:19:00.767\nOur FTP port, let's see if we\ncan get any information there.\n\n351\n00:19:00.767 --> 00:19:03.111\nAnd notice that I get just\na little bit of information.\n\n352\n00:19:03.111 --> 00:19:07.185\nThis one didn't give us quite as much\ninformation as the last one did, but\n\n353\n00:19:07.185 --> 00:19:10.879\nI can see that you're running\nthe Microsoft FTP service, right?\n\n354\n00:19:10.879 --> 00:19:14.097\nAnd I can get even more\ninformation potentially by doing,\n\n355\n00:19:14.097 --> 00:19:15.942\nnow that I know you have FTP open.\n\n356\n00:19:15.942 --> 00:19:18.248\nWell, let's drop down to\nthe same command prompt.\n\n357\n00:19:18.248 --> 00:19:22.520\nAnd I'll actually use the FTP command\nto see if we can glean a little bit\n\n358\n00:19:22.520 --> 00:19:24.121\nof information, right?\n\n359\n00:19:24.121 --> 00:19:28.318\nSo we'll just go ahead and\nwe'll do that real quick,\n\n360\n00:19:28.318 --> 00:19:32.515\nwe'll do an FTP and\nI'll do that same IP address, and\n\n361\n00:19:32.515 --> 00:19:36.267\nnow notice whether I am\nallowed to log in or not.\n\n362\n00:19:36.267 --> 00:19:40.343\nNow, I've gained a lot more information\nthan just the fact that it was running\n\n363\n00:19:40.343 --> 00:19:41.717\nthe FTP service, right?\n\n364\n00:19:41.717 --> 00:19:43.819\nWe can see a little bit more information.\n\n365\n00:19:43.819 --> 00:19:45.234\nThat's the purpose of banner grabbing.\n\n366\n00:19:45.234 --> 00:19:48.208\nAnd like I said, they've got utilities\nout there that'll do this for you and\n\n367\n00:19:48.208 --> 00:19:49.734\nglean a lot more information, right?\n\n368\n00:19:49.734 --> 00:19:52.259\nI wouldn't have to do the individual test.\n\n369\n00:19:52.259 --> 00:19:56.354\nIt would do those tests all as a part of\nlike one scan and we would receive that\n\n370\n00:19:56.354 --> 00:20:00.842\ninformation and I could kinda gain some\nkind of like, what attacks might happen.\n\n371\n00:20:00.842 --> 00:20:03.406\nNow, if you're doing security\nposture assessment, right?\n\n372\n00:20:03.406 --> 00:20:07.505\nThis information might be something\nthat a pen tester would find out, right?\n\n373\n00:20:07.505 --> 00:20:11.860\nAnd we're hoping that we're simulating an\nattack and it's not an actual attack, and\n\n374\n00:20:11.860 --> 00:20:14.677\nif they are gleaning a little\nbit too much information.\n\n375\n00:20:14.677 --> 00:20:17.745\nFor instance, if I'm not using FTP,\nif I'm not using SMTP,\n\n376\n00:20:17.745 --> 00:20:19.699\nthen I need to disable those services.\n\n377\n00:20:19.699 --> 00:20:23.780\nBecause we can start to glean a little bit\nof information, and we can start in that\n\n378\n00:20:23.780 --> 00:20:27.742\nreconnaissance sense start to gain\ninformation about where I can maybe tailor\n\n379\n00:20:27.742 --> 00:20:31.598\nmake a tax to hit something like FTP or\nSMTP, like forwarders, if you will.\n\n380\n00:20:31.598 --> 00:20:34.713\n&gt;&gt; Exactly, by knowing the vulnerabilities\nin those particular protocols or\n\n381\n00:20:34.713 --> 00:20:36.082\nservices that you're running.\n\n382\n00:20:36.082 --> 00:20:39.581\nEven using tools that will go ahead and\nlet you know what operating systems\n\n383\n00:20:39.581 --> 00:20:43.429\nyou're using, will let you know those\nvulnerabilities and those weaknesses.\n\n384\n00:20:43.429 --> 00:20:48.513\nAnd then that's just gonna kind of really\ngive them a method to go ahead and\n\n385\n00:20:48.513 --> 00:20:50.079\nexecute that attack.\n\n386\n00:20:50.079 --> 00:20:52.466\nSo using these tools can be helpful for\nus,\n\n387\n00:20:52.466 --> 00:20:55.531\nto make sure we're not\nexposing ourselves in any way.\n\n388\n00:20:55.531 --> 00:20:56.846\n&gt;&gt; Most definitely.\n\n389\n00:20:56.846 --> 00:20:59.468\nNow, some of the other things that\nthey call out there Cherokee,\n\n390\n00:20:59.468 --> 00:21:01.052\nthey call out some command line tools.\n\n391\n00:21:01.052 --> 00:21:06.047\nAnd these tools could be used for\nmany, many different reasons, right?\n\n392\n00:21:06.047 --> 00:21:12.051\nThey're using it in the context of helping\nsupport security posture assessment,\n\n393\n00:21:12.051 --> 00:21:12.658\nright?\n\n394\n00:21:12.658 --> 00:21:15.705\nOne of the ones that they call out\nwe've been using for a long time and\n\n395\n00:21:15.705 --> 00:21:17.914\nreally it's just about\ntesting reachability.\n\n396\n00:21:17.914 --> 00:21:21.769\nDifferent scanning software you use\nthe ping utility is what I'm talking\n\n397\n00:21:21.769 --> 00:21:22.647\nabout, right?\n\n398\n00:21:22.647 --> 00:21:25.403\nICMP, echo request and reply messages.\n\n399\n00:21:25.403 --> 00:21:29.775\nYou do have software, like Nmap and other\nonce out there that will do ping swift, so\n\n400\n00:21:29.775 --> 00:21:32.592\nwill use the same kinda\nutility to do host discovery.\n\n401\n00:21:32.592 --> 00:21:35.052\nWe wanna find out what host\nare available on our network,\n\n402\n00:21:35.052 --> 00:21:36.599\nwhich ones are are active, right?\n\n403\n00:21:36.599 --> 00:21:39.140\nAnd we can also use a, just for\ninstance, let me show you.\n\n404\n00:21:39.140 --> 00:21:42.324\nJust basic reachability, right?\n\n405\n00:21:42.324 --> 00:21:45.540\nWe can run our ping utility now,\nI'm in Mac here.\n\n406\n00:21:45.540 --> 00:21:47.559\nSo Mac is gonna run a persistent ping.\n\n407\n00:21:47.559 --> 00:21:52.005\nAnd in the Unix based systems in Mac you\nactually have to stop your ping utility.\n\n408\n00:21:52.005 --> 00:21:54.882\nIf you're in Windows you can add\nthe -t option to the end of it,\n\n409\n00:21:54.882 --> 00:21:56.196\nmakes it a persistent ping.\n\n410\n00:21:56.196 --> 00:21:57.841\nBut that's just a little\nbit of information,\n\n411\n00:21:57.841 --> 00:22:00.173\nI don't think you're gonna have\nto worry about that on the exam.\n\n412\n00:22:00.173 --> 00:22:04.701\nSo the ping utility test reachability\ncan also be used for host discovery and\n\n413\n00:22:04.701 --> 00:22:08.466\nfinding the hosts that are available and\nlive on your network.\n\n414\n00:22:08.466 --> 00:22:11.409\nSome of the other ones,\nother utilities that we have, we have for\n\n415\n00:22:11.409 --> 00:22:12.327\ninstance NETSTAT.\n\n416\n00:22:12.327 --> 00:22:16.314\nSo I'll tell you what, let me jump\nback into my Windows machine here and\n\n417\n00:22:16.314 --> 00:22:18.051\nlet's kinda look at NETSTAT.\n\n418\n00:22:18.051 --> 00:22:19.772\nSo NETSTAT is a great utility for\n\n419\n00:22:19.772 --> 00:22:24.060\nfinding out the state of the connections\nthat your computer is using right now.\n\n420\n00:22:24.060 --> 00:22:27.764\nSo for instance let me go ahead and\nclear the screen here.\n\n421\n00:22:27.764 --> 00:22:31.511\nAll right, and I wanna go ahead and\nI'm gonna kind of simulate a couple of\n\n422\n00:22:31.511 --> 00:22:35.575\nconnections here just like we were doing\nwith our banner grabbing real quick.\n\n423\n00:22:35.575 --> 00:22:39.269\nSo let me go ahead and launch up\na couple of these command prompts.\n\n424\n00:22:39.269 --> 00:22:44.022\nAnd we'll make sure that we\nmake some connections here.\n\n425\n00:22:44.022 --> 00:22:46.833\nCuz you're gonna make some\nconnections there and you know what?\n\n426\n00:22:46.833 --> 00:22:50.326\n&gt;&gt; And just like the command line implies,\nthis particular utility here,\n\n427\n00:22:50.326 --> 00:22:52.572\nwe're looking at those network statistics.\n\n428\n00:22:52.572 --> 00:22:53.879\nIt's a really helpful tool.\n\n429\n00:22:53.879 --> 00:22:55.207\nThere are a lot of different switches.\n\n430\n00:22:55.207 --> 00:22:56.695\nIf you're not familiar with those,\n\n431\n00:22:56.695 --> 00:22:58.815\nremember that you can use\nthe use the help function.\n\n432\n00:22:58.815 --> 00:22:59.504\nWhat is it?\n\n433\n00:22:59.504 --> 00:23:04.145\n/?, here to look at all those associated\nswitches just to really give you\n\n434\n00:23:04.145 --> 00:23:06.879\na good idea on how to\nbest utilize this tool.\n\n435\n00:23:06.879 --> 00:23:08.304\n&gt;&gt; Yes, definitely there.\n\n436\n00:23:08.304 --> 00:23:12.185\nSo, I got a couple of connections going on\nthe way, the other one that I'm gonna do.\n\n437\n00:23:12.185 --> 00:23:14.746\nLet's go ahead and make a connection too,\n\n438\n00:23:14.746 --> 00:23:17.529\nlike the administrative\nshare on the server.\n\n439\n00:23:17.529 --> 00:23:21.532\nOops, we're gonna make sure that you\ntype the administrative share right, or\n\n440\n00:23:21.532 --> 00:23:22.616\nit will not connect.\n\n441\n00:23:22.616 --> 00:23:25.403\nSo we'll go ahead and\nget that connection done.\n\n442\n00:23:25.403 --> 00:23:28.482\nOops, I've got all kinds of\nthings clicking around here.\n\n443\n00:23:28.482 --> 00:23:32.961\nSo it does help to be to type.\n\n444\n00:23:32.961 --> 00:23:33.672\n&gt;&gt; It can be a little trouble there,\nwith that little.\n\n445\n00:23:33.672 --> 00:23:35.579\n&gt;&gt; Yeah,\nyeah Cortana is giving me a hard time.\n\n446\n00:23:35.579 --> 00:23:37.056\n&gt;&gt; [LAUGH]\n&gt;&gt; So I'm gonna go ahead and\n\n447\n00:23:37.056 --> 00:23:40.014\njust go to the traditional run line\nbecause it doesn't decide to disappear in\n\n448\n00:23:40.014 --> 00:23:41.207\nthe middle of you typing in it.\n\n449\n00:23:41.207 --> 00:23:42.053\n&gt;&gt; Right.\n\n450\n00:23:42.053 --> 00:23:45.998\n&gt;&gt; All right, so lets go ahead and\ncontinuing on, I'll go ahead and\n\n451\n00:23:45.998 --> 00:23:49.249\nit looks like I've already\nauthenticated earlier.\n\n452\n00:23:49.249 --> 00:23:50.491\nSo we do have a few connections, right?\n\n453\n00:23:50.491 --> 00:23:54.162\nWe've got a connection from this Windows\n10 machine over to the server, and\n\n454\n00:23:54.162 --> 00:23:57.571\nI could run NETSTAT either on this\nmachine or I could run it on the server.\n\n455\n00:23:57.571 --> 00:23:59.596\nLet's go ahead and\nswitch over to the server and\n\n456\n00:23:59.596 --> 00:24:02.085\nsee what the server is actually\nseeing here with NETSTAT.\n\n457\n00:24:02.085 --> 00:24:04.618\nWe'll go ahead, and\nwe're gonna do the same thing,\n\n458\n00:24:04.618 --> 00:24:07.508\nwe'll just bring up our PowerShell or\ncommand prompt here.\n\n459\n00:24:07.508 --> 00:24:12.129\nThat font looks absolutely horrible, so\nwe'll go ahead and adjust that real quick,\n\n460\n00:24:12.129 --> 00:24:16.491\nmake it a little easier, I don't want you\nguys having a- Suffer out there when it\n\n461\n00:24:16.491 --> 00:24:20.640\ncomes to seeing things, so\nwe'll go ahead and get that changed up.\n\n462\n00:24:20.640 --> 00:24:25.270\nThere we go, much better, all right,\nso now we're gonna use netstat, and\n\n463\n00:24:25.270 --> 00:24:26.690\nwe'll test connections.\n\n464\n00:24:26.690 --> 00:24:29.510\nNow, there's a couple of ways that\nyou can do this, for instance,\n\n465\n00:24:29.510 --> 00:24:30.630\nI could do a netstat-a.\n\n466\n00:24:30.630 --> 00:24:34.050\nAnd this is gonna show me all\nof the connection states.\n\n467\n00:24:34.050 --> 00:24:38.190\nI will tell you, though, this can take\na little bit, and you're gonna notice that\n\n468\n00:24:38.190 --> 00:24:41.730\nat the end of this output,\nwe have a bunch of UDP information.\n\n469\n00:24:41.730 --> 00:24:43.490\nAnd personally,\n\n470\n00:24:43.490 --> 00:24:47.050\nwhen I'm looking for connection states,\nI don't really care about UDP, why?\n\n471\n00:24:47.050 --> 00:24:49.300\nWell, it's a connectionless service,\nright,\n\n472\n00:24:49.300 --> 00:24:51.500\nUDP is not gonna show me any information.\n\n473\n00:24:51.500 --> 00:24:54.244\nBut it's the TCP information\nthat's important here, so\n\n474\n00:24:54.244 --> 00:24:57.999\nwe'll show you some ways that you can make\nthis run a little bit more optimized.\n\n475\n00:24:57.999 --> 00:24:59.628\n&gt;&gt; Yeah, and you really can customize it.\n\n476\n00:24:59.628 --> 00:25:03.613\nBecause if you look at those individual\nswitches, those parameter options that you\n\n477\n00:25:03.613 --> 00:25:06.320\nhave in the command prompt,\nyou can actually add those.\n\n478\n00:25:06.320 --> 00:25:07.580\nSo you can kind of build and\n\n479\n00:25:07.580 --> 00:25:10.450\nadd extra switches to make it\na really customized tool there.\n\n480\n00:25:10.450 --> 00:25:13.135\n&gt;&gt; Yeah, and it speeds up the process too,\nand that's the great thing.\n\n481\n00:25:13.135 --> 00:25:18.090\nCuz for instance, right now, it's trying\nto find out UDP connections which,\n\n482\n00:25:18.090 --> 00:25:19.280\nagain, are connectionless.\n\n483\n00:25:19.280 --> 00:25:22.951\nIt's trying to do name resolution, and\nas you can see looking at my computer,\n\n484\n00:25:22.951 --> 00:25:24.630\nI mean, it's taking awhile here.\n\n485\n00:25:24.630 --> 00:25:27.934\nBut I can see some of the connections\nthat I established earlier, right.\n\n486\n00:25:27.934 --> 00:25:32.800\nI could see port 21, it's established,\nport 25, right, we can see port 80.\n\n487\n00:25:32.800 --> 00:25:36.480\nThere I've got IIS also\ninstalled on the server there.\n\n488\n00:25:36.480 --> 00:25:39.953\nSo the web server it shows me\nhas an established connection.\n\n489\n00:25:39.953 --> 00:25:42.509\nI'm gonna go ahead,\nbecause this is taking a long time and\n\n490\n00:25:42.509 --> 00:25:44.501\nthis is really only a 30\nminute show [LAUGH].\n\n491\n00:25:44.501 --> 00:25:48.089\n&gt;&gt; But yeah, by omitting those particular\nswitches and really just picking and\n\n492\n00:25:48.089 --> 00:25:51.786\nchoosing what it is you exactly wanna see,\nthat's what Wes is talking about for\n\n493\n00:25:51.786 --> 00:25:54.010\njust kind of streamlining\nthis process here.\n\n494\n00:25:54.010 --> 00:25:58.050\n&gt;&gt; Definitely, so let's go ahead and\nshow you guys an example of that.\n\n495\n00:25:58.050 --> 00:26:01.340\nSo first of all,\nI don't wanna do name resolution, right.\n\n496\n00:26:01.340 --> 00:26:04.920\nName resolution takes awhile, and I just\nwanna see the state of the connections.\n\n497\n00:26:04.920 --> 00:26:09.050\nWell, what I can do is a netstat -n,\nand what that says is,\n\n498\n00:26:09.050 --> 00:26:11.130\njust show me the numerical format.\n\n499\n00:26:11.130 --> 00:26:13.834\nYou're gonna notice something,\nthat when I run it, it's finished.\n\n500\n00:26:13.834 --> 00:26:16.796\n&gt;&gt; It kind of reminds me,\nthe -n, like subtract the names,\n\n501\n00:26:16.796 --> 00:26:18.316\ntake away those names [LAUGH].\n\n502\n00:26:18.316 --> 00:26:22.302\n&gt;&gt; Exactly, that's a great way to\nremember it, too, on the exam,\n\n503\n00:26:22.302 --> 00:26:24.460\nexam hint there, or alert.\n\n504\n00:26:24.460 --> 00:26:29.320\nBut notice that one of the ones that\nI really wanted, I can see port 25,\n\n505\n00:26:29.320 --> 00:26:31.290\nport 445 there as well.\n\n506\n00:26:31.290 --> 00:26:36.007\nAnd I can see the foreign address, in this\ncase, it's the Windows 10 machine there,\n\n507\n00:26:36.007 --> 00:26:37.680\nso you can do things like that.\n\n508\n00:26:37.680 --> 00:26:41.593\nNow, notice that I said don't do name\nresolution, we can go even farther,\n\n509\n00:26:41.593 --> 00:26:44.910\nwe can get protocol specific, and\nthis is the one I really like.\n\n510\n00:26:44.910 --> 00:26:49.793\nWhen I do netstat, right, I do -n,\nI don't want name resolution, and\n\n511\n00:26:49.793 --> 00:26:54.533\nI do -p for protocol, and I just put TCP,\nit's the only thing I want.\n\n512\n00:26:54.533 --> 00:26:56.555\nAnd when I run it,\njust like that, it's done-\n\n513\n00:26:56.555 --> 00:26:57.283\n&gt;&gt; You're not waiting for\n\n514\n00:26:57.283 --> 00:27:00.098\nthose UDP connections-\n&gt;&gt; Exactly, I don't have to wait, and\n\n515\n00:27:00.098 --> 00:27:01.161\nwe're good to go.\n\n516\n00:27:01.161 --> 00:27:04.400\nNow, maybe you want a little bit\nmore information, right, remember,\n\n517\n00:27:04.400 --> 00:27:06.080\ngleaning information here.\n\n518\n00:27:06.080 --> 00:27:10.268\nWell, we can actually do something like\nthis, where we say, you know what,\n\n519\n00:27:10.268 --> 00:27:16.110\nI don't wanna do name resolution, right,\nbut I wanna do per protocol statistics.\n\n520\n00:27:16.110 --> 00:27:18.981\nWell, I can do that,\nI can run something like a -s.\n\n521\n00:27:18.981 --> 00:27:23.529\nAnd notice that when I run a -s,\nit gives me per protocol statistics,\n\n522\n00:27:23.529 --> 00:27:29.050\nwhich are very, very good, in case you\nneed to find out that information.\n\n523\n00:27:29.050 --> 00:27:31.341\nYou can go even farther too with this, but\n\n524\n00:27:31.341 --> 00:27:35.219\nthis just kinda scratches the surface\nof what you can do with netstat.\n\n525\n00:27:35.219 --> 00:27:38.729\nI want you to keep in mind,\nthough, very, very good for\n\n526\n00:27:38.729 --> 00:27:42.415\nlooking at those established\nconnections that you have.\n\n527\n00:27:42.415 --> 00:27:45.559\nAll right some of the other things\nthat we have, we have tracert,\n\n528\n00:27:45.559 --> 00:27:49.180\nand if you're in Windows, this one\nreally isn't gonna be too crazy here.\n\n529\n00:27:49.180 --> 00:27:51.120\nIf I do tracert, remember,\n\n530\n00:27:51.120 --> 00:27:55.470\nthis helps me to determine the path\na packet takes from source to destination.\n\n531\n00:27:55.470 --> 00:28:00.740\nAnd I'll go ahead and do a tracert,\nI'm not sure if I'll be able to run it.\n\n532\n00:28:00.740 --> 00:28:03.938\nAgain, cuz there aren't any\nhops in this machine, right,\n\n533\n00:28:03.938 --> 00:28:05.890\nthis is a virtualized environment.\n\n534\n00:28:05.890 --> 00:28:10.622\nAnd what tracert does is, it helps me\nto determine the path a packet takes\n\n535\n00:28:10.622 --> 00:28:13.630\nfrom the source to destination, right.\n\n536\n00:28:13.630 --> 00:28:18.350\nAnd those intermediate hops that it passes\nthrough on its way to its destination.\n\n537\n00:28:18.350 --> 00:28:22.031\nNow, this really isn't giving me too much\ninformation, so let me go ahead, and\n\n538\n00:28:22.031 --> 00:28:23.945\nI'm gonna jump over here to the Mac here.\n\n539\n00:28:23.945 --> 00:28:27.183\nAnd what we'll use is one that\nyou see in the Nix base systems,\n\n540\n00:28:27.183 --> 00:28:29.020\nwhich is spelled out traceroute.\n\n541\n00:28:29.020 --> 00:28:35.690\nSo we can do traceroute, and I could do\nthis by the fully qualified domain name.\n\n542\n00:28:35.690 --> 00:28:37.910\nAnd I picked a couple here on purpose,\nright?\n\n543\n00:28:37.910 --> 00:28:40.445\nI'm gonna pick on Google here\na little bit, because Google,\n\n544\n00:28:40.445 --> 00:28:43.050\nyou're gonna notice that traceroute,\ndoing the same thing.\n\n545\n00:28:43.050 --> 00:28:45.875\nDetermining a path a packet takes\nfrom source to destination.\n\n546\n00:28:45.875 --> 00:28:52.290\nBut Google has a lot of IP addresses for\nwww.google.com, right.\n\n547\n00:28:52.290 --> 00:28:54.710\nWell, how do I know that,\nit's giving me this warning.\n\n548\n00:28:54.710 --> 00:28:58.820\nSo I can actually see those addresses if\nI want to do things like testing name\n\n549\n00:28:58.820 --> 00:29:01.440\nresolution, how do you\ntest name resolution?\n\n550\n00:29:01.440 --> 00:29:03.244\nWell, you got a couple different options,\nright,\n\n551\n00:29:03.244 --> 00:29:05.588\ninside of your Windows based systems,\nyou have nslookup, right.\n\n552\n00:29:05.588 --> 00:29:11.380\nnslookup allows me to test whether name\nresolution's happening on this machine.\n\n553\n00:29:11.380 --> 00:29:14.950\nNow, I'm gonna go ahead,\nI'm gonna stop this,\n\n554\n00:29:14.950 --> 00:29:18.740\nremember that traceroute\nuses ICMP messages.\n\n555\n00:29:18.740 --> 00:29:22.280\nAnd sometimes ICMP messages can\nbe blocked for security purposes.\n\n556\n00:29:22.280 --> 00:29:26.490\nSo that doesn't necessarily mean that\nthis connection here is failing.\n\n557\n00:29:26.490 --> 00:29:28.820\nIt could be the fact that\nICMPs being blocked, so\n\n558\n00:29:28.820 --> 00:29:30.330\nwe're not seeing any information on it.\n\n559\n00:29:30.330 --> 00:29:33.087\nBut I wanna show you\nhow I could figure out,\n\n560\n00:29:33.087 --> 00:29:37.616\nwhat are some of the IP addresses used for\nwww.google.com, right?\n\n561\n00:29:37.616 --> 00:29:42.210\nWell, we can use dig, right, I can go do\ndig for the domain Internet Groper here.\n\n562\n00:29:42.210 --> 00:29:49.453\nAnd we can do www.google.com, all right,\nand we'll go ahead and run this.\n\n563\n00:29:49.453 --> 00:29:51.175\nAnd notice here what we have here, right?\n\n564\n00:29:51.175 --> 00:29:53.560\n&gt;&gt; Good point,\nJim pointed out in the chat there.\n\n565\n00:29:53.560 --> 00:29:59.556\nAlso, you can remove those DNS names to\nhelp speed the traceroute process as well.\n\n566\n00:29:59.556 --> 00:30:02.265\nWhich is really helpful if\nyou're in a crunch for time.\n\n567\n00:30:02.265 --> 00:30:04.840\n&gt;&gt; Yep, definitely, and\nit's another one of those things.\n\n568\n00:30:04.840 --> 00:30:07.430\nAnytime I have to add\na layer of complexity,\n\n569\n00:30:07.430 --> 00:30:10.480\nit's gonna slow down the results\nthat you're gonna see.\n\n570\n00:30:10.480 --> 00:30:14.110\nBut notice how I can see,\nthese are a lot of IP addresses, and\n\n571\n00:30:14.110 --> 00:30:15.560\ndig helped me do that, right?\n\n572\n00:30:15.560 --> 00:30:20.090\nIt helped me see what those\nname resolutions were,\n\n573\n00:30:20.090 --> 00:30:23.960\nwhat www.google.com was resolving to.\n\n574\n00:30:23.960 --> 00:30:27.168\nNow, the other thing that\nyou can do as well is,\n\n575\n00:30:27.168 --> 00:30:32.398\nyou can find sometimes where you actually\nsee the entire path a packet takes.\n\n576\n00:30:32.398 --> 00:30:35.845\nLike for instance if I do tracert,\nlisten to me,\n\n577\n00:30:35.845 --> 00:30:39.306\ntracert instead of a Unix based system,\nright.\n\n578\n00:30:39.306 --> 00:30:42.396\nTraceroute, [LAUGH], and\n\n579\n00:30:42.396 --> 00:30:48.830\nI do www.facebook.com,\nright, and we run that.\n\n580\n00:30:48.830 --> 00:30:54.780\nYou can see, this traceroute has already\ncompleted, and I can see the intermediate\n\n581\n00:30:54.780 --> 00:30:59.320\nhops that this packet passed through\nfrom its source to destination.\n\n582\n00:30:59.320 --> 00:31:00.840\nAgain, keep in mind, nslookup,\n\n583\n00:31:00.840 --> 00:31:06.360\nwe can do that inside of your\nWindows operating systems, too.\n\n584\n00:31:06.360 --> 00:31:09.180\n&gt;&gt; So that's just comporable\nto dig in our Nix base?\n\n585\n00:31:09.180 --> 00:31:10.850\n&gt;&gt; Most definitely, all right, so\n\n586\n00:31:10.850 --> 00:31:14.320\nwe've got a few more that we've gotta talk\nabout, let's see, what else do we have?\n\n587\n00:31:14.320 --> 00:31:16.270\nWe have the address resolution protocol,\nand\n\n588\n00:31:16.270 --> 00:31:19.880\nagain, address resolution protocol,\nremember, ARP.\n\n589\n00:31:19.880 --> 00:31:23.280\nARP is the command for\nessentially controlling, modifying, and\n\n590\n00:31:23.280 --> 00:31:26.162\nviewing the ARP table\ninside of your machine.\n\n591\n00:31:26.162 --> 00:31:28.830\nSo if we jump back down\nto our Windows machine,\n\n592\n00:31:28.830 --> 00:31:31.600\nwe can bring up our command prompt.\n\n593\n00:31:31.600 --> 00:31:34.180\nAnd let me go ahead and\nquit my FTP connection here.\n\n594\n00:31:36.470 --> 00:31:40.675\nAnd if I run an arp,\nactually I'll just do arp and\n\n595\n00:31:40.675 --> 00:31:43.980\na -a, that's the one I want, arp -a.\n\n596\n00:31:43.980 --> 00:31:47.117\nAnd this will show me the ARP cache,\nright, and\n\n597\n00:31:47.117 --> 00:31:51.700\nI can see the ones that I've learned\nversus the ones that are static.\n\n598\n00:31:51.700 --> 00:31:54.830\nThese are the ones that are generated,\nlike for instance,\n\n599\n00:31:54.830 --> 00:31:58.600\nlocal broadcast and\nyour multicast addresses as well.\n\n600\n00:31:58.600 --> 00:32:03.110\nIf you need to see things like your IP\nconfiguration information here in Windows,\n\n601\n00:32:03.110 --> 00:32:04.450\nyou can use ipconfig.\n\n602\n00:32:04.450 --> 00:32:07.116\nLet me go ahead and clear the screen,\nkinda show you that one.\n\n603\n00:32:07.116 --> 00:32:11.144\nSo we can do an ipconfig, and\nI can add a ton of switches to this.\n\n604\n00:32:11.144 --> 00:32:15.353\nIf I run it by itself, it shows me basic\nconfiguration of the network adapter.\n\n605\n00:32:15.353 --> 00:32:19.630\nWe could go a little bit farther than\nthis and we could run the for /all,\n\n606\n00:32:19.630 --> 00:32:21.554\nall right, and when I run that,\n\n607\n00:32:21.554 --> 00:32:26.190\nthat gives me very detailed\ninformation about the network adapter.\n\n608\n00:32:26.190 --> 00:32:30.750\nInside of your Nix based systems, you have\nthings like ifconfig so, for instance,\n\n609\n00:32:30.750 --> 00:32:35.515\nif I bump back down to the Mac here,\nright, I can do ifconfig.\n\n610\n00:32:35.515 --> 00:32:40.900\nifconfig is something again,\nlike I said, that you can use inside\n\n611\n00:32:40.900 --> 00:32:44.920\nof your Nix based systems pretty\nmuch doing the same thing right,\n\n612\n00:32:44.920 --> 00:32:48.650\nshowing me things like for instance,\nmy network adapters right and\n\n613\n00:32:48.650 --> 00:32:50.910\nthe IP addresses to\nthose network adapters.\n\n614\n00:32:51.940 --> 00:32:58.510\nRight, you also have inside for instance\nyour, let me get back to my machine here.\n\n615\n00:32:58.510 --> 00:33:00.900\nThere we go, there's my CentOS machine.\n\n616\n00:33:00.900 --> 00:33:03.760\nYou also have things like IP\nthat they talk about too.\n\n617\n00:33:03.760 --> 00:33:08.270\nFor instance, I can do an ip addr and\nwhen I do this,\n\n618\n00:33:08.270 --> 00:33:11.640\nrunning this command, ip addr, you can\nsee that it shows me the same thing.\n\n619\n00:33:11.640 --> 00:33:15.840\nShows me our interfaces that we have\nin the machine as well as what the IP\n\n620\n00:33:15.840 --> 00:33:17.060\naddresses are.\n\n621\n00:33:17.060 --> 00:33:19.740\nThere are a couple other ones\nthat they call out here, too.\n\n622\n00:33:19.740 --> 00:33:23.090\nThey call out TCP dump,\nTCP dump is something.\n\n623\n00:33:23.090 --> 00:33:27.500\nIt's basically a packet capture\nutility that you can run, and\n\n624\n00:33:27.500 --> 00:33:31.180\nit is inside of your\nNix based systems here.\n\n625\n00:33:31.180 --> 00:33:34.200\nSo you can always run that\nto do packet capture.\n\n626\n00:33:34.200 --> 00:33:37.260\nKeep in mind that you're not gonna\nget a GUI based on this one.\n\n627\n00:33:37.260 --> 00:33:40.420\nSo if you are not familiar\nwith the command line,\n\n628\n00:33:40.420 --> 00:33:42.390\nI would recommend\nsomething like Wireshark.\n\n629\n00:33:42.390 --> 00:33:45.120\nBut you do have the ability to do that.\n\n630\n00:33:45.120 --> 00:33:49.490\nWe can also do things like, for instance,\nwe can run utilities like Nmap.\n\n631\n00:33:49.490 --> 00:33:52.020\nSo, for instance,\nI've already downloaded Nmap and\n\n632\n00:33:52.020 --> 00:33:55.650\nI can do a very basic\nscan against the machine.\n\n633\n00:33:55.650 --> 00:33:59.550\nI'm not sure that I have,\nI'll tell you what.\n\n634\n00:33:59.550 --> 00:34:04.320\nLet me see, if I do a scan against\nthe local host, there we go.\n\n635\n00:34:04.320 --> 00:34:07.640\nSo I went ahead and just scanned the local\nhost, but kind of show you guys here, but\n\n636\n00:34:07.640 --> 00:34:09.620\nI can see the current state of,\n\n637\n00:34:09.620 --> 00:34:13.730\nfor instance,\nthe different ports here that are open.\n\n638\n00:34:13.730 --> 00:34:18.430\nI can see SSH, port 25 here, and\nthen some other ones, as well, too.\n\n639\n00:34:18.430 --> 00:34:23.640\nSo it's good to Nmap, again, doing\nbasic port scans, doing OS discovery.\n\n640\n00:34:23.640 --> 00:34:28.470\nAnd the last one that you also have\nin your Nix based systems is Netcat.\n\n641\n00:34:28.470 --> 00:34:32.570\nNetcat can also do things like banner\nrubbing as well, so a lot of utilities\n\n642\n00:34:32.570 --> 00:34:36.010\nthat you have that are available,\nkeep in mind to be familiar with them.\n\n643\n00:34:36.010 --> 00:34:40.760\nI don't know that they are gonna ask\nyou specific implementation or switches\n\n644\n00:34:40.760 --> 00:34:45.620\nindividual, like help topics if you will,\nbut they are gonna definitely want you to\n\n645\n00:34:45.620 --> 00:34:49.600\nknow what these utilities do and in what\nscenarios you're gonna implement them.\n\n646\n00:34:49.600 --> 00:34:52.400\n&gt;&gt; You really did show us a ton of\ndifferent tools that we have available\n\n647\n00:34:52.400 --> 00:34:53.070\nto use.\n\n648\n00:34:53.070 --> 00:34:55.120\nSo it really shouldn't be a problem,\n\n649\n00:34:55.120 --> 00:34:58.210\nan issue of not being able\nto find a proper tool.\n\n650\n00:34:58.210 --> 00:35:03.350\nThe real problem may lie with choosing the\nappropriate tool for your particular need.\n\n651\n00:35:03.350 --> 00:35:06.770\nSo thank you so much for that, and thank\nyou, ladies and gentlemen, for tuning in.\n\n652\n00:35:06.770 --> 00:35:08.810\nBut for this show,\nwe're gonna go ahead and sign off.\n\n653\n00:35:08.810 --> 00:35:11.340\nRemember I'm your host, Cherokee Boose,\n&gt;&gt; And I'm Wes Bryan.\n\n654\n00:35:11.340 --> 00:35:14.562\n&gt;&gt; See you next time here at ITProTV.\n\n655\n00:35:14.562 --> 00:35:20.809\n[MUSIC]\n\n656\n00:35:20.809 --> 00:35:22.989\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "251320494"
        },
        {
          "description": "In this show, Cherokee and Wes begin to cover different issues one may have to troubleshoot. They begin explaining protocols that send information in clear or plain text such as FTP, Telnet, PAP and HTTP. Nest they discuss the importance of logs, permissions, access violations and certificate issues.",
          "length": "2217",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-3-1-troubleshoot_common_security_issues-042117-PGM.00_37_03_19.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-3-1-troubleshoot_common_security_issues-042117-PGM.00_37_03_19.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-3-1-troubleshoot_common_security_issues-042117-PGM.00_37_03_19.Still001-sm.jpg",
          "title": "Troubleshoot Common Security Issues",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:06.366\nWelcome to ITPRO.TV,\nI'm your host, [CROSSTALK]\n\n2\n00:00:06.366 --> 00:00:08.395\n[MUSIC]\n\n3\n00:00:08.395 --> 00:00:12.065\n&gt;&gt; You're watching ITPRO.TV.\n\n4\n00:00:12.065 --> 00:00:16.590\n&gt;&gt; Welcome to your CompTIA Security+\nseries, I'm your show host Cherokee Boose.\n\n5\n00:00:16.590 --> 00:00:20.370\nIn this episode, we're gonna be looking at\nour different types of common issues that\n\n6\n00:00:20.370 --> 00:00:24.110\nwe may have and, well, how to troubleshoot\nthem when we're dealing with security.\n\n7\n00:00:24.110 --> 00:00:26.600\nWith us today in studios we have Mr.\nWes Bryan.\n\n8\n00:00:26.600 --> 00:00:27.690\nThank you for joining us, Wes.\n\n9\n00:00:27.690 --> 00:00:29.140\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n10\n00:00:29.140 --> 00:00:31.940\nThat's right, we have a bunch of\ndifferent things that can happen.\n\n11\n00:00:31.940 --> 00:00:35.708\nWe wanna kinda throw a few different\nscenarios at you as we go through\n\n12\n00:00:35.708 --> 00:00:36.575\nthe list here.\n\n13\n00:00:36.575 --> 00:00:41.346\nAnd kinda give you some idea of\nwhat maybe you can expect when you\n\n14\n00:00:41.346 --> 00:00:47.005\ncome into some of these different\nsecurity issues, if you will.\n\n15\n00:00:47.005 --> 00:00:49.005\nWe're gonna talk about all\ndifferent kinds of things.\n\n16\n00:00:49.005 --> 00:00:52.150\nLet's go ahead and we will jump right in.\n\n17\n00:00:52.150 --> 00:00:55.650\nOne of the things that we have to worry\nabout, they call out first of all,\n\n18\n00:00:55.650 --> 00:00:59.370\nis unencrypted credentials, right?\n\n19\n00:00:59.370 --> 00:01:01.490\nClear text information.\n\n20\n00:01:01.490 --> 00:01:03.300\nAnd as we've been moving\nthrough this series,\n\n21\n00:01:03.300 --> 00:01:06.350\nthere are many a protocols out\nthere we have to worry about.\n\n22\n00:01:06.350 --> 00:01:10.580\nSome of them are oldies but goodies\nthat even though they've been around for\n\n23\n00:01:10.580 --> 00:01:13.320\na very long time we can\nstill use them today.\n\n24\n00:01:13.320 --> 00:01:17.735\nBut we have to be careful, keep in mind\nanytime we are sending information across\n\n25\n00:01:17.735 --> 00:01:21.360\nthe public communication channel,\nit doesn't matter if it's wired or\n\n26\n00:01:21.360 --> 00:01:22.250\nit's wireless.\n\n27\n00:01:22.250 --> 00:01:26.220\nWe do have to take some precautions\nto make sure that somebody can't\n\n28\n00:01:26.220 --> 00:01:29.710\nstand in this, the middle of that\nconversation and eavesdrop, right?\n\n29\n00:01:29.710 --> 00:01:31.920\nAnd collect and\nscrape that information, right?\n\n30\n00:01:31.920 --> 00:01:34.370\nThat's why we wanna use encryption, right?\n\n31\n00:01:34.370 --> 00:01:39.123\nWe wanna use things like TLS/SSL and\nI know sometimes people say SSL/TLS,\n\n32\n00:01:39.123 --> 00:01:42.630\nI'm gonna go ahead and\nsaid TLS/SSL because, right?\n\n33\n00:01:42.630 --> 00:01:44.956\nWe're primarily using TLS today, right?\n\n34\n00:01:44.956 --> 00:01:48.960\nWe wanna ensure that when we\nconnect to endpoints, right?\n\n35\n00:01:48.960 --> 00:01:52.410\nThat as that information gets\nsent over that public medium,\n\n36\n00:01:52.410 --> 00:01:54.000\nthat public channel, right?\n\n37\n00:01:54.000 --> 00:01:56.760\nThat if somebody was to grab\nthat information, sure,\n\n38\n00:01:56.760 --> 00:01:57.970\nthey could grab that information.\n\n39\n00:01:57.970 --> 00:02:01.250\nBut they couldn't see any of\nthe information that is inside of\n\n40\n00:02:01.250 --> 00:02:02.385\nthe communication itself.\n\n41\n00:02:02.385 --> 00:02:04.940\nThey'd know that there's a message there,\nbut it's scrambled, right?\n\n42\n00:02:04.940 --> 00:02:07.490\nAnd they can't deduce what it is, right?\n\n43\n00:02:07.490 --> 00:02:09.265\nSo we have to worry\nabout things like that,\n\n44\n00:02:09.265 --> 00:02:10.820\nespecially when we talk about credentials.\n\n45\n00:02:10.820 --> 00:02:14.880\nNot only the data itself, but when we're\nauthenticating against the system, right?\n\n46\n00:02:14.880 --> 00:02:18.140\nIt's bad enough when one piece of data\nthat's sent over a public channel is\n\n47\n00:02:18.140 --> 00:02:20.760\nunencrypted, get's scraped, if you will.\n\n48\n00:02:20.760 --> 00:02:24.570\nAnd I say scraped, just figuratively\nspeaking, is getting data captured, right?\n\n49\n00:02:24.570 --> 00:02:26.922\nWe're doing packet capture.\n\n50\n00:02:26.922 --> 00:02:29.933\nThat hacker, or attacker if you will,\ngrabs that data,\n\n51\n00:02:29.933 --> 00:02:34.630\ncan read that information, and now we\npotentially have some problems, right?\n\n52\n00:02:34.630 --> 00:02:36.030\nBut how bad is it, right?\n\n53\n00:02:36.030 --> 00:02:37.200\nThat's one piece of information.\n\n54\n00:02:37.200 --> 00:02:38.490\nAnd yes, that's bad enough.\n\n55\n00:02:38.490 --> 00:02:41.300\nHow about unencrypted access, right?\n\n56\n00:02:41.300 --> 00:02:45.580\nUnencrypted authentication gives you\naccess to potentially the entire system.\n\n57\n00:02:45.580 --> 00:02:48.575\nNot just a single piece of data, right?\n\n58\n00:02:48.575 --> 00:02:53.325\nBut there's really no way that once\nsomebody has your credentials, right?\n\n59\n00:02:53.325 --> 00:02:56.405\nThat the authenticating system,\nthere's no real way for\n\n60\n00:02:56.405 --> 00:03:00.525\nit to tell that that isn't the person\nthat should have access to the system.\n\n61\n00:03:00.525 --> 00:03:03.125\nSo we do have to keep that in mind, right?\n\n62\n00:03:03.125 --> 00:03:06.720\nThings that we've talked about in\nthe past, things like FTP, right?\n\n63\n00:03:06.720 --> 00:03:08.310\nWe talked about file transfer protocol.\n\n64\n00:03:08.310 --> 00:03:09.780\nIt is an oldie but goodie.\n\n65\n00:03:09.780 --> 00:03:12.230\nIt's been around for\na very long time, right?\n\n66\n00:03:12.230 --> 00:03:16.663\nAnd that's because it's highly optimized\nfor large file transfers, right?\n\n67\n00:03:16.663 --> 00:03:19.566\nAn FTP server,\nyou can throw commands at it, right?\n\n68\n00:03:19.566 --> 00:03:21.332\nYou can implement a GUI\non top of those commands,\n\n69\n00:03:21.332 --> 00:03:22.980\nyou don't necessarily have to use command.\n\n70\n00:03:22.980 --> 00:03:25.430\nBut you can implement commands,\nyou can throw commands at it.\n\n71\n00:03:25.430 --> 00:03:30.210\nAnd again, it is highly optimized for\nlarge data transfer.\n\n72\n00:03:30.210 --> 00:03:34.030\nBut by itself it's plain text, right?\n\n73\n00:03:34.030 --> 00:03:37.153\nIt's unencrypted and even worse, right?\n\n74\n00:03:37.153 --> 00:03:39.384\nIf we're doing things like\nanonymous logons, right?\n\n75\n00:03:39.384 --> 00:03:43.618\nThose could lend in, they lend themselves\nto things like authentication issues,\n\n76\n00:03:43.618 --> 00:03:47.546\nbecause of the fact that, if you have\nFTP are coupled with anonymous logon and\n\n77\n00:03:47.546 --> 00:03:49.069\nI'm doing package capture?\n\n78\n00:03:50.270 --> 00:03:53.760\nI don't really need a password, I've just\nfound out that the username that I've\n\n79\n00:03:53.760 --> 00:03:56.530\ncaptured says anonymous in the packet.\n\n80\n00:03:56.530 --> 00:04:00.310\nWell, if it says anonymous, now that I've\nfigured out that you're allowing anonymous\n\n81\n00:04:00.310 --> 00:04:03.810\nlogon to your FTP server and\nI don't have to have a password.\n\n82\n00:04:03.810 --> 00:04:05.810\nSo then it gets even worse, right?\n\n83\n00:04:05.810 --> 00:04:10.402\nAnd that's why we couple things with SSL,\nright?\n\n84\n00:04:10.402 --> 00:04:14.543\nSo for instance, one of the things you\nhave to keep in mind is, for instance,\n\n85\n00:04:14.543 --> 00:04:17.302\nif you're gonna fire up a Windows server,\nright?\n\n86\n00:04:17.302 --> 00:04:22.782\nAnd more importantly, if you're going\nto implement something like FTP.\n\n87\n00:04:22.782 --> 00:04:24.980\nWhen you are in the middle\nof implementing FTP,\n\n88\n00:04:24.980 --> 00:04:30.600\none of the things that the IIS Wizard,\nas part of bringing up that website\n\n89\n00:04:30.600 --> 00:04:37.370\nwill default to is requiring an SSL\ncertificate for that FTP server, right?\n\n90\n00:04:37.370 --> 00:04:40.968\nSo well, what does SSL do for us, right?\n\n91\n00:04:40.968 --> 00:04:42.070\nThink about it, right?\n\n92\n00:04:42.070 --> 00:04:46.450\nIt is an encrypted communication,\nand that's what we want.\n\n93\n00:04:46.450 --> 00:04:50.597\nThat is a way we implement FTPS, right?\n\n94\n00:04:50.597 --> 00:04:53.378\nOr FTP over SSL.\n\n95\n00:04:53.378 --> 00:04:56.782\nWe wanna make sure that if we\nare connecting to an FTP server\n\n96\n00:04:56.782 --> 00:05:01.226\nthat the information, let alone the\nusername and password used to log on and\n\n97\n00:05:01.226 --> 00:05:04.920\nauthenticate against the system\nhas been encrypted, right?\n\n98\n00:05:04.920 --> 00:05:08.290\nRegardless of the authentication\nmechanism in and of itself.\n\n99\n00:05:08.290 --> 00:05:11.790\nAnd like I said, that's one of\nthe reasons, if you are going to\n\n100\n00:05:11.790 --> 00:05:15.704\nbring online through, let's say IIS,\nyou're gonna create an FTP site.\n\n101\n00:05:15.704 --> 00:05:18.720\nWindows defaults to requiring SSL.\n\n102\n00:05:18.720 --> 00:05:23.171\nAnd it's up to you really to kinda\ndegrade the security by saying no,\n\n103\n00:05:23.171 --> 00:05:26.315\nwe're not gonna use SF or,\nexcuse me, SSL, and\n\n104\n00:05:26.315 --> 00:05:31.031\nallow things like read and write access\nto all users or anonymous users.\n\n105\n00:05:31.031 --> 00:05:35.080\nSo definitely be careful with\nthings like FTP, all right?\n\n106\n00:05:35.080 --> 00:05:39.990\nNow, more so that we use more\nthan FTP today is HTTP, right?\n\n107\n00:05:39.990 --> 00:05:43.640\nHTTP is another clear text,\npoint text protocol, right?\n\n108\n00:05:43.640 --> 00:05:48.970\nAnd if I'm sending information to\na website that isn't using things like\n\n109\n00:05:48.970 --> 00:05:54.750\nSSL certificates or TLS if you will,\nthen I'm running the risk\n\n110\n00:05:54.750 --> 00:05:59.805\nthat my username and password, if I\nhappen to be authenticating to a system.\n\n111\n00:05:59.805 --> 00:06:03.810\nI do run the risk that somebody else\ncould eavesdrop on that information and\n\n112\n00:06:03.810 --> 00:06:05.660\npotentially get access to it.\n\n113\n00:06:05.660 --> 00:06:09.330\nAnd that certainly isn't what we wanna do.\n\n114\n00:06:09.330 --> 00:06:13.990\nSo, we do wanna make sure that if we are\ngonna use, and connect to any kind of web\n\n115\n00:06:13.990 --> 00:06:18.900\nserver where we have to put in not\njust financial information, right?\n\n116\n00:06:18.900 --> 00:06:22.606\nBut if we do put in something\nlike a username and\n\n117\n00:06:22.606 --> 00:06:25.558\npassword that we keep it encrypted.\n\n118\n00:06:25.558 --> 00:06:29.420\nIn fact, I've got a Windows 2016 server,\nlet me show you here,\n\n119\n00:06:29.420 --> 00:06:31.790\nif you were to spin up an FTP site, right?\n\n120\n00:06:31.790 --> 00:06:35.850\nAnd I might still have\none already spun up.\n\n121\n00:06:35.850 --> 00:06:39.210\nOkay, so I've got FTP already set up.\n\n122\n00:06:39.210 --> 00:06:41.270\nBut let me show you what\nI mean by the defaults.\n\n123\n00:06:41.270 --> 00:06:43.884\nIf I was gonna add another FTP site,\nright?\n\n124\n00:06:43.884 --> 00:06:53.080\nAnd we're gonna say, we'll just call this\nFTP demo because I'm very, very creative.\n\n125\n00:06:53.080 --> 00:06:56.790\nAnd we'll go ahead and we'll put this\nwhere it's supposed to be, down in.\n\n126\n00:06:56.790 --> 00:06:59.910\nWe'll put it in the FTP route here,\nand we'll choose Next.\n\n127\n00:06:59.910 --> 00:07:03.140\nI want you to notice what it\nsays right away, all right?\n\n128\n00:07:03.140 --> 00:07:07.300\nAgain, notice that the default\nis to require SSL, all right?\n\n129\n00:07:07.300 --> 00:07:09.424\nMicrosoft is very aware of FTP, right?\n\n130\n00:07:09.424 --> 00:07:13.172\nThey've been on the forefront of a lot of\nthese technologies that we use today that\n\n131\n00:07:13.172 --> 00:07:14.720\nare industry-wide standards.\n\n132\n00:07:14.720 --> 00:07:18.580\nAnd that's why it defaults\nto requiring a certificate.\n\n133\n00:07:18.580 --> 00:07:21.390\nNow I don't have a certificate\nhere in order to implement, but\n\n134\n00:07:21.390 --> 00:07:25.560\nyou can see it would be\na weak implementation.\n\n135\n00:07:25.560 --> 00:07:27.690\nIf you did something where you said,\nyou know what?\n\n136\n00:07:27.690 --> 00:07:30.050\nI don't care about SSL.\n\n137\n00:07:30.050 --> 00:07:35.650\nI choose Next and we're gonna allow\nAnonymous and Basic Authentication, right?\n\n138\n00:07:35.650 --> 00:07:39.990\nAnd we're gonna allow All users Read and\nWrtie Access, right?\n\n139\n00:07:39.990 --> 00:07:41.625\nThat's a very weak implementation.\n\n140\n00:07:41.625 --> 00:07:45.041\nAnd one of the things that we have to\nworry about is now when people log on,\n\n141\n00:07:45.041 --> 00:07:48.513\nlet alone the anonymous aspect of it,\nthat even if somebody does use basic\n\n142\n00:07:48.513 --> 00:07:51.938\nauthentication, the law again,\nlet's say Windows authentication.\n\n143\n00:07:51.938 --> 00:07:56.475\nThat information could potentially be\nscraped by somebody that has the know-how\n\n144\n00:07:56.475 --> 00:08:01.385\nand can get into and understand the packet\nof information, reverse engineer that.\n\n145\n00:08:01.385 --> 00:08:04.232\nAnd now they've actually got\naccess to your systems, too.\n\n146\n00:08:04.232 --> 00:08:09.075\nSo keep in mind Things like HTTP,\nthings like Telnet, FTP.\n\n147\n00:08:09.075 --> 00:08:13.340\nThings like the old password\nauthentication protocol, right?\n\n148\n00:08:13.340 --> 00:08:17.318\nWe use things like CHAP today, Challenge\nHandshake Authentication Protocol right,\n\n149\n00:08:17.318 --> 00:08:18.415\nbecause what happens?\n\n150\n00:08:18.415 --> 00:08:22.112\nIt's a challenge and\na response comes back that\n\n151\n00:08:22.112 --> 00:08:26.610\nnever brings the password\nover a public wire, right?\n\n152\n00:08:26.610 --> 00:08:29.500\nNow CHAP is using your NIXbased systems.\n\n153\n00:08:29.500 --> 00:08:32.680\nMicrosoft has their own implementation\nthat's gone through different versions,\n\n154\n00:08:32.680 --> 00:08:36.140\nand the latest version of it pretty\nmuch is an industry wide standard for\n\n155\n00:08:36.140 --> 00:08:38.635\nauthentication over any kind of network,\nright?\n\n156\n00:08:38.635 --> 00:08:42.060\nWe have MS-CHAP, and\nMS-CHAP is considered weak.\n\n157\n00:08:42.060 --> 00:08:45.330\nI think it's the way it manages\nthe authentication, it should be kind of\n\n158\n00:08:45.330 --> 00:08:49.320\navoided but Microsoft knows that, they\nimplemented MS Chap version two, right.\n\n159\n00:08:49.320 --> 00:08:52.120\nAnd that's kind of been become one of\nthe industry wide standards today.\n\n160\n00:08:52.120 --> 00:08:55.290\nSo you have to keep in mind that we\ndon't implement things like PAP.\n\n161\n00:08:55.290 --> 00:08:58.290\nPAP, and in fact,\ninside of your Windows environment,\n\n162\n00:08:58.290 --> 00:09:00.130\nthey all it unencrypted authentication.\n\n163\n00:09:00.130 --> 00:09:04.080\nBecause the password authentication\nprotocol is one of those that it allows\n\n164\n00:09:04.080 --> 00:09:07.200\nyou to do an authentication over\na network, but it does not,\n\n165\n00:09:07.200 --> 00:09:12.040\nexcuse me encrypt your information,\nall right so it's in plain text.\n\n166\n00:09:12.040 --> 00:09:15.440\nThese things are things that we\ndefinitely have to worry about.\n\n167\n00:09:16.660 --> 00:09:18.240\nAll right,\nsome of the other things that they say,\n\n168\n00:09:18.240 --> 00:09:19.710\nwere you gonna say something there,\nCherokee?\n\n169\n00:09:19.710 --> 00:09:21.950\n&gt;&gt; No, I just see here on our list\nwe've got logs and events, and\n\n170\n00:09:21.950 --> 00:09:27.560\nit's kind of interesting Wes\nbecause just about every network\n\n171\n00:09:27.560 --> 00:09:31.650\nsolution out there is incorporating\nlogs into their software products.\n\n172\n00:09:31.650 --> 00:09:34.385\nI mean, if you look at SIEM systems for\n\n173\n00:09:34.385 --> 00:09:40.129\nour security event information management,\nit's really just so necessary.\n\n174\n00:09:40.129 --> 00:09:45.141\nAnd manufacturers are seeing this need\nthat we really should talk about that.\n\n175\n00:09:45.141 --> 00:09:45.912\n&gt;&gt; Most definitely.\n\n176\n00:09:45.912 --> 00:09:49.823\nI mean, you look at the complexities\nof managing something like a security\n\n177\n00:09:49.823 --> 00:09:53.548\nincident and then monitoring system,\nor then management system, and\n\n178\n00:09:53.548 --> 00:09:56.058\nyou could be aggregating a lot of logs,\nright?\n\n179\n00:09:56.058 --> 00:10:00.670\nSo it is important to make sure that\nthe way we access those logs, and\n\n180\n00:10:00.670 --> 00:10:03.450\nthe way we store those logs\nis in a secure manner, right?\n\n181\n00:10:03.450 --> 00:10:07.070\nYou wanna make sure first of all that\nyou're backing up your logs, right?\n\n182\n00:10:07.070 --> 00:10:08.850\nI mean that is something\nthat is important.\n\n183\n00:10:08.850 --> 00:10:09.550\n&gt;&gt; Good point.\n\n184\n00:10:09.550 --> 00:10:12.490\n&gt;&gt; And maybe even stepping back\na little bit farther than that,\n\n185\n00:10:12.490 --> 00:10:16.940\nright, is the fact that if\nyou are implementing logs,\n\n186\n00:10:16.940 --> 00:10:18.390\nyou use them\n&gt;&gt; Right?\n\n187\n00:10:18.390 --> 00:10:20.990\nBecause logs, actually,\neven though they're just text files.\n\n188\n00:10:20.990 --> 00:10:23.240\nIn certain ways that they're\nimplemented within different systems,\n\n189\n00:10:23.240 --> 00:10:26.030\nthey can actually become\na performance degradation\n\n190\n00:10:26.030 --> 00:10:29.440\nbecause they start to accrue\ntoo much hard drive space.\n\n191\n00:10:29.440 --> 00:10:31.230\nAnd now your performance slows down.\n\n192\n00:10:31.230 --> 00:10:33.480\nAnd remember,\nwe talked about availability.\n\n193\n00:10:33.480 --> 00:10:35.230\nWe start to run into problems.\n\n194\n00:10:35.230 --> 00:10:37.880\n&gt;&gt; Yeah, if you have just\nsomething simple like a checklist,\n\n195\n00:10:37.880 --> 00:10:41.200\nmaybe a rotational job duty where\nyou have a person in charge of\n\n196\n00:10:41.200 --> 00:10:45.160\nclearing out those logs on particular\nservers at particular times.\n\n197\n00:10:45.160 --> 00:10:49.380\nBut It's interesting that you say, look,\ngo ahead and save those logs because if we\n\n198\n00:10:49.380 --> 00:10:52.940\ngo ahead even remove them off site\ndepending whatever your security policy\n\n199\n00:10:52.940 --> 00:10:58.240\nis, because while they may not seem\nimportant at that moment in time,\n\n200\n00:10:58.240 --> 00:11:01.460\nthey may present historical data\nafter an attack has occurred.\n\n201\n00:11:01.460 --> 00:11:04.100\nSo, you can analyze that and say hey,\nlook, did we miss something?\n\n202\n00:11:04.100 --> 00:11:08.930\nWere there any kind of, anything to offer,\nany kind of precautions that\n\n203\n00:11:08.930 --> 00:11:13.020\nwe can follow and make sure we can prevent\nthis in order from happening again.\n\n204\n00:11:13.020 --> 00:11:14.750\n&gt;&gt; Well,\nlike the concept lesson learned, right?\n\n205\n00:11:14.750 --> 00:11:17.060\nAfter we've seen attacks happen,\nwhen are we gonna turn around-\n\n206\n00:11:17.060 --> 00:11:18.250\n&gt;&gt; Hindsight's 20/20.\n\n207\n00:11:18.250 --> 00:11:21.570\n&gt;&gt; Exactly, we can always look\nback if we've got those logs.\n\n208\n00:11:21.570 --> 00:11:24.150\nBut for instance,\nlet's jump down to our Windows 10 machine.\n\n209\n00:11:24.150 --> 00:11:28.330\nLet's say somebody does get access to\nyour machine and you are not, you aren't,\n\n210\n00:11:28.330 --> 00:11:31.560\nexcuse me, backing up those\nlogs to an external location.\n\n211\n00:11:31.560 --> 00:11:35.080\nSo for instance,\nWindows Event Viewer here.\n\n212\n00:11:35.080 --> 00:11:36.000\nOldie but goodie.\n\n213\n00:11:36.000 --> 00:11:38.450\nAnother one that's been around for\na very long time.\n\n214\n00:11:38.450 --> 00:11:40.940\nThey have the security logs, right?\n\n215\n00:11:40.940 --> 00:11:44.630\nAnd security logs,\nyou can see her logging in information.\n\n216\n00:11:44.630 --> 00:11:46.020\nNow, we can change this,\n\n217\n00:11:46.020 --> 00:11:49.150\nyou can see it's success events\nthat are being recorded here.\n\n218\n00:11:49.150 --> 00:11:52.540\nBut we could also, I don't know if\nwe can filter to failed events.\n\n219\n00:11:52.540 --> 00:11:55.570\nI think it, just by default,\nit's all success events.\n\n220\n00:11:55.570 --> 00:12:00.940\nBut you can also audit things like\nfailed login attempts, right.\n\n221\n00:12:00.940 --> 00:12:03.370\nWell, why would failed login attempts and\nsuccessful,\n\n222\n00:12:03.370 --> 00:12:05.630\nthey're both just as\nimportant as each other.\n\n223\n00:12:05.630 --> 00:12:08.000\nSome people might tell you,\nmaybe the failed login attempts, or\n\n224\n00:12:08.000 --> 00:12:09.880\nmaybe the successful login attempts.\n\n225\n00:12:09.880 --> 00:12:14.350\nI really kinda think both are good for\npattern analysis, right,\n\n226\n00:12:14.350 --> 00:12:15.260\nlike you were saying.\n\n227\n00:12:15.260 --> 00:12:16.430\nWe review the fact, right?\n\n228\n00:12:16.430 --> 00:12:21.120\nSo let's say that we are reviewing these\nlogs, and I see these first seven logs, or\n\n229\n00:12:21.120 --> 00:12:28.050\nfirst whatever handful of logs have failed\nlogin attempt, failed login attempt,\n\n230\n00:12:28.050 --> 00:12:31.321\nfailed login attempt, failed login\nattempt, successful login attempt, okay?\n\n231\n00:12:31.321 --> 00:12:32.640\nWhat does that mean?\n\n232\n00:12:32.640 --> 00:12:34.380\nWell it might not mean anything.\n\n233\n00:12:34.380 --> 00:12:38.250\nIt might not mean a simple thing if I find\nout that it happened at Monday morning,\n\n234\n00:12:38.250 --> 00:12:40.010\n8:30 in the morning, right?\n\n235\n00:12:40.010 --> 00:12:44.860\nSomebody coming off the weekend and hasn't\nhad their coffee, doing like Wes types,\n\n236\n00:12:44.860 --> 00:12:47.280\nlearn the type from Wes and\nthe fat finger on the keyboard.\n\n237\n00:12:47.280 --> 00:12:50.289\nThey might have just entered their\npassword wrong and then that happens.\n\n238\n00:12:51.290 --> 00:12:55.270\nBut what happens if it's at 2:30 AM when\nnobody's supposed to be in the building?\n\n239\n00:12:55.270 --> 00:12:58.760\nWell that might tell me that there's some\nkind of sign of a brute force attack,\n\n240\n00:12:58.760 --> 00:13:00.670\na guessing attack, all right?\n\n241\n00:13:00.670 --> 00:13:02.220\nSo the failed log ins are just, for\n\n242\n00:13:02.220 --> 00:13:05.690\nme, seeing that information\nis just as important.\n\n243\n00:13:05.690 --> 00:13:08.800\nTo see that I had a failed log in,\nI had a series of failed log ins, and\n\n244\n00:13:08.800 --> 00:13:12.050\nthen also all of a sudden I had\na successful log in at 2:30 AM.\n\n245\n00:13:13.430 --> 00:13:15.090\nThat's a problem, right?\n\n246\n00:13:15.090 --> 00:13:18.150\nThat could be somebody that\nhas compromised your system.\n\n247\n00:13:18.150 --> 00:13:21.771\nNow back to the point of backing up,\nthat's redundant,\n\n248\n00:13:21.771 --> 00:13:24.420\nback to the point of backing up your logs.\n\n249\n00:13:24.420 --> 00:13:26.627\nWhy is that something that's important?\n\n250\n00:13:26.627 --> 00:13:27.482\nWell, let me show you.\n\n251\n00:13:27.482 --> 00:13:30.009\nOne of the last things that attackers do,\nwhat do you think they\n\n252\n00:13:30.009 --> 00:13:33.120\ndo when before they leave the system\nthey try to cover their tracks Cherokee?\n\n253\n00:13:33.120 --> 00:13:34.090\n&gt;&gt; Delete the logs.\n\n254\n00:13:34.090 --> 00:13:35.200\n&gt;&gt; Delete the logs, right?\n\n255\n00:13:35.200 --> 00:13:40.380\nSo if I come in here, and I see something\nwhere we've got this Clear Log option,\n\n256\n00:13:40.380 --> 00:13:44.720\nand I clear this log, notice it gives me\nthe option to save and clear it, right?\n\n257\n00:13:44.720 --> 00:13:47.530\nAnd we'll just,\nI'll save it to the desktop here.\n\n258\n00:13:47.530 --> 00:13:50.210\nAnd we'll call it Audit Log.\n\n259\n00:13:51.390 --> 00:13:57.680\nAudit Security, and see this is why you\nshould not have me typing on camera.\n\n260\n00:13:57.680 --> 00:14:01.340\nSecurity, I can spell, I swear.\n\n261\n00:14:01.340 --> 00:14:04.120\nLogs, couldn't prove it\nto you on camera though.\n\n262\n00:14:04.120 --> 00:14:06.350\nAnd now it's clear, all right?\n\n263\n00:14:06.350 --> 00:14:09.950\nWell, I backed it up,\nyou guys seen me back up the logs, here.\n\n264\n00:14:09.950 --> 00:14:14.530\nBut if I came in here And\nI see Audit Success, Eventlogs.\n\n265\n00:14:14.530 --> 00:14:15.740\nAnd I come in here and look at the event.\n\n266\n00:14:15.740 --> 00:14:19.310\nAnd there might be some kind of\nevent anomaly to me, because I say,\n\n267\n00:14:19.310 --> 00:14:22.750\nwell wait a second here,\nI didn't clear those logs.\n\n268\n00:14:22.750 --> 00:14:23.880\nCherokee's another admin.\n\n269\n00:14:23.880 --> 00:14:25.310\nShe didn't clear those logs.\n\n270\n00:14:25.310 --> 00:14:26.500\nWhat happened?\n\n271\n00:14:26.500 --> 00:14:29.490\nWell, if we are periodically\nbacking up the logs,\n\n272\n00:14:29.490 --> 00:14:34.550\nwe might have some kinda trend that we can\nsee, some information that we can view.\n\n273\n00:14:35.550 --> 00:14:38.890\nEven though we can tell that\nthe logs have been cleared, right?\n\n274\n00:14:38.890 --> 00:14:40.130\nCuz that's what hackers try to do.\n\n275\n00:14:40.130 --> 00:14:44.040\nAnd I keep saying hackers, understand that\nI mean in the context of an attacker.\n\n276\n00:14:44.040 --> 00:14:44.990\nHacking is not bad.\n\n277\n00:14:44.990 --> 00:14:46.460\nI mean attackers, right?\n\n278\n00:14:46.460 --> 00:14:51.970\nBut if we've backed up the logs we\nhave that information right here.\n\n279\n00:14:51.970 --> 00:14:55.220\nAnd it’s just as simple as\nclicking on the information.\n\n280\n00:14:55.220 --> 00:15:00.860\nIt throws it right back into Event Viewer,\nand it loads it right back up, right?\n\n281\n00:15:00.860 --> 00:15:05.600\nAnd we’ve got our logs that\nare now traceable, right?\n\n282\n00:15:05.600 --> 00:15:09.450\nWe see things like special privileges\nassigned to new login, right?\n\n283\n00:15:09.450 --> 00:15:11.690\nSo we can get that information.\n\n284\n00:15:11.690 --> 00:15:13.300\nWe can recover that information.\n\n285\n00:15:13.300 --> 00:15:15.140\nSo logs are important.\n\n286\n00:15:15.140 --> 00:15:18.020\nThis isn't the only place we have\nto worry about things like logs,\n\n287\n00:15:18.020 --> 00:15:22.160\nthings like syslogs inside of your\nnetwork devices if you have things like,\n\n288\n00:15:22.160 --> 00:15:24.000\nSNMP that's on your network.\n\n289\n00:15:24.000 --> 00:15:28.660\nWhere you're logging the state and\nhealth of your network devices.\n\n290\n00:15:28.660 --> 00:15:32.000\nWe need to make sure we're using\nthings like SNMP Version 3, right,\n\n291\n00:15:32.000 --> 00:15:36.990\nmore complex to set up but\nessentially more secure.\n\n292\n00:15:36.990 --> 00:15:40.160\nThat information is very important\nbecause if people can gain\n\n293\n00:15:40.160 --> 00:15:42.620\naccess to that information,\nwell guess what?\n\n294\n00:15:42.620 --> 00:15:45.190\nThey now have a lot of information\nabout your network and\n\n295\n00:15:45.190 --> 00:15:47.920\nthe state of those devices that\nare on your network right?\n\n296\n00:15:47.920 --> 00:15:52.830\nIt could be something for instance as\nsimple as a wireless router right?\n\n297\n00:15:52.830 --> 00:15:55.825\nSo if we're logged into this\nwireless router here, right?\n\n298\n00:15:55.825 --> 00:16:01.355\nAnd I log in and I see that I do not\nwanna add that to that last pass there.\n\n299\n00:16:01.355 --> 00:16:02.842\nThank you, last pass.\n\n300\n00:16:02.842 --> 00:16:04.640\nBut I go over to Administration, right?\n\n301\n00:16:04.640 --> 00:16:09.115\nIn Administration portion of this I\nhave a log and it's been disabled.\n\n302\n00:16:09.115 --> 00:16:11.886\nRight, well what if it was enabled before?\n\n303\n00:16:11.886 --> 00:16:14.199\nWell again, that might show you that\nthere's signs that somebody has\n\n304\n00:16:14.199 --> 00:16:15.105\ncompromised your system.\n\n305\n00:16:15.105 --> 00:16:19.157\nAnd if we enabled the logs we\ncan always view them, right.\n\n306\n00:16:19.157 --> 00:16:21.779\nAnd we might be looking at things,\nlike for instance,\n\n307\n00:16:21.779 --> 00:16:23.680\na few different types of logs, right.\n\n308\n00:16:23.680 --> 00:16:27.060\nIt might be something like incoming\npackets, outgoing packets,\n\n309\n00:16:27.060 --> 00:16:30.220\ncould be a security log, in this case\nwe're gonna look at the security log here.\n\n310\n00:16:30.220 --> 00:16:32.248\nBut it could be in the DHCB Client Log.\n\n311\n00:16:32.248 --> 00:16:35.190\nWell why would a DHCP Client Log\n\n312\n00:16:35.190 --> 00:16:37.910\nbe something that would be\nsecurity-related, right?\n\n313\n00:16:37.910 --> 00:16:43.160\nWell, if I see that a DHCP\naddress has been leased\n\n314\n00:16:43.160 --> 00:16:46.290\nto a device, and\nI look at the DHCP lease information, and\n\n315\n00:16:46.290 --> 00:16:49.100\nit started at four in the morning,\nwhen nobody should be in my building,\n\n316\n00:16:49.100 --> 00:16:52.340\nchances are, I've got somebody that's\ngot physical access to my network.\n\n317\n00:16:52.340 --> 00:16:56.160\nWhich is even worse than [LAUGH]\nany other log clearing for sure.\n\n318\n00:16:56.160 --> 00:16:59.700\nBut I can see that information if I have\naccess to the logs, but if we aren't\n\n319\n00:16:59.700 --> 00:17:05.790\nbacking up the logs, then we won't be,\nwe will not be privy to this information.\n\n320\n00:17:05.790 --> 00:17:08.139\nI know my head's kinda covering this up,\nbut if you look at it here,\n\n321\n00:17:09.460 --> 00:17:13.460\nthis might be the example of one of\nthose attacks that we're saying, okay.\n\n322\n00:17:13.460 --> 00:17:14.910\nIs it?\nI don't know, but\n\n323\n00:17:14.910 --> 00:17:17.680\nI could see Authentication failed,\nAuthentication failed,\n\n324\n00:17:17.680 --> 00:17:20.310\nAuthentication failed,\nall of a sudden we've got a success.\n\n325\n00:17:20.310 --> 00:17:20.840\n&gt;&gt; Yeah.\n\n326\n00:17:20.840 --> 00:17:22.790\n&gt;&gt; Could that be a guessing attack?\n\n327\n00:17:22.790 --> 00:17:24.338\nCould that be a brute force attack?\n\n328\n00:17:24.338 --> 00:17:27.440\nIt could be, but\nif the logs are cleared and\n\n329\n00:17:27.440 --> 00:17:32.090\nwe don't have that information this\nis gonna be a sign of a problem.\n\n330\n00:17:32.090 --> 00:17:35.530\nSo remember, you need to save these logs,\nback the logs up.\n\n331\n00:17:35.530 --> 00:17:38.360\nIf you're using SIEM systems,\npay attention to trending analysis,\n\n332\n00:17:38.360 --> 00:17:41.685\nsee if you can identify things like event\nanomalies, like something like this.\n\n333\n00:17:41.685 --> 00:17:42.325\nIt might be a long one.\n\n334\n00:17:42.325 --> 00:17:43.185\n&gt;&gt; Correlations.\n\n335\n00:17:43.185 --> 00:17:44.645\n&gt;&gt; Very good, absolutely.\n\n336\n00:17:44.645 --> 00:17:48.324\n&gt;&gt; And another thing is also whenever\nyou need to pull back in those backups\n\n337\n00:17:48.324 --> 00:17:51.715\nof the logs, and we've talked\nabout this in a previous episode.\n\n338\n00:17:51.715 --> 00:17:54.223\nBut we mentioned separation of duty, so\n\n339\n00:17:54.223 --> 00:17:57.855\nyou don't want any kind of\nscrutiny on the IT department.\n\n340\n00:17:57.855 --> 00:18:02.575\nSo let's say I was the one in charge\nof creating those log file backups and\n\n341\n00:18:02.575 --> 00:18:03.860\ntaking them off site.\n\n342\n00:18:03.860 --> 00:18:07.350\nWell, in the event that we needed to pull\nthose back in, then they really wouldn't\n\n343\n00:18:07.350 --> 00:18:10.460\nwant me to do it, they'd ask Wes to\ndo that, so that they couldn't say,\n\n344\n00:18:10.460 --> 00:18:13.550\nlook, Cherokee was trying to cover\nher tracks, or something like that.\n\n345\n00:18:13.550 --> 00:18:16.095\nWe wanna be completely\ntransparent in that department.\n\n346\n00:18:16.095 --> 00:18:17.020\n&gt;&gt; Definitely,\n\n347\n00:18:17.020 --> 00:18:20.170\nsome of the other things that they\ncall out too are permission issues.\n\n348\n00:18:20.170 --> 00:18:23.639\nAnd permission issues a lot\nof times are because people\n\n349\n00:18:25.480 --> 00:18:28.050\njust don't understand how\nthe permissions interact.\n\n350\n00:18:28.050 --> 00:18:32.800\nLike in Windows, Windows has got a pretty\ninteresting characteristics that you have\n\n351\n00:18:32.800 --> 00:18:35.430\nNTFS permissions that\nare called local permissions,\n\n352\n00:18:35.430 --> 00:18:37.480\nas well as share permissions, right.\n\n353\n00:18:37.480 --> 00:18:41.610\nAnd we have to understand that NTFS local\npermissions apply to the resource or\n\n354\n00:18:41.610 --> 00:18:46.960\nthe object when somebody is accessing it\nfrom the computer that it's on, right.\n\n355\n00:18:46.960 --> 00:18:48.230\nBut if I go over the network and\n\n356\n00:18:48.230 --> 00:18:50.570\nI connect back to the same machine,\nthat that resource is on,\n\n357\n00:18:50.570 --> 00:18:54.010\nnow I have a couple sets of permissions\nthat are actually being in place, right.\n\n358\n00:18:54.010 --> 00:18:56.360\nI've got NTFS permissions,\ncuz they always apply,\n\n359\n00:18:56.360 --> 00:18:58.860\ndoesn't matter where you're\naccessing the information.\n\n360\n00:18:58.860 --> 00:19:00.830\nBut now, because we're\naccessing it over the network,\n\n361\n00:19:00.830 --> 00:19:03.880\nwe also have share permissions, all right.\n\n362\n00:19:03.880 --> 00:19:07.250\nAnd let's go ahead, and let me show you,\nfor instance, an example of a file.\n\n363\n00:19:07.250 --> 00:19:11.390\nLet me pull up the ACL here on that\naudit log that I just created, right.\n\n364\n00:19:11.390 --> 00:19:15.360\nAnd most objects within Windows,\nlike many other systems,\n\n365\n00:19:15.360 --> 00:19:19.050\nare gonna have some kind of ACL,\nan access control list, right.\n\n366\n00:19:19.050 --> 00:19:21.280\nAnd when you look at things like,\nfor instance,\n\n367\n00:19:21.280 --> 00:19:23.930\nadministrators, right,\nadministrators have full control.\n\n368\n00:19:23.930 --> 00:19:29.720\nLet me see if I can edit this,\nit's inherited permissions but anyways,\n\n369\n00:19:30.940 --> 00:19:34.560\nif you look, if somebody has full control\npermissions when we're talking about local\n\n370\n00:19:34.560 --> 00:19:39.370\npermissions, they have all the other\nassociated permissions below it, right.\n\n371\n00:19:39.370 --> 00:19:42.900\nSo it's the highest level of permission,\nif you get the highest level of permission\n\n372\n00:19:42.900 --> 00:19:45.570\nyou're gonna get all lower permissions,\ntoo, right.\n\n373\n00:19:45.570 --> 00:19:49.786\nThat's just the way NTF permissions work,\nright, if I have modified permission that\n\n374\n00:19:49.786 --> 00:19:52.921\nmeans I also have read and execute,\nread and write permission.\n\n375\n00:19:52.921 --> 00:19:57.169\nBut when we couple in something like\nshare permissions on top of that it\n\n376\n00:19:57.169 --> 00:19:59.042\nworks a little bit different.\n\n377\n00:19:59.042 --> 00:20:02.917\nYou don't get all the permissions,\nIi I have Share,\n\n378\n00:20:02.917 --> 00:20:08.500\nRead permissions but I have full\ncontrol permissions on NTFS side.\n\n379\n00:20:08.500 --> 00:20:12.140\nWell when I sit at that computer where\nthe NTFS permissions are applying\n\n380\n00:20:12.140 --> 00:20:16.300\nbecause the share permissions are not,\nI have full control over that document.\n\n381\n00:20:16.300 --> 00:20:19.190\nBut when I go to my other\ncomputer let's say, and I connect\n\n382\n00:20:19.190 --> 00:20:23.900\nback to the same resource over the network\nand my share permissions are Read.\n\n383\n00:20:23.900 --> 00:20:24.680\nNow which ones apply?\n\n384\n00:20:25.690 --> 00:20:27.185\nWell when you're comparing NTFS and\n\n385\n00:20:27.185 --> 00:20:30.140\nShared permissions it's the most\nrestrictive that apply.\n\n386\n00:20:30.140 --> 00:20:34.630\nSo just because I have full\ncontrol NTFS permissions when\n\n387\n00:20:34.630 --> 00:20:38.630\nI'm accessing is over the network if I get\nRead permissions I can read the document.\n\n388\n00:20:38.630 --> 00:20:44.630\nI have no way to add information to those\nfiles or the document that's in question.\n\n389\n00:20:44.630 --> 00:20:46.230\nNow, where does that become a problem?\n\n390\n00:20:46.230 --> 00:20:47.770\nRemember the CIA triad?\n\n391\n00:20:47.770 --> 00:20:51.390\nIt's not only the confidentiality,\nit's also about availability.\n\n392\n00:20:51.390 --> 00:20:55.340\nAnd if you have an authorized user,\nthe principal says authorized users should\n\n393\n00:20:55.340 --> 00:20:59.172\nbe able to access the information\nif they're authorized, right.\n\n394\n00:20:59.172 --> 00:21:02.080\nAll right we also implement things\nlike the principle of least privilege.\n\n395\n00:21:02.080 --> 00:21:05.560\nBut if you can't give them access to\na document that they need to modify to do\n\n396\n00:21:05.560 --> 00:21:09.610\nproductivity work that's what\nyou're in business for, right.\n\n397\n00:21:09.610 --> 00:21:11.040\n&gt;&gt; You're working against yourself.\n\n398\n00:21:11.040 --> 00:21:14.620\n&gt;&gt; Most definitely, right, you're\nbasically fighting an incoming tide right.\n\n399\n00:21:14.620 --> 00:21:18.829\nWe have no productivity right, lack of\navailability to authorized users usually\n\n400\n00:21:18.829 --> 00:21:20.905\nequals limited productivity, right.\n\n401\n00:21:20.905 --> 00:21:22.561\nAnd that's not something that we want, and\n\n402\n00:21:22.561 --> 00:21:24.503\nit's something that hurts our business,\nright.\n\n403\n00:21:24.503 --> 00:21:27.807\nSo in the end it automatically\nhurts security, or\n\n404\n00:21:27.807 --> 00:21:33.460\nit could be something like this, maybe\nyou give somebody too much permission.\n\n405\n00:21:33.460 --> 00:21:37.940\nRight, remember, principle of least\nprivilege says you only give those\n\n406\n00:21:37.940 --> 00:21:41.640\nusers the level of access that they need,\nno more, no less.\n\n407\n00:21:41.640 --> 00:21:44.480\nBut you don't wanna burden anybody,\nso you give them full control.\n\n408\n00:21:44.480 --> 00:21:47.170\nAnd now you've given them too much\naccess and they can do things like,\n\n409\n00:21:47.170 --> 00:21:50.250\nif they were crafty enough,\ncan change permissions.\n\n410\n00:21:50.250 --> 00:21:53.890\n&gt;&gt; And it's usually that people will let\nyou know when they don't have enough\n\n411\n00:21:53.890 --> 00:21:54.930\npermissions, but\n\n412\n00:21:54.930 --> 00:22:00.430\nthey very seldomly let you know if they\nhave been given additional access.\n\n413\n00:22:00.430 --> 00:22:03.970\nSo, that's where we see things like\nour audits come in really handy.\n\n414\n00:22:03.970 --> 00:22:06.170\n&gt;&gt; And that's where access\nviolations come in, right,\n\n415\n00:22:06.170 --> 00:22:09.629\nwe talk about access violations\nthat might not be intentional.\n\n416\n00:22:10.640 --> 00:22:15.610\nUnderstand that you can have\nviolations of a security policy.\n\n417\n00:22:15.610 --> 00:22:17.870\nLet's step back,\nwhat's a violation of security policy?\n\n418\n00:22:17.870 --> 00:22:20.040\nNo that's not Tom Cruise\ndropping through the ceiling and\n\n419\n00:22:20.040 --> 00:22:24.160\nhanging on wires with night\nvision goggles, right.\n\n420\n00:22:24.160 --> 00:22:27.240\nA violation of a security policy\nis what a security breach,\n\n421\n00:22:27.240 --> 00:22:29.270\nthat's the definition\nof a security breach.\n\n422\n00:22:29.270 --> 00:22:31.156\nSecurity breach is nothing more than\na violation of a security policy.\n\n423\n00:22:31.156 --> 00:22:35.744\nSecurity breach could be the fact that you\ndidn't use the wireless network according\n\n424\n00:22:35.744 --> 00:22:39.836\nto the AUP acceptable use policy,\nthat could be a security breach, right.\n\n425\n00:22:39.836 --> 00:22:44.444\n&gt;&gt; Yeah, those incidents could be as\nsimple as a misconficured permission set\n\n426\n00:22:44.444 --> 00:22:45.310\nfor that ACL.\n\n427\n00:22:45.310 --> 00:22:47.021\n&gt;&gt; Then we have access violations and\n\n428\n00:22:47.021 --> 00:22:50.160\nwe know that goes against\nour security policy, right.\n\n429\n00:22:50.160 --> 00:22:53.200\nAnd that could be unintentional,\nit doesn't have to be intentional.\n\n430\n00:22:53.200 --> 00:22:56.960\nDoesn't have to be a malicious insider,\ndoesn't have to be somewhat external user,\n\n431\n00:22:56.960 --> 00:23:00.025\ndoesn't have to be a hacktivist,\ndoesn't have to be the nation states and\n\n432\n00:23:00.025 --> 00:23:02.930\nall of the other types of threat\nactors that we're talking about,\n\n433\n00:23:02.930 --> 00:23:05.080\nyou could be the problem.\n\n434\n00:23:05.080 --> 00:23:08.540\nNot you, you never wanna hear that,\nright, but, I have been in a situation,\n\n435\n00:23:08.540 --> 00:23:09.058\n&gt;&gt; It happens a lot.\n\n436\n00:23:09.058 --> 00:23:11.950\n&gt;&gt; It does, I've been in a situation\nwhere somebody mistakenly, and\n\n437\n00:23:11.950 --> 00:23:13.980\nthis person was MCSE.\n\n438\n00:23:13.980 --> 00:23:18.450\nRight, very, very good admin just\nhappened to make one mistake.\n\n439\n00:23:18.450 --> 00:23:21.602\nI don't know if it was because he was\nconfiguring Active Directory without\n\n440\n00:23:21.602 --> 00:23:22.962\nhaving his susceptible's on.\n\n441\n00:23:22.962 --> 00:23:23.926\n&gt;&gt; Overworked maybe?\n\n442\n00:23:23.926 --> 00:23:25.718\n&gt;&gt; Yep that could be,\nit could've been tired,\n\n443\n00:23:25.718 --> 00:23:29.660\nright, got the old two dimensional vision\nbecause he's looking at a screen so long.\n\n444\n00:23:29.660 --> 00:23:33.350\nAnd gave me Enterprise admin rights\nto an Active Directory domain,\n\n445\n00:23:33.350 --> 00:23:34.830\nyou should never do that.\n\n446\n00:23:34.830 --> 00:23:38.330\nRight, you only have, depending on\nhow big your company is, right.\n\n447\n00:23:38.330 --> 00:23:41.040\nI don't need enterprise level anything,\n\n448\n00:23:41.040 --> 00:23:44.690\nright, I rarely don't even\nneed domain admin privileges.\n\n449\n00:23:44.690 --> 00:23:48.590\nI was granted domain admin privileges for\ncertain aspects of my job, but\n\n450\n00:23:48.590 --> 00:23:50.260\nI really didn't even need that.\n\n451\n00:23:50.260 --> 00:23:51.730\nSo, you can see in that case,\n\n452\n00:23:51.730 --> 00:23:55.160\nnow we can have access violations\nthat are unintentional.\n\n453\n00:23:55.160 --> 00:23:57.745\nAnd you can actually have denial\nof service access, it was\n\n454\n00:23:57.745 --> 00:24:01.545\nkinda interesting how it's set up, because\nit made me the enterprise level admin and\n\n455\n00:24:01.545 --> 00:24:03.480\nit cleared the domain admins, every one.\n\n456\n00:24:03.480 --> 00:24:05.650\nI was the only one that can get\ninto the Active Directory domain.\n\n457\n00:24:06.820 --> 00:24:07.955\nThank goodness for backups.\n\n458\n00:24:07.955 --> 00:24:12.810\n[LAUGH] And authoritative\nActive Directory restores because\n\n459\n00:24:12.810 --> 00:24:17.949\nthey were able to get that in line,\nbut there that kinda shows you\n\n460\n00:24:17.949 --> 00:24:23.185\nwhere a simple configuration issue\ncould cause you a devastating\n\n461\n00:24:23.185 --> 00:24:29.000\nlevel of access violation at\nthe enterprise level, right?\n\n462\n00:24:29.000 --> 00:24:33.240\nOr It could be something as simple\nas a doorstop that's open, right?\n\n463\n00:24:33.240 --> 00:24:35.100\nI know that I'm just as guilty, right?\n\n464\n00:24:35.100 --> 00:24:37.650\nI can't sit here and say hey,\ndo as I say not as I do.\n\n465\n00:24:37.650 --> 00:24:40.630\nAnd I forget one of my keycards, right.\n\n466\n00:24:40.630 --> 00:24:43.470\nI leave my keycard at home,\nand well unfortunately,\n\n467\n00:24:43.470 --> 00:24:45.970\nI can't get to the different\nlocations within the building I need.\n\n468\n00:24:45.970 --> 00:24:46.510\nSo what do I do?\n\n469\n00:24:46.510 --> 00:24:50.090\nI don't want to bug anybody,\nI don't want to burden anybody, so\n\n470\n00:24:50.090 --> 00:24:51.300\nI put a doorstop in the door.\n\n471\n00:24:52.590 --> 00:24:56.770\nAnd now a $100,000 security system\nthat has motion sensors and\n\n472\n00:24:56.770 --> 00:25:01.360\nall the great low light cameras and\nRFID cards,\n\n473\n00:25:01.360 --> 00:25:06.580\nproximity cards has now been\ncompromised with a $0.50 door stop.\n\n474\n00:25:06.580 --> 00:25:10.330\nRight, so you have to keep in mind that\nthese things can happen very, very easily.\n\n475\n00:25:10.330 --> 00:25:12.850\nThey can be malicious,\nthey can be intentional, but\n\n476\n00:25:12.850 --> 00:25:15.180\nthey don't necessarily\nhave to be intentional.\n\n477\n00:25:15.180 --> 00:25:17.040\nSometimes they can be unintentional.\n\n478\n00:25:17.040 --> 00:25:18.150\n&gt;&gt; Sure.\n\n479\n00:25:18.150 --> 00:25:21.110\nNow, Wes, we're looking at the clock\nhere so we got a few minutes left.\n\n480\n00:25:21.110 --> 00:25:23.620\nDo you wanna go ahead and\ntake a look at our certificate issues?\n\n481\n00:25:23.620 --> 00:25:25.560\n&gt;&gt; I think we can,\nI think I can fit this in.\n\n482\n00:25:25.560 --> 00:25:28.910\nWe talked a lot about\ncertificates in the past, and\n\n483\n00:25:28.910 --> 00:25:33.890\nin our PKI endeavor we said that there\nare certain things we have to worry about.\n\n484\n00:25:33.890 --> 00:25:37.760\nSo for instance,\ngoing out across the Internet,\n\n485\n00:25:37.760 --> 00:25:42.370\nright, if we're doing e-commerce,\nwe go to a secure website.\n\n486\n00:25:42.370 --> 00:25:45.590\nThen one of the things that we do,\nwe have to worry about,\n\n487\n00:25:45.590 --> 00:25:51.590\nis essentially being presented\na certificate that is fraudulent.\n\n488\n00:25:51.590 --> 00:25:57.390\nWe do chain validation, we validate each\ncertificate going back up to the root.\n\n489\n00:25:57.390 --> 00:26:04.210\nThe problem is sometimes these\ncertificates can have issues, right?\n\n490\n00:26:04.210 --> 00:26:07.970\nAnd some of the issues are, could be\nthings like an expired certificate, right?\n\n491\n00:26:07.970 --> 00:26:09.460\nMaybe it's being presented to you.\n\n492\n00:26:09.460 --> 00:26:12.550\nYou've probably seen this,\nwhere you've gone to a website before, and\n\n493\n00:26:12.550 --> 00:26:14.080\nit's warned you in the web browser.\n\n494\n00:26:14.080 --> 00:26:18.560\nI know Internet Explorer probably makes\none of the best visualizations of this,\n\n495\n00:26:18.560 --> 00:26:21.440\nbecause the whole address bar glows red,\nright.\n\n496\n00:26:21.440 --> 00:26:25.390\nChrome does it where it puts text in\nthere, Internet Explorer also does this.\n\n497\n00:26:25.390 --> 00:26:26.980\nThey put text in there,\nit says warned you.\n\n498\n00:26:26.980 --> 00:26:30.980\nYour information isn't secured but\nboy you are red lighted immediately.\n\n499\n00:26:30.980 --> 00:26:32.308\n&gt;&gt; Danger, Will Robinson!\n\n500\n00:26:32.308 --> 00:26:33.600\n&gt;&gt; [LAUGH] That's right.\n\n501\n00:26:33.600 --> 00:26:36.470\nBecause the certificate expired, right?\n\n502\n00:26:36.470 --> 00:26:42.240\nI tell you what, let's go ahead, and let's\njump back down to our Windows 10 machine.\n\n503\n00:26:42.240 --> 00:26:45.150\nAnd if I happen to look at\nthe local certificate store,\n\n504\n00:26:45.150 --> 00:26:47.440\nyou can actually see\na certificate revocation list.\n\n505\n00:26:47.440 --> 00:26:48.580\nOops, it didn't pair.\n\n506\n00:26:48.580 --> 00:26:51.390\nI was a little bit faster than Cortana,\non that one.\n\n507\n00:26:51.390 --> 00:26:53.650\nMMC, and there she is.\n\n508\n00:26:53.650 --> 00:26:55.300\nShe got it.\nI was a little bit faster than her\n\n509\n00:26:55.300 --> 00:26:56.570\nwhen I hit it.\n\n510\n00:26:56.570 --> 00:26:59.360\nAll right, so let's go ahead and choose-\n&gt;&gt; Racing BAI.\n\n511\n00:26:59.360 --> 00:27:02.020\n&gt;&gt; That's right, racing Cortana.\n\n512\n00:27:02.020 --> 00:27:07.055\nSo for instance, if I put in certificates,\nright, just kind of a little recap here.\n\n513\n00:27:07.055 --> 00:27:10.795\nWe do have a certificate revocation\nlist that is baked right into the local\n\n514\n00:27:10.795 --> 00:27:12.965\ncertificate store within\na Windows machine.\n\n515\n00:27:12.965 --> 00:27:15.035\nAnd you can see it under\nIntermediate Trust or\n\n516\n00:27:15.035 --> 00:27:18.045\nIntermediate Certification Authorities.\n\n517\n00:27:18.045 --> 00:27:21.035\nSo for instance,\nremember here's our Root Authority.\n\n518\n00:27:21.035 --> 00:27:26.490\nWell if I am presented an application,\na website.\n\n519\n00:27:26.490 --> 00:27:31.720\nAnd it's digitally signed, and\nI don't have the root CA certificate\n\n520\n00:27:31.720 --> 00:27:36.290\nin here that's signed, that whole chain,\nit's not gonna be trusted by my machine.\n\n521\n00:27:36.290 --> 00:27:38.790\nBut also you can see things like\nCertificate Revocation List.\n\n522\n00:27:38.790 --> 00:27:39.710\nSo like for instance,\n\n523\n00:27:39.710 --> 00:27:42.820\nhere In the Intermediate Certificate,\nI was gonna do that.\n\n524\n00:27:42.820 --> 00:27:44.820\nCertification Authorities.\n\n525\n00:27:44.820 --> 00:27:47.110\nYou'll see the CRL here, right?\n\n526\n00:27:47.110 --> 00:27:49.990\nSo we can give you an example\nof like a Verisign CRL.\n\n527\n00:27:49.990 --> 00:27:52.450\nThis is an old one here,\nbut it's just as valid.\n\n528\n00:27:52.450 --> 00:27:54.860\nAnd we could open this up and\n\n529\n00:27:54.860 --> 00:27:59.840\nwe could see that there is our\ncertificate revocation list, right.\n\n530\n00:27:59.840 --> 00:28:03.760\nSo remember when a certificate expires or\n\n531\n00:28:03.760 --> 00:28:07.770\nis compromised, it's put in serial\nnumbers, put within this list.\n\n532\n00:28:07.770 --> 00:28:12.580\nAnd that's part of the validation process\nevery time you go to a website that says\n\n533\n00:28:12.580 --> 00:28:14.030\nHTTPS.\n\n534\n00:28:14.030 --> 00:28:18.830\nNow if that happens and you don't\nget that little green light, right?\n\n535\n00:28:18.830 --> 00:28:22.070\nLet's say you get something\nlike this right here,\n\n536\n00:28:22.070 --> 00:28:25.950\nall right Notice it says not secure,\nright?\n\n537\n00:28:25.950 --> 00:28:31.070\nI have an HTTPS, and\nit's kinda lined out there, right?\n\n538\n00:28:31.070 --> 00:28:33.670\nNow, this is not, by the way,\nI love this website.\n\n539\n00:28:33.670 --> 00:28:35.130\nThis is a really, really cool website.\n\n540\n00:28:35.130 --> 00:28:37.310\nThis is not a fraudulent website.\n\n541\n00:28:37.310 --> 00:28:41.160\nAnd you can see their good certificates\ngo right back up to the highest CAs.\n\n542\n00:28:41.160 --> 00:28:47.490\nBut this is for showing you what bad\ncertificates would look like right?\n\n543\n00:28:47.490 --> 00:28:49.382\nSo for instance broken HTTPS.\n\n544\n00:28:49.382 --> 00:28:53.220\nI can see that there is a issue\nwith this certificate all right.\n\n545\n00:28:53.220 --> 00:28:56.610\nAnd it tells me kind of what\nthe issue is here right?\n\n546\n00:28:56.610 --> 00:28:59.540\nError cert date invalid right?\n\n547\n00:28:59.540 --> 00:29:02.850\nThat's a common,\nit's not a commonality with certificates,\n\n548\n00:29:02.850 --> 00:29:05.428\nbut that's the error\nit's a standard right?\n\n549\n00:29:05.428 --> 00:29:06.086\n&gt;&gt; Potential error.\n\n550\n00:29:06.086 --> 00:29:06.810\n&gt;&gt; That's right.\n\n551\n00:29:06.810 --> 00:29:10.300\nAnd notice that it tells me\nthis certificate has expired.\n\n552\n00:29:10.300 --> 00:29:12.230\nWell I shouldn't trust this certificate.\n\n553\n00:29:12.230 --> 00:29:17.470\nIn fact, I shouldn't put any\ninformation inside of this type\n\n554\n00:29:17.470 --> 00:29:23.050\nof website if I see this kind of,\nkind of certificate.\n\n555\n00:29:23.050 --> 00:29:26.290\nSo for instance, I'm showing you guys,\nand let me just be careful with this one,\n\n556\n00:29:26.290 --> 00:29:28.170\nbecause this is a good website, right?\n\n557\n00:29:28.170 --> 00:29:32.930\nThey are endorsed all the way back\nup to the top, Komodo, again,\n\n558\n00:29:32.930 --> 00:29:36.250\nwhich is a top level RCA.\n\n559\n00:29:36.250 --> 00:29:39.377\nRight, you can do things like on untrusted\nroot, this is an interesting one.\n\n560\n00:29:39.377 --> 00:29:41.800\nThis is really what I wanted\nto kind of show here.\n\n561\n00:29:41.800 --> 00:29:43.740\nBecause if you look,\nwhat does it say here?\n\n562\n00:29:43.740 --> 00:29:47.220\nWith this certificate,\nI've got a certificate right?\n\n563\n00:29:47.220 --> 00:29:48.670\nBut it says your connection\nis not private and\n\n564\n00:29:49.680 --> 00:29:51.630\nthen it gives me an error detail, right?\n\n565\n00:29:51.630 --> 00:29:53.510\nError, Cert_Authority_Invalid.\n\n566\n00:29:53.510 --> 00:29:56.220\nWell, that could be a problem right?\n\n567\n00:29:56.220 --> 00:30:01.020\nAnd if I look and view the certificate,\nI don't see a certificate chain, right?\n\n568\n00:30:01.020 --> 00:30:05.001\nI see a wildcard here for badssl.com.\n\n569\n00:30:05.001 --> 00:30:06.770\nWho is that?\n\n570\n00:30:06.770 --> 00:30:13.330\nWell I don't know let me drop back down\nto my root certification authority right?\n\n571\n00:30:13.330 --> 00:30:21.960\nAnd, Run this real quick.\n\n572\n00:30:21.960 --> 00:30:24.430\nAgain just a little bit faster than\nthe search functionality on that.\n\n573\n00:30:25.660 --> 00:30:31.790\nRight, do I have one of\nthose bad SSL if you will,\n\n574\n00:30:31.790 --> 00:30:36.360\nroot certificates down in that\ncertificate trusted root authority?\n\n575\n00:30:36.360 --> 00:30:39.400\nWell I don't know, let's find out, right?\n\n576\n00:30:39.400 --> 00:30:42.180\nAnd this is the process that\nyour computer goes through every\n\n577\n00:30:42.180 --> 00:30:44.210\ntime is tries to do one\nof these validations.\n\n578\n00:30:44.210 --> 00:30:46.640\nRemember it's going to look to\nthat trusted root authority,\n\n579\n00:30:46.640 --> 00:30:51.070\ncertification authority, and\nit's gonna say, do I find bad SSL here?\n\n580\n00:30:51.070 --> 00:30:56.540\nAnd they're alphabetized, so I could see\nup at the top, I don't have that, right?\n\n581\n00:30:56.540 --> 00:31:00.410\nSo again you can see that there are times\nwhen you have things like a root\n\n582\n00:31:00.410 --> 00:31:01.860\ncertificate that aren't entrusted.\n\n583\n00:31:01.860 --> 00:31:05.490\nLet me show you, you know and it's one\nplace that this can happen a lot and.\n\n584\n00:31:05.490 --> 00:31:09.350\nIn fact one of our members just mentioned\nit in the chat room right now talks about\n\n585\n00:31:09.350 --> 00:31:11.230\nfor instance a sonic firewall.\n\n586\n00:31:11.230 --> 00:31:14.080\nRight?\nThere's other types of software where you\n\n587\n00:31:14.080 --> 00:31:16.480\nuse a self-signed certificate, right?\n\n588\n00:31:16.480 --> 00:31:20.500\nAnd it's the software itself\nthat you're going to HTTPS.\n\n589\n00:31:20.500 --> 00:31:24.000\nIt is encrypted communication,\nbut it is a self-signed\n\n590\n00:31:24.000 --> 00:31:27.410\ncertificate by the product itself and\nit's letting you know not to trust it.\n\n591\n00:31:27.410 --> 00:31:33.510\nBut you know that it's the web management\ninterface to that network device, right?\n\n592\n00:31:33.510 --> 00:31:38.070\nIt's just the network device itself that\nissues the certificate, it isn't found\n\n593\n00:31:38.070 --> 00:31:43.170\nin your root certification authorities,\nso again it isn't trusted.\n\n594\n00:31:43.170 --> 00:31:47.730\nAll right, one of the other things\nI want to mention is that sometimes\n\n595\n00:31:47.730 --> 00:31:52.100\nwhen they talk about certificate errors,\nyou might be none the wiser.\n\n596\n00:31:52.100 --> 00:31:53.590\nLet me show you what I mean here.\n\n597\n00:31:53.590 --> 00:31:58.493\nAll right, so, imagine a situation\nwhere you go to a website, right,\n\n598\n00:31:58.493 --> 00:32:00.720\nand when you go to this website.\n\n599\n00:32:00.720 --> 00:32:02.215\nLet me see if I can find it here.\n\n600\n00:32:06.910 --> 00:32:08.134\nYou know, I'm not finding it here.\n\n601\n00:32:08.134 --> 00:32:13.191\nI was gonna show you,\nthey did have one where it was TLS 1.0 and\n\n602\n00:32:13.191 --> 00:32:14.980\nit would be accepted.\n\n603\n00:32:14.980 --> 00:32:22.240\nBut it's basically a weaker cipher suite,\nnope, this one's saying not secure.\n\n604\n00:32:22.240 --> 00:32:28.208\nThere's sometimes when TLS even TLS 1.0,\nlet's see here,\n\n605\n00:32:28.208 --> 00:32:32.861\nbadssl, let's call it secure,\nokay here we go.\n\n606\n00:32:32.861 --> 00:32:35.390\nAnd this is what I was talking about,\nright?\n\n607\n00:32:35.390 --> 00:32:37.719\nNotice that we have a secure connection.\n\n608\n00:32:38.980 --> 00:32:40.690\nI should trust it, right?\n\n609\n00:32:40.690 --> 00:32:41.530\nIt says secure.\n\n610\n00:32:41.530 --> 00:32:42.390\nI can see it right here.\n\n611\n00:32:42.390 --> 00:32:43.190\nIt's green, it's lit up.\n\n612\n00:32:44.250 --> 00:32:49.910\nBut under the hood,\nI want you to notice something.\n\n613\n00:32:49.910 --> 00:32:53.490\nNotice that it says,\nthis is a secure page.\n\n614\n00:32:54.860 --> 00:32:57.840\nHTTPS, Valid Certificate.\n\n615\n00:32:57.840 --> 00:33:01.730\nThe connection to this site is using\na valid, trusted server certificate.\n\n616\n00:33:02.750 --> 00:33:03.370\nWe're good, right?\n\n617\n00:33:03.370 --> 00:33:03.970\nI should trust it.\n\n618\n00:33:05.070 --> 00:33:06.310\nNot necessarily.\n\n619\n00:33:06.310 --> 00:33:08.440\nIf we scroll down a little\nbit more in this information,\n\n620\n00:33:08.440 --> 00:33:10.570\nI want you to see what it says.\n\n621\n00:33:10.570 --> 00:33:13.795\nSecure Connection, the connection\nto this site is encrypted and\n\n622\n00:33:13.795 --> 00:33:17.500\nauthenticated using a strong protocol\nusing, and that's not the one.\n\n623\n00:33:17.500 --> 00:33:19.460\nThey're actually doing\na good job on this one.\n\n624\n00:33:19.460 --> 00:33:21.190\nI wish I could find the one that was 1.0.\n\n625\n00:33:21.190 --> 00:33:24.070\nThey had one up here that\nwas using TLS 1.0, and\n\n626\n00:33:25.450 --> 00:33:29.950\nI don't seem to be able\nto find it in the list.\n\n627\n00:33:29.950 --> 00:33:31.864\nOkay, here's sha1.\n\n628\n00:33:31.864 --> 00:33:33.810\nAnd again, most of these will be caught.\n\n629\n00:33:33.810 --> 00:33:39.630\nBut there are times when a weaker\ncipher suite might be used,\n\n630\n00:33:39.630 --> 00:33:43.260\nand something like that,\nyou might see as secure, right?\n\n631\n00:33:43.260 --> 00:33:44.848\nAnd I can't seem to find one right now.\n\n632\n00:33:44.848 --> 00:33:48.650\n[LAUGH] Chrome is doing its job, right?\n\n633\n00:33:48.650 --> 00:33:50.920\nBut you might see something\nwhere it's defaulted.\n\n634\n00:33:50.920 --> 00:33:56.105\nIt says it's secure, it says it's trusted,\nbut you come down here to the connection\n\n635\n00:33:56.105 --> 00:34:00.510\ninformation, and it says it's using\nsomething like TLS 1.0 right?\n\n636\n00:34:00.510 --> 00:34:05.130\nAnd it isn't maybe,\nit's not using a very strong key exchange.\n\n637\n00:34:05.130 --> 00:34:08.741\nSo these are issues too that might\ngive you the green light for\n\n638\n00:34:08.741 --> 00:34:12.330\nchecking the website and maybe\nputting your information in there when\n\n639\n00:34:12.330 --> 00:34:15.900\nunder the hood it's actually\nusing a weaker cipher strength.\n\n640\n00:34:15.900 --> 00:34:17.360\nAnd that could cause problems, as well.\n\n641\n00:34:17.360 --> 00:34:20.770\nSo you have to keep in mind,\npay attention if you are doing e-commerce.\n\n642\n00:34:20.770 --> 00:34:22.522\nEspecially if you're in your own business,\nand\n\n643\n00:34:22.522 --> 00:34:24.370\nyou don't want that\ninformation to get out there.\n\n644\n00:34:24.370 --> 00:34:28.540\nImplement TLS 1.2,\nlike you can see that these website are.\n\n645\n00:34:28.540 --> 00:34:32.650\nDo not be using the older cipher suites,\nbecause of the fact that things like SSL.\n\n646\n00:34:32.650 --> 00:34:35.540\nThey allow you to negotiate\na weaker cipher strength.\n\n647\n00:34:35.540 --> 00:34:38.410\nTLS doesn't allow that\nweaker negotiation there.\n\n648\n00:34:38.410 --> 00:34:41.800\nIt says you got 1.2,\nthat's what we're gonna use.\n\n649\n00:34:41.800 --> 00:34:44.180\nIf you don't use it,\nthen we're not gonna allow the connection.\n\n650\n00:34:44.180 --> 00:34:47.300\nSo you do have to keep in mind that\nsometimes the certificate will\n\n651\n00:34:47.300 --> 00:34:49.260\nappear secure and it really isn't.\n\n652\n00:34:49.260 --> 00:34:52.214\nSo just knowing what's under\nthe hood is a good start.\n\n653\n00:34:52.214 --> 00:34:55.651\n&gt;&gt; All right Wes, I wish that I could say\nthat we are finished looking at different\n\n654\n00:34:55.651 --> 00:34:57.920\ntypes of security issues\nthat we may encounter.\n\n655\n00:34:57.920 --> 00:34:59.160\nHowever, we're not.\n\n656\n00:34:59.160 --> 00:35:02.015\nBut before we wrap up this particular\nepisode, is there anything else you want\n\n657\n00:35:02.015 --> 00:35:04.237\nto go ahead and throw out there,\nany kind of final thoughts?\n\n658\n00:35:04.237 --> 00:35:08.000\n&gt;&gt; Yeah, I got to give props\nto the chat room out there.\n\n659\n00:35:08.000 --> 00:35:09.590\nSome people have been to this website and\n\n660\n00:35:09.590 --> 00:35:11.240\nthey helped me get to\nwhere I needed to go.\n\n661\n00:35:11.240 --> 00:35:14.226\nIf we can take a look at\nmy screen one more time.\n\n662\n00:35:14.226 --> 00:35:19.178\nWhen you're on this website if you hit the\ndashboard, right, again, it is badssl.com,\n\n663\n00:35:19.178 --> 00:35:22.410\nif you hit the dashboard\nit takes you to this list.\n\n664\n00:35:22.410 --> 00:35:25.760\nAnd what I really wanted to show you is\nthat there are some legacy protocols.\n\n665\n00:35:25.760 --> 00:35:30.360\nAnd more so than that, how the connection\ncan look like it's secure, but\n\n666\n00:35:30.360 --> 00:35:34.060\nwhen the underlying cipher suite is\nweak you might not be aware of that.\n\n667\n00:35:34.060 --> 00:35:36.510\nSo for instance if I click on this one,\n\n668\n00:35:36.510 --> 00:35:40.180\nyou can see plainly they're\ntelling us this is TLS 1.0, right?\n\n669\n00:35:40.180 --> 00:35:44.000\nSo we can see that it says bad because\nthank goodness they're letting us know.\n\n670\n00:35:44.000 --> 00:35:50.930\nBut if I look up here, I don't see any\nwarning of any kind of vulnerability.\n\n671\n00:35:50.930 --> 00:35:55.040\nI have to go back to the certificate\ninformation right, to see that.\n\n672\n00:35:55.040 --> 00:35:59.790\nAnd if I bring back that certificate\ninformation, notice what I can see,\n\n673\n00:35:59.790 --> 00:36:01.330\nsame thing that we seen before.\n\n674\n00:36:01.330 --> 00:36:03.520\nIt said this page is secure.\n\n675\n00:36:03.520 --> 00:36:05.330\nIt's a valid certificate.\n\n676\n00:36:05.330 --> 00:36:07.720\nBut when you scroll down,\nsecure resources,\n\n677\n00:36:07.720 --> 00:36:10.469\nit says all resources on this\npage are served securely.\n\n678\n00:36:11.880 --> 00:36:14.860\nBut with an obsolete connection setting.\n\n679\n00:36:14.860 --> 00:36:16.850\nNotice it's TLS 1.0.\n\n680\n00:36:16.850 --> 00:36:19.260\nAgain it's a weaker cipher strength.\n\n681\n00:36:19.260 --> 00:36:25.520\nAnd this one may or may not be as\nbad as a untrusted certificate.\n\n682\n00:36:25.520 --> 00:36:29.514\nBut it is a weaker cipher strength\nthan the security context that always\n\n683\n00:36:29.514 --> 00:36:31.390\nrepresents a vulnerability.\n\n684\n00:36:31.390 --> 00:36:32.230\n&gt;&gt; Alright Wes, thank you for\n\n685\n00:36:32.230 --> 00:36:34.480\nthat and thank you ladies and\ngentlemen for joining us.\n\n686\n00:36:34.480 --> 00:36:37.620\nBut we do have more information\nto cover so stayed tuned.\n\n687\n00:36:37.620 --> 00:36:39.120\nFor this show we'll go ahead and sign out.\n\n688\n00:36:39.120 --> 00:36:40.980\nRemember I'm your host Cherokee Boose.\n\n689\n00:36:40.980 --> 00:36:41.760\n&gt;&gt; And I'm Wes Bryan.\n\n690\n00:36:41.760 --> 00:36:45.136\n&gt;&gt; See you next time here at ITProTV.\n\n691\n00:36:45.136 --> 00:36:50.981\n[MUSIC]\n\n692\n00:36:50.981 --> 00:36:54.248\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "214665466"
        },
        {
          "description": "In this show, Cherokee and Wes continue to examine common issues that one may encounter.  They point out insecure protocols, missing log information, permission issues, access violations and more. Tune in now to learn techniques and tips that may help mitigate problems one might face.",
          "length": "1388",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-3-2-troubleshoot_common_security_issues_pt2-042717.00_22_52_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-3-2-troubleshoot_common_security_issues_pt2-042717.00_22_52_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-3-2-troubleshoot_common_security_issues_pt2-042717.00_22_52_23.Still001-sm.jpg",
          "title": "Troubleshoot Common Security Issues Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:01.190\nWelcome to ITProTV.\n\n2\n00:00:01.190 --> 00:00:03.455\nI'm your host Don Pezet.\n\n3\n00:00:03.455 --> 00:00:06.474\n[CROSSTALK]\n\n4\n00:00:06.474 --> 00:00:08.281\n[MUSIC]\n\n5\n00:00:08.281 --> 00:00:12.147\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:12.147 --> 00:00:15.150\n&gt;&gt; Welcome, ladies and gentlemen,\nto your security plus series.\n\n7\n00:00:15.150 --> 00:00:16.940\nI'm your show host, Cherokee Boose.\n\n8\n00:00:16.940 --> 00:00:19.500\nI'm super excited to be back in\nstudios here with the part two\n\n9\n00:00:19.500 --> 00:00:23.740\nto help you understand different types of\nissues, common troubleshooting issues,\n\n10\n00:00:23.740 --> 00:00:25.710\nthat you may encounter out in the field.\n\n11\n00:00:25.710 --> 00:00:28.250\nAnd of course for that certification exam.\n\n12\n00:00:28.250 --> 00:00:31.110\nBack in studio with us today,\nwe have Mr. Wes Bryan.\n\n13\n00:00:31.110 --> 00:00:32.090\nThank you for joining us, Wes.\n\n14\n00:00:32.090 --> 00:00:33.460\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n15\n00:00:33.460 --> 00:00:35.450\nThat's right,\nwe got a part two coming at you,\n\n16\n00:00:35.450 --> 00:00:39.670\nbecause we got a few more things that\nwe kinda wanna wrap up in this episode.\n\n17\n00:00:39.670 --> 00:00:42.740\nWe left off, we were talking about\nin the last episode things like\n\n18\n00:00:42.740 --> 00:00:44.520\nunencrypted credentials, right?\n\n19\n00:00:44.520 --> 00:00:48.520\nYou never want to be logging into\nprotocols that are unencrypted because\n\n20\n00:00:48.520 --> 00:00:53.880\nthe fact that you do run the risk of\nan eavesdropping, confidentiality is lost.\n\n21\n00:00:53.880 --> 00:00:58.446\nThings like Cleartech's protocol,\nwe mentioned things like FTP, Telnet,\n\n22\n00:00:58.446 --> 00:01:00.323\nif you will, these HTTP right?\n\n23\n00:01:00.323 --> 00:01:02.796\nIt's one of the reasons\nwe want to go to HTTPS.\n\n24\n00:01:02.796 --> 00:01:05.905\nYou want to use SSh with FTTP or SSL.\n\n25\n00:01:05.905 --> 00:01:07.906\nYou do an SSL certificate, if you will.\n\n26\n00:01:07.906 --> 00:01:10.460\nTLS more common today.\n\n27\n00:01:10.460 --> 00:01:13.850\nAnd you can encrypt that communication\nbetween the destination and\n\n28\n00:01:13.850 --> 00:01:16.460\nthe end point or between both end points.\n\n29\n00:01:16.460 --> 00:01:18.840\nWe also talked about things like our logs,\nright?\n\n30\n00:01:18.840 --> 00:01:21.270\nWe have to keep those safe and secure.\n\n31\n00:01:21.270 --> 00:01:25.060\nTalked about permission issues,\nand then access violations, right?\n\n32\n00:01:25.060 --> 00:01:28.970\nAccess violations could be because your\npermission issues is not set right.\n\n33\n00:01:28.970 --> 00:01:31.750\nIt could be the fact that you are allowing\nsomebody to log into a system that\n\n34\n00:01:31.750 --> 00:01:33.070\nmaybe they shouldn't have access to.\n\n35\n00:01:33.070 --> 00:01:35.336\nSo when it comes to access violations,\njust remember,\n\n36\n00:01:35.336 --> 00:01:37.567\nimplement the principle at\nleast privilege, right?\n\n37\n00:01:37.567 --> 00:01:40.728\nYou only give the users exactly\nwhat they need to do their jobs.\n\n38\n00:01:40.728 --> 00:01:41.900\nNo more, no less.\n\n39\n00:01:41.900 --> 00:01:46.580\nIf you do less, then the availability\npart starts to wane, right?\n\n40\n00:01:46.580 --> 00:01:48.700\nSo we gotta keep that in mind.\n\n41\n00:01:48.700 --> 00:01:51.560\nWe also talked about things\nlike certificate issues.\n\n42\n00:01:51.560 --> 00:01:53.400\nKeep in mind,\nthere's a whole bunch of them.\n\n43\n00:01:53.400 --> 00:01:56.750\nIf you didn't see some of those\ncertificate issues that we mentioned,\n\n44\n00:01:56.750 --> 00:01:59.730\ngo back and check that out and\nthen come back and watch this one.\n\n45\n00:02:01.040 --> 00:02:05.450\nWe also talked a little bit, and\nI'm actually not sure if I mentioned this,\n\n46\n00:02:05.450 --> 00:02:09.840\nbut I do wanna talk a little\nbit about data exfiltration.\n\n47\n00:02:09.840 --> 00:02:14.770\nKeep in mind that we implement\nthings like ACLs, network isolation.\n\n48\n00:02:14.770 --> 00:02:19.040\nWe wanna make sure that people can't\ntake information off of our networks.\n\n49\n00:02:19.040 --> 00:02:21.580\nAnd that doesn't necessarily\nmean that it's intentional, too.\n\n50\n00:02:21.580 --> 00:02:25.580\nEspecially with the prevalence today\nof things like mobile devices on your\n\n51\n00:02:25.580 --> 00:02:27.060\nnetwork, as we talked about.\n\n52\n00:02:27.060 --> 00:02:30.380\nFor instance, BYOD,\nwe have to have MDM solutions,\n\n53\n00:02:30.380 --> 00:02:33.922\nmobile device management solutions, to\nmake sure that if people are using things\n\n54\n00:02:33.922 --> 00:02:36.710\nlike cell phones,\nthat if we're under a HIPAA compliance,\n\n55\n00:02:36.710 --> 00:02:41.140\nif we're under a PCI-type payment card\nindustry type standard, that people aren't\n\n56\n00:02:41.140 --> 00:02:44.410\ntaking that information, pulling it down\nto their mobile devices and then walking\n\n57\n00:02:44.410 --> 00:02:48.080\noff of your network with it because that\ncould be an access violation, right?\n\n58\n00:02:48.080 --> 00:02:51.770\nIt would be evaluation of the standards\nthat your company is trying to comply with\n\n59\n00:02:51.770 --> 00:02:54.350\nthat could really cause\nthe company a lot of money.\n\n60\n00:02:54.350 --> 00:02:56.250\nWe've mentioned things in\nthe past like the target,\n\n61\n00:02:56.250 --> 00:03:00.029\nI think Cherokee, you mentioned like, for\ninstance, things like systems, right?\n\n62\n00:03:00.029 --> 00:03:04.000\nIt's one of the things that allowed people\ninto the target networks that we have\n\n63\n00:03:04.000 --> 00:03:06.870\na lot of that information that was\nscraped off of their networks, right?\n\n64\n00:03:06.870 --> 00:03:09.350\nThat's a form of data exfiltration.\n\n65\n00:03:09.350 --> 00:03:13.900\nSo keep in mind things\nlike VPN communications.\n\n66\n00:03:13.900 --> 00:03:16.140\nNo clear text communications.\n\n67\n00:03:16.140 --> 00:03:19.790\nUsing things like HTTPS and your\npermissions and ACLs to make sure that\n\n68\n00:03:19.790 --> 00:03:22.970\nthe data that is supposed to stay on\nyour network stays on your network.\n\n69\n00:03:22.970 --> 00:03:25.950\nAnd even more importantly that\nthe people that are authorized to\n\n70\n00:03:25.950 --> 00:03:28.390\nhave access to that information,\nhave access to it, and\n\n71\n00:03:28.390 --> 00:03:32.030\nthe people that aren't authorized\ndon't have access to that information.\n\n72\n00:03:33.120 --> 00:03:35.860\nThey also talk about different\nthings like mis-configured devices.\n\n73\n00:03:35.860 --> 00:03:39.175\nAnd there are quite a few different things\nthat we can look at when it comes to\n\n74\n00:03:39.175 --> 00:03:40.670\nmis-configured devices.\n\n75\n00:03:40.670 --> 00:03:44.430\nTalk about configuration issues,\nthings like firewalls.\n\n76\n00:03:44.430 --> 00:03:45.850\nIt's not uncommon.\n\n77\n00:03:45.850 --> 00:03:49.350\nI know we kinda joke around about it and\nwe've mentioned it throughout the series.\n\n78\n00:03:49.350 --> 00:03:52.990\nWe say, well, disable the firewall,\nthat's gonna solve your problem, right?\n\n79\n00:03:52.990 --> 00:03:55.238\nSometimes people use that as\na troubleshooting method.\n\n80\n00:03:55.238 --> 00:03:58.170\nRight now, albeit,\nit should be the last ditch effort,\n\n81\n00:03:58.170 --> 00:03:59.420\njust try everything else, right?\n\n82\n00:03:59.420 --> 00:04:03.522\nBut if somebody forgets to\nturn that firewall back on,\n\n83\n00:04:03.522 --> 00:04:06.540\nthen we can have problems.\n\n84\n00:04:06.540 --> 00:04:08.580\nThe other thing I wanna mention\nabout firewalls, too, right,\n\n85\n00:04:08.580 --> 00:04:11.830\nwhen you a firewall or an ACL,\nright, you have incoming traffic.\n\n86\n00:04:11.830 --> 00:04:15.570\nAnd when a firewall looks at the rules\nthat it has in its database,\n\n87\n00:04:15.570 --> 00:04:18.210\nwhat it's going to do is it's\ngoing to find the traffic and\n\n88\n00:04:18.210 --> 00:04:21.280\nit's going to find the first rule that\nmatches whatever that traffic is.\n\n89\n00:04:21.280 --> 00:04:24.870\nAnd you have to keep in mind\nthat if you have rules below\n\n90\n00:04:24.870 --> 00:04:26.390\nthey might never get processed, right?\n\n91\n00:04:26.390 --> 00:04:28.290\nThey might not get processed at all.\n\n92\n00:04:28.290 --> 00:04:29.030\nAnd why is that?\n\n93\n00:04:29.030 --> 00:04:31.490\nWell, you have to think about\nhow an ACL is going to work.\n\n94\n00:04:31.490 --> 00:04:35.130\nIt's going to look at your data, it's\ngoing to look at your ACL entries, right?\n\n95\n00:04:35.130 --> 00:04:39.640\nAnd in those entries, if it finds a match,\nits gonna process that match and\n\n96\n00:04:39.640 --> 00:04:41.260\nits never gonna go to the rules below it.\n\n97\n00:04:41.260 --> 00:04:44.960\nSo you also have to keep in\nmind that order that you have,\n\n98\n00:04:44.960 --> 00:04:46.970\nyour rules applied inside of a firewall.\n\n99\n00:04:46.970 --> 00:04:51.250\nIt could be problems, and\nit could be that either it's a little bit\n\n100\n00:04:51.250 --> 00:04:54.150\ntoo restrictive or maybe the fact\nthat it's not restrictive enough.\n\n101\n00:04:54.150 --> 00:04:57.330\nSome of the other things that we talk\nabout are things like content filters.\n\n102\n00:04:57.330 --> 00:05:00.030\nKeep in mind, content filters could\nbe a couple of things, right?\n\n103\n00:05:00.030 --> 00:05:01.820\nThe lack thereof.\n\n104\n00:05:01.820 --> 00:05:04.830\nMaybe there's certain things that you\ndon't want your end users seeing.\n\n105\n00:05:04.830 --> 00:05:06.610\nSome of the obvious things.\n\n106\n00:05:06.610 --> 00:05:09.380\nThe risque sites that you\nguys are aware of out there.\n\n107\n00:05:09.380 --> 00:05:11.200\nBut it could be something as\nsimple as things like, for\n\n108\n00:05:11.200 --> 00:05:15.250\ninstance, sites that are known for\nphishing attacks, right?\n\n109\n00:05:15.250 --> 00:05:19.220\nSo you have content filtering that could\ncause things like availability problems.\n\n110\n00:05:19.220 --> 00:05:22.110\nIf it's set to strict, and you have to\ngo to certain websites, if you have\n\n111\n00:05:22.110 --> 00:05:25.570\na content filter on but you don't have,\nfor instance, an Internet Explorer,\n\n112\n00:05:25.570 --> 00:05:29.660\nyou don't have zones put into your safe\nsecurity zones, then you won't be able to,\n\n113\n00:05:29.660 --> 00:05:33.000\nlike in a trusted list, then you\nwon't be able to gain access to it.\n\n114\n00:05:33.000 --> 00:05:35.950\nSo you also have to worry\nabout those as well.\n\n115\n00:05:35.950 --> 00:05:38.990\nThey call out things like, for\ninstance, weak security configurations.\n\n116\n00:05:38.990 --> 00:05:43.487\nAnd when it comes down to it, that's\nreally what just about this whole episode\n\n117\n00:05:43.487 --> 00:05:47.730\nis about, are the different weak,\nimplementing encryption or\n\n118\n00:05:47.730 --> 00:05:51.380\nnot implementing encryption when\nyou should be implementing it.\n\n119\n00:05:51.380 --> 00:05:52.940\nChoosing a weaker cipher strength.\n\n120\n00:05:52.940 --> 00:05:57.157\nSomething like TLS 1.0,\nyou really shouldn't be using it, right?\n\n121\n00:05:57.157 --> 00:06:00.399\nAnd TLS 1.0 can get you in trouble\nsometimes because of the fact that,\n\n122\n00:06:00.399 --> 00:06:04.281\nwhen your web browsers connect to it, and\nwe've seen this in the certificate issues,\n\n123\n00:06:04.281 --> 00:06:07.300\nthat the browser thinks that it's trusted.\n\n124\n00:06:07.300 --> 00:06:09.830\nAnd it says HTTPS.\n\n125\n00:06:09.830 --> 00:06:13.830\nThe problem is that\nthe cypher suite is weak and\n\n126\n00:06:13.830 --> 00:06:17.720\nthat might not manifest itself and\nyou might not even get a warning on that.\n\n127\n00:06:17.720 --> 00:06:20.780\n&gt;&gt; All right, so when we talk about\nmisconfigured devices, there's a lot to\n\n128\n00:06:20.780 --> 00:06:24.245\nthink about, especially when we're dealing\nwith the realm of wireless, right, Wes?\n\n129\n00:06:24.245 --> 00:06:27.355\n&gt;&gt; Absolutely, because if you think\nabout it a lot of home users,\n\n130\n00:06:27.355 --> 00:06:29.535\nand I'm not talking about the IT.\n\n131\n00:06:29.535 --> 00:06:33.195\nAnd, yes, IT, you guys,\nas you're getting into security,\n\n132\n00:06:33.195 --> 00:06:36.990\nobviously cuz you're taking an exam it\nis important for you to understand, and\n\n133\n00:06:36.990 --> 00:06:38.100\nthere's always stepping stones.\n\n134\n00:06:38.100 --> 00:06:40.610\nBut for instance, home users.\n\n135\n00:06:40.610 --> 00:06:41.920\nIf home users gets devices,\n\n136\n00:06:41.920 --> 00:06:44.440\nthey do make things out there\nthat are make it convenient.\n\n137\n00:06:44.440 --> 00:06:48.440\nMake it convenient for the end user to do-\n&gt;&gt; Like WPS, we've talked about that.\n\n138\n00:06:48.440 --> 00:06:50.720\n&gt;&gt; Most definitely,\nit is a problem, right?\n\n139\n00:06:50.720 --> 00:06:52.960\nBecause WPS, the way it authenticates,\n\n140\n00:06:52.960 --> 00:06:56.290\na lot of manufacturers out there\nhave it to where you can disable it.\n\n141\n00:06:56.290 --> 00:06:58.420\nIn fact, let me show you some of\nthe things that you have to worry about\n\n142\n00:06:58.420 --> 00:07:01.700\nwhen it comes to wireless configurations.\n\n143\n00:07:01.700 --> 00:07:05.720\nSo for instance, right,\nI'm in a Linksys device here, if you will.\n\n144\n00:07:05.720 --> 00:07:09.193\nAnd you can see right here where they talk\nabout use this advanced utility to change\n\n145\n00:07:09.193 --> 00:07:10.280\nyour router settings.\n\n146\n00:07:10.280 --> 00:07:13.360\nBut you could use something\nlike Cisco Connect.\n\n147\n00:07:14.550 --> 00:07:19.428\nYou just pop in a CD and it goes through\nconfiguring your device for you.\n\n148\n00:07:19.428 --> 00:07:21.560\nBut even moreso than that,\nif we go ahead and\n\n149\n00:07:21.560 --> 00:07:24.830\nwe get out of this basic configuration and\nwe switch over to wireless, you're gonna\n\n150\n00:07:24.830 --> 00:07:28.070\nsee exactly what Cherokee just mentioned,\nand it is a problem, right?\n\n151\n00:07:28.070 --> 00:07:30.190\nThe Wi-Fi protected setup, right?\n\n152\n00:07:30.190 --> 00:07:33.650\nAgain, it's push button security,\nthat's what it is, it's about convenience.\n\n153\n00:07:33.650 --> 00:07:37.580\nIf you end up having one of these on\nyour device, you could push that device,\n\n154\n00:07:37.580 --> 00:07:43.060\nthe WPS button, and it will set up\nyour wireless security for you.\n\n155\n00:07:43.060 --> 00:07:46.730\nBut the problem is, keep in mind, every\ntime we've been talking about convenience,\n\n156\n00:07:46.730 --> 00:07:48.690\nwe've been talking about security, right?\n\n157\n00:07:48.690 --> 00:07:49.710\nAnd that's on the of the problems.\n\n158\n00:07:49.710 --> 00:07:52.464\nAgain, Wi-Fi protected set\nup it's a good idea, right?\n\n159\n00:07:52.464 --> 00:07:56.189\nThe intention behind it was very good,\nbut the way it was implemented,\n\n160\n00:07:56.189 --> 00:07:58.002\nit's a security vulnerability.\n\n161\n00:07:58.002 --> 00:07:59.767\nNow, I'm not going to set this up.\n\n162\n00:07:59.767 --> 00:08:02.239\nBut I want you to notice something.\n\n163\n00:08:02.239 --> 00:08:03.882\nEven though I'm not gonna set it up,\n\n164\n00:08:03.882 --> 00:08:06.400\nnotice in the background\nit's still enabled, right?\n\n165\n00:08:06.400 --> 00:08:09.342\nIt's gonna be something that you wanna\nturn off even if you're not using it.\n\n166\n00:08:09.342 --> 00:08:12.413\nAnd then what I'm gonna do is\nsomething like a manual configuration,\n\n167\n00:08:12.413 --> 00:08:14.370\nand we gotta watch those as well.\n\n168\n00:08:14.370 --> 00:08:17.160\n&gt;&gt; Yeah, Wes, I've worked with people\nin the past and they wanted to\n\n169\n00:08:17.160 --> 00:08:20.620\ndisable this particular feature,\nbut they couldn't find the setting.\n\n170\n00:08:20.620 --> 00:08:23.210\nIf you encounter that, you might\nwanna check for a firmware update,\n\n171\n00:08:23.210 --> 00:08:28.500\nbecause the manufacturers are aware of\nthis potential risk, this vulnerability.\n\n172\n00:08:28.500 --> 00:08:31.230\nSo you might have an older\nversion running on your device.\n\n173\n00:08:31.230 --> 00:08:34.004\n&gt;&gt; And how could you check that out cuz\nthat's also a security vulnerability in\n\n174\n00:08:34.004 --> 00:08:36.966\nand of itself, just the firmware, even\nif doesn't have to do with WPS, right?\n\n175\n00:08:36.966 --> 00:08:40.450\nAn old firmware, you might have a bug or\na flaw in that firmware.\n\n176\n00:08:40.450 --> 00:08:41.840\nIn fact, let me go ahead and\nshow you that.\n\n177\n00:08:41.840 --> 00:08:43.080\nI'm glad you mentioned that.\n\n178\n00:08:43.080 --> 00:08:45.547\nWe'll get back into some\nof these settings but\n\n179\n00:08:45.547 --> 00:08:49.277\nif I have a device that I know is quite\na few years old and I come in here and\n\n180\n00:08:49.277 --> 00:08:52.712\nI see something like this,\nfirmware version 1.0.0.0.\n\n181\n00:08:52.712 --> 00:08:56.004\nAnd this is already a couple years old,\nyou don't know how long some of these\n\n182\n00:08:56.004 --> 00:08:58.480\ndevices sit on the shelf\nbefore they're actually sold.\n\n183\n00:08:58.480 --> 00:08:59.900\nNow they're not going to be there forever,\nright?\n\n184\n00:08:59.900 --> 00:09:01.279\nThey're gonna make way for new products.\n\n185\n00:09:02.400 --> 00:09:05.520\nBut there is a possibility that it could\nbe sitting there for a while, right?\n\n186\n00:09:05.520 --> 00:09:06.340\nSo you wanna go in there and\n\n187\n00:09:06.340 --> 00:09:08.550\nyou wanna make sure that your\nfirmware version is up to date.\n\n188\n00:09:08.550 --> 00:09:11.920\nBecause there was a certain point in\ntime when the hardware manufacturers\n\n189\n00:09:11.920 --> 00:09:15.689\nrealize that even though people were just\ndoing things like we just did here, and\n\n190\n00:09:15.689 --> 00:09:19.760\ndisabling Wi-Fi Protected Setup,\n\n191\n00:09:19.760 --> 00:09:22.500\nit didn't disable it underneath,\nunder the hood, right?\n\n192\n00:09:22.500 --> 00:09:25.025\nSo make sure that your\nfirmware's up-to-date as well.\n\n193\n00:09:25.025 --> 00:09:28.212\nNow there are other things that\nwe have to keep in mind, too,\n\n194\n00:09:28.212 --> 00:09:30.860\nlike even your basic wireless security,\nright?\n\n195\n00:09:30.860 --> 00:09:33.240\nLet's start out here\nwith the network name.\n\n196\n00:09:34.250 --> 00:09:38.090\nThis is a default SSID,\nService Set Identifier.\n\n197\n00:09:38.090 --> 00:09:39.390\nBut what's the problem with that?\n\n198\n00:09:39.390 --> 00:09:40.910\n&gt;&gt; I can see what kind of device you have.\n\n199\n00:09:40.910 --> 00:09:44.880\n&gt;&gt; Absolutely, and let me go and\nthrow it back to you from there.\n\n200\n00:09:44.880 --> 00:09:48.070\nIf you know what device I have,\nhow does that information help you?\n\n201\n00:09:48.070 --> 00:09:49.180\nWell, if I think about it,\n\n202\n00:09:49.180 --> 00:09:52.570\nthere's not a link, a thousand\ndifferent linksys devices out there.\n\n203\n00:09:52.570 --> 00:09:56.410\nI have a little list that I go by and look\nat, kinda like a car, the make and model.\n\n204\n00:09:56.410 --> 00:10:00.090\nI could do a quick search engine check and\nsay, hey,\n\n205\n00:10:00.090 --> 00:10:02.590\nlook, what's my default username and\npassword?\n\n206\n00:10:02.590 --> 00:10:05.470\nI've done this thousands of times,\njust like helping clients and\n\n207\n00:10:05.470 --> 00:10:09.890\ncustomers, because a lot of times they\nforget or they leave it at this default.\n\n208\n00:10:09.890 --> 00:10:13.060\nThat's definitely one of the first\nthings we wanna change when\n\n209\n00:10:13.060 --> 00:10:14.580\nwe're setting up a wireless device.\n\n210\n00:10:14.580 --> 00:10:17.850\n&gt;&gt; Most definitely yes, come in here,\nchange that default SSID.\n\n211\n00:10:17.850 --> 00:10:19.950\nWe talk about changing\nthe default username.\n\n212\n00:10:19.950 --> 00:10:22.410\nSometimes you can't change the username.\n\n213\n00:10:22.410 --> 00:10:26.110\nBut you can definitely change the default\npassword because if Cherokee can find that\n\n214\n00:10:26.110 --> 00:10:30.290\nlist, the person is out there hacking you\nor attacking you, not again, not to give\n\n215\n00:10:30.290 --> 00:10:33.450\nhackers a bad name, but attackers,\nthey can get this information, too.\n\n216\n00:10:33.450 --> 00:10:37.030\nSo you wanna pay attention to things\nlike that were you're disabling, for\n\n217\n00:10:37.030 --> 00:10:41.380\ninstance, or not disabling,\nexcuse me, changing that name.\n\n218\n00:10:41.380 --> 00:10:45.170\nOther things here that you have to worry\nabout, for instance, wireless security.\n\n219\n00:10:45.170 --> 00:10:49.700\nNotice, well, this is a big thing,\nright, disabled, the lack thereof.\n\n220\n00:10:49.700 --> 00:10:52.970\nBut just because you enabled security,\ndoesn't mean you've done it right.\n\n221\n00:10:52.970 --> 00:10:57.050\nAnd what I mean by that is we have\nquite a few different options here.\n\n222\n00:10:57.050 --> 00:10:59.980\nAnd it is important that you know\nthe options that are available and\n\n223\n00:10:59.980 --> 00:11:02.180\nwhy you would choose one over the other,\nright?\n\n224\n00:11:02.180 --> 00:11:06.380\nWe almost never wanna\nimplement something like WEP.\n\n225\n00:11:06.380 --> 00:11:10.430\nRemember WEP, Wired Equivalent Privacy has\na lot of problems, initialization vector\n\n226\n00:11:10.430 --> 00:11:16.125\nattacks using the RC4 relatively weak and\nvulnerable stream cipher.\n\n227\n00:11:17.210 --> 00:11:19.511\nBut then there are other things,\ntoo, that we gotta consider as well.\n\n228\n00:11:19.511 --> 00:11:23.048\nWPA, WPA Personal,\nwhile it is relatively secure,\n\n229\n00:11:23.048 --> 00:11:26.830\nit is known that brute force\nattacks can cause problems.\n\n230\n00:11:26.830 --> 00:11:28.530\nCuz we're talking about pre-shared keys,\nright?\n\n231\n00:11:28.530 --> 00:11:31.813\nUnless we're doing something\nlike Enterprise mode.\n\n232\n00:11:31.813 --> 00:11:34.239\nIf we're doing something\nlike Enterprise mode,\n\n233\n00:11:34.239 --> 00:11:37.135\nthen we could be coupling\nit with things like 802.1x.\n\n234\n00:11:37.135 --> 00:11:41.462\n&gt;&gt; Now Wes, you did just mention disabling\non that last screen we were taking a look\n\n235\n00:11:41.462 --> 00:11:46.045\nat, that setting there, which is also a\ngood point, because sometimes if that SSID\n\n236\n00:11:46.045 --> 00:11:50.040\nhas accidentally been disabled and\nyou're not seeing it pop up.\n\n237\n00:11:50.040 --> 00:11:51.660\nAnd remember we've talked\nabout that before.\n\n238\n00:11:51.660 --> 00:11:57.780\nIt's not necessarily a security feature,\nbut we call it\n\n239\n00:11:57.780 --> 00:12:02.600\nsecurity through obscurity, kind of again\njust adding those layers of security.\n\n240\n00:12:02.600 --> 00:12:06.000\n&gt;&gt; Yeah, so the basics of security through\nobscurity, I want you to think of this.\n\n241\n00:12:06.000 --> 00:12:08.520\nTake the key,\nthrow it under the mat, right.\n\n242\n00:12:08.520 --> 00:12:09.110\nIs it hidden?\n\n243\n00:12:09.110 --> 00:12:10.030\nYeah, it's hidden.\n\n244\n00:12:10.030 --> 00:12:11.460\nCan people see it in plain sight?\n\n245\n00:12:11.460 --> 00:12:14.916\nNo, but what are the chances that if\nsomebody wants to break into your home,\n\n246\n00:12:14.916 --> 00:12:17.404\nthat they don't know that that's there,\nall right?\n\n247\n00:12:17.404 --> 00:12:21.550\nSo it's not really secure and\nthe same goes with disabling the SSID.\n\n248\n00:12:21.550 --> 00:12:24.470\nA lot of times, the only thing it\nreally does is it keeps the honest\n\n249\n00:12:24.470 --> 00:12:27.580\npeople out of your network and\nit does little to stop the attackers.\n\n250\n00:12:27.580 --> 00:12:30.840\nSo those are things that you\nhave to worry about as well.\n\n251\n00:12:30.840 --> 00:12:33.775\nSome of the other things that\nwe have to keep in mind, again,\n\n252\n00:12:33.775 --> 00:12:36.496\nit's just making sure that\nyou are enabling security.\n\n253\n00:12:36.496 --> 00:12:42.330\nOther things like guest access, maybe you\nwant guest access, but maybe you don't.\n\n254\n00:12:42.330 --> 00:12:44.280\nAgain, this is something that\nyou have to keep in mind.\n\n255\n00:12:44.280 --> 00:12:48.200\nDo you wanna allow people to use\nyour Internet connection, right?\n\n256\n00:12:48.200 --> 00:12:50.220\nAnd that's not so\nmuch to break into your network but\n\n257\n00:12:50.220 --> 00:12:54.100\nthe fact that you are liable for\nwhat happens on your network.\n\n258\n00:12:54.100 --> 00:12:56.170\nIt doesn't matter that\nyou can say all you want.\n\n259\n00:12:56.170 --> 00:12:57.170\nSomebody else did this but\n\n260\n00:12:57.170 --> 00:13:00.870\nif you're giving things like guest access,\nthat could be a problem as well.\n\n261\n00:13:00.870 --> 00:13:04.850\n&gt;&gt; And sometimes these devices kind of\nmarket it as DMZ, I've seen that before.\n\n262\n00:13:04.850 --> 00:13:09.350\nBut truly this is not a true DMZ here.\n\n263\n00:13:09.350 --> 00:13:11.290\nSo just kind of keep that in mind as well.\n\n264\n00:13:11.290 --> 00:13:12.680\n&gt;&gt; Yeah, definitely.\n\n265\n00:13:12.680 --> 00:13:15.667\nSo again, those are some of the things\nthat you can see in your access points.\n\n266\n00:13:15.667 --> 00:13:18.280\nWe could spend a whole\nweek pretty much on this.\n\n267\n00:13:18.280 --> 00:13:21.840\nLet me give you one other thing\nthat I do wanna talk about.\n\n268\n00:13:21.840 --> 00:13:26.552\nIn general, things like administration,\nlocal management access, right,\n\n269\n00:13:26.552 --> 00:13:30.352\nyou're definitely gonna wanna\nhave local management access,\n\n270\n00:13:30.352 --> 00:13:33.542\nbut notice that it defaults\nover clear text, right?\n\n271\n00:13:33.542 --> 00:13:35.510\nIt defaults to HTTP.\n\n272\n00:13:35.510 --> 00:13:39.100\nAgain, if I'm logging into this and\nsomebody just happens to be on my network,\n\n273\n00:13:39.100 --> 00:13:43.970\nor is trying to get into my network,\nbecause remember, radiated connections,\n\n274\n00:13:43.970 --> 00:13:46.550\nthey don't have to be\nphysically within my network.\n\n275\n00:13:46.550 --> 00:13:49.380\nBut they do have to be close\nenough that they could get in.\n\n276\n00:13:49.380 --> 00:13:51.120\nThey now could potentially have access.\n\n277\n00:13:51.120 --> 00:13:55.290\nThe other thing, too, is things like,\nfor instance, Remote Management Access.\n\n278\n00:13:55.290 --> 00:13:59.820\nThis is not something that personally\nI would recommend, anybody enabling.\n\n279\n00:13:59.820 --> 00:14:00.600\nAnd one of the things that I do.\n\n280\n00:14:00.600 --> 00:14:02.016\n&gt;&gt; Especially in a business environment.\n\n281\n00:14:02.016 --> 00:14:05.105\n&gt;&gt; Most definitely cuz you don't want\nanybody being able to have access remotely\n\n282\n00:14:05.105 --> 00:14:06.387\nto that management interface.\n\n283\n00:14:06.387 --> 00:14:09.482\nSo a lot of things,\nwhat I'll do, for instance,\n\n284\n00:14:09.482 --> 00:14:14.053\nis I'll have a machine that's within\nmy network that I can do an SSH into or\n\n285\n00:14:14.053 --> 00:14:18.440\neven remote desktop protocol and\nsecurely go into my network.\n\n286\n00:14:18.440 --> 00:14:21.400\nAnd then I'll come back the other way and\ndo the management, right?\n\n287\n00:14:21.400 --> 00:14:24.010\nSo I've already made it into my\nnetwork port forwarding rules.\n\n288\n00:14:24.010 --> 00:14:27.091\nI don't have to just leave this wide\nopen to where everybody can just gain\n\n289\n00:14:27.091 --> 00:14:27.706\naccess to it.\n\n290\n00:14:27.706 --> 00:14:31.935\nSo again, those are some of the things,\nagain, there are a lot of things that we\n\n291\n00:14:31.935 --> 00:14:36.123\ncan be doing inside of wireless access\npoints that could be causing problems.\n\n292\n00:14:36.123 --> 00:14:38.420\nSo remember your cipher suites.\n\n293\n00:14:38.420 --> 00:14:42.140\nRemember the strengths and weaknesses of\nthe encryption protocols that you're gonna\n\n294\n00:14:42.140 --> 00:14:45.580\nimplement, because it could be the\ndifference between having a secure network\n\n295\n00:14:45.580 --> 00:14:49.180\nand having one that is now very vulnerable\nto all different types of attacks.\n\n296\n00:14:49.180 --> 00:14:51.116\n&gt;&gt; What about our troublemakers, Wes?\n\n297\n00:14:51.116 --> 00:14:52.710\n&gt;&gt; Yeah, [LAUGH] yeah.\n\n298\n00:14:52.710 --> 00:14:55.340\nAre you insinuating something here?\n\n299\n00:14:55.340 --> 00:14:58.470\nBut we have things like, for instance,\npersonal issues that they talk about.\n\n300\n00:14:58.470 --> 00:15:01.570\nNow you didn't come to this episode\nto talk a whole bunch about\n\n301\n00:15:01.570 --> 00:15:02.420\npersonal issues, right?\n\n302\n00:15:02.420 --> 00:15:05.280\nBut some of the ones that they call out,\nthey call out things that\n\n303\n00:15:05.280 --> 00:15:10.190\nyou probably think they are kinda obvious,\nthings like policy violations,\n\n304\n00:15:10.190 --> 00:15:14.510\nlinear company security policy,\nacceptable use policies like this.\n\n305\n00:15:14.510 --> 00:15:16.061\nThis could be a problem.\n\n306\n00:15:16.061 --> 00:15:19.390\nSome of the other things they talk about,\nyeah, speaking of troublemakers, right?\n\n307\n00:15:19.390 --> 00:15:23.320\nInsider threat,\nwe've talked about the attack from within.\n\n308\n00:15:23.320 --> 00:15:26.190\nPeople that are disgruntled,\nif you will, and they want to\n\n309\n00:15:26.190 --> 00:15:29.540\ncause some kind of havoc to prove a point,\nwhatever that point might be.\n\n310\n00:15:30.630 --> 00:15:31.460\nSocial media and\n\n311\n00:15:31.460 --> 00:15:35.263\nthings like social engineering,\nnot that they run hand in hand, they can.\n\n312\n00:15:35.263 --> 00:15:38.148\nAnd phishing attacks can come\nthrough social media, too.\n\n313\n00:15:38.148 --> 00:15:42.916\nBut with social media, it's also about,\nwe talk about data exfiltration.\n\n314\n00:15:42.916 --> 00:15:44.642\nYou might be giving trade secrets out.\n\n315\n00:15:44.642 --> 00:15:46.540\nYou don't realize it over social media.\n\n316\n00:15:46.540 --> 00:15:48.382\nSo those are things that we\nhave to keep in mind, too.\n\n317\n00:15:48.382 --> 00:15:51.704\nSocial engineering, there are different\ntypes of social engineering, attacks,\n\n318\n00:15:51.704 --> 00:15:53.260\nphishing just happen to be one of them.\n\n319\n00:15:53.260 --> 00:15:56.720\nBut we have to worry about people\ntrying to grab your credentials.\n\n320\n00:15:56.720 --> 00:15:59.544\nSo that they could mount\nan attack against your network.\n\n321\n00:15:59.544 --> 00:16:02.463\n&gt;&gt; And we really do,\nbecause when we stop worrying about it,\n\n322\n00:16:02.463 --> 00:16:04.320\nthat's when these problems arise.\n\n323\n00:16:04.320 --> 00:16:08.260\nNow, Wes, I know that you know we're not\ngoing to be putting any kind of PII,\n\n324\n00:16:08.260 --> 00:16:10.500\nPersonally Identifiable Information,\non social media,\n\n325\n00:16:10.500 --> 00:16:13.870\nespecially when it comes\nto a business entity.\n\n326\n00:16:13.870 --> 00:16:17.890\nIf I have any kind of secret,\ntop secret prototypes,\n\n327\n00:16:17.890 --> 00:16:19.830\nI'm dealing with really\nsensitive information.\n\n328\n00:16:19.830 --> 00:16:22.372\nBut that's not to say\nthat all the individuals,\n\n329\n00:16:22.372 --> 00:16:25.913\nthe personnel within your organization\nhave that mindset as well.\n\n330\n00:16:25.913 --> 00:16:27.473\nSo we need to educate our end users,\n\n331\n00:16:27.473 --> 00:16:30.762\nI know you guys are probably sick of\nhearing us say that, but it's so true.\n\n332\n00:16:30.762 --> 00:16:34.472\n&gt;&gt; Yeah, that's right Cherokee,\nthat is a never ending process,\n\n333\n00:16:34.472 --> 00:16:38.992\nyou always have to keep communication\nlines open, so that people can be aware of\n\n334\n00:16:38.992 --> 00:16:42.714\nwhat's going on within your\nsecurity environment and attacks.\n\n335\n00:16:42.714 --> 00:16:46.795\nThey're always changing so\nthat's a never ending process.\n\n336\n00:16:46.795 --> 00:16:48.210\nSome of the other things\nthat they call out for\n\n337\n00:16:48.210 --> 00:16:51.590\ninstance are unauthorized software, right?\n\n338\n00:16:51.590 --> 00:16:55.544\nThere is a reason that you're company\nwould go through the process of making\n\n339\n00:16:55.544 --> 00:16:58.282\nsure that the software that\nthey have has a license.\n\n340\n00:16:58.282 --> 00:17:01.798\nYou're in compliant with the license\nagreement because that can cost\n\n341\n00:17:01.798 --> 00:17:05.970\nhundreds of thousands of dollars if you\nget audited and you're using software that\n\n342\n00:17:05.970 --> 00:17:10.000\nis deemed to be pirated because you're\nnot following license compliance.\n\n343\n00:17:10.000 --> 00:17:13.296\nIt could be just the fact that your\ncompany wants to use a specific piece of\n\n344\n00:17:13.296 --> 00:17:16.553\nsoftware and they don't want you\nbringing in things like open source.\n\n345\n00:17:16.553 --> 00:17:20.890\nGuys, this isn't a debate about\nproprietary versus open source,\n\n346\n00:17:20.890 --> 00:17:23.247\nbut keep in mind, that open source,\n\n347\n00:17:23.247 --> 00:17:27.980\nthere's a lot of room in there that\nit could be untested, undocumented.\n\n348\n00:17:27.980 --> 00:17:30.980\nYou're not aware of what's going on,\nand it could cause problems.\n\n349\n00:17:30.980 --> 00:17:33.810\nThe other thing is making sure that\nyou're downloading from trusted\n\n350\n00:17:33.810 --> 00:17:34.810\ninformation sources.\n\n351\n00:17:34.810 --> 00:17:35.630\nThis is right.\n\n352\n00:17:35.630 --> 00:17:37.950\nWe want to be aware if you\nare installing software,\n\n353\n00:17:37.950 --> 00:17:40.310\nthat you are aware fol\nwhere it comes from.\n\n354\n00:17:40.310 --> 00:17:43.560\nFor instance,\nI have a notepad plus plus installer here.\n\n355\n00:17:43.560 --> 00:17:48.046\nAnd if I go to install it, the first thing\nthat kicks in is the UAC in this case,\n\n356\n00:17:48.046 --> 00:17:49.580\ncuz I'm running as a non administrator.\n\n357\n00:17:49.580 --> 00:17:52.790\nI can do a privilege\nescalation if I want here.\n\n358\n00:17:52.790 --> 00:17:56.290\nBut I wanna be able to know\nthings like show information\n\n359\n00:17:56.290 --> 00:17:58.610\nabout the publisher certificate.\n\n360\n00:17:58.610 --> 00:18:02.220\nI wanna be able to view that information\nand I wanna know things like, for\n\n361\n00:18:02.220 --> 00:18:04.150\ninstance, the certificate is bad, right?\n\n362\n00:18:04.150 --> 00:18:06.980\nYou could, and Windows is really\ngood at protecting itself here.\n\n363\n00:18:06.980 --> 00:18:12.090\nSo use things like the user account\ncontrol definitely when it comes to\n\n364\n00:18:12.090 --> 00:18:15.710\nthings like software if you're in a home\nenvironment, an enterprise environment.\n\n365\n00:18:15.710 --> 00:18:17.860\nYou're probably gonna be following\nthings like a policy too.\n\n366\n00:18:19.040 --> 00:18:21.140\nSome of the other things that they\ntalk about are things like for\n\n367\n00:18:21.140 --> 00:18:24.060\ninstance asset management.\n\n368\n00:18:24.060 --> 00:18:27.797\nAsset management could be something that,\nit could be the lack of, right?\n\n369\n00:18:27.797 --> 00:18:30.453\nIt could be the fact that it\nis not updated regularly and\n\n370\n00:18:30.453 --> 00:18:33.513\nyou are not aware of the devices\nthat you have on your network and\n\n371\n00:18:33.513 --> 00:18:37.384\nagain more devices on your network that\nyou're not aware of could lead to things\n\n372\n00:18:37.384 --> 00:18:41.605\nlike compliance violations, security\nviolations, security breaches if you will,\n\n373\n00:18:41.605 --> 00:18:44.590\nso we also have to worry about\nthings like that as well.\n\n374\n00:18:44.590 --> 00:18:47.860\n&gt;&gt; Sure, we also need to keep that kind\nof information to a secure location,\n\n375\n00:18:47.860 --> 00:18:52.030\nso no one is manipulating that\ninformation, trying to fudge the fact,\n\n376\n00:18:52.030 --> 00:18:54.050\nthey might have taken something off site.\n\n377\n00:18:54.050 --> 00:18:58.450\n&gt;&gt; Definitely, one of the last\nthings that they talk about here and\n\n378\n00:18:58.450 --> 00:19:02.220\nlet me just make sure,\nare authentication issues.\n\n379\n00:19:02.220 --> 00:19:07.010\nAnd authentication issues can go on for\na many a different reasons, right.\n\n380\n00:19:07.010 --> 00:19:08.160\nLet's talk about, for instance,\n\n381\n00:19:08.160 --> 00:19:11.310\ninside of a domain environment\nauthentication issues.\n\n382\n00:19:11.310 --> 00:19:13.610\nYou've seen me login,\nor the lack there of,\n\n383\n00:19:13.610 --> 00:19:17.300\nwhere it could be just the fact that\na user is typing their password wrong.\n\n384\n00:19:17.300 --> 00:19:21.940\nIt could be that the work station\nthat they are logging into\n\n385\n00:19:21.940 --> 00:19:24.140\nhas lost a trust\nrelationship with a domain.\n\n386\n00:19:24.140 --> 00:19:27.490\nWhen that happens you're not\ngonna be able to login and\n\n387\n00:19:28.620 --> 00:19:30.470\nthat causes availability problems.\n\n388\n00:19:30.470 --> 00:19:34.420\nCIA triad Authorized people should\nhave access to their workstation so\n\n389\n00:19:34.420 --> 00:19:35.220\nthey can do their work.\n\n390\n00:19:35.220 --> 00:19:39.980\nAnd if they don't, well,\nagain that runs contrary to the CIA triad.\n\n391\n00:19:39.980 --> 00:19:42.690\nCould be things like, for\ninstance, lock out thresholds.\n\n392\n00:19:42.690 --> 00:19:46.310\nIf a person is Monday morning not\ntyping their password correctly and\n\n393\n00:19:46.310 --> 00:19:47.440\nthey do it past that.\n\n394\n00:19:47.440 --> 00:19:48.622\n&gt;&gt; Were you watching me this morning?\n\n395\n00:19:48.622 --> 00:19:49.180\n&gt;&gt; Most definitely [LAUGH].\n\n396\n00:19:49.180 --> 00:19:52.140\nEnjoy the key logger,\nno just kidding [LAUGH].\n\n397\n00:19:52.140 --> 00:19:54.470\nBut yeah, it could be the thing,\nthings like that.\n\n398\n00:19:54.470 --> 00:19:58.110\nFor instance, a user has been locked out,\nthey might be locked out\n\n399\n00:19:58.110 --> 00:20:01.200\nindefinitely until the administrator\nenables the account,\n\n400\n00:20:01.200 --> 00:20:03.810\ncould be somebody in active\ndirectory disabled the account.\n\n401\n00:20:03.810 --> 00:20:06.310\nCould be the fact that the account\nis deleted again by accident.\n\n402\n00:20:06.310 --> 00:20:10.470\nOther things that's can happen is if you\nhave workstations within your domains that\n\n403\n00:20:10.470 --> 00:20:11.940\ndon't take in with the domain controller,\n\n404\n00:20:11.940 --> 00:20:14.900\nthings about 180 days,\ndon't quote me on that.\n\n405\n00:20:14.900 --> 00:20:18.740\nThey can update the machine password\ninside of the directory database and\n\n406\n00:20:18.740 --> 00:20:21.200\nthat causes them to be\nkicked off of the domain.\n\n407\n00:20:21.200 --> 00:20:24.410\nAnytime you got a domain computer\nthat used to be on the domain.\n\n408\n00:20:24.410 --> 00:20:26.920\nGets kicked off,\nit doesn't have a trust, right.\n\n409\n00:20:26.920 --> 00:20:28.250\nIt's not gonna allow you to log in.\n\n410\n00:20:28.250 --> 00:20:29.970\nSo that could be issues too.\n\n411\n00:20:29.970 --> 00:20:32.370\nSome of the other issues that you\ncould see, things like, for instance,\n\n412\n00:20:32.370 --> 00:20:34.070\nanonymous log on, right.\n\n413\n00:20:34.070 --> 00:20:37.930\nIf you have an FTP server and most people\ndon't do this, because they're aware.\n\n414\n00:20:37.930 --> 00:20:42.030\nBut if you're not aware, you wanna make\nsure that you don't implement this\n\n415\n00:20:42.030 --> 00:20:43.770\nnice to have a file server, right?\n\n416\n00:20:43.770 --> 00:20:47.070\nNice to make it nice and easy so people\ncan get into the file server and you don't\n\n417\n00:20:47.070 --> 00:20:50.372\nhave all this help desk tickets that you\nhave to call because people can't type\n\n418\n00:20:50.372 --> 00:20:54.350\na password or they can't remember their\nusername and you allow anonymous log on.\n\n419\n00:20:54.350 --> 00:20:58.690\nWell, the problem is when people\nanonymously logging on it's hard to track\n\n420\n00:20:59.900 --> 00:21:03.400\nwho it is that's logging on and who it is\nthat's doing or performing the action.\n\n421\n00:21:03.400 --> 00:21:05.200\nSo when it comes to\nthings like logging and\n\n422\n00:21:05.200 --> 00:21:08.280\nauditing, you really can't point\nit back to any one person.\n\n423\n00:21:08.280 --> 00:21:11.210\nSo we definitely have to\nworry about that as well.\n\n424\n00:21:11.210 --> 00:21:14.258\nSo keep in mind that if you are running\nthings like your file servers or\n\n425\n00:21:14.258 --> 00:21:17.728\nany resource on your network that you\nhave some kind of authentication that has\n\n426\n00:21:17.728 --> 00:21:20.750\nto go on and that you're implementing\nthings like authorization.\n\n427\n00:21:20.750 --> 00:21:24.486\nRemember, authorization is not so\nmuch about who you are but\n\n428\n00:21:24.486 --> 00:21:26.940\nit's about what you can do.\n\n429\n00:21:26.940 --> 00:21:30.650\nThen we talk about things like AA\nwe'll talk about in another episode.\n\n430\n00:21:30.650 --> 00:21:31.810\nAlso accounting, right?\n\n431\n00:21:31.810 --> 00:21:34.565\nWe have to know who are you?\n\n432\n00:21:34.565 --> 00:21:35.195\nRight?\n\n433\n00:21:35.195 --> 00:21:36.675\nWhat are you allowed to do?\n\n434\n00:21:36.675 --> 00:21:38.955\nAnd then finally, what did you do, right?\n\n435\n00:21:38.955 --> 00:21:42.891\nSo making sure that you can track\na user that logs into a system and you\n\n436\n00:21:42.891 --> 00:21:47.677\ncan tie their identity to the actions that\nthey perform within a network is a must.\n\n437\n00:21:47.677 --> 00:21:50.375\nIt's one of the reasons that\nwe really shouldn't be using\n\n438\n00:21:50.375 --> 00:21:52.680\nthings like anonymous logon.\n\n439\n00:21:52.680 --> 00:21:59.240\nAll right, so things that you have to\nworry about, keep in mind on your exam.\n\n440\n00:21:59.240 --> 00:22:00.960\nLook at things like authentication issues,\nand\n\n441\n00:22:00.960 --> 00:22:03.110\nlook at multiple scenarios like\nwe've been discussing here.\n\n442\n00:22:03.110 --> 00:22:07.680\nStudy multiple scenarios in which\na person might not be able to log in and\n\n443\n00:22:07.680 --> 00:22:09.170\nagain, it cause a problem.\n\n444\n00:22:09.170 --> 00:22:12.570\nCould be something like for instance, the\ndomain controller isn't reachable, right.\n\n445\n00:22:12.570 --> 00:22:15.730\nSo one of the things we implement\nredundancy, multiple domain controller,\n\n446\n00:22:15.730 --> 00:22:18.240\nso one goes down,\none loses network connectivity.\n\n447\n00:22:18.240 --> 00:22:21.220\nWe can still authenticate against the net,\nanother one,\n\n448\n00:22:21.220 --> 00:22:26.380\nbecause again, it is about availability as\nwell as authentication and authorization.\n\n449\n00:22:26.380 --> 00:22:28.920\n&gt;&gt; Wes, we've covered a lot\nof different topics and\n\n450\n00:22:28.920 --> 00:22:31.830\ndifferent scenarios that might\nplay out in real life, but\n\n451\n00:22:31.830 --> 00:22:35.490\nI don't think we can cover every\nsingle scenario in a particular show.\n\n452\n00:22:35.490 --> 00:22:38.400\nBecause I've encountered\nsome really strange ones and\n\n453\n00:22:38.400 --> 00:22:39.910\nI'm sure you guys will too.\n\n454\n00:22:39.910 --> 00:22:42.981\nBut for this particular show,\nwe did as best as we could.\n\n455\n00:22:42.981 --> 00:22:45.796\nGood luck, I hope you're able to work\nthrough all those different problems you\n\n456\n00:22:45.796 --> 00:22:46.392\nmay encounter.\n\n457\n00:22:46.392 --> 00:22:48.490\nWe're gonna go ahead and\nsign out for this show.\n\n458\n00:22:48.490 --> 00:22:50.260\nRemember, I'm your host Cherokee Boose.\n\n459\n00:22:50.260 --> 00:22:50.980\n&gt;&gt; And I'm Wes Bryan.\n\n460\n00:22:50.980 --> 00:22:52.989\n&gt;&gt; See you next time here at ITProTV.\n\n461\n00:22:54.630 --> 00:23:00.299\n[MUSIC]\n\n462\n00:23:00.299 --> 00:23:03.400\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216004883"
        },
        {
          "description": "With the vast selection of tools available it may not be difficult to find one to suite your needs, however learning all of those tools may not always come without some practice. Tune in to watch Cherokee and Wes demonstrate how to interpret the output of some commonly used tools.",
          "length": "1359",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-4-1-analyze_and_interpret_outputs-041217-PGM.00_22_24_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-4-1-analyze_and_interpret_outputs-041217-PGM.00_22_24_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-4-1-analyze_and_interpret_outputs-041217-PGM.00_22_24_27.Still001-sm.jpg",
          "title": "Analyze and Interpret Outputs",
          "transcript": "WEBVTT\n\n1\n00:00:00.290 --> 00:00:02.964\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.964 --> 00:00:05.893\n[CROSSTALK]\n\n3\n00:00:05.893 --> 00:00:08.406\n[MUSIC]\n\n4\n00:00:08.406 --> 00:00:12.015\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.015 --> 00:00:14.448\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n6\n00:00:14.448 --> 00:00:16.809\nI'm your show host, Cherokee Boose.\n\n7\n00:00:16.809 --> 00:00:20.730\nWith the plethora of different types of\ntools available for us to use out there,\n\n8\n00:00:20.730 --> 00:00:23.670\nwe have different types of\noutputs that we need to analyze.\n\n9\n00:00:23.670 --> 00:00:27.340\nAnd with us today, in the studios, we have\nMr. Wes Bryan to help us with this topic.\n\n10\n00:00:27.340 --> 00:00:28.639\nAnd just really sifting through and\n\n11\n00:00:28.639 --> 00:00:30.820\ndeciphering all that\nadditional information.\n\n12\n00:00:30.820 --> 00:00:31.850\nThank you for joining us, Wes.\n\n13\n00:00:31.850 --> 00:00:32.920\n&gt;&gt; Hey, thanks for having me here.\n\n14\n00:00:32.920 --> 00:00:36.190\nThat's right, we are gonna be looking\nat a whole bunch of different types of\n\n15\n00:00:36.190 --> 00:00:36.870\nutilities.\n\n16\n00:00:36.870 --> 00:00:39.860\nAnd some of the things that we need to be\naware of when it comes to just analyzing\n\n17\n00:00:39.860 --> 00:00:41.470\nand interpreting that output.\n\n18\n00:00:41.470 --> 00:00:43.840\nOne of the first things\nthat they call out are,\n\n19\n00:00:43.840 --> 00:00:47.490\nwell, some of the technologies\nthat we talked about before.\n\n20\n00:00:47.490 --> 00:00:49.810\nThey talk HIDS and HIPS, right?\n\n21\n00:00:49.810 --> 00:00:54.760\nHost-based intrusion detection system and\nHost-based intrusion prevention systems.\n\n22\n00:00:54.760 --> 00:01:00.290\nAnd keep in mind it depends on if these\nare in line or if they're passive, right?\n\n23\n00:01:00.290 --> 00:01:03.030\nWill kind of dictate which one they are,\nright?\n\n24\n00:01:03.030 --> 00:01:06.810\nBecause remember an IPS,\nwe talked about an IPS.\n\n25\n00:01:06.810 --> 00:01:09.550\nWe're typically talking\nabout two network adapters.\n\n26\n00:01:09.550 --> 00:01:13.530\nBecause, all information is\npassing in to one adapter\n\n27\n00:01:13.530 --> 00:01:16.230\nthrough the other adapter as it\ngoes out to your network right?\n\n28\n00:01:16.230 --> 00:01:19.220\nSo it's an inline device versus an IDS,\n\n29\n00:01:19.220 --> 00:01:23.060\nwhich can be software just running\non a machine that passively\n\n30\n00:01:23.060 --> 00:01:26.770\nscans you know information across your\nnetwork for signs of an intrusion.\n\n31\n00:01:26.770 --> 00:01:30.510\nBut it doesn't implement countermeasures,\nso do keep that in mind.\n\n32\n00:01:30.510 --> 00:01:33.100\nBut there are a few\ndifferent options out there.\n\n33\n00:01:33.100 --> 00:01:38.120\nFor instance, one of the ones that we have\nout there that you can actually get is\n\n34\n00:01:38.120 --> 00:01:39.710\nthings like Sophos.\n\n35\n00:01:39.710 --> 00:01:43.500\nSophos is one,\nin fact I've got it here on our screen.\n\n36\n00:01:43.500 --> 00:01:48.980\nIf we take a look, right, it offers\na third party service for this, right?\n\n37\n00:01:48.980 --> 00:01:55.500\nAnd you can see that they're pretty much\noffering both IDS and IPS implementations.\n\n38\n00:01:55.500 --> 00:02:00.660\nNotice that they have the Prevent,\nDetect, and Respond, right?\n\n39\n00:02:00.660 --> 00:02:05.190\nRemember that IDS do detection and\nresponse if you will, right?\n\n40\n00:02:05.190 --> 00:02:08.610\nMonitoring, detection,\nand alerting, if you will.\n\n41\n00:02:08.610 --> 00:02:10.490\nHowever, the IPS,\n\n42\n00:02:10.490 --> 00:02:15.610\nright, not only does it do the detection\nand the alerting, if you will.\n\n43\n00:02:15.610 --> 00:02:17.520\nBut it also does\nthe prevention side of it,\n\n44\n00:02:17.520 --> 00:02:20.340\nwhich typically means counter measures,\nright?\n\n45\n00:02:20.340 --> 00:02:23.130\nAnd we can get a third\nparty utility like this,\n\n46\n00:02:23.130 --> 00:02:26.780\nor we can implement something like Snort,\nright?\n\n47\n00:02:26.780 --> 00:02:30.320\nSnort is a command line driven\nutility that you can implement.\n\n48\n00:02:30.320 --> 00:02:34.890\nIn fact, let's see, I've actually got\nSnort installed on this machine here.\n\n49\n00:02:34.890 --> 00:02:38.160\nSo this would be, not so\nmuch an IPS as it would be an IDS, right?\n\n50\n00:02:38.160 --> 00:02:42.710\nBecause it's just running on a simple,\na system within the network, right?\n\n51\n00:02:42.710 --> 00:02:46.590\nThis would be a host-based\nintrusion detection system.\n\n52\n00:02:46.590 --> 00:02:49.340\nAnd kinda give you an overview\nof what we got here.\n\n53\n00:02:49.340 --> 00:02:51.320\nIn fact, let me go ahead and\ndrop down into C:,\n\n54\n00:02:51.320 --> 00:02:54.740\nand you can see that Snort is right here.\n\n55\n00:02:54.740 --> 00:02:56.830\n&gt;&gt; Now this is a free tool, Wes, right?\n\n56\n00:02:56.830 --> 00:03:00.200\nSo it might not be the easiest to use\nright at first, but there's a lot of\n\n57\n00:03:00.200 --> 00:03:04.090\ndifferent resources out there to\nhelp you use this really free tool.\n\n58\n00:03:04.090 --> 00:03:07.280\n&gt;&gt; Yeah there's a lot of support there,\na lot of documentation.\n\n59\n00:03:07.280 --> 00:03:10.020\nIn fact SAMs has\ndocumentation on it as well.\n\n60\n00:03:10.020 --> 00:03:13.930\nAnd what it does is it essentially\nuses a series of rules, right?\n\n61\n00:03:13.930 --> 00:03:17.850\nSo, for instance, we've got rules here and\nI'm just using the community driven rules.\n\n62\n00:03:17.850 --> 00:03:21.838\nThey have register rules too that you go\nto Snort, you register for an account, and\n\n63\n00:03:21.838 --> 00:03:23.330\nyou can get up to date rules.\n\n64\n00:03:23.330 --> 00:03:26.630\nYou also have subscription-based, too,\nso even though it is a free utility.\n\n65\n00:03:26.630 --> 00:03:30.480\nKeep in mind, a lot of this open source\nsoftware that's under the GPL support is\n\n66\n00:03:30.480 --> 00:03:32.990\nnot free, Versus the software being free.\n\n67\n00:03:32.990 --> 00:03:35.910\nBut one of the great things is at least,\nyou can get started free utility.\n\n68\n00:03:35.910 --> 00:03:39.530\nThey've got community based forums,\ncommunity based rules here.\n\n69\n00:03:39.530 --> 00:03:41.972\nWhat we are looking at is a whole\nbunch of different rules.\n\n70\n00:03:41.972 --> 00:03:44.190\nI'm gonna open this up with Notepad++,\n\n71\n00:03:44.190 --> 00:03:48.840\nI would not recommend opening these\nrules with Notepad, that native Notepad.\n\n72\n00:03:48.840 --> 00:03:52.170\nJust because of the fact that\nit's very very hard to tell,\n\n73\n00:03:52.170 --> 00:03:53.850\nwhere you are at in the document.\n\n74\n00:03:53.850 --> 00:03:56.210\nYou can see This is\nessentially the rules list.\n\n75\n00:03:56.210 --> 00:03:59.040\nNow you can see the majority of them\nare pretty much all commented out.\n\n76\n00:03:59.040 --> 00:04:02.694\nThere are a couple in here, if I scroll\ndown, I believe there's like two or\n\n77\n00:04:02.694 --> 00:04:04.960\nthree of them in here\nthat aren't commented.\n\n78\n00:04:04.960 --> 00:04:06.770\nBut you can see,\nI'm up to line 300, right?\n\n79\n00:04:06.770 --> 00:04:11.020\nSo a lot of rules, there's one,\nfor instance, you can see, and\n\n80\n00:04:11.020 --> 00:04:12.060\nit isn't commented out.\n\n81\n00:04:12.060 --> 00:04:14.480\nAnd this is a rule that's gonna look\nout and it's gonna look for traffic.\n\n82\n00:04:14.480 --> 00:04:15.810\nAnd it's gonna find, okay,\n\n83\n00:04:15.810 --> 00:04:19.560\ndo I see traffic like this\ncoming on in an interface?\n\n84\n00:04:19.560 --> 00:04:21.960\nIf I do, what kind of response\ndo I have to give it?\n\n85\n00:04:21.960 --> 00:04:24.880\nDo I have to send, say for instance,\nCherokee's systems administrator?\n\n86\n00:04:24.880 --> 00:04:26.370\nDo I have to send her an email, right?\n\n87\n00:04:26.370 --> 00:04:29.270\nAnd I mean the system, right, do I have\nto send her an email-automated message.\n\n88\n00:04:29.270 --> 00:04:32.540\nSo that she can interpret is this\nsomething that she needs to take action\n\n89\n00:04:32.540 --> 00:04:33.600\nagainst?\n\n90\n00:04:33.600 --> 00:04:35.280\nAnd really that's gonna\nbe how you configure it.\n\n91\n00:04:35.280 --> 00:04:37.520\nSo there's a little bit\nabout the rules here,\n\n92\n00:04:37.520 --> 00:04:41.160\nbut we can drop down to\nour command prompt here.\n\n93\n00:04:41.160 --> 00:04:43.440\nLet me go ahead and clear our screen.\n\n94\n00:04:43.440 --> 00:04:48.790\nAnd I'm going to go ahead and\nnavigate into the location where Snort is,\n\n95\n00:04:48.790 --> 00:04:53.990\nand Snort's Binary is in the bin folder,\nthe binary folder.\n\n96\n00:04:53.990 --> 00:05:01.102\nAnd if we do a DIR, what I'm looking for\nis this Snort executable here.\n\n97\n00:05:01.102 --> 00:05:03.320\nSo we'll go ahead and run that, all right.\n\n98\n00:05:03.320 --> 00:05:04.930\nOne of the things that I have to do,\n\n99\n00:05:04.930 --> 00:05:08.430\nis I have to figure out what\nthe interfaces are, right.\n\n100\n00:05:08.430 --> 00:05:10.320\nIf you have a multi-homed machine,\n\n101\n00:05:10.320 --> 00:05:15.170\nI believe that's w,\nI don't think I did that right there.\n\n102\n00:05:15.170 --> 00:05:20.330\nIt might be a capital W here,\nyes, that's capital W.\n\n103\n00:05:20.330 --> 00:05:23.660\nAgain, remember syntax is\nimportant in these commands.\n\n104\n00:05:23.660 --> 00:05:26.990\nSo I did a lowercase w, and\nit's supposed to be a capital W.\n\n105\n00:05:26.990 --> 00:05:29.880\nAnd what that helps me to\ndo is find the interfaces.\n\n106\n00:05:29.880 --> 00:05:34.720\nBecause I need to tell Snort which network\nadapter do I want you monitoring for\n\n107\n00:05:34.720 --> 00:05:36.500\nsigns of an intrusion right?\n\n108\n00:05:36.500 --> 00:05:39.960\nSo I can see that it's\nadapter 3 that I want,\n\n109\n00:05:39.960 --> 00:05:44.040\nyour numbers will change depending\non how your configuration is.\n\n110\n00:05:44.040 --> 00:05:48.820\nSo what we're gonna do, we'll go ahead and\ndo a snort, we'll do -I for\n\n111\n00:05:48.820 --> 00:05:51.120\nthe interface, I'm gonna say interface 3.\n\n112\n00:05:51.120 --> 00:05:55.310\nAnd then what I'm gonna do,\nwe could redirect this to a text file.\n\n113\n00:05:55.310 --> 00:05:57.300\nBut that's going to make for\na very boring episode,\n\n114\n00:05:57.300 --> 00:05:58.790\nbecause you won't be able to see anything.\n\n115\n00:05:58.790 --> 00:06:01.010\nSo what I'm gonna do is\nI'm gonna use a capital A.\n\n116\n00:06:01.010 --> 00:06:05.140\nAnd I'm gonna say console,\nwhich means I want it to turn around.\n\n117\n00:06:05.140 --> 00:06:08.195\nAnd I want it to send everything\nright back to this console.\n\n118\n00:06:08.195 --> 00:06:13.740\nAnd now,\nit's asking me to monitor traffic here.\n\n119\n00:06:13.740 --> 00:06:18.740\nSo let me go ahead and\nwe'll let this authenticate, right?\n\n120\n00:06:18.740 --> 00:06:20.280\nAnd you can see that it's monitoring,\n\n121\n00:06:20.280 --> 00:06:22.200\nbut I don't have a lot of\ninformation going on here,\n\n122\n00:06:22.200 --> 00:06:25.810\nso I'm going to go ahead and I'm going\nto jump over to another machine here.\n\n123\n00:06:25.810 --> 00:06:28.640\nAnd on that other machine,\nwe'll go ahead and,\n\n124\n00:06:28.640 --> 00:06:33.160\nI'll just go ahead and\nping the machine that's got Snort running.\n\n125\n00:06:33.160 --> 00:06:37.720\nSo we'll run a ping, 10.10.10,\nand we'll let this fire off.\n\n126\n00:06:37.720 --> 00:06:39.580\nAnd I probably should\nmake it persistent again,\n\n127\n00:06:39.580 --> 00:06:41.850\nwe're not in *nix based systems here.\n\n128\n00:06:41.850 --> 00:06:44.150\nSo it keeps running,\nnow notice what's happening.\n\n129\n00:06:44.150 --> 00:06:46.190\nWe'll go right back over\nto where Snort's running.\n\n130\n00:06:46.190 --> 00:06:47.900\nNotice it's giving me warnings here, and\n\n131\n00:06:47.900 --> 00:06:51.640\nit's telling me that I'm finding\ntraffic coming in on that interface.\n\n132\n00:06:51.640 --> 00:06:56.860\nAnd each one of these is a response\nto the ping packets, the individual\n\n133\n00:06:56.860 --> 00:07:00.390\nICMP packets that we're sending\nacross the wire back to that machine.\n\n134\n00:07:00.390 --> 00:07:04.490\nSo you can see that it's\ngiving me detection, right?\n\n135\n00:07:04.490 --> 00:07:05.530\nAnd that's kinda what we want.\n\n136\n00:07:05.530 --> 00:07:07.600\nNow, in a situation like this, right,\n\n137\n00:07:07.600 --> 00:07:11.330\nwe can't be right in front\nof this machine saying okay.\n\n138\n00:07:11.330 --> 00:07:13.700\nHey, we'll stay here for\nthe next three weeks and\n\n139\n00:07:13.700 --> 00:07:16.430\nwe'll figure out if there are intrusions.\n\n140\n00:07:16.430 --> 00:07:20.520\nThis is where you can go a step farther\nand we could put in, hey, I want you to\n\n141\n00:07:20.520 --> 00:07:24.870\nsend a response or an email out to\nwhatever the systems administrator is.\n\n142\n00:07:24.870 --> 00:07:29.790\nSo that they're aware that there is some\nkind of potential intrusion detection,\n\n143\n00:07:29.790 --> 00:07:31.510\nor intrusion that's going on.\n\n144\n00:07:31.510 --> 00:07:33.630\nYou have to be very careful\nwith this though, right?\n\n145\n00:07:33.630 --> 00:07:38.520\nThis is just a ping packet, Cherokee\nprobably wouldn't want to get an alert,\n\n146\n00:07:38.520 --> 00:07:40.540\nright, at two in the morning\nwhen she's sleeping.\n\n147\n00:07:40.540 --> 00:07:42.990\nBecause somebody was pinging the machine,\nright?\n\n148\n00:07:42.990 --> 00:07:46.520\nHowever, if there's a rule that says\nsomething like, this is a sign of denial\n\n149\n00:07:46.520 --> 00:07:48.670\nof service attack,\nthat would be very different, right?\n\n150\n00:07:48.670 --> 00:07:53.210\nSo be careful because you can audit\nevery kind of packet that's coming in.\n\n151\n00:07:53.210 --> 00:07:55.610\nBut that might not be the most\nefficient thing you can have.\n\n152\n00:07:55.610 --> 00:07:57.213\nYou end up having logs that\nare very hard to sift through.\n\n153\n00:07:57.213 --> 00:08:01.991\nIt could become very complex in trying\nto figure out what exactly has happened,\n\n154\n00:08:01.991 --> 00:08:04.001\nif anything has happened at all.\n\n155\n00:08:04.001 --> 00:08:08.710\nAll right, so that's a little bit about\nyour host-based intrusion detection\n\n156\n00:08:08.710 --> 00:08:13.760\nsystems and HIPS, if you will,\nhost-based intrusion prevention system.\n\n157\n00:08:13.760 --> 00:08:18.270\nKeep in mind that one is in line and\none is more passive,\n\n158\n00:08:18.270 --> 00:08:22.620\nif you will, next thing that they call\nout, they call out antivirus, right.\n\n159\n00:08:22.620 --> 00:08:27.090\nAntivirus, a lot of times,\nis kinda easy to interpret.\n\n160\n00:08:27.090 --> 00:08:30.700\nYou'll get things like warnings that'll\npop up on the screen that says,\n\n161\n00:08:30.700 --> 00:08:34.150\nhey, this machine has\nbeen infected by a file.\n\n162\n00:08:34.150 --> 00:08:38.150\nThe antivirus software, hopefully,\nis taking steps to quarantine,\n\n163\n00:08:38.150 --> 00:08:41.120\nremediate, right, and\nthen delete all those files.\n\n164\n00:08:41.120 --> 00:08:45.974\nRemember, it's about identification,\nfirst of all, it's about detection, right.\n\n165\n00:08:45.974 --> 00:08:50.811\nWe don't necessarily identify it right\naway, but detection, identification,\n\n166\n00:08:50.811 --> 00:08:53.100\nquarantine and remediation, right.\n\n167\n00:08:53.100 --> 00:08:56.287\nAnd we have to make sure that\nwe're checking the output, and\n\n168\n00:08:56.287 --> 00:08:59.930\nthat our anti-virus software is\ndoing exactly what we want it to do.\n\n169\n00:08:59.930 --> 00:09:02.340\nSo, let me give you an example,\nI've got a test file here,\n\n170\n00:09:02.340 --> 00:09:06.660\nmaybe you've heard of this file before,\nthe EICAR virus string.\n\n171\n00:09:06.660 --> 00:09:08.430\nNow this isn't a virus, guys, but\n\n172\n00:09:08.430 --> 00:09:12.208\nthis little string of information minus\nsome of the extra information that I\n\n173\n00:09:12.208 --> 00:09:15.928\nput in here is just a industry wide\nstandard to test the real time protection\n\n174\n00:09:15.928 --> 00:09:19.793\nof your antivirus software to see is it\ndoing what it's supposed to be doing.\n\n175\n00:09:19.793 --> 00:09:24.724\nNow as I take these extra characters out,\nyou're gonna notice that it's\n\n176\n00:09:24.724 --> 00:09:28.542\ngonna come up quick that my\nhead's kinda covering it up,\n\n177\n00:09:28.542 --> 00:09:32.836\nthat hopefully, Windows Defender\nis gonna see this as a virus,\n\n178\n00:09:32.836 --> 00:09:37.070\nthe moment I save it and\nlet's see what ends up happening here.\n\n179\n00:09:37.070 --> 00:09:41.830\nLet's go ahead and we'll do a Ctrl S,\nwe'll save that, and as you notice it is\n\n180\n00:09:41.830 --> 00:09:47.930\ntelling me, found some malware, Windows\nDefender is now removing it, right.\n\n181\n00:09:47.930 --> 00:09:50.720\nSo we want to know that,\nright, we want to know that,\n\n182\n00:09:50.720 --> 00:09:55.030\nhey our antivirus software\nis stopping the problem.\n\n183\n00:09:55.030 --> 00:09:58.880\nNow I could close this down and\nI could try to open it back up.\n\n184\n00:09:58.880 --> 00:10:01.740\nAnd yeah, notice that it won't\neven let me open up that file.\n\n185\n00:10:01.740 --> 00:10:05.900\nIt's in the middle of quarantining\nthis and it's telling me\n\n186\n00:10:05.900 --> 00:10:10.160\nOperation did not complete successfully\nbecause the file contains a virus or\n\n187\n00:10:10.160 --> 00:10:13.470\npotentially unwanted software, right.\n\n188\n00:10:13.470 --> 00:10:15.490\nAnd that really is\nthe definition of a virus,\n\n189\n00:10:15.490 --> 00:10:17.967\nit's anything that you\ndidn't wanna run all right.\n\n190\n00:10:17.967 --> 00:10:21.590\nSo we'll go ahead, we'll say okay to that,\nwe're not gonna worry about this file and\n\n191\n00:10:21.590 --> 00:10:25.840\nyou can even see that by now\nthe reason it couldn't open that file.\n\n192\n00:10:25.840 --> 00:10:28.080\nNotice it isn't in the recycle bin, right,\n\n193\n00:10:28.080 --> 00:10:29.800\nnotice that it's not\non my desktop anymore.\n\n194\n00:10:29.800 --> 00:10:33.920\nIt's gone, right,\nthe antivirus software is doing its job.\n\n195\n00:10:33.920 --> 00:10:37.250\nNow, this one,\non the other hand, this is not\n\n196\n00:10:38.410 --> 00:10:42.990\nan industry wide standard for\ntesting antivirus software.\n\n197\n00:10:42.990 --> 00:10:47.380\nThis is actually a form of malware, this\nis one of the ransomware cryptolockers, so\n\n198\n00:10:47.380 --> 00:10:48.930\nwe gotta be careful with this one.\n\n199\n00:10:48.930 --> 00:10:52.540\nAnd let me just double check\nwith my network adapter, and\n\n200\n00:10:52.540 --> 00:10:54.700\nmake sure we're not plugged\ninto my network here.\n\n201\n00:10:54.700 --> 00:10:58.520\nJust double check here real quick,\nwe've gotta be safe, right?\n\n202\n00:10:58.520 --> 00:11:02.780\nAnd you're gonna notice, the same thing's\ngonna happen when I try to extract this.\n\n203\n00:11:02.780 --> 00:11:07.000\nWe'll go ahead, we'll try this process\nit's actually password protected.\n\n204\n00:11:07.000 --> 00:11:12.910\nAnd when I try to extract it, I should\nget that it's been password protected.\n\n205\n00:11:12.910 --> 00:11:15.850\nAll right so I'm gonna go ahead and\nI'm gonna enter the password.\n\n206\n00:11:15.850 --> 00:11:20.370\nAnd just like we did before, it's gonna\ncome up quick but what we should see\n\n207\n00:11:20.370 --> 00:11:24.570\nwith my head covering it up is that we\ndo have another one of those where,\n\n208\n00:11:24.570 --> 00:11:28.740\nhopefully Windows finds this as malware.\n\n209\n00:11:28.740 --> 00:11:31.400\nNotice it did too,\nit said found some malware, and\n\n210\n00:11:31.400 --> 00:11:33.040\nWindows Defender is removing it.\n\n211\n00:11:33.040 --> 00:11:37.280\nAnd that's what we want, that lets\nme know that Windows Defender, or\n\n212\n00:11:37.280 --> 00:11:41.780\nin this case the anti-malware, antivirus\nsoftware, is running appropriately.\n\n213\n00:11:41.780 --> 00:11:46.340\nAnd it's doing what I want it to do, now\nlet's dig down into the Windows Defender\n\n214\n00:11:46.340 --> 00:11:50.080\nsoftware and\nfind out kinda what it's seeing,\n\n215\n00:11:50.080 --> 00:11:52.940\nand if it's giving us any kind of\nreports as to what is going on.\n\n216\n00:11:52.940 --> 00:11:55.380\nSo I'm gonna go ahead and\nright-click, on my Windows icon,\n\n217\n00:11:55.380 --> 00:11:57.150\nI'm gonna chose Control Panel.\n\n218\n00:11:57.150 --> 00:12:00.970\nWe'll choose System and Security, and\nyou know what's actually easier for me?\n\n219\n00:12:00.970 --> 00:12:04.090\nIt's always been easier for me to get to\nWindows Defender if I just go ahead and\n\n220\n00:12:04.090 --> 00:12:07.570\nI separate from Category View\nto Large Icons.\n\n221\n00:12:07.570 --> 00:12:10.470\nBecause then I know it's all\nthe way down here at the bottom at\n\n222\n00:12:10.470 --> 00:12:12.260\nthe center column here.\n\n223\n00:12:12.260 --> 00:12:15.350\nJust for me, it's easy for\nme to remember it.\n\n224\n00:12:15.350 --> 00:12:16.120\nAll right, I'm gonna go and\n\n225\n00:12:16.120 --> 00:12:19.190\nclose this because what I wanna\nlook at is the history, right.\n\n226\n00:12:19.190 --> 00:12:20.940\nDo we have any quarantined items?\n\n227\n00:12:20.940 --> 00:12:24.740\nNow, notice that I don't have\nanything in my recycle bin, so\n\n228\n00:12:24.740 --> 00:12:28.380\nchances are there aren't\nany quarantined items here.\n\n229\n00:12:28.380 --> 00:12:34.000\nThe EICAR virus test is, see, so I can see\nthat it has identified this as a virus.\n\n230\n00:12:34.000 --> 00:12:38.971\nNow keep in mind this program,\nthis one here it isn't a virus in anyway,\n\n231\n00:12:38.971 --> 00:12:41.008\nbut it's used, like I said,\n\n232\n00:12:41.008 --> 00:12:46.530\nas a standard to test the real time\nprotection of your antivirus software.\n\n233\n00:12:46.530 --> 00:12:49.140\nBut I also wanna look at deleted items,\nand I want you to kinda\n\n234\n00:12:49.140 --> 00:12:53.240\nunderstand something here, notice\nthat there's this little shield here.\n\n235\n00:12:53.240 --> 00:12:56.660\nAnd if you're familiar with Windows, that\nmeans that it takes administrative level\n\n236\n00:12:56.660 --> 00:13:00.070\nprivileges in order to see this\ninformation, and why is that?\n\n237\n00:13:00.070 --> 00:13:03.780\nCuz this could potentially have\ninformation that a standard user really\n\n238\n00:13:03.780 --> 00:13:04.570\nshouldn't be looking at,\n\n239\n00:13:04.570 --> 00:13:07.590\nand that's why they require administrative\nlevel privileges to see the logs.\n\n240\n00:13:07.590 --> 00:13:12.750\nAnd if I choose this,\nnotice that I get some information, right.\n\n241\n00:13:12.750 --> 00:13:15.770\nI get some information that it\ndetected the ransomware here,\n\n242\n00:13:15.770 --> 00:13:18.920\nthe Crytpolocker virus\nthat we just looked at.\n\n243\n00:13:18.920 --> 00:13:25.420\nAnd if I decide to select this,\nright, I can apply an action to it.\n\n244\n00:13:25.420 --> 00:13:29.710\nI can either remove it, or I can allow it,\nagain, both of these are quarantined.\n\n245\n00:13:29.710 --> 00:13:33.705\nBut we're gonna go ahead and we'll do\nthe remediation, and we'll go ahead and\n\n246\n00:13:33.705 --> 00:13:35.260\nchoose the remove all option.\n\n247\n00:13:35.260 --> 00:13:37.220\nAnd now we have a clean system,\n\n248\n00:13:37.220 --> 00:13:41.810\nnow keep in mind had I not had real-time\nprotection, had I not had some\n\n249\n00:13:41.810 --> 00:13:45.770\nkind of antivirus software on the machine,\nwe wouldn't even have been aware of that.\n\n250\n00:13:45.770 --> 00:13:48.600\nAnd that's where you can get\ninto a little bit of trouble.\n\n251\n00:13:48.600 --> 00:13:52.720\nThe other thing, too, sometimes people\nwill do is they'll disable notifications.\n\n252\n00:13:52.720 --> 00:13:56.240\nBecause well, you just don't wanna be\nbugged by it, and I understand that.\n\n253\n00:13:56.240 --> 00:14:01.210\nKeep in mind that also you won't be aware\nof when you're under an attack, right.\n\n254\n00:14:01.210 --> 00:14:05.520\nIf you go to a certain website,\nmaybe you go into a gaming site or\n\n255\n00:14:05.520 --> 00:14:09.550\nsomething like that, right, and\nyou've disabled the notifications, right.\n\n256\n00:14:09.550 --> 00:14:12.770\nYou've disable the notifications cuz\nyou don't want it being intrusive.\n\n257\n00:14:12.770 --> 00:14:16.790\nBut if those notifications were there, and\nthey kept popping up, you would know that\n\n258\n00:14:16.790 --> 00:14:19.410\nhey, there's something going on on\nthis site that I need to back out.\n\n259\n00:14:19.410 --> 00:14:23.530\nI just need to stay away from it, whatever\nmight be happening, so be careful.\n\n260\n00:14:23.530 --> 00:14:26.690\nAgain, I understand the intrusive\nnature of pop-ups and warnings,\n\n261\n00:14:26.690 --> 00:14:28.040\nespecially if it's in presentations.\n\n262\n00:14:28.040 --> 00:14:31.520\nI mean, it has its use to disable it,\nbut permanently disabling it,\n\n263\n00:14:31.520 --> 00:14:36.190\nyou might not recognize that you're\nactually under some kind of a threat, and\n\n264\n00:14:36.190 --> 00:14:39.340\nyou won't be aware of it because\nyou've disabled those notifications.\n\n265\n00:14:39.340 --> 00:14:41.070\n&gt;&gt; All right Wes,\nwhat are we gonna be looking at next?\n\n266\n00:14:41.070 --> 00:14:43.733\n&gt;&gt; Well, we've kinda talked about\ndifferent things like message\n\n267\n00:14:43.733 --> 00:14:44.480\ndigest, right.\n\n268\n00:14:44.480 --> 00:14:47.910\nWe've talked about, and in fact, we've\nseen it in other episodes where we were\n\n269\n00:14:47.910 --> 00:14:49.850\nlooking at things like\nIP suck communications.\n\n270\n00:14:49.850 --> 00:14:52.420\nAnd I mentioned things like\nintegrity check values.\n\n271\n00:14:52.420 --> 00:14:55.554\nWe've mentioned things\nlike message digest 5,\n\n272\n00:14:55.554 --> 00:14:58.693\nand SHA1, and\nwhy we should be using SHA256.\n\n273\n00:14:58.693 --> 00:15:04.090\nWe've talked about what these\ntechnologies are, right.\n\n274\n00:15:04.090 --> 00:15:08.089\nWe've said, hey, that it verifies\nthe integrity of a piece of information,\n\n275\n00:15:08.089 --> 00:15:08.886\nlike an IPsec.\n\n276\n00:15:08.886 --> 00:15:12.322\nIf I send a packet of data between\nCherokee's computer and mine, and\n\n277\n00:15:12.322 --> 00:15:14.337\nwe're having an IPsec communication,\n\n278\n00:15:14.337 --> 00:15:18.367\nher computer can check every single\npacket that's sent in that communication,\n\n279\n00:15:18.367 --> 00:15:20.818\nby looking at the little\nintegrity check value.\n\n280\n00:15:20.818 --> 00:15:24.845\nAnd the fixed check sum, the fixed\nlink value that's put at the end and\n\n281\n00:15:24.845 --> 00:15:26.219\ncompare them, right.\n\n282\n00:15:26.219 --> 00:15:28.926\nIf the values matched,\nthen we know that the data is good,\n\n283\n00:15:28.926 --> 00:15:32.810\nif the values don't match, then we\nknow that there is something wrong.\n\n284\n00:15:32.810 --> 00:15:33.330\nAll right, and\n\n285\n00:15:33.330 --> 00:15:39.180\nit's up us to make sure that we're\nusing these technologies appropriately.\n\n286\n00:15:39.180 --> 00:15:42.640\nBut there are other technologies out there\nwhere you can actually see this in place.\n\n287\n00:15:42.640 --> 00:15:47.228\nIn fact, I've got one here on the Mac\nit's called QuickHash, all right.\n\n288\n00:15:47.228 --> 00:15:51.578\nAnd then this is one that we\ncan kinda run, so for instance,\n\n289\n00:15:51.578 --> 00:15:53.582\nI could, let's see here.\n\n290\n00:15:53.582 --> 00:15:57.575\nSo for instance I could take like a file,\nfor instance.\n\n291\n00:15:57.575 --> 00:15:58.419\nRight?\n\n292\n00:15:58.419 --> 00:16:02.139\nOr just, I'll tell you what, we'll\ncompare a couple of files, all right?\n\n293\n00:16:02.139 --> 00:16:05.819\nSo this file here,\nthat I've labeled file integrity,\n\n294\n00:16:05.819 --> 00:16:09.830\nnotice that it says,\nThis is my important text, all right?\n\n295\n00:16:09.830 --> 00:16:12.332\nSo that's the information\nthat's inside of this file.\n\n296\n00:16:12.332 --> 00:16:16.408\nWhat I'm gonna go ahead and do is,\nI'm gonna copy this file, all right, and\n\n297\n00:16:16.408 --> 00:16:18.745\nI'm gonna go ahead and paste another copy.\n\n298\n00:16:18.745 --> 00:16:22.000\nWe'll just go ahead and paste it\nright over here to the Desktop, okay?\n\n299\n00:16:22.000 --> 00:16:26.800\nSo I've got one in the folder, and\nit should be the same file, right?\n\n300\n00:16:26.800 --> 00:16:28.570\nLet's find out, I don't know.\n\n301\n00:16:28.570 --> 00:16:31.660\nSo we got this option here that\nwe can compare two files, right?\n\n302\n00:16:31.660 --> 00:16:34.156\nJust like we've kinda told\nyou checksums allow us to do.\n\n303\n00:16:34.156 --> 00:16:36.540\nSo I'm gonna go ahead and\nselect the first file, all right?\n\n304\n00:16:36.540 --> 00:16:41.100\nAnd that file is inside of The sha_folder.\n\n305\n00:16:41.100 --> 00:16:42.860\nAnd we'll go ahead and load that up.\n\n306\n00:16:42.860 --> 00:16:46.367\nAll right, and\nthen we're gonna select the second file.\n\n307\n00:16:46.367 --> 00:16:49.873\nAnd remember that was the one that\nwas right there on the Desktop,\n\n308\n00:16:49.873 --> 00:16:51.710\nnot in the folder.\n\n309\n00:16:51.710 --> 00:16:55.270\nAnd we'll go ahead, and\nnow we've got these two files, all right?\n\n310\n00:16:55.270 --> 00:16:57.804\nAnd what we're gonna do is we're\ngonna do a comparison, and\n\n311\n00:16:57.804 --> 00:17:00.820\nwe're gonna do a comparison in SHA256.\n\n312\n00:17:01.940 --> 00:17:04.850\nNow for us guys,\nI don't expect you guys or\n\n313\n00:17:04.850 --> 00:17:07.260\nCherokee to remember\nthis long crazy number.\n\n314\n00:17:07.260 --> 00:17:12.110\nI just want you guys to kinda focus\nin on the last few digits, right?\n\n315\n00:17:12.110 --> 00:17:16.632\nNotice how we got B5B207, B5B207?\n\n316\n00:17:16.632 --> 00:17:20.990\nIt lets me know that these\nfiles are identical, all right?\n\n317\n00:17:20.990 --> 00:17:23.710\nBut what happens if we make modifications?\n\n318\n00:17:23.710 --> 00:17:26.090\nWell, I'll tell you what, the one\nthat we copied here on the Desktop,\n\n319\n00:17:26.090 --> 00:17:29.000\nI'm gonna go ahead and\nI'm gonna add just a single space.\n\n320\n00:17:29.000 --> 00:17:30.580\nI want you to notice that.\n\n321\n00:17:30.580 --> 00:17:34.543\nI didn't add a comma,\nI didn't an extra character.\n\n322\n00:17:34.543 --> 00:17:38.050\nWell, I guess I kinda did with the space,\nbut I didn't add any text.\n\n323\n00:17:38.050 --> 00:17:40.300\nAnd we'll go ahead and\nwe're gonna save that.\n\n324\n00:17:40.300 --> 00:17:43.355\nAnd I'm gonna compare that\nfile now a second time, right?\n\n325\n00:17:43.355 --> 00:17:48.209\nSo File B, we're gonna select that\none from the Desktop again, and\n\n326\n00:17:48.209 --> 00:17:52.580\nwe'll choose that one, and\nwe'll calculate it again.\n\n327\n00:17:52.580 --> 00:17:56.240\nAll I did was added\na single space to the file.\n\n328\n00:17:56.240 --> 00:17:59.796\nAnd now I want you to notice something,\nnotice the B5B207?\n\n329\n00:17:59.796 --> 00:18:02.880\nThe first one hasn't changed,\nwe didn't do anything to that one.\n\n330\n00:18:02.880 --> 00:18:06.205\nBut notice this last part,\nnotice that it has changed.\n\n331\n00:18:06.205 --> 00:18:08.277\nAnd that this would be the point, right,\n\n332\n00:18:08.277 --> 00:18:12.499\nwhen you're talking about packet\nintegrity, communication integrity, right?\n\n333\n00:18:12.499 --> 00:18:14.432\nWhere we talk about that CIA triad,\n\n334\n00:18:14.432 --> 00:18:17.585\nmaking sure that the data\nstays in its original state?\n\n335\n00:18:17.585 --> 00:18:20.498\nWell this is what these hashing\nalgorithms allow us to do.\n\n336\n00:18:20.498 --> 00:18:24.275\nAnd a lot of times they're built\ninto the technologies that we use.\n\n337\n00:18:24.275 --> 00:18:28.570\nAnd we don't actually see them unless\nwe're running a protocol analyzer\n\n338\n00:18:28.570 --> 00:18:30.830\nto actually see that.\n\n339\n00:18:30.830 --> 00:18:35.029\nNow this isn't the only place that you\ncan see, for instance, these hash values.\n\n340\n00:18:35.029 --> 00:18:39.673\nFor instance, if I jump back over to\nmy sent box that I'm logged into here,\n\n341\n00:18:39.673 --> 00:18:42.470\nlet me find out where the heck I am,\nand do I?\n\n342\n00:18:42.470 --> 00:18:46.672\nOkay, so If I create a file right\nhere real quick, and again,\n\n343\n00:18:46.672 --> 00:18:49.440\nLinux distro here,\nthis happens to be sent, all right?\n\n344\n00:18:49.440 --> 00:18:53.102\nSo we'll do touch,\nwe'll do file1, we'll do txt.\n\n345\n00:18:53.102 --> 00:18:59.900\nAll right, now, if I do a list, you can\nsee that here's my file, right, file1.txt.\n\n346\n00:18:59.900 --> 00:19:05.526\nAnd we'll go ahead and we'll do a vi\nfile1.txt, and let's go ahead and\n\n347\n00:19:05.526 --> 00:19:11.100\nwe'll add some information to this\nfile here, real quick, all right?\n\n348\n00:19:11.100 --> 00:19:17.368\nSo we'll do, This is my important text,\n\n349\n00:19:17.368 --> 00:19:23.560\nall right, and we'll go ahead and\nwe will get out of that.\n\n350\n00:19:23.560 --> 00:19:27.940\nWe'll save this, all right, all right?\n\n351\n00:19:27.940 --> 00:19:30.440\nAnd now let's just verify\nthat that file is created.\n\n352\n00:19:30.440 --> 00:19:32.552\nWe'll open it up one more time,\nand you can see hey,\n\n353\n00:19:32.552 --> 00:19:35.010\nokay, This is my important text,\nall right?\n\n354\n00:19:35.010 --> 00:19:38.830\nSo let's go ahead and Esc out of that,\nand now we've got that file.\n\n355\n00:19:38.830 --> 00:19:46.010\nAll right, so we can actually run hashing\nalgorithms right here on our machine.\n\n356\n00:19:46.010 --> 00:19:47.090\nThis is built-in, right?\n\n357\n00:19:47.090 --> 00:19:48.800\nSo I can do something like this.\n\n358\n00:19:48.800 --> 00:19:54.815\nI can do a sha256sum,\nif I know how to spell 256.\n\n359\n00:19:54.815 --> 00:19:59.880\n[LAUGH] We'll do a sum, and we'll do\nfile1 and we'll let that run, all right?\n\n360\n00:19:59.880 --> 00:20:05.550\nNow I want you to notice,\nnotice the fixed length value here.\n\n361\n00:20:05.550 --> 00:20:09.890\nI'm certainly not going to expect you guys\nto remember that or will I remember that.\n\n362\n00:20:09.890 --> 00:20:13.490\nSo what I'm gonna do here is we'll take\na little quick screenshot of it and\n\n363\n00:20:13.490 --> 00:20:15.320\nwe'll save that for later, all right?\n\n364\n00:20:15.320 --> 00:20:17.953\nNow I'm gonna rerun our vi command.\n\n365\n00:20:17.953 --> 00:20:22.291\nAnd I'm gonna get in here and what I'm\ngonna do is I'll do that exact same thing\n\n366\n00:20:22.291 --> 00:20:24.560\nthat we just did on the Mac, right?\n\n367\n00:20:24.560 --> 00:20:30.066\nI'm gonna add one letter, or\nactually let's make it fun.\n\n368\n00:20:30.066 --> 00:20:36.470\nThis is my evil text.\n\n369\n00:20:36.470 --> 00:20:43.670\nAnd then we'll put a MWAHAHAHAHA in there,\ncuz you gotta have that or it's not legit.\n\n370\n00:20:43.670 --> 00:20:46.920\nAll right, so we've modified\nthe file a little bit, okay?\n\n371\n00:20:46.920 --> 00:20:51.000\nLet's go ahead and\nwe'll rerun our sha256sum.\n\n372\n00:20:51.000 --> 00:20:54.910\nAnd we'll go ahead, and what we're\ngonna do, I'll do the same thing here.\n\n373\n00:20:54.910 --> 00:20:58.589\nLet's just take a real quick\nscreenshot of this value, and\n\n374\n00:20:58.589 --> 00:21:01.397\nthen we'll jump back to the Desktop, okay?\n\n375\n00:21:01.397 --> 00:21:03.910\nSo here I have the two screen\nshots of those values,\n\n376\n00:21:03.910 --> 00:21:05.435\nkinda easier to compare here.\n\n377\n00:21:05.435 --> 00:21:11.090\nWe'll open this one up, notice this is the\nfirst time we took that screenshot, right?\n\n378\n00:21:11.090 --> 00:21:13.630\nAnd the second screen shot.\n\n379\n00:21:13.630 --> 00:21:17.060\nNow, Cherokee,\nI'm gonna throw you a curve ball here.\n\n380\n00:21:17.060 --> 00:21:21.164\nCan you see the end of those files,\nand do they look to be different,\n\n381\n00:21:21.164 --> 00:21:23.616\njust kinda looking at the last few here?\n\n382\n00:21:23.616 --> 00:21:27.230\n&gt;&gt; 96c69, 96, yeah they look different.\n\n383\n00:21:27.230 --> 00:21:31.370\n&gt;&gt; No kidding, so\nmy evil text, right, [LAUGH]\n\n384\n00:21:31.370 --> 00:21:32.570\nwe could verify, right?\n\n385\n00:21:32.570 --> 00:21:35.675\nThis is the same thing that for\ninstance your network adapters are doing,\n\n386\n00:21:35.675 --> 00:21:37.141\nIP set communications are doing.\n\n387\n00:21:37.141 --> 00:21:41.228\nWhy we want it to run things like sha\nsums, if you will, over our documents.\n\n388\n00:21:41.228 --> 00:21:45.587\nTo make sure that part of that CIA not\nonly confidentiality, that integrity,\n\n389\n00:21:45.587 --> 00:21:50.320\nthat data stays in its orignal state,\nand hasn't been modified in transit.\n\n390\n00:21:50.320 --> 00:21:51.530\nWhether it be a malicious attack,\n\n391\n00:21:51.530 --> 00:21:53.820\nor whether it just be transmission errors,\nright?\n\n392\n00:21:53.820 --> 00:21:54.720\nAnd that can happen.\n\n393\n00:21:54.720 --> 00:21:58.438\nSo you can see things like your file\nintegrity checks, that you can do.\n\n394\n00:21:58.438 --> 00:22:03.255\nAnd a couple of cool little tools,\nthat you can kinda do this yourself,\n\n395\n00:22:03.255 --> 00:22:04.750\nif need be.\n\n396\n00:22:04.750 --> 00:22:08.900\nNow Cherokee I'm looking at our list and\nI know I've got a lot more to go, but\n\n397\n00:22:08.900 --> 00:22:11.640\nI think we're running a little\nbit low on time on this one.\n\n398\n00:22:11.640 --> 00:22:14.180\n&gt;&gt; All right, so that's fine Wes,\nwe don't wanna rush through anything.\n\n399\n00:22:14.180 --> 00:22:16.980\nWe'll go ahead and save the rest of\nthe information, we'll have a part two.\n\n400\n00:22:16.980 --> 00:22:19.900\nSo, ladies and gentlemen,\nstay tuned for that information.\n\n401\n00:22:19.900 --> 00:22:21.480\nFor this show,\nwe'll go ahead and sign off.\n\n402\n00:22:21.480 --> 00:22:23.037\nRemember, I'm your host Cherokee Boose.\n\n403\n00:22:23.037 --> 00:22:23.890\n&gt;&gt; And I'm Wes Bryan.\n\n404\n00:22:23.890 --> 00:22:27.481\n&gt;&gt; See you next time here at ITProTV.\n\n405\n00:22:27.481 --> 00:22:32.846\n[MUSIC]\n\n406\n00:22:32.846 --> 00:22:36.000\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213514478"
        },
        {
          "description": "In this show Cherokee and Wes continue to analyze and interpret the output of various tools. They begin with firewalls and continue to examine additional tools such as Microsoft's AppLocker followed with assorted malware utilities.",
          "length": "1366",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-4-2-analyze_and_interpret_outputs_pt2-041217-PGM.00_22_33_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-4-2-analyze_and_interpret_outputs_pt2-041217-PGM.00_22_33_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-4-2-analyze_and_interpret_outputs_pt2-041217-PGM.00_22_33_07.Still001-sm.jpg",
          "title": "Analyze and Interpret Outputs Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.290 --> 00:00:02.853\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.853 --> 00:00:06.024\n[CROSSTALK]\n\n3\n00:00:06.024 --> 00:00:07.746\n[MUSIC]\n\n4\n00:00:07.746 --> 00:00:11.011\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.170 --> 00:00:14.640\nWelcome to your CompTIA Security+ series.\n\n6\n00:00:14.640 --> 00:00:16.790\nI'm your show host, Cherokee Boose.\n\n7\n00:00:16.790 --> 00:00:20.750\nToday, we're gonna be continuing\na discussion where we're interpreting and\n\n8\n00:00:20.750 --> 00:00:24.570\nanalyzing different outputs from\nvarious tools and utilities.\n\n9\n00:00:24.570 --> 00:00:26.705\nAnd with us today, back in studios,\nwe have Mr Wes Bryan.\n\n10\n00:00:26.705 --> 00:00:28.130\nThank you for joining us, Wes.\n\n11\n00:00:28.130 --> 00:00:29.480\n&gt;&gt; Thanks for having me back, Cherokee.\n\n12\n00:00:29.480 --> 00:00:33.500\nThat's right, we are going to be looking\nat things like well, our firewalls.\n\n13\n00:00:33.500 --> 00:00:37.824\nWe got a handful of things that we\njust couldn't fit in the first one, so\n\n14\n00:00:37.824 --> 00:00:40.072\nI went ahead and we made it a part two.\n\n15\n00:00:40.072 --> 00:00:43.740\nOne of the first things that they call\nout, our host base firewalls, right?\n\n16\n00:00:43.740 --> 00:00:48.530\nAnalyzing the output of your firewall, and\nthis can be done in different ways, right?\n\n17\n00:00:48.530 --> 00:00:50.841\nFor instance,\ninside in your Windows Base System,\n\n18\n00:00:50.841 --> 00:00:53.372\nyou have your\nWindows Firewall With Advanced Security.\n\n19\n00:00:53.372 --> 00:00:57.728\nIn your mixed based systems like Linux,\nyou have things like IP tables, if you\n\n20\n00:00:57.728 --> 00:01:02.684\nwill, and then you have a firewall-cmd for\nsome of the newer implementations, right?\n\n21\n00:01:02.684 --> 00:01:07.172\nSo most of your major operating\nsystems today have some kind of\n\n22\n00:01:07.172 --> 00:01:09.980\nfirewall baked right into them.\n\n23\n00:01:09.980 --> 00:01:13.050\nSo that you don't have to go\nthrough a third party and buy one.\n\n24\n00:01:13.050 --> 00:01:16.432\nYou might remember the days before Service\nPack 3 going all the way back to XP.\n\n25\n00:01:16.432 --> 00:01:19.274\nI think Service Pack 2 actually\nthat brought in things\n\n26\n00:01:19.274 --> 00:01:21.882\nlike Windows Defender and\nthe Windows Firewall.\n\n27\n00:01:21.882 --> 00:01:26.537\nI remember prior to that, prior to\nService Pack 2 of XP, going out to like\n\n28\n00:01:26.537 --> 00:01:30.460\nthird parties like ZoneAlarm was\none that I used to use today.\n\n29\n00:01:30.460 --> 00:01:33.690\nBut thank goodness today,\nmost of the major operating systems,\n\n30\n00:01:33.690 --> 00:01:37.440\nas far as I'm aware of, including Windows,\nhave a firewall built right into it to\n\n31\n00:01:37.440 --> 00:01:40.890\ngive you the functionality that you\nneed so that you are protected.\n\n32\n00:01:40.890 --> 00:01:44.838\nEven if you do decide that maybe you wanna\ngo with a third party type firewall,\n\n33\n00:01:44.838 --> 00:01:48.299\nit's nice to have something in place\nalready so that you can set it,\n\n34\n00:01:48.299 --> 00:01:50.144\nit's active and it's ready to go.\n\n35\n00:01:50.144 --> 00:01:53.584\nNow, one of the things that you\ncan also keep in mind is that,\n\n36\n00:01:53.584 --> 00:01:57.440\nwe're looking at analyzing\nthe output of different logs, right?\n\n37\n00:01:57.440 --> 00:02:00.450\nSo, let's go ahead and\nlet's jump down into our Windows machine.\n\n38\n00:02:00.450 --> 00:02:01.940\nAnd, which machine am I on?\n\n39\n00:02:01.940 --> 00:02:02.829\nOkay, Windows 10 machine here.\n\n40\n00:02:02.829 --> 00:02:07.181\nThere are some settings that\nyou have to configure because,\n\n41\n00:02:07.181 --> 00:02:12.400\naccording to logs, right,\ncertain logs aren't turned on by default.\n\n42\n00:02:12.400 --> 00:02:16.220\nBecause if people don't utilize the logs,\nthe logs in and\n\n43\n00:02:16.220 --> 00:02:19.820\nof themselves can become\na performance hindrance, right?\n\n44\n00:02:19.820 --> 00:02:22.340\nSo, keep in mind that if you\ndo turn the logs on, and\n\n45\n00:02:22.340 --> 00:02:26.930\nyou have no intentions of using them,\nthere's no reason to turn them on.\n\n46\n00:02:26.930 --> 00:02:28.923\nSo, there are a couple of things\nthat you have to do here, in fact.\n\n47\n00:02:28.923 --> 00:02:30.299\nI'm gonna go ahead and\n\n48\n00:02:30.299 --> 00:02:35.320\nI'll do this through the local\nGroup Policy on this Windows 10 machine.\n\n49\n00:02:35.320 --> 00:02:40.010\nWe'll go ahead and\nopen up our Group Policy Editor.\n\n50\n00:02:40.010 --> 00:02:43.490\nWe'll do a gpedit.msc.\n\n51\n00:02:43.490 --> 00:02:46.703\nRight, bring up our Local Group Policy\nEditor here and then we're gonna get down\n\n52\n00:02:46.703 --> 00:02:49.128\ninto the security settings\nunder Computer Configuration.\n\n53\n00:02:49.128 --> 00:02:52.856\nRight, We're gonna be under\nWindows Settings, then we'll be under our\n\n54\n00:02:52.856 --> 00:02:56.760\nSecurity Settings, and then if we kind\nof scroll down just a little bit here,\n\n55\n00:02:56.760 --> 00:03:00.560\nyou can see we have the Windows Firewall\nwith Advanced Security.\n\n56\n00:03:00.560 --> 00:03:03.100\nAll right, now, when they talk\nabout interpreting the output,\n\n57\n00:03:03.100 --> 00:03:05.960\nyou won't have any output if you don't\nmake some configuration changes.\n\n58\n00:03:05.960 --> 00:03:08.800\nAnd that's the reason I've already\nmade these configuration changes.\n\n59\n00:03:08.800 --> 00:03:11.790\nBut, at least you'll be aware\nof where you have to do this.\n\n60\n00:03:11.790 --> 00:03:15.210\nSo, we're just gonna right click on the\nWindows Firewall with Advanced Security,\n\n61\n00:03:15.210 --> 00:03:16.650\nwe're gonna choose Properties.\n\n62\n00:03:17.750 --> 00:03:22.830\nNow, pay attention, remember that Windows\nfor instance, the Microsoft or Windows\n\n63\n00:03:22.830 --> 00:03:26.820\noperating system, it supports something\nknown as NLA, Network Location Awareness.\n\n64\n00:03:26.820 --> 00:03:30.597\nReally cool functionality that just says,\nhey, based on what network you're located,\n\n65\n00:03:30.597 --> 00:03:33.987\nyou, the choice you make, we're gonna\nset a global suite of settings, right?\n\n66\n00:03:33.987 --> 00:03:34.916\nThat's a profile,\n\n67\n00:03:34.916 --> 00:03:38.310\na global suite of security settings\non the firewall based on that choice.\n\n68\n00:03:38.310 --> 00:03:42.236\nSo you have to pay attention to what\nthe current network location is,\n\n69\n00:03:42.236 --> 00:03:46.092\nbecause if you turn logging on,\nlet's say to a Domain Profile, but\n\n70\n00:03:46.092 --> 00:03:50.330\nyou're connected to a Public Profile and\nit don't turned logging on?\n\n71\n00:03:50.330 --> 00:03:53.400\nWhile you might have turned logging on,\none of the network locations and one of\n\n72\n00:03:53.400 --> 00:03:57.000\nthe profiles types but you haven't turned\nit on, on the one you're connected to.\n\n73\n00:03:57.000 --> 00:04:00.784\nSo what I'll do a lot times and so\nI go down to Network and Sharing Center,\n\n74\n00:04:00.784 --> 00:04:03.080\nI'll open up Network and\nSharing Center and\n\n75\n00:04:03.080 --> 00:04:05.826\nI find out what network\nlocation I'm connected to.\n\n76\n00:04:05.826 --> 00:04:10.650\nNow, if this happens to be a laptop,\nright, or any kind of device that's gonna\n\n77\n00:04:10.650 --> 00:04:15.258\nbe doing hopping across different networks\nfrom time to time, I go ahead and\n\n78\n00:04:15.258 --> 00:04:17.850\nI will come down to this Customize option.\n\n79\n00:04:17.850 --> 00:04:19.570\nI know I kinda did that\na little bit too quick.\n\n80\n00:04:19.570 --> 00:04:20.780\nLet me jump back here.\n\n81\n00:04:20.780 --> 00:04:21.748\nNotice that we have the Logging option.\n\n82\n00:04:21.748 --> 00:04:26.733\nI make sure that, if I know it's a laptop,\nand it's going to be moving from network\n\n83\n00:04:26.733 --> 00:04:31.360\nto network, I set each one of the\nindividual profile logging, if you will.\n\n84\n00:04:31.360 --> 00:04:34.710\nJust because I'm not sure which\none's going to be turned on.\n\n85\n00:04:34.710 --> 00:04:36.789\nSo, I figured that we'll make\nsure that all of them are-\n\n86\n00:04:36.789 --> 00:04:37.724\n&gt;&gt; Better safe than sorry.\n\n87\n00:04:37.724 --> 00:04:39.630\n&gt;&gt; That's right, that's right.\n\n88\n00:04:39.630 --> 00:04:42.320\nSo notice that it's asking me,\ndo you want to log dropped packets or\n\n89\n00:04:42.320 --> 00:04:44.040\nsuccessful connections.\n\n90\n00:04:44.040 --> 00:04:46.440\nI'm gonna go ahead and\nI'm gonna log both of these.\n\n91\n00:04:46.440 --> 00:04:48.080\nYou can see that by default it says, No.\n\n92\n00:04:48.080 --> 00:04:50.739\nAnd then it also tells me\nwhere the firewall log is.\n\n93\n00:04:50.739 --> 00:04:53.730\nI'm gonna go ahead and choose OK to this.\n\n94\n00:04:53.730 --> 00:04:54.249\nAnd we'll just run through.\n\n95\n00:04:54.249 --> 00:04:57.443\nAnd even though I know it's\na public profile setting,\n\n96\n00:04:57.443 --> 00:04:59.880\nI'm just gonna go ahead and just verify.\n\n97\n00:04:59.880 --> 00:05:03.450\nNotice, we are logging packets there.\n\n98\n00:05:03.450 --> 00:05:04.580\nWe're good there.\n\n99\n00:05:04.580 --> 00:05:07.080\nOne more time,\nwe'll just kind of check this.\n\n100\n00:05:07.080 --> 00:05:10.888\nAnd notice, the firewall is On,\nand we are also logging there, so\n\n101\n00:05:10.888 --> 00:05:13.680\nwe wanted to make sure\nthat logging is turned on.\n\n102\n00:05:13.680 --> 00:05:18.045\nAnd you can look at that in\nthe local Group Policy object.\n\n103\n00:05:18.045 --> 00:05:20.795\nAgain, keep in mind that in a domain\nenvironment, typically, you're gonna be\n\n104\n00:05:20.795 --> 00:05:23.970\npushing this out through a Group Policy\nthat can affect multiple computers.\n\n105\n00:05:23.970 --> 00:05:27.763\nNot just a single computer cuz that's\na very decentralized configuration\n\n106\n00:05:27.763 --> 00:05:28.975\nmanagement solution.\n\n107\n00:05:28.975 --> 00:05:32.635\nAnd that's one of the reasons we have,\nthings like Microsoft's Active Directory\n\n108\n00:05:32.635 --> 00:05:37.330\nto do that centralized administration with\nthe least amount of administrative effort.\n\n109\n00:05:37.330 --> 00:05:39.110\nAll right so that being said,\nlet's go ahead and\n\n110\n00:05:39.110 --> 00:05:41.830\nlet's take a look at my\nWindows machine here.\n\n111\n00:05:41.830 --> 00:05:47.880\nWe'll dive back into where\nthe firewall log is.\n\n112\n00:05:47.880 --> 00:05:50.476\nAll right, I'm gonna go ahead and\nchoose this PC, LocalDisk C.\n\n113\n00:05:50.476 --> 00:05:54.342\nWe'll get down in here into\nthe Windows directory.\n\n114\n00:05:54.342 --> 00:05:58.520\nAnd then I'm gonna do some,\nI love just typing the letters in here.\n\n115\n00:05:58.520 --> 00:06:00.409\nIt makes it a little easier\nto get to system 32.\n\n116\n00:06:00.409 --> 00:06:05.310\nBe careful, let me just mention this,\ntoo, be careful because in\n\n117\n00:06:05.310 --> 00:06:10.930\nthe Windows folder there is,\nlet me go back up here towards the top.\n\n118\n00:06:10.930 --> 00:06:13.995\nYou do have Logs here,\nbe careful, all right?\n\n119\n00:06:13.995 --> 00:06:16.570\nI'm going to throw my\nJedi mind trick in here.\n\n120\n00:06:16.570 --> 00:06:18.940\nThese are not the logs you're looking for,\nokay?\n\n121\n00:06:18.940 --> 00:06:23.473\nDo keep that in mind, because the ones\nthat we're looking for are in System 32.\n\n122\n00:06:23.473 --> 00:06:30.017\nAnd, it is a directory called LogFiles so,\nkeep that in mind.\n\n123\n00:06:30.017 --> 00:06:31.264\n&gt;&gt; Good to know.\n\n124\n00:06:31.264 --> 00:06:33.827\n&gt;&gt; Yeah, I don't know if they'll\nask you that on the exam, but\n\n125\n00:06:33.827 --> 00:06:37.514\nthat could be one of the questions, maybe\nthey do, and we're gonna look at Firewall.\n\n126\n00:06:37.514 --> 00:06:41.904\nNow the implicit deny says that,\nnobody has access to this file, for\n\n127\n00:06:41.904 --> 00:06:44.940\ninstance, here's our Firewall log, right?\n\n128\n00:06:44.940 --> 00:06:46.340\nAnd if I go and try to open this up.\n\n129\n00:06:47.780 --> 00:06:52.030\nNo food for you, right, I didn't make\nreservations so access is denied.\n\n130\n00:06:52.030 --> 00:06:54.830\nSo keep in mind, I'm gonna go ahead and\nI'm gonna modify the ACL so\n\n131\n00:06:54.830 --> 00:06:57.870\nwe can kind of see what\nis going on in this log.\n\n132\n00:06:57.870 --> 00:07:00.360\nI do see that there's a little bit\nof information here, not much.\n\n133\n00:07:00.360 --> 00:07:05.270\nBut again with text files,\ndoesn't have to be a very beefy file for\n\n134\n00:07:05.270 --> 00:07:07.620\nit to have a lot of\nindividual text in there.\n\n135\n00:07:07.620 --> 00:07:08.520\nSo we're gonna go ahead and\n\n136\n00:07:08.520 --> 00:07:11.940\nwe're gonna right click,\nwe'll right click on the firewall here.\n\n137\n00:07:11.940 --> 00:07:15.040\nAnd it should give us a couple\nof warnings about setting these\n\n138\n00:07:15.040 --> 00:07:16.610\nACLs the way I'm gonna do.\n\n139\n00:07:16.610 --> 00:07:20.065\nBut you'll notice it says,\nMust have Read permission to do this.\n\n140\n00:07:20.065 --> 00:07:24.005\nSo I'm gonna go down to our\nAdvanced permissions editor, right?\n\n141\n00:07:24.005 --> 00:07:26.685\nI'm gonna change the principle\nthat's behind this.\n\n142\n00:07:26.685 --> 00:07:28.525\nAnd who do we have, who am I logged in?\n\n143\n00:07:28.525 --> 00:07:32.405\nI think I'm logged in as admin, so\nwe'll go ahead and choose admin,\n\n144\n00:07:32.405 --> 00:07:37.895\nmake it Advanced, and\nfind out who we got on this machine here.\n\n145\n00:07:37.895 --> 00:07:38.575\nAll right, there we go.\n\n146\n00:07:38.575 --> 00:07:39.819\nWe got admin, we'll choose OK.\n\n147\n00:07:39.819 --> 00:07:44.903\nAll right, and, what we're gonna do\nnow that I've kinda taken over that,\n\n148\n00:07:44.903 --> 00:07:47.310\nI'm gonna add myself.\n\n149\n00:07:47.310 --> 00:07:51.600\nAgain, we'll add admin one more time,\nhopefully it finds it, choose OK.\n\n150\n00:07:51.600 --> 00:07:54.435\nAnd we really only need read and\nI'm gonna go ahead and put write.\n\n151\n00:07:54.435 --> 00:07:58.372\nI don't really need the write permission,\nbut I'll go ahead and choose that,\n\n152\n00:07:58.372 --> 00:07:59.326\nwe'll choose OK.\n\n153\n00:07:59.326 --> 00:08:01.538\nAnd it's giving me,\nit's letting me know that hey,\n\n154\n00:08:01.538 --> 00:08:04.538\nyou're about to To change the permission\nsettings on a system file, and\n\n155\n00:08:04.538 --> 00:08:06.281\nthis could reduce the overall security.\n\n156\n00:08:06.281 --> 00:08:09.930\nBut I can't even view the file if I\ndon't have the read permission on it.\n\n157\n00:08:09.930 --> 00:08:13.920\nSo now once that's done,\nwe can open it up and\n\n158\n00:08:13.920 --> 00:08:17.940\nwe can see some of the information\nthat it has gathered.\n\n159\n00:08:17.940 --> 00:08:21.450\nIn fact, this file, and\nwe'll get bigger, too.\n\n160\n00:08:21.450 --> 00:08:23.940\nYou can see that we've got\nsome allow rules here or\n\n161\n00:08:23.940 --> 00:08:26.600\nsome allow packets that came across UDP.\n\n162\n00:08:26.600 --> 00:08:30.300\nAnd I can see the IP addresses\nwhere they're being bounced off of.\n\n163\n00:08:30.300 --> 00:08:31.790\nI can even see ports.\n\n164\n00:08:31.790 --> 00:08:35.760\nWe can see information,\nlike what is the destination port?\n\n165\n00:08:35.760 --> 00:08:39.210\nSo chances are Port 53, got an idea, Ms.\n\n166\n00:08:39.210 --> 00:08:42.190\nCherokee, on which port that is,\nwhat port 53 is used for?\n\n167\n00:08:42.190 --> 00:08:43.020\n&gt;&gt; For DNS?\n&gt;&gt; That's right.\n\n168\n00:08:43.020 --> 00:08:45.190\nSo there's some kind of DNS going on here.\n\n169\n00:08:45.190 --> 00:08:46.730\nSo we can see that, right?\n\n170\n00:08:46.730 --> 00:08:51.120\nAnd it's good to be able to\ninterpret that type of information.\n\n171\n00:08:51.120 --> 00:08:53.760\nSo a little bit of a setup\nthat you gotta do on this one.\n\n172\n00:08:53.760 --> 00:08:57.600\nBut again, it's one of those things that I\nthink Microsoft's done a good job because\n\n173\n00:08:57.600 --> 00:09:01.520\nof the fact that they're not\noverburdening the performance of\n\n174\n00:09:01.520 --> 00:09:06.230\nyour computer by turning on a log that\nyou might not even be using, right?\n\n175\n00:09:06.230 --> 00:09:09.950\nSo keep in mind, there are some\nmodifications you have to do in order to\n\n176\n00:09:09.950 --> 00:09:10.610\nmake that work.\n\n177\n00:09:11.660 --> 00:09:14.660\nOne of the next things that they call\nout is application whitelisting, right?\n\n178\n00:09:14.660 --> 00:09:17.190\nThis is just a process of verifying\n\n179\n00:09:17.190 --> 00:09:20.490\nwhat applications are allowed\nto run within our systems.\n\n180\n00:09:20.490 --> 00:09:21.960\nThe opposite would be blacklisting,\n\n181\n00:09:21.960 --> 00:09:26.140\nand these are the applications that\ncan't run within your systems.\n\n182\n00:09:26.140 --> 00:09:28.230\nWe can actually do\napplication whitelisting and\n\n183\n00:09:28.230 --> 00:09:29.930\nblacklisting inside of Windows as well.\n\n184\n00:09:29.930 --> 00:09:32.090\nThere's other third-party\nutilities that will do this, too.\n\n185\n00:09:32.090 --> 00:09:35.220\nBut if we go back to our\nWindows machine here,\n\n186\n00:09:35.220 --> 00:09:38.120\nthey've actually got a really cool\nutility that's been around for awhile.\n\n187\n00:09:38.120 --> 00:09:41.760\nPay attention to the version of\nthe operating system you have.\n\n188\n00:09:41.760 --> 00:09:46.620\nThe home type or home-centric editions\ndon't have this functionality.\n\n189\n00:09:46.620 --> 00:09:50.290\nTypically, it takes your enterprise\nlevel editions in order to support this\n\n190\n00:09:50.290 --> 00:09:52.850\nfunctionality cuz they really believe that\nthis is something you're gonna use in\n\n191\n00:09:52.850 --> 00:09:55.650\nan enterprise and you're not gonna\nuse in a small home environment.\n\n192\n00:09:55.650 --> 00:09:59.550\nSo pay attention to the edition of Windows\nthat you have to make sure that you're\n\n193\n00:09:59.550 --> 00:10:01.730\ngonna have this functionality\nthat I'm gonna show you.\n\n194\n00:10:01.730 --> 00:10:03.950\nAnd what we're gonna do is we're\ngonna go back in, imagine this,\n\n195\n00:10:03.950 --> 00:10:08.190\nWindows settings again, and\nsecurity settings one more time.\n\n196\n00:10:08.190 --> 00:10:10.830\nAnd what I'm looking at\nare a couple of different options.\n\n197\n00:10:10.830 --> 00:10:13.420\nWe have the earlier software\nrestriction policies.\n\n198\n00:10:13.420 --> 00:10:14.250\nThese are kinda older.\n\n199\n00:10:14.250 --> 00:10:17.840\nThese are the predecessor to\napplication control policies and\n\n200\n00:10:17.840 --> 00:10:20.870\nmore specifically something\nknown as AppLocker.\n\n201\n00:10:20.870 --> 00:10:24.610\nAppLocker is a way that we can create\nrules that either whitelist or\n\n202\n00:10:24.610 --> 00:10:26.520\nblacklist different technologies.\n\n203\n00:10:26.520 --> 00:10:31.300\nSo, for instance, I could come in here and\nwe could make executable rules, right?\n\n204\n00:10:31.300 --> 00:10:34.840\nMaybe Notepad Plus Plus is something\nthat I want people to be able to use.\n\n205\n00:10:34.840 --> 00:10:38.720\nSo I can make a rule that comes in\nhere and says, okay, that executable.\n\n206\n00:10:38.720 --> 00:10:42.980\nWe'll create a new rule here,\nand we'll choose Allow, right?\n\n207\n00:10:42.980 --> 00:10:47.220\nAt this point, this is where I can\nallow or I can deny the ability for\n\n208\n00:10:47.220 --> 00:10:48.470\nthis application to run.\n\n209\n00:10:48.470 --> 00:10:50.280\nAnd I could say allow for everyone.\n\n210\n00:10:50.280 --> 00:10:53.430\nMaybe I want everyone to\nbe able to run it, right?\n\n211\n00:10:53.430 --> 00:10:54.510\nAnd I choose Next.\n\n212\n00:10:54.510 --> 00:10:57.830\nAnd I could choose a couple\nof different types.\n\n213\n00:10:57.830 --> 00:11:00.850\nFor instance, file hash is really\ngood when you have a specific\n\n214\n00:11:00.850 --> 00:11:05.790\nversion of an application that maybe\nis tested, we know that it's secure,\n\n215\n00:11:05.790 --> 00:11:07.930\nit's sanctioned, right,\n\n216\n00:11:07.930 --> 00:11:12.940\nunder the, other than some application\nthat isn't like a later version of it.\n\n217\n00:11:12.940 --> 00:11:14.020\nMay be we haven't tasted that.\n\n218\n00:11:14.020 --> 00:11:17.530\nSo I could actually do\nlike a hash value as well.\n\n219\n00:11:17.530 --> 00:11:20.700\nOr in this case I could just do\na path right to the executable.\n\n220\n00:11:20.700 --> 00:11:24.300\n&gt;&gt; Yeah, and sometimes it's nice to be\nable to use that hash because if that\n\n221\n00:11:24.300 --> 00:11:28.150\nlocation for that path moves,\nthat hash is still gonna stay the same.\n\n222\n00:11:28.150 --> 00:11:29.990\nSo it's a little more\nconstant in that aspect.\n\n223\n00:11:29.990 --> 00:11:33.050\n&gt;&gt; And it definitely keeps\ncontrol like version and control.\n\n224\n00:11:33.050 --> 00:11:35.476\nHere's the other thing, too,\nlike the hash values, too.\n\n225\n00:11:35.476 --> 00:11:37.643\nWell, we've been talking\nabout file integrity, but\n\n226\n00:11:37.643 --> 00:11:40.190\nwhat if you have license compliance,\nright?\n\n227\n00:11:40.190 --> 00:11:42.650\nYou know that you're licensed\nto use this software.\n\n228\n00:11:42.650 --> 00:11:44.930\nWell, if you're not licensed\nto use this software, and\n\n229\n00:11:44.930 --> 00:11:50.118\nyou're using it under unauthorized or\nillegal means, that can spell some pretty\n\n230\n00:11:50.118 --> 00:11:55.170\nhefty fines, right, for your employer,\nor the company that you work for.\n\n231\n00:11:55.170 --> 00:11:58.180\nThat's why having these\ntechnologies is really handy.\n\n232\n00:11:58.180 --> 00:12:00.460\nSo, for instance, I can,\nif we look back at my machine here,\n\n233\n00:12:00.460 --> 00:12:02.647\nI can browse to the files, right?\n\n234\n00:12:02.647 --> 00:12:07.490\nAnd Notepad++,\nI wanna say that's a 32-bit program.\n\n235\n00:12:07.490 --> 00:12:08.750\nYeah, there it is.\n\n236\n00:12:08.750 --> 00:12:12.410\nAll right, well,\nat least the one that I downloaded is.\n\n237\n00:12:12.410 --> 00:12:14.698\nAll right, and there's the executable.\n\n238\n00:12:14.698 --> 00:12:16.297\nAnd I can include that, right?\n\n239\n00:12:16.297 --> 00:12:18.350\nCuz this is an executable rule.\n\n240\n00:12:18.350 --> 00:12:20.290\nAnd I can say we want to allow that.\n\n241\n00:12:20.290 --> 00:12:23.480\nAnd if we want publisher exemptions,\nwe can do exemptions.\n\n242\n00:12:23.480 --> 00:12:24.855\nI'm not going to do any exemptions.\n\n243\n00:12:24.855 --> 00:12:31.490\nAnd I might name this something\nlike maybe Notepad++allow, right?\n\n244\n00:12:31.490 --> 00:12:33.025\nJust for my own sake.\n\n245\n00:12:33.025 --> 00:12:37.680\nNow, one of the things that it's gonna\ntell you, and I like this because\n\n246\n00:12:37.680 --> 00:12:41.760\nif you didn't have this warning,\ncertain accounts,\n\n247\n00:12:41.760 --> 00:12:46.650\nlike the system account, might not\nbe able to run certain locations.\n\n248\n00:12:46.650 --> 00:12:48.770\nAnd that can cause all kinds of\nproblems within your system.\n\n249\n00:12:48.770 --> 00:12:52.150\nAnd those are the default rules that\nit tells you, hey, those default\n\n250\n00:12:52.150 --> 00:12:55.600\nrules aren't in place, it's gonna cause\nsome problems, could cause some problems.\n\n251\n00:12:55.600 --> 00:12:57.020\nYou want me to go ahead and\ncreate them now?\n\n252\n00:12:57.020 --> 00:13:02.760\nAnd we go ahead and say, yes, and\nit puts the default policies in there.\n\n253\n00:13:04.420 --> 00:13:05.350\nAnd you know what?\n\n254\n00:13:05.350 --> 00:13:10.090\nI'm using that process right now, so it's\ntelling me that it could not be saved,\n\n255\n00:13:10.090 --> 00:13:11.380\none of them couldn't be.\n\n256\n00:13:11.380 --> 00:13:14.030\nSo, well, we'll troubleshoot\nthat a little bit later.\n\n257\n00:13:14.030 --> 00:13:18.010\nBut now, you notice that I have this\nAllow rule, and I've whitelisted\n\n258\n00:13:18.010 --> 00:13:21.960\nthis application for pretty much everyone\non this computer to be able to use.\n\n259\n00:13:21.960 --> 00:13:25.556\n&gt;&gt; We still are able to see the concept\nthat AppBlocker's such a powerful utility\n\n260\n00:13:25.556 --> 00:13:29.043\nwhen it comes to really controlling\nwhat particular programs can run on that\n\n261\n00:13:29.043 --> 00:13:29.547\nmachine.\n\n262\n00:13:29.547 --> 00:13:34.121\nSo it's a little more, I always like\nthat concept better than blacklisting,\n\n263\n00:13:34.121 --> 00:13:36.896\nlike you had mentioned\nbecause blacklisting,\n\n264\n00:13:36.896 --> 00:13:41.333\nyou just open the floodgates and as you\nfind a particular application to have\n\n265\n00:13:41.333 --> 00:13:45.322\na negative result on your organization,\nyou go ahead and block it.\n\n266\n00:13:45.322 --> 00:13:49.412\nBut with your whitelisting, you only\nallow what you know to be good, right?\n\n267\n00:13:49.412 --> 00:13:50.915\n&gt;&gt; Most definitely.\n\n268\n00:13:50.915 --> 00:13:54.655\nAll right, so that's a little bit\nabout whitelisting applications.\n\n269\n00:13:54.655 --> 00:13:57.675\nNow they also talk about\nremovable media control.\n\n270\n00:13:57.675 --> 00:14:00.265\nAnd we've already mentioned\nthis in past episodes, but\n\n271\n00:14:00.265 --> 00:14:02.415\nI wanna kinda touch base on it again and\n\n272\n00:14:02.415 --> 00:14:07.470\nkinda tell you why would we wanna block,\nagain, removable media, right?\n\n273\n00:14:07.470 --> 00:14:09.220\nWell, there's a couple of reasons, right?\n\n274\n00:14:09.220 --> 00:14:11.280\nIt might be data that's coming\ninto your network, right?\n\n275\n00:14:11.280 --> 00:14:15.960\nLike somebody does a bootable virus on a\nUSB drive, a handful of them, throws them\n\n276\n00:14:15.960 --> 00:14:19.290\nthrough the parking lot, somebody comes\nin, plugs them into your machines, and\n\n277\n00:14:19.290 --> 00:14:21.720\nnow you have malware spreading\nthrough your network, right?\n\n278\n00:14:21.720 --> 00:14:24.605\nBut it also could be for\ndoing data loss prevention, right?\n\n279\n00:14:24.605 --> 00:14:28.040\nData leak prevention that we don't\nwant information going out of our\n\n280\n00:14:28.040 --> 00:14:28.920\nnetwork as well.\n\n281\n00:14:28.920 --> 00:14:31.850\nSo we can use things like BitLocker\nto got that allows you to encrypt\n\n282\n00:14:31.850 --> 00:14:33.040\nthings like removable media.\n\n283\n00:14:33.040 --> 00:14:36.040\nWe can use third party technology as well.\n\n284\n00:14:36.040 --> 00:14:39.180\nI say third party in\nthe context Windows here\n\n285\n00:14:39.180 --> 00:14:43.350\nwhere we could actually set contents\naware, context aware, as well.\n\n286\n00:14:43.350 --> 00:14:47.170\nPolicies that monitor your\napplications and monitor the data.\n\n287\n00:14:47.170 --> 00:14:50.970\nI'd just kinda like to mention some\nthings that you can do to keep in mind.\n\n288\n00:14:50.970 --> 00:14:51.730\nFor instance,\n\n289\n00:14:51.730 --> 00:14:55.840\neducate your users and maintain awareness\non why removable media can be so\n\n290\n00:14:55.840 --> 00:15:00.630\ndetrimental to your company's health,\nif you will, overall security posture.\n\n291\n00:15:00.630 --> 00:15:03.930\nWhat else, too-\n&gt;&gt; Wes, we got a comment in the chat, and\n\n292\n00:15:03.930 --> 00:15:05.110\nI was thinking about mentioning it.\n\n293\n00:15:05.110 --> 00:15:07.950\nBut I know it's not really a very\n\n294\n00:15:07.950 --> 00:15:11.360\ntypical type of response to\npreventing that removable media.\n\n295\n00:15:11.360 --> 00:15:16.054\nBut I have heard about a different,\nespecially in the military, using\n\n296\n00:15:16.054 --> 00:15:21.468\na physical epoxy to destroy those ports,\naside from just disabling those ports.\n\n297\n00:15:21.468 --> 00:15:24.590\nBut just to make sure that you\ncannot stick anything in this port.\n\n298\n00:15:24.590 --> 00:15:26.170\n&gt;&gt; I would say that's ultimate-\n&gt;&gt; [LAUGH]\n\n299\n00:15:26.170 --> 00:15:28.200\n&gt;&gt; Physical port security for sure.\n\n300\n00:15:28.200 --> 00:15:30.320\nThat is interesting.\n\n301\n00:15:30.320 --> 00:15:32.390\nWhat are some of the other things\nthat I want you to keep in mind?\n\n302\n00:15:32.390 --> 00:15:34.060\nLimit the use of removable media.\n\n303\n00:15:34.060 --> 00:15:37.340\nThat is about as limiting\nas you get right there.\n\n304\n00:15:37.340 --> 00:15:39.440\nMaybe not to that extreme, if you will.\n\n305\n00:15:39.440 --> 00:15:41.240\nImplement removable media policies and\n\n306\n00:15:41.240 --> 00:15:44.500\nencrypt all of the information\nthat's on your removable media\n\n307\n00:15:44.500 --> 00:15:49.040\nif you are gonna allow your users\nto utilize this type of technology.\n\n308\n00:15:49.040 --> 00:15:50.948\nAnd that's why I said things\nlike BitLocker To Go.\n\n309\n00:15:50.948 --> 00:15:54.696\nIt's a great technology that I can\nbring the BitLocker functionality and\n\n310\n00:15:54.696 --> 00:15:58.276\nI can encrypt the removable drives\nthat are plugged into the machine.\n\n311\n00:15:58.276 --> 00:16:00.956\nAll right, some of the other\nthings that they call out.\n\n312\n00:16:00.956 --> 00:16:03.318\nThey call out advanced malware tools, and\n\n313\n00:16:03.318 --> 00:16:06.610\nadvanced I think is relative to\nthe person that is using it.\n\n314\n00:16:06.610 --> 00:16:10.980\nBut some of the techniques that we talk\nabout, we talk about advanced threat or\n\n315\n00:16:10.980 --> 00:16:13.140\nadvanced, persistent threats, right?\n\n316\n00:16:13.140 --> 00:16:17.700\nThose ongoing ones that stay with us,\npeople constantly monitoring.\n\n317\n00:16:17.700 --> 00:16:19.520\nThings like threat intelligence.\n\n318\n00:16:19.520 --> 00:16:22.580\nWhy do we need advanced\nmalware protection, right?\n\n319\n00:16:22.580 --> 00:16:25.160\nWell, one of the big things is is\nthat attacks are getting more and\n\n320\n00:16:25.160 --> 00:16:26.680\nmore sophisticated, right?\n\n321\n00:16:26.680 --> 00:16:29.920\nAnd the way that we've commonly in\nthe past identified viruses and\n\n322\n00:16:29.920 --> 00:16:32.830\nidentified malware is through\nknown exploits, right?\n\n323\n00:16:32.830 --> 00:16:34.440\nWe have a static database.\n\n324\n00:16:34.440 --> 00:16:38.480\nI say static, it's kind of dynamic in the\nfact that you do update definitions, but\n\n325\n00:16:38.480 --> 00:16:43.260\nthey're known threats, right, and\nattacks have got very, very sophisticated.\n\n326\n00:16:43.260 --> 00:16:46.533\nWe talked about things like obs,\nyou're gonna help me out with that word?\n\n327\n00:16:46.533 --> 00:16:47.105\n&gt;&gt; Obfuscation.\n\n328\n00:16:47.105 --> 00:16:47.605\n&gt;&gt; Obfuscation.\n&gt;&gt; [LAUGH]\n\n329\n00:16:47.605 --> 00:16:48.583\n&gt;&gt; Obfuscation,\n\n330\n00:16:48.583 --> 00:16:50.620\nI can never say that word.\nI never will.\n\n331\n00:16:50.620 --> 00:16:51.586\n&gt;&gt; It's okay, I told you Wes,\n\n332\n00:16:51.586 --> 00:16:53.495\nI was having such a hard time\nwith telemetry yesterday.\n\n333\n00:16:53.495 --> 00:16:55.320\n&gt;&gt; Telemetry, yes, okay.\n\n334\n00:16:55.320 --> 00:16:56.940\nSo we'll help each other out here and\n\n335\n00:16:56.940 --> 00:17:00.020\nwe'll make our own contributions to\nthe English language here at ITProTV.\n\n336\n00:17:00.020 --> 00:17:01.654\nSome of the other things, you know,\n\n337\n00:17:01.654 --> 00:17:03.950\nlike code morphing, right?\nPolymorphic,\n\n338\n00:17:03.950 --> 00:17:08.269\nthe fact that these viruses can\nchange what they look like, pieces of\n\n339\n00:17:08.269 --> 00:17:12.810\nmalware can change what they look like.\nWe constantly need things like zero\n\n340\n00:17:12.810 --> 00:17:16.050\nday and\nnew threat identification capabilities, so\n\n341\n00:17:16.050 --> 00:17:18.700\nwe can use cloud-based samples, right.\n\n342\n00:17:18.700 --> 00:17:20.580\nWe can use heuristics.\n\n343\n00:17:20.580 --> 00:17:24.850\nHeuristics a best guess type of effort\nwhere I'm not exactly sure, but\n\n344\n00:17:24.850 --> 00:17:28.160\nI could make a best guess that that hey,\nkinda looks like a virus.\n\n345\n00:17:28.160 --> 00:17:31.480\nIt might increase the likelihood\nof false positives, but remember,\n\n346\n00:17:31.480 --> 00:17:35.560\na few false positives might slow you down\na little bit, but it's better than a false\n\n347\n00:17:35.560 --> 00:17:38.630\nnegative, and some kind of malware\nactually making its way through.\n\n348\n00:17:39.790 --> 00:17:41.780\nThey also talk about patch\nmanagement tools, right?\n\n349\n00:17:41.780 --> 00:17:43.250\nWhen we talk about patch management,\n\n350\n00:17:43.250 --> 00:17:46.150\nwe've got many different\ngreat systems out there.\n\n351\n00:17:46.150 --> 00:17:51.330\nSome that are, maybe you're in\na Windows-based domain, right?\n\n352\n00:17:51.330 --> 00:17:52.700\nIf you're in a Windows-based domain,\n\n353\n00:17:52.700 --> 00:17:54.860\nyou're using something\nlike Active Directory.\n\n354\n00:17:54.860 --> 00:17:59.000\nWe've got things like, an oldie but\ngoodie like WSUS servers.\n\n355\n00:17:59.000 --> 00:18:04.300\nWindows Server Update Service where we\ncan point our internal devices to a patch\n\n356\n00:18:04.300 --> 00:18:08.750\nmanagement solution like that where\nyour administrators can do the research.\n\n357\n00:18:08.750 --> 00:18:11.720\nThey can test, and prove or\ndeny, the various updates for\n\n358\n00:18:11.720 --> 00:18:14.530\nthe systems that they support\nwithin their networks.\n\n359\n00:18:14.530 --> 00:18:17.210\nWe've got Windows Update\non all your clients.\n\n360\n00:18:17.210 --> 00:18:20.330\nIt might work in a home environment,\ndo your updates regularly.\n\n361\n00:18:20.330 --> 00:18:21.020\nBut keep in mind,\n\n362\n00:18:21.020 --> 00:18:23.550\nin a corporate environment,\nyou might go through a testing process,\n\n363\n00:18:23.550 --> 00:18:27.100\nand have some kind of patch\nmanagement solution like WSUS or\n\n364\n00:18:27.100 --> 00:18:30.810\neven System Center Configuration Manager,\nvery complex setups.\n\n365\n00:18:31.920 --> 00:18:32.600\nYou-\n&gt;&gt; Linux, a little\n\n366\n00:18:32.600 --> 00:18:33.470\ndifferent, right, and Unix?\n\n367\n00:18:33.470 --> 00:18:37.030\n&gt;&gt; Linux is a little bit different, that's\nright, you have things for instance YUM,\n\n368\n00:18:37.030 --> 00:18:41.790\nyou have Appget and\nyou have the Red Hat Package Manager,\n\n369\n00:18:41.790 --> 00:18:46.680\nRPM, too but again things like YUM and\nAppget can do help you do your updates.\n\n370\n00:18:46.680 --> 00:18:49.360\n&gt;&gt; And with those repositories we might\nwanna be a little careful that they're not\n\n371\n00:18:49.360 --> 00:18:52.990\nin some sort of beta mode or,\nusually they have their disclaimers, but\n\n372\n00:18:52.990 --> 00:18:54.430\nthat's always something to be aware of.\n\n373\n00:18:54.430 --> 00:18:57.951\n&gt;&gt; Definitely, now we got a little bit\nmore alphabet soup to throw at you,\n\n374\n00:18:57.951 --> 00:18:59.487\nright here at the end, right?\n\n375\n00:18:59.487 --> 00:19:02.890\nWe have unified threat management,\nyou might say UTM.\n\n376\n00:19:02.890 --> 00:19:06.859\nUnified threat management essentially is,\nif you have all these different security\n\n377\n00:19:06.859 --> 00:19:10.223\nproducts, we're constantly talking\nabout a layered defense system,\n\n378\n00:19:10.223 --> 00:19:11.998\na layered defense and depth, right.\n\n379\n00:19:11.998 --> 00:19:15.190\nSo you've got a lot of moving components.\n\n380\n00:19:15.190 --> 00:19:17.970\nWouldn't it be nice to have\nall of those moving components\n\n381\n00:19:17.970 --> 00:19:20.690\ncommunicate with a single\ninterface that you can control\n\n382\n00:19:20.690 --> 00:19:23.190\nevery one of them from that\nsingle interface, right?\n\n383\n00:19:23.190 --> 00:19:27.240\nThat is going to be your unified\nthreat management, tying\n\n384\n00:19:27.240 --> 00:19:31.650\nthose security technologies into a single\ninterface so that you can manage them.\n\n385\n00:19:31.650 --> 00:19:33.830\nYou have things like third\nparty utilities out there.\n\n386\n00:19:33.830 --> 00:19:35.750\nIn fact, I've got one here on my screen,\nlike for\n\n387\n00:19:35.750 --> 00:19:40.110\ninstance WatchGuard is one of them that\ndoes UTM, unified threat management and\n\n388\n00:19:40.110 --> 00:19:43.480\nagain, it's one of those ones where\nit's one appliance, total security.\n\n389\n00:19:43.480 --> 00:19:45.610\nRight now, I sound like I'm\nan advertisement for them.\n\n390\n00:19:45.610 --> 00:19:49.900\nYou have advanced things,\nlike Cisco's FirePOWER,\n\n391\n00:19:49.900 --> 00:19:56.310\nwhich brings all of those security\ntechnologies into a centralized location.\n\n392\n00:19:56.310 --> 00:20:01.440\nSo again, kind of just understand what\nthe unified threat management is.\n\n393\n00:20:01.440 --> 00:20:04.300\nWe also have things, like for\ninstance, web application firewalls.\n\n394\n00:20:04.300 --> 00:20:07.380\nKeep in mind what a web application\nfirewall is doing for us.\n\n395\n00:20:07.380 --> 00:20:11.956\nIt is monitoring for things like\nyour cross-side scripting attacks,\n\n396\n00:20:11.956 --> 00:20:15.856\nSQL injection attacks,\ndirectory traversal, like that.\n\n397\n00:20:15.856 --> 00:20:20.315\nThat's more of your next generation\nfirewalls that know not just layer three\n\n398\n00:20:20.315 --> 00:20:25.065\nand layer four, but they can also go above\nthat, go into the presentation layer.\n\n399\n00:20:25.065 --> 00:20:29.434\nThey can go into the application layer and\nreally understand being aware of\n\n400\n00:20:29.434 --> 00:20:32.430\nthe protocols that those\napplications are using.\n\n401\n00:20:34.020 --> 00:20:37.580\nThey also call out things, for\ninstance, Data Execution Protection.\n\n402\n00:20:37.580 --> 00:20:39.500\nMaybe you've heard of this before,\nmaybe not.\n\n403\n00:20:40.540 --> 00:20:44.290\nData Execution Protection, in fact,\nI can jump into my Windows machine and\n\n404\n00:20:44.290 --> 00:20:46.330\nshow you this, they implement this.\n\n405\n00:20:46.330 --> 00:20:50.200\nThey implement this through something\ncalled DEP, Data Execution Protection and\n\n406\n00:20:50.200 --> 00:20:52.540\nyou can get into your\nadvanced system properties.\n\n407\n00:20:52.540 --> 00:20:55.650\nAll right, so if I right-click on\nmy Windows charm, our Windows icon,\n\n408\n00:20:55.650 --> 00:21:00.530\nchoose System, notice that we have some\nAdvanced system settings over here.\n\n409\n00:21:00.530 --> 00:21:03.170\nWe can choose that, all right.\n\n410\n00:21:03.170 --> 00:21:05.060\nAnd then you'll see things like,\nfor instance,\n\n411\n00:21:05.060 --> 00:21:08.700\nPerformance, processor scheduling, right.\n\n412\n00:21:08.700 --> 00:21:10.120\nAnd if I choose Settings here,\n\n413\n00:21:10.120 --> 00:21:14.880\nyou'll notice that there's Data Execution\nProtection right here and it is turned on,\n\n414\n00:21:14.880 --> 00:21:18.850\nand again notice it says helping\nprotect against damage from viruses and\n\n415\n00:21:18.850 --> 00:21:19.710\nother security threats.\n\n416\n00:21:19.710 --> 00:21:21.780\nSo what is Data Execution Protection?\n\n417\n00:21:21.780 --> 00:21:25.567\nBut let's talk about things like\nthe no-execute, NX bit, right?\n\n418\n00:21:25.567 --> 00:21:29.720\nA reserved portion of memory that we\nquarantine it off and we say, yeah,\n\n419\n00:21:29.720 --> 00:21:34.624\nyou can store your information program,\nyou could store your information here, but\n\n420\n00:21:34.624 --> 00:21:36.920\nthat code cannot be executed, right.\n\n421\n00:21:36.920 --> 00:21:38.720\nSo it's a quarantine portion of memory,\n\n422\n00:21:38.720 --> 00:21:41.195\nthat where the application can\nstore their information, but\n\n423\n00:21:41.195 --> 00:21:46.495\nthey're not gonna execute any kind of code\nthat resides in that portion of memory.\n\n424\n00:21:46.495 --> 00:21:49.584\nYou'll see things like Internet Explorer\ndoes this with Protected Mode, and\n\n425\n00:21:49.584 --> 00:21:52.976\nwhen Protected Mode in Internet Explorer's\nturned on, it means that quarantines.\n\n426\n00:21:52.976 --> 00:21:57.497\nAnd I said quarantines,\njust blocks off a piece of memory that we\n\n427\n00:21:57.497 --> 00:22:02.357\ncannot have code execution,\nespecially when you're talking about\n\n428\n00:22:02.357 --> 00:22:06.990\nviruses that are trying to do some\nkind of remote code execution.\n\n429\n00:22:06.990 --> 00:22:09.062\nAll right,\nwell I think that has got it all.\n\n430\n00:22:09.062 --> 00:22:10.410\nLet me just kinda look over here.\n\n431\n00:22:10.410 --> 00:22:10.963\nI think we've got it all.\n\n432\n00:22:10.963 --> 00:22:15.668\nSo just keep in mind patch management\ntools, things like data loss prevention,\n\n433\n00:22:15.668 --> 00:22:20.578\nunified threat management, DEP as well,\nand keep in mind what your web application\n\n434\n00:22:20.578 --> 00:22:23.750\nfirewalls are doing to\nsecure your networks.\n\n435\n00:22:23.750 --> 00:22:25.240\n&gt;&gt; Thank you for\njoining us today, Wes, and\n\n436\n00:22:25.240 --> 00:22:27.450\nthank you, ladies and\ngentlemen for joining as well.\n\n437\n00:22:27.450 --> 00:22:29.500\nFor this show we're gonna go ahead and\nsign off.\n\n438\n00:22:29.500 --> 00:22:31.350\nRemember, I'm your host Cherokee Boose.\n\n439\n00:22:31.350 --> 00:22:32.130\n&gt;&gt; And I'm Wes Bryan.\n\n440\n00:22:32.130 --> 00:22:33.930\n&gt;&gt; See you next time here at ITProTV.\n\n441\n00:22:33.930 --> 00:22:40.977\n[MUSIC]\n\n442\n00:22:40.977 --> 00:22:44.164\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213515371"
        },
        {
          "description": "In this episode, Cherokee and Wes discuss the importance of mobile security. Because mobile devices have become such an integral part of our lives it is imperative to address the potential vulnerabilities and weaknesses. Tune in now to learn how to increase security while using these devices.",
          "length": "1410",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-5-deploy_mobile_security-041417-PGM.00_23_16_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-5-deploy_mobile_security-041417-PGM.00_23_16_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-5-deploy_mobile_security-041417-PGM.00_23_16_02.Still001-sm.jpg",
          "title": "Deploy Mobile Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.023 --> 00:00:02.860\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.860 --> 00:00:09.191\n[CROSSTALK]\n&gt;&gt; You're\n\n3\n00:00:09.191 --> 00:00:13.050\nwatching ITProTV\n&gt;&gt; Welcome ladies and\n\n4\n00:00:13.050 --> 00:00:15.720\ngentleman to your\nCompTIA Security+ series.\n\n5\n00:00:15.720 --> 00:00:17.680\nI'm your show host Cherokee Boose and\n\n6\n00:00:17.680 --> 00:00:20.990\nthis episode we'll be looking\nat mobile device security.\n\n7\n00:00:20.990 --> 00:00:24.000\nAnd with us today back in the studios\nwe have Mr Wes Bryan, thank you for\n\n8\n00:00:24.000 --> 00:00:24.870\ncoming today Wes.\n\n9\n00:00:24.870 --> 00:00:25.669\n&gt;&gt; Hey thanks for having me back.\n\n10\n00:00:25.669 --> 00:00:28.981\nYeah, now were gonna move\ninto mobile security and\n\n11\n00:00:28.981 --> 00:00:32.447\nthat is definitely a big topic\ntoday as we have more and\n\n12\n00:00:32.447 --> 00:00:35.932\nmore mobile devices hitting\nour networks everyday.\n\n13\n00:00:35.932 --> 00:00:37.575\nIn fact it was a few years back,\n\n14\n00:00:37.575 --> 00:00:41.179\nI believe it was Cisco that made\na prediction that said, by the end,\n\n15\n00:00:41.179 --> 00:00:45.479\nI don't know if this has happened yet I\nthink it was 2017 they said by the end of\n\n16\n00:00:45.479 --> 00:00:50.185\n2017 there would be over 50 billion TCP IP\nenabled devices on the Internet today.\n\n17\n00:00:50.185 --> 00:00:53.014\nI'm sure we're well past that\ncuz I know that for myself,\n\n18\n00:00:53.014 --> 00:00:55.630\nI probably got seven or\neight devices alone, right.\n\n19\n00:00:55.630 --> 00:00:58.990\nSo you can see that there are a lot\nof devices on our networks and\n\n20\n00:00:58.990 --> 00:01:03.110\nmobility has definitely become something\nthat is a, not just a trend but\n\n21\n00:01:03.110 --> 00:01:04.980\nalmost a necessity today, right.\n\n22\n00:01:04.980 --> 00:01:08.250\nYou're almost finding it today where\npeople don't have landlines anymore,\n\n23\n00:01:08.250 --> 00:01:11.230\nand they have mobile devices over\nhaving the traditional landline.\n\n24\n00:01:11.230 --> 00:01:14.060\nSo it's definitely become\nsomething that's very popular, and\n\n25\n00:01:14.060 --> 00:01:17.440\nit's definitely something we have to\nconsider when it comes to security.\n\n26\n00:01:17.440 --> 00:01:22.280\nBecause of the fact that, well, a lot of\ntimes, the mobile devices are property\n\n27\n00:01:22.280 --> 00:01:27.340\nof the employee, and\nthat's something that we call BYOD today.\n\n28\n00:01:27.340 --> 00:01:29.260\nThere are a couple of\ndifferent models today,\n\n29\n00:01:29.260 --> 00:01:31.980\nBring Your Own Device means\nquite literally that.\n\n30\n00:01:31.980 --> 00:01:35.269\nThis is my device,\nI am the purchaser of this device,\n\n31\n00:01:35.269 --> 00:01:38.777\nI want to use it to work inside\nof a corporate network, and\n\n32\n00:01:38.777 --> 00:01:42.088\nthat presents a challenge for\nyour administrators.\n\n33\n00:01:42.088 --> 00:01:43.140\nWell what's the challenge?\n\n34\n00:01:43.140 --> 00:01:47.346\nWell the challenge is securing a device\nthat the company doesn't own, right,\n\n35\n00:01:47.346 --> 00:01:51.517\nhow can we secure a device when the device\nis personally owned by the employee?\n\n36\n00:01:51.517 --> 00:01:53.780\nAnd that's why they've got a couple\nof other models here, too.\n\n37\n00:01:53.780 --> 00:01:55.450\nThey have for instance,\n\n38\n00:01:55.450 --> 00:02:01.370\ncarry your own device if you will where\nyou're given an option of several devices.\n\n39\n00:02:01.370 --> 00:02:03.970\nThe company gives you an option, right,\nand they say you can pick this one and\n\n40\n00:02:03.970 --> 00:02:06.060\nyou can use it for personal as well.\n\n41\n00:02:06.060 --> 00:02:07.420\nThey also have what's known as COPE and\n\n42\n00:02:07.420 --> 00:02:10.290\nthat's corporate owned\nby personally enabled.\n\n43\n00:02:10.290 --> 00:02:13.105\nAnd that's where you have one specific\ndevice that they give to you.\n\n44\n00:02:13.105 --> 00:02:16.440\nAnd they allow you to do personal\nstuff with it as well, but\n\n45\n00:02:16.440 --> 00:02:19.654\neither model that you look\nat does present a challenge.\n\n46\n00:02:19.654 --> 00:02:24.491\nEven if it's a corporate owned device,\nwhich quite literally means no\n\n47\n00:02:24.491 --> 00:02:29.265\npersonal business at all, all right,\njust corporate business too.\n\n48\n00:02:29.265 --> 00:02:33.121\nRegardless of who owns the device,\nthe security implementations,\n\n49\n00:02:33.121 --> 00:02:36.440\nthe security concerns,\nare really gonna be the same.\n\n50\n00:02:36.440 --> 00:02:41.032\nIt's just, the thing is, I think\nliability changes a little bit, right.\n\n51\n00:02:41.032 --> 00:02:43.565\nIf we have a corporately owned device,\n\n52\n00:02:43.565 --> 00:02:48.340\nit's going to be managed in a way that\nonly corporate documents are on it.\n\n53\n00:02:48.340 --> 00:02:53.480\nIf we say, also personally enabled,\nthen we need to be able to separate\n\n54\n00:02:53.480 --> 00:02:55.810\npersonal information from\ncorporately owned data, right.\n\n55\n00:02:55.810 --> 00:02:59.720\nWe talked about things like\ncontainerization, being able to isolate\n\n56\n00:02:59.720 --> 00:03:05.100\na portion of the storage medium on that\ndevice as only having corporate data.\n\n57\n00:03:05.100 --> 00:03:09.680\nBut at the same time, being able to make\nsure that the, if it is personally enabled\n\n58\n00:03:09.680 --> 00:03:13.190\nthat the personal data doesn't\nget compromised either.\n\n59\n00:03:13.190 --> 00:03:16.810\nThat there's a clear distinction\nbetween the photos of my family and\n\n60\n00:03:16.810 --> 00:03:19.830\nthe business documents that I've taken\noff of the network that come and\n\n61\n00:03:19.830 --> 00:03:22.820\nare owned from, if you will,\nthe corporation itself.\n\n62\n00:03:22.820 --> 00:03:26.850\n&gt;&gt; You know Wes, a lot of software\ncompanies I think are really\n\n63\n00:03:26.850 --> 00:03:30.910\nnoticing that need to really\nsegregate with that containerization.\n\n64\n00:03:30.910 --> 00:03:34.130\nAnd they're working to go ahead and\ndo that.\n\n65\n00:03:34.130 --> 00:03:37.260\nAnd I know I don't wanna sound like\na Debbie Downer all the time and say,\n\n66\n00:03:37.260 --> 00:03:38.490\ndon't use this or don't use that.\n\n67\n00:03:38.490 --> 00:03:40.600\nBut if you really don't\nhave that segregation and\n\n68\n00:03:40.600 --> 00:03:45.240\nthere's not a distinct black and\nwhite and there's kind of a grey area.\n\n69\n00:03:45.240 --> 00:03:48.672\nIn my opinion I just say\ndon't use that device for\n\n70\n00:03:48.672 --> 00:03:53.529\nboth business and pleasure because\nin a legal situation it's really\n\n71\n00:03:53.529 --> 00:03:57.648\ngonna play out that way well\nyou know who owns this device.\n\n72\n00:03:57.648 --> 00:04:00.423\n&gt;&gt; Sure and one of the big concepts that\nwe've been talking about is data loss\n\n73\n00:04:00.423 --> 00:04:02.050\nprevention and date leakage prevention.\n\n74\n00:04:02.050 --> 00:04:06.221\nAnd that becomes very, very difficult, the\nother thing that is difficult is mobile\n\n75\n00:04:06.221 --> 00:04:10.571\ndevices aren't traditionally managed,\nright, they're not managed, if you will,\n\n76\n00:04:10.571 --> 00:04:14.767\naccording to traditional methods that we\ndo things like servers and work stations.\n\n77\n00:04:14.767 --> 00:04:17.177\nLet me give you an example if you\nhave an active directory domain and\n\n78\n00:04:17.177 --> 00:04:18.479\nyou're running Windows, right.\n\n79\n00:04:18.479 --> 00:04:21.798\nIf it's a Windows Workstation, or\na Windows Server, doesn't matter,\n\n80\n00:04:21.798 --> 00:04:25.065\nwe can apply group policies where\nthe Systems Administrator can control\n\n81\n00:04:25.065 --> 00:04:28.562\nthe configurations and the settings and\nthe ability to do different things.\n\n82\n00:04:28.562 --> 00:04:31.450\nAnd also give authorization,\na certain level of authorization,\n\n83\n00:04:31.450 --> 00:04:34.030\nto different resources within the network.\n\n84\n00:04:34.030 --> 00:04:37.760\nWell, if you add one of these\ndevices here into the mix,\n\n85\n00:04:37.760 --> 00:04:40.100\nhow is it that we secure those devices?\n\n86\n00:04:40.100 --> 00:04:44.880\nHow is it that we manage those devices\nwith things like ACLs and permissions,\n\n87\n00:04:44.880 --> 00:04:47.080\nif you will,\nif they can't join a corporate domain?\n\n88\n00:04:47.080 --> 00:04:50.620\nAnd that's where we do have technologies\nout there that allow us to do that.\n\n89\n00:04:50.620 --> 00:04:54.320\nThings like, for instance, work folders is\nsomething that was in Windows where you\n\n90\n00:04:54.320 --> 00:04:58.430\ncould give a certain level of access\nto the resources within the domain and\n\n91\n00:04:58.430 --> 00:05:00.660\nmaintain some kind of configurability or\n\n92\n00:05:00.660 --> 00:05:04.100\nat least some kind of security\nconfigurations over the device, right.\n\n93\n00:05:04.100 --> 00:05:07.960\nFor instance, making sure that all\nof the information is encrypted.\n\n94\n00:05:07.960 --> 00:05:11.690\nDevice encryption, right, for\nthe device and that's very important.\n\n95\n00:05:11.690 --> 00:05:15.330\nThings like content management and\napplication management,\n\n96\n00:05:15.330 --> 00:05:19.321\nwhich applications can be used and\ncannot be used on the network too.\n\n97\n00:05:19.321 --> 00:05:23.157\nSo we have to keep that in mind as well,\nthat those reconsideration, like for\n\n98\n00:05:23.157 --> 00:05:27.119\ninstance, application management and\ncontent management on those devices.\n\n99\n00:05:27.119 --> 00:05:27.969\n&gt;&gt; Good point, Wes,\n\n100\n00:05:27.969 --> 00:05:31.330\na lot of these applications do have\nsome pretty serious vulnerabilities.\n\n101\n00:05:31.330 --> 00:05:35.230\nWhen you look at secured\ndevices like the black phone,\n\n102\n00:05:35.230 --> 00:05:37.430\nthey're not very compatible with\na lot of these applications.\n\n103\n00:05:37.430 --> 00:05:41.120\nYou can't even install them on this phone,\nwell, you got that trade off there.\n\n104\n00:05:41.120 --> 00:05:42.290\nWhat's more important to you?\n\n105\n00:05:42.290 --> 00:05:46.000\n&gt;&gt; Right, and again, any time we gotta\ntalk about convenience we talk about\n\n106\n00:05:46.000 --> 00:05:50.470\nthe potential, if you will to,\nor hinder security.\n\n107\n00:05:50.470 --> 00:05:53.540\nSo what I want to talk a little bit about\nsome of the connection methods we use.\n\n108\n00:05:53.540 --> 00:05:55.420\nYou're probably familiar\nwith most of these but\n\n109\n00:05:55.420 --> 00:05:58.820\nmaybe not the consideration of\nwhere does the protection lie?\n\n110\n00:05:58.820 --> 00:05:59.900\nWhat do we have to do?\n\n111\n00:05:59.900 --> 00:06:02.950\nSo for instance they talk about\nconnection methods of cellular.\n\n112\n00:06:02.950 --> 00:06:07.360\nWell if I'm using cellular, is the\ncellular company gonna encrypt my data and\n\n113\n00:06:07.360 --> 00:06:11.030\nmake sure that we have end\nto end transport encryption?\n\n114\n00:06:11.030 --> 00:06:16.250\nProbably not, right, so, if we have\ncommunications going from a satellite\n\n115\n00:06:16.250 --> 00:06:20.820\nright off of our phone down to another\nlocation within that carrier's network,\n\n116\n00:06:20.820 --> 00:06:23.858\nwhat do we have to do to ensure\nthat we secure that communication?\n\n117\n00:06:23.858 --> 00:06:25.490\nWell, that's where encryption,\n\n118\n00:06:25.490 --> 00:06:29.570\nwe have to encrypt the information before\nit ever leaves the phone to ensure\n\n119\n00:06:29.570 --> 00:06:33.690\nthat as it traverses the public network,\nthat it does stay encrypted.\n\n120\n00:06:33.690 --> 00:06:38.010\nWe also have things like, for instance,\nWi-Fi, Wi-Fi is susceptible to all\n\n121\n00:06:38.010 --> 00:06:41.480\nthe other attacks that we've been talking\nabout throughout this series, right.\n\n122\n00:06:41.480 --> 00:06:44.970\nEavesdropping is a big one of them,\njust because of the fact that any type of\n\n123\n00:06:44.970 --> 00:06:48.720\nwireless communication, whether\nit's Wi-Fi, whether it's Bluetooth.\n\n124\n00:06:48.720 --> 00:06:52.540\nBluetooth is another one,\ndata is emanating off that device, and\n\n125\n00:06:52.540 --> 00:06:55.740\npeople only have to be in the proximity\nif they are crafty enough and\n\n126\n00:06:55.740 --> 00:06:58.140\nsmart enough to gain access\nto that information.\n\n127\n00:06:58.140 --> 00:07:01.138\nFor instance, like Bluetooth-based attacks\nthat we've talked about in the past.\n\n128\n00:07:01.138 --> 00:07:04.610\nThings like blue-snarfing, right?,\nthe fact that I wanna get your data\n\n129\n00:07:04.610 --> 00:07:08.470\noff of that, through the Bluetooth\nconnection off of your device.\n\n130\n00:07:08.470 --> 00:07:11.880\nThings like Bluejacking where\nI actually piggy back off your\n\n131\n00:07:11.880 --> 00:07:15.330\nBluetooth communication instead\nof my own communications.\n\n132\n00:07:15.330 --> 00:07:17.154\nAll right we talked\nabout in other episodes,\n\n133\n00:07:17.154 --> 00:07:19.250\nwe talk about ITSEC\nproviding non-repudiation.\n\n134\n00:07:19.250 --> 00:07:23.030\nWell if you're under a Bluetooth,\nBluejacking attack,\n\n135\n00:07:23.030 --> 00:07:26.430\nhow can I sit there and say no Cherokee,\nthat information is not mine.\n\n136\n00:07:26.430 --> 00:07:30.720\nCherokee say well I can see it\nplainly came from your device, right.\n\n137\n00:07:30.720 --> 00:07:34.580\nAgain I can't refute the fact\nif it is coming from my device.\n\n138\n00:07:34.580 --> 00:07:37.889\nOther types of things Satcom, right,\nagain a satellite communications, right,\n\n139\n00:07:37.889 --> 00:07:40.930\nyou can see cellular communications\nagain too, gumming off of satellites.\n\n140\n00:07:40.930 --> 00:07:44.324\nWe have to make sure that that data is\nencrypted on the device before it ever\n\n141\n00:07:44.324 --> 00:07:45.980\nleaves the device.\n\n142\n00:07:45.980 --> 00:07:49.832\nWe have other things to like a technology\nthat's really close to Bluetooth that's\n\n143\n00:07:49.832 --> 00:07:50.997\nproprietary I believe.\n\n144\n00:07:50.997 --> 00:07:55.900\nI think it's own by a Canadian developer\ncalled ANT, ANT is a very low,\n\n145\n00:07:55.900 --> 00:07:59.191\nit's really comparable to Bluetooth 4.0.\n\n146\n00:07:59.191 --> 00:08:02.345\nWhich Bluetooth 4.0 is\njust low power Bluetooth.\n\n147\n00:08:02.345 --> 00:08:05.680\nAnd this is a very low-powered\nwireless communication,\n\n148\n00:08:05.680 --> 00:08:10.114\nthat you use in things like, what\nare the workout watch, FitBits and stuff?\n\n149\n00:08:10.114 --> 00:08:11.090\n&gt;&gt; Activity trackers?\n\n150\n00:08:11.090 --> 00:08:12.530\n&gt;&gt; Activity trackers, absolutely.\n\n151\n00:08:12.530 --> 00:08:15.890\nThings like little sensors, monitoring\nthings like your heart rate and stuff, and\n\n152\n00:08:15.890 --> 00:08:17.120\nthat's what this technology is.\n\n153\n00:08:17.120 --> 00:08:21.450\nAnd again, if you think about it, that can\nalso be some type of avenue for attack,\n\n154\n00:08:21.450 --> 00:08:22.600\nso we have to secure that.\n\n155\n00:08:25.350 --> 00:08:30.620\nInfrared is used still a lot, I don't\nreally have an infrared phone on me,\n\n156\n00:08:30.620 --> 00:08:33.020\nbut there are technology out\nthere that use infrared.\n\n157\n00:08:33.020 --> 00:08:37.746\nAnd again, infrared can get you into a\nsituation where it can be simply a denial\n\n158\n00:08:37.746 --> 00:08:38.975\nof service attack.\n\n159\n00:08:38.975 --> 00:08:42.195\nIt's a very finicky, sensitive,\nline-of-sight communication that can't\n\n160\n00:08:42.195 --> 00:08:44.860\nhave any obstructions between\nthe transmitter and the receiver.\n\n161\n00:08:46.810 --> 00:08:49.430\nIt's so sensitive that just a little\nbit of cigarette smoke going between\n\n162\n00:08:49.430 --> 00:08:54.260\nthe receiver and the transmitter could\npotentially cause communication issues.\n\n163\n00:08:54.260 --> 00:08:58.360\nSo again, we have to worry\nabout things like infrared.\n\n164\n00:08:58.360 --> 00:09:03.070\nWe also have to worry about USB,\nright, USB presents a problem, right?\n\n165\n00:09:03.070 --> 00:09:06.700\nThings like the USB,\nOTG cables, right, On The Go,\n\n166\n00:09:06.700 --> 00:09:11.540\nthat allows me to transfer information\nover a USB cable between phones,\n\n167\n00:09:12.760 --> 00:09:15.530\nthat could be an attack, right?\n\n168\n00:09:15.530 --> 00:09:18.440\nIt could be, again, because mobile\ndevices are what you think about it,\n\n169\n00:09:18.440 --> 00:09:21.650\nthat mobile device,\nsomebody could steal it, right?\n\n170\n00:09:21.650 --> 00:09:25.620\nAnd if somebody could steal it and\nput one of those USB OTG cables in there,\n\n171\n00:09:25.620 --> 00:09:28.200\nplug it into your phone that's stolen and\nplug it into their phone,\n\n172\n00:09:28.200 --> 00:09:31.430\nthey could transfer sensitive information\nright over the phone on the fly, right?\n\n173\n00:09:31.430 --> 00:09:33.740\nSo we have to worry\nabout things like that.\n\n174\n00:09:33.740 --> 00:09:36.620\n&gt;&gt; Wes, with all those different examples\nyou just gave us for the different types\n\n175\n00:09:36.620 --> 00:09:41.630\nof connection methods, with infrared, you\nhad mentioned a type of denial of service.\n\n176\n00:09:41.630 --> 00:09:45.969\nAnd that's really something that we need\nto think about as well because all of\n\n177\n00:09:45.969 --> 00:09:50.241\nthose communication methods are in some\nway vulnerable to a type of denial of\n\n178\n00:09:50.241 --> 00:09:54.673\nservice via different various jamming\ntechniques and things of that nature.\n\n179\n00:09:54.673 --> 00:09:57.437\nAnd if you think back to our CIA triad,\navailability,\n\n180\n00:09:57.437 --> 00:09:59.490\ndefinitely is something to consider.\n\n181\n00:09:59.490 --> 00:10:01.330\n&gt;&gt; Certainly, yeah,\nyou don't have that member,\n\n182\n00:10:01.330 --> 00:10:03.405\nauthorized people don't have\naccess to their information,\n\n183\n00:10:03.405 --> 00:10:06.360\nthen we're not doing our jobs\nas security technicians.\n\n184\n00:10:06.360 --> 00:10:10.656\nSome of the other concepts that we gotta\nbe aware of too, remote wipe, right,\n\n185\n00:10:10.656 --> 00:10:13.992\nwe said containerization,\ndata classification, right.\n\n186\n00:10:13.992 --> 00:10:16.782\nI know Microsoft has this in Windows.\n\n187\n00:10:16.782 --> 00:10:18.459\n&gt;&gt; Microsoft, yeah,\nthey've been working on that.\n\n188\n00:10:18.459 --> 00:10:23.190\n&gt;&gt; They have the remote wipe, I think they\ncall it business data removal technology,\n\n189\n00:10:23.190 --> 00:10:25.430\nand it starts with classification.\n\n190\n00:10:25.430 --> 00:10:28.200\nEven if you call it a remote wipe,\nit starts with classification,\n\n191\n00:10:28.200 --> 00:10:31.830\nbeing able to classify what is corporate\ndata and what is personal data.\n\n192\n00:10:31.830 --> 00:10:34.695\nAnd being able to say that okay,\nif I'm gonna perform a remote wipe,\n\n193\n00:10:34.695 --> 00:10:39.280\nI'm not remotely wiping all\nthe pictures of Cherokee's kids, right?\n\n194\n00:10:39.280 --> 00:10:41.006\nThat's personal information, so\n\n195\n00:10:41.006 --> 00:10:43.945\nyou need a technology that can\ndistinguish between the two.\n\n196\n00:10:43.945 --> 00:10:47.961\nAnd then you add things like,\nfor instance, containerization,\n\n197\n00:10:47.961 --> 00:10:52.121\nstorage isolation there,\nto where the company data is protected and\n\n198\n00:10:52.121 --> 00:10:56.750\nit's in its isolated environment so\nthat it can't be manipulated.\n\n199\n00:10:56.750 --> 00:11:02.530\nOther things that we can do too,\nwe talked about storage segmentation,\n\n200\n00:11:02.530 --> 00:11:07.010\nfull device encryption,\ncontext aware authentication.\n\n201\n00:11:07.010 --> 00:11:11.874\nThis is actually a really, really cool\ntechnology, the geek in me coming out.\n\n202\n00:11:11.874 --> 00:11:14.452\nTime aware, right, I know what time it is,\n\n203\n00:11:14.452 --> 00:11:18.920\nwe can do authentication based\non being time aware, what else?\n\n204\n00:11:18.920 --> 00:11:21.950\nEndpoint type, right,\nlocation, geolocation.\n\n205\n00:11:21.950 --> 00:11:22.660\n&gt;&gt; That's really cool.\n\n206\n00:11:22.660 --> 00:11:26.133\n&gt;&gt; That's really cool is the fact that\nwe can authenticate you by where you're\n\n207\n00:11:26.133 --> 00:11:29.877\ncurrently located, all right, the GPS\nsystem through geolocation says, hey,\n\n208\n00:11:29.877 --> 00:11:31.249\nyou are within the building.\n\n209\n00:11:31.249 --> 00:11:36.112\nOkay, login, but you're not in the\nbuilding anymore, your access is denied,\n\n210\n00:11:36.112 --> 00:11:40.860\nright, so context aware authentication\nis something that we can do as well.\n\n211\n00:11:40.860 --> 00:11:44.030\nThings like implementing geo fencing,\nright, geo fencing,\n\n212\n00:11:44.030 --> 00:11:46.376\nwe talked about geolocation,\nright, geolocation,\n\n213\n00:11:46.376 --> 00:11:50.340\nyou're probably seeing this in\ncombination with things like GPS tagging.\n\n214\n00:11:50.340 --> 00:11:54.080\nI think of Facebook, if you've ever had a\nfriend that's posted on Facebook and said,\n\n215\n00:11:54.080 --> 00:11:58.328\nhey, this was posted from West Side Park,\nright, that's GPS tagging, right.\n\n216\n00:11:58.328 --> 00:11:59.670\nIt's also geolocation too,\n\n217\n00:11:59.670 --> 00:12:02.953\nbecause it takes the GPS to find\nthe location that you're currently in.\n\n218\n00:12:02.953 --> 00:12:06.607\nBut geofencing,\nimagine being able to use GPS and\n\n219\n00:12:06.607 --> 00:12:10.437\nRFID to create some kind\nof geographical boundary.\n\n220\n00:12:10.437 --> 00:12:12.152\nAnd whether you enter that boundary or\n\n221\n00:12:12.152 --> 00:12:15.910\nyou exit that boundary triggers some kind\nof event, whatever the event might be.\n\n222\n00:12:15.910 --> 00:12:19.140\nYou leave the boundary,\nwe're gonna do a virus scan,\n\n223\n00:12:19.140 --> 00:12:22.490\nright, or maybe you're coming into that\nlocation, we're gonna do a virus scan.\n\n224\n00:12:22.490 --> 00:12:27.900\nBut it triggers some kind of event based\non a virtualized geographical boundary,\n\n225\n00:12:27.900 --> 00:12:29.810\nright, that's geofencing.\n\n226\n00:12:29.810 --> 00:12:33.250\nThings like screen locks, screen locks is\nanother thing, you don't wanna just keep\n\n227\n00:12:33.250 --> 00:12:35.924\nyourself logged into the device to\nwhere if you walk away from it and\n\n228\n00:12:35.924 --> 00:12:38.957\nit stays logged in all the time, somebody\njust has to walk over and grab it.\n\n229\n00:12:38.957 --> 00:12:41.048\nNow they can gain access to it and\nthey really didn't have to hack it,\n\n230\n00:12:41.048 --> 00:12:43.330\nit's like leaving the front door opened.\n\n231\n00:12:43.330 --> 00:12:45.510\nDon't leave the front door open and\nwonder why.\n\n232\n00:12:45.510 --> 00:12:48.040\nSomething got stolen out of your house.\n\n233\n00:12:49.330 --> 00:12:52.489\nAll right, so yeah,\nI think we've covered that.\n\n234\n00:12:52.489 --> 00:12:55.111\nWe've gotta a couple of other things\nthat we need to talk about too,\n\n235\n00:12:55.111 --> 00:12:56.600\nthings like third party app stores.\n\n236\n00:12:56.600 --> 00:13:01.540\nI want you to think about, and I know you\ncan do this inside of iOS devices and\n\n237\n00:13:01.540 --> 00:13:03.410\nI know you can do it\ninside of Android devices.\n\n238\n00:13:03.410 --> 00:13:08.410\nBut the ability to download applications\nfrom things like untrusted sources,\n\n239\n00:13:08.410 --> 00:13:09.920\nthat presents a problem.\n\n240\n00:13:09.920 --> 00:13:11.650\nIn fact,\nI can tell you one problem it has,\n\n241\n00:13:11.650 --> 00:13:15.630\nsome of the banking applications that\nyou have running on your machines\n\n242\n00:13:15.630 --> 00:13:18.465\nwill warn you when you log\ninto your banking application.\n\n243\n00:13:18.465 --> 00:13:21.520\nThat it says,\nyou've got developer options turned on and\n\n244\n00:13:21.520 --> 00:13:25.510\ndownloading from unknown sources,\nuntrusted sources, and why is that?\n\n245\n00:13:25.510 --> 00:13:30.586\nWell, typically, these third-party app\nstores do a very good job in making\n\n246\n00:13:30.586 --> 00:13:35.506\nsure that the applications that they're\nallowing to be pushed out to their\n\n247\n00:13:35.506 --> 00:13:40.917\ndevices are not necessarily free from\nvulnerabilities, or anything like that.\n\n248\n00:13:40.917 --> 00:13:44.130\nBut they can verify with the publishers\nthat they came from, right?\n\n249\n00:13:44.130 --> 00:13:48.430\nI know Apple's big on this,\nApple is very hard to get an application\n\n250\n00:13:48.430 --> 00:13:52.329\ninto their store because you have to\ngo through a pretty rigorous process.\n\n251\n00:13:52.329 --> 00:13:55.539\nI know Microsoft is very good at this too,\n\n252\n00:13:55.539 --> 00:13:59.550\nin the fact that if they catch\nan application that has shady,\n\n253\n00:13:59.550 --> 00:14:02.660\nfraudulent means, they take it\nright out of the store, right.\n\n254\n00:14:02.660 --> 00:14:04.610\nGoogle Play is another one,\nthey're very good.\n\n255\n00:14:04.610 --> 00:14:08.399\nAnd again,\nkeep in mind that if you are gonna go to\n\n256\n00:14:08.399 --> 00:14:12.180\na third party store, you need to make sure\nthat the applications you're downloading\n\n257\n00:14:12.180 --> 00:14:14.230\nare approved by your company, right?\n\n258\n00:14:14.230 --> 00:14:17.860\nEspecially if it's in one of those devices\nthat is a COPE-based deployment model,\n\n259\n00:14:17.860 --> 00:14:20.220\nwhere it's corporately owned,\nbut personally enabled.\n\n260\n00:14:20.220 --> 00:14:22.250\nAnd that's something that we can do,\nright?\n\n261\n00:14:22.250 --> 00:14:25.410\nWe can basically do\napplication management and\n\n262\n00:14:25.410 --> 00:14:29.560\nwe can control what can go on those phones\nand what doesn't go on those phones?\n\n263\n00:14:29.560 --> 00:14:32.206\nAll right, some of the other things\nthat we need to worry about,\n\n264\n00:14:32.206 --> 00:14:33.898\nrooting and jailbreaking, right?\n\n265\n00:14:33.898 --> 00:14:37.230\nWhen you root your system or you jailbreak\nyour system, there is the ability to put\n\n266\n00:14:37.230 --> 00:14:41.241\non things like custom ROMs, and\nthat does present a problem, right?\n\n267\n00:14:41.241 --> 00:14:45.219\nThere are some things like mobile device\nmanagement solutions, that if your device\n\n268\n00:14:45.219 --> 00:14:48.300\nis known to be jailbroken,\nyou can't bring it into the company,\n\n269\n00:14:48.300 --> 00:14:49.120\nbecause-\n&gt;&gt; Yeah,\n\n270\n00:14:49.120 --> 00:14:50.671\ndon't expect to use your warranty.\n\n271\n00:14:50.671 --> 00:14:53.941\n&gt;&gt; That's right, definitely don't\nexpect to use the warranty for sure.\n\n272\n00:14:53.941 --> 00:14:56.570\nSideloading, well, what's sideloading?\n\n273\n00:14:56.570 --> 00:14:59.120\nLet's go back to the third\nparty app stores.\n\n274\n00:14:59.120 --> 00:15:02.675\nAnd typically,\nwhen those applications get downloaded,\n\n275\n00:15:02.675 --> 00:15:06.185\nwhat they have is a digital signature and\nthe digital signature matches\n\n276\n00:15:06.185 --> 00:15:09.675\na certificate that's typically in the\nphone that says, yeah, you can trust us.\n\n277\n00:15:10.825 --> 00:15:14.045\nWell, the problem here with sideloading\nis, what if you've got an application that\n\n278\n00:15:14.045 --> 00:15:18.620\nyour company is testing but you don't\nwanna put it up in one of the app stores?\n\n279\n00:15:18.620 --> 00:15:21.435\nWell they do allow the ability to do that.\n\n280\n00:15:21.435 --> 00:15:24.120\nSideload just means going and\nloading that application, but\n\n281\n00:15:24.120 --> 00:15:26.170\nnot going through the traditional\napp store to do it.\n\n282\n00:15:26.170 --> 00:15:28.330\nThat's why they call it sideloading,\nall right.\n\n283\n00:15:28.330 --> 00:15:31.250\nThis does present a problem in\nthe fact that if it's turned on and\n\n284\n00:15:31.250 --> 00:15:33.734\nsomebody can potentially download and\n\n285\n00:15:33.734 --> 00:15:38.690\nsideload an application that has\nvulnerabilities or is untrusted.\n\n286\n00:15:38.690 --> 00:15:40.800\nSo again, these can be problems.\n\n287\n00:15:40.800 --> 00:15:44.780\nCustom firmware, anytime we talk\nabout customizing firmware,\n\n288\n00:15:44.780 --> 00:15:47.550\nwhat's in the firmware package,\ndo you know?\n\n289\n00:15:47.550 --> 00:15:50.540\nWell I'm not sure, but\nwe gotta hope, we trust it, so\n\n290\n00:15:50.540 --> 00:15:52.600\ncustomized firmware can be a problem.\n\n291\n00:15:52.600 --> 00:15:54.400\nFirmware OTA updates, right,\n\n292\n00:15:54.400 --> 00:15:58.630\nover the air, I actually got one waiting\non my phone right now that just came out.\n\n293\n00:15:58.630 --> 00:16:01.591\nAnd this is usually where they bake in\nboth the operating system updates and\n\n294\n00:16:01.591 --> 00:16:04.082\nthe firmware into a single package and\nthey deliver it to you and\n\n295\n00:16:04.082 --> 00:16:06.214\nyou press a button you say,\nyou got a new update.\n\n296\n00:16:06.214 --> 00:16:09.174\nData available to the operating system and\nyou download it.\n\n297\n00:16:09.174 --> 00:16:15.681\nAgain, you can enforce this, maybe you\ngo through a waiting period, right?\n\n298\n00:16:15.681 --> 00:16:18.620\nDepends on what kind of mobile\ndevice management solution you have,\n\n299\n00:16:18.620 --> 00:16:20.630\ncan you use the camera, right?\n\n300\n00:16:20.630 --> 00:16:22.260\nCamera's a privacy concern, and\n\n301\n00:16:22.260 --> 00:16:25.170\nthere are solutions where you're\nnot allowed to use the camera.\n\n302\n00:16:25.170 --> 00:16:26.630\nIn fact, let me go ahead and show you.\n\n303\n00:16:26.630 --> 00:16:28.810\nI know I've been talking here for\nabout 15 minutes and\n\n304\n00:16:28.810 --> 00:16:30.610\nhaven't shown you guys anything.\n\n305\n00:16:30.610 --> 00:16:32.470\nLet's go ahead and kind of dive in here.\n\n306\n00:16:32.470 --> 00:16:34.160\nThis is VMware's AirWatch, right?\n\n307\n00:16:34.160 --> 00:16:37.970\nMaybe some of you guys have seen\nthings like Microsoft's Intune,\n\n308\n00:16:37.970 --> 00:16:40.700\nwhich is a mobile device\nmanagement solution.\n\n309\n00:16:40.700 --> 00:16:44.880\nWell, this is VMware's form of\nmobile device management, right?\n\n310\n00:16:44.880 --> 00:16:48.938\nAnd we can do a lot of things in here, for\ninstance, we can create blueprints, right?\n\n311\n00:16:48.938 --> 00:16:51.008\nAnd in these blueprints we can say, okay,\n\n312\n00:16:51.008 --> 00:16:54.530\nwhat kind of applications are allowed\nto be downloaded to your machine?\n\n313\n00:16:54.530 --> 00:16:58.760\nSo you can see Android apps that\nare allowed right here are Twitter, and\n\n314\n00:16:58.760 --> 00:17:03.120\nyou can see that's both for Android and\nApple applications as well.\n\n315\n00:17:03.120 --> 00:17:06.020\nLet's see, let's go ahead and\nget in here and\n\n316\n00:17:06.020 --> 00:17:09.970\nI wanna see some of the devices and\ngroups and settings.\n\n317\n00:17:09.970 --> 00:17:13.570\nOkay, so earlier we were\ntalking about things like for\n\n318\n00:17:13.570 --> 00:17:17.210\ninstance, let me see if I can find it,\nApple, that's what I'm looking for.\n\n319\n00:17:17.210 --> 00:17:19.000\nRemember we talked about\npush notifications?\n\n320\n00:17:19.000 --> 00:17:21.400\nBeing able to push out\nnotifications to that device?\n\n321\n00:17:21.400 --> 00:17:25.760\nWell, if you are gonna do push\nnotifications from a mobile\n\n322\n00:17:25.760 --> 00:17:27.760\ndevice management solution,\n\n323\n00:17:27.760 --> 00:17:30.690\nthings like Apple that requires\ncertificate to be downloaded.\n\n324\n00:17:30.690 --> 00:17:35.850\nYou notice this right here, this APN for\nMDM, guys I know alphabet soup,\n\n325\n00:17:35.850 --> 00:17:39.100\nthat's Apple Push Notifications\nis actually a certificate.\n\n326\n00:17:39.100 --> 00:17:42.510\nThat you go to Apple, you download,\nyou register for, you download and\n\n327\n00:17:42.510 --> 00:17:45.310\nthen you can throw that\ninto your MDM solution.\n\n328\n00:17:45.310 --> 00:17:49.200\nSo that you could push out notifications\nfrom a solution like this.\n\n329\n00:17:49.200 --> 00:17:52.160\nAll right, so what are some of the other\nthings that we can do as well here?\n\n330\n00:17:52.160 --> 00:17:57.102\nControlling SMS messages and\nthe multimedia message, MMS messages too.\n\n331\n00:17:57.102 --> 00:17:58.993\nI really wanted to kind of show you guys.\n\n332\n00:17:58.993 --> 00:18:00.680\nI tell you what,\nlet's add a blueprint here.\n\n333\n00:18:00.680 --> 00:18:01.800\nWe'll kind of create a blueprint.\n\n334\n00:18:01.800 --> 00:18:03.419\nYou can see some of the things\nthat you can do, right?\n\n335\n00:18:04.560 --> 00:18:06.660\nAs we go through here,\nwe can name the blueprint.\n\n336\n00:18:06.660 --> 00:18:08.800\nWe'll just call this Demo.\n\n337\n00:18:08.800 --> 00:18:11.880\nAnd we'll save and continue this.\n\n338\n00:18:11.880 --> 00:18:13.200\nAll right, Applications.\n\n339\n00:18:13.200 --> 00:18:20.065\nWhat kind of applications do I wanna\nallow inside of my mobile devices, right?\n\n340\n00:18:20.065 --> 00:18:23.085\nAnd I could, if I want,\nmaybe add an application.\n\n341\n00:18:23.085 --> 00:18:24.995\nWhat country will the application be used?\n\n342\n00:18:24.995 --> 00:18:27.451\nSo we'll just go ahead and\nkind of next through this.\n\n343\n00:18:27.451 --> 00:18:30.945\nAnd maybe we do something,\nI don't know, LinkedIn.\n\n344\n00:18:33.960 --> 00:18:37.250\nTry that, see if we can find a LinkedIn\nand maybe we allow that to be.\n\n345\n00:18:37.250 --> 00:18:39.179\nAnd if we don't find it, that's fine.\n\n346\n00:18:39.179 --> 00:18:40.990\nBut I really wanna get to,\nI'll tell you what.\n\n347\n00:18:40.990 --> 00:18:43.502\nLet's go ahead and save and exit this.\n\n348\n00:18:43.502 --> 00:18:47.890\nI wanna show you some of the settings\nthat you can do in here if\n\n349\n00:18:47.890 --> 00:18:52.860\nI could find the applications,\ndevices and users, system, nope.\n\n350\n00:18:53.975 --> 00:18:58.999\nI'm not seeing it, hold on a second,\ndevices, okay, device settings.\n\n351\n00:18:58.999 --> 00:19:01.250\nAll right, that's not where we need to be.\n\n352\n00:19:01.250 --> 00:19:02.570\nLet me go ahead and close this down.\n\n353\n00:19:02.570 --> 00:19:05.500\nAnd what we need to do is go\nback into our blueprints and\n\n354\n00:19:05.500 --> 00:19:07.020\nit's the policies that I was looking at.\n\n355\n00:19:07.020 --> 00:19:09.480\nCuz I wanna kind of show you some of\nthe settings that you can control.\n\n356\n00:19:09.480 --> 00:19:13.409\nBy pushing out the policies and\nI've already got a blue print here and\n\n357\n00:19:13.409 --> 00:19:15.588\nwe don't have any policies defined.\n\n358\n00:19:15.588 --> 00:19:18.788\nBut if we kind of zoom in right here,\nthis is what we are looking at,\n\n359\n00:19:18.788 --> 00:19:21.720\nwe wanna be able to enforce\ndifferent types of settings.\n\n360\n00:19:21.720 --> 00:19:26.326\nFor instance, are you gonna allow\nrecordings through the microphone, right,\n\n361\n00:19:26.326 --> 00:19:28.370\nor are we gonna allow\nthings like our cameras.\n\n362\n00:19:28.370 --> 00:19:29.660\nAnd if we get into policies here,\n\n363\n00:19:29.660 --> 00:19:33.860\nyou can see that they have it broken\ndown and it's kind of interesting.\n\n364\n00:19:33.860 --> 00:19:37.160\nl really like this,\nIntune's another one word,\n\n365\n00:19:37.160 --> 00:19:40.990\nnot just l used to call it Windows Intune,\nnow they call it Microsoft Intune.\n\n366\n00:19:40.990 --> 00:19:43.945\nAnd l think this is a really good choice\nby Microsoft on the naming convention.\n\n367\n00:19:43.945 --> 00:19:47.440\nBecause of the fact that it's not\njust managing Windows anymore.\n\n368\n00:19:47.440 --> 00:19:52.289\nYou see just like VMware's AirWatch here,\nwe have Android, iOS devices, Mac OS,\n\n369\n00:19:52.289 --> 00:19:55.179\nright, we have the Windows Phone and\nWindows PC.\n\n370\n00:19:55.179 --> 00:19:57.748\nAnd there's a lot of different\nthings that we can do, right?\n\n371\n00:19:57.748 --> 00:20:00.140\nDo I wanna allow the use of the camera?\n\n372\n00:20:00.140 --> 00:20:03.670\nDo I wanna use things like Bluetooth and\nFC?\n\n373\n00:20:03.670 --> 00:20:08.610\nDo I even wanna allow AirDrop or\nthe near field communications, right?\n\n374\n00:20:08.610 --> 00:20:11.480\nHow about the personal assistance\nlike Siri and Cortana?\n\n375\n00:20:11.480 --> 00:20:12.622\nDo I wanna allow that,\n\n376\n00:20:12.622 --> 00:20:16.178\ndo I wanna allow things like\nthe Device Wipe that we've talked about?\n\n377\n00:20:16.178 --> 00:20:21.618\nOther things that we might do is\nthings like carrier unlocking, right,\n\n378\n00:20:21.618 --> 00:20:27.161\nI don't want to be just controlled\nby a single carrier here, let's see.\n\n379\n00:20:27.161 --> 00:20:29.516\nAllow access to the App Store, right?\n\n380\n00:20:29.516 --> 00:20:32.060\nGaming centers,\ndata loss prevention, right?\n\n381\n00:20:32.060 --> 00:20:34.150\nScreen captures, do I allow that?\n\n382\n00:20:34.150 --> 00:20:37.320\nDo I allow external storage medium?\n\n383\n00:20:37.320 --> 00:20:40.020\nAll right, it's something that\nwe can also do too, right?\n\n384\n00:20:40.020 --> 00:20:42.760\nSo do we want external media\nto be allowed, do we wanna\n\n385\n00:20:42.760 --> 00:20:46.680\nallow things like tethering, is other\nthings that we need to keep in mind?\n\n386\n00:20:46.680 --> 00:20:48.820\nDifferent types of payment methods.\n\n387\n00:20:48.820 --> 00:20:51.160\nRight here, I like this,\ndon't require encryption.\n\n388\n00:20:52.700 --> 00:20:55.460\nAllow unmanaged use of managed documents,\nright?\n\n389\n00:20:55.460 --> 00:20:58.430\nSo we've got a lot of\noptions that we can use here,\n\n390\n00:20:58.430 --> 00:21:01.660\nas long as we set up our policies right.\n\n391\n00:21:01.660 --> 00:21:03.940\nSo a couple of different\nthings that you can do here.\n\n392\n00:21:03.940 --> 00:21:06.350\nA lot of control when\nyou talk about AirWatch.\n\n393\n00:21:06.350 --> 00:21:10.410\nA lot of good, device control,\nyou get your heads up.\n\n394\n00:21:10.410 --> 00:21:15.234\nFor instance, I can see right here that\none of these machines was compromised,\n\n395\n00:21:15.234 --> 00:21:15.738\nright?\n\n396\n00:21:15.738 --> 00:21:17.638\nAnd this is actually kind of cool,\n\n397\n00:21:17.638 --> 00:21:22.130\none of our other hosts did a compromise on\none of, I believe it was an iOS device.\n\n398\n00:21:22.130 --> 00:21:26.470\nRight, we can see for instance,\nwe can see, well let's see here,\n\n399\n00:21:26.470 --> 00:21:28.930\nif I can find the devices here on the hub.\n\n400\n00:21:28.930 --> 00:21:31.280\nYeah, that's where we need to go,\nthe hub, right.\n\n401\n00:21:31.280 --> 00:21:34.940\nI can see enrollment history,\nwhat kind of platforms we have,\n\n402\n00:21:34.940 --> 00:21:36.930\nregistered versus unenrolled.\n\n403\n00:21:36.930 --> 00:21:40.994\nAnd that was kind of cool because\nthis device was jailbroken,\n\n404\n00:21:40.994 --> 00:21:43.738\nit went to an unenrolled status, right?\n\n405\n00:21:43.738 --> 00:21:48.541\nAnd I can see that we've got a couple of\ndevices, right, corporate, dedicated,\n\n406\n00:21:48.541 --> 00:21:50.269\nand employee owned, right?\n\n407\n00:21:50.269 --> 00:21:54.758\nDifference between, things like cope, the\ncope deployment model and the BYOD model.\n\n408\n00:21:54.758 --> 00:21:56.584\nAnd we can even see what the devices are.\n\n409\n00:21:56.584 --> 00:22:02.401\nSo we've got a lot of flexibility inside\nof our mobile device management solution.\n\n410\n00:22:02.401 --> 00:22:06.873\nBut do keep in mind that it does\nrequire setting a mobile device\n\n411\n00:22:06.873 --> 00:22:09.290\nmanagement authority, right?\n\n412\n00:22:09.290 --> 00:22:13.131\nAnd you alsohave to enroll your\ndevice inside of an MDM for\n\n413\n00:22:13.131 --> 00:22:16.470\nthis to be something that you can use.\n\n414\n00:22:16.470 --> 00:22:19.221\nAll right, so\nthat's a lot about mobile security,\n\n415\n00:22:19.221 --> 00:22:22.560\ncouple of other things that I\nwanna kind of mention, right?\n\n416\n00:22:22.560 --> 00:22:26.610\nDo we allow things like tethering,\nI kind of just briefly mentioned it.\n\n417\n00:22:26.610 --> 00:22:30.270\nRemember that tethering is allowing\nyour device to piggy back off on\n\n418\n00:22:30.270 --> 00:22:31.440\nanother connection.\n\n419\n00:22:31.440 --> 00:22:34.556\nIs it something that we wanna\nallow cuz again, keep in mind,\n\n420\n00:22:34.556 --> 00:22:37.257\nis the device that you're\ntethering off of secure?\n\n421\n00:22:37.257 --> 00:22:39.620\nCould that be used as a leap frog attack?\n\n422\n00:22:39.620 --> 00:22:43.582\nAgain, that will be something\nthat you do have to keep in mind.\n\n423\n00:22:43.582 --> 00:22:46.680\nSo a lot of different things when\nit comes to mobile security and\n\n424\n00:22:46.680 --> 00:22:50.150\nwe do have to make sure that\nthose devices stay secure\n\n425\n00:22:50.150 --> 00:22:54.470\nbecause we're only gonna see more and\nmore of them as time goes by.\n\n426\n00:22:54.470 --> 00:22:55.640\n&gt;&gt; That is so true.\n\n427\n00:22:55.640 --> 00:22:59.850\nAnd just like Cisco's predictions,\nwho knows what the exponential\n\n428\n00:22:59.850 --> 00:23:02.660\nrate of these mobile devices\nwill be in the near future.\n\n429\n00:23:02.660 --> 00:23:05.864\nBut for now, at least we have some good\ntips to know where we should begin as far\n\n430\n00:23:05.864 --> 00:23:07.520\nas securing these mobile devices.\n\n431\n00:23:07.520 --> 00:23:08.600\nThank you, Wes.\n\n432\n00:23:08.600 --> 00:23:10.670\nAnd thank you ladies and\ngentlemen for joining us today.\n\n433\n00:23:10.670 --> 00:23:12.670\nBut for this show,\nwe'll go ahead and sign out.\n\n434\n00:23:12.670 --> 00:23:14.008\nI'm your host, Cherokee Boose.\n\n435\n00:23:14.008 --> 00:23:14.621\n&gt;&gt; And I'm Wes Bryan.\n\n436\n00:23:14.621 --> 00:23:18.177\n&gt;&gt; See you next time here at ITVProTV.\n\n437\n00:23:18.177 --> 00:23:24.134\n[MUSIC]\n\n438\n00:23:24.134 --> 00:23:27.301\n&gt;&gt; Thank you for watching ITVProTV.\n\n",
          "vimeoId": "213663436"
        },
        {
          "description": "In this show, Cherokee and Wes stess the importance of not only knowing what secure protocols are but rather one should also understand why they should not use the insecure counterpart. They also mention that in addition to understanding these protocols it is very important to be able to recognize the port numbers associated with these protocols for proper configuration and network analysis.",
          "length": "1662",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-6-implement_secure_protocols-041317-PGM.00_27_27_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-6-implement_secure_protocols-041317-PGM.00_27_27_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-2-6-implement_secure_protocols-041317-PGM.00_27_27_23.Still001-sm.jpg",
          "title": "Implement Secure Protocols",
          "transcript": "WEBVTT\n\n1\n00:00:00.290 --> 00:00:06.458\nWelcome to ITPRO TV, I'm your host Don-\n&gt;&gt; [CROSSTALK]\n\n2\n00:00:06.458 --> 00:00:08.363\n&gt;&gt; [MUSIC]\n\n3\n00:00:08.363 --> 00:00:11.771\n&gt;&gt; You're watching ITPRO TV.\n\n4\n00:00:11.771 --> 00:00:14.397\n&gt;&gt; Welcome to your\nCompTIA Security+ Series.\n\n5\n00:00:14.397 --> 00:00:16.850\nI'm your show host Cherokee Boose.\n\n6\n00:00:16.850 --> 00:00:18.650\nKnowing which protocols are secure and\n\n7\n00:00:18.650 --> 00:00:22.350\nunsecure can really make a big difference\nwhen choosing what to use on your network.\n\n8\n00:00:22.350 --> 00:00:26.010\nSo in this show,\nwe'll be examining the secure protocols.\n\n9\n00:00:26.010 --> 00:00:28.290\nWith us today we have\nMr Wes Bryan in studios.\n\n10\n00:00:28.290 --> 00:00:29.043\nThank you for joining us, Wes.\n\n11\n00:00:29.043 --> 00:00:30.570\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n12\n00:00:30.570 --> 00:00:33.420\nYeah, that's right we're gonna look\nat some ways that you can secure\n\n13\n00:00:33.420 --> 00:00:35.804\nthe communication between your source and\ndestination.\n\n14\n00:00:35.804 --> 00:00:39.790\nAnd there are a handful of protocols that\nthey call out that you should be aware of\n\n15\n00:00:39.790 --> 00:00:41.195\nfor the exam.\n\n16\n00:00:41.195 --> 00:00:43.365\nSo, we'll go ahead and\nwe'll just dive right in.\n\n17\n00:00:43.365 --> 00:00:44.951\nWe'll start with the very first one.\n\n18\n00:00:44.951 --> 00:00:48.284\nIn some of the past episodes,\nwe've talked about various attacks,\n\n19\n00:00:48.284 --> 00:00:51.336\nvulnerabilities that you could\nbe faced with on your network.\n\n20\n00:00:51.336 --> 00:00:53.366\nAnd one of the most important services,\n\n21\n00:00:53.366 --> 00:00:56.662\nalot of these network services\nthat we talk about are important.\n\n22\n00:00:56.662 --> 00:00:58.682\nBut one of the most important ones is,\nwell,\n\n23\n00:00:58.682 --> 00:01:03.882\npretty how how we find computers out there\nacross the internet just by using a name.\n\n24\n00:01:03.882 --> 00:01:04.724\nA fully qualified domain name.\n\n25\n00:01:04.724 --> 00:01:07.302\nAnd what service are we talking about?\n\n26\n00:01:07.302 --> 00:01:10.299\nNone other than the domain name system,\nDNS.\n\n27\n00:01:10.299 --> 00:01:16.610\nSo, DNS is one that can be vulnerable cuz,\nfor the most part, it lacks security.\n\n28\n00:01:16.610 --> 00:01:19.385\nI say it lacks security,\nthere is a way that we can secure this and\n\n29\n00:01:19.385 --> 00:01:21.645\nthat's the protocol that\nwe're gonna talk about.\n\n30\n00:01:21.645 --> 00:01:25.266\nBut, what can happen when it comes to DNS?\n\n31\n00:01:25.266 --> 00:01:26.186\nWhat are we vulnerable to?\n\n32\n00:01:26.186 --> 00:01:32.160\nWell, we're vulnerable to things like DNS\nspoofing attacks, DNS hijacking attacks.\n\n33\n00:01:32.160 --> 00:01:36.811\nDNS poisoning attacks, where somebody puts\na record inside of that DNS zone file.\n\n34\n00:01:36.811 --> 00:01:41.593\nThat database that holds those fully\nqualified domain names to IP addresses,\n\n35\n00:01:41.593 --> 00:01:43.633\nputs an invalid record in there.\n\n36\n00:01:43.633 --> 00:01:46.339\nAnd when I decide that I\nwanna go to a website,\n\n37\n00:01:46.339 --> 00:01:50.767\nI get returned that invalid response\nthat says whatever that IP address.\n\n38\n00:01:50.767 --> 00:01:52.652\nMaps the name to an IP address, and\n\n39\n00:01:52.652 --> 00:01:56.520\nthat IP address just happens to\nbe maybe a malicious website.\n\n40\n00:01:56.520 --> 00:01:58.090\nThese are things that\nwe have to worry about.\n\n41\n00:01:58.090 --> 00:02:02.890\nSo imagine having a technology in\nwhich when DNS responds back to you\n\n42\n00:02:02.890 --> 00:02:07.580\nit's got a digital signature on every\nsingle response that it gives you back.\n\n43\n00:02:07.580 --> 00:02:10.230\nSo you know it came from\nthe right DNS server.\n\n44\n00:02:10.230 --> 00:02:13.410\nAnd more so you know that it's\nan authoritative response coming from\n\n45\n00:02:13.410 --> 00:02:16.490\nthe DNS server saying,\nI am the authority over these records and\n\n46\n00:02:16.490 --> 00:02:19.900\nhere's the digital signature on\nthe response so that you can verify it.\n\n47\n00:02:19.900 --> 00:02:22.390\nAnd that's where something known\nas DNS security comes in, and\n\n48\n00:02:22.390 --> 00:02:25.060\nit's typically just DNSSEC for short.\n\n49\n00:02:25.060 --> 00:02:26.550\nNow, where can we see things like this?\n\n50\n00:02:26.550 --> 00:02:29.480\nWell, I've got a Windows Server\n2016 machine here.\n\n51\n00:02:29.480 --> 00:02:34.340\nIf we could bring that up, let me show\nyou where you can actually see this.\n\n52\n00:02:34.340 --> 00:02:38.210\nTypically, we're gonna do this inside of\na domain environment where we're gonna be\n\n53\n00:02:38.210 --> 00:02:40.330\nmodifying group policy objects.\n\n54\n00:02:40.330 --> 00:02:42.156\nKeep in mind that maybe\nyou're practicing at home.\n\n55\n00:02:42.156 --> 00:02:45.026\nMaybe if you don't have a server on there,\n\n56\n00:02:45.026 --> 00:02:49.610\nyou have a Windows 10 machine,\nyou can always type gpedit.msc.\n\n57\n00:02:49.610 --> 00:02:52.711\nAnd you're pretty much gonna go to the\nsame location in order to see where you\n\n58\n00:02:52.711 --> 00:02:54.177\ncan implement things like DNSSEC.\n\n59\n00:02:54.177 --> 00:02:58.630\nSo let me go ahead, and I'll go to my\nGroup Policy Management Console here.\n\n60\n00:03:00.240 --> 00:03:02.680\nAll right, and\nwe're just gonna go ahead and\n\n61\n00:03:02.680 --> 00:03:06.760\nI'll go under Domains here,\nand under Group Policy.\n\n62\n00:03:06.760 --> 00:03:14.429\nAnd we're just gonna create a new GPO\nhere, and we'll just call this DNSSEC.\n\n63\n00:03:14.429 --> 00:03:20.754\nAll right, like I said, you can see signs\nof this, or the configurations here,\n\n64\n00:03:20.754 --> 00:03:25.510\nto configure a client to use\nthe DNSSEC here under policies.\n\n65\n00:03:25.510 --> 00:03:29.635\nAnd then it's under your\nWindows security settings.\n\n66\n00:03:29.635 --> 00:03:34.335\nAnd then you'll see that there is\na name resolution policy here.\n\n67\n00:03:34.335 --> 00:03:36.476\nNow, this is used for a couple of things.\n\n68\n00:03:36.476 --> 00:03:40.873\nIn fact when we get in here, you should\nsee that we have multiple settings.\n\n69\n00:03:40.873 --> 00:03:45.149\nFor instance, we have something known\nas the name resolution policy table,\n\n70\n00:03:45.149 --> 00:03:49.645\nanother component used, if you will,\nfor storing those DNS settings.\n\n71\n00:03:49.645 --> 00:03:54.420\nAnd DNSSEC,\nthis is where we are going to enable this.\n\n72\n00:03:54.420 --> 00:03:58.036\nAnd we can say, all right, well,\nwe're gonna enable DNSSEC here.\n\n73\n00:03:58.036 --> 00:04:01.831\nAnd we're gonna require the DNS\nclients to check the name and\n\n74\n00:04:01.831 --> 00:04:05.460\naddress data has been\nvalidated by the DNS server.\n\n75\n00:04:05.460 --> 00:04:10.280\nAgain, we get that the integrity that\nwe talk about so much that we wanna\n\n76\n00:04:10.280 --> 00:04:15.100\nknow that, first of all, those responses\nare coming from a server we trust.\n\n77\n00:04:15.100 --> 00:04:16.892\nSo, we have what's known\nas a trust anchor.\n\n78\n00:04:16.892 --> 00:04:20.972\nWe trust this DNS server, because again,\nit uses public key cryptology to\n\n79\n00:04:20.972 --> 00:04:24.164\ndo the digital signing of every\nresponse that comes back.\n\n80\n00:04:24.164 --> 00:04:29.604\nAnd you can see that again, require DNS\nclients to check that the name and address\n\n81\n00:04:29.604 --> 00:04:34.750\ndata, the response that comes back,\nhas been validated by the DNS server.\n\n82\n00:04:34.750 --> 00:04:36.460\nAnd of course we can go\na little bit farther and\n\n83\n00:04:36.460 --> 00:04:37.890\nwe could use IPsec if you want.\n\n84\n00:04:37.890 --> 00:04:40.040\nBut again,\nwe've already talked about IPsec.\n\n85\n00:04:40.040 --> 00:04:44.819\nKeep in mind, that this is more for\nthe purposes of looking at DNSSEC.\n\n86\n00:04:44.819 --> 00:04:48.613\nSo, that's one of the things that\nyou can utilize in order to validate\n\n87\n00:04:48.613 --> 00:04:51.460\nthose responses that come\nback from the DNS server.\n\n88\n00:04:51.460 --> 00:04:55.684\nWhen you do say hey,\nI wanna go to www.mycompany.com.\n\n89\n00:04:55.684 --> 00:04:59.983\nAnd the DNS server responds back to you,\nand you can validate that response is\n\n90\n00:04:59.983 --> 00:05:03.052\ncoming from a source that you\nexpected it to come from.\n\n91\n00:05:03.052 --> 00:05:08.750\nAll right, so what are some of the other\ntechnologies that we talk about?\n\n92\n00:05:08.750 --> 00:05:09.757\nWe talk about securing email.\n\n93\n00:05:09.757 --> 00:05:14.052\nOne of the ways that you can secure email\nis through something known as S/MIME.\n\n94\n00:05:14.052 --> 00:05:16.779\nWithout the S on it it just means secure,\nbut\n\n95\n00:05:16.779 --> 00:05:20.900\nit's multimedia internet mail extensions,\nI believe.\n\n96\n00:05:20.900 --> 00:05:23.410\nAnd what this does,\nagain, it's a signature.\n\n97\n00:05:23.410 --> 00:05:25.488\nIt's a way to encrypt\nthat communication so\n\n98\n00:05:25.488 --> 00:05:28.800\nthat we can verify that not only is\nit coming from the right source, but\n\n99\n00:05:28.800 --> 00:05:32.358\nthat you have confidentiality and\nnobody eavesdrop on your information.\n\n100\n00:05:32.358 --> 00:05:37.020\nSo, do keep in mind with\nthings like S/MIME.\n\n101\n00:05:37.020 --> 00:05:41.461\nAll right, so some of the other things\nthat they call out here too, see voice and\n\n102\n00:05:41.461 --> 00:05:45.062\nvideo is becoming more and\nmore prevalent within our networks.\n\n103\n00:05:45.062 --> 00:05:49.915\nA lot of high definition traffic,\nvideo teleconferencing, if you will,\n\n104\n00:05:49.915 --> 00:05:52.640\nhigh definition conferencing.\n\n105\n00:05:52.640 --> 00:05:54.450\nWe have a lot of things like, for\n\n106\n00:05:54.450 --> 00:05:58.250\ninstance, real time\ntransport protocol traffic,\n\n107\n00:05:58.250 --> 00:06:03.330\nor real time media transport protocol,\nRMTP, I believe I get that right.\n\n108\n00:06:03.330 --> 00:06:06.198\nSo a lot of communications that\nare using video and audio.\n\n109\n00:06:06.198 --> 00:06:11.230\nWell, we could potentially not want\nsomebody to eavesdrop on that, so\n\n110\n00:06:11.230 --> 00:06:13.110\nthere are ways that we\ncan secure that as well.\n\n111\n00:06:13.110 --> 00:06:16.290\n&gt;&gt; You bring up a good point, Wes,\nbecause a lot of times people think about\n\n112\n00:06:16.290 --> 00:06:21.010\ndata as just kind of being text or\nhave written information.\n\n113\n00:06:21.010 --> 00:06:24.104\nBut with the advent of our video\nteleconferencing and our VOIP\n\n114\n00:06:24.104 --> 00:06:28.049\ncommunications, all of that information\ncan be just as easily intercepted.\n\n115\n00:06:28.049 --> 00:06:30.590\nSo it's something that\nwe can't neglect here.\n\n116\n00:06:30.590 --> 00:06:32.852\n&gt;&gt; Most definitely, cuz we gotta think\nof it as communications streams, right?\n\n117\n00:06:32.852 --> 00:06:34.130\n&gt;&gt; Right.\n&gt;&gt; We think about,\n\n118\n00:06:34.130 --> 00:06:38.620\nmaybe a file transfer,\ntraditional base communications.\n\n119\n00:06:38.620 --> 00:06:39.140\nBut today,\n\n120\n00:06:39.140 --> 00:06:45.090\nwe have constant connection-oriented video\nstreams in which we might wanna secure.\n\n121\n00:06:45.090 --> 00:06:51.377\nAnd one of the ways that we can do that\nis with the secure RTP if you will, SRTP.\n\n122\n00:06:51.377 --> 00:06:55.818\nAll right, and what this does is it\nprovides authentication and encryption for\n\n123\n00:06:55.818 --> 00:07:00.850\nyour communication streams that are using\nthe real time transfer protocol.\n\n124\n00:07:00.850 --> 00:07:04.100\nSome of the other ones that they call out,\nthey call out secure LDAP.\n\n125\n00:07:04.100 --> 00:07:06.660\nAll right, so\nwhat do we mean when we say secure LDAP?\n\n126\n00:07:06.660 --> 00:07:09.420\nWell I want you to think of a situation\nwhere you're communicating with\n\n127\n00:07:09.420 --> 00:07:12.670\na directory service.\n\n128\n00:07:12.670 --> 00:07:15.643\nLDAP, lightweight directory access\nprotocol, I might want my clients to\n\n129\n00:07:15.643 --> 00:07:18.438\ncommunicate, if you will, and\nI don't really care if it's secure.\n\n130\n00:07:18.438 --> 00:07:22.703\nMaybe they're just sending a Kerberos\nauthentication request up to\n\n131\n00:07:22.703 --> 00:07:24.768\nthe directory services server.\n\n132\n00:07:24.768 --> 00:07:27.888\nWell, Kerberos, or Kerberos, if you will,\n\n133\n00:07:27.888 --> 00:07:33.880\nit has its own security techniques, if\nyou will, or technologies built into it.\n\n134\n00:07:33.880 --> 00:07:38.629\nBut what if I have communications that\nare going from one domain controller to\n\n135\n00:07:38.629 --> 00:07:40.467\nanother domain controller?\n\n136\n00:07:40.467 --> 00:07:42.350\nThings like replication.\n\n137\n00:07:42.350 --> 00:07:46.045\nI might not want anybody to be able to\nsit in between that communications,\n\n138\n00:07:46.045 --> 00:07:49.970\neavesdrop on it and\npotentially start scraping information.\n\n139\n00:07:49.970 --> 00:07:55.932\nSo, your directory servers actually\nhave what's know as LDAP over SSL.\n\n140\n00:07:55.932 --> 00:07:58.261\nWe benefit from SSL encryption.\n\n141\n00:07:58.261 --> 00:08:02.847\nNow keep in mind, a lot of times typically\ntoday anytime we say SSL Under the hood\n\n142\n00:08:02.847 --> 00:08:04.366\nwe're really using TLS.\n\n143\n00:08:04.366 --> 00:08:06.404\nWe've been using TLS for awhile now.\n\n144\n00:08:06.404 --> 00:08:11.256\nLet me show you here, but you can see\nI've got that Windows server that I was\n\n145\n00:08:11.256 --> 00:08:15.200\nlogged into, well let's see\nif it's running secure LDAP.\n\n146\n00:08:15.200 --> 00:08:16.850\nSo we'll just go ahead real quick and\n\n147\n00:08:16.850 --> 00:08:21.880\nwe'll do an Nmap scan against\nthe domain controller.\n\n148\n00:08:21.880 --> 00:08:25.840\nLike we've done in the past, right,\ntesting to see whether ports are open.\n\n149\n00:08:25.840 --> 00:08:27.230\n&gt;&gt; Sure.\n\n150\n00:08:27.230 --> 00:08:29.440\n&gt;&gt; Right, and\nwe'll see what we can find out here.\n\n151\n00:08:29.440 --> 00:08:32.460\nSo it's initializing a scan,\nit shouldn't take too long.\n\n152\n00:08:32.460 --> 00:08:36.890\nAnd we'll see, is our domain controller\nrunning things like port 389,\n\n153\n00:08:36.890 --> 00:08:41.130\nwhich is your unsecure LDAP,\nright, it's just plain text LDAP.\n\n154\n00:08:41.130 --> 00:08:45.150\nAs well as it running your secure LDAP?\n\n155\n00:08:45.150 --> 00:08:47.968\nAll right, and if we dive down in here,\n\n156\n00:08:47.968 --> 00:08:52.570\nyou can see port 636,\nright, versus port 389.\n\n157\n00:08:52.570 --> 00:08:57.028\nIf I say port 389, I know that it's\nunencrypted LDAP communications.\n\n158\n00:08:57.028 --> 00:09:01.500\nIf I say port 636,\nI can tell right away that that's LDAP,\n\n159\n00:09:01.500 --> 00:09:06.700\nin this case the way the centos\nbox lets you know its ldapssl.\n\n160\n00:09:06.700 --> 00:09:09.967\nNo different guys if you're\ntalking about ldaps, right,\n\n161\n00:09:09.967 --> 00:09:11.873\nthey're just abbreviating ssl.\n\n162\n00:09:11.873 --> 00:09:15.135\nKinda like what we do when\nwe talk about HTTPS, right.\n\n163\n00:09:15.135 --> 00:09:15.925\nWhen we talk about HTTPS,\n\n164\n00:09:15.925 --> 00:09:19.279\nwhat we are talking about is\nhypertext transport protocol over\n\n165\n00:09:19.279 --> 00:09:23.195\na secure socket layer, right, and\nwe want to encrypt those communications.\n\n166\n00:09:23.195 --> 00:09:25.705\nThat's why when we go to different\nwebsites we will see things\n\n167\n00:09:25.705 --> 00:09:26.425\nlike HTTPS, right.\n\n168\n00:09:26.425 --> 00:09:29.635\n&gt;&gt; Regardless if you are using SSL or TLS.\n\n169\n00:09:29.635 --> 00:09:30.345\n&gt;&gt; Most definitely.\n\n170\n00:09:30.345 --> 00:09:31.964\nBecause if we think about it, right,\n\n171\n00:09:31.964 --> 00:09:34.962\nwe've talked about weak cypher\nstrengths in a past episode, right.\n\n172\n00:09:34.962 --> 00:09:38.798\nYou really wanna be using TLS,\nwhat is it, 1.2, and again,\n\n173\n00:09:38.798 --> 00:09:43.431\n1.3 is in draft right now, we'll see\nwhen that specification comes out.\n\n174\n00:09:43.431 --> 00:09:46.482\nBut for now, 1.2 is the latest and\ngreatest and\n\n175\n00:09:46.482 --> 00:09:50.994\nthe strongest cypher suite versus\nthings like 1.1 and really 1.0.\n\n176\n00:09:50.994 --> 00:09:58.010\n1.0, TLS 1.0 and the last SSL version 3.0,\nthey're almost identical.\n\n177\n00:09:58.010 --> 00:10:01.250\nBut there's just enough minor\ndifferences where they're\n\n178\n00:10:01.250 --> 00:10:02.340\nnot compatible with each other.\n\n179\n00:10:02.340 --> 00:10:06.500\nSo we're really not going to be\nusing SSL in any of its variants.\n\n180\n00:10:06.500 --> 00:10:08.140\nBut you never know, you could have,\n\n181\n00:10:08.140 --> 00:10:10.830\nI'm sure you have plenty of people\nout there that are probably using it.\n\n182\n00:10:10.830 --> 00:10:14.780\nIt's a big world out there, and\nnever is kind of an absolute.\n\n183\n00:10:14.780 --> 00:10:15.510\n&gt;&gt; Yes, never say never.\n\n184\n00:10:15.510 --> 00:10:16.095\n&gt;&gt; That's right.\n\n185\n00:10:16.095 --> 00:10:17.580\n&gt;&gt; [LAUGH]\n&gt;&gt; So let's kind of look and see.\n\n186\n00:10:17.580 --> 00:10:21.990\nWhat are we seeing here when we\nsee this secure HTTPS, right?\n\n187\n00:10:21.990 --> 00:10:23.854\nI can see that it says, for instance,\n\n188\n00:10:23.854 --> 00:10:27.200\nyour information is private when\nit's sent to this site, right.\n\n189\n00:10:27.200 --> 00:10:30.390\nBut we can go a little bit further than\nthat, and we can dig down into the browser\n\n190\n00:10:30.390 --> 00:10:34.290\nhere and we can actually see\nthat certificate in Chrome here.\n\n191\n00:10:34.290 --> 00:10:39.990\nIt's under the Additional Options,\nMore Tools, and then Developer Tools.\n\n192\n00:10:39.990 --> 00:10:43.210\nAnd then you'll have this little\ndrop down button next to Elements.\n\n193\n00:10:43.210 --> 00:10:44.140\nDoesn't look like it.\n\n194\n00:10:44.140 --> 00:10:46.520\nAnd if you just scroll down to Security,\n\n195\n00:10:46.520 --> 00:10:49.780\nwhat this does is it allows you\nto see the certificate, right.\n\n196\n00:10:49.780 --> 00:10:52.967\nSo what happened here,\nwhen we visited the website, right,\n\n197\n00:10:52.967 --> 00:10:57.535\nmy computer went through something known\nas certification chain validation.\n\n198\n00:10:57.535 --> 00:11:00.362\nAnd what that means is, essentially,\nGoogle is presenting me with its,\n\n199\n00:11:00.362 --> 00:11:02.060\nlet's say its driver's license, right.\n\n200\n00:11:02.060 --> 00:11:05.375\nHere's how you can identify\nI am who I say I am.\n\n201\n00:11:05.375 --> 00:11:09.315\nWell why is it that, to a bank or let's\nsay law enforcement officer, when you\n\n202\n00:11:09.315 --> 00:11:13.485\npresent your ID, provided it doesn't look\nlike it's been taped together, right?\n\n203\n00:11:13.485 --> 00:11:15.278\n&gt;&gt; Altered.\n&gt;&gt; [CROSSTALK] altered, why is it,\n\n204\n00:11:15.278 --> 00:11:18.306\nin all seriousness, that the law\nenforcement officer, or if you will,\n\n205\n00:11:18.306 --> 00:11:20.089\nlike your bank, and you go into your bank,\n\n206\n00:11:20.089 --> 00:11:23.091\nwhy is it that they trust the\nidentification that you're giving them?\n\n207\n00:11:23.091 --> 00:11:27.300\nIt's because they trust\nthe authority that issued it, right.\n\n208\n00:11:27.300 --> 00:11:29.040\nSo, for us here in Florida, right,\n\n209\n00:11:29.040 --> 00:11:31.390\nthe state of Florida issued\nme my drivers license.\n\n210\n00:11:31.390 --> 00:11:35.450\nAnd the reason law enforcement,\nor again like our bank trust,\n\n211\n00:11:35.450 --> 00:11:39.360\nmy identification that I get is\nbecause it has checks and balances and\n\n212\n00:11:39.360 --> 00:11:43.820\nit also has, it's come from\nan authority that they trust.\n\n213\n00:11:43.820 --> 00:11:47.040\nSo when I need to find out,\nwhen my computer needs to find out, hey,\n\n214\n00:11:47.040 --> 00:11:50.670\ncan I trust this website, right?\n\n215\n00:11:50.670 --> 00:11:52.290\nHow do I know that I trust Google?\n\n216\n00:11:52.290 --> 00:11:54.570\nWell, it goes through\na validation process, and\n\n217\n00:11:54.570 --> 00:11:56.020\nlet's bring that certificate up again.\n\n218\n00:11:57.270 --> 00:12:03.060\nAnd it says, well, I'm not sure\nthat I trust Google, but I might\n\n219\n00:12:03.060 --> 00:12:08.430\ntrust Google's Internet Authority, they're\nactually a CA, a certificate authority.\n\n220\n00:12:08.430 --> 00:12:11.560\nBut what I like about this\nis they didn't say, well,\n\n221\n00:12:11.560 --> 00:12:14.540\nyou could trust me because,\nwell I said you can trust me.\n\n222\n00:12:14.540 --> 00:12:18.000\nThey actually went to a separate entity,\nright, they went to one of the root\n\n223\n00:12:18.000 --> 00:12:22.080\ncertification authorities that\nare out there and their public.\n\n224\n00:12:22.080 --> 00:12:25.680\nAnd it means that do I trust GeoTrust?\n\n225\n00:12:25.680 --> 00:12:26.280\nWell you should,\n\n226\n00:12:26.280 --> 00:12:30.520\nagain the root trust model says\nthese guys are the top of the chain.\n\n227\n00:12:30.520 --> 00:12:34.291\nAnd let's see here, and we could even\nlook at GeoTrust root authority, right.\n\n228\n00:12:34.291 --> 00:12:36.132\nThis is kind of like saying, hey,\n\n229\n00:12:36.132 --> 00:12:39.145\nI wanna look at the drivers\nlicense of Florida, right.\n\n230\n00:12:39.145 --> 00:12:43.140\nAgain to the analogy of using my\ndrivers license for identification.\n\n231\n00:12:43.140 --> 00:12:46.060\nAnd we can find out what is\nthe encryption that's being used.\n\n232\n00:12:46.060 --> 00:12:49.390\nYou can see that it's relatively\nkind of weak, SHA-1, but\n\n233\n00:12:49.390 --> 00:12:51.110\nit's got RSA encryption, right.\n\n234\n00:12:51.110 --> 00:12:53.670\nSo we're using public key cryptology.\n\n235\n00:12:53.670 --> 00:12:54.810\nAnd it's 256 bytes,\n\n236\n00:12:54.810 --> 00:13:00.390\nI would almost be willing to bet\nsomewhere in here we'll see, yes.\n\n237\n00:13:00.390 --> 00:13:03.160\nOkay, so\nthey're using SHA-256 fingerprints too.\n\n238\n00:13:03.160 --> 00:13:06.728\nSo we can see that information\ninside of the certificate, but\n\n239\n00:13:06.728 --> 00:13:09.757\nmore importantly we can see\nthe name of the company.\n\n240\n00:13:09.757 --> 00:13:14.300\nOr in this case the server that's\npresenting us with a certificate and\n\n241\n00:13:14.300 --> 00:13:18.535\nthat the certificate's valid and\nthat we can actually say that,\n\n242\n00:13:18.535 --> 00:13:20.540\nverified that this is Google.\n\n243\n00:13:20.540 --> 00:13:24.970\nSo that's one of the reasons we\nwanna use something like HTTPS.\n\n244\n00:13:24.970 --> 00:13:28.120\nNow we've kind of mentioned\nSSL already and TLS.\n\n245\n00:13:28.120 --> 00:13:31.090\nKeep in mind, SSL's been around for\na long time, but\n\n246\n00:13:31.090 --> 00:13:34.360\ntoday primarily we're using\nthe transport layer security.\n\n247\n00:13:34.360 --> 00:13:39.300\nBecause transport layer security, what it\ndoesn't allow is for a downgrade, right,\n\n248\n00:13:39.300 --> 00:13:45.050\na negotiation of a weaker cypher strength,\nwhich is what SSL would allow you to do.\n\n249\n00:13:45.050 --> 00:13:45.870\nAll right.\n\n250\n00:13:45.870 --> 00:13:49.470\n&gt;&gt; So Wes if we're taking about those\nprotocol suites where we're taking more\n\n251\n00:13:49.470 --> 00:13:52.570\nthan one combined together\nto create that security.\n\n252\n00:13:52.570 --> 00:13:54.820\nSomething that we've had on our\nnetworks for a very long time, FTP.\n\n253\n00:13:55.960 --> 00:13:58.660\nWe know in Trivial FTP,\nvery unsecure protocols,\n\n254\n00:13:58.660 --> 00:14:00.930\nbut what can we do with this situation?\n\n255\n00:14:00.930 --> 00:14:02.330\n&gt;&gt; That's a great question, Cherokee.\n\n256\n00:14:02.330 --> 00:14:06.809\nIn fact, let's take\nTrivial File Transfer Protocol first, and\n\n257\n00:14:06.809 --> 00:14:09.790\nsee when you say really insecure, right.\n\n258\n00:14:09.790 --> 00:14:13.048\nWell, obviously that's no security\nbuilt in, but it also goes over UDP.\n\n259\n00:14:13.048 --> 00:14:15.720\nSo it's connection-less, right.\n\n260\n00:14:15.720 --> 00:14:19.830\nUDP at best has a checksum, right, that\nsays, when the recipient computer receives\n\n261\n00:14:19.830 --> 00:14:23.130\nit, it says, no, that's bad,\nthat's damaged and it throws it away.\n\n262\n00:14:23.130 --> 00:14:26.670\nIt never calls back home and says,\nhey, send me the next package, right.\n\n263\n00:14:26.670 --> 00:14:31.670\nSo, not only no security in Trivial File\nTransfer Protocol, the fact that we're\n\n264\n00:14:31.670 --> 00:14:35.140\nnot even using a connection oriented\nservice makes it even weaker than that.\n\n265\n00:14:35.140 --> 00:14:38.620\nHowever, with File Transfer Trotocol,\nright, it's plain text.\n\n266\n00:14:38.620 --> 00:14:42.350\nSo the big difference here is it's now\nusing Transmission Control Protocol and\n\n267\n00:14:42.350 --> 00:14:44.070\nyou can throw some more\ncommands at it than you can,\n\n268\n00:14:44.070 --> 00:14:47.400\nyou don't have any commands for\nthe Trivial File Transfer Protocol.\n\n269\n00:14:47.400 --> 00:14:50.770\n&gt;&gt; But how I was sniffing that network, I\nwould see that information in clear text.\n\n270\n00:14:50.770 --> 00:14:53.230\n&gt;&gt; Most definitely, and\nif you're logging in with a user name and\n\n271\n00:14:53.230 --> 00:14:57.510\npassword you could see the username and\npassword too, so it makes it pretty bad.\n\n272\n00:14:57.510 --> 00:14:59.530\nSo there's a couple of\ndifferent technologies and\n\n273\n00:14:59.530 --> 00:15:03.100\nyou have to figure out which side of\nthe tracks do they put the letter s.\n\n274\n00:15:03.100 --> 00:15:08.715\nYou'll see FTPS and\nyou'll also see SFTP, all right.\n\n275\n00:15:08.715 --> 00:15:12.300\nLet's take the first one here where\nthe S The s is on the end, right.\n\n276\n00:15:12.300 --> 00:15:16.700\nThe s being on the end is FTP over SSL.\n\n277\n00:15:16.700 --> 00:15:18.620\nIn fact let me kind of show\nyou what we can do here.\n\n278\n00:15:18.620 --> 00:15:21.050\nSee I've got an FTP server\nspun up on this machine.\n\n279\n00:15:21.050 --> 00:15:24.920\nAnd if I dial down into\nInternet Information Services here,\n\n280\n00:15:24.920 --> 00:15:28.670\nIIS is Microsoft's web server here.\n\n281\n00:15:28.670 --> 00:15:33.270\nAnd we look at the site, if I go over\nhere under sites, expand that out, and\n\n282\n00:15:33.270 --> 00:15:35.640\nI look at my FTP site, all right.\n\n283\n00:15:35.640 --> 00:15:38.890\nNow FTP site we've got authentication,\nright,\n\n284\n00:15:38.890 --> 00:15:42.370\nbut one of the things that we're\nmissing here is right here.\n\n285\n00:15:42.370 --> 00:15:46.570\nThis is what i really want to look at,\nright, FTP SSL Security Settings.\n\n286\n00:15:46.570 --> 00:15:49.120\nSo to answer your question, what are some\nof the things that we can do, right?\n\n287\n00:15:49.120 --> 00:15:52.154\nWell I can if I want, depends on\nif I want public reachability or\n\n288\n00:15:52.154 --> 00:15:53.656\nit's just internal, right.\n\n289\n00:15:53.656 --> 00:15:57.486\nIf it's just internal and this is only\ngonna be like an intranet type FTP server\n\n290\n00:15:57.486 --> 00:16:01.388\nthat only my employees or The employees\nwith inside the company are using them.\n\n291\n00:16:01.388 --> 00:16:04.414\nI can spin up a PKI,\na public key infrastructure,\n\n292\n00:16:04.414 --> 00:16:07.942\nwith a root CA and what we can\ndo is issue, from the root CA or\n\n293\n00:16:07.942 --> 00:16:11.849\nsubordinate CA, we can issue\nan SSL certificate here, right.\n\n294\n00:16:11.849 --> 00:16:16.770\nAnd we can we can require SSL.\n\n295\n00:16:16.770 --> 00:16:18.540\nAnd we can also do things like for\ninstance,\n\n296\n00:16:18.540 --> 00:16:23.250\nchecking that off it says use 128-bit\nencryption for SSL connections.\n\n297\n00:16:23.250 --> 00:16:24.470\nNow, what is that doing?\n\n298\n00:16:24.470 --> 00:16:28.380\nWell, that's adding the same layer of\nsecurity that we're adding if you will to\n\n299\n00:16:28.380 --> 00:16:31.820\nHTTP when we don't want it\nto be in plain text, right.\n\n300\n00:16:31.820 --> 00:16:33.480\nWe do public key exchange, right?\n\n301\n00:16:33.480 --> 00:16:36.580\nWe use SSL and\nit gives us that public key or\n\n302\n00:16:36.580 --> 00:16:39.480\nthe key pair,\nasymmetric key encryption, right?\n\n303\n00:16:39.480 --> 00:16:44.409\nAnd now, we can verify not only do we\nknow who the server is when we connect to\n\n304\n00:16:44.409 --> 00:16:45.516\nthe FTP Server.\n\n305\n00:16:45.516 --> 00:16:50.503\nBut that the FTP Server will now\nhave 128-bit encryption when we talk\n\n306\n00:16:50.503 --> 00:16:55.110\nabout the communications and\ntransferring the files.\n\n307\n00:16:55.110 --> 00:16:59.350\nSo, that is with the S on the end,\nall right?\n\n308\n00:16:59.350 --> 00:17:01.610\nNow, how about if they put\nthe S in front of FTP?\n\n309\n00:17:01.610 --> 00:17:03.620\nWhat does that mean?\n\n310\n00:17:03.620 --> 00:17:05.360\nWell, that's kinda an easy one too.\n\n311\n00:17:05.360 --> 00:17:11.100\nRemember that is just saying,\nhey that's SSH, FTP, all right?\n\n312\n00:17:11.100 --> 00:17:14.740\nSo, SSH, FTP or FTP over SSL.\n\n313\n00:17:14.740 --> 00:17:17.280\nSo, keep in mind what Secure Shell, right?\n\n314\n00:17:17.280 --> 00:17:20.070\nThis is one of the things that we\ndefinitely wanna be running, right?\n\n315\n00:17:20.070 --> 00:17:21.670\nIf we're running Secure Shell,\n\n316\n00:17:21.670 --> 00:17:26.020\nit's because we want things like\nencrypted remote communications, right?\n\n317\n00:17:26.020 --> 00:17:29.340\nOur file transfers, right,\nwe wanna make sure that they are secure.\n\n318\n00:17:29.340 --> 00:17:33.320\nSo we're gonna use FTPS or over SSL.\n\n319\n00:17:33.320 --> 00:17:36.920\nOr we're gonna use something like SSH,\nFTP, which is SFTP.\n\n320\n00:17:36.920 --> 00:17:41.409\nAll right, so-\n&gt;&gt; SNMP?\n\n321\n00:17:41.409 --> 00:17:42.960\nWhat version should we be using?\n\n322\n00:17:42.960 --> 00:17:44.720\n&gt;&gt; SNMP, that's a great question, too,\n\n323\n00:17:44.720 --> 00:17:47.570\nbecause there's three, I almost said\nthere's three different versions.\n\n324\n00:17:47.570 --> 00:17:49.355\nLet's take this one off I can count.\n\n325\n00:17:49.355 --> 00:17:52.760\n[LAUGH] The very first edition\nreally had no security,\n\n326\n00:17:52.760 --> 00:17:55.380\nwe really shouldn't be using that at all.\n\n327\n00:17:55.380 --> 00:18:00.090\nIf you have an ultra secure network\nthat's completely error gap\n\n328\n00:18:00.090 --> 00:18:01.712\nfrom maybe the rest of the world.\n\n329\n00:18:01.712 --> 00:18:02.830\n&gt;&gt; [LAUGH]\n&gt;&gt; And then,\n\n330\n00:18:02.830 --> 00:18:08.300\nyou could probably get away with\nstill using SNMP version two,\n\n331\n00:18:08.300 --> 00:18:11.070\nbecause what it does is it uses\nthings like community strings,\n\n332\n00:18:11.070 --> 00:18:13.290\nwhich is akin to a preshare key,\na password.\n\n333\n00:18:13.290 --> 00:18:15.383\n&gt;&gt; Like a very rudimentary password-\n&gt;&gt; Very rudimentary.\n\n334\n00:18:15.383 --> 00:18:16.356\n&gt;&gt; [CROSSTALK] community names.\n\n335\n00:18:16.356 --> 00:18:17.992\n&gt;&gt; Yeah absolutely.\n\n336\n00:18:17.992 --> 00:18:20.783\nSo SNMP version three, or\nexcuse me version two,\n\n337\n00:18:20.783 --> 00:18:22.850\nisn't really too complex to set up.\n\n338\n00:18:22.850 --> 00:18:23.660\nAnd again like I said,\n\n339\n00:18:23.660 --> 00:18:27.370\nif you have an error gapped network,\nwell it's gonna be just fine for it.\n\n340\n00:18:27.370 --> 00:18:30.610\n&gt;&gt; However, if it's not air gap and\nthen you're gonna wanna be using\n\n341\n00:18:30.610 --> 00:18:35.260\nSNMP version three, because now we have\nthings like authentication and encryption.\n\n342\n00:18:35.260 --> 00:18:38.060\nSo, that's really what you're\ngonna wanna be using today,\n\n343\n00:18:38.060 --> 00:18:42.110\nit's a lot of more complexed to set up but\nin the end, when you are setting up things\n\n344\n00:18:42.110 --> 00:18:45.150\nlike traps, Remember why you\nwanted to secure that too?\n\n345\n00:18:45.150 --> 00:18:46.737\nMaybe we should get to the why?\n\n346\n00:18:46.737 --> 00:18:49.367\n&gt;&gt; Work management protocol,\nI did kind of jump the gun there,\n\n347\n00:18:49.367 --> 00:18:51.630\njust in case you didn't\nknow the protocoling?\n\n348\n00:18:51.630 --> 00:18:52.590\n&gt;&gt; Yeah, that's okay.\n\n349\n00:18:52.590 --> 00:18:53.389\nAnd what does it do?\n\n350\n00:18:53.389 --> 00:18:58.176\nI takes my network devices and my servers,\nand it reports their conditions,\n\n351\n00:18:58.176 --> 00:19:02.530\ntheir state back to centralize\nmonitoring system, right?\n\n352\n00:19:02.530 --> 00:19:05.990\nWell, I certainly don't want those\ncommunications getting in the hands of\n\n353\n00:19:05.990 --> 00:19:09.731\na hacker, because they're gonna know\na lot of information about every network-\n\n354\n00:19:09.731 --> 00:19:10.313\n&gt;&gt; Devices.\n\n355\n00:19:10.313 --> 00:19:14.920\n&gt;&gt; [CROSSTALK]\n&gt;&gt; And it could cause a problem, right?\n\n356\n00:19:14.920 --> 00:19:17.810\nSo, we definitely want to\nsecure those communications.\n\n357\n00:19:18.930 --> 00:19:21.630\nAll right, so that takes care of FTP.\n\n358\n00:19:21.630 --> 00:19:24.164\nI know I've said this a lot,\njust remember,\n\n359\n00:19:24.164 --> 00:19:28.446\nif the s is on the end that's SSL if\nthe SS on the front, that SSH, all right.\n\n360\n00:19:28.446 --> 00:19:33.820\nLet's kinda show you what we\ncan see when it comes to SSH?\n\n361\n00:19:33.820 --> 00:19:35.320\nAnd why we would we want it.\n\n362\n00:19:35.320 --> 00:19:38.590\nIn fact, I'm gonna go ahead and\nI'm not gonna save any changes on IIS.\n\n363\n00:19:38.590 --> 00:19:41.290\nIf we can take a look at my screen here.\n\n364\n00:19:41.290 --> 00:19:46.960\nWhat I've got is, first of all,\nI've got a CentOS machine here, all right?\n\n365\n00:19:46.960 --> 00:19:52.030\nAnd it is running SSH, right, and I could\nverify that if I do something like this,\n\n366\n00:19:52.030 --> 00:19:55.000\nif we do systemctl status, all I\n\n367\n00:19:55.000 --> 00:19:59.840\njust kind of wanna see what the services\nare doing, what services are running.\n\n368\n00:19:59.840 --> 00:20:01.490\nAnd I'll grep that out to ssh.\n\n369\n00:20:01.490 --> 00:20:06.480\nAnd notice that I can see\nright here that I have, for\n\n370\n00:20:06.480 --> 00:20:11.290\ninstance, I've got\nthe Secure Shell daemon running.\n\n371\n00:20:11.290 --> 00:20:15.816\nWe can see that is active, and\nthat it is up, and it is running.\n\n372\n00:20:15.816 --> 00:20:19.600\nI have to have that running on the machine\nin order to be able to use it.\n\n373\n00:20:19.600 --> 00:20:20.538\nSo let's go ahead.\n\n374\n00:20:20.538 --> 00:20:22.681\nWhere we're gonna do a couple of things,\n\n375\n00:20:22.681 --> 00:20:26.725\nlet's SSH from one server back to\nthe other, let's SSH into that server, and\n\n376\n00:20:26.725 --> 00:20:30.300\nlet's find out, kinda,\nwhat that communication would look like.\n\n377\n00:20:30.300 --> 00:20:37.080\nSo, on my machine, here, I've got PuTTY,\nand I'll go ahead and get logged in.\n\n378\n00:20:37.080 --> 00:20:38.420\nI don't know what the IP address is.\n\n379\n00:20:38.420 --> 00:20:39.440\nI should have had that prepared.\n\n380\n00:20:39.440 --> 00:20:41.389\nLet me do an IP adder, okay.\n\n381\n00:20:41.389 --> 00:20:45.222\nI had it right,\njust wanna make sure it's 128.\n\n382\n00:20:45.222 --> 00:20:50.570\nAll right, and we'll go ahead and,\nlet me change the font here,\n\n383\n00:20:50.570 --> 00:20:53.580\nbecause I know, if you guys are like me,\nhave four eyes like me out there-.\n\n384\n00:20:53.580 --> 00:20:55.508\n&gt;&gt; Kind of blind.\n&gt;&gt; It might be a little bit hard\n\n385\n00:20:55.508 --> 00:20:56.330\nto see, yeah.\n\n386\n00:20:56.330 --> 00:20:58.020\nSo, let's go ahead and do that.\n\n387\n00:20:58.020 --> 00:21:00.290\nThere we go,\nit's a little bit easier to see there.\n\n388\n00:21:00.290 --> 00:21:02.090\nAnd what we'll do is we'll log in.\n\n389\n00:21:02.090 --> 00:21:04.720\nI'm gonna log in myself here.\n\n390\n00:21:04.720 --> 00:21:08.940\nAnd we'll let it reach out to\nthat machine over SSH here, and\n\n391\n00:21:08.940 --> 00:21:12.590\nthen I'll go ahead, and\nwe'll put the password in.\n\n392\n00:21:12.590 --> 00:21:14.240\nWe'll go ahead and log in here.\n\n393\n00:21:14.240 --> 00:21:16.400\nThere we go.\nIt's challenging me for my password.\n\n394\n00:21:16.400 --> 00:21:18.860\n&gt;&gt; And that'll analyse that\ncommunication with our PuTTY tool?\n\n395\n00:21:18.860 --> 00:21:23.091\n&gt;&gt; That's right, well, what we're gonna\ndo here is I'm gonna kinda run a ping\n\n396\n00:21:23.091 --> 00:21:27.016\nback from the SSH or back from the CentOS\nserver, back to this one here.\n\n397\n00:21:27.016 --> 00:21:27.730\n&gt;&gt; Okay.\n\n398\n00:21:27.730 --> 00:21:30.970\n&gt;&gt; All right, so now what we have is we\nhave some, we got some traffic, right?\n\n399\n00:21:30.970 --> 00:21:33.040\nSome of the traffic is going\nthrough the tunnel and\n\n400\n00:21:33.040 --> 00:21:36.075\nthen some of the traffic that's coming\nback to this machine is not, right?\n\n401\n00:21:36.075 --> 00:21:37.215\nSo let's see the difference.\n\n402\n00:21:37.215 --> 00:21:41.895\nWhat is going through the tunnel,\nversus what isn't in an SSH communication.\n\n403\n00:21:41.895 --> 00:21:46.035\nSo let's go ahead, and I also got\nWireshark on this server here, so\n\n404\n00:21:46.035 --> 00:21:49.505\nwe can kinda fire that up and\nsee what these packets look like.\n\n405\n00:21:49.505 --> 00:21:53.915\nSo we'll go ahead, and I've already got\nthe one, network adapter, so that's good.\n\n406\n00:21:53.915 --> 00:21:57.040\nRemember in some of the past episodes,\nI said especially with virtualization\n\n407\n00:21:57.040 --> 00:21:59.300\nwe have a whole slew of\nnetwork adapters here.\n\n408\n00:21:59.300 --> 00:22:01.000\nMake sure you're picking the right one.\n\n409\n00:22:01.000 --> 00:22:02.992\nSo it's kinda easy,\neven Wes can't mess this one up.\n\n410\n00:22:02.992 --> 00:22:06.320\nBut notice here,\nnotice what's going on, right.\n\n411\n00:22:06.320 --> 00:22:09.730\nI can see that I have some SSH\ncommunications going on, but\n\n412\n00:22:09.730 --> 00:22:12.740\nI also have ICMP communications going on.\n\n413\n00:22:12.740 --> 00:22:17.710\nWell, why is it that I can tell the SSH\ncommunication is encrypted, but\n\n414\n00:22:17.710 --> 00:22:22.930\nwhen it comes to things like\nICMP it's not encrypted, right?\n\n415\n00:22:22.930 --> 00:22:26.460\nWell again,\nif it's going through the SSH tunnel,\n\n416\n00:22:27.620 --> 00:22:31.970\nthat information, you can see is\nusing packet encryption, right?\n\n417\n00:22:31.970 --> 00:22:33.560\nAnd that's what we want.\n\n418\n00:22:33.560 --> 00:22:37.000\nI can't tell what this\ninformation actually is and hex.\n\n419\n00:22:37.000 --> 00:22:38.890\nI just know that it is scrambled.\n\n420\n00:22:38.890 --> 00:22:42.020\nI know the messages there,\nI know the communication is there.\n\n421\n00:22:42.020 --> 00:22:45.740\nBut, what I don't know is what\nthe communication actually is.\n\n422\n00:22:45.740 --> 00:22:48.400\nVersus something that you can\nsee that's bouncing back from\n\n423\n00:22:48.400 --> 00:22:51.360\nthe sent off server that isn't\ngoing through the tunnel, and\n\n424\n00:22:51.360 --> 00:22:55.430\nthat being those ICMP echo requests,\nright?\n\n425\n00:22:55.430 --> 00:22:59.810\nAnd again, I can pick up any one\nof these SSH communications and\n\n426\n00:22:59.810 --> 00:23:02.160\nI can't tell what the information is.\n\n427\n00:23:02.160 --> 00:23:05.660\nYou can see what packet length is, but\nI cannot tell what the information is.\n\n428\n00:23:05.660 --> 00:23:07.640\nBecause it's using encryption, right.\n\n429\n00:23:07.640 --> 00:23:11.480\nAnd we can see it's just a whole bunch of\nscrambled information that really doesn't\n\n430\n00:23:11.480 --> 00:23:13.780\nmean too much to me at this point.\n\n431\n00:23:13.780 --> 00:23:17.720\nSo, that's the purposes of\nutilizing something like SSH.\n\n432\n00:23:17.720 --> 00:23:21.570\nKeep in mind when you are doing\nthings like remote access,\n\n433\n00:23:21.570 --> 00:23:23.730\nyou don't wanna use something\nlike telnet to write.\n\n434\n00:23:23.730 --> 00:23:27.830\nTelnet is good for testing whether ports\nare open, but it is a clear text protocol.\n\n435\n00:23:27.830 --> 00:23:30.650\nAnd that's why we wanna be\nusing something like SSH.\n\n436\n00:23:32.470 --> 00:23:36.030\nAll right, so that's got our Secure Shell.\n\n437\n00:23:36.030 --> 00:23:38.910\nRemember port 22 if I\nhaven't mentioned that.\n\n438\n00:23:38.910 --> 00:23:41.240\nJust remember port 22 cuz it\nmight come up on the exam.\n\n439\n00:23:41.240 --> 00:23:44.460\nIt says you need to make\na remote encryption.\n\n440\n00:23:44.460 --> 00:23:47.180\nWhich of these ports are you gonna use?\n\n441\n00:23:47.180 --> 00:23:51.490\nIt's a very easy answer to get right,\nbased on just sheer memorization.\n\n442\n00:23:51.490 --> 00:23:53.499\n&gt;&gt; Yeah, those are kind of\nour give me questions, and\n\n443\n00:23:53.499 --> 00:23:55.242\nit can be worded in\na couple different ways.\n\n444\n00:23:55.242 --> 00:23:57.807\nIt could give you that\nnumerical port number or\n\n445\n00:23:57.807 --> 00:24:00.321\nit could just have\nthe actual protocol name.\n\n446\n00:24:00.321 --> 00:24:03.198\nSo knowing both of those is really\ngonna help you out on the exam.\n\n447\n00:24:03.198 --> 00:24:05.883\nAnd in real life when you're\nusing these tools, so [LAUGH].\n\n448\n00:24:05.883 --> 00:24:08.043\n&gt;&gt; Yeah, most definitely,\nand that's the thing too.\n\n449\n00:24:08.043 --> 00:24:09.479\nIt's not just about the certification,\n\n450\n00:24:09.479 --> 00:24:11.170\nit's about what you're\ngonna see in real life.\n\n451\n00:24:11.170 --> 00:24:14.613\nIt's why one of the things we wanna do\nhere is kind of show you the protocol\n\n452\n00:24:14.613 --> 00:24:15.580\nanalyzer, right?\n\n453\n00:24:15.580 --> 00:24:18.130\nWhat is even going on when it\ncomes to that communication?\n\n454\n00:24:18.130 --> 00:24:21.184\nAnd now you can see we get\nthe encryption that we need.\n\n455\n00:24:21.184 --> 00:24:22.692\nCherokee, a couple of last little ones.\n\n456\n00:24:22.692 --> 00:24:24.910\nI know we're kind of coming\nto the end of this one.\n\n457\n00:24:24.910 --> 00:24:27.890\nGuys, this is really just,\nI dont' have any demonstrations for this.\n\n458\n00:24:27.890 --> 00:24:30.220\nThis is just, again,\nkind of like Cherokee mentioned,\n\n459\n00:24:30.220 --> 00:24:31.520\nthose kind of one-off questions.\n\n460\n00:24:31.520 --> 00:24:34.380\nIf you can remember it,\nit can help you out on the exam.\n\n461\n00:24:34.380 --> 00:24:37.920\nSo, we have a series of our email\nprotocols, that you guys are probably\n\n462\n00:24:37.920 --> 00:24:40.826\nalready aware of,\nby the time you get to Security+, right?\n\n463\n00:24:40.826 --> 00:24:44.480\nThe oldie-but-goodies,\nSMTP, we've got POP3.\n\n464\n00:24:44.480 --> 00:24:46.440\nRemember port 25 and port 110.\n\n465\n00:24:46.440 --> 00:24:49.988\nWe also got the Internet\nmessage mail access protocol,\n\n466\n00:24:49.988 --> 00:24:52.110\nIMAP, and that's port 143.\n\n467\n00:24:52.110 --> 00:24:55.680\nNone of those ports,\nnone of those services are secure, right?\n\n468\n00:24:55.680 --> 00:24:59.500\nHowever, we do have secure versions\nof every one of those protocols,\n\n469\n00:24:59.500 --> 00:25:00.620\nfor instance.\n\n470\n00:25:00.620 --> 00:25:03.280\nAnd let me just go ahead and\nmake sure that you guys understand that.\n\n471\n00:25:03.280 --> 00:25:06.610\nWhen I say secure POP,\nevery one of these is over SSL,\n\n472\n00:25:06.610 --> 00:25:09.770\nwhich typically means under the hood,\nit's gonna be TLS encryption.\n\n473\n00:25:09.770 --> 00:25:17.153\nSo, SSL IMAP, instead of being port 143,\nwe're talking about port 993.\n\n474\n00:25:17.153 --> 00:25:24.659\nIf we're talking about POP3, or POP3 if\nyou will over SSL, not 110, but port 995.\n\n475\n00:25:24.659 --> 00:25:28.559\nThe other one that we have to is SMP,\nSMTP, excuse me.\n\n476\n00:25:28.559 --> 00:25:31.260\nAnd that is again over SSL and\nthat is port,\n\n477\n00:25:31.260 --> 00:25:34.954\nI think I might have that port wrong,\nlet me check on that.\n\n478\n00:25:34.954 --> 00:25:35.475\nI said port 465.\n\n479\n00:25:35.475 --> 00:25:38.792\n&gt;&gt; No worries and then it's important\nto know, I had students who'd asked me,\n\n480\n00:25:38.792 --> 00:25:41.969\nthey said, why are there two port\nnumbers for the same exact technology?\n\n481\n00:25:41.969 --> 00:25:45.250\nAnd it is doing the same function?\n\n482\n00:25:45.250 --> 00:25:47.720\nHowever, like you had said,\nit's not providing that encryption.\n\n483\n00:25:47.720 --> 00:25:50.370\nSo if you receive a question, or\n\n484\n00:25:50.370 --> 00:25:55.270\nyou have a situation in life where you\nneed to suggest a secure alternative.\n\n485\n00:25:55.270 --> 00:25:57.889\nKnowing these different port numbers\nis really gonna come in handy.\n\n486\n00:25:57.889 --> 00:26:01.654\n&gt;&gt; And I just wanted to make sure I had\nit right because you see things like port\n\n487\n00:26:01.654 --> 00:26:04.098\n993, port 995, port, wait, 465?\n\n488\n00:26:04.098 --> 00:26:06.900\nBut it is port 465, so\ndo keep that in mind.\n\n489\n00:26:06.900 --> 00:26:10.666\nThat that's the way we can secure,\nanother way, if you will,\n\n490\n00:26:10.666 --> 00:26:12.241\nthat we can secure email.\n\n491\n00:26:12.241 --> 00:26:15.214\nAll right, so some of the last\nthings we've talked about,\n\n492\n00:26:15.214 --> 00:26:19.560\ntime synchronization's one thing that\nI didn't mention and I wanna mention.\n\n493\n00:26:19.560 --> 00:26:23.140\nAny time you're using encryption\ntechnologies that have time\n\n494\n00:26:23.140 --> 00:26:23.880\nstamping in it.\n\n495\n00:26:23.880 --> 00:26:27.400\nTime synchronization is important for\nall of your networks, right.\n\n496\n00:26:27.400 --> 00:26:33.080\nAs simple as using NTP, right, the network\ntime protocol, that is important.\n\n497\n00:26:33.080 --> 00:26:37.630\nWe talked about securing your directory\nservices, there's secure LDAP.\n\n498\n00:26:37.630 --> 00:26:41.032\nFile transfer through secure FTP.\n\n499\n00:26:41.032 --> 00:26:43.838\nWhen it comes to routing and switching,\nkeep in mind that when it comes to\n\n500\n00:26:43.838 --> 00:26:46.644\nrouting and switching, a lot of these\nprotocols are going to help secure\n\n501\n00:26:46.644 --> 00:26:48.940\nthe communications that\nare traversing your networks.\n\n502\n00:26:48.940 --> 00:26:51.790\nSubscription services they mentioned too.\n\n503\n00:26:51.790 --> 00:26:56.137\nThink about this, one of the reasons we\nwant to use HTTPS is because we're sending\n\n504\n00:26:56.137 --> 00:26:59.670\nvaluable information between\nthe client and the server.\n\n505\n00:26:59.670 --> 00:27:02.440\nAnd it could be something like\nsubscription based services that we want\n\n506\n00:27:02.440 --> 00:27:05.040\nto keep people from eavesdropping on.\n\n507\n00:27:05.040 --> 00:27:07.430\nAll right,\nI think we've got all of them there.\n\n508\n00:27:07.430 --> 00:27:10.678\nI don't really have anything else, but\njust keep in mind know which of those\n\n509\n00:27:10.678 --> 00:27:13.340\nprotocols are secure,\nknow where you would implement them.\n\n510\n00:27:13.340 --> 00:27:16.070\nAnd why you would want to\nimplement them as well.\n\n511\n00:27:16.070 --> 00:27:18.580\n&gt;&gt; Sounds great, that's a lot of new\ninformation that we can add to our\n\n512\n00:27:18.580 --> 00:27:20.490\nsecurity repertoire there.\n\n513\n00:27:20.490 --> 00:27:24.520\nBut for this show, we are about out of\ntime, so we'll go ahead and sign out.\n\n514\n00:27:24.520 --> 00:27:26.180\nRemember, I'm your host Cherokee Boose.\n\n515\n00:27:26.180 --> 00:27:27.060\n&gt;&gt; And I'm Wes Bryan.\n\n516\n00:27:27.060 --> 00:27:30.022\n&gt;&gt; See you next time here at ITProTV.\n\n517\n00:27:30.022 --> 00:27:36.097\n[MUSIC]\n\n518\n00:27:36.097 --> 00:27:39.213\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213515630"
        }
      ],
      "title": "Technologies and Tools"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Daniel and Wes explore common best practices and security configuration guides covered in the Security+ exam. Here they look into industry standard frameworks to secure specialized environments, defense-in-depth guides, and user training. All these are used to make the securing of a networked system easier and consistent.",
          "length": "1853",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-1-best_practices_and_secure_config_guids-050217-PGM.00_31_38_15.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-1-best_practices_and_secure_config_guids-050217-PGM.00_31_38_15.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-1-best_practices_and_secure_config_guids-050217-PGM.00_31_38_15.Still001-sm.jpg",
          "title": "Best Practices and Secure Config Guides",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:05.949\nWelcome to ITPRO TV,\nI'm you host [CROSSTALK]\n\n2\n00:00:05.949 --> 00:00:08.523\n[MUSIC]\n\n3\n00:00:08.523 --> 00:00:12.175\n&gt;&gt; You're watching ITPRO TV.\n\n4\n00:00:12.175 --> 00:00:13.968\n&gt;&gt; All right, greetings everyone and\n\n5\n00:00:13.968 --> 00:00:17.050\nwelcome to another exciting\nepisode of ITPRO TV.\n\n6\n00:00:17.050 --> 00:00:19.700\nI'm your host Daniel Lowrie and\nin today's episode, well,\n\n7\n00:00:19.700 --> 00:00:23.940\nwe're going along with more on that\ngood old security plus strain and\n\n8\n00:00:23.940 --> 00:00:27.280\njoining us the conductor of it\nour good friend Mr. Wes Bryan.\n\n9\n00:00:27.280 --> 00:00:28.540\nWes, welcome back now, how is it going?\n\n10\n00:00:28.540 --> 00:00:29.630\n&gt;&gt; It's going great, man.\n\n11\n00:00:29.630 --> 00:00:31.780\nLookout, yes we are on a journey.\n\n12\n00:00:31.780 --> 00:00:34.240\nLike I've said before, hopefully\nthat journey leads to clarity and\n\n13\n00:00:34.240 --> 00:00:34.930\nunderstanding.\n\n14\n00:00:34.930 --> 00:00:38.420\nAnd we are gonna be talking\nabout some of the things today.\n\n15\n00:00:38.420 --> 00:00:40.365\nAren't maybe so fun, right?\n\n16\n00:00:40.365 --> 00:00:41.900\n&gt;&gt; [LAUGH]\n&gt;&gt; We think about security, right?\n\n17\n00:00:41.900 --> 00:00:46.610\nWe think about, what are the threats\nthat are out there, vulnerabilities,\n\n18\n00:00:46.610 --> 00:00:47.970\npenetration testing, all right.\n\n19\n00:00:47.970 --> 00:00:50.010\nAll the fun stuff when\nyou think about security.\n\n20\n00:00:50.010 --> 00:00:53.355\nBut some of the things that we look at or\n\n21\n00:00:53.355 --> 00:00:57.145\nmaybe not so fun are things like\nirregulations, regulatory compliances,\n\n22\n00:00:57.145 --> 00:01:01.175\nthings like, for instance,\nconfiguration, secure configuration.\n\n23\n00:01:01.175 --> 00:01:04.680\nSo, we're gonna be talking about\nthings like best practices today and\n\n24\n00:01:04.680 --> 00:01:06.790\nsecure configuration guides.\n\n25\n00:01:06.790 --> 00:01:08.210\nAnd there are ton of amount there.\n\n26\n00:01:08.210 --> 00:01:12.640\nNow, I want to go ahead and prefers\nthis episode where the fact that you\n\n27\n00:01:12.640 --> 00:01:15.390\nguys have to know the individuals\nspecifics, right?\n\n28\n00:01:15.390 --> 00:01:19.300\nSo, we're gonna talk about like some\nthings some regulatory compliance for\n\n29\n00:01:19.300 --> 00:01:20.320\ndata, right?\n\n30\n00:01:20.320 --> 00:01:25.470\nI don't want you guys to hang up on\nthe individual policies if you will,\n\n31\n00:01:25.470 --> 00:01:29.540\njust understanding that they're out\nthere and why we would use them.\n\n32\n00:01:29.540 --> 00:01:34.212\nIf you are going on to higher levels of\nsecurity training, then some of these\n\n33\n00:01:34.212 --> 00:01:38.665\npolicies might be adequate for that,\nbut we just wanna kinda get you into\n\n34\n00:01:38.665 --> 00:01:43.212\nthe mindset of these different best\npractices in configuration guides.\n\n35\n00:01:43.212 --> 00:01:47.172\nSo very first, one of the things that they\ncall out are industry standard frameworks\n\n36\n00:01:47.172 --> 00:01:49.477\nlike, for instance, regulatory frameworks.\n\n37\n00:01:49.477 --> 00:01:53.162\nAnd we wanna kinda talk about why\nwould we even use something that's\n\n38\n00:01:53.162 --> 00:01:55.000\nregulatory, right?\n\n39\n00:01:55.000 --> 00:01:58.020\nWell, keep in mind that any time we talk\nabout a standard, or standardization,\n\n40\n00:01:58.020 --> 00:02:00.440\nwe try to have consistency, right?\n\n41\n00:02:00.440 --> 00:02:04.610\nSo that if one person is doing something,\nor a company, organization is doing\n\n42\n00:02:04.610 --> 00:02:09.320\nsomething that we do follow consistency,\nregardless of what the organization is.\n\n43\n00:02:09.320 --> 00:02:12.860\nBut when it comes to regulatory,\nthis is a mandatory or\n\n44\n00:02:12.860 --> 00:02:16.840\nit could be a legal requirement, or\nboth, a mandatory legal requirement.\n\n45\n00:02:16.840 --> 00:02:19.896\nAnd they can address all\ndifferent kinds of things, right?\n\n46\n00:02:19.896 --> 00:02:21.816\nWe have things like OSHA out there, right?\n\n47\n00:02:21.816 --> 00:02:24.652\nNow, OSHA is occupation Safety and\nhealth administration and\n\n48\n00:02:24.652 --> 00:02:27.230\nthey address things like\nhealth requirements, right?\n\n49\n00:02:27.230 --> 00:02:28.650\nProduct safety.\n\n50\n00:02:28.650 --> 00:02:31.670\nWe have other things like user and\noperational safety, so\n\n51\n00:02:31.670 --> 00:02:34.580\nit could be safety concerns\nthat we're worried about.\n\n52\n00:02:34.580 --> 00:02:37.380\nOn the other hand, it could be\nthings like financial processing,\n\n53\n00:02:37.380 --> 00:02:41.490\ndata processing compliance that we might\nhave to adhere to if we're working for\n\n54\n00:02:41.490 --> 00:02:45.510\na banking institution or\nif we're taking payments, right?\n\n55\n00:02:45.510 --> 00:02:49.080\nIf we're handling people's\nfinancial information in some\n\n56\n00:02:49.080 --> 00:02:51.630\nkind of customers paying\nwith their credit cards.\n\n57\n00:02:51.630 --> 00:02:55.960\nWe have to make sure that those\ntransactions are secured.\n\n58\n00:02:55.960 --> 00:02:59.270\nWe also have things like for\ninstance privacy concerns.\n\n59\n00:02:59.270 --> 00:03:04.280\nPrivacy concerns are very important\npart we do potentially from day to day.\n\n60\n00:03:04.280 --> 00:03:07.790\nWe have things like heavy appliance\nthat we have to understand.\n\n61\n00:03:07.790 --> 00:03:10.890\nWe have to make sure\nthat's the industry or\n\n62\n00:03:10.890 --> 00:03:14.290\nthat's our business model that\nwe are complying to those.\n\n63\n00:03:14.290 --> 00:03:17.390\nWe have other things for\nservice providers and service providing.\n\n64\n00:03:17.390 --> 00:03:20.930\nWe have things like SLA's that we\ntalk about service level agreements.\n\n65\n00:03:20.930 --> 00:03:24.370\nAnd these could be on\nseveral different levels.\n\n66\n00:03:24.370 --> 00:03:28.480\nAnybody who has dealt\nwith any kind of state,\n\n67\n00:03:28.480 --> 00:03:31.580\nlocal, federal regulations\nunderstand what we're talking about.\n\n68\n00:03:31.580 --> 00:03:35.640\nBut again, could also be international and\nforeign regulations too,\n\n69\n00:03:35.640 --> 00:03:38.980\nbecause if you have an international\ncompany, or a company in two different\n\n70\n00:03:38.980 --> 00:03:42.160\ncountries you have to understand that\nthere are different standards and\n\n71\n00:03:42.160 --> 00:03:44.570\norganizations and maybe,\nwhat you follow here in the States,\n\n72\n00:03:44.570 --> 00:03:47.520\nthat’s where we are and we have\nviewers that are all over the world.\n\n73\n00:03:47.520 --> 00:03:50.080\nSo, let’s say you are in New Zealand or\nAustralia,\n\n74\n00:03:50.080 --> 00:03:53.910\nmaybe you’re in the UK you have compliance\nthat you have to understand there too.\n\n75\n00:03:53.910 --> 00:03:57.520\nSo, that's a little bit what we're\ngonna talk about in this episode and\n\n76\n00:03:57.520 --> 00:04:02.350\none of the reasons we really have to know\na little bit about regulatory standards.\n\n77\n00:04:02.350 --> 00:04:05.400\nNow, let me give you an example of\nsome regulatory standards that we\n\n78\n00:04:05.400 --> 00:04:09.830\npotentially have to abide by\ninside of our organization.\n\n79\n00:04:09.830 --> 00:04:13.480\nSo for instance I got some regulatory\nstandards here on my desktop here.\n\n80\n00:04:13.480 --> 00:04:15.630\nWe've got what is Sox.\n\n81\n00:04:15.630 --> 00:04:17.600\nSox compliance to Sarbanes-Oxley.\n\n82\n00:04:17.600 --> 00:04:20.870\nNow, this is one that is a security\nrequirement, if you will,\n\n83\n00:04:20.870 --> 00:04:25.170\nfor things like application and\nfinancial processing.\n\n84\n00:04:25.170 --> 00:04:27.850\nAny kind of financial\nprocessing that you're doing.\n\n85\n00:04:27.850 --> 00:04:31.060\nAccess management,\nhow do you access that information, right?\n\n86\n00:04:31.060 --> 00:04:33.660\nAnd just the general controls, in general.\n\n87\n00:04:33.660 --> 00:04:38.580\nI do want you to keep in mind that don't\nworry about the individual specifications,\n\n88\n00:04:38.580 --> 00:04:40.980\nbut just to understand\nthat they are out there.\n\n89\n00:04:40.980 --> 00:04:46.010\nAnd as you enter the security world\nhere taking your security plus exam,\n\n90\n00:04:46.010 --> 00:04:47.220\nyou might have to be more and\n\n91\n00:04:47.220 --> 00:04:52.155\nmore aware of these as you progress\nthe security hierarchy, if you will.\n\n92\n00:04:52.155 --> 00:04:53.535\nOther things that we have,\nwe talked about,\n\n93\n00:04:53.535 --> 00:04:55.605\nyou know, payment card processing, right?\n\n94\n00:04:55.605 --> 00:04:57.565\nFinancial information that\nyou might be processing.\n\n95\n00:04:57.565 --> 00:05:00.705\nWe have things like payment card\nindustry data security standard.\n\n96\n00:05:00.705 --> 00:05:02.780\nIt's another one that's out there too.\n\n97\n00:05:02.780 --> 00:05:06.320\nRight, it protects the security of\nwhoever the credit card holder is, and\n\n98\n00:05:06.320 --> 00:05:10.700\nit's made up of different levels,\nit's a multi-level type of hierarchy, and\n\n99\n00:05:10.700 --> 00:05:15.050\nit enforces standards,\nbased on whatever that level might be.\n\n100\n00:05:15.050 --> 00:05:17.720\nWe've gotta mention,\nI briefly mentioned HIPPA, right?\n\n101\n00:05:17.720 --> 00:05:20.500\nHIPPA compliance is a major thing\nthat we have to worry about,\n\n102\n00:05:20.500 --> 00:05:23.970\nthe health insurance It's portability and\naccountability act.\n\n103\n00:05:23.970 --> 00:05:27.440\nIt safeguards things like\nyour medical information.\n\n104\n00:05:27.440 --> 00:05:30.250\nI have to understand that if I\nhave sensitive medical records we\n\n105\n00:05:30.250 --> 00:05:33.710\nhave to understand how do we\nretain that information and\n\n106\n00:05:33.710 --> 00:05:37.610\ndo we ensure that it's not\ndisclosed to unauthorized users.\n\n107\n00:05:37.610 --> 00:05:40.660\nSo, we have regulatory compliance for\nthings like that.\n\n108\n00:05:40.660 --> 00:05:43.530\nAnother one that's out there is the COBIT,\nCOBIT.\n\n109\n00:05:43.530 --> 00:05:48.190\nNow, as good as I am on acronyms,\nthis one is one that always slips me.\n\n110\n00:05:48.190 --> 00:05:51.970\nWhen it comes to COBIT,\nit is the Control Objectives for\n\n111\n00:05:51.970 --> 00:05:55.130\nInformation and Related Technology.\n\n112\n00:05:55.130 --> 00:05:56.780\nDon't try to say that ten times,\nthat's right.\n\n113\n00:05:56.780 --> 00:06:01.860\n[LAUGH] And again, this is a framework\nthat was developed in the 90s, and\n\n114\n00:06:01.860 --> 00:06:05.570\nit is one that kind of assists\n\n115\n00:06:05.570 --> 00:06:09.700\nthe socks compliance service it's how\nwe get it to compliance with that.\n\n116\n00:06:09.700 --> 00:06:13.970\nThere is other ones out too like the ISO\n2700 suite, will take a little bit more\n\n117\n00:06:13.970 --> 00:06:20.030\nabout ISO coming up and again, it's one\nof those for information technology.\n\n118\n00:06:20.030 --> 00:06:23.490\nNow, keep in mind that when we talk about\nthings like regulatory compliance again,\n\n119\n00:06:23.490 --> 00:06:26.330\nthese are mandated by law.\n\n120\n00:06:26.330 --> 00:06:27.320\nIf you think about it,\n\n121\n00:06:27.320 --> 00:06:31.660\nwe have many things int he past\nthat have caused problems, right?\n\n122\n00:06:31.660 --> 00:06:36.550\nI think if things like the ENRONs I am\nout there and stuff where people were\n\n123\n00:06:36.550 --> 00:06:41.640\nreally taken taken by surprise by that and\nthat's why she know you can see that a lot\n\n124\n00:06:41.640 --> 00:06:45.730\nof these different standards are where\nthey're at and why they're put in place.\n\n125\n00:06:45.730 --> 00:06:49.620\n&gt;&gt; So, this is all about not reinventing\nthe wheel right we trying to figure out\n\n126\n00:06:49.620 --> 00:06:53.830\nthe mistakes of the past, so\nthat we can better guide the future into\n\n127\n00:06:53.830 --> 00:06:58.940\ndoing something more securely and\nwith better accuracy and consistency.\n\n128\n00:06:58.940 --> 00:06:59.820\n&gt;&gt; Definatley.\n\n129\n00:06:59.820 --> 00:07:02.860\nYou know they also call out things\nlike for instance non regulatory and\n\n130\n00:07:02.860 --> 00:07:06.320\nit's kind of interesting cuz we us this\nI've used this a lot in Security Plus, and\n\n131\n00:07:06.320 --> 00:07:08.830\nI know Dan you've been involved\nin some security episodes and\n\n132\n00:07:08.830 --> 00:07:10.470\nshows that we've done around here.\n\n133\n00:07:10.470 --> 00:07:12.492\nBut another one,\nthey call out non-regulatory.\n\n134\n00:07:12.492 --> 00:07:16.789\nWell, non-regulatory is things like NIST,\nthe National Institute for\n\n135\n00:07:16.789 --> 00:07:18.462\nStandards and Technology.\n\n136\n00:07:18.462 --> 00:07:23.608\nIt's non-regulatory, however if I I was\nto, let me go ahead and show you guys,\n\n137\n00:07:23.608 --> 00:07:28.678\nif I was to jump down here, and if you've\nnever been to NIST, NIST is one of those\n\n138\n00:07:28.678 --> 00:07:33.554\norganizations that if for\ninstances I did like a NIST 800-53 series.\n\n139\n00:07:33.554 --> 00:07:34.470\nAnd when you look,\n\n140\n00:07:34.470 --> 00:07:38.082\nit talks about things like for\ninstance publication that recommends, and\n\n141\n00:07:38.082 --> 00:07:42.240\nthat's the difference between\na non-regulatory, and a regulatory body.\n\n142\n00:07:42.240 --> 00:07:43.810\nThey're recommending something.\n\n143\n00:07:43.810 --> 00:07:46.994\nIf it's regulatory, it isn't\na recommendation, it's not a option-\n\n144\n00:07:46.994 --> 00:07:48.512\n&gt;&gt; Right do this command.\n\n145\n00:07:48.512 --> 00:07:49.540\n&gt;&gt; That's exactly right.\n\n146\n00:07:49.540 --> 00:07:51.240\nYou will do it this way.\n\n147\n00:07:51.240 --> 00:07:54.561\nSo, again, it's just one of those\nones that again recommends.\n\n148\n00:07:54.561 --> 00:07:57.402\nAnd this is one of their standards,\ntheir publications here for\n\n149\n00:07:57.402 --> 00:07:59.940\nfederal information systems and\norganizations right?\n\n150\n00:07:59.940 --> 00:08:00.983\nYou can read the information.\n\n151\n00:08:00.983 --> 00:08:02.942\nSo like, FIPS compliance, right,\n\n152\n00:08:02.942 --> 00:08:06.229\nthe Federal Information\nProcessing Standards Act, again,\n\n153\n00:08:06.229 --> 00:08:09.215\nthis is the way we would come\ninto compliance with this.\n\n154\n00:08:09.215 --> 00:08:15.504\nEven though it's a non-regulatory body,\nit is helping us, assist us if you will,\n\n155\n00:08:15.504 --> 00:08:21.280\nand then guide us into compliance with\nother standards that are regulatory.\n\n156\n00:08:22.380 --> 00:08:23.010\nAll right, so\n\n157\n00:08:23.010 --> 00:08:26.040\nwe've got other bodies out there that\nwe have to keep in mind too, right.\n\n158\n00:08:26.040 --> 00:08:28.760\nSome of the things that they call out,\nthey call out things like for\n\n159\n00:08:28.760 --> 00:08:32.130\ninstance national bodies and\ninternational bodies, right.\n\n160\n00:08:32.130 --> 00:08:36.640\nAnd there are many different types of\nthese, in fact we talk about them in A+,\n\n161\n00:08:36.640 --> 00:08:38.730\nwe talk about them in Net+, and well,\n\n162\n00:08:38.730 --> 00:08:40.544\nwe're gonna talk about them\na little bit in Security+.\n\n163\n00:08:40.544 --> 00:08:44.988\nSo let me go and show you what I mean\nwhen I say national and international,\n\n164\n00:08:44.988 --> 00:08:48.654\nthere is a whole list of national and\ninternational bodies.\n\n165\n00:08:48.654 --> 00:08:53.341\nAnd again, I don't want you to get\ntripped up on the minutias, the detail,\n\n166\n00:08:53.341 --> 00:08:55.990\njust understand that they're out there.\n\n167\n00:08:55.990 --> 00:09:00.500\nFor instance, a national standards\nbody that we have right now,\n\n168\n00:09:00.500 --> 00:09:04.360\nright at the top of the list, ANSI, that's\nthe American National Standards Institute.\n\n169\n00:09:04.360 --> 00:09:09.690\nWhen we look at things like ANSI,\nright, ANSI is here in the States,\n\n170\n00:09:09.690 --> 00:09:14.620\nbut they do promote internationally,\nso we do have to keep that in mind.\n\n171\n00:09:14.620 --> 00:09:18.830\nYou also have things like NERC,\nNERC is the North American Electrical and\n\n172\n00:09:18.830 --> 00:09:23.080\nReliability Corporation, that's one\nhere that's in the North America, right,\n\n173\n00:09:23.080 --> 00:09:26.380\nit's more national, if you will,\nhere to the United States.\n\n174\n00:09:26.380 --> 00:09:30.260\nBut again, some of these bodies\nkinda cross lines, right, and\n\n175\n00:09:30.260 --> 00:09:33.920\nthey're also on some of these\ninternational standards, as well.\n\n176\n00:09:33.920 --> 00:09:37.384\nYou also have for\ninstance the British Standards Institute,\n\n177\n00:09:37.384 --> 00:09:41.445\nthis is another one and they're part\nof an international body as well but\n\n178\n00:09:41.445 --> 00:09:45.322\nthey promote their specifications,\nif you will, inside of the UK.\n\n179\n00:09:45.322 --> 00:09:49.970\nThere's also BEC, maybe you've even seen\nsome of these documentations where they\n\n180\n00:09:49.970 --> 00:09:52.325\nsay something like ISO forward slash BEC,\n\n181\n00:09:52.325 --> 00:09:55.560\nagain that's\nthe British Electrotechnical Committee.\n\n182\n00:09:55.560 --> 00:09:58.990\nThey're another one that's national\nto the UK, if you will, but\n\n183\n00:09:58.990 --> 00:10:03.580\nalso kinda crossing the borders and\npromoting international standards too.\n\n184\n00:10:03.580 --> 00:10:06.540\nThen we got some of the big guys,\nright, the big guys, the ISO, and\n\n185\n00:10:06.540 --> 00:10:08.230\nI always think this is funny and\nI always have,\n\n186\n00:10:08.230 --> 00:10:11.420\nis that the ISO is the International\nOrganization for Standardization.\n\n187\n00:10:11.420 --> 00:10:13.190\nSo it almost seems like even\nthough they're good at standards,\n\n188\n00:10:13.190 --> 00:10:14.414\nthey can't standardize their name right.\n\n189\n00:10:14.414 --> 00:10:15.582\n&gt;&gt; Yeah, yeah.\n\n190\n00:10:15.582 --> 00:10:16.523\n&gt;&gt; How do they get that acronym,\nright, it's a little wrong.\n\n191\n00:10:16.523 --> 00:10:17.857\n&gt;&gt; A little confusing.\n\n192\n00:10:17.857 --> 00:10:21.538\n[LAUGH]\n&gt;&gt; That's right, it is, and that's because\n\n193\n00:10:21.538 --> 00:10:26.974\ntheir name is actually a form of something\ncalled isos, which it just means equal,\n\n194\n00:10:26.974 --> 00:10:31.810\nright, I-S-O-S, I believe is how\nyou spell that, so it means equal.\n\n195\n00:10:31.810 --> 00:10:37.557\nBut again, this is pretty much the largest\ninternational standards body in the world,\n\n196\n00:10:37.557 --> 00:10:41.530\nright, it's made up of like\n127 different committees.\n\n197\n00:10:41.530 --> 00:10:45.946\nAnd some of the committees that you see in\nthis list that are national committees,\n\n198\n00:10:45.946 --> 00:10:47.810\nthey also stand as part of the ISO.\n\n199\n00:10:49.490 --> 00:10:52.000\nWhat are some of the other\nones we have here too?\n\n200\n00:10:52.000 --> 00:10:54.450\nWell, so for instance,\nwe've got the ITU up there,\n\n201\n00:10:54.450 --> 00:10:58.140\nthat's the International\nTelecommunications Union, as you can see\n\n202\n00:10:58.140 --> 00:11:02.980\nthat is an International standards body\npromoting things like communication,\n\n203\n00:11:02.980 --> 00:11:07.120\nstandards in communication,\ntechnology information as well.\n\n204\n00:11:08.330 --> 00:11:13.120\nLast one on the list that I got here for\nan example is CEPT, if you will, or\n\n205\n00:11:13.120 --> 00:11:15.510\nCEPT I guess you could say, C-E-P-T.\n\n206\n00:11:15.510 --> 00:11:18.150\nAnd that's the Conference of Postal and\n\n207\n00:11:18.150 --> 00:11:22.330\nTelecommunications, don't confuse\nthat name, the name is actually,\n\n208\n00:11:24.320 --> 00:11:29.270\nthe acronym I should say,\ncomes from the French version of its name.\n\n209\n00:11:29.270 --> 00:11:34.040\nAll right, so this gives you an example of\nsome of the governing bodies that you can\n\n210\n00:11:34.040 --> 00:11:37.370\nsee out there, and the difference between\nnational and international standards.\n\n211\n00:11:37.370 --> 00:11:39.158\nAnd really a lot of times today, guys,\n\n212\n00:11:39.158 --> 00:11:43.220\nwhat we're seeing is a crossing of\nthe streams, right, a blending of the two.\n\n213\n00:11:43.220 --> 00:11:47.550\nSo even though, like I said, the American\nNational Standards Institute is here in\n\n214\n00:11:47.550 --> 00:11:52.850\nthe United States they do promote their\nstandards on an international basis.\n\n215\n00:11:52.850 --> 00:11:56.390\nAnd that's just because, if you think\nabout it when we talk about networking,\n\n216\n00:11:56.390 --> 00:11:57.730\nwhen we talk about technology,\n\n217\n00:11:57.730 --> 00:12:02.580\nwhen we talk about security, this\nreally isn't just a small niche market\n\n218\n00:12:02.580 --> 00:12:08.290\nthat is just isolated to a single\ngeographical location, it's worldwide.\n\n219\n00:12:08.290 --> 00:12:10.338\nSo we do have to keep that in mind,\n\n220\n00:12:10.338 --> 00:12:15.460\nthat while we might be following some of\nthese standards here in the United States,\n\n221\n00:12:15.460 --> 00:12:20.291\nif we are an international organization or\nmultinational organization it's\n\n222\n00:12:20.291 --> 00:12:25.120\nnot always that those standards are gonna\nbe the ones that we follow when data or\n\n223\n00:12:25.120 --> 00:12:29.323\nour interests lie on foreign soil so\nwe have to keep that in mind too.\n\n224\n00:12:29.323 --> 00:12:35.171\nAll right, so those are some of the,\nif you will, the different types\n\n225\n00:12:35.171 --> 00:12:41.960\nof standards bodies when it comes\nto national versus international.\n\n226\n00:12:41.960 --> 00:12:47.010\nNow we also have industry specific\nframeworks, right, and some of\n\n227\n00:12:47.010 --> 00:12:51.610\nthe standards that we've already mentioned\nalso go to industry specific as well.\n\n228\n00:12:51.610 --> 00:12:56.300\nSo for instance,\nthings like your PCI DSS information,\n\n229\n00:12:56.300 --> 00:13:00.420\nif it's a banking, right, you might\nhave an industry standard framework for\n\n230\n00:13:00.420 --> 00:13:05.400\nthings like banking, and financial,\nand insurance firms, if you will.\n\n231\n00:13:05.400 --> 00:13:08.967\nYou might have, for instance,\nit might be data processing and\n\n232\n00:13:08.967 --> 00:13:10.726\nthe services surrounding it.\n\n233\n00:13:10.726 --> 00:13:14.303\nCould be things like, for instance,\nhealthcare, right, healthcare is\n\n234\n00:13:14.303 --> 00:13:18.700\nwhere things like HIPAA come into play,\nright, how do we handle that information?\n\n235\n00:13:18.700 --> 00:13:23.870\nThat is an industry specific framework\nspecifically for things like PHI,\n\n236\n00:13:23.870 --> 00:13:28.127\nyour private or\npersonal healthcare information.\n\n237\n00:13:29.280 --> 00:13:34.280\nWe also have industry specific frameworks\nfor things like telecommunications, right,\n\n238\n00:13:34.280 --> 00:13:37.760\nwe talk about telecommunication\nstandards out there as well.\n\n239\n00:13:37.760 --> 00:13:38.770\nThings like you've got,\n\n240\n00:13:38.770 --> 00:13:43.610\nwell ISO is one of them, the Internet\nEngineering Task Force is another.\n\n241\n00:13:43.610 --> 00:13:47.576\nAnd in fact,\nyou can find a lot of these sites just,\n\n242\n00:13:47.576 --> 00:13:50.920\na lot of these companies online,\njust by doing a simple Google search.\n\n243\n00:13:50.920 --> 00:13:53.840\nLet me give you an example of some,\nrather than just talk about them here.\n\n244\n00:13:53.840 --> 00:13:57.616\nI've got for instance the American\nNational Standards Institute is pulled\n\n245\n00:13:57.616 --> 00:14:01.333\nup here, and you can always view their\nwebsite if you wanna find a little bit\n\n246\n00:14:01.333 --> 00:14:04.418\nmore information about them,\nand again, www.ansi.org.\n\n247\n00:14:04.418 --> 00:14:08.960\nRight, we have for instance, I mentioned\nthe British Standards Institute for\n\n248\n00:14:08.960 --> 00:14:13.294\nthe UK, right, this has actually been,\nas you can see it's been around for\n\n249\n00:14:13.294 --> 00:14:14.365\na very long time.\n\n250\n00:14:14.365 --> 00:14:17.204\n[LAUGH] Even before some of\nthe first computers were invented it\n\n251\n00:14:17.204 --> 00:14:18.301\nwas out there, right.\n\n252\n00:14:18.301 --> 00:14:23.136\nSo it goes all the way back to 1901 and\nyou can see promoting trade, right, and\n\n253\n00:14:23.136 --> 00:14:26.952\nagain talking about by developing\ncommon industry standards.\n\n254\n00:14:26.952 --> 00:14:31.077\nAll right, we have the International\nTelecommunications Union, again,\n\n255\n00:14:31.077 --> 00:14:33.532\ncommitted to connecting the world, right.\n\n256\n00:14:33.532 --> 00:14:38.516\nSo it's not just here in the United\nStates, it's not just in the UK if you\n\n257\n00:14:38.516 --> 00:14:44.238\nwill, or over in Europe, it really isn't\njust tied to any one specific location,\n\n258\n00:14:44.238 --> 00:14:49.065\nbut it is again promoting these\nindustry specific frameworks like for\n\n259\n00:14:49.065 --> 00:14:51.430\ninstance telecommunications.\n\n260\n00:14:51.430 --> 00:14:55.390\nOther ones out there that we've talked\nabout the European Conference of Postal\n\n261\n00:14:55.390 --> 00:14:59.730\nand Telecommunications Administrations,\nagain, the CEPT, this is one, again,\n\n262\n00:14:59.730 --> 00:15:00.670\nthat's out there.\n\n263\n00:15:00.670 --> 00:15:05.000\nAnd then I also mentioned things like, for\ninstance, the International Organization\n\n264\n00:15:05.000 --> 00:15:09.280\nfor Standardization, big company,\nbig organization if you will.\n\n265\n00:15:09.280 --> 00:15:14.240\nLike I said, I believe it's 127 different\ncountries, 26 different countries,\n\n266\n00:15:14.240 --> 00:15:16.658\ndon't quote me on that, but\na very large organization.\n\n267\n00:15:16.658 --> 00:15:19.890\nWhen you talk about also\ntelecommunication standards, right,\n\n268\n00:15:19.890 --> 00:15:23.414\nwe talk about things like\nthe Internet Engineering Task Force, IETF,\n\n269\n00:15:23.414 --> 00:15:25.424\nbeen around for a very long time in fact.\n\n270\n00:15:25.424 --> 00:15:29.104\nIf you've ever heard of an RFC,\na request for comment,\n\n271\n00:15:29.104 --> 00:15:34.038\nright, the request for comments,\nthey have a lot of RFCs specifically for\n\n272\n00:15:34.038 --> 00:15:37.580\nthings like your encryption protocols,\nright.\n\n273\n00:15:37.580 --> 00:15:40.075\nIf an encryption protocol is\ngonna be standardized and\n\n274\n00:15:40.075 --> 00:15:43.980\nis gonna be used inside of your companies,\nchances are there's gonna be a request for\n\n275\n00:15:43.980 --> 00:15:46.547\ncomments on it that explains\nwhat it's doing, right.\n\n276\n00:15:46.547 --> 00:15:52.367\nSo also know things like the Internet\nEngineering Task Force, all right.\n\n277\n00:15:52.367 --> 00:15:57.625\nSo those are some of the crazy different\nstandards that we have out there and\n\n278\n00:15:57.625 --> 00:16:00.305\nsome of the bodies that oversee them.\n\n279\n00:16:00.305 --> 00:16:01.578\nBut we also have other things too.\n\n280\n00:16:01.578 --> 00:16:06.330\nWe have for instance we have vendor\nspecific documentation, right?\n\n281\n00:16:06.330 --> 00:16:09.030\nAnd why might we go with\nvendor specific documentation?\n\n282\n00:16:09.030 --> 00:16:13.545\nWell typically if you're gonna\nimplement a product right,\n\n283\n00:16:13.545 --> 00:16:17.295\nthe vendor knows exactly what she\nshould be doing to secure it, right?\n\n284\n00:16:17.295 --> 00:16:21.435\nAnd that is important that if you need\nthat information, you need that security,\n\n285\n00:16:21.435 --> 00:16:24.325\nyou need to harden a server or a product\nthat you're going to implement in\n\n286\n00:16:24.325 --> 00:16:27.515\nyour networks that you go to\nthe people who invented it.\n\n287\n00:16:27.515 --> 00:16:30.865\nThe people who have the knowledge and\nthe know how and\n\n288\n00:16:30.865 --> 00:16:32.485\ncan give you some of those best practices.\n\n289\n00:16:32.485 --> 00:16:34.635\nSo for\ninstance they call a few different types.\n\n290\n00:16:36.730 --> 00:16:38.377\nVendor specific guy is right for\n\n291\n00:16:38.377 --> 00:16:41.978\ninstance web servers,operating\nsystems,application servers and\n\n292\n00:16:41.978 --> 00:16:46.015\nnetworking devices, right, so if it\nhappens to be for instance a web server.\n\n293\n00:16:46.015 --> 00:16:48.965\nNow I know that web servers,\nright, typically out there on\n\n294\n00:16:48.965 --> 00:16:52.510\nthe backbone of the Internet are usually\ngonna be like Apache, right?\n\n295\n00:16:52.510 --> 00:16:55.640\nApache, I believe, is one of the most\ncommon web servers out there.\n\n296\n00:16:55.640 --> 00:17:00.540\nAnd if I need to learn how to maybe\nsecure HTTPD, I can go out to Red Hat.\n\n297\n00:17:00.540 --> 00:17:04.350\nRed Hat has a lot of documentation,\nright, for\n\n298\n00:17:04.350 --> 00:17:08.750\nyou secure one of your web servers.\n\n299\n00:17:08.750 --> 00:17:10.290\nBut you also have things like for\ninstance,\n\n300\n00:17:10.290 --> 00:17:14.420\nI got the best security best practices,\nguide pulled up here for IIS, right?\n\n301\n00:17:14.420 --> 00:17:17.830\nInternet information services,\nMicrosoft web servers, right?\n\n302\n00:17:17.830 --> 00:17:22.840\nAnd if I need to know some of the best\npractices in what we need to do, again,\n\n303\n00:17:22.840 --> 00:17:26.430\nif it's a web application, so\nmaybe it's not only a web server,\n\n304\n00:17:26.430 --> 00:17:28.390\nmaybe it's a hosting web application,\nright?\n\n305\n00:17:28.390 --> 00:17:31.450\nWe've talked about some of the things\nthat you're gonna do to secure your web\n\n306\n00:17:31.450 --> 00:17:32.640\napplication servers, right?\n\n307\n00:17:32.640 --> 00:17:36.640\nDon't keep your database on that web\nservers especially if it's in a DMZ.\n\n308\n00:17:36.640 --> 00:17:40.390\nAnd these could be some of the things that\nyou could be implementing in order to\n\n309\n00:17:40.390 --> 00:17:41.980\nharden that server.\n\n310\n00:17:41.980 --> 00:17:43.140\nWe've got other ones out there too.\n\n311\n00:17:43.140 --> 00:17:45.790\nMaybe it's just basic operating\nsystem hardening, right?\n\n312\n00:17:45.790 --> 00:17:48.270\nYou're just doing, for\ninstance, server hardening.\n\n313\n00:17:48.270 --> 00:17:53.170\nWell, you have a lot of good,\ngood guides out there.\n\n314\n00:17:53.170 --> 00:17:57.430\nAnd they also tell you how to implement\nsomething called defense in depth,\n\n315\n00:17:57.430 --> 00:18:00.360\nwhich we're gonna look at here\nin this series in just a moment.\n\n316\n00:18:00.360 --> 00:18:06.880\nSo again, keep in mind that you do\nhave a vendor specific guides too.\n\n317\n00:18:06.880 --> 00:18:11.180\nSo for instance, I also call out\nthings like general purpose guides.\n\n318\n00:18:11.180 --> 00:18:14.030\nAnd again, general purpose guides\ncould be just configuration, right?\n\n319\n00:18:14.030 --> 00:18:17.150\nMaking sure that you're renaming defaults,\nright?\n\n320\n00:18:17.150 --> 00:18:19.390\nWe're not leaving defaults\nto where they are.\n\n321\n00:18:19.390 --> 00:18:22.840\nCould be more specific\nto your network devices.\n\n322\n00:18:22.840 --> 00:18:23.560\nWell, guess what?\n\n323\n00:18:23.560 --> 00:18:26.570\nCisco has got a lot of good documentation,\nright?\n\n324\n00:18:26.570 --> 00:18:27.770\nJuniper's another one.\n\n325\n00:18:27.770 --> 00:18:31.840\nThey're gonna have documentation too,\nbecause they know their devices,\n\n326\n00:18:31.840 --> 00:18:36.790\nthey know how they were initially meant\nto be deployed in various situations.\n\n327\n00:18:36.790 --> 00:18:41.190\nNow, keep in mind that when they\ntalk about these best practices and\n\n328\n00:18:41.190 --> 00:18:46.090\nsecurity configuration guides, it doesn't\nmean as one-size-fits-all, right?\n\n329\n00:18:46.090 --> 00:18:48.440\nAgain, best practice might\nbe your security baseline.\n\n330\n00:18:48.440 --> 00:18:51.270\nAnd then you might have to go a little bit\nfarther after you set your baseline, and\n\n331\n00:18:51.270 --> 00:18:54.670\npeaking and tweaking a server\nto fit a specific need, right?\n\n332\n00:18:54.670 --> 00:18:59.380\nMaybe you don't need data encryption on\nyour hard drives, maybe you do, right.\n\n333\n00:18:59.380 --> 00:19:02.070\nSo again, at least these give you a nice,\n\n334\n00:19:02.070 --> 00:19:06.640\ngood secure baseline to leapfrog off and\nthen you can tailor make whatever you need\n\n335\n00:19:06.640 --> 00:19:10.410\nto suit the needs within your\nenvironment you're supporting.\n\n336\n00:19:10.410 --> 00:19:13.020\n&gt;&gt; But the good news is these vendors,\nthey've been around a long time.\n\n337\n00:19:13.020 --> 00:19:16.310\nThey don't stay in business\nby allowing their [LAUGH]\n\n338\n00:19:16.310 --> 00:19:18.200\nequipment to be compromisable, right?\n\n339\n00:19:18.200 --> 00:19:23.290\nAnd they do everything that they can\nto try to mitigate that from happening.\n\n340\n00:19:23.290 --> 00:19:26.980\nCuz they want you to trust them as a\nvendor and continue to use their product.\n\n341\n00:19:26.980 --> 00:19:30.400\nSo, for them to put out these guides\nis very beneficial for them and for\n\n342\n00:19:30.400 --> 00:19:34.070\nyou keeps your system secure and keeps\nyou going back to them for more, right?\n\n343\n00:19:34.070 --> 00:19:35.080\n&gt;&gt; Yeah definitely right.\n\n344\n00:19:35.080 --> 00:19:38.160\nYou got to keep the gators that's\nright cuz they're gonna come back.\n\n345\n00:19:38.160 --> 00:19:41.140\nSo I did kinda mentioned\nDanny in passing here.\n\n346\n00:19:41.140 --> 00:19:43.740\nAnd it's kinda interesting because\nI wish I could have said I\n\n347\n00:19:43.740 --> 00:19:47.260\nplanned it that way but I didn't see the\nfirst sentence of that secure hardening\n\n348\n00:19:47.260 --> 00:19:49.040\nguide talked about defense and depth.\n\n349\n00:19:49.040 --> 00:19:51.920\nWell what a coincidence we have to\ntalk about defense and depth here so\n\n350\n00:19:51.920 --> 00:19:52.780\nit makes a good segue.\n\n351\n00:19:52.780 --> 00:19:55.750\nSo what are they talking about\nwhen they say defense and depth?\n\n352\n00:19:55.750 --> 00:19:59.280\nWell this actually, if I understand it\nright it started with the military and\n\n353\n00:19:59.280 --> 00:20:03.840\nit's been a secure layer defense\nsystem that a lot of industries have\n\n354\n00:20:03.840 --> 00:20:06.770\nfollowed because it works well for\nthe military, right?\n\n355\n00:20:06.770 --> 00:20:09.190\nSo, when we talk about defense in depth,\n\n356\n00:20:09.190 --> 00:20:15.280\nwe're not talking about a single security\nsolution, we walk over and lock a door.\n\n357\n00:20:15.280 --> 00:20:18.100\nOkay, that secures the building, but\nwhat about the network that's inside\n\n358\n00:20:18.100 --> 00:20:21.310\nthe building, what would that do for the\nnetwork and the data that's traversing it?\n\n359\n00:20:21.310 --> 00:20:23.850\nSo, we wanna apply a layered system.\n\n360\n00:20:23.850 --> 00:20:28.772\nAnd I got a little diagram up here, and\nyou can see that, in this layered model,\n\n361\n00:20:28.772 --> 00:20:32.391\nthere are seven different\nlayers of the defense in depth.\n\n362\n00:20:32.391 --> 00:20:35.793\nAnd you can see It starts\nfrom the outer ring here,\n\n363\n00:20:35.793 --> 00:20:39.150\nis policies procedures and\nawareness, right.\n\n364\n00:20:39.150 --> 00:20:42.060\nOne of the first good\nlines of defense is people\n\n365\n00:20:42.060 --> 00:20:47.020\nunderstanding what you need to defend,\nright, or what you need to defend from.\n\n366\n00:20:47.020 --> 00:20:51.470\nSo, security policies, acceptable use\npolicies, some of these regulatory\n\n367\n00:20:51.470 --> 00:20:54.090\ncompliance standards that we're talking\nabout might be something that's\n\n368\n00:20:54.090 --> 00:20:57.320\nincorporated into your policies that\nyou're making for your company.\n\n369\n00:20:57.320 --> 00:21:00.200\nAnd you have to be aware of them,\nyour users have to be aware of them.\n\n370\n00:21:00.200 --> 00:21:02.710\nI mean, when it comes to user training,\nit's usually a very,\n\n371\n00:21:02.710 --> 00:21:04.080\nvery redundant process.\n\n372\n00:21:04.080 --> 00:21:06.680\nBecause new things\nare coming out all the time.\n\n373\n00:21:06.680 --> 00:21:09.840\nAs you guys, I'm sure are aware,\ntechnology doesn't just stagnate,\n\n374\n00:21:09.840 --> 00:21:11.850\ndoesn't stay still.\n\n375\n00:21:11.850 --> 00:21:14.940\nYou jump on the bus and you follow it or\nyou're gonna get left behind.\n\n376\n00:21:14.940 --> 00:21:19.210\nSo that's why policies and\nawareness is an ongoing thing.\n\n377\n00:21:19.210 --> 00:21:21.010\nPhysical security, guys,\n\n378\n00:21:21.010 --> 00:21:24.720\nwe have an episode that's dedicated\nto physical security controls.\n\n379\n00:21:24.720 --> 00:21:27.830\nJust keep in mind in brief here,\n\n380\n00:21:27.830 --> 00:21:31.330\nthat we have to make sure that people\ndon't have access to our networks.\n\n381\n00:21:31.330 --> 00:21:34.850\nBecause if people have access to\nour networks, the other layers,\n\n382\n00:21:34.850 --> 00:21:37.440\njust throw them away,\nthey really don't matter at that point.\n\n383\n00:21:37.440 --> 00:21:41.780\nBecause if I can get into your building\nand I can get into your network,\n\n384\n00:21:41.780 --> 00:21:44.660\nI can get into your operating system,\nI can get into your server, or\n\n385\n00:21:44.660 --> 00:21:46.440\nyour application, guess what?\n\n386\n00:21:46.440 --> 00:21:48.050\nThey're no longer yours anymore.\n\n387\n00:21:48.050 --> 00:21:51.663\nAnd that's one of the ten mutable laws\nof secure that says that if I can\n\n388\n00:21:51.663 --> 00:21:55.355\ngain physical access to your network,\nit's no longer your network.\n\n389\n00:21:55.355 --> 00:21:58.950\nSo we have to make sure the physical\nsecurity through the things like locks,\n\n390\n00:21:58.950 --> 00:22:02.768\nif you will biometrics, cameras, and\nsome of the other stuff that we've talked\n\n391\n00:22:02.768 --> 00:22:07.110\nabout in previous episodes to make sure\nthe physical security is there as well.\n\n392\n00:22:07.110 --> 00:22:08.510\nWe also have things like\nperimeter security.\n\n393\n00:22:08.510 --> 00:22:11.160\nRight, when we look at\na perimeter security,\n\n394\n00:22:11.160 --> 00:22:13.168\nwe talk about things like border routers,\nright?\n\n395\n00:22:13.168 --> 00:22:16.900\nDMZs, right, demilitarized zones,\nscreen subnets, if you will,\n\n396\n00:22:16.900 --> 00:22:20.690\nperimeter networks are all things\nthat we need to implement.\n\n397\n00:22:20.690 --> 00:22:23.130\nThings like IPSS and IDSS, right.\n\n398\n00:22:23.130 --> 00:22:26.710\nIntrusion detection system, intrusion\nprevention systems that tried to stop\n\n399\n00:22:26.710 --> 00:22:30.790\nthings before they even make it\nto our internal network, right?\n\n400\n00:22:30.790 --> 00:22:32.600\nThat's where our network\nsecurity comes in.\n\n401\n00:22:32.600 --> 00:22:34.980\nWe implement things like\nnetwork access control,\n\n402\n00:22:34.980 --> 00:22:38.330\nnetwork based firewalls that\nare screening all information as\n\n403\n00:22:38.330 --> 00:22:42.555\nit goes past the DMZ into\nthe internal network, right?\n\n404\n00:22:42.555 --> 00:22:44.540\nAnti-malware gateways, right?\n\n405\n00:22:44.540 --> 00:22:46.750\nAgain, it's like a concentrator,\nif you will,\n\n406\n00:22:46.750 --> 00:22:49.760\nit's screening all traffic\nthat's coming into your network.\n\n407\n00:22:49.760 --> 00:22:51.250\nNetwork segmentation, right?\n\n408\n00:22:51.250 --> 00:22:53.070\nIt's one of the reasons\nwe separate networks.\n\n409\n00:22:53.070 --> 00:22:54.870\nWe do things like air gapping networks.\n\n410\n00:22:54.870 --> 00:22:59.580\nWe implement things like wireless\nsecurity, just to give you an example.\n\n411\n00:22:59.580 --> 00:23:01.230\nThen we have things like host security.\n\n412\n00:23:01.230 --> 00:23:02.690\nHost security is important as well.\n\n413\n00:23:02.690 --> 00:23:04.400\nAnd that's where things\nlike your OS hardening,\n\n414\n00:23:04.400 --> 00:23:09.190\nwhen they talk about operating system,\nvendor specific, secure, best practices.\n\n415\n00:23:09.190 --> 00:23:13.940\nGo to your website or go to your vendors,\nfind out what they recommend.\n\n416\n00:23:13.940 --> 00:23:18.320\nAgain, running things like host-based anti\nmalware systems, host-based firewalls like\n\n417\n00:23:18.320 --> 00:23:23.460\nthe Windows Firewall, was Iptables\nin Linux or in there, or Firewall D,\n\n418\n00:23:23.460 --> 00:23:28.500\nI think it's called today,\nhost-based intrusion prevention systems.\n\n419\n00:23:28.500 --> 00:23:31.410\nAnd how about things as simple as backups?\n\n420\n00:23:31.410 --> 00:23:33.080\nThat's apart of host security.\n\n421\n00:23:33.080 --> 00:23:35.420\nIt should be normal system maintenance,\nbut\n\n422\n00:23:35.420 --> 00:23:40.860\nit should be part of your layered\nsecurity inside of your networks.\n\n423\n00:23:40.860 --> 00:23:41.770\nWhat else do we got here, Dan?\n\n424\n00:23:41.770 --> 00:23:44.460\nWe've got application security, right?\n\n425\n00:23:44.460 --> 00:23:46.110\nWe talk about application security.\n\n426\n00:23:46.110 --> 00:23:48.141\nWe want things like\napplication layer firewalls.\n\n427\n00:23:48.141 --> 00:23:50.050\nWhy do we want application\nlayer firewalls?\n\n428\n00:23:50.050 --> 00:23:53.557\nBecause they can peel back the onion\nof that encapsulated data and\n\n429\n00:23:53.557 --> 00:23:56.299\nthey can see What's inside\nof that information and\n\n430\n00:23:56.299 --> 00:24:00.530\nthey can make decisions based on\nthe application layer information, right.\n\n431\n00:24:00.530 --> 00:24:04.577\nThe next generation firewalls that\ndon't just operate at layer three and\n\n432\n00:24:04.577 --> 00:24:07.260\nlayer four, they go beyond that, right.\n\n433\n00:24:07.260 --> 00:24:12.142\nThey can actually interact with\nthe upper layers of the OSI model.\n\n434\n00:24:12.142 --> 00:24:14.620\nAnd then last but not least,\ndata security, right?\n\n435\n00:24:14.620 --> 00:24:16.800\nData security can be as simple as ACLs,\nright.\n\n436\n00:24:16.800 --> 00:24:18.630\nIt can be data encryption.\n\n437\n00:24:18.630 --> 00:24:22.650\nMaking sure that your data, if it's in\ntransit, we're implementing things like\n\n438\n00:24:22.650 --> 00:24:27.270\nnetwork security where we have encrypted\ncommunication between endpoints.\n\n439\n00:24:27.270 --> 00:24:30.590\nIf it's sitting at rest,\nstored on that hard drive.\n\n440\n00:24:30.590 --> 00:24:34.330\nIs the hard drive, again, encrypted?\n\n441\n00:24:34.330 --> 00:24:36.160\nACLs, are we applying permissions,\n\n442\n00:24:36.160 --> 00:24:39.530\nmaking sure that only authorized users\nhave access to that information?\n\n443\n00:24:39.530 --> 00:24:44.670\nSo as you can see, there are quite\na few different things that you can do,\n\n444\n00:24:44.670 --> 00:24:46.280\nbut it's not just a single thing, right?\n\n445\n00:24:46.280 --> 00:24:52.410\nIt's a layered approach, and that\nessentially is what defense in depth is.\n\n446\n00:24:52.410 --> 00:24:54.570\nThey also talk about things\nlike vendor diversity.\n\n447\n00:24:54.570 --> 00:24:57.620\nVendor diversity is good,\nin the earlier days it's\n\n448\n00:24:57.620 --> 00:25:02.290\none of the reasons they started\nimplementing standards, right.\n\n449\n00:25:02.290 --> 00:25:04.550\nBecause in the early days of\nnetworking and communication,\n\n450\n00:25:04.550 --> 00:25:06.440\neverybody was doing it in their own way.\n\n451\n00:25:06.440 --> 00:25:10.400\nAnd you never had any interoperability,\nand you would get vendor-locked, right?\n\n452\n00:25:10.400 --> 00:25:12.820\nAnd if you get vendor-locked\nto a specific vendor,\n\n453\n00:25:12.820 --> 00:25:15.220\nthen well,\nyou're at the mercy of that vendor.\n\n454\n00:25:15.220 --> 00:25:16.230\nMore than one vendor.\n\n455\n00:25:16.230 --> 00:25:20.260\nAgain, you want to implement\nthings like vendor diversity.\n\n456\n00:25:21.730 --> 00:25:24.890\nAll right Dan, I know that we're running\na little bit short on time here.\n\n457\n00:25:24.890 --> 00:25:28.050\nBut I do have one last thing\nthat I wanna kinda talk about.\n\n458\n00:25:28.050 --> 00:25:31.220\nAnd they talk about control types,\nall right.\n\n459\n00:25:31.220 --> 00:25:33.210\nAnd these are those eight control types.\n\n460\n00:25:33.210 --> 00:25:33.980\nSo, you can see here.\n\n461\n00:25:33.980 --> 00:25:36.720\nSo, let's go ahead and\nlet's kinda just rundown the list of these\n\n462\n00:25:36.720 --> 00:25:41.130\ndifferent control types and\nkinda explain what each one is.\n\n463\n00:25:41.130 --> 00:25:44.200\nAnd again, you might be confronted\nwith these on the exam.\n\n464\n00:25:44.200 --> 00:25:46.060\nSo, the first one is Administrative.\n\n465\n00:25:46.060 --> 00:25:47.580\nAnd when we look at Administrative,\n\n466\n00:25:47.580 --> 00:25:51.030\nwe're essentially talking about\ncontrol types that are implemented.\n\n467\n00:25:51.030 --> 00:25:55.461\nIf you will, through things like policies,\nprocedures, and different guidelines.\n\n468\n00:25:55.461 --> 00:25:57.317\nWhen we talk about technical controls,\n\n469\n00:25:57.317 --> 00:25:59.730\nwe're talking about technology-based,\nright.\n\n470\n00:25:59.730 --> 00:26:05.475\nSo for instance, firewalls,\nanti-malware, IDS-based systems as well.\n\n471\n00:26:05.475 --> 00:26:08.005\nWe also have things like, for\ninstance, preventative controls.\n\n472\n00:26:08.005 --> 00:26:12.055\nAnd preventative controls is\nsomething that tries to stop\n\n473\n00:26:12.055 --> 00:26:15.945\nsomething from happening to begin with,\nright, before it even takes place.\n\n474\n00:26:17.290 --> 00:26:20.920\nPreventative controls could be things like\nlocks, could be things like biometrics\n\n475\n00:26:20.920 --> 00:26:24.420\npreventing unauthorized access,\nif you will, before they even happen.\n\n476\n00:26:24.420 --> 00:26:30.313\nBut again, those could also be considered\nphysical controls as well too, all right.\n\n477\n00:26:30.313 --> 00:26:33.913\nA deterrent is anything,\nthink of a, for instance,\n\n478\n00:26:33.913 --> 00:26:36.480\na sign that says secure area, right?\n\n479\n00:26:36.480 --> 00:26:41.436\nAll trespassers will be prosecuted, right,\nthat's the term I was going to say.\n\n480\n00:26:41.436 --> 00:26:42.187\n&gt;&gt; Shot.\n\n481\n00:26:42.187 --> 00:26:43.860\n[LAUGH]\n&gt;&gt; Yeah, I was going to say shot, but\n\n482\n00:26:43.860 --> 00:26:46.551\nwe probably don't wanna use that one,\nmaybe that's a little extreme.\n\n483\n00:26:46.551 --> 00:26:48.184\n&gt;&gt; [LAUGH] That's a heck of a deterrent.\n\n484\n00:26:48.184 --> 00:26:50.310\n&gt;&gt; [LAUGH] I was going to say,\nthat is a deterrent.\n\n485\n00:26:50.310 --> 00:26:52.490\nDon't go into that data center, for sure.\n\n486\n00:26:52.490 --> 00:26:55.688\nBut you know again, joking aside,\nagain, things like lighting,\n\n487\n00:26:55.688 --> 00:26:57.999\nsecurity guards,\nif you will, strobe lights.\n\n488\n00:26:57.999 --> 00:27:02.463\nAnd areas letting you know that\nsecurity cameras are there,\n\n489\n00:27:02.463 --> 00:27:05.713\nthese are all deterrent types of controls.\n\n490\n00:27:05.713 --> 00:27:06.781\nDetective, right,\n\n491\n00:27:06.781 --> 00:27:10.530\ndetective-based controls are trying\nto uncover some kind of violation.\n\n492\n00:27:10.530 --> 00:27:13.180\nRemember, a security breach is\nnothing more than a violation of\n\n493\n00:27:13.180 --> 00:27:14.070\na security policy.\n\n494\n00:27:14.070 --> 00:27:17.540\nAnd it doesn't have to be what I've\nkind of joked around in the past,\n\n495\n00:27:17.540 --> 00:27:22.120\nTom Cruise sliding down from the ceiling\nwith ropes into this highly secure area.\n\n496\n00:27:22.120 --> 00:27:25.520\nIt could be as simple as somebody\nputting a doorstop in a secure area,\n\n497\n00:27:25.520 --> 00:27:27.350\nkeeping that door propped open, right?\n\n498\n00:27:27.350 --> 00:27:31.380\nThat's a violation of the security policy,\nhence it's a security breach and\n\n499\n00:27:31.380 --> 00:27:36.160\na detective, if you will, is trying\nto uncover those type of violations.\n\n500\n00:27:37.200 --> 00:27:38.310\nWell, we got a couple more here.\n\n501\n00:27:38.310 --> 00:27:43.060\nCorrective, corrective is one that\ntries to restore a system to its\n\n502\n00:27:43.060 --> 00:27:48.780\nprevious state before or\nafter some kind of action has happened.\n\n503\n00:27:48.780 --> 00:27:51.320\nBasically trying to minimize the impact,\n\n504\n00:27:51.320 --> 00:27:54.690\nthat whatever has happened,\nminimize the impact to the company.\n\n505\n00:27:54.690 --> 00:27:57.500\nCould be things like backups,\nyour backup software, if you will.\n\n506\n00:27:57.500 --> 00:28:00.430\nThings like snapshots in\nyour virtual machines.\n\n507\n00:28:00.430 --> 00:28:03.135\nCould be things like, for instance,\n\n508\n00:28:03.135 --> 00:28:06.693\noperating system upgrades,\nif it happens to be.\n\n509\n00:28:06.693 --> 00:28:10.110\nAll right, last one on the list here,\nactually there's a couple more.\n\n510\n00:28:10.110 --> 00:28:13.385\nLast one on the list though,\nfor control types.\n\n511\n00:28:13.385 --> 00:28:16.690\nThese compensating control types,\nif you will,\n\n512\n00:28:16.690 --> 00:28:19.560\ntry to assist the controls that fail,\nright.\n\n513\n00:28:19.560 --> 00:28:21.680\nA sign is a deterrent.\n\n514\n00:28:21.680 --> 00:28:26.500\nHowever If the sign doesn't work when\nthe door opens, an alarm goes off, right.\n\n515\n00:28:26.500 --> 00:28:30.960\nSo that's a compensating type of control\nand it's just another control, right.\n\n516\n00:28:30.960 --> 00:28:34.450\nWe talk about things like emergency\nexits with a sign, right.\n\n517\n00:28:34.450 --> 00:28:36.710\nThose are both, if you will, a deterrent.\n\n518\n00:28:36.710 --> 00:28:39.936\nHowever, if an alarm is triggered\nthe moment you open that door,\n\n519\n00:28:39.936 --> 00:28:43.585\nnow we're talking about a compensation\nto the sign that's on that door.\n\n520\n00:28:43.585 --> 00:28:46.642\nSo those are compensating controls.\n\n521\n00:28:46.642 --> 00:28:49.090\nAll right, here's another one.\n\n522\n00:28:49.090 --> 00:28:51.570\nIf you think about disaster\nrecovery failover,\n\n523\n00:28:51.570 --> 00:28:54.290\nthat's a type of compensating control.\n\n524\n00:28:54.290 --> 00:28:57.200\nBecause if one site goes down,\nwe failover to the other site, right?\n\n525\n00:28:57.200 --> 00:29:01.980\nThe failover site is compensating,\nif you will, the primary site.\n\n526\n00:29:01.980 --> 00:29:05.340\nLast but not least, and we've talked\nabout this in events in depth.\n\n527\n00:29:05.340 --> 00:29:07.640\nThey call out user training, right?\n\n528\n00:29:07.640 --> 00:29:11.472\nUser training very basically, again,\npolicies, procedures, awareness,\n\n529\n00:29:11.472 --> 00:29:14.514\nmaking sure that you're doing\nsecurity awareness training.\n\n530\n00:29:14.514 --> 00:29:18.037\nAnd it has to be just\na very redundant cycle so\n\n531\n00:29:18.037 --> 00:29:23.760\nthat people are aware of what their\nrole is inside of your company.\n\n532\n00:29:23.760 --> 00:29:27.730\nAnd what they're maybe even liable for,\nwhen it comes to security.\n\n533\n00:29:27.730 --> 00:29:29.910\nSo user training is always important.\n\n534\n00:29:29.910 --> 00:29:30.530\n&gt;&gt; Very important.\n\n535\n00:29:30.530 --> 00:29:35.220\nThat's right, the weakest link in any\nchain is going to be usually your users.\n\n536\n00:29:35.220 --> 00:29:38.240\nBecause they have the least amount\nof technical knowledge and skill.\n\n537\n00:29:38.240 --> 00:29:41.540\nSo we have to get them,\nup to snuff as it were,\n\n538\n00:29:41.540 --> 00:29:43.760\nso that they can help in our security,\nas well.\n\n539\n00:29:43.760 --> 00:29:45.380\nThey're part of that security chain.\n\n540\n00:29:45.380 --> 00:29:48.490\nThat being said Wes, we have covered\na lot of ground in this episode.\n\n541\n00:29:48.490 --> 00:29:50.550\nAnd it's really just\nthe tip of the iceberg.\n\n542\n00:29:50.550 --> 00:29:52.590\nThere are full on certifications.\n\n543\n00:29:52.590 --> 00:29:56.900\nOnly about regulatory items and\nbest practices, frameworks,\n\n544\n00:29:56.900 --> 00:29:58.000\nthings of that nature.\n\n545\n00:29:58.000 --> 00:30:01.900\nSo if you think this was a bit of\na torrent, then you have no idea.\n\n546\n00:30:01.900 --> 00:30:02.930\nYou have just begun.\n\n547\n00:30:02.930 --> 00:30:06.270\nIt's quite a litany of different\nthings you have to learn about.\n\n548\n00:30:06.270 --> 00:30:07.466\nBut for the Security Plus exam,\n\n549\n00:30:07.466 --> 00:30:10.712\nthey just want you to have a well-rounded\nknowledge of these different regulations.\n\n550\n00:30:10.712 --> 00:30:13.390\nSo that you can impart them\ninto your own systems.\n\n551\n00:30:13.390 --> 00:30:14.767\nWes, we do thank you for\nshowing us each one of these things.\n\n552\n00:30:14.767 --> 00:30:15.445\n&gt;&gt; Sure.\n\n553\n00:30:15.445 --> 00:30:18.500\n&gt;&gt; And what is expected for\nus on the Security Plus exam.\n\n554\n00:30:18.500 --> 00:30:20.990\nBut I'm looking at our clock and\nwe have well exhausted our time for\n\n555\n00:30:20.990 --> 00:30:23.430\nthis episode, but\nI think it was really good.\n\n556\n00:30:23.430 --> 00:30:28.610\nHopefully you users out there are, users,\nwatchers, got me in IT world over here.\n\n557\n00:30:28.610 --> 00:30:29.170\n&gt;&gt; That's right.\n\n558\n00:30:29.170 --> 00:30:31.030\n&gt;&gt; Our watchers, our viewers.\n\n559\n00:30:31.030 --> 00:30:33.800\nI enjoyed it as well, but\nit's time for us to sign off.\n\n560\n00:30:33.800 --> 00:30:36.740\nSo, doing that, for ITProTV,\nI've been your host, Daniel Lowrie.\n\n561\n00:30:36.740 --> 00:30:37.385\n&gt;&gt; And I'm Wes Bryan.\n\n562\n00:30:37.385 --> 00:30:39.897\n&gt;&gt; And we'll see you next time.\n\n563\n00:30:39.897 --> 00:30:45.988\n[MUSIC]\n\n564\n00:30:45.988 --> 00:30:49.065\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216164028"
        },
        {
          "description": "In this show, Cherokee and Wes explain how the successful network designs can improve the overall network security. Tune in to learn what they recommend.",
          "length": "1801",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-2-secure_network_architecture_concepts-041317-PGM.00_29_47_08.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-2-secure_network_architecture_concepts-041317-PGM.00_29_47_08.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-2-secure_network_architecture_concepts-041317-PGM.00_29_47_08.Still001-sm.jpg",
          "title": "Secure Network Architecture Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.290 --> 00:00:02.113\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.113 --> 00:00:08.314\n[CROSSTALK]\n\n3\n00:00:08.314 --> 00:00:12.167\n&gt;&gt; You're watching IT Pro TV.\n\n4\n00:00:12.167 --> 00:00:15.672\n&gt;&gt; Welcome Ladies and Gentlemen\nto your CompTIA Security+ series.\n\n5\n00:00:15.672 --> 00:00:17.690\nI'm your show host Cherokee Boose.\n\n6\n00:00:17.690 --> 00:00:21.740\nIn this episode, we'll be talking about\ndifferent secure architecture concepts.\n\n7\n00:00:21.740 --> 00:00:24.820\nYou might not need to be a network\nengineer, but it really is important to\n\n8\n00:00:24.820 --> 00:00:29.900\nunderstand ways that we can defend our\nnetwork just by the design itself.\n\n9\n00:00:29.900 --> 00:00:32.670\nAnd with us today we have\nMr Wes Bryan back in studios\n\n10\n00:00:32.670 --> 00:00:34.000\nto help us cover this concept.\n\n11\n00:00:34.000 --> 00:00:35.020\nThank you for joining us Wes.\n\n12\n00:00:35.020 --> 00:00:36.400\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n13\n00:00:36.400 --> 00:00:40.600\nThat's right we have to look at a few\ndifferent architectural concepts.\n\n14\n00:00:40.600 --> 00:00:43.760\nSome of the things that they call out\nare things like topologies, right?\n\n15\n00:00:43.760 --> 00:00:45.120\nZones, if you will.\n\n16\n00:00:45.120 --> 00:00:48.400\nAnd we also call things like isolation and\nsegmentation.\n\n17\n00:00:48.400 --> 00:00:51.590\nBecause it is important,\nin certain network topologies,\n\n18\n00:00:51.590 --> 00:00:55.040\nto make sure that we do have\na division for purposes of security.\n\n19\n00:00:55.040 --> 00:00:58.490\nSo that is what we're going to\ntalk about here, in this episode.\n\n20\n00:00:58.490 --> 00:01:01.440\nSo let's go ahead and\nlet's dive right into\n\n21\n00:01:01.440 --> 00:01:05.390\nthe first category that we need to look\nat, and that is zones and topology.\n\n22\n00:01:05.390 --> 00:01:07.730\nI said the first category,\nsounds like it's a Jeopardy episode here,\n\n23\n00:01:07.730 --> 00:01:08.754\nAlex Trebek here, but.\n\n24\n00:01:08.754 --> 00:01:09.499\n&gt;&gt; [LAUGH] That would be fun.\n\n25\n00:01:09.499 --> 00:01:12.680\n&gt;&gt; [LAUGH] The first thing that we're\ngonna look at are topologies, and\n\n26\n00:01:12.680 --> 00:01:16.550\none of the first things that they call out\nare, well they call out the DMZ, right,\n\n27\n00:01:16.550 --> 00:01:18.020\nthe demilitarized zone.\n\n28\n00:01:18.020 --> 00:01:19.400\nWhat's that?\n&gt;&gt; Not the rapper?\n\n29\n00:01:19.400 --> 00:01:20.825\n&gt;&gt; No, definitely not.\n\n30\n00:01:20.825 --> 00:01:23.870\n[LAUGH] They call out DMZ, not DMX, right?\n\n31\n00:01:23.870 --> 00:01:26.130\n&gt;&gt; Not DMX. [LAUGH] &gt;&gt; Right,\nI've got your back on that one.\n\n32\n00:01:26.130 --> 00:01:29.060\n&gt;&gt; You see how well I'm versed in that,\nyeah.\n\n33\n00:01:29.060 --> 00:01:31.770\n&gt;&gt; [LAUGH] So DMZ is demilitarized zone.\n\n34\n00:01:31.770 --> 00:01:33.950\nWe've gotta keep in mind that\nthey do have some other terms,\n\n35\n00:01:33.950 --> 00:01:36.950\nin fact in another episode,\nCherokee, I know you mentioned it.\n\n36\n00:01:36.950 --> 00:01:41.437\nYou might hear Microsoft talk about things\nlike screen sub nets, perimeter networks.\n\n37\n00:01:41.437 --> 00:01:44.397\nYou might hear if you're talking about\nthings like network access control or\n\n38\n00:01:44.397 --> 00:01:45.546\nnetwork access protection.\n\n39\n00:01:45.546 --> 00:01:48.458\nIn the Windows world,\nyou might hear of isolation networks or\n\n40\n00:01:48.458 --> 00:01:50.034\nremediation networks, right.\n\n41\n00:01:50.034 --> 00:01:53.350\nAll of these play into\nthe concept of the DMZ.\n\n42\n00:01:53.350 --> 00:01:55.770\nAnd what it is, really with our DMZ,\n\n43\n00:01:55.770 --> 00:02:00.440\nis more about giving the external world,\nif you will, public access\n\n44\n00:02:00.440 --> 00:02:05.140\nbasically to your resources without\ngiving them too much access, right?\n\n45\n00:02:05.140 --> 00:02:08.663\nAnd that being access into your\nlocal internal network, right.\n\n46\n00:02:08.663 --> 00:02:12.836\nSo I got a little diagram here and\nif we look at what the DMZ is.\n\n47\n00:02:12.836 --> 00:02:16.334\nI want you to think and I probably could\nhave put you know the router the firewall\n\n48\n00:02:16.334 --> 00:02:19.570\nand different positions here,\ndepends on how it's designed, right?\n\n49\n00:02:19.570 --> 00:02:22.440\nBut for theory purposes,\njust keep in mind that what we have is we\n\n50\n00:02:22.440 --> 00:02:26.800\ntypically have some kind of\npublic facing resource, right?\n\n51\n00:02:26.800 --> 00:02:30.230\nSo for instance I might have, we'll\njust drop something in here real quick,\n\n52\n00:02:30.230 --> 00:02:32.090\nI might have it like a web server, right?\n\n53\n00:02:32.090 --> 00:02:36.120\nAnd I wanna give access to the website,\nright,\n\n54\n00:02:36.120 --> 00:02:37.550\nbecause maybe we're doing e-commerce,\nright?\n\n55\n00:02:37.550 --> 00:02:40.900\n&gt;&gt; Sure, we want people to access and\nbrowse our product catalog and\n\n56\n00:02:40.900 --> 00:02:41.990\nbuy things from us, right?\n\n57\n00:02:41.990 --> 00:02:42.980\n&gt;&gt; Most definitely.\n&gt;&gt; That's the purpose.\n\n58\n00:02:42.980 --> 00:02:45.810\n&gt;&gt; That's right, but at the same time\nwe don't want them to be able to get\n\n59\n00:02:45.810 --> 00:02:49.470\ninto our internal network and\nthat's the point of the DMZ.\n\n60\n00:02:49.470 --> 00:02:53.535\nThe DMZ is typically a logical,\nif you will, two firewalls, right.\n\n61\n00:02:53.535 --> 00:02:55.560\nWe have what's known as\nan external firewall.\n\n62\n00:02:55.560 --> 00:02:57.690\nWe have the internal firewall.\n\n63\n00:02:57.690 --> 00:03:01.920\nThe external firewall, if you will,\nis going to allow access to that resource\n\n64\n00:03:01.920 --> 00:03:06.030\nwithin that screen subnet or\nthat perimeter network if you will.\n\n65\n00:03:06.030 --> 00:03:11.500\nBut the internal firewall doesn't allow\naccess into the local area network\n\n66\n00:03:11.500 --> 00:03:14.870\nwithout the help of things like\nremote access technologies.\n\n67\n00:03:14.870 --> 00:03:18.180\nBut again, It's just the point\nof the de-militarized zone here.\n\n68\n00:03:18.180 --> 00:03:20.240\nSo, do keep that in mind.\n\n69\n00:03:20.240 --> 00:03:23.940\n&gt;&gt; So, I like to think about,\nI love coffee, kind of an addict here.\n\n70\n00:03:23.940 --> 00:03:28.540\nBut if you go to, like, Starbucks and you\nuse their free WiFi, the portion of that\n\n71\n00:03:28.540 --> 00:03:33.060\nnetwork that you're accessing is not the\nportion of the network, hopefully, that is\n\n72\n00:03:33.060 --> 00:03:38.300\nstoring any kind of employee information,\nmaybe their personally identifiable\n\n73\n00:03:38.300 --> 00:03:42.300\ninformation, scheduling, any kind of\nfinancial information for Starbucks.\n\n74\n00:03:42.300 --> 00:03:46.436\nSo when we connect to these\nfree captive portals, DMZs,\n\n75\n00:03:46.436 --> 00:03:51.700\nhot spots, we need to be careful that\nthere is a reduction or a reduced\n\n76\n00:03:51.700 --> 00:03:55.710\namount of security for that portion of\nthe network so we don't wanna really\n\n77\n00:03:55.710 --> 00:03:59.420\nwant to be doing anything too sensitive\non those types of networks either.\n\n78\n00:03:59.420 --> 00:04:01.500\n&gt;&gt; Most definitely and\nthis is really what it comes down to.\n\n79\n00:04:01.500 --> 00:04:02.700\nIt's about isolation, right?\n\n80\n00:04:02.700 --> 00:04:06.780\nWe have isolation from the public-facing\nside of our networks and\n\n81\n00:04:06.780 --> 00:04:09.332\nthe internal-facing side of our networks.\n\n82\n00:04:09.332 --> 00:04:13.420\nThe next thing that they call out are some\ndifferent topology categories that you've\n\n83\n00:04:13.420 --> 00:04:19.200\nprobably heard before and that is what are\nknown as things like intranets and they\n\n84\n00:04:19.200 --> 00:04:22.930\ntalk about extranets and I got a little\ndiagram to show you what's going on here.\n\n85\n00:04:22.930 --> 00:04:27.320\nKeep in mind that anytime we say\nan intranet we're talking, essentially,\n\n86\n00:04:27.320 --> 00:04:28.855\nabout the company network.\n\n87\n00:04:28.855 --> 00:04:33.780\nIntranet, more specifically, uses some of\nthose same web-based technologies that\n\n88\n00:04:33.780 --> 00:04:39.020\nthe Internet uses but\nthe Internet is publicly accessible.\n\n89\n00:04:39.020 --> 00:04:40.040\nThe intranet,\n\n90\n00:04:40.040 --> 00:04:44.720\non the other hand, is communications with\ninside of your corporate network, right.\n\n91\n00:04:44.720 --> 00:04:47.368\nI might have a web server on\nthe inside of the network,\n\n92\n00:04:47.368 --> 00:04:50.880\nright, using all the same technologies\nthat we see inside of the intranet.\n\n93\n00:04:50.880 --> 00:04:53.950\nBut Internet excuse me but\nthe difference is\n\n94\n00:04:53.950 --> 00:04:58.650\nmaybe that web server's only serving\nup things like employee documentations,\n\n95\n00:04:58.650 --> 00:05:03.150\nacceptable use policies,\nmaybe an employee handbook, right.\n\n96\n00:05:03.150 --> 00:05:06.800\nAnd we don't allow anybody on\nthe outside to have access to it.\n\n97\n00:05:06.800 --> 00:05:10.300\nNow on the other hand, we've already\nmentioned we've got the Internet,\n\n98\n00:05:10.300 --> 00:05:14.180\nthat is publicly accessible but\nwe also have what's known as an extranet.\n\n99\n00:05:14.180 --> 00:05:19.324\nAll right, notice that the intranet here,\nthe same company owns both networks,\n\n100\n00:05:19.324 --> 00:05:20.100\nright.\n\n101\n00:05:20.100 --> 00:05:22.920\nSo we could use things like VPN\ncommunications between them.\n\n102\n00:05:22.920 --> 00:05:28.000\nAnd I didn't draw those VPN communications\nbut this is owned by a single company.\n\n103\n00:05:28.000 --> 00:05:30.700\nHowever, I might have a business partner\n\n104\n00:05:30.700 --> 00:05:32.760\nthat I want to allow\na certain amount of access.\n\n105\n00:05:32.760 --> 00:05:35.840\nWhatever the level of of\naccess back into my network.\n\n106\n00:05:35.840 --> 00:05:36.700\nSo what do we do?\n\n107\n00:05:36.700 --> 00:05:41.180\nWe set that partner up so that they can\naccess a portion of the resources within\n\n108\n00:05:41.180 --> 00:05:43.310\nour company owned network.\n\n109\n00:05:43.310 --> 00:05:46.772\nAnd that's what becomes known\nas the extranet, right?\n\n110\n00:05:46.772 --> 00:05:49.920\nThe extranet is when you're\ngiving external access,\n\n111\n00:05:49.920 --> 00:05:52.650\ntypically some kind of business partner,\nright?\n\n112\n00:05:52.650 --> 00:05:54.970\nAccess to some of the resources\nwithin your network.\n\n113\n00:05:54.970 --> 00:05:59.130\nSo you implement what's known\nas an extranet, all right?\n\n114\n00:05:59.130 --> 00:06:03.000\nWe've talked a little bit\nabout this in the past.\n\n115\n00:06:03.000 --> 00:06:06.139\nAnd I want to go ahead and\nkind of mention it here.\n\n116\n00:06:06.139 --> 00:06:10.324\nThey talk about things for\ninstance, honeypots, all right.\n\n117\n00:06:10.324 --> 00:06:14.320\nWe have talked about things like honeypots\nand honeynets in another episode.\n\n118\n00:06:14.320 --> 00:06:18.400\nBut since it's on topology, let's go\nahead and let's talk about here, right.\n\n119\n00:06:18.400 --> 00:06:21.840\nTypically when I have honeypot, I've got\na single resource that I have set up\n\n120\n00:06:21.840 --> 00:06:26.460\nIt's kind of like a decoy if you will, to\nlearn information whether it is learning\n\n121\n00:06:26.460 --> 00:06:30.830\ninformation on how users access your\nwebsites or more importantly learning\n\n122\n00:06:30.830 --> 00:06:35.810\nhow malicious users maybe potentially\ntrying to attack your resources, right.\n\n123\n00:06:35.810 --> 00:06:38.610\nWe don't want them to attack anything\nin a production based network.\n\n124\n00:06:38.610 --> 00:06:40.020\nSo what we do-\n&gt;&gt; It may stall them to give you\n\n125\n00:06:40.020 --> 00:06:42.990\nenough time to build up your\ninternal infrastructure or\n\n126\n00:06:42.990 --> 00:06:44.230\njust defenses in that way.\n\n127\n00:06:44.230 --> 00:06:48.101\n&gt;&gt; Yeah, absolutely, nothing like having\na governor placed on the hackers, right?\n\n128\n00:06:48.101 --> 00:06:49.905\n&gt;&gt; [LAUGH]\n&gt;&gt; Slow them a little bit,\n\n129\n00:06:49.905 --> 00:06:51.242\nspeed bumps in their way.\n\n130\n00:06:51.242 --> 00:06:52.245\nAnd what does it do?\n\n131\n00:06:52.245 --> 00:06:55.580\nRight, well, the dummy, the honey net\nif you will is what they call out here.\n\n132\n00:06:55.580 --> 00:06:57.150\nA honeypot is a single resource.\n\n133\n00:06:57.150 --> 00:06:57.870\nIt's like a decoy.\n\n134\n00:06:57.870 --> 00:07:02.735\nA honeynet Is an entire network,\nright, and again, we make it very,\n\n135\n00:07:02.735 --> 00:07:04.970\nvery enticing to the attacker.\n\n136\n00:07:04.970 --> 00:07:09.400\nSo that the attacker thinks that\nwhen they're gaining access to this\n\n137\n00:07:09.400 --> 00:07:13.860\ndummy network, the honeynet,\nthey're not really affecting,\n\n138\n00:07:13.860 --> 00:07:18.520\nif you will, the production based network,\nright, it gives us that separation.\n\n139\n00:07:18.520 --> 00:07:23.197\nSo definitely know a little\nbit about the honeynets too.\n\n140\n00:07:24.390 --> 00:07:25.600\nAll right, so what else do we have?\n\n141\n00:07:25.600 --> 00:07:29.520\nWell we got all kinds of technologies\nthat we need to learn about.\n\n142\n00:07:29.520 --> 00:07:33.810\nI wanna mention a little bit about\nsome of the segmentation types.\n\n143\n00:07:33.810 --> 00:07:36.790\nBecause they do call out\na few different ones, right?\n\n144\n00:07:36.790 --> 00:07:41.160\nThey call out a physical segmentation and\nthey call out a logical segmentation or\n\n145\n00:07:41.160 --> 00:07:42.600\nsegregation if you will, right?\n\n146\n00:07:42.600 --> 00:07:45.770\nWell, how we implement these\nare a little bit different.\n\n147\n00:07:45.770 --> 00:07:52.220\nIf we talk about some kind of\na physical segmentation, if you will.\n\n148\n00:07:52.220 --> 00:07:56.134\nThen typically, what that's gonna be done,\nwe can bring up my computer here.\n\n149\n00:07:56.134 --> 00:08:00.119\nThat's essentially going to be\ntwo different switches, right?\n\n150\n00:08:00.119 --> 00:08:03.456\nAnd I do mean two physical switches,\nright?\n\n151\n00:08:03.456 --> 00:08:09.000\nIf we want a physical separation,\nthen that's what we're gonna have to do.\n\n152\n00:08:09.000 --> 00:08:11.240\nWe have one switch going\ninto another switch, and\n\n153\n00:08:11.240 --> 00:08:13.100\nwe have two different segments.\n\n154\n00:08:13.100 --> 00:08:19.190\nAnd if we wanna have communication travel\nbetween the two different segments,\n\n155\n00:08:19.190 --> 00:08:22.020\nwell, that's where we have to put\nthe layer three routing in place\n\n156\n00:08:22.020 --> 00:08:24.310\nin order to allow that communication.\n\n157\n00:08:24.310 --> 00:08:28.710\nAnd if we don't want them to communicate,\nwe don't put the layer three routing in\n\n158\n00:08:28.710 --> 00:08:32.340\nthere, and then we have physically\nseparated those networks.\n\n159\n00:08:32.340 --> 00:08:34.480\n&gt;&gt; Now Wes,\nswitches are kind of a weird one, right?\n\n160\n00:08:34.480 --> 00:08:37.480\nBecause not only can we\nphysically segment with switches.\n\n161\n00:08:37.480 --> 00:08:39.890\nBut can't we also logically\nsegment with switches?\n\n162\n00:08:39.890 --> 00:08:40.670\n&gt;&gt; Most definitely.\n\n163\n00:08:40.670 --> 00:08:43.130\nAnd that's where the other type of\n\n164\n00:08:43.130 --> 00:08:46.470\nseparation comes in that they\nwant you to be aware of, right?\n\n165\n00:08:46.470 --> 00:08:49.110\nThey want you to be aware\nof a logical division.\n\n166\n00:08:49.110 --> 00:08:51.790\nNow imagine that you have one switch.\n\n167\n00:08:51.790 --> 00:08:55.760\nBut in software, you kind of divide\nit up into multiple switches.\n\n168\n00:08:55.760 --> 00:08:56.550\nHow do we do that?\n\n169\n00:08:56.550 --> 00:08:59.890\nWell that's typically, in the manage\nswitches we can implement what's known as\n\n170\n00:08:59.890 --> 00:09:01.410\na Virtual Local Area Network.\n\n171\n00:09:01.410 --> 00:09:05.580\nAnd a Virtual Local Area Network is\na logical division of devices that\n\n172\n00:09:05.580 --> 00:09:10.602\nare connected into a single switch into\nthese logical networks, if you will.\n\n173\n00:09:10.602 --> 00:09:14.980\nSo kinda give you an example here,\nI've got a little diagram up here.\n\n174\n00:09:14.980 --> 00:09:19.570\nWe can have a series of devices and\nthey can be plugged into the same\n\n175\n00:09:19.570 --> 00:09:23.950\nphysical switch, but the way we divide\nthem up is based on what our choice is.\n\n176\n00:09:23.950 --> 00:09:27.400\nAnd we say, okay well PC1 here,\nit's on VLAN 10.\n\n177\n00:09:27.400 --> 00:09:28.170\nWith PC4 and 5.\n\n178\n00:09:28.170 --> 00:09:31.840\nEven though they're plugged into\nthe same switch, the only way that\n\n179\n00:09:31.840 --> 00:09:36.130\nthese three devices could connect or\ncommunicate with other devices,\n\n180\n00:09:36.130 --> 00:09:39.885\neven connect to the same switch, is if\nwe implement layer three routing, right?\n\n181\n00:09:39.885 --> 00:09:41.030\nSo VLANs, if you will,\n\n182\n00:09:41.030 --> 00:09:45.810\nare a logical grouping of devices that\nare connected to the same physical switch.\n\n183\n00:09:45.810 --> 00:09:48.250\nAnd it allows us that logical division,\nright?\n\n184\n00:09:48.250 --> 00:09:52.820\nRather than having to physically re-map\nports on a switch, all we have to do is go\n\n185\n00:09:52.820 --> 00:09:56.030\ninto the configuration on the switch,\nand we just say, okay.\n\n186\n00:09:56.030 --> 00:09:59.210\nWell, maybe PC1 I now want on VLAN20,\nright?\n\n187\n00:09:59.210 --> 00:10:01.550\nSo a simple reconfiguration of the port or\n\n188\n00:10:01.550 --> 00:10:06.360\nthe switch or the VLAN itself, now we have\na device that can be on that network.\n\n189\n00:10:06.360 --> 00:10:10.840\nSo logical divisions are a good\nway to go too, all right?\n\n190\n00:10:10.840 --> 00:10:12.690\n&gt;&gt; You might think,\nwell why would we wanna do that?\n\n191\n00:10:12.690 --> 00:10:14.980\nWes just explained how we could do it.\n\n192\n00:10:14.980 --> 00:10:19.270\nBut in a real life situation\nif we think about segmenting,\n\n193\n00:10:19.270 --> 00:10:21.100\nwell first we need to know\nwhy we wanna segment,\n\n194\n00:10:21.100 --> 00:10:26.360\nyou know there's many reasons why\nas if we wanted to apply security,\n\n195\n00:10:26.360 --> 00:10:29.820\ndifferent levels of security\nto these different segments.\n\n196\n00:10:29.820 --> 00:10:34.270\nAnd also to reduce traffic, so if we think\nabout that diagram he just showed us.\n\n197\n00:10:34.270 --> 00:10:37.070\nIf we have a multi-story building.\n\n198\n00:10:37.070 --> 00:10:40.080\nAnd maybe we have a sales department,\na marketing department, and\n\n199\n00:10:40.080 --> 00:10:43.600\nwe think about those nodes, those devices\nthat wanna communicate with each other,\n\n200\n00:10:43.600 --> 00:10:45.415\nthat communicate with each other the most.\n\n201\n00:10:45.415 --> 00:10:48.040\nSo we could have,\nby using that switch and VLANs,\n\n202\n00:10:48.040 --> 00:10:51.880\nwe could have someone on the first story\nand the second story be on the same VLAN.\n\n203\n00:10:52.940 --> 00:10:57.840\nBy having kind of, we're limiting\nourself somewhat to the length\n\n204\n00:10:57.840 --> 00:11:01.550\nof the cabling there, because we're\nusing this layer two technology.\n\n205\n00:11:01.550 --> 00:11:04.470\nBut we're also reducing\nthe traffic by implementing that\n\n206\n00:11:04.470 --> 00:11:06.100\nlogical component that you're mentioning.\n\n207\n00:11:06.100 --> 00:11:09.460\n&gt;&gt; Most definitely, and the logical nature\nallows us to not have to go in there and\n\n208\n00:11:09.460 --> 00:11:11.596\nphysically reconfigure the switch by-\n&gt;&gt; [LAUGH]\n\n209\n00:11:11.596 --> 00:11:12.890\n&gt;&gt; Putting things back in different,\n\n210\n00:11:12.890 --> 00:11:15.588\nthe patch panels, and before you know it-\n&gt;&gt; Super easy, like you mentioned,\n\n211\n00:11:15.588 --> 00:11:17.126\njust with the click of\nthat button [CROSSTALK].\n\n212\n00:11:17.126 --> 00:11:20.413\n&gt;&gt; Most definitely, so it does give\nyou the ability to do this with\n\n213\n00:11:20.413 --> 00:11:22.780\nthe least amount of administrative effort.\n\n214\n00:11:22.780 --> 00:11:27.280\nNow, there is another type of\nseparation that they call out.\n\n215\n00:11:27.280 --> 00:11:30.050\nAnd we've kinda mentioned it throughout\nthe series a couple of times.\n\n216\n00:11:30.050 --> 00:11:32.930\nCherokee, I know you've mentioned it,\nand that's called air gapping.\n\n217\n00:11:32.930 --> 00:11:34.470\nAir gapping is a little bit different.\n\n218\n00:11:34.470 --> 00:11:36.600\nIf we can go back to my machine here.\n\n219\n00:11:36.600 --> 00:11:39.540\nNow, instead of doing\na physical segmentation,\n\n220\n00:11:39.540 --> 00:11:45.060\nwe still have a communication connection\nbetween segment 1 and segment 2 here.\n\n221\n00:11:45.060 --> 00:11:48.380\nBut when you air gap,\nthere are no inbound and\n\n222\n00:11:48.380 --> 00:11:51.580\noutbound communications into this network,\nright?\n\n223\n00:11:51.580 --> 00:11:53.087\nIt could be a secure network.\n\n224\n00:11:53.087 --> 00:11:55.133\nCould be an isolated lab environment,\nright?\n\n225\n00:11:55.133 --> 00:11:58.509\nWhere maybe we're testing\nany viral software,\n\n226\n00:11:58.509 --> 00:12:02.467\nwhere we're releasing live\nviruses into this network.\n\n227\n00:12:02.467 --> 00:12:05.668\nI don't want,\neven with the physical segmentation,\n\n228\n00:12:05.668 --> 00:12:10.263\nI don't want any chance of whatever we're\nreleasing in this secure network to\n\n229\n00:12:10.263 --> 00:12:12.788\nmake its way outbound to another network.\n\n230\n00:12:12.788 --> 00:12:15.360\nOr the reverse.\n\n231\n00:12:15.360 --> 00:12:18.750\nI don't want anybody to actually make\ntheir way into this network through\n\n232\n00:12:18.750 --> 00:12:20.330\na communication channel, right?\n\n233\n00:12:20.330 --> 00:12:23.900\nThat's why they have to rely on other\ntechniques to get into communications.\n\n234\n00:12:23.900 --> 00:12:25.750\nIn fact, when Stuxnet came out,\n\n235\n00:12:25.750 --> 00:12:31.500\nthis was a facility air gapped\nnetwork that got attacked.\n\n236\n00:12:31.500 --> 00:12:32.500\nSo, how did they get attacked?\n\n237\n00:12:32.500 --> 00:12:36.520\nThey got attacked with probably the old\nUSB with a virus on it that somebody\n\n238\n00:12:36.520 --> 00:12:39.790\nplugged into a machine, and that was the\nonly way they could get into the network,\n\n239\n00:12:39.790 --> 00:12:40.530\nbut understand.\n\n240\n00:12:40.530 --> 00:12:41.430\n&gt;&gt; Out of band.\n\n241\n00:12:41.430 --> 00:12:41.940\n&gt;&gt; Out of band.\n\n242\n00:12:41.940 --> 00:12:43.900\nThat's right.\nSo, understand that they didn't\n\n243\n00:12:44.910 --> 00:12:47.620\nhave a communication means\ndirectly into the network.\n\n244\n00:12:47.620 --> 00:12:50.990\nThey had to use other techniques in\norder to get into that network and\n\n245\n00:12:50.990 --> 00:12:52.590\nexploit anything that was on it.\n\n246\n00:12:52.590 --> 00:12:55.457\n&gt;&gt; So we definitely have to have a very\nstrong will when we're talking about\n\n247\n00:12:55.457 --> 00:12:56.452\nkeeping those air gaps.\n\n248\n00:12:56.452 --> 00:12:59.661\nIt's not like, Wes,\nlet me just check my Facebook one time.\n\n249\n00:12:59.661 --> 00:13:00.271\nNo, [LAUGH].\n\n250\n00:13:00.271 --> 00:13:02.610\n&gt;&gt; No, most definitely.\n\n251\n00:13:02.610 --> 00:13:05.950\nSo some of the other things that we\ngotta look at, they do call out.\n\n252\n00:13:05.950 --> 00:13:10.310\nAnd we've talked about this kind of\nextensively in other episodes, but\n\n253\n00:13:10.310 --> 00:13:12.610\nI kinda wanna just rehash it here.\n\n254\n00:13:12.610 --> 00:13:15.650\nSince we are talking about\nthings like topologies.\n\n255\n00:13:15.650 --> 00:13:18.690\nThey mention things like tunnelling and\nVPN communications.\n\n256\n00:13:18.690 --> 00:13:21.180\nSo I wanna, and I know I'm kinda\njumping out of order here but\n\n257\n00:13:21.180 --> 00:13:24.390\nI wanna kinda go ahead and\njust rehash this out.\n\n258\n00:13:24.390 --> 00:13:28.140\nSo if we look at things like VPN\ncommunications, I do want you to keep in\n\n259\n00:13:28.140 --> 00:13:31.940\nmind that there are a few different types\nof VPNs that we need to be aware of.\n\n260\n00:13:31.940 --> 00:13:35.650\nWe need to be aware of what\nare known as site-to-site VPNs and\n\n261\n00:13:35.650 --> 00:13:37.750\nremote access VPNs, they do call it out.\n\n262\n00:13:37.750 --> 00:13:40.350\nSo if we could take a look\nat my machine here.\n\n263\n00:13:40.350 --> 00:13:44.180\n&gt;&gt; And Wes, if I'm not mistaken, did we do\na show specifically about VPNs already?\n\n264\n00:13:44.180 --> 00:13:46.650\nJust for the viewers, I know that\nsometimes the shows kinda mesh, but\n\n265\n00:13:46.650 --> 00:13:47.310\nI think we did, right?\n\n266\n00:13:47.310 --> 00:13:49.420\n&gt;&gt; Yeah, yeah, we talked about it.\n\n267\n00:13:49.420 --> 00:13:50.660\nSo if we look here,\n\n268\n00:13:50.660 --> 00:13:54.390\nnotice that a site-to-site VPN is\ntypically where you have gateway routers\n\n269\n00:13:54.390 --> 00:13:59.210\nand it's the two routers that\nare doing the tunneling, encryption or\n\n270\n00:13:59.210 --> 00:14:03.090\nencapsulation and decapsulation,\nand then encryption and decryption.\n\n271\n00:14:03.090 --> 00:14:05.790\nAgain, you might hear\nthis called site-to-site,\n\n272\n00:14:05.790 --> 00:14:07.960\nyou might hear it called\ngateway-to-gateway.\n\n273\n00:14:07.960 --> 00:14:11.510\nA remote access VPN, keep in mind,\nis typically when you need a single\n\n274\n00:14:11.510 --> 00:14:15.540\nconnection, using VPN communications, if\nyou will, back in your corporate networks.\n\n275\n00:14:15.540 --> 00:14:18.070\nSo this young lady here\nmaybe works at home.\n\n276\n00:14:18.070 --> 00:14:19.910\nBut needs access to the corporate network.\n\n277\n00:14:19.910 --> 00:14:22.820\nSo we set up client software on\nher machine, that connects back to\n\n278\n00:14:22.820 --> 00:14:26.780\nthe gateway router and allows her\nthe communication inside of the network.\n\n279\n00:14:26.780 --> 00:14:30.050\nAnd again,\nwe can couple this with things like IPsec,\n\n280\n00:14:30.050 --> 00:14:34.520\nInternet Key Exchange Version 2, if it's\na mobility that we're worried about.\n\n281\n00:14:34.520 --> 00:14:38.180\nAnd we get the encryption\nlevels of things like IPsec.\n\n282\n00:14:38.180 --> 00:14:41.260\nSo that we can use a public network and\n\n283\n00:14:41.260 --> 00:14:44.030\nwe create this logical\npoint-to-point connection.\n\n284\n00:14:44.030 --> 00:14:46.170\nAt least it looks like\na point-to-point connection with us.\n\n285\n00:14:46.170 --> 00:14:48.240\nAnd then you couple it with\nthe encryption technologies, and\n\n286\n00:14:48.240 --> 00:14:51.540\nyou don't have to worry about people\neavesdropping on your information\n\n287\n00:14:51.540 --> 00:14:53.490\nas it traverses the public network.\n\n288\n00:14:54.550 --> 00:14:59.700\nAll right, so a couple other topologies\nthat I want you to be aware of.\n\n289\n00:14:59.700 --> 00:15:03.190\nWe've kind of mentioned\nthe VPN technologies.\n\n290\n00:15:03.190 --> 00:15:06.310\nWe've talked about the honey nets.\n\n291\n00:15:06.310 --> 00:15:10.084\nThe other one that they\ncall out is wireless.\n\n292\n00:15:10.084 --> 00:15:15.003\nAnd wireless has many different topologies\nit really just depends on the level\n\n293\n00:15:15.003 --> 00:15:19.251\nof coverage you need, and\nwhat type of topology you're gonna use in\n\n294\n00:15:19.251 --> 00:15:22.553\nfact I've got kind of a diagram for\nthis right here.\n\n295\n00:15:22.553 --> 00:15:26.619\nSo for instance you could have something\nlike an extended service set where you\n\n296\n00:15:26.619 --> 00:15:28.652\nhave multiple access points, right,\n\n297\n00:15:28.652 --> 00:15:31.780\nall responding to the same\nserver set identifier.\n\n298\n00:15:31.780 --> 00:15:36.970\nAgain, keep in mind, you have your managed\nstations here, each access point is\n\n299\n00:15:36.970 --> 00:15:42.381\nreally gonna be managed overall by the\nwireless local area network controller,\n\n300\n00:15:42.381 --> 00:15:44.000\nthe WLAN controller if you will.\n\n301\n00:15:44.000 --> 00:15:46.900\nAnd the access points are what\nare known as thin access points\n\n302\n00:15:46.900 --> 00:15:49.430\nbecause they're really not\ncontrolling any of the devices.\n\n303\n00:15:49.430 --> 00:15:54.671\nThey're just literally allowing access to\nthe wired network and it's the wireless\n\n304\n00:15:54.671 --> 00:15:59.408\nLAN controller that's gonna control,\nif you will, the communications.\n\n305\n00:15:59.408 --> 00:16:03.806\nWe also have other things, for\ninstance this is an extended service set.\n\n306\n00:16:03.806 --> 00:16:05.259\nI think I have a basic service set here.\n\n307\n00:16:05.259 --> 00:16:09.310\nNow, basic service set is where you have\na single thick AP, as we've call it.\n\n308\n00:16:09.310 --> 00:16:13.380\nIt's a managing AP and\nit is managing every one of the stations.\n\n309\n00:16:13.380 --> 00:16:17.960\nKeep in mind that they can't communicate\nlike this PC to this PC directly.\n\n310\n00:16:17.960 --> 00:16:21.160\nThey actually have to send their\ninformation through the access point and\n\n311\n00:16:21.160 --> 00:16:24.890\nit is what controls the communications\nbetween end points, right?\n\n312\n00:16:24.890 --> 00:16:27.510\nThat is a basic service set, or a BSS,\n\n313\n00:16:27.510 --> 00:16:32.420\nin the fact that it is a single access\npoint that is managing multiple devices.\n\n314\n00:16:32.420 --> 00:16:36.130\nThere's another type of wireless\ncommunication that we could set up, and\n\n315\n00:16:36.130 --> 00:16:37.310\nthat's known as Ad hoc.\n\n316\n00:16:38.310 --> 00:16:42.440\nAd hoc, it's kinda like\na point-to-point communication,\n\n317\n00:16:42.440 --> 00:16:46.460\nwhere you don't have stations\nbeing just stations.\n\n318\n00:16:46.460 --> 00:16:48.550\nSometimes they can act as both, right?\n\n319\n00:16:48.550 --> 00:16:51.441\nAn access point, they can act\nas a station as well, meaning,\n\n320\n00:16:51.441 --> 00:16:53.232\nthey control their communications.\n\n321\n00:16:53.232 --> 00:16:54.530\n&gt;&gt; A print server, file server.\n\n322\n00:16:54.530 --> 00:16:55.150\n&gt;&gt; Most definitely.\n\n323\n00:16:55.150 --> 00:16:56.650\nSo where would you use\nsomething like this?\n\n324\n00:16:56.650 --> 00:17:01.260\nWell, imagine an environment where maybe\nyou gotta give a presentation, but\n\n325\n00:17:01.260 --> 00:17:03.870\nsomebody doesn't wanna give you\naccess to their wireless network.\n\n326\n00:17:03.870 --> 00:17:06.330\nWell, you got a couple people with you.\n\n327\n00:17:06.330 --> 00:17:09.820\nYou can set up an ad hoc network, and\nyou guys can directly communicate with one\n\n328\n00:17:09.820 --> 00:17:13.390\nanother so that you don't have to worry\nabout going through the access point.\n\n329\n00:17:13.390 --> 00:17:17.780\nSo, those are a couple of the wireless\ntopologies that we want you to be aware of\n\n330\n00:17:17.780 --> 00:17:19.860\nwhen it comes to the Security+ exam.\n\n331\n00:17:19.860 --> 00:17:21.478\n&gt;&gt; Now Wes,\nyou did say a couple of people.\n\n332\n00:17:21.478 --> 00:17:24.350\nWe do wanna keep in mind that if we\nlook at that diagram one more time,\n\n333\n00:17:24.350 --> 00:17:28.340\nyou can see how each one of those\nnodes have to be connected directly.\n\n334\n00:17:28.340 --> 00:17:33.340\nIf you don't, then it's not a full, that\nmesh design there, but we don't wanna add\n\n335\n00:17:33.340 --> 00:17:36.750\na ton of devices here because that's\njust really gonna bog down that traffic.\n\n336\n00:17:36.750 --> 00:17:39.690\nSo we have to be a little bit careful\nabout where we implement that.\n\n337\n00:17:39.690 --> 00:17:41.690\n&gt;&gt; Yeah, most definitely.\nWhen you look at the difference in\n\n338\n00:17:41.690 --> 00:17:45.164\nthe communication technologies,\none is using something like the new AC and\n\n339\n00:17:45.164 --> 00:17:48.550\nthe other one's using N or\nmaybe some of the older technologies.\n\n340\n00:17:48.550 --> 00:17:52.190\nYou're end up, it's not really,\nit's not a high-performance network.\n\n341\n00:17:52.190 --> 00:17:55.890\nIt's a more of, hey,\nat least we have this ability or\n\n342\n00:17:55.890 --> 00:17:58.960\ncapability to perform this\ntype of communications.\n\n343\n00:17:58.960 --> 00:18:02.670\nBut it's, I don't know if it's something\nwe would set out to do, and say, hey,\n\n344\n00:18:02.670 --> 00:18:05.754\nthis is the latest thing-\n&gt;&gt; #NetworkGoals.\n\n345\n00:18:05.754 --> 00:18:07.098\n[LAUGH]\n&gt;&gt; Yeah, definitely not.\n\n346\n00:18:07.098 --> 00:18:11.930\n[LAUGH] And, speaking of the wireless\nnetwork, one thing that I did forget, and\n\n347\n00:18:11.930 --> 00:18:14.720\nit really isn't just limited to wireless,\nbut\n\n348\n00:18:14.720 --> 00:18:17.420\na lot of times we associate it with\nwireless and that's guest networks.\n\n349\n00:18:18.420 --> 00:18:22.960\nKeep in mind that the guest networks are\nkind of like a wireless DMZ, if you will.\n\n350\n00:18:22.960 --> 00:18:24.818\nIt allows people to join your networks.\n\n351\n00:18:24.818 --> 00:18:28.700\nAnd typically,\nyou should password protect it.\n\n352\n00:18:28.700 --> 00:18:32.220\nBut what it doesn't allow them to\ndo is gain access to the resources\n\n353\n00:18:32.220 --> 00:18:33.500\nof the wireless network.\n\n354\n00:18:33.500 --> 00:18:36.970\nSo for instance, if I have a guest\nnetwork at my house, right, my wife,\n\n355\n00:18:36.970 --> 00:18:39.750\nI let her obviously log\ninto our home network, and\n\n356\n00:18:39.750 --> 00:18:42.220\nshe has access to all\nthe resources within our network.\n\n357\n00:18:42.220 --> 00:18:46.110\nBut, if she has a friend come over,\nright, or if I have a friend come over,\n\n358\n00:18:46.110 --> 00:18:48.950\nwe'll give them access to\nthe guest network because,\n\n359\n00:18:48.950 --> 00:18:52.080\nI really don't want them getting access\nto the files within our network.\n\n360\n00:18:52.080 --> 00:18:56.030\nAnd some of the different devices like I\ndon't need them streaming from a raspberry\n\n361\n00:18:56.030 --> 00:18:57.610\npie on my network and stuff like that.\n\n362\n00:18:57.610 --> 00:19:01.337\nSo, that's one of the great ways that you\ncould really control what level of access\n\n363\n00:19:01.337 --> 00:19:04.800\nsomebody has within your network without\nhow having to just say, okay, join\n\n364\n00:19:04.800 --> 00:19:08.606\nmy network, and then we'll hope that you\ndo your due diligence and behave, right.\n\n365\n00:19:08.606 --> 00:19:10.305\n[LAUGH]\n&gt;&gt; Behave.\n\n366\n00:19:10.305 --> 00:19:12.129\n[LAUGH]\n&gt;&gt; Without having an acceptable use\n\n367\n00:19:12.129 --> 00:19:12.645\npolicy.\n\n368\n00:19:12.645 --> 00:19:15.460\nSo guest networks are very good, in that\nthe fact that you can give somebody some\n\n369\n00:19:15.460 --> 00:19:17.655\nkind of,\nit's typically just Internet connectivity.\n\n370\n00:19:17.655 --> 00:19:20.140\nIt's a lot of times what\nthe guest networks are doing, and\n\n371\n00:19:20.140 --> 00:19:22.400\nit's not really about sharing resources,\nif you will.\n\n372\n00:19:23.490 --> 00:19:26.790\nBut you do have those likewise.\n\n373\n00:19:26.790 --> 00:19:30.730\nAll right so, let's see here,\nkeep an eye on my time here.\n\n374\n00:19:30.730 --> 00:19:36.050\nSo, that takes care of those, there are\na couple other techniques or technologies\n\n375\n00:19:36.050 --> 00:19:40.470\nthat I kinda wanna make you aware of,\nand one is network address translation.\n\n376\n00:19:40.470 --> 00:19:42.820\nNetwork address translation\ncomes in a few different forms.\n\n377\n00:19:42.820 --> 00:19:46.480\nAnd it depends on how much money\n[LAUGH] you have, I guess,\n\n378\n00:19:46.480 --> 00:19:50.960\nas to which form of network address\ntranslation that you will be implementing.\n\n379\n00:19:50.960 --> 00:19:53.310\nLet's go ahead and\ntake a look real quick, just in general,\n\n380\n00:19:53.310 --> 00:19:55.627\nat what network address\ntranslation is doing, all right?\n\n381\n00:19:55.627 --> 00:20:00.286\nSo in network address translation, I have,\nif you can pull up the diagram here,\n\n382\n00:20:00.286 --> 00:20:03.384\nwe have essentially internal IP addresses,\nright?\n\n383\n00:20:03.384 --> 00:20:07.920\nInternal private IP addresses\naccording to RFC1918 are not\n\n384\n00:20:07.920 --> 00:20:11.815\nsupposed to be routable\nacross the Internet, right?\n\n385\n00:20:11.815 --> 00:20:14.850\nISPs are supposed to drop those\npackets when they find them, okay?\n\n386\n00:20:14.850 --> 00:20:19.790\nSo how is it sometimes, we have to use\ninternal non-routable IP addresses,\n\n387\n00:20:19.790 --> 00:20:24.806\nbecause, if we have 1,000 computers\non our network, it's not feasible\n\n388\n00:20:24.806 --> 00:20:30.513\nto buy 1,000 public IP addresses in order\nto communicate with the rest of the world.\n\n389\n00:20:30.513 --> 00:20:35.138\nSo we use things like network address\ntranslation in the fact that,\n\n390\n00:20:35.138 --> 00:20:37.760\nI can take private IP addresses.\n\n391\n00:20:37.760 --> 00:20:39.210\nSend them off to the router and\n\n392\n00:20:39.210 --> 00:20:42.720\nwhat the router can do is strip\noff the private IP address and\n\n393\n00:20:42.720 --> 00:20:47.770\nreplace it with the public IP address and\nthen, send that out over the Internet.\n\n394\n00:20:47.770 --> 00:20:51.314\nAll right, so according to the rest of the\nworld, all the rest of the world sees is\n\n395\n00:20:51.314 --> 00:20:53.943\nthe public IP address,\nin this case, the gateway router.\n\n396\n00:20:53.943 --> 00:20:58.898\nAnd when the information comes back into\nour network, what it can do is through\n\n397\n00:20:58.898 --> 00:21:03.853\na database, it can remove the public IP\naddress and then put back the private IP\n\n398\n00:21:03.853 --> 00:21:08.460\naddress and deliver that to the right\ncomputer on the internal network.\n\n399\n00:21:08.460 --> 00:21:13.000\nAnd what it does is that, basically,\nmasks our internal architecture.\n\n400\n00:21:13.000 --> 00:21:18.160\nNow keep in mind, it's not the one-sized\nfits all for network security, but\n\n401\n00:21:18.160 --> 00:21:23.580\nit does kinda obscure, if you will, what\nthe internal IP address infrastructure is.\n\n402\n00:21:23.580 --> 00:21:26.890\n&gt;&gt; Now Wes you've mentioned,\nIt's like 1000 devices, but even out for\n\n403\n00:21:26.890 --> 00:21:31.270\nhome networks, right,\nI didn't purchased multiple IP addresses.\n\n404\n00:21:31.270 --> 00:21:34.190\nAnd I have more than one device\nconnecting to my home network.\n\n405\n00:21:34.190 --> 00:21:37.980\nSo, we can see, and like you said, it's\nnot always a one size fits all solution.\n\n406\n00:21:37.980 --> 00:21:41.410\nYou'll see sometimes, like in that\nsituation, you might even hear\n\n407\n00:21:41.410 --> 00:21:45.270\nlike a one to one ratio mapping where\ncompanies do buy additional IP addresses.\n\n408\n00:21:45.270 --> 00:21:46.890\nThere are many different flavors,\n\n409\n00:21:46.890 --> 00:21:49.390\nor ways we can implement\nnetwork address translation.\n\n410\n00:21:49.390 --> 00:21:53.520\nBut even our most basic devices like\nour all in one device that we see for\n\n411\n00:21:53.520 --> 00:21:57.200\nour just basic home use\nsupport NAT functions as well.\n\n412\n00:21:57.200 --> 00:21:57.860\n&gt;&gt; Yeah, that's right.\n\n413\n00:21:57.860 --> 00:22:01.160\nSo, what are the different types of NAT\nfunctions that she's talking about?\n\n414\n00:22:01.160 --> 00:22:04.585\nWell, there's what is known as static map,\nthere's what's known as dynamic map, and\n\n415\n00:22:04.585 --> 00:22:05.831\nthere's what's known as PAT.\n\n416\n00:22:05.831 --> 00:22:09.640\nAnd I don't mean Pat off of SNL,\nI mean Port Address Translation, right?\n\n417\n00:22:09.640 --> 00:22:12.010\nPort Address Translation's\na cheaper implementation.\n\n418\n00:22:12.010 --> 00:22:14.535\nThat's typically what we're doing\ninside of our home networks.\n\n419\n00:22:14.535 --> 00:22:16.950\nAnd let's go ahead and\ntake a look at this, all right?\n\n420\n00:22:16.950 --> 00:22:19.930\nSo a static NAT is the same concept,\nright?\n\n421\n00:22:19.930 --> 00:22:24.660\nWe have a private internal IP address that\nneeds to be translated, like I just said,\n\n422\n00:22:24.660 --> 00:22:28.940\nit strips off the private IP address and\nputs in the public IP address.\n\n423\n00:22:28.940 --> 00:22:32.600\nBut this is where, if you do static mat,\nyou have a one to one mapping.\n\n424\n00:22:32.600 --> 00:22:36.890\nWhich means for\nevery internal IP address that I have,\n\n425\n00:22:36.890 --> 00:22:41.870\nI have to have a single\nseparate public IP address,\n\n426\n00:22:41.870 --> 00:22:44.880\nright, one-to-one mapping and\nit never changes.\n\n427\n00:22:44.880 --> 00:22:46.960\nNow, why might you do something like that,\nright?\n\n428\n00:22:46.960 --> 00:22:51.510\nWell, maybe I have a resource that\nI do wanna give access to, but,\n\n429\n00:22:51.510 --> 00:22:54.600\nI don't want you knowing\nthe internal infrastructure,\n\n430\n00:22:54.600 --> 00:22:57.290\nright this would be a scenario\nin which you could use that.\n\n431\n00:22:57.290 --> 00:23:00.000\nBut then we also have what's\nknown as dynamic NAT.\n\n432\n00:23:00.000 --> 00:23:03.360\nAnd dynamic NAT,\nworks kind of like static NAT,\n\n433\n00:23:03.360 --> 00:23:06.990\nbut the difference is it's kind of\nlike a first come first serve basis.\n\n434\n00:23:06.990 --> 00:23:09.287\nSo, what I mean by that is, if we were,\n\n435\n00:23:09.287 --> 00:23:14.650\nlet's say that we have three computers and\nthey are gonna communicate out bound.\n\n436\n00:23:14.650 --> 00:23:17.270\nWell they might, at this point,\n\n437\n00:23:17.270 --> 00:23:20.960\nthis first computer might take that\nIP address at that point, right?\n\n438\n00:23:20.960 --> 00:23:24.109\nBut then, the next time it communicates,\nit might not, that might not be available.\n\n439\n00:23:24.109 --> 00:23:26.580\nIt might take this public IP address,\nright?\n\n440\n00:23:26.580 --> 00:23:30.300\nSo a dynamic NAT means,\nit's gonna rotate, right?\n\n441\n00:23:30.300 --> 00:23:34.608\nBut what happens if we only have three\npublic IP addresses, and I have, well,\n\n442\n00:23:34.608 --> 00:23:36.519\nthree machines connect, right?\n\n443\n00:23:36.519 --> 00:23:39.180\nAt whatever way that might be, right?\n\n444\n00:23:39.180 --> 00:23:41.330\nWe're just gonna do it\nin random order here.\n\n445\n00:23:41.330 --> 00:23:43.650\nWhat happens, oops,\nto the line of off of this one?\n\n446\n00:23:43.650 --> 00:23:44.370\nLet's get it ready.\n\n447\n00:23:44.370 --> 00:23:47.620\nWhat happens to this private IP address?\n\n448\n00:23:47.620 --> 00:23:49.035\nYou don't have access then, right?\n\n449\n00:23:49.035 --> 00:23:52.749\nSo, you do have to keep in mind the\ndynamic address translation does allow you\n\n450\n00:23:52.749 --> 00:23:54.933\nto rotate through your\npublic IP addresses.\n\n451\n00:23:54.933 --> 00:23:58.581\nBut, when you run out of public IP\naddress, you're gonna have potentially\n\n452\n00:23:58.581 --> 00:24:01.740\na computer in your network\nthat isn't gonna communicate.\n\n453\n00:24:01.740 --> 00:24:04.960\nNow what we have inside of\nour home networks, right?\n\n454\n00:24:04.960 --> 00:24:09.610\nThis is what you're gonna see inside\nof your larger networks, right?\n\n455\n00:24:09.610 --> 00:24:10.780\nBut in your home networks, and\n\n456\n00:24:10.780 --> 00:24:14.480\nI know that we use this here on\nour network occasionally, too.\n\n457\n00:24:14.480 --> 00:24:17.100\nIs what's known as port\naddress translation, right?\n\n458\n00:24:17.100 --> 00:24:20.890\nNow what we have is we have a packet\nof information that's going outbound,\n\n459\n00:24:20.890 --> 00:24:21.660\nno different, right?\n\n460\n00:24:21.660 --> 00:24:23.600\nAnd there's a port associated with it.\n\n461\n00:24:23.600 --> 00:24:26.250\nAnd then your router, or\nyour device that's performing work address\n\n462\n00:24:26.250 --> 00:24:30.710\ntranslation, what it does is it basically\nkeeps track of the port number.\n\n463\n00:24:30.710 --> 00:24:34.300\nAnd it puts this port up in a listing,\nright, a database.\n\n464\n00:24:34.300 --> 00:24:35.840\nAnd it does the same thing.\n\n465\n00:24:35.840 --> 00:24:40.430\nIt puts that public IP address on it,\nand it sends it out to the Internet.\n\n466\n00:24:40.430 --> 00:24:43.230\nWell, when it comes\nback in to the network,\n\n467\n00:24:43.230 --> 00:24:45.690\nthe router looks at this port number and\nsays, okay.\n\n468\n00:24:45.690 --> 00:24:48.770\nI see that that was mapped\nto this IP address.\n\n469\n00:24:48.770 --> 00:24:52.555\nRemoves the public IP address,\nputs the private IP address in,\n\n470\n00:24:52.555 --> 00:24:56.141\nits associated port back, and\ndelivers it to the end point.\n\n471\n00:24:56.141 --> 00:25:00.232\nThat's Port Address Translation and\nthat's a cheaper implementation today.\n\n472\n00:25:00.232 --> 00:25:03.449\nAnd that's commonly what we use\ninside of our home networks.\n\n473\n00:25:03.449 --> 00:25:04.946\n&gt;&gt; That sure is a lot of acronyms, Wes.\n\n474\n00:25:04.946 --> 00:25:09.405\nWe've got PAT, we've got DNAT,\nSNAT, regular NAT.\n\n475\n00:25:09.405 --> 00:25:12.350\nAnd you know and\njust not to convolute anything here.\n\n476\n00:25:12.350 --> 00:25:17.240\nBut I've even read documentation where you\nhave destination NAT versus source NAT.\n\n477\n00:25:17.240 --> 00:25:21.790\nWhich really is just talking about where\nthat IP address is being concealed.\n\n478\n00:25:21.790 --> 00:25:26.090\nSo don't get that confused with,\nlike Wes was explaining, dynamic NAT, and\n\n479\n00:25:26.090 --> 00:25:26.780\nstatic NAT.\n\n480\n00:25:26.780 --> 00:25:28.890\nWhich is the same acronym, lucky you.\n\n481\n00:25:28.890 --> 00:25:30.248\n[LAUGH]\n&gt;&gt; [LAUGH] That's right.\n\n482\n00:25:30.248 --> 00:25:33.430\nWe got some other technologies\nthat we wanna be aware of too.\n\n483\n00:25:33.430 --> 00:25:36.940\nThey talk about some of the security\ndevices that we can see out there.\n\n484\n00:25:36.940 --> 00:25:40.070\nAnd they talk about things\nlike sensors and collectors.\n\n485\n00:25:40.070 --> 00:25:43.030\nI want you to think of,\nwhen you think of sensors and collectors,\n\n486\n00:25:43.030 --> 00:25:46.300\nI want you to think of your seam,\nall right?\n\n487\n00:25:46.300 --> 00:25:50.080\nCollectors, we have multiple\nevent sources coming in, and\n\n488\n00:25:50.080 --> 00:25:53.948\nwe need a way that we can\ncollect that information, right?\n\n489\n00:25:53.948 --> 00:25:56.185\nSensors, think SCADA systems, right?\n\n490\n00:25:56.185 --> 00:25:59.850\nWe got a lot of different, the remote\ntelemetry units, PLCs out there.\n\n491\n00:25:59.850 --> 00:26:01.150\nI want you to keep that in mind.\n\n492\n00:26:01.150 --> 00:26:04.470\nAnd they talk about correlation engines,\nall right?\n\n493\n00:26:04.470 --> 00:26:06.830\nAnd correlation engines are really good.\n\n494\n00:26:06.830 --> 00:26:11.060\nSo imagine in a seam situation,\nor even an IPS situation, right?\n\n495\n00:26:11.060 --> 00:26:15.620\nIn an IPS situation, if we have\nmultiple events, we need a way to\n\n496\n00:26:15.620 --> 00:26:19.110\nbe able to compare those events to\ndetermine if it's an actual attack, right?\n\n497\n00:26:19.110 --> 00:26:22.600\nIs it just happenstance that we had\na couple of these events happen?\n\n498\n00:26:22.600 --> 00:26:26.190\nIs it something that we need to be\naware of and we need to be alerted to?\n\n499\n00:26:26.190 --> 00:26:30.460\nWell a correlation engine essentially\ntakes two different entities and\n\n500\n00:26:30.460 --> 00:26:33.310\nit creates a relationship between them,\nright?\n\n501\n00:26:33.310 --> 00:26:35.440\nCorrelating things like\nfirewalls to alert,\n\n502\n00:26:35.440 --> 00:26:38.590\nto determine, is this an attack, right?\n\n503\n00:26:38.590 --> 00:26:43.000\nAgain, you might get a correlation of\n\n504\n00:26:43.000 --> 00:26:48.020\nmultiple logs that do expose some kind of\nthreat event has happened on your network.\n\n505\n00:26:48.020 --> 00:26:50.920\nKeep in mind that we have\ncorrelation objects, right?\n\n506\n00:26:50.920 --> 00:26:53.560\nAnd the correlation object\nis basically a file\n\n507\n00:26:53.560 --> 00:26:56.600\nthat identifies the pattern to be matched.\n\n508\n00:26:56.600 --> 00:26:58.410\nAnd then you'll have things\nlike correlation events.\n\n509\n00:26:58.410 --> 00:27:02.720\nAnd a correlation event is a logged event\nthat matches what the correlation object,\n\n510\n00:27:02.720 --> 00:27:04.980\nthe pattern, that we are looking at.\n\n511\n00:27:04.980 --> 00:27:06.260\nWhat else do we have?\n\n512\n00:27:06.260 --> 00:27:07.380\nThings like filters, right?\n\n513\n00:27:07.380 --> 00:27:11.000\nWe've already talked content filters,\nURL filtering.\n\n514\n00:27:11.000 --> 00:27:14.620\nI don't want employees going to certain\nwebsites out there on the Internet.\n\n515\n00:27:14.620 --> 00:27:17.690\nWe can put in things like proxies,\nand we can do content filtering, and\n\n516\n00:27:17.690 --> 00:27:19.100\nwe can drop packets.\n\n517\n00:27:19.100 --> 00:27:21.740\nWe can do IP filtering at layer two,\nright?\n\n518\n00:27:21.740 --> 00:27:23.690\nOr excuse me,\nlayer three with our routers.\n\n519\n00:27:24.780 --> 00:27:26.410\nFirewalls, we've talked\nabout the Firewalls.\n\n520\n00:27:26.410 --> 00:27:29.140\nFirewalls are the way we set up DMZs,\nright?\n\n521\n00:27:29.140 --> 00:27:30.470\nWhat else do we have here?\n\n522\n00:27:30.470 --> 00:27:32.280\nVPN concentrators, right?\n\n523\n00:27:32.280 --> 00:27:36.120\nWhen I need to aggregate multiple,\nI mean thousands potentially,\n\n524\n00:27:36.120 --> 00:27:38.220\nsimultaneous VPN communications.\n\n525\n00:27:38.220 --> 00:27:43.183\nWe typically have this multi-functioning\ndevices today that will perform VPN\n\n526\n00:27:43.183 --> 00:27:44.830\nconcentration.\n\n527\n00:27:44.830 --> 00:27:45.770\nWhat else?\n\n528\n00:27:45.770 --> 00:27:49.810\nLoad balancers, again making sure that\nwe're distributing the workload of\n\n529\n00:27:49.810 --> 00:27:52.260\na service evenly across multiple devices.\n\n530\n00:27:53.350 --> 00:27:57.900\nSSL aggregators, or accelerators,\nexcuse me, SSL accelerators.\n\n531\n00:27:57.900 --> 00:28:00.520\nKeep in mind that when we\ntalk about encryption and\n\n532\n00:28:00.520 --> 00:28:03.670\ndecryption that's very CPU intensive.\n\n533\n00:28:03.670 --> 00:28:07.667\nSo imagine having a dedicated processing\nboard that we can offload that to, and\n\n534\n00:28:07.667 --> 00:28:09.945\ngives a better end user experience, right?\n\n535\n00:28:09.945 --> 00:28:11.628\nEspecially when you're\nselling products online.\n\n536\n00:28:11.628 --> 00:28:15.229\nEvery second that a user has to wait is\na potential second that somebody's gonna\n\n537\n00:28:15.229 --> 00:28:16.905\nleave and go find it somewhere else.\n\n538\n00:28:16.905 --> 00:28:21.528\nSSL acceleration can help to make sure\nthat the encrypted communcations happen\n\n539\n00:28:21.528 --> 00:28:25.533\nfaster so your web pages, if you will,\nrender a little bit quicker.\n\n540\n00:28:25.533 --> 00:28:26.379\nWhat else?\n\n541\n00:28:26.379 --> 00:28:29.061\nDenial of service mitigators.\n\n542\n00:28:29.061 --> 00:28:34.498\nAnd again, these are just guards to make\nsure that if legitimate traffic looks like\n\n543\n00:28:34.498 --> 00:28:40.029\nit could be a denial of service attack, we\ncould apply some kind of response to that.\n\n544\n00:28:41.070 --> 00:28:43.660\nAggregation switches,\nwhen we talk about aggregation switches.\n\n545\n00:28:43.660 --> 00:28:48.465\nAgain, how about combining multiple\nports together to get a better,\n\n546\n00:28:48.465 --> 00:28:50.860\nfaster communication.\n\n547\n00:28:50.860 --> 00:28:51.570\nWhat else, too?\n\n548\n00:28:51.570 --> 00:28:53.607\nTaps and port mirroring,\nthis is about spying.\n\n549\n00:28:53.607 --> 00:28:55.320\n[LAUGH] No just kidding.\n\n550\n00:28:55.320 --> 00:28:58.050\nTaps, again, tapping into a line,\nbeing able to see the information.\n\n551\n00:28:58.050 --> 00:28:58.660\nPort mirroring,\n\n552\n00:28:58.660 --> 00:29:01.790\nsaying that we're gonna send the\ninformation that's coming into one port.\n\n553\n00:29:01.790 --> 00:29:04.533\nWe're gonna map it or\nmirror it over to another port.\n\n554\n00:29:04.533 --> 00:29:06.938\nAnd that second port,\nI can plug in a machine, and\n\n555\n00:29:06.938 --> 00:29:09.130\nI can start monitoring the communications.\n\n556\n00:29:09.130 --> 00:29:10.140\n&gt;&gt; Good for troubleshooting.\n\n557\n00:29:10.140 --> 00:29:13.750\n&gt;&gt; Most definitely, so that and\nalso software defined networking.\n\n558\n00:29:13.750 --> 00:29:19.450\nKeep in mind, a way to abstract the\nmultiple layers within an application and\n\n559\n00:29:19.450 --> 00:29:21.850\nthe components that we\nservice up to our end users.\n\n560\n00:29:21.850 --> 00:29:24.487\n&gt;&gt; Kind of like a fancy restaurant\nwhen they deconstruct those dishes.\n\n561\n00:29:24.487 --> 00:29:27.105\nThat's what you really get with\nsoftware define networking, right?\n\n562\n00:29:27.105 --> 00:29:28.115\n&gt;&gt; Yeah, most definitely.\n\n563\n00:29:28.115 --> 00:29:31.375\n&gt;&gt; So Wes, thank you for taking the time\nto explain all those different devices\n\n564\n00:29:31.375 --> 00:29:32.825\nthat we can use on our network.\n\n565\n00:29:32.825 --> 00:29:35.665\nAnd how the actual design of\nthe network really does affect\n\n566\n00:29:35.665 --> 00:29:38.355\nthe overall security of an organization,\nas well.\n\n567\n00:29:38.355 --> 00:29:40.185\nAnd thank you, ladies and\ngentlemen, for tuning in.\n\n568\n00:29:40.185 --> 00:29:42.860\nBut stay tuned we have more\ninformation headed your way.\n\n569\n00:29:42.860 --> 00:29:44.200\nFor this show,\nwe'll go ahead and sign out.\n\n570\n00:29:44.200 --> 00:29:45.890\nRemember, I'm your host Cherokee Boose.\n\n571\n00:29:45.890 --> 00:29:46.680\n&gt;&gt; And I'm Wes Bryan.\n\n572\n00:29:46.680 --> 00:29:48.169\n&gt;&gt; See you next time here at ITProTV.\n\n573\n00:29:48.169 --> 00:29:55.666\n[MUSIC]\n\n574\n00:29:55.666 --> 00:29:57.740\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213663996"
        },
        {
          "description": "In this show, Cherokee and Wes explain how the design of individual devices may add  an additional layer of security. Tune in to learn several suggestions for consideration when choosing what type of devices to use within your environment.",
          "length": "1952",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-3-secure_system_design-041317-PGM.00_32_18_11.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-3-secure_system_design-041317-PGM.00_32_18_11.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-3-secure_system_design-041317-PGM.00_32_18_11.Still001-sm.jpg",
          "title": "Secure System Design",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:03.730\nWelcome to ITProTV,\n\n2\n00:00:03.730 --> 00:00:08.503\nI'm your host [CROSSTALK].\n\n3\n00:00:08.503 --> 00:00:12.364\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.364 --> 00:00:14.886\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n5\n00:00:14.886 --> 00:00:17.120\nI'm your show host, Cherokee Boose.\n\n6\n00:00:17.120 --> 00:00:18.190\nIn the previous episode,\n\n7\n00:00:18.190 --> 00:00:22.190\nwe were examining how the design of\na network can affect the overall security.\n\n8\n00:00:22.190 --> 00:00:25.370\nHowever in this episode,\nwe're really gonna be focusing and\n\n9\n00:00:25.370 --> 00:00:27.840\nnarrowing in on our individual devices.\n\n10\n00:00:27.840 --> 00:00:30.420\nWith us today, we have Mr.\nWes Bryan in studios.\n\n11\n00:00:30.420 --> 00:00:31.580\nThank you for joining us, Wes.\n\n12\n00:00:31.580 --> 00:00:32.940\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n13\n00:00:32.940 --> 00:00:37.630\nThat is right, we're gonna be looking at\na whole bunch of alphabet soup today.\n\n14\n00:00:37.630 --> 00:00:41.260\nBut this one has given a scenario,\nimplement secure system design.\n\n15\n00:00:41.260 --> 00:00:43.770\nAnd there are a couple different\ncategories that we're gonna be\n\n16\n00:00:43.770 --> 00:00:44.800\nlooking at today.\n\n17\n00:00:44.800 --> 00:00:48.120\nWe're gonna be looking at things like\nyour hardware and your firmware security.\n\n18\n00:00:48.120 --> 00:00:53.150\nWe'll be looking at operating systems,\njust basic patch management if you will.\n\n19\n00:00:53.150 --> 00:00:55.340\nAnd a few other things too.\n\n20\n00:00:55.340 --> 00:00:59.140\nSo, what do you say we go ahead and\nwe dive right in.\n\n21\n00:00:59.140 --> 00:01:02.060\nIn the first of the list,\nthey talk about things like hardware and\n\n22\n00:01:02.060 --> 00:01:03.320\nfirmware security.\n\n23\n00:01:04.420 --> 00:01:06.680\nHere it comes, alphabet soup right away.\n\n24\n00:01:06.680 --> 00:01:10.306\nWe have FDE and SED, and\nyou're probably saying well Pat, I don't\n\n25\n00:01:10.306 --> 00:01:14.392\nthink I could solve the puzzle, I'd\nlike to buy a few more variables right.\n\n26\n00:01:14.392 --> 00:01:15.610\nWhat are these acronyms?\n\n27\n00:01:15.610 --> 00:01:22.474\nWell, FDE is full drive encryption, right,\nSED is self encrypting drives, right.\n\n28\n00:01:22.474 --> 00:01:26.495\nA couple of different technologies that we\nhave to make sure that the data that is\n\n29\n00:01:26.495 --> 00:01:28.750\nbeing stored on our\nstorage medium is safe.\n\n30\n00:01:28.750 --> 00:01:31.370\nSo when we talk about things\nlike full drive encryption,\n\n31\n00:01:31.370 --> 00:01:34.320\nthere are technologies out there and one\nthat comes to mind in the Windows world\n\n32\n00:01:34.320 --> 00:01:37.210\nthat's been around since the days\nof Vista, and its gone through its\n\n33\n00:01:38.770 --> 00:01:42.820\nupgrades and enhancements over the years,\nis BitLocker drive encryption.\n\n34\n00:01:42.820 --> 00:01:45.040\nReally cool technology\nin the Windows world,\n\n35\n00:01:45.040 --> 00:01:48.480\nthat if you need to do full\ndisk encryption, you can.\n\n36\n00:01:48.480 --> 00:01:49.980\nBut that's not the only\nthing that's out there.\n\n37\n00:01:49.980 --> 00:01:53.490\nThey've got some third part software out\nthere that can help you do this too.\n\n38\n00:01:53.490 --> 00:01:58.090\nMcAfee or Intel, depending on how long\nyou've been looking over McAfee, right?\n\n39\n00:01:58.090 --> 00:02:02.200\nIntel based security, if you will,\ncalled the Complete Endpoint Protection.\n\n40\n00:02:03.220 --> 00:02:06.080\nSophos has one too, Safeguard Enterprise.\n\n41\n00:02:06.080 --> 00:02:07.750\nJust to kind of give you\nguys examples there.\n\n42\n00:02:07.750 --> 00:02:12.610\nSymantec Endpoint Protection,\nas well, or Endpoint Encryption.\n\n43\n00:02:12.610 --> 00:02:16.900\nAll different third party technologies\nthat do full drive encryption.\n\n44\n00:02:16.900 --> 00:02:21.720\nIn fact, let's go ahead and show you on\nthe Windows machine our drive encryption.\n\n45\n00:02:21.720 --> 00:02:26.540\nIf I go ahead and open up my File\nExplorer, and we look at, for instance,\n\n46\n00:02:26.540 --> 00:02:28.440\nthis PC, all right.\n\n47\n00:02:28.440 --> 00:02:30.580\nAnd in fact let me do that, there we go.\n\n48\n00:02:30.580 --> 00:02:34.050\nYou can kind of see that these drives\nhave little locks on them, right?\n\n49\n00:02:34.050 --> 00:02:37.610\nThat little lock lets me know that it is,\nwell first of all that BitLocker's\n\n50\n00:02:37.610 --> 00:02:40.070\nunlocked and\nwe can actually see the information here.\n\n51\n00:02:40.070 --> 00:02:44.200\nBut that little lock right there\nlets me know that BitLocker is\n\n52\n00:02:44.200 --> 00:02:45.370\nencrypting this drive.\n\n53\n00:02:45.370 --> 00:02:46.857\nSo, what does it do for me?\n\n54\n00:02:46.857 --> 00:02:49.205\nWell, I need to,\nwhen I boot the computer up,\n\n55\n00:02:49.205 --> 00:02:52.543\nI need to know a password in order\nto launch the operating system.\n\n56\n00:02:52.543 --> 00:02:56.341\nThis is kinda interesting because\nwe're not talking about logging on\n\n57\n00:02:56.341 --> 00:02:59.942\nthrough the traditional, what is it,\nthe login in dialogue box,\n\n58\n00:02:59.942 --> 00:03:02.510\nwhere you put in user name and password.\n\n59\n00:03:02.510 --> 00:03:04.075\nNo, we're talking even before that.\n\n60\n00:03:04.075 --> 00:03:05.487\n&gt;&gt; A password for the hardware.\n\n61\n00:03:05.487 --> 00:03:07.910\n&gt;&gt; That's right,\na passware that is stored, a passware?\n\n62\n00:03:07.910 --> 00:03:10.239\nI don't know what a passware is,\n\n63\n00:03:10.239 --> 00:03:13.573\na password that is stored in hardware,\nright?\n\n64\n00:03:13.573 --> 00:03:17.846\nAnd that's the BitLocker\nencryption system here, all right.\n\n65\n00:03:17.846 --> 00:03:21.115\nOther kinds of technologies, and we'll\ncome back to BitLocker encryption here\n\n66\n00:03:21.115 --> 00:03:24.880\nbecause there is a component that it's\nusing that we need to talk about as well.\n\n67\n00:03:24.880 --> 00:03:27.030\nBut there are also other\nthings out there too.\n\n68\n00:03:27.030 --> 00:03:29.373\nFor instance,\nthey have self-encrypting drives.\n\n69\n00:03:29.373 --> 00:03:31.660\nNow, self-encrypting drive\nis kinda interesting.\n\n70\n00:03:31.660 --> 00:03:34.770\nIt's not like what we see here when we're\ntalking about full drive encryption,\n\n71\n00:03:34.770 --> 00:03:36.390\nthis is something completely different.\n\n72\n00:03:36.390 --> 00:03:40.020\nIn the fact that you can\nactually get a drive that has\n\n73\n00:03:40.020 --> 00:03:44.240\nbuilt into the logic of the controller\nthe ability to encrypt itself on the fly.\n\n74\n00:03:44.240 --> 00:03:47.650\nAnd this is a way that if you need\nencryption but you don't want to use\n\n75\n00:03:47.650 --> 00:03:51.150\ntechnologies like this that you\nhave to encrypt after the fact,\n\n76\n00:03:51.150 --> 00:03:55.660\nthe drives can come in with their own\nabilities to do hardware based encryption.\n\n77\n00:03:55.660 --> 00:03:59.260\nThere are some technologies out there,\nsome vendors out there that you can see.\n\n78\n00:03:59.260 --> 00:04:02.660\nAnd I just mentioned some of\nthe vendors for your own edification.\n\n79\n00:04:02.660 --> 00:04:06.852\nI don't expect if you will that individual\nvendors are gonna be on the exam,\n\n80\n00:04:06.852 --> 00:04:11.440\nmaybe BitLocker might just because it's\nkinda become common inside of the Windows\n\n81\n00:04:11.440 --> 00:04:12.706\nbased environments.\n\n82\n00:04:12.706 --> 00:04:16.321\nBut with self-encrypting drives\nwe have things like for instance,\n\n83\n00:04:16.321 --> 00:04:18.700\nSeagate Constellation\nis a brand out there.\n\n84\n00:04:18.700 --> 00:04:20.810\nThis can get very expensive, too.\n\n85\n00:04:20.810 --> 00:04:22.340\nHP makes them, Dell makes them,\n\n86\n00:04:22.340 --> 00:04:27.260\nSamsung makes them, and Toshiba's\nanother one that makes these as well.\n\n87\n00:04:27.260 --> 00:04:32.040\nAnd these can be internal drives, right,\nor they could be external drives.\n\n88\n00:04:32.040 --> 00:04:35.320\nThey can also be things like, for\ninstance, hot swappable, right.\n\n89\n00:04:35.320 --> 00:04:38.642\nIf they're hot swappable, then chances\nare they're going to be like a SAS drive,\n\n90\n00:04:38.642 --> 00:04:43.240\nthe store serial attached SCSI\nbased drives and they can get very,\n\n91\n00:04:43.240 --> 00:04:44.950\nvery expensive.\n\n92\n00:04:44.950 --> 00:04:47.860\nAgain, they can be mechanical or\nthey can be solid state.\n\n93\n00:04:47.860 --> 00:04:50.010\nThey can also be serial ATA, as well.\n\n94\n00:04:50.010 --> 00:04:52.910\nCommonly, where you're gonna see\na self-encrypted drive is gonna\n\n95\n00:04:52.910 --> 00:04:56.460\nbe maybe little bit more popular ia inside\nof your servers, inside of your storage,\n\n96\n00:04:56.460 --> 00:05:00.600\nyour SANs your storage area networks,\nwhere you have multitudes of these drives.\n\n97\n00:05:00.600 --> 00:05:04.025\nThat is a little bit about things like,\nfor instance,\n\n98\n00:05:04.025 --> 00:05:07.760\nfull drive encryption and\nyour self-encrypting drives.\n\n99\n00:05:07.760 --> 00:05:10.930\nNow, another topic that they call\nout is what is known as the TPM.\n\n100\n00:05:10.930 --> 00:05:13.860\nThat's known as a trusted platform module.\n\n101\n00:05:13.860 --> 00:05:17.650\nAnd the trusted platform module is\na very interesting concept, all right.\n\n102\n00:05:17.650 --> 00:05:20.740\nThis is about a trusted computing\nbase is what they call it.\n\n103\n00:05:20.740 --> 00:05:26.990\nA trusted state of, well, firmware and\nyour operating system, right.\n\n104\n00:05:26.990 --> 00:05:30.240\nTrusted platform module, one of the first\ntime that we've seen it for instance,\n\n105\n00:05:30.240 --> 00:05:33.900\nin the windows environment,\nwas going back to the days of Vista.\n\n106\n00:05:33.900 --> 00:05:35.580\nWhen we've first seen BitLocker.\n\n107\n00:05:35.580 --> 00:05:37.020\nNow I said full drive encryption,\n\n108\n00:05:37.020 --> 00:05:39.780\nwhere are the encryption keys\nstored if you're using BitLocker?\n\n109\n00:05:39.780 --> 00:05:42.900\nWell, they're stored in a TPM,\nthe trusted platform module.\n\n110\n00:05:42.900 --> 00:05:45.180\nNow, is this a Windows\nspecific technology?\n\n111\n00:05:45.180 --> 00:05:46.219\nAnd the answer is no.\n\n112\n00:05:46.219 --> 00:05:48.299\nIt's an industry wide technology,\nall right.\n\n113\n00:05:48.299 --> 00:05:50.433\nAnd today, and for a long time,\n\n114\n00:05:50.433 --> 00:05:54.400\nit's been overseen by\nthe Trusted Computing Group, TCG.\n\n115\n00:05:54.400 --> 00:05:55.944\nThe Trusted Computing Group,\n\n116\n00:05:55.944 --> 00:05:59.275\nthey're the special interest\ngroup that oversees the standard.\n\n117\n00:05:59.275 --> 00:06:01.534\nAnd it's gone through some\nvariations throughout the years.\n\n118\n00:06:01.534 --> 00:06:08.192\nWe've had TPM 1, 1.1 if you will,\nTPM 1.2, and now we have TPM 2.0.\n\n119\n00:06:08.192 --> 00:06:11.194\nAnd again, they always increase\na little bit of its functionality,\n\n120\n00:06:11.194 --> 00:06:14.900\na little bit about its capabilities and\nstuff, and the security.\n\n121\n00:06:14.900 --> 00:06:17.880\nAnd it can contain information\nbased on the trusted\n\n122\n00:06:17.880 --> 00:06:20.510\noperational state of the machine.\n\n123\n00:06:20.510 --> 00:06:24.700\nInside of a TPM, you have what are known\nas Platform Configuration Registers, PCRs.\n\n124\n00:06:24.700 --> 00:06:30.740\nAnd the PCRs are what dictate what is\nthe current configuration of this machine.\n\n125\n00:06:30.740 --> 00:06:36.180\nAnd if we launch the computer,\nif we start bootstrap the computer, and\n\n126\n00:06:36.180 --> 00:06:41.470\nchecks and balances are being looked and\nbeing observed here and\n\n127\n00:06:42.730 --> 00:06:45.610\nyou expect to see this trusted state and\n\n128\n00:06:45.610 --> 00:06:49.620\nit doesn't match, the boot loader doesn't\nallow it to load the operating system.\n\n129\n00:06:49.620 --> 00:06:52.080\nAnd in fact,\nyou have to have trusted boot loaders.\n\n130\n00:06:52.080 --> 00:06:53.530\nThat's another great thing, too, right?\n\n131\n00:06:53.530 --> 00:06:55.775\nIt implements something known\nas secure boot in fact,\n\n132\n00:06:55.775 --> 00:07:00.455\nthat secure boot is also using the trusted\nplatform module, the TPMs, right.\n\n133\n00:07:00.455 --> 00:07:03.815\nAnd it's holding things like\nyour configuration state.\n\n134\n00:07:03.815 --> 00:07:06.075\nWhat is the current state of your BIOS?\n\n135\n00:07:06.075 --> 00:07:08.550\nAnd what is the BiOS configuration?\n\n136\n00:07:08.550 --> 00:07:12.720\nWhen the computer goes to boot,\ndo we even trust the boot loader?\n\n137\n00:07:12.720 --> 00:07:15.650\nWell, we can store that\ncryptographic information,\n\n138\n00:07:15.650 --> 00:07:18.340\nincluding a list of known\ntrusted boot loaders.\n\n139\n00:07:18.340 --> 00:07:24.180\nAnd if a piece of software goes to try\nto bootstrap the operating system and\n\n140\n00:07:24.180 --> 00:07:25.470\nwe check the TPM and\n\n141\n00:07:25.470 --> 00:07:28.760\nit says, well wait a second,\nI don't know what that bootloader is.\n\n142\n00:07:28.760 --> 00:07:31.660\nI don't have any information in the TPM,\nthat trusted platform module,\n\n143\n00:07:31.660 --> 00:07:35.700\nthat little chip, that hardware based chip\nthat's embedded into the motherboard.\n\n144\n00:07:35.700 --> 00:07:40.230\nIf it doesn't contain a listing for that\nbootloader, it says I don't trust you.\n\n145\n00:07:40.230 --> 00:07:41.790\nI don't know what you are.\n\n146\n00:07:41.790 --> 00:07:44.000\nAnd it doesn't allow\nthe computer to be bootstrapped.\n\n147\n00:07:44.000 --> 00:07:51.040\nThe other great thing too about storing\nthat information is we can do attestation.\n\n148\n00:07:51.040 --> 00:07:52.761\nI'll give you an example\nof this technology.\n\n149\n00:07:52.761 --> 00:07:54.404\nWe say secure boot.\n\n150\n00:07:54.404 --> 00:07:58.562\nSecure boot makes sure that only\nKnown trusted boot loaders load,\n\n151\n00:07:58.562 --> 00:08:02.540\nthe configuration state stays\nthe same inside of the TPM.\n\n152\n00:08:02.540 --> 00:08:04.590\nBut we also can do\n\n153\n00:08:05.880 --> 00:08:10.010\na measured boot inside of Windows is\none of the technologies that uses it.\n\n154\n00:08:10.010 --> 00:08:13.460\nThat says,\nhere's my corporate security policy.\n\n155\n00:08:13.460 --> 00:08:16.250\nMy corporate security policy\nsays this computer must be\n\n156\n00:08:16.250 --> 00:08:18.320\nin this configuration state.\n\n157\n00:08:18.320 --> 00:08:22.150\nNow secure boot uses its own checks and\nbalances and\n\n158\n00:08:22.150 --> 00:08:24.290\nit says, yeah, I trust everything.\n\n159\n00:08:24.290 --> 00:08:28.050\nBut maybe you have a security policy that\nsays it has to be configured this way.\n\n160\n00:08:28.050 --> 00:08:32.260\nWell, you can send that information out\nto a third party attestation server and\n\n161\n00:08:32.260 --> 00:08:36.550\nyou can compare it what the current\nconfiguration is to maybe a policy and\n\n162\n00:08:36.550 --> 00:08:38.510\nyou can see if they match up.\n\n163\n00:08:38.510 --> 00:08:41.330\nHence why Microsoft calls\ntheirs measured boot.\n\n164\n00:08:41.330 --> 00:08:44.600\nIt's not only working with secure boot,\nbut it's also saying that,\n\n165\n00:08:44.600 --> 00:08:48.340\nwhat if the configurations\nstate that your company needs,\n\n166\n00:08:48.340 --> 00:08:52.850\nis maybe just a little bit different then\njust what the basics of secure boots is?\n\n167\n00:08:52.850 --> 00:08:54.006\nWe can actually do\na measured boot as well.\n\n168\n00:08:54.006 --> 00:08:57.962\nLet me show you just a little\nbit about the TPM here, and\n\n169\n00:08:57.962 --> 00:08:59.860\ngive you an example here.\n\n170\n00:08:59.860 --> 00:09:05.337\nI'm gonna go ahead and\njump down to our Windows PowerShell here.\n\n171\n00:09:06.530 --> 00:09:07.334\nLet me go ahead and\n\n172\n00:09:07.334 --> 00:09:10.420\nlaunch up PowerShell, and\nwe'll kind of look at this a little bit.\n\n173\n00:09:10.420 --> 00:09:15.385\nThey've got inside of Windows,\nyou have what is known as manage BDE, for\n\n174\n00:09:15.385 --> 00:09:18.330\nmanagement BitLocker drive encryption.\n\n175\n00:09:18.330 --> 00:09:21.200\nI'm gonna change the font\nsize a little bit.\n\n176\n00:09:21.200 --> 00:09:25.850\n&gt;&gt; So while this a great technology Wes,\nand we're really securing that low level\n\n177\n00:09:25.850 --> 00:09:31.090\nthere, sometimes you may want to\ninstall untrusted operating systems,\n\n178\n00:09:31.090 --> 00:09:34.520\nif it's an older operating system.\n\n179\n00:09:34.520 --> 00:09:37.775\nBut for whatever reason, you might wanna\ncheck those BIOS settings to disable that\n\n180\n00:09:37.775 --> 00:09:40.910\nsecure boot in that\nrare type of situation.\n\n181\n00:09:40.910 --> 00:09:44.403\n&gt;&gt; Yes, let me give you an example\nwhere that is absolutely the case.\n\n182\n00:09:44.403 --> 00:09:48.222\nOne of the things that they did have\na problem, there was a little bit\n\n183\n00:09:48.222 --> 00:09:52.252\nof a controversy, when secure boot\ncame out, especially with Linux.\n\n184\n00:09:52.252 --> 00:09:54.670\nBecause you might well,\nLinux is usually a GRUB boot loader.\n\n185\n00:09:54.670 --> 00:09:56.675\nAnd that's absolutely true, but\n\n186\n00:09:56.675 --> 00:10:00.280\nevery distribution modifies\nGRUB just a little bit, right.\n\n187\n00:10:00.280 --> 00:10:04.043\nIt's not the same consistency, and when\nwe talked about file integrity, right,\n\n188\n00:10:04.043 --> 00:10:07.320\nfile signatures, remember all I had\nto do was add a blank character, and\n\n189\n00:10:07.320 --> 00:10:09.000\nit changed the signature?\n\n190\n00:10:09.000 --> 00:10:11.659\nWell here was the center of\nthe controversy, was, well,\n\n191\n00:10:11.659 --> 00:10:15.407\nif the bootloader isn't trusted, then\nwe can't boot the operating system, and\n\n192\n00:10:15.407 --> 00:10:17.276\nwhat happens when we can't boot Linux.\n\n193\n00:10:17.276 --> 00:10:20.656\nWhere we're gonna be stuck with\nonly what you say is trusted, and\n\n194\n00:10:20.656 --> 00:10:24.480\nwe can't use our computers for\nthird party software like that and stuff.\n\n195\n00:10:24.480 --> 00:10:28.770\nSo there was a big controversy out there,\nI'm not sure if it's ever been settled.\n\n196\n00:10:28.770 --> 00:10:33.790\nBut yeah, you can run into that to where\nmaybe you can't just run any operating\n\n197\n00:10:33.790 --> 00:10:36.920\nsystems you want on your machines, and\nthat was one of the controversies there.\n\n198\n00:10:36.920 --> 00:10:42.350\nSo we're in our PowerShell here.\n\n199\n00:10:42.350 --> 00:10:47.150\nThere is a command called manage BDE.\n\n200\n00:10:47.150 --> 00:10:51.647\nAnd what this allows me to do is to see\nthis current status of the BitLocker\n\n201\n00:10:51.647 --> 00:10:53.890\nencryption, is it even on.\n\n202\n00:10:53.890 --> 00:10:56.944\nAnd we can see that BitLocker,\nwe can see the version of it,\n\n203\n00:10:56.944 --> 00:10:59.342\nwe can see that the driver\nis fully encrypted.\n\n204\n00:10:59.342 --> 00:11:00.642\nWe can also see for\n\n205\n00:11:00.642 --> 00:11:05.242\ninstance, the encryption method\nthat it is using AES 128.\n\n206\n00:11:05.242 --> 00:11:08.009\nYou can go in to group policies and\nyou can bump this up if you\n\n207\n00:11:08.009 --> 00:11:12.152\nwanted the encryption to be a little bit\nstronger, that's up to your administrator.\n\n208\n00:11:12.152 --> 00:11:15.150\nSo we can see,\nthese are called Key Protectors,\n\n209\n00:11:15.150 --> 00:11:20.490\nthis is another thing by the way that\nthe TPM stores, is the protection method.\n\n210\n00:11:20.490 --> 00:11:23.100\nAnd you can see it's a numerical password.\n\n211\n00:11:23.100 --> 00:11:27.030\nAnd an external key for\nthe automatic unlock.\n\n212\n00:11:27.030 --> 00:11:31.220\nWe had a great question come in through\nthe chat room, it says what is the PCRs?\n\n213\n00:11:31.220 --> 00:11:34.456\nThat's a Platform Configuration Register,\nand what it is,\n\n214\n00:11:34.456 --> 00:11:36.583\nthat's the industry-wide standard.\n\n215\n00:11:36.583 --> 00:11:41.456\nAnd then the vendors choose which one\nof those that they implement in order\n\n216\n00:11:41.456 --> 00:11:45.630\nto verify the configuration\nstate of their operating system.\n\n217\n00:11:45.630 --> 00:11:48.250\nSo for instance,\nif you're using BitLocker,\n\n218\n00:11:48.250 --> 00:11:52.300\nBitLocker uses the platform\nconfiguration register number 11.\n\n219\n00:11:52.300 --> 00:11:56.801\nSo if I see a PCR number 11,\nin a Windows implementation,\n\n220\n00:11:56.801 --> 00:12:01.128\nI know that that is a BitLocker\nconfiguration register.\n\n221\n00:12:01.128 --> 00:12:05.144\nAll right, so I said let's go ahead and\nlook at the TPM a little bit,\n\n222\n00:12:05.144 --> 00:12:06.851\nlet's go ahead and do that.\n\n223\n00:12:06.851 --> 00:12:11.214\nInside of Windows they have a utility\ncalled the TPM Manager, and\n\n224\n00:12:11.214 --> 00:12:15.760\nwe can launch it up here from\nPowerShell just doing a tpm.msc here.\n\n225\n00:12:15.760 --> 00:12:17.010\nWe'll go ahead and launch that up.\n\n226\n00:12:19.400 --> 00:12:22.330\nMaybe, I think it launched it up.\n\n227\n00:12:22.330 --> 00:12:26.840\nWe're gonna find out here in a second,\nmy ability to spell or not.\n\n228\n00:12:29.360 --> 00:12:32.985\nThere we go, all right, that's what we\nwant, I just gotta know how to hit Enter.\n\n229\n00:12:32.985 --> 00:12:37.740\n[LAUGH] So we can see here, for\ninstance, our trusted platform module.\n\n230\n00:12:37.740 --> 00:12:40.138\nAnd we can get a little\nbit of information,\n\n231\n00:12:40.138 --> 00:12:42.074\nwe can see that it's ready to use.\n\n232\n00:12:42.074 --> 00:12:46.766\nThe manufacture, and the version in\nfact we had somebody in the chatroom,\n\n233\n00:12:46.766 --> 00:12:50.805\nthat's made a good mention,\ncuz this is a fairly new computer.\n\n234\n00:12:50.805 --> 00:12:55.457\nThat even though TPM version 2.0 is out,\na lot of times it is common in fact,\n\n235\n00:12:55.457 --> 00:12:58.769\nin a couple of machines that I have,\nhave a TPM in them and\n\n236\n00:12:58.769 --> 00:13:01.990\nthey're also using a 1.2 version as well.\n\n237\n00:13:01.990 --> 00:13:04.770\nBut we would have the ability\nif we wanted to clear the TPM.\n\n238\n00:13:04.770 --> 00:13:07.950\nWe wanted to clear out all the information\nthat's stored in that little hardware\n\n239\n00:13:07.950 --> 00:13:10.060\nmodule if you will, or little chip, and\n\n240\n00:13:10.060 --> 00:13:13.420\nthen we could transfer\nownership over if we needed to.\n\n241\n00:13:13.420 --> 00:13:15.970\nSo you can make modifications to that.\n\n242\n00:13:15.970 --> 00:13:19.690\nKeep in mind that your trusted\nplatform module is also\n\n243\n00:13:19.690 --> 00:13:21.230\nhow we implement Secure Boot.\n\n244\n00:13:21.230 --> 00:13:23.520\nNow Secure Boot actually\nmoves over into our BIOS.\n\n245\n00:13:23.520 --> 00:13:25.042\nSince we're talking about firmware,\n\n246\n00:13:25.042 --> 00:13:31.970\nwe kinda gotta mention something\nknown as UEFI and BIOS.\n\n247\n00:13:31.970 --> 00:13:37.260\nFor a very long time, I wanna say going\nback to the late 70s, it was Gary Kildall\n\n248\n00:13:37.260 --> 00:13:40.600\nwas the one that invented BIOS,\nthe basic input output system,\n\n249\n00:13:40.600 --> 00:13:44.030\na way that we could bootstrap\nthe hardware, if you will.\n\n250\n00:13:44.030 --> 00:13:46.260\nTurn the hardware on, get it stabilized,\n\n251\n00:13:46.260 --> 00:13:48.510\nthe operating system wouldn't\nhave to know about it.\n\n252\n00:13:48.510 --> 00:13:51.650\nAnd then we could transfer the control\nover the operating system, and\n\n253\n00:13:51.650 --> 00:13:53.050\nit now controls the hardware.\n\n254\n00:13:54.140 --> 00:13:56.950\nBut the problem here is basic input\noutput system has been around for\n\n255\n00:13:56.950 --> 00:13:58.130\na very long time.\n\n256\n00:13:58.130 --> 00:14:00.789\nIt was made back in the days of 8-bit and\n16-bit systems-\n\n257\n00:14:00.789 --> 00:14:01.639\n&gt;&gt; Over 25 years.\n\n258\n00:14:01.639 --> 00:14:04.830\nYeah, I mean how long is a technology,\n25 years in computing.\n\n259\n00:14:04.830 --> 00:14:05.590\n&gt;&gt; While running, yeah.\n\n260\n00:14:05.590 --> 00:14:06.910\n&gt;&gt; Yeah, that's pretty bad,\nif you think about it,\n\n261\n00:14:06.910 --> 00:14:08.047\nsix months usually things\nare out of date and\n\n262\n00:14:08.047 --> 00:14:09.198\nhere's something that we've been using.\n\n263\n00:14:09.198 --> 00:14:11.570\n&gt;&gt; I think it's time for\na facelift [LAUGH].\n\n264\n00:14:11.570 --> 00:14:12.770\n&gt;&gt; Yeah, and what is that facelift?\n\n265\n00:14:12.770 --> 00:14:17.520\nWell the facelift is UEFI,\nthe Unified Extensible Firmware Interface.\n\n266\n00:14:17.520 --> 00:14:20.232\nNow this was an implementation\noriginally by Intel.\n\n267\n00:14:20.232 --> 00:14:24.000\nAnd when it first started out, it was just\ncalled EFI, extensible firmware interface.\n\n268\n00:14:25.060 --> 00:14:28.539\nIntel, like they've done with a lot of\ntechnologies, Microsoft is one that's done\n\n269\n00:14:28.539 --> 00:14:31.940\nthis with technologies, wanted it to\nbecome more of an industry-wide standard.\n\n270\n00:14:31.940 --> 00:14:36.440\nSo what they did is basically transferred\nthe whole platform over to more like\n\n271\n00:14:36.440 --> 00:14:40.480\nan open standards, and it became became\nknown as the unified extensible firmware\n\n272\n00:14:40.480 --> 00:14:45.450\ninterface, just to separate it from\nthe early implementation of Intel today.\n\n273\n00:14:45.450 --> 00:14:48.770\nNow, today, everybody's using the unified\nextensible firmware interface.\n\n274\n00:14:48.770 --> 00:14:52.340\nNow, I want you to understand,\nfirmware interface.\n\n275\n00:14:52.340 --> 00:14:55.700\nSome people sometimes say UEFI BIOS.\n\n276\n00:14:55.700 --> 00:14:59.950\nGuys, if we're talking outside of an exam\nenvironment, I'm not gonna correct you.\n\n277\n00:14:59.950 --> 00:15:01.470\nUnderstand what it is, it's firmware.\n\n278\n00:15:01.470 --> 00:15:04.420\nIt's BIOS and UEFI,\nessentially are doing the same thing.\n\n279\n00:15:04.420 --> 00:15:06.475\nThey do it and\nhandle it in a different manner, and\n\n280\n00:15:06.475 --> 00:15:10.040\nUEFI adds some advantages\nthat BIOS never had.\n\n281\n00:15:10.040 --> 00:15:12.470\nFor instance, secure boot.\n\n282\n00:15:12.470 --> 00:15:14.249\nYou cannot use secure boot with BIOS,\n\n283\n00:15:14.249 --> 00:15:17.450\nyou have to have the unified\nextensible firmware interface.\n\n284\n00:15:17.450 --> 00:15:20.180\nAnd since we're talking about\navailability too as part of security,\n\n285\n00:15:20.180 --> 00:15:23.320\nyou might as well mention\nthat the master boot record.\n\n286\n00:15:23.320 --> 00:15:26.820\nIn our earlier systems BIOS would get\ndone with its job, it would look for\n\n287\n00:15:26.820 --> 00:15:31.410\nthe hard drive that had and contained the\nboot information, the master boot record.\n\n288\n00:15:31.410 --> 00:15:34.880\nAnd one of the limitations to BIOS was\nwhen it found the master boot record,\n\n289\n00:15:34.880 --> 00:15:35.840\nits job was done.\n\n290\n00:15:35.840 --> 00:15:37.740\nThrow in the towel, I'm done.\n\n291\n00:15:37.740 --> 00:15:41.380\nDidn't matter what state the master boot\nrecord was in, and it could be corrupted.\n\n292\n00:15:41.380 --> 00:15:44.985\nIf it was corrupted,\nBIOS looks at that master boot record,\n\n293\n00:15:44.985 --> 00:15:49.016\nfails to bootstrap the operating\nsystem and now you gotta reboot and\n\n294\n00:15:49.016 --> 00:15:52.001\nfigure out how to rebuild\nthe master boot record.\n\n295\n00:15:52.001 --> 00:15:55.485\nUEFI on the other hand uses\nsomething a little bit different,\n\n296\n00:15:55.485 --> 00:16:00.376\nit uses a series of GUIDs, globally unique\nidentifiers to find the boot information,\n\n297\n00:16:00.376 --> 00:16:02.868\nit's called GPT, a GUID Partition Table.\n\n298\n00:16:02.868 --> 00:16:06.250\nAnd the GUID partition table has\none that is essentially protected,\n\n299\n00:16:06.250 --> 00:16:07.800\nit's got two of them, right.\n\n300\n00:16:07.800 --> 00:16:11.857\nAnd what's kind of interesting is if that\nGUID partition table, which is akin to\n\n301\n00:16:11.857 --> 00:16:15.571\nthe MBR inside a BIOS, gets corrupted,\nwe have a protected one, right.\n\n302\n00:16:15.571 --> 00:16:19.028\nAnd that protected one can\nhelp you to continue and\n\n303\n00:16:19.028 --> 00:16:23.060\nboot the machine and\nrebuild the corrupted GPT.\n\n304\n00:16:23.060 --> 00:16:25.250\nSo again, UEFI has a lot of benefits.\n\n305\n00:16:25.250 --> 00:16:29.690\nOne of the facts, that it has more of\na redundant boot type configuration.\n\n306\n00:16:29.690 --> 00:16:33.030\nAnd the other thing is that, you could\nimplement things like secure boot.\n\n307\n00:16:33.030 --> 00:16:35.100\n&gt;&gt; And just,\nI was joking about the face lift.\n\n308\n00:16:35.100 --> 00:16:38.950\nBut even realistically,\nthe user interface there is a lot\n\n309\n00:16:38.950 --> 00:16:41.860\nnicer than what we had did in\nthe past with that menu driven.\n\n310\n00:16:41.860 --> 00:16:42.900\n&gt;&gt; Most definitely.\n\n311\n00:16:42.900 --> 00:16:44.765\n&gt;&gt; You can use the mouse now.\n\n312\n00:16:44.765 --> 00:16:45.520\n[LAUGH]\n&gt;&gt; [LAUGH] Yes, exactly.\n\n313\n00:16:45.520 --> 00:16:46.540\n&gt;&gt; That's a big change.\n\n314\n00:16:46.540 --> 00:16:51.030\n&gt;&gt; I've actually seen that in some\nold base systems where they would\n\n315\n00:16:51.030 --> 00:16:53.600\nimplement BIOS over some\nkind of software layer.\n\n316\n00:16:53.600 --> 00:16:56.480\nSo, some of the Dell machines that\nyou could still use your mouse.\n\n317\n00:16:56.480 --> 00:16:59.140\nEven going back to the days\nof the old BIOS, too.\n\n318\n00:17:01.220 --> 00:17:03.170\nWe've called it,\nwe've kind of talked about secure boot.\n\n319\n00:17:03.170 --> 00:17:04.910\nWe talked about attestation.\n\n320\n00:17:04.910 --> 00:17:06.490\nAgain, secure boot,\n\n321\n00:17:06.490 --> 00:17:10.580\nyou know what the configuration is of\nthe operating system, if you will.\n\n322\n00:17:10.580 --> 00:17:13.890\nYou know the firmware,\nwhat the configuration of the firmware is.\n\n323\n00:17:13.890 --> 00:17:16.619\nBut, you might have to go a little\nbit farther than that and\n\n324\n00:17:16.619 --> 00:17:20.201\nyou have to prove that to a third party\nagain according to a security policy.\n\n325\n00:17:20.201 --> 00:17:23.212\nSo again you could send that\ninformation to a third party server and\n\n326\n00:17:23.212 --> 00:17:26.492\nit can validate kind of like we talked\nabout with health certificates and\n\n327\n00:17:26.492 --> 00:17:30.256\nhealth registration authorities, kind of\nthink about it as the same concept, but\n\n328\n00:17:30.256 --> 00:17:33.140\nthe difference is the boot\nconfiguration is being presented.\n\n329\n00:17:34.400 --> 00:17:37.240\nAll right, we also have HSMs,\nhardware security modules.\n\n330\n00:17:37.240 --> 00:17:41.200\nAnd we've talked about that in other\nepisodes, but that is also a part of when\n\n331\n00:17:41.200 --> 00:17:46.220\nwe talk about firmware, and if you will,\na hardware-based security implementation.\n\n332\n00:17:46.220 --> 00:17:50.020\nBasically, HSMs are storing\ncryptographic information.\n\n333\n00:17:50.020 --> 00:17:52.990\nThey can prevent things like\nexternal programs being run\n\n334\n00:17:52.990 --> 00:17:55.210\non your machines without\nbeing digitally signed.\n\n335\n00:17:55.210 --> 00:17:56.670\nAnd if it is digitally signed,\n\n336\n00:17:56.670 --> 00:17:59.600\nit has to be signed with certificates\nthat are stored in the HSM.\n\n337\n00:17:59.600 --> 00:18:00.670\n&gt;&gt; Sure, key distribution.\n\n338\n00:18:00.670 --> 00:18:03.460\nAnd you know what Wes, if I'm gonna spend\nthat much money on a hardware device,\n\n339\n00:18:03.460 --> 00:18:04.640\nI'm gonna make sure it's up to date.\n\n340\n00:18:04.640 --> 00:18:06.130\nAt least, that's just my take on it.\n\n341\n00:18:06.130 --> 00:18:06.750\n&gt;&gt; You better believe it.\n\n342\n00:18:06.750 --> 00:18:08.820\nEspecially with the money\nthat you spend on these.\n\n343\n00:18:08.820 --> 00:18:11.190\nYou better be getting all\nthe use you can out of them.\n\n344\n00:18:11.190 --> 00:18:11.742\n&gt;&gt; Right.\n&gt;&gt; For sure,\n\n345\n00:18:11.742 --> 00:18:13.930\nbecause they can be thousands and\nthousands of dollars, guys.\n\n346\n00:18:13.930 --> 00:18:18.160\nBut again, that would be an example\nof an external cryptographic\n\n347\n00:18:18.160 --> 00:18:20.130\nhardware based implementation, right?\n\n348\n00:18:20.130 --> 00:18:23.035\nWhere the TPM isn't really\nexternal to the system.\n\n349\n00:18:23.035 --> 00:18:24.934\nIt's baked into\nthe motherboard if you will.\n\n350\n00:18:24.934 --> 00:18:26.745\nAll right, so what else do we got?\n\n351\n00:18:26.745 --> 00:18:29.571\nYou know it's interesting,\nthey call out supply chain, all right.\n\n352\n00:18:29.571 --> 00:18:35.353\nSupply chain is interesting in that we\nhave to worry about supply chain attacks.\n\n353\n00:18:35.353 --> 00:18:37.756\nWhat is a supply chain?\n\n354\n00:18:37.756 --> 00:18:41.218\nI want you to think,\nmaybe I'm a hardware manufacturer and\n\n355\n00:18:41.218 --> 00:18:44.621\nI'm relying from chips coming\nfrom overseas, alright.\n\n356\n00:18:44.621 --> 00:18:48.192\nBut somebody does make this current\nemployee from this chip manufacturer,\n\n357\n00:18:48.192 --> 00:18:50.089\ndecides that they're gonna go ahead and\n\n358\n00:18:50.089 --> 00:18:53.450\npre-bake a little bit of malware in\nthose chips that we're gonna buy.\n\n359\n00:18:53.450 --> 00:18:54.180\nAnd then what happens?\n\n360\n00:18:54.180 --> 00:18:57.950\nI put them into the PCBs\nthat we're configuring.\n\n361\n00:18:57.950 --> 00:19:02.010\nAnd now, as I distributed them\nto maybe the machines that we're\n\n362\n00:19:02.010 --> 00:19:04.860\nbuilding with them, they already\ngot malware pre-baked in them.\n\n363\n00:19:04.860 --> 00:19:06.630\nRight?\nSo we have to make sure that we protect\n\n364\n00:19:06.630 --> 00:19:10.380\nagainst supply chain attacks, and that's\none of the things that they do call out.\n\n365\n00:19:10.380 --> 00:19:14.190\nI've actually got some documentation,\nif you guys want additional information.\n\n366\n00:19:14.190 --> 00:19:17.510\nI don't really think that they're\ngonna go completely in depth, but\n\n367\n00:19:17.510 --> 00:19:19.390\nyou guys might like your\nown information out there.\n\n368\n00:19:19.390 --> 00:19:22.610\nAnd NIST, the National Institute for\nStandards and\n\n369\n00:19:22.610 --> 00:19:26.270\nTechnology, They actually have\nsome good documentation out here.\n\n370\n00:19:26.270 --> 00:19:29.920\nAnd if we can bring up my computer,\nI've got one of them up here.This\n\n371\n00:19:29.920 --> 00:19:34.420\nfirst one here is supply chain\nstandards mapping and road map.\n\n372\n00:19:34.420 --> 00:19:39.310\nThis one here is the NIST\n18227 documentation.\n\n373\n00:19:39.310 --> 00:19:41.820\nAgain, guys, I don't expect\nthat to come up on the exam.\n\n374\n00:19:41.820 --> 00:19:44.230\nI'm not sure, they don't really\nspecifically call it out.\n\n375\n00:19:44.230 --> 00:19:46.710\nBut they do call out supply chain attacks.\n\n376\n00:19:46.710 --> 00:19:47.240\nKnow what they are.\n\n377\n00:19:47.240 --> 00:19:49.970\nAnd this information\ncan help you out a lot.\n\n378\n00:19:49.970 --> 00:19:54.420\nI also have another one out here,\nand this is NIST 800-161.\n\n379\n00:19:54.420 --> 00:19:58.050\nAnd you can see the documentation.\n\n380\n00:19:58.050 --> 00:20:01.940\n800 is a whole body of information,\nthis just happens to be 161.\n\n381\n00:20:01.940 --> 00:20:04.957\nWhich is talking about,let's see,\nyeah, there we go,\n\n382\n00:20:04.957 --> 00:20:09.340\nsupply chain risk management for federal\ninformation systems and organizations.\n\n383\n00:20:09.340 --> 00:20:14.100\nAgain, lot of great information, you can\nkinda understand why we need to protect\n\n384\n00:20:14.100 --> 00:20:20.260\nagainst this type of an attack and again,\nit's because somebody can counterfeit.\n\n385\n00:20:20.260 --> 00:20:23.900\nIt's not just about the fact that\nit includes malicious software,\n\n386\n00:20:23.900 --> 00:20:25.460\ncould be counterfeits right?\n\n387\n00:20:25.460 --> 00:20:29.060\nAnd that we make sure that we do have\na production quality that we expect\n\n388\n00:20:29.060 --> 00:20:32.370\nif we are working with\noutside vendors like that.\n\n389\n00:20:32.370 --> 00:20:36.060\n&gt;&gt; Well sure, Wes, I mean,\neven if you think about our government.\n\n390\n00:20:36.060 --> 00:20:39.760\nWe don't want to be outsourcing and\nsending the manufacturing of a lot of\n\n391\n00:20:39.760 --> 00:20:44.270\nproducts overseas, because there may be\nsome kind of integrated kill switch or\n\n392\n00:20:44.270 --> 00:20:46.810\nit's just kind of a risk there\nthat we don't wanna take.\n\n393\n00:20:46.810 --> 00:20:47.620\n&gt;&gt; Yeah, most definitely.\n\n394\n00:20:47.620 --> 00:20:48.440\nLet me give you an example.\n\n395\n00:20:48.440 --> 00:20:50.590\nIt's not really IT related, but\nlet me give you an example.\n\n396\n00:20:50.590 --> 00:20:52.940\nYou guys have probably seen plenty\nof those hover boards around,\n\n397\n00:20:52.940 --> 00:20:54.210\nwhere you stand on them.\n\n398\n00:20:54.210 --> 00:20:55.023\nI can't stand on them.\n\n399\n00:20:55.023 --> 00:20:56.422\n&gt;&gt; [LAUGH]\n&gt;&gt; I'd kill myself on one.\n\n400\n00:20:56.422 --> 00:20:58.311\nBut the, one of the major manufacturers,\n\n401\n00:20:58.311 --> 00:21:00.569\nthey started having problems\nwith the batteries,\n\n402\n00:21:00.569 --> 00:21:04.260\nlike another phone we won't talk about,\nit started going up in flames if you will.\n\n403\n00:21:04.260 --> 00:21:06.660\nAnd they found out that the manufacturer,\nand\n\n404\n00:21:06.660 --> 00:21:10.360\ntried to save money by implementing\ncheap lithium ion batteries.\n\n405\n00:21:10.360 --> 00:21:13.450\nThose lithium ion batteries\nstarted to catch fire, hence,\n\n406\n00:21:13.450 --> 00:21:16.450\nthey didn't,\nwhether it was a supply chain attack,\n\n407\n00:21:16.450 --> 00:21:19.890\nkeep in mind that it doesn't have\nto be about malicious software.\n\n408\n00:21:19.890 --> 00:21:24.420\nSupply chain risk management could be\nabout the fact that, you wanna make sure\n\n409\n00:21:24.420 --> 00:21:27.400\nthat the production value is where\nit needs, production quality, right?\n\n410\n00:21:27.400 --> 00:21:30.181\nCuz it's still a risk.\n&gt;&gt; All of those different countries don't\n\n411\n00:21:30.181 --> 00:21:33.070\nhave the same regulations\nthat our country has.\n\n412\n00:21:33.070 --> 00:21:35.690\nSo the quality may be\nslipping a little bit there.\n\n413\n00:21:35.690 --> 00:21:38.760\nYou just need to be careful about who\nyou are getting your supplies from,\n\n414\n00:21:38.760 --> 00:21:39.510\nyour vendors.\n\n415\n00:21:39.510 --> 00:21:42.760\n&gt;&gt; Most definitely, documentation,\ndocumentation, and yes,\n\n416\n00:21:42.760 --> 00:21:43.670\nmore documentation.\n\n417\n00:21:43.670 --> 00:21:46.490\n[LAUGH] Some of the other\nthings that they call out to.\n\n418\n00:21:46.490 --> 00:21:47.860\nHardware root of trust.\n\n419\n00:21:47.860 --> 00:21:49.110\nWhat is a hardware root of trust?\n\n420\n00:21:49.110 --> 00:21:54.120\nWell your TPM, this is an example\nof hardware root of trust, right.\n\n421\n00:21:54.120 --> 00:21:57.840\nA continual set of procedures,\nright, if you will, or\n\n422\n00:21:57.840 --> 00:22:02.620\nroutines that are rooted if you will,\nthat's why the root of trust,\n\n423\n00:22:02.620 --> 00:22:05.420\nrooted in the hardware,\nthey begin in the hardware, right.\n\n424\n00:22:05.420 --> 00:22:07.840\nWe worry about things like root kits.\n\n425\n00:22:07.840 --> 00:22:08.380\nWhy?\n\n426\n00:22:08.380 --> 00:22:12.225\nWell, cuz the root kits try to install\nthemselves before your operating system\n\n427\n00:22:12.225 --> 00:22:16.535\nand it's anti virus or anti malware\nprotection even initiates, right.\n\n428\n00:22:16.535 --> 00:22:19.695\nso if we can do something like Microsoft\ndoes to their Windows systems and\n\n429\n00:22:19.695 --> 00:22:23.405\nthey bake in a low level system driver\nthat starts before the operating system\n\n430\n00:22:23.405 --> 00:22:27.615\neven loads up called ELAM,\nEarly Launch Anti Malware system driver,\n\n431\n00:22:27.615 --> 00:22:30.495\nwhat it does is it checks\nthings like the state,\n\n432\n00:22:30.495 --> 00:22:33.910\nwe put in in combination with secure boot\n&gt;&gt; We know\n\n433\n00:22:33.910 --> 00:22:35.760\nwhat the trusted configuration is.\n\n434\n00:22:35.760 --> 00:22:37.720\nAgain, it starts there in the firmware.\n\n435\n00:22:37.720 --> 00:22:38.860\nThis is the root of trust.\n\n436\n00:22:38.860 --> 00:22:39.906\nTPMs are an example.\n\n437\n00:22:39.906 --> 00:22:45.750\nHere's another one [LAUGH] and if you're\nlike me and you like to customize,\n\n438\n00:22:45.750 --> 00:22:48.640\nput custom ROMs on your phone maybe\nyou don't like this technology,\n\n439\n00:22:48.640 --> 00:22:49.970\nI know there's some debate on this one.\n\n440\n00:22:49.970 --> 00:22:55.930\nBut Knox, Knox is a form of trust root,\nright, a root of trust.\n\n441\n00:22:55.930 --> 00:22:59.775\nWe know what the configuration is of\nthis phone, even before it boots.\n\n442\n00:22:59.775 --> 00:23:03.440\nKnox is an example of\na hardware root of trust.\n\n443\n00:23:04.540 --> 00:23:07.200\nOther things that they call out,\nagain, keep in mind that for\n\n444\n00:23:07.200 --> 00:23:10.210\nthe most part we have,\neven when we're talking about firmware,\n\n445\n00:23:10.210 --> 00:23:17.740\nit is stored in chips that could be\nsensitive to electrical current, right?\n\n446\n00:23:17.740 --> 00:23:19.850\nThink about the earlier\ndays in PROM chips, right?\n\n447\n00:23:19.850 --> 00:23:22.700\nWe talk about PROM chips,\nthey were read once and that was it,\n\n448\n00:23:22.700 --> 00:23:24.360\nyou couldn't reprogram it at all.\n\n449\n00:23:24.360 --> 00:23:28.520\nAs they went through the process,\nwe went to EPROM chips,\n\n450\n00:23:28.520 --> 00:23:31.170\nhad a little window that you\ncould use a UV light, right?\n\n451\n00:23:31.170 --> 00:23:33.990\nPretty much the same technology\nwhen we went to EEPROM, but\n\n452\n00:23:33.990 --> 00:23:36.960\nthe difference is it didn't\nreact to an ultraviolet light.\n\n453\n00:23:36.960 --> 00:23:40.990\nWe can send an electrical current across\nthe motherboard into it, to reprogram it.\n\n454\n00:23:40.990 --> 00:23:44.990\nNow, imagine if we have things like\nelectromagnetic interference, EMI, or\n\n455\n00:23:44.990 --> 00:23:46.355\neven electromagnetic pulse.\n\n456\n00:23:46.355 --> 00:23:47.523\n[SOUND] Tap it.\n\n457\n00:23:47.523 --> 00:23:51.310\nWe can completely erase the chip, so you\ngotta be careful with things like that.\n\n458\n00:23:53.000 --> 00:23:54.190\nWhat else do they call out?\n\n459\n00:23:54.190 --> 00:23:56.560\nOther things like your operating systems,\nright.\n\n460\n00:23:56.560 --> 00:23:58.991\nThey've got a whole slew of\noperating systems and again,\n\n461\n00:23:58.991 --> 00:24:02.329\nkeep in mind how we configure these are\ngonna be a little bit different, right.\n\n462\n00:24:02.329 --> 00:24:05.855\nThe way that I can configure\na server is not necessarily the way,\n\n463\n00:24:05.855 --> 00:24:08.934\nexact way I'm gonna configure\na workstation, right.\n\n464\n00:24:08.934 --> 00:24:12.781\nOn our servers, we disable unnecessary\nservices, unnecessary ports,\n\n465\n00:24:12.781 --> 00:24:13.780\nwe clos them down.\n\n466\n00:24:13.780 --> 00:24:19.330\nA lot of times they're one in the same,\nif I disable service, the port goes away.\n\n467\n00:24:19.330 --> 00:24:21.620\nBut you disable the services and\nports on servers,\n\n468\n00:24:21.620 --> 00:24:23.980\nI might not do that on the client, right.\n\n469\n00:24:23.980 --> 00:24:28.040\nMy network devices, the network\noperating systems which most of your\n\n470\n00:24:28.040 --> 00:24:30.990\noperating systems today are network\nbased operating systems, but\n\n471\n00:24:30.990 --> 00:24:34.060\neven things like your network\nappliances out there, right.\n\n472\n00:24:34.060 --> 00:24:37.060\niOS, and I don't mean,\nit could be mobile, right,\n\n473\n00:24:37.060 --> 00:24:41.750\nI could be talking about a mobile iOS\ntoo or Android, if you will, the way\n\n474\n00:24:43.170 --> 00:24:47.260\nwe secure those operating systems are\ndifferent than our work stations, right?\n\n475\n00:24:47.260 --> 00:24:49.580\nBut even iOS talking to CISCO, right,\n\n476\n00:24:49.580 --> 00:24:54.655\nCISCO we have to steer away from the\ndefault, disable guest accounts, right.\n\n477\n00:24:54.655 --> 00:24:59.354\nIn Windows we don't use the administrative\naccount, we steer away from the defaults,\n\n478\n00:24:59.354 --> 00:25:03.292\nwe change change things like your\nusernames, your default usernames and\n\n479\n00:25:03.292 --> 00:25:06.678\npasswords, if you will,\nsteering away from those defaults.\n\n480\n00:25:06.678 --> 00:25:07.494\nA kiosk,\n\n481\n00:25:07.494 --> 00:25:11.720\nright, a kiosk is gonna be different\nthan maybe the average work station too.\n\n482\n00:25:11.720 --> 00:25:14.680\nEven though it's running the same\noperating system, could be on the same\n\n483\n00:25:14.680 --> 00:25:19.480\ntype of computer, I'm typically gonna lock\ndown a kiosk to only allow guest access\n\n484\n00:25:19.480 --> 00:25:24.790\nand only a very, very limited\namount of guest access, right.\n\n485\n00:25:24.790 --> 00:25:29.580\nSo we're gonna try to secure that\nas far as we can, all right.\n\n486\n00:25:29.580 --> 00:25:31.790\nLet's see,\nI know we got a few more minutes,\n\n487\n00:25:31.790 --> 00:25:35.170\nwe're probably gonna have to, I know we're\ngonna have to wrap this one up soon.\n\n488\n00:25:35.170 --> 00:25:39.870\nSo some of the other things that they call\nout are lease functionality, all right,\n\n489\n00:25:39.870 --> 00:25:41.190\ndon't let this confuse you.\n\n490\n00:25:41.190 --> 00:25:44.220\nLease functionality, it's the same\nthing as principle release privilege.\n\n491\n00:25:44.220 --> 00:25:47.110\nBut what we're doing is we're talking\nabout the functionality of our\n\n492\n00:25:47.110 --> 00:25:49.430\nsystems that we have with\ninside of our networks.\n\n493\n00:25:49.430 --> 00:25:53.610\nIf I'm not using FTP, if I'm not using\nTelnet, if I'm not using things like SNMP,\n\n494\n00:25:53.610 --> 00:25:57.270\nif I'm not using SMTP,\nI need to disable it.\n\n495\n00:25:57.270 --> 00:26:00.090\nI need to reduce that functionality,\nso I can reduce the attack surface.\n\n496\n00:26:00.090 --> 00:26:03.250\nSo lease functionality's the same\nthing as principle of lease privilege,\n\n497\n00:26:03.250 --> 00:26:05.880\nbut when usually when we say principle\nof lease privilege we're restricting\n\n498\n00:26:05.880 --> 00:26:06.770\nthe human's ability.\n\n499\n00:26:06.770 --> 00:26:08.420\n&gt;&gt; Access controls that way, yeah.\n\n500\n00:26:08.420 --> 00:26:10.670\n&gt;&gt; Most definitely, so\nlease functionality is saying,\n\n501\n00:26:10.670 --> 00:26:14.460\nhey, why don't we reduce\nour attack surface down to\n\n502\n00:26:14.460 --> 00:26:18.420\njust the functionality that these\ndevices are playing within our networks?\n\n503\n00:26:18.420 --> 00:26:21.090\nAll right, secure configurations.\n\n504\n00:26:21.090 --> 00:26:24.570\nAgain, secure configurations is just\nanalyzing your system and saying,\n\n505\n00:26:24.570 --> 00:26:28.630\nare the current processes that are running\non that systems, have they been secured?\n\n506\n00:26:28.630 --> 00:26:29.880\nAre they necessary, too?\n\n507\n00:26:29.880 --> 00:26:32.080\nAnd that's another thing that\nyou have to keep in mind.\n\n508\n00:26:32.080 --> 00:26:34.040\nJust because you might have a system,\n\n509\n00:26:34.040 --> 00:26:38.830\nthe ability to run a certain process on\na system doesn't mean that you should be.\n\n510\n00:26:38.830 --> 00:26:41.240\nAgain, only what is necessary.\n\n511\n00:26:42.340 --> 00:26:43.140\nWhat else do they call out?\n\n512\n00:26:43.140 --> 00:26:45.340\nThey call out things like\ntrusted operating systems.\n\n513\n00:26:45.340 --> 00:26:47.222\nWhen we talk about\ntrusted operating system,\n\n514\n00:26:47.222 --> 00:26:50.100\nall right,\nessentially what we're saying here is that\n\n515\n00:26:50.100 --> 00:26:53.960\nan operating system that provides\nmultiple layers of security, right.\n\n516\n00:26:53.960 --> 00:26:57.830\nIt's the ability for the operating\nsystem's security mechanisms to achieve\n\n517\n00:26:57.830 --> 00:27:03.910\nsome kind of compliance, if you will,\nwith average security standards.\n\n518\n00:27:03.910 --> 00:27:06.520\nWe've also mentioned things like\napplication white listing and\n\n519\n00:27:06.520 --> 00:27:07.120\nblack listing.\n\n520\n00:27:07.120 --> 00:27:09.370\nWe kind of looked at app\nblocker in a previous episode.\n\n521\n00:27:09.370 --> 00:27:14.020\nAgain, white listing is saying which\napplications I'm going to allow to run.\n\n522\n00:27:14.020 --> 00:27:17.610\nVersus blacklisting,\nsays I'm not gonna allow anything and\n\n523\n00:27:17.610 --> 00:27:22.350\nI'm gonna do more just a explicit allow,\nright, I'm gonna say I'm gonna blacklist,\n\n524\n00:27:22.350 --> 00:27:27.720\nI'm not gonna let anything run except for\nthese applications.\n\n525\n00:27:27.720 --> 00:27:32.400\nWe've talked about disabling\ndefault accounts, passwords, again,\n\n526\n00:27:32.400 --> 00:27:37.210\nkeep in mind, if you've got default system\naccounts, if you've got default passwords,\n\n527\n00:27:37.210 --> 00:27:40.610\nif I can find them out there on the\ninternet so can the hackers too, right.\n\n528\n00:27:40.610 --> 00:27:44.640\nAnd that just goes with a lot of the\ndifferent connectivity devices we have.\n\n529\n00:27:44.640 --> 00:27:47.760\nEspecially when you talk about home\nconnectivity devices cuz a lot of them get\n\n530\n00:27:47.760 --> 00:27:50.920\ndeployed and if the person's not\nexactly sure what they're doing\n\n531\n00:27:50.920 --> 00:27:52.510\nthey never steer away from the default.\n\n532\n00:27:52.510 --> 00:27:55.680\nAnd all the hacker has to do is go check\na list of vendor documentation and\n\n533\n00:27:55.680 --> 00:27:58.480\nthey can find out what those defaults are.\n\n534\n00:27:58.480 --> 00:28:01.290\nSome of the peripherals that\nwe have to worry about,\n\n535\n00:28:01.290 --> 00:28:04.160\nwe have to worry about things like,\nfor instance, wireless keyboards.\n\n536\n00:28:04.160 --> 00:28:08.609\nAnd again, any wireless device because of\nthe data that's emanating off of it could\n\n537\n00:28:08.609 --> 00:28:10.360\npotentially be captured.\n\n538\n00:28:10.360 --> 00:28:15.910\nDisplays, they tell you to put things\nlike privacy filters on them, again,\n\n539\n00:28:15.910 --> 00:28:20.620\njust to be able, so you have to sit right\nin front of them in order to see them.\n\n540\n00:28:20.620 --> 00:28:25.140\nThere is a little bit of worry with things\nlike electromagnetic emanation off of\n\n541\n00:28:25.140 --> 00:28:31.060\nthose displays that potentially they could\ngrab the information and reconstruct it.\n\n542\n00:28:31.060 --> 00:28:35.921\nWired, this is interesting, WiFi enabled\nmicro SD cards, you have things like iFi\n\n543\n00:28:35.921 --> 00:28:40.781\nout there, EASYSHARE, and again, any time\nwe talk about a wireless communication\n\n544\n00:28:40.781 --> 00:28:44.614\nbecause it is unbounded radiated energy,\nthere is a potential for\n\n545\n00:28:44.614 --> 00:28:49.980\nsomebody to stand in between that and\nactually intercept that information.\n\n546\n00:28:49.980 --> 00:28:54.490\nPrinters, they're a shared resource,\nthey can contain information that we can\n\n547\n00:28:54.490 --> 00:28:59.020\ngain access to, so for instance,\nlogs or maybe the print queue,\n\n548\n00:28:59.020 --> 00:29:01.590\nand find sensitive documents that\nhave been sent to the printer.\n\n549\n00:29:01.590 --> 00:29:05.520\nIf we can attack these, including\nthings like multi-functioning devices,\n\n550\n00:29:05.520 --> 00:29:08.640\nMFDs, that are doing\na multitude of functionality,\n\n551\n00:29:08.640 --> 00:29:13.640\ndifferent services that they're providing\ninside of a single device, like copy,\n\n552\n00:29:13.640 --> 00:29:18.320\nscan, if you will, and\nprint technologies, could be fax as well.\n\n553\n00:29:18.320 --> 00:29:19.480\nExternal storage devices,\n\n554\n00:29:19.480 --> 00:29:23.570\nwe kind of talked base doing\na doing full drive encryption.\n\n555\n00:29:23.570 --> 00:29:25.610\nUsing things like BitLocker,\nif you will, and\n\n556\n00:29:25.610 --> 00:29:29.310\nsome of the other third-parties we've\nmentioned to do full disk encryption,\n\n557\n00:29:29.310 --> 00:29:32.460\nkeep in mind external storage\nneeds to be secured as well.\n\n558\n00:29:32.460 --> 00:29:35.390\nAnd then finally, they talk about\ndigital cameras too, and again,\n\n559\n00:29:35.390 --> 00:29:38.260\ndigital cameras I would think of\nlike the removable storage in them.\n\n560\n00:29:38.260 --> 00:29:41.560\n&gt;&gt; Well, some of them can even connect\nvia WiFi to transmit those photos.\n\n561\n00:29:41.560 --> 00:29:44.840\nSo, theoretically, you could\nintercept that transmission as well.\n\n562\n00:29:44.840 --> 00:29:47.133\n&gt;&gt; Most definitely, and\nif it's NFC communication,\n\n563\n00:29:47.133 --> 00:29:49.279\nthen we could also get to it,\nso very good point.\n\n564\n00:29:49.279 --> 00:29:52.658\nSo keep in mind, anytime you've\ngot an unbounded radiated energy,\n\n565\n00:29:52.658 --> 00:29:56.810\nsomebody could be in the middle of that,\nlistening to it to scrape the information.\n\n566\n00:29:56.810 --> 00:29:59.430\nSo it's important that\nyou secure those devices.\n\n567\n00:29:59.430 --> 00:30:01.290\n&gt;&gt; All right, Wes,\nI'm looking through the list here,\n\n568\n00:30:01.290 --> 00:30:03.320\ndid we wanna take a look\nat patch management?\n\n569\n00:30:03.320 --> 00:30:06.560\nI know we spoke about it several times,\nbut I saw you had a link.\n\n570\n00:30:06.560 --> 00:30:10.570\n&gt;&gt; Yeah and I'm glad you brought that\nup cuz in past episodes we just kinda\n\n571\n00:30:10.570 --> 00:30:14.420\ntalked about Windows updates,\nwe talked about Yum and app.get,\n\n572\n00:30:14.420 --> 00:30:18.460\nif you will, WSUS if you're in a corporate\nenvironment using Windows machines.\n\n573\n00:30:18.460 --> 00:30:24.140\nBut NIST does have some information out,\nnow this is SANS patch management.\n\n574\n00:30:24.140 --> 00:30:25.900\nLet me see if I can find\nthat documentation,\n\n575\n00:30:25.900 --> 00:30:28.270\nI know I said I have\nthe link up there but.\n\n576\n00:30:28.270 --> 00:30:30.925\n&gt;&gt; And ladies and gentlemen, yes,\nwe will put that in the show notes, so\n\n577\n00:30:30.925 --> 00:30:31.962\nyou will have that as well.\n\n578\n00:30:31.962 --> 00:30:36.240\n&gt;&gt; Most definitely, so SANS has some\ngood patch management information and\n\n579\n00:30:36.240 --> 00:30:37.970\nyou guys are right out there.\n\n580\n00:30:37.970 --> 00:30:41.320\nThank you, Cherokee, we will make\nsure that you guys have access to\n\n581\n00:30:41.320 --> 00:30:43.170\nthese links cuz it's a lot\nof great information.\n\n582\n00:30:43.170 --> 00:30:46.060\nIt's taking a little bit longer\nthan I want to load it up.\n\n583\n00:30:46.060 --> 00:30:48.710\nLet's see if we can do\na reload here real quick.\n\n584\n00:30:48.710 --> 00:30:53.690\nAnd eventually we'll have a white paper\non it, if you need to know which one it\n\n585\n00:30:53.690 --> 00:30:59.370\nactually it is,\nit is Patch Management Documentation 2064.\n\n586\n00:30:59.370 --> 00:31:03.180\nAnd boy that is taking\na long time to open up.\n\n587\n00:31:03.180 --> 00:31:08.200\nSo yeah guys, check that out if you get\na chance, I'm gonna try one more thing\n\n588\n00:31:08.200 --> 00:31:11.777\nlast little thing here and-\n&gt;&gt; See I didn't mean to jinx you there.\n\n589\n00:31:11.777 --> 00:31:15.740\n&gt;&gt; No that's a, no, that's okay,\nthis is something that I really want\n\n590\n00:31:15.740 --> 00:31:20.420\npeople to see so if it takes little\nbit longer that is just fine, and\n\n591\n00:31:20.420 --> 00:31:22.210\nthis is actually a NIST standard.\n\n592\n00:31:22.210 --> 00:31:26.050\nI know I said SANS on this one but\nit is SANS reading room.\n\n593\n00:31:26.050 --> 00:31:29.950\nAnd for whatever reason it's taking\na little bit, so I'll put the links,\n\n594\n00:31:29.950 --> 00:31:34.070\nif you wil,l in the documentation\nthere for you, in the show notes so\n\n595\n00:31:34.070 --> 00:31:36.390\nthat you guys can,\nhere we go it finally loaded up.\n\n596\n00:31:36.390 --> 00:31:38.100\nLet me go ahead and show you guys this.\n\n597\n00:31:38.100 --> 00:31:40.300\nTook forever for this thing to load.\n\n598\n00:31:40.300 --> 00:31:43.455\nAnd again, they just give you\na method to the madness for\n\n599\n00:31:43.455 --> 00:31:47.632\nimplementing patch management and\nthis is from SANS Institute, right?\n\n600\n00:31:47.632 --> 00:31:49.706\nAnd they give you some good information,\n\n601\n00:31:49.706 --> 00:31:53.270\nlike understanding the risk of\npatching versus not patching, right.\n\n602\n00:31:53.270 --> 00:31:57.040\nAnd most of us would probably say,\nno, we need to do some patching.\n\n603\n00:31:57.040 --> 00:31:59.210\nBut at least you get some\nkind of formalized process,\n\n604\n00:31:59.210 --> 00:32:01.220\ncuz everybody does it\na little bit differently.\n\n605\n00:32:01.220 --> 00:32:04.770\nIf you wanna plum line then this\nis the documentation you go to,\n\n606\n00:32:04.770 --> 00:32:06.780\nbecause again,\neverybody's gonna be looking at,\n\n607\n00:32:06.780 --> 00:32:09.790\na lot of people will be looking at\nSANS for this kind of documentation.\n\n608\n00:32:09.790 --> 00:32:12.800\n&gt;&gt; Thank you Wes, and thank you ladies and\ngentlemen, but we are out of time for\n\n609\n00:32:12.800 --> 00:32:15.320\nthis episode so\nwe're gonna go ahead and sign out.\n\n610\n00:32:15.320 --> 00:32:17.190\nRemember, I'm your show\nhost Cherokee Boose.\n\n611\n00:32:17.190 --> 00:32:17.990\n&gt;&gt; And I'm Wes Bryan.\n\n612\n00:32:17.990 --> 00:32:21.184\n&gt;&gt; See you next time here at ITProTV.\n\n613\n00:32:21.184 --> 00:32:27.105\n[MUSIC]\n\n614\n00:32:27.105 --> 00:32:29.000\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "213664474"
        },
        {
          "description": "Wes and Zach breakdown secure staging deployment concepts, what is sandboxing and why its important, environment types including Development-Test-Staging-Production, Secure Baseline, then concluding with what is Integrity Measurement.",
          "length": "1327",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-4-secure_staging_deployment_concepts-051017.00_21_50_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-4-secure_staging_deployment_concepts-051017.00_21_50_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-4-secure_staging_deployment_concepts-051017.00_21_50_02.Still001-sm.jpg",
          "title": "Secure Staging Deployment Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.010 --> 00:00:05.563\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:05.563 --> 00:00:06.441\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.441 --> 00:00:08.091\n[MUSIC]\n\n4\n00:00:08.091 --> 00:00:10.681\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:10.681 --> 00:00:14.569\n&gt;&gt; Hello, and thank you for\nwatching ITProTV,\n\n6\n00:00:14.569 --> 00:00:18.055\nhelping you learn wherever you go.\n\n7\n00:00:18.055 --> 00:00:22.465\nI'm your host, Zach Memos, as we continue\non with CompTIA Security+ and right now,\n\n8\n00:00:22.465 --> 00:00:28.070\nwe're looking at secure staging deployment\nconcepts, with our IT Pro Wes Bryan.\n\n9\n00:00:28.070 --> 00:00:28.630\nHey, Wes.\n\n10\n00:00:28.630 --> 00:00:29.480\n&gt;&gt; Hey, how you doing Zach?\n\n11\n00:00:29.480 --> 00:00:30.134\nThanks for having me back.\n\n12\n00:00:30.134 --> 00:00:30.960\n&gt;&gt; Sure.\n&gt;&gt; That's right,\n\n13\n00:00:30.960 --> 00:00:35.510\nwe are going to be looking at the\ndifferent ways that you can secure your\n\n14\n00:00:35.510 --> 00:00:37.100\nstaging deployment environment.\n\n15\n00:00:37.100 --> 00:00:40.750\nSo let's go ahead, and\nwe are gonna dive right in.\n\n16\n00:00:40.750 --> 00:00:43.130\nThe objective here is\n\n17\n00:00:43.130 --> 00:00:47.640\nexplain the importance of secure\nstaging deployment concepts.\n\n18\n00:00:47.640 --> 00:00:51.920\nSo, we're gonna go ahead, we'll start off\nin this episode with that right there.\n\n19\n00:00:51.920 --> 00:00:54.900\n&gt;&gt; Awesome, so why don't we talk\nabout sandboxing right away.\n\n20\n00:00:54.900 --> 00:00:55.850\n&gt;&gt; Sandboxing, okay.\n\n21\n00:00:55.850 --> 00:00:59.690\nSo sandboxing is an interesting concept,\nand really when it comes down to it,\n\n22\n00:00:59.690 --> 00:01:04.230\nsandboxing, you could be using\nthroughout your entire deployment\n\n23\n00:01:05.540 --> 00:01:06.800\nschedule if you will.\n\n24\n00:01:06.800 --> 00:01:10.720\nSandboxing is a lot like when\nwe talk about the benefits of\n\n25\n00:01:10.720 --> 00:01:11.620\nvirtualization, right?\n\n26\n00:01:11.620 --> 00:01:14.560\nWe talk about the fact that\na virtualization, it allows us to\n\n27\n00:01:14.560 --> 00:01:17.390\nrun more than one operation system\non a single physical device.\n\n28\n00:01:17.390 --> 00:01:20.870\nAnd each operating system is\nisolated in the fact that,\n\n29\n00:01:20.870 --> 00:01:24.600\nit doesn't affect what's going on,\non another operating system, right?\n\n30\n00:01:24.600 --> 00:01:26.750\n&gt;&gt; So a sandbox is a virtual environment?\n\n31\n00:01:26.750 --> 00:01:28.720\n&gt;&gt; It is a virtualized environment,\nabsolutely.\n\n32\n00:01:28.720 --> 00:01:31.380\nNow, I will tell you that\nthere are other types of\n\n33\n00:01:31.380 --> 00:01:33.780\nways that applications\nthey sandbox themselves.\n\n34\n00:01:33.780 --> 00:01:38.000\nBut more often than not,\nthe sandboxing is gonna be a completely,\n\n35\n00:01:38.000 --> 00:01:43.410\nit's like the environment that we're\ngonna use, however, what we do inside\n\n36\n00:01:43.410 --> 00:01:48.010\nof that sandbox doesn't adversely effect\nother members of our development team.\n\n37\n00:01:48.010 --> 00:01:50.160\n&gt;&gt; That what happens in the sandbox,\nstays in the sandbox.\n\n38\n00:01:50.160 --> 00:01:52.100\n&gt;&gt; That's right,\nthat's first rule of sandboxing.\n\n39\n00:01:52.100 --> 00:01:53.386\nDon't talk about sandboxing.\n\n40\n00:01:53.386 --> 00:01:56.718\n[LAUGH] That being said,\none of the benefits of sandboxing right,\n\n41\n00:01:56.718 --> 00:02:01.640\nthe developers can utilize the sandbox\nenvironment and again, at their leisure.\n\n42\n00:02:01.640 --> 00:02:03.680\nSo the great thing about the sandboxing,\nif I don't have,\n\n43\n00:02:03.680 --> 00:02:06.210\nto let's say as management,\nI don't have to worry about\n\n44\n00:02:06.210 --> 00:02:09.980\na sandbox causing problems with\na code that the team is writing.\n\n45\n00:02:09.980 --> 00:02:13.770\nOr, bringing down an operating\nsystem that everybody's using, well,\n\n46\n00:02:13.770 --> 00:02:18.100\nwe don't really need authorization\nto be required in order for\n\n47\n00:02:18.100 --> 00:02:21.390\none of our development team\nto spin up some kind sandbox.\n\n48\n00:02:21.390 --> 00:02:23.360\nThat's the great thing about\nthings like containers, right?\n\n49\n00:02:23.360 --> 00:02:26.270\nWe can pull these containers down,\nand it gives us\n\n50\n00:02:26.270 --> 00:02:30.640\nessentially the runtime environment we\nneed without spinning up a full VM, so\n\n51\n00:02:30.640 --> 00:02:32.960\nyou can also see things like that as well.\n\n52\n00:02:32.960 --> 00:02:35.310\nBut keep in mind when\nit comes to sandboxing,\n\n53\n00:02:35.310 --> 00:02:39.550\nyou might be using a sandbox throughout\nyour entire deployment life cycle,\n\n54\n00:02:39.550 --> 00:02:42.570\nbecause of the fact that you get\nthe benefits of a virtualization.\n\n55\n00:02:42.570 --> 00:02:47.860\nThe virtualization technology and again,\nthe isolation from everybody else.\n\n56\n00:02:47.860 --> 00:02:52.059\nKeep in mind that every dev team, like I\nsaid, has access to their own sandbox.\n\n57\n00:02:52.059 --> 00:02:56.319\nAnd one of the great things, in fact, I\nwas talking to one of the other hosts that\n\n58\n00:02:56.319 --> 00:02:59.562\nactually worked in a staging and\ndeployment type solution,\n\n59\n00:02:59.562 --> 00:03:03.759\nthat he wrote script that would revert\nevery sandbox at the end of the night back\n\n60\n00:03:03.759 --> 00:03:07.085\nto a clean state, so the next morning,\npeople would come in.\n\n61\n00:03:07.085 --> 00:03:09.970\nThey would have a clean state, and\nthey could start to work again.\n\n62\n00:03:09.970 --> 00:03:13.260\nSo, sandboxing is a great thing to have,\nand because of virtualization,\n\n63\n00:03:13.260 --> 00:03:14.600\nit makes it so much easier today.\n\n64\n00:03:14.600 --> 00:03:17.080\nAnd then you add things like\ncontainerization to where we don't even\n\n65\n00:03:17.080 --> 00:03:19.330\nhave to spin up a full operating system.\n\n66\n00:03:19.330 --> 00:03:23.160\nWe can just take that environment, pull\nit down and put it on a single operating\n\n67\n00:03:23.160 --> 00:03:26.430\nsystem, and run multiple containers\non a single operating system.\n\n68\n00:03:26.430 --> 00:03:29.000\nIt makes our life a lot easier.\n\n69\n00:03:29.000 --> 00:03:33.150\n&gt;&gt; So once the sandbox exists\noutside environment types.\n\n70\n00:03:33.150 --> 00:03:33.660\n&gt;&gt; That's right.\n\n71\n00:03:33.660 --> 00:03:35.910\nAnd it's usually kind of\nassist the environment types.\n\n72\n00:03:35.910 --> 00:03:36.524\n&gt;&gt; Right.\n&gt;&gt; Right, but\n\n73\n00:03:36.524 --> 00:03:39.197\nit's not it's actual stage and\nthat's why, yes,\n\n74\n00:03:39.197 --> 00:03:42.730\nI would say it kind of sits\noutside of your environment types.\n\n75\n00:03:42.730 --> 00:03:43.862\nSo what are your environment types?\n\n76\n00:03:43.862 --> 00:03:45.180\n&gt;&gt; What are the environment types?\n\n77\n00:03:45.180 --> 00:03:46.310\n&gt;&gt; That's right.\n&gt;&gt; Hey, I wanna ask.\n\n78\n00:03:46.310 --> 00:03:49.600\n&gt;&gt; Let's go ahead, and let's dive right\nin to what those environment types are.\n\n79\n00:03:49.600 --> 00:03:53.810\nSo, they really call out four on the exam,\nI do want you to keep in mind that these\n\n80\n00:03:53.810 --> 00:03:58.280\ncould be modified,\nyou might find different names for them.\n\n81\n00:03:58.280 --> 00:03:59.800\nSo for instance in the testing phase,\n\n82\n00:03:59.800 --> 00:04:01.946\nyou might hear that's\nthe quality assurance phase.\n\n83\n00:04:01.946 --> 00:04:05.994\nSo again guys, keep in mind these\nare more the commonalities geared towards\n\n84\n00:04:05.994 --> 00:04:08.660\nthe objectives that you need to know for\nthe exam.\n\n85\n00:04:08.660 --> 00:04:11.730\nAnd they could be modified to suit\nwhatever the company is that you work for.\n\n86\n00:04:11.730 --> 00:04:14.020\nSo again, more like a guideline.\n\n87\n00:04:14.020 --> 00:04:15.650\nSo let's talk about the very first phase.\n\n88\n00:04:15.650 --> 00:04:17.320\nLets talk about developments, okay?\n\n89\n00:04:17.320 --> 00:04:22.770\nWhen we look at development,\nthis differs from a sandbox, how?\n\n90\n00:04:22.770 --> 00:04:29.224\nWell in a sandbox, keep in mind that,\nEvery member has their access\n\n91\n00:04:29.224 --> 00:04:34.300\nto their own sandbox, and not necessarily\nmembers sharing sandboxes, right?\n\n92\n00:04:34.300 --> 00:04:38.070\nThat's the great thing about them,\nright, is my sandbox, you get your own.\n\n93\n00:04:38.070 --> 00:04:41.100\nWith the development environment,\neverybody has access.\n\n94\n00:04:41.100 --> 00:04:44.400\nAll your members of the team have\naccess to the development environment.\n\n95\n00:04:44.400 --> 00:04:47.230\nWhen you're doing from concept to design,\n\n96\n00:04:47.230 --> 00:04:51.600\nany changes that are made inside of\nthat development environment could\n\n97\n00:04:51.600 --> 00:04:54.290\nadversely affect anything else\nthat somebody else is doing.\n\n98\n00:04:54.290 --> 00:05:00.060\nSo, keep in mind here that again,\nnow we're talking about authorization,\n\n99\n00:05:00.060 --> 00:05:02.980\nright, if you're in the development\nenvironment, you're part of the dev team,\n\n100\n00:05:02.980 --> 00:05:05.670\nif you're gonna make a change or\nsubmit a change,\n\n101\n00:05:05.670 --> 00:05:08.000\nyou're gonna have to get\nauthorization to make those changes.\n\n102\n00:05:08.000 --> 00:05:10.140\nIt's a little bit different\nthan the sandbox, right.\n\n103\n00:05:10.140 --> 00:05:11.920\nSandbox, I don't have to\nworry about it because,\n\n104\n00:05:11.920 --> 00:05:15.240\nif I don't like what I've changed,\nit doesn't work right, we revert it.\n\n105\n00:05:15.240 --> 00:05:18.040\nYou don't revert the whole\ndevelopment stage back, right?\n\n106\n00:05:18.040 --> 00:05:20.690\nWell, you can, and\nthat's through things like versioning,\n\n107\n00:05:20.690 --> 00:05:22.610\nversion control software as well, and\n\n108\n00:05:22.610 --> 00:05:26.580\nwe'll talk about that coming up when we\ntalk about things like secure baselines.\n\n109\n00:05:26.580 --> 00:05:28.150\nAll right, so\nwhat else here do we need to know?\n\n110\n00:05:28.150 --> 00:05:33.280\nOkay so also understand,\nthat our development environment,\n\n111\n00:05:33.280 --> 00:05:37.660\nit might not really truly mirror\nour production environment.\n\n112\n00:05:37.660 --> 00:05:41.060\nAnd what I mean by that is, let's say\nthat in your production environment,\n\n113\n00:05:41.060 --> 00:05:45.430\nthis software is gonna be running\non a combination of maybe a server,\n\n114\n00:05:45.430 --> 00:05:46.390\na web cluster, right?\n\n115\n00:05:46.390 --> 00:05:50.233\nSo ten web servers, your application\nservers, that's the front end, right,\n\n116\n00:05:50.233 --> 00:05:51.769\nthat's what the end users see.\n\n117\n00:05:51.769 --> 00:05:54.541\nAnd then maybe you're running\ntwo redundant databases, right,\n\n118\n00:05:54.541 --> 00:05:58.057\ndatabases are important because they hold\nthe information that's being entered on\n\n119\n00:05:58.057 --> 00:05:59.066\nthe front end, right?\n\n120\n00:05:59.066 --> 00:06:03.640\nSo if that's your production environment,\nright, in your development environment,\n\n121\n00:06:03.640 --> 00:06:05.790\nyou might have just a single machine.\n\n122\n00:06:05.790 --> 00:06:08.890\nRight, I mean, it might be a single server\nthat is running multiple virtual machines.\n\n123\n00:06:08.890 --> 00:06:12.090\nBut as a single server, and\nyou could say things like this.\n\n124\n00:06:12.090 --> 00:06:15.760\nMaybe you're running\nthe application server and\n\n125\n00:06:15.760 --> 00:06:17.200\nthe database on the same server.\n\n126\n00:06:17.200 --> 00:06:20.060\nNow we know that's not production,\nwe don't do that in production,\n\n127\n00:06:20.060 --> 00:06:21.260\nwe separate those two, right?\n\n128\n00:06:21.260 --> 00:06:24.440\nWe don't want somebody to be able\nto hit our web interface, and\n\n129\n00:06:24.440 --> 00:06:28.730\nthen also be able to manipulate\nthe database itself.\n\n130\n00:06:28.730 --> 00:06:32.190\nBut again,\nthis is an isolated environment.\n\n131\n00:06:32.190 --> 00:06:34.480\nJust like the sandbox,\nit's an isolated environment but\n\n132\n00:06:34.480 --> 00:06:38.090\nthe difference is here everybody has\naccess to that isolated environment.\n\n133\n00:06:38.090 --> 00:06:39.661\nSo how do we secure it?\n\n134\n00:06:39.661 --> 00:06:43.424\nWell one of the things that we can do,\nagain, it's environment isolation is that,\n\n135\n00:06:43.424 --> 00:06:46.498\nwe aren't working with servers that\nare even close to the production\n\n136\n00:06:46.498 --> 00:06:47.840\nenvironment, right?\n\n137\n00:06:47.840 --> 00:06:48.816\nIt's isolated by itself.\n\n138\n00:06:48.816 --> 00:06:51.958\nThe other thing that we can do is,\nimplement things like ACLs,\n\n139\n00:06:51.958 --> 00:06:55.890\nAccess Control Lists, Endpoint security,\nwe do auditing reviews, right?\n\n140\n00:06:55.890 --> 00:07:01.572\nWe find out who has the authority\nto access that environment.\n\n141\n00:07:01.572 --> 00:07:04.442\nAll right so then the next thing\nthat we're gonna go into is,\n\n142\n00:07:04.442 --> 00:07:06.895\nwe are gonna go into the testing phase,\nall right?\n\n143\n00:07:06.895 --> 00:07:09.945\nNow the testing phase can have different\nnames, too, you might hear it called QA,\n\n144\n00:07:09.945 --> 00:07:11.965\nright, it might be quality assurance.\n\n145\n00:07:11.965 --> 00:07:14.175\nBut now,\nnotice that we are moving closer and\n\n146\n00:07:14.175 --> 00:07:16.780\ncloser down the ladder\nto our production stage.\n\n147\n00:07:17.800 --> 00:07:21.270\nIn the testing stage however,\nthis is where we can do things like for\n\n148\n00:07:21.270 --> 00:07:23.020\ninstance code review.\n\n149\n00:07:23.020 --> 00:07:24.427\nWe do functionality checking, right?\n\n150\n00:07:24.427 --> 00:07:25.576\nWe do bug checking,\n\n151\n00:07:25.576 --> 00:07:29.435\nwe might even implement a security\ncheck point right here, right?\n\n152\n00:07:29.435 --> 00:07:33.371\nWhere we find out,\nwe hit it was stress test, right?\n\n153\n00:07:33.371 --> 00:07:35.490\nWe do things like fuzzing.\n\n154\n00:07:35.490 --> 00:07:38.935\nWe try to run our application\nin unfavorable conditions\n\n155\n00:07:38.935 --> 00:07:41.288\nto see what's gonna happen, right?\n\n156\n00:07:41.288 --> 00:07:46.363\nWe do code integrity reviews, right,\nintegrity measurements like running hash\n\n157\n00:07:46.363 --> 00:07:51.660\nfunctions, obfuscation if you will, as\nwell as doing inspections of the code too.\n\n158\n00:07:51.660 --> 00:07:53.810\nAgain, more code review.\n\n159\n00:07:53.810 --> 00:07:55.627\nKeep in mind that the testing.\n\n160\n00:07:55.627 --> 00:07:58.336\nTesting now we might go\na little bit closer again to\n\n161\n00:07:58.336 --> 00:08:02.917\nthe production environment, and the fact\nthat now we're not gonna be running maybe\n\n162\n00:08:02.917 --> 00:08:05.648\nWeb application and\ndatabase on the same server.\n\n163\n00:08:05.648 --> 00:08:07.450\nMaybe now,\nwe're splitting them off, right?\n\n164\n00:08:07.450 --> 00:08:09.870\nWe're getting, again, a little bit\ncloser to the production environment.\n\n165\n00:08:09.870 --> 00:08:13.390\nSo now we've got a web server and\na separate database server, right?\n\n166\n00:08:13.390 --> 00:08:16.200\nAgain, just suggestions here.\n\n167\n00:08:16.200 --> 00:08:20.290\nIn the testing phase, this might be where\nyou're doing your unit testing, right,\n\n168\n00:08:20.290 --> 00:08:24.817\nbreaking down your code into smaller\nindividual programs, right, and\n\n169\n00:08:24.817 --> 00:08:26.240\ndoing unit testing.\n\n170\n00:08:26.240 --> 00:08:29.650\nNow I do want you to keep\nin mind that this process\n\n171\n00:08:29.650 --> 00:08:31.770\ndoesn't necessarily\nalways go sequentially.\n\n172\n00:08:31.770 --> 00:08:34.942\nWe would like to, and I'm sure the C level\nemployees would love it if it's sequential\n\n173\n00:08:34.942 --> 00:08:37.370\nwhen we go from development right into,\n\n174\n00:08:37.370 --> 00:08:42.610\nif you will, testing, and\nthen right into staging and production.\n\n175\n00:08:42.610 --> 00:08:44.670\nThat doesn't necessarily happen.\n\n176\n00:08:44.670 --> 00:08:47.300\nIt's actually more of\na kind of a cyclic process.\n\n177\n00:08:47.300 --> 00:08:51.200\nThat means that if I go into\nthe testing phase, and let's say,\n\n178\n00:08:51.200 --> 00:08:54.320\nthe functionality that we're looking for\nin doing the code review, functionality\n\n179\n00:08:54.320 --> 00:08:58.250\ntesting, bug checking, whatever it\nmight be, is completely hosed up.\n\n180\n00:08:58.250 --> 00:09:00.210\nWell, we might have to go back\ninto the development phase.\n\n181\n00:09:00.210 --> 00:09:04.310\nSo keep that in mind, that we might go\nfrom one phase to the next as we're\n\n182\n00:09:04.310 --> 00:09:09.000\ngetting closer and closer to the\nproduction phase or stage, if you will.\n\n183\n00:09:09.000 --> 00:09:12.950\nAnd here's redundant, now we've got the\nstaging stage to the stage to the stage.\n\n184\n00:09:12.950 --> 00:09:16.061\n&gt;&gt; Are you from the redundancy\noffice of the redundancy department?\n\n185\n00:09:16.061 --> 00:09:19.528\n&gt;&gt; That's right, [LAUGH] in\nthe dictionary, next to redundancy,\n\n186\n00:09:19.528 --> 00:09:20.884\nit says see redundancy.\n\n187\n00:09:20.884 --> 00:09:27.530\nSo what is the staging area now,\nor the staging stage, if you will?\n\n188\n00:09:27.530 --> 00:09:33.080\nWell, this is where we start to\ncompletely mirror, it is a replica\n\n189\n00:09:33.080 --> 00:09:36.460\nof what the production environment is,\nand that is important to keep in mind.\n\n190\n00:09:36.460 --> 00:09:40.070\nRight, the staging environment not only\nbeing a complete replica, let’s say that,\n\n191\n00:09:40.070 --> 00:09:42.750\nremember we said there were ten\nweb servers and a web cluster, and\n\n192\n00:09:42.750 --> 00:09:44.830\nthere’s also two redundant databases?\n\n193\n00:09:44.830 --> 00:09:45.360\nWell, guess what?\n\n194\n00:09:45.360 --> 00:09:49.213\nIn your staging environment, that's what's\ngonna be sitting in a server closet,\n\n195\n00:09:49.213 --> 00:09:52.523\nright, because it is as close to\nthe production environment, in fact,\n\n196\n00:09:52.523 --> 00:09:53.630\nit mirrors it, right?\n\n197\n00:09:53.630 --> 00:09:55.070\nAnd inside a staging,\n\n198\n00:09:55.070 --> 00:09:58.860\nright, projects might be moved\nfrom staging back to testing.\n\n199\n00:09:58.860 --> 00:10:00.044\nKeep that in mind as well.\n\n200\n00:10:00.044 --> 00:10:05.500\nA product in staging might stay in\nstaging for a short period of time.\n\n201\n00:10:05.500 --> 00:10:06.007\nLet me tell you why.\n\n202\n00:10:06.007 --> 00:10:08.968\nBecause since we are right on\nthe outskirts of going into\n\n203\n00:10:08.968 --> 00:10:13.578\nthe production environment, how about I\ntake 15 or 20 of our tech-savvy people?\n\n204\n00:10:13.578 --> 00:10:16.691\nAnd instead of deploying to production,\nwe deploy to staging,\n\n205\n00:10:16.691 --> 00:10:18.197\nessentially stage it to them.\n\n206\n00:10:18.197 --> 00:10:21.395\nAnd we let it run for\ntwo weeks on their machines.\n\n207\n00:10:21.395 --> 00:10:24.445\nAnd we test it on the backend,\nwe do things like monitoring,\n\n208\n00:10:24.445 --> 00:10:27.345\nwe do things like auditing reviews,\nif you will.\n\n209\n00:10:27.345 --> 00:10:30.048\nAnd we see, is the functionality\nwhere we need it to be?\n\n210\n00:10:30.048 --> 00:10:31.430\n&gt;&gt; I think it makes perfect sense.\n\n211\n00:10:31.430 --> 00:10:34.223\n&gt;&gt; That's right, and if it's not,\nwell, then we just turn around,\n\n212\n00:10:34.223 --> 00:10:36.120\nwe move it back to testing again.\n\n213\n00:10:36.120 --> 00:10:38.704\nAgain, keep in mind that\nwe could move back and\n\n214\n00:10:38.704 --> 00:10:40.969\nforth between these different phases.\n\n215\n00:10:40.969 --> 00:10:45.640\nAll right,\nlet's see if I forgot anything here.\n\n216\n00:10:45.640 --> 00:10:48.750\nWell, next one is gonna be\nthe production environment.\n\n217\n00:10:48.750 --> 00:10:51.160\nNow the production environment\nis the final stage.\n\n218\n00:10:51.160 --> 00:10:52.790\nKeep in mind, though,\n\n219\n00:10:52.790 --> 00:10:57.450\nit does not mean that we're\ngoing to stop monitoring, right?\n\n220\n00:10:57.450 --> 00:11:00.560\nI want you to think of a piece of\nsoftware maybe that you've downloaded,\n\n221\n00:11:00.560 --> 00:11:02.290\nwhatever software it might be.\n\n222\n00:11:02.290 --> 00:11:06.080\nLet's take the Office suite, all right,\nso for Microsoft Office, right?\n\n223\n00:11:06.080 --> 00:11:10.370\nYou might notice that over time,\nthey release updates, right?\n\n224\n00:11:10.370 --> 00:11:11.870\nThey release security patches.\n\n225\n00:11:11.870 --> 00:11:12.870\nWhy is that?\n\n226\n00:11:12.870 --> 00:11:14.770\nWell, in the production phase,\n\n227\n00:11:14.770 --> 00:11:17.140\nyou're going to be listening\nto things like feedback.\n\n228\n00:11:17.140 --> 00:11:20.650\nYou're gonna be looking at statistical\nutilization, right, analysis.\n\n229\n00:11:20.650 --> 00:11:22.710\nAnd you're gonna analyze that information,\n\n230\n00:11:22.710 --> 00:11:25.220\nand you're gonna find out if\nthere are additional bugs.\n\n231\n00:11:25.220 --> 00:11:28.581\nI will tell you one thing that\ndiffers from production and\n\n232\n00:11:28.581 --> 00:11:31.530\nstaging, things go into production.\n\n233\n00:11:31.530 --> 00:11:34.140\nThey never go out of production,\nall right, so keep that in mind.\n\n234\n00:11:34.140 --> 00:11:37.719\nAnd what I mean by that is if we're in\nthe staging phase, and we find a problem,\n\n235\n00:11:37.719 --> 00:11:38.601\nwe do code review.\n\n236\n00:11:38.601 --> 00:11:41.201\nWe take our integrity measurements, and\n\n237\n00:11:41.201 --> 00:11:45.780\nwe find out that something is\nnot where it's supposed to be.\n\n238\n00:11:45.780 --> 00:11:46.430\nWhat do we do?\n\n239\n00:11:46.430 --> 00:11:48.600\nWe move it from staging back\nup to testing, all right?\n\n240\n00:11:49.940 --> 00:11:51.940\nIt doesn't work that way in production.\n\n241\n00:11:51.940 --> 00:11:54.010\nThings go into production.\n\n242\n00:11:54.010 --> 00:11:56.610\nThey never get taken out of production.\n\n243\n00:11:56.610 --> 00:11:58.540\nSo keep in mind your staging area.\n\n244\n00:11:58.540 --> 00:12:01.990\nYour staging area is where it's supposed\nto be if you think you have to move back\n\n245\n00:12:01.990 --> 00:12:03.570\nin this process.\n\n246\n00:12:03.570 --> 00:12:06.330\nOnce you go to production,\nyou don't come out of production and\n\n247\n00:12:06.330 --> 00:12:07.830\ngo back to staging, right?\n\n248\n00:12:07.830 --> 00:12:11.141\nSo let's say, for instance,\nthey released the next Office Suite,\n\n249\n00:12:11.141 --> 00:12:13.380\nI think we're on 2016 is the current one.\n\n250\n00:12:13.380 --> 00:12:15.620\nLet's say 2018, they release.\n\n251\n00:12:15.620 --> 00:12:18.470\nWe don't take it back after you\nrelease it to the market, right?\n\n252\n00:12:18.470 --> 00:12:20.937\nYou don't take everything back,\nyou just can't do that.\n\n253\n00:12:20.937 --> 00:12:24.630\nSo keep in mind that's\nthe way this process works.\n\n254\n00:12:24.630 --> 00:12:27.750\nOnce you're in the production phase, you\ndon't come out of the production phase.\n\n255\n00:12:27.750 --> 00:12:32.023\nSo it is important that you make sure that\nyou have your integrity measurements.\n\n256\n00:12:32.023 --> 00:12:35.486\nThey talk about security base lines too,\nand we've talked about this in\n\n257\n00:12:35.486 --> 00:12:39.250\nthe software development life cycle,\nthrough things like version control.\n\n258\n00:12:39.250 --> 00:12:42.842\nImagine we get to a certain point\nin our development process,\n\n259\n00:12:42.842 --> 00:12:44.714\nmaybe we're in testing phase.\n\n260\n00:12:44.714 --> 00:12:48.488\nAnd we think up until this point,\nall of our code is good.\n\n261\n00:12:48.488 --> 00:12:51.402\nNow we still got more work to do,\nbut what we have now is good.\n\n262\n00:12:51.402 --> 00:12:56.249\nWell, I'm gonna wanna make sure\nthat becomes our baseline, so\n\n263\n00:12:56.249 --> 00:13:00.018\nthat any progress that we make or\nwe move forward,\n\n264\n00:13:00.018 --> 00:13:05.770\nif it causes problems, well,\nwe can roll back to the secure baseline.\n\n265\n00:13:05.770 --> 00:13:08.070\nThink of it as kinda like I was\nsaying about your sandbox, right?\n\n266\n00:13:08.070 --> 00:13:09.950\nSandbox, we can roll back,\nand we can clean it up.\n\n267\n00:13:09.950 --> 00:13:13.900\nNext morning,\nit's as fresh as we didn't even touch it.\n\n268\n00:13:13.900 --> 00:13:17.670\nWell, think about your secure baseline\nas being that point where your\n\n269\n00:13:17.670 --> 00:13:19.420\ncode is where it needs to be.\n\n270\n00:13:19.420 --> 00:13:21.647\nRight, now you're still gonna\nbe developing more features.\n\n271\n00:13:21.647 --> 00:13:23.657\nYou're not production, right?\n\n272\n00:13:23.657 --> 00:13:27.110\nWe're not putting this into production,\nbut the great thing is,\n\n273\n00:13:27.110 --> 00:13:28.158\nfrom this point on,\n\n274\n00:13:28.158 --> 00:13:32.490\nif any changes are made that need to be\nundone, do things like versioning control.\n\n275\n00:13:32.490 --> 00:13:35.798\nWe can roll back to that earlier\nversion and then move forward, so\n\n276\n00:13:35.798 --> 00:13:38.360\nkinda undoing anything that\nmight cause problems, right?\n\n277\n00:13:38.360 --> 00:13:39.820\nSo it's great to have that too.\n\n278\n00:13:39.820 --> 00:13:41.290\n&gt;&gt; It's like unwrapping a present.\n\n279\n00:13:41.290 --> 00:13:42.100\n&gt;&gt; That's right.\n\n280\n00:13:42.100 --> 00:13:44.400\n&gt;&gt; Yeah, and so it's from secure baseline,\n\n281\n00:13:44.400 --> 00:13:46.345\nwe're going into integrity measurement,\nright?\n\n282\n00:13:46.345 --> 00:13:49.700\n&gt;&gt; Yep, integrity measurements and\nwe've kind of called them out,\n\n283\n00:13:49.700 --> 00:13:50.998\nas we've gone through here.\n\n284\n00:13:50.998 --> 00:13:55.720\nReally, integrity measurements\nare about a couple of things, right?\n\n285\n00:13:55.720 --> 00:13:57.297\nWhen we talked about integrity,\n\n286\n00:13:57.297 --> 00:14:01.160\nwe talk about it in the concept of\nthings like files, communications.\n\n287\n00:14:01.160 --> 00:14:04.745\nA lot of times,\nwe talk about hashing values, right?\n\n288\n00:14:04.745 --> 00:14:09.868\nI run an algorithm across that code,\nproduces a fixed link value.\n\n289\n00:14:09.868 --> 00:14:11.867\nAnd then if we check that\ncode on the other end,\n\n290\n00:14:11.867 --> 00:14:14.135\nwe run it through the same\nmathematical algorithm.\n\n291\n00:14:14.135 --> 00:14:18.092\nHopefully, the outputs match,\nwe've maintained integrity.\n\n292\n00:14:18.092 --> 00:14:21.332\nThis is more about things like quality\nassurance and quality control, all right?\n\n293\n00:14:21.332 --> 00:14:24.152\nWhen we talk about things like\nquality assurance, this is part of\n\n294\n00:14:24.152 --> 00:14:29.592\na quality management that essentially\nis focused on providing confidence.\n\n295\n00:14:29.592 --> 00:14:34.310\nThat whatever the quality standard or\ngoal is, that it's going to be fulfilled.\n\n296\n00:14:34.310 --> 00:14:38.053\nThink of it as a positive declaration,\nif you will, of a quality fulfillment, and\n\n297\n00:14:38.053 --> 00:14:41.808\nit's really process focused, it's how\nthat process is going to happen, right?\n\n298\n00:14:41.808 --> 00:14:48.270\nIt's the verification that the process\nis happening the way it should happen.\n\n299\n00:14:48.270 --> 00:14:50.250\nUnlike something like quality control,\n\n300\n00:14:50.250 --> 00:14:53.520\nnow quality control is the part of\nquality management, if you will,\n\n301\n00:14:53.520 --> 00:14:57.560\nthat's responsible on actually\nfulfilling the quality requests.\n\n302\n00:14:57.560 --> 00:15:00.270\nAll right, so not verification,\n\n303\n00:15:00.270 --> 00:15:04.900\nbut more validation, and\nit's focused on the product itself.\n\n304\n00:15:04.900 --> 00:15:06.300\nSo when we say quality assurance,\n\n305\n00:15:06.300 --> 00:15:10.150\nwe're looking at the process,\nmore than we are the actual product.\n\n306\n00:15:10.150 --> 00:15:13.240\nWhen we look at quality control,\nwe're saying hey,\n\n307\n00:15:13.240 --> 00:15:19.020\nlet's inspect the product and see if\nit met what the quality assurance was.\n\n308\n00:15:19.020 --> 00:15:22.804\nSo again, keep in mind that\nthings like quality assurance,\n\n309\n00:15:22.804 --> 00:15:26.601\nthey're focused on the process\nof preventing the defects.\n\n310\n00:15:26.601 --> 00:15:29.496\nQuality control is identifying defects,\nright, so\n\n311\n00:15:29.496 --> 00:15:32.890\nthe difference between verification and\nvalidation.\n\n312\n00:15:32.890 --> 00:15:35.570\nQuality control is about\nvalidating that the product\n\n313\n00:15:35.570 --> 00:15:40.230\nmeets whatever the quality level was that\nwe guaranteed by the quality assurance.\n\n314\n00:15:40.230 --> 00:15:41.856\n&gt;&gt; So once again,\nit's checks and balances.\n\n315\n00:15:41.856 --> 00:15:42.913\n&gt;&gt; Yeah, most definitely.\n\n316\n00:15:42.913 --> 00:15:43.760\n&gt;&gt; Yeah, absolutely.\n\n317\n00:15:43.760 --> 00:15:48.932\n&gt;&gt; So again, as you can see,\nthey call that a four step process.\n\n318\n00:15:48.932 --> 00:15:53.190\nKeep in mind that there are many different\nways that we can secure this environment.\n\n319\n00:15:53.190 --> 00:15:56.092\nKind of just recapping some\nof them Remember sandboxing.\n\n320\n00:15:56.092 --> 00:15:58.977\nI don't have it up here but sandboxing is\na great way to secure the environment.\n\n321\n00:15:58.977 --> 00:16:03.014\nAnd the fact that I don't have to worry\nabout changes having an adverse affect on\n\n322\n00:16:03.014 --> 00:16:06.380\nwhat another portion of\nthe development team is doing.\n\n323\n00:16:06.380 --> 00:16:07.610\nWe move it into development.\n\n324\n00:16:07.610 --> 00:16:09.580\nKeep in mind we could\nstill be using sandboxing.\n\n325\n00:16:09.580 --> 00:16:12.007\nBut you keep in mind that when you're in\nthe development phase you usually have\n\n326\n00:16:12.007 --> 00:16:12.902\nmultiple members of a team.\n\n327\n00:16:12.902 --> 00:16:17.467\nAnd each member of that team has access to\nthe environment which means that changes\n\n328\n00:16:17.467 --> 00:16:20.650\nthat need to be made are gonna\nhave to be authorized.\n\n329\n00:16:20.650 --> 00:16:22.570\nIt's still environment isolation,\n\n330\n00:16:22.570 --> 00:16:26.720\nwe haven't mirrored any\nproduction environment at all.\n\n331\n00:16:26.720 --> 00:16:31.280\nWe're gonna use concepts or technologies\nlike containerization and virtualization.\n\n332\n00:16:31.280 --> 00:16:34.002\nWe're gonna use endpoint security and\naccess controls.\n\n333\n00:16:34.002 --> 00:16:39.180\nWe wanna make sure that only authorized\npeople have access to the dev environment.\n\n334\n00:16:39.180 --> 00:16:42.332\nI don't know a bit of code,\nI can spell C++ on a good day.\n\n335\n00:16:42.332 --> 00:16:42.845\nMaybe?\n&gt;&gt; [LAUGH]\n\n336\n00:16:42.845 --> 00:16:44.475\n&gt;&gt; So you don't want me.\n\n337\n00:16:44.475 --> 00:16:45.484\nI can help you fix your operating system.\n\n338\n00:16:45.484 --> 00:16:48.023\nI can help you troubleshoot your network.\n\n339\n00:16:48.023 --> 00:16:48.765\nBut when it comes\n\n340\n00:16:48.765 --> 00:16:52.051\nto running code I shouldn't have access\nto that dev environment as I could\n\n341\n00:16:52.051 --> 00:16:53.650\ncause problems, right.\n\n342\n00:16:53.650 --> 00:16:56.502\nAnd that's why we wanna control who has\naccess to any one of these stages for\n\n343\n00:16:56.502 --> 00:16:57.054\nthat matter.\n\n344\n00:16:57.054 --> 00:17:01.262\nBut it definitely when you're worried\nabout integrity you don't want\n\n345\n00:17:01.262 --> 00:17:05.630\nunauthorized people having access\nto this information, right?\n\n346\n00:17:05.630 --> 00:17:08.860\nAgain, remember when we move into the\ntesting phase this is where we're gonna do\n\n347\n00:17:08.860 --> 00:17:11.820\nthings like we're actually\nworking with our data.\n\n348\n00:17:11.820 --> 00:17:16.100\nWorking with the code if you will,\nwe're doing functionality testing.\n\n349\n00:17:16.100 --> 00:17:19.770\nCould be stress testing,\nmaking sure that our\n\n350\n00:17:20.770 --> 00:17:24.450\nproduct is running the way\nthat it's intended to run.\n\n351\n00:17:24.450 --> 00:17:28.304\nAgain, throwing things at it maybe in\nunfavorable conditions, do we get crashes?\n\n352\n00:17:28.304 --> 00:17:29.886\nDo we get bugs?\n\n353\n00:17:29.886 --> 00:17:33.740\nIs it performing the way we expect it to?\n\n354\n00:17:33.740 --> 00:17:36.315\nSo for instance we do things like fuzzing,\nright?\n\n355\n00:17:36.315 --> 00:17:39.740\nJust send that program as much\nrandom information as you can\n\n356\n00:17:39.740 --> 00:17:41.150\nand see what happens.\n\n357\n00:17:41.150 --> 00:17:44.570\nAgain, does it cause\nthe application to hang?\n\n358\n00:17:44.570 --> 00:17:47.010\nDoes it cause the application to crash?\n\n359\n00:17:47.010 --> 00:17:49.410\nIf it does,\ndo we have things like memory dumps?\n\n360\n00:17:49.410 --> 00:17:50.930\nAre we reviewing the memory dumps?\n\n361\n00:17:50.930 --> 00:17:51.790\nWhat is causing the issue, right?\n\n362\n00:17:51.790 --> 00:17:57.345\nAll in the testing phase then we do things\nlike making sure that we have integrity,\n\n363\n00:17:57.345 --> 00:17:57.960\nright?\n\n364\n00:17:57.960 --> 00:18:00.620\nGetting to a secure point.\n\n365\n00:18:00.620 --> 00:18:04.445\nWhere we know that our code has come so\nfar where we can move to the next phase.\n\n366\n00:18:04.445 --> 00:18:06.362\nAnd that becomes a baseline so\n\n367\n00:18:06.362 --> 00:18:11.041\nthat if we implement changes later down\nthe way and they call as an adverse\n\n368\n00:18:11.041 --> 00:18:14.820\neffect we can always roll back\nto an earlier point in time.\n\n369\n00:18:14.820 --> 00:18:19.080\n&gt;&gt; And remember that in projection,\nthings go in but nothing comes out.\n\n370\n00:18:19.080 --> 00:18:20.729\n&gt;&gt; That's right,\nonce you get into the production phase.\n\n371\n00:18:20.729 --> 00:18:24.611\nYou're not taking things out of production\nand going back into the staging phase and\n\n372\n00:18:24.611 --> 00:18:26.810\nthat's the importance\nof that staging phase.\n\n373\n00:18:26.810 --> 00:18:28.240\nAgain, things like, and\n\n374\n00:18:28.240 --> 00:18:32.310\nyou can have security check points\nthroughout this process making sure that\n\n375\n00:18:32.310 --> 00:18:35.300\nyou're not opening yourself up\nto vulnerabilities if you will.\n\n376\n00:18:35.300 --> 00:18:37.530\nAgain, continue audit and logging.\n\n377\n00:18:37.530 --> 00:18:42.100\nRemember that staging environment pretty\nmuch mirrors the production environment.\n\n378\n00:18:42.100 --> 00:18:46.470\nAnd this is where, you can consider this\nkind of like your pre-deployment, right.\n\n379\n00:18:46.470 --> 00:18:49.954\nIf I'm gonna deploy it I don't wanna\ndeploy it to 100 users and then have those\n\n380\n00:18:49.954 --> 00:18:53.148\n100 users have a bad experience and\nnow they're reporting back to me.\n\n381\n00:18:53.148 --> 00:18:58.003\nI would rather deploy it in the staging\nphase to, like I said, 10 or\n\n382\n00:18:58.003 --> 00:19:03.560\n15 of our tech savvy individuals so\nthey can give us great feedback, right?\n\n383\n00:19:03.560 --> 00:19:06.430\nThey can give us feedback that is useful.\n\n384\n00:19:06.430 --> 00:19:11.610\nNot well it's slow or no I just don't like\nthe experience or it took too long, right?\n\n385\n00:19:11.610 --> 00:19:14.982\nIf you give it to the tech savvy user,\nthe tech savvy user can say I can give you\n\n386\n00:19:14.982 --> 00:19:17.791\n,information about what's going\non based on my experience.\n\n387\n00:19:17.791 --> 00:19:22.261\nAnd that's information that you can\nutilize to maybe fix things like\n\n388\n00:19:22.261 --> 00:19:24.040\nfunctionality flaws.\n\n389\n00:19:24.040 --> 00:19:26.020\n&gt;&gt; So staging is like a dress rehearsal.\n\n390\n00:19:26.020 --> 00:19:26.854\n&gt;&gt; It absolutely is.\n&gt;&gt; Yeah.\n\n391\n00:19:26.854 --> 00:19:28.130\n&gt;&gt; That's a great way to put it.\n\n392\n00:19:28.130 --> 00:19:29.646\nIt's your dress rehearsal\nbefore you say I do.\n\n393\n00:19:29.646 --> 00:19:32.772\n'Cuz remember well,\nI guess it's not so true.\n\n394\n00:19:32.772 --> 00:19:33.874\n&gt;&gt; [LAUGH]\n&gt;&gt; Once you say, I do,\n\n395\n00:19:33.874 --> 00:19:35.064\nyou can't say I don't after the fact.\n\n396\n00:19:35.064 --> 00:19:37.017\n&gt;&gt; Well.\n&gt;&gt; Again, I was gonna say, well,\n\n397\n00:19:37.017 --> 00:19:38.285\nwe really can't say that.\n\n398\n00:19:38.285 --> 00:19:43.149\n&gt;&gt; That's right, once we get to the\nproduction phase now you're not really,\n\n399\n00:19:43.149 --> 00:19:44.061\nyou're not so\n\n400\n00:19:44.061 --> 00:19:48.630\nmuch just isolated to feedback if you\nwill from your tech savvy people.\n\n401\n00:19:48.630 --> 00:19:51.110\nNow you're getting feedback\nfrom your customers, right?\n\n402\n00:19:51.110 --> 00:19:54.570\nAnd that is important but also one\nof the things that I didn't mention\n\n403\n00:19:54.570 --> 00:19:59.670\nis when we talk about the production phase\nkeep in mind that the job isn't done then.\n\n404\n00:19:59.670 --> 00:20:01.243\nJob just isn't done yet.\n\n405\n00:20:01.243 --> 00:20:06.012\nYour life cycle of your software is\nup until the point that you will not\n\n406\n00:20:06.012 --> 00:20:08.080\nsupport it anymore, right?\n\n407\n00:20:08.080 --> 00:20:10.780\nSo this is an all in production\nenvironment still an ongoing thing.\n\n408\n00:20:10.780 --> 00:20:14.960\nYou continuously monitoring for\nthe performance, your functionality, and\n\n409\n00:20:14.960 --> 00:20:16.030\nsecurity.\n\n410\n00:20:16.030 --> 00:20:16.980\nWhy do I say that?\n\n411\n00:20:16.980 --> 00:20:18.760\nWell this is why we have updates, right?\n\n412\n00:20:18.760 --> 00:20:20.720\nThis is why they patch software.\n\n413\n00:20:20.720 --> 00:20:25.480\nA lot of times they patch software for\ntwo reasons,\n\n414\n00:20:25.480 --> 00:20:28.830\na functionality flaw for\nsecurity vulnerability, right?\n\n415\n00:20:28.830 --> 00:20:32.320\nWe have to keep continuous monitoring.\n\n416\n00:20:32.320 --> 00:20:36.860\nAgain take that feedback from your end\nusers, your customers if you will.\n\n417\n00:20:36.860 --> 00:20:40.560\nBecause then it might make\ngive you good feedback.\n\n418\n00:20:40.560 --> 00:20:43.794\nMaybe you need to go a version\n1.1 rather than 1.0.\n\n419\n00:20:43.794 --> 00:20:47.355\nOr if you're gonna release the next\nversion you can gather all that\n\n420\n00:20:47.355 --> 00:20:48.190\ninformation.\n\n421\n00:20:48.190 --> 00:20:50.740\nIt can be very useful and\nsave you a lot of time and\n\n422\n00:20:50.740 --> 00:20:55.020\nheadache as you maybe deploy\nthe next revision of whatever\n\n423\n00:20:55.020 --> 00:20:57.440\nthe application might be\nthat you're developing.\n\n424\n00:20:57.440 --> 00:21:00.550\n&gt;&gt; Awesome, and you know once you\nmake it so easy to understand.\n\n425\n00:21:00.550 --> 00:21:04.265\nSecure staging, deployment concepts\npretty easy to understand though?\n\n426\n00:21:04.265 --> 00:21:07.326\n&gt;&gt; Yeah, and I'll tell you it's not so\nsometimes when you look\n\n427\n00:21:07.326 --> 00:21:10.485\nat some of these concepts maybe\nthere not the funnest things.\n\n428\n00:21:10.485 --> 00:21:13.890\nCuz I love the security side of it you\nknow when we're talking about hacking and\n\n429\n00:21:13.890 --> 00:21:15.960\ntacking and how do we prevent that?\n\n430\n00:21:15.960 --> 00:21:18.053\nBut it will be something that\nthey could potentially ask you on\n\n431\n00:21:18.053 --> 00:21:18.905\nthe security plus exam.\n\n432\n00:21:18.905 --> 00:21:20.613\nSo know the terminology.\n\n433\n00:21:20.613 --> 00:21:23.470\nKeep in mind it's not\na ones size fits all.\n\n434\n00:21:23.470 --> 00:21:26.787\nAnd it will be something that will\nbe kind of tailored to whatever your\n\n435\n00:21:26.787 --> 00:21:27.710\norganization is.\n\n436\n00:21:27.710 --> 00:21:29.481\nAnd it might have additional steps but\n\n437\n00:21:29.481 --> 00:21:33.840\nthese are more the commonalities that\nyou should know for the Security+ exam.\n\n438\n00:21:33.840 --> 00:21:35.635\n&gt;&gt; Cool and Wes,\nlet's do a dress rehearsal.\n\n439\n00:21:35.635 --> 00:21:37.979\n&gt;&gt; [LAUGH]\n&gt;&gt; I'm just throwing it out there.\n\n440\n00:21:37.979 --> 00:21:38.748\n&gt;&gt; No, I don't want to do.\n\n441\n00:21:38.748 --> 00:21:39.946\n[CROSSTALK]\n&gt;&gt; No, no, no, no, no.\n\n442\n00:21:39.946 --> 00:21:42.170\n&gt;&gt; [LAUGH]\n&gt;&gt; Security staging, deployment concepts,\n\n443\n00:21:42.170 --> 00:21:43.730\nthanks very very much.\n\n444\n00:21:43.730 --> 00:21:48.088\nHey, I'm your host, Zack Nemmis for\nCompTIA Security Plus and thanks for\n\n445\n00:21:48.088 --> 00:21:49.274\nwatching ITProTV.\n\n446\n00:21:49.274 --> 00:21:51.710\n&gt;&gt; And I'm Wes Bryan.\n\n447\n00:21:51.710 --> 00:21:53.950\n&gt;&gt; And we will see you next time.\n\n448\n00:21:53.950 --> 00:21:59.664\n[MUSIC]\n\n449\n00:21:59.664 --> 00:22:02.514\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217169331"
        },
        {
          "description": "In this episode, Cherokee and Wes discuss the security implications of embedded systems. They explain how SCADA systems can be used to perform pretty serious attacks. They also point out additional elements to consider such as IoT devices, HVAC systems, systems on a chip (SoC) and real-time operating system (RTOS) to name a few.",
          "length": "1628",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-5-security_implications_of_embedded_systems-041417-PGM.00_26_54_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-5-security_implications_of_embedded_systems-041417-PGM.00_26_54_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-5-security_implications_of_embedded_systems-041417-PGM.00_26_54_23.Still001-sm.jpg",
          "title": "Security Implications of Embedded Systems",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:03.131\nWelcome to ITProTV,\nI'm your host Don [CROSSTALK]\n\n2\n00:00:03.131 --> 00:00:03.938\n&gt;&gt; Coming at you live from\n\n3\n00:00:03.938 --> 00:00:04.833\nSan Francisco [CROSSTALK]\n\n4\n00:00:04.833 --> 00:00:07.626\n[MUSIC]\n\n5\n00:00:07.626 --> 00:00:10.100\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:10.100 --> 00:00:14.582\n&gt;&gt; Welcome ladies and\ngentlemen to your Security+ series.\n\n7\n00:00:14.582 --> 00:00:16.900\nI'm your show host Cherokee Boose.\n\n8\n00:00:16.900 --> 00:00:19.790\nIn this episode we're looking at\nimplementations of different types\n\n9\n00:00:19.790 --> 00:00:21.340\nof embedded systems.\n\n10\n00:00:21.340 --> 00:00:24.000\nWith us today we have Mr.\nWes Bryan back in studios.\n\n11\n00:00:24.000 --> 00:00:24.859\nThank you for joining us Wes.\n\n12\n00:00:24.859 --> 00:00:26.466\n&gt;&gt; Hey thanks for having me back Cherokee.\n\n13\n00:00:26.466 --> 00:00:30.040\nThat's right we are gonna be looking at\nquite a few different systems here that we\n\n14\n00:00:30.040 --> 00:00:31.050\nhave to worry about.\n\n15\n00:00:31.050 --> 00:00:33.522\nI would at least take into\nconsideration because so\n\n16\n00:00:33.522 --> 00:00:37.845\nfar what we've been traditionally talking\nabout are our traditional systems, right.\n\n17\n00:00:37.845 --> 00:00:40.141\nWe've been talking about things\nlike network appliances,\n\n18\n00:00:40.141 --> 00:00:42.050\nwe've been talking about work stations.\n\n19\n00:00:42.050 --> 00:00:44.440\nTalking about servers and laptops.\n\n20\n00:00:44.440 --> 00:00:46.845\nWell we're gonna go a little\nbit off the beaten path.\n\n21\n00:00:46.845 --> 00:00:49.864\nAnd we're gonna talk about some\nsystems that, while they are common,\n\n22\n00:00:49.864 --> 00:00:53.650\nmaybe it's not commonplace to think\nabout the security that's behind them.\n\n23\n00:00:53.650 --> 00:00:57.090\nAnd one of the very first things that\nthey call out are things like our\n\n24\n00:00:57.090 --> 00:01:00.860\nSCADAS systems, Supervisory Control and\nData Acquisition Systems.\n\n25\n00:01:00.860 --> 00:01:04.720\nAnd one of the things that you\nreally have to keep in mind about\n\n26\n00:01:04.720 --> 00:01:07.620\nSCADA based systems is the fact that\nwe've got a lot of moving parts.\n\n27\n00:01:07.620 --> 00:01:11.010\nIn fact I've got a diagram\nhere on my screen here.\n\n28\n00:01:11.010 --> 00:01:14.100\nAnd it kinda just shows you some of\nthe different parts that you could see\n\n29\n00:01:14.100 --> 00:01:15.950\ninside of a SCADA system, right.\n\n30\n00:01:15.950 --> 00:01:18.760\nWe have things like the supervisory\nsystem here, right.\n\n31\n00:01:18.760 --> 00:01:20.780\nThat's where we get\nthe data normalization and\n\n32\n00:01:20.780 --> 00:01:25.010\ncollecting all of this information\nif you will from multiple sources.\n\n33\n00:01:25.010 --> 00:01:29.190\nWe have things like well, the acquisition\nstorage part of it if you will.\n\n34\n00:01:29.190 --> 00:01:32.900\nWe have things like programmable\nlogical controllers,\n\n35\n00:01:32.900 --> 00:01:37.170\nright, as well as things like\nour programming interfaces.\n\n36\n00:01:37.170 --> 00:01:40.622\nThey also call out things like HMI,\nyour human interfaces, right,\n\n37\n00:01:40.622 --> 00:01:42.237\nHuman Management Interfaces.\n\n38\n00:01:42.237 --> 00:01:46.180\nRTU's, right, the Remote Telemetry Units.\n\n39\n00:01:46.180 --> 00:01:47.890\nAnd these things\nare connected to scanners.\n\n40\n00:01:47.890 --> 00:01:51.410\nSo we have a lot of moving\ncomponents in a SCADA system.\n\n41\n00:01:51.410 --> 00:01:55.250\nAnd it's one of the things that we have\nto keep in mind if we're gonna secure it.\n\n42\n00:01:55.250 --> 00:01:58.280\nThese are highly sought after targets.\n\n43\n00:01:58.280 --> 00:02:01.071\nIf you think about things like for\ninstance Stuxnet.\n\n44\n00:02:01.071 --> 00:02:05.677\nStuxnet was essentially\na botnet if you will,\n\n45\n00:02:05.677 --> 00:02:10.410\nan attack against a nuclear power plant.\n\n46\n00:02:10.410 --> 00:02:14.910\nAnd one of the things that we have to\ntake into consideration is the fact that\n\n47\n00:02:14.910 --> 00:02:17.560\nthey can present multiple attack vectors.\n\n48\n00:02:17.560 --> 00:02:19.080\nAnd that's why it's important,\n\n49\n00:02:19.080 --> 00:02:22.695\nagain keep in mind that we\nhave to secure these systems.\n\n50\n00:02:22.695 --> 00:02:26.400\nThey're massively complex,\nthere's a lot of moving parts,\n\n51\n00:02:26.400 --> 00:02:28.260\na lot of interconnections.\n\n52\n00:02:28.260 --> 00:02:30.550\nAnd because of all\nthe interconnections that they have,\n\n53\n00:02:30.550 --> 00:02:33.050\nthose end up being\nmultiple points of attack.\n\n54\n00:02:33.050 --> 00:02:37.390\nSo SCADA systems again\nhighly sought after targets.\n\n55\n00:02:37.390 --> 00:02:41.310\nAnd we've talk about bad actors our\nthreat actors in past episodes, right.\n\n56\n00:02:41.310 --> 00:02:43.539\nThese could be ones where we\nhave nation states, right.\n\n57\n00:02:43.539 --> 00:02:46.734\nAnd we have the advanced persistent\nthreats coming in because not only\n\n58\n00:02:46.734 --> 00:02:48.531\nare they highly sought after targets.\n\n59\n00:02:48.531 --> 00:02:51.452\nBut a lot of times these\nare gonna be targets where you\n\n60\n00:02:51.452 --> 00:02:55.450\nhave like some foreign country that\nwants to try to glean information.\n\n61\n00:02:55.450 --> 00:02:58.283\nOr maybe get in there and\ncause disruption.\n\n62\n00:02:58.283 --> 00:03:01.260\n&gt;&gt; Well Wes we had mentioned this, I\nthink you had brought it up in a previous\n\n63\n00:03:01.260 --> 00:03:03.520\nepisode when we were talking\nabout different types of malware.\n\n64\n00:03:03.520 --> 00:03:08.776\nAnd you mentioned Stuxnet and that was\nreally kind of a very pivotal point,\n\n65\n00:03:08.776 --> 00:03:10.956\na historical mark if you will.\n\n66\n00:03:10.956 --> 00:03:12.240\n[CROSSTALK]\n&gt;&gt; An eye opener.\n\n67\n00:03:12.240 --> 00:03:15.289\n&gt;&gt; Yeah,\nwhen we saw different types of malware.\n\n68\n00:03:15.289 --> 00:03:18.683\nAnd they were really focused on not\njust attacking individual systems.\n\n69\n00:03:18.683 --> 00:03:22.333\nBut they were focused on attacking\nthose programmable logic controllers,\n\n70\n00:03:22.333 --> 00:03:25.021\nthose actually centrifuges\nin that nuclear facility.\n\n71\n00:03:25.021 --> 00:03:27.681\nAnd it just really makes you think\nabout a lot of different things.\n\n72\n00:03:27.681 --> 00:03:30.533\nAnd maybe focus on building\nup the security so\n\n73\n00:03:30.533 --> 00:03:36.410\nthat you don't have to worry about really\ncatastrophic events that could take place.\n\n74\n00:03:36.410 --> 00:03:39.990\n&gt;&gt; Sure, and\nwith Stuxnet an attack like that,\n\n75\n00:03:39.990 --> 00:03:43.050\nthis was an air gap machine or\nair gap system, right?\n\n76\n00:03:43.050 --> 00:03:44.810\nIt didn't have direct connections or\n\n77\n00:03:44.810 --> 00:03:47.564\neven point-to-point connections\nto any other systems.\n\n78\n00:03:47.564 --> 00:03:50.619\nSo they had to get into\nthe system other ways.\n\n79\n00:03:50.619 --> 00:03:54.038\nAnd one of the things I think is it's\nprobably one of the USB based attacks\n\n80\n00:03:54.038 --> 00:03:54.888\nwe talked about.\n\n81\n00:03:54.888 --> 00:03:56.854\nLoading in malware on USB devices and\n\n82\n00:03:56.854 --> 00:04:01.062\nscattering them through the parking lot\nand curiosity kills the cat, right?\n\n83\n00:04:01.062 --> 00:04:03.940\nSomebody says, I got a USB device now\nwe're gonna go ahead and plug it in and\n\n84\n00:04:03.940 --> 00:04:04.840\nsee what's going on.\n\n85\n00:04:04.840 --> 00:04:08.370\nAnd it's got some kind of boot\nloader in there and it runs wild.\n\n86\n00:04:08.370 --> 00:04:11.735\nAnd the thing to keep in mind with\nthese like Cherokee's mentioned like\n\n87\n00:04:11.735 --> 00:04:12.866\ncentrifuges, right.\n\n88\n00:04:12.866 --> 00:04:17.725\nWe gotta understand that these\nsystems perform critical,\n\n89\n00:04:17.725 --> 00:04:22.770\ncritical tasks essentially\nagainst services that we need.\n\n90\n00:04:22.770 --> 00:04:27.163\nSome of the things that we have to also\nkeep in mind is that these systems have\n\n91\n00:04:27.163 --> 00:04:31.648\nvery, very long or potential to have very,\nvery long life cycles, right.\n\n92\n00:04:31.648 --> 00:04:32.678\nWhen we talk about things like\noperating systems if you will.\n\n93\n00:04:32.678 --> 00:04:36.985\nOperating systems around XP was probably\none of the ones that was around\n\n94\n00:04:36.985 --> 00:04:39.229\nthe longest, and it went ten years.\n\n95\n00:04:39.229 --> 00:04:43.457\nWell your systems, your SCADA systems\ncan be just that long, right?\n\n96\n00:04:43.457 --> 00:04:48.512\nAnd the fact that if they're not being\nconstantly monitored or maybe even\n\n97\n00:04:48.512 --> 00:04:54.200\nupdated on the different components then\nthey do present an avenue for attack.\n\n98\n00:04:54.200 --> 00:04:58.280\nThe other thing I want you to consider,\nif we don't secure things like our scatter\n\n99\n00:04:58.280 --> 00:05:01.600\nsystems we have to worry\nabout denial of service.\n\n100\n00:05:01.600 --> 00:05:03.870\nBut this is a little bit different\nwhen we say denial of service.\n\n101\n00:05:03.870 --> 00:05:07.560\nWe're talking denial of service,\nthese are vital services that we need.\n\n102\n00:05:07.560 --> 00:05:10.020\nThings like process redirection, right.\n\n103\n00:05:10.020 --> 00:05:12.837\nManipulation your\noperational data as well.\n\n104\n00:05:12.837 --> 00:05:16.190\nThings like for\ninstance hard coded passwords.\n\n105\n00:05:16.190 --> 00:05:19.130\nHard coded default passwords that\nare built into the link it's like\n\n106\n00:05:19.130 --> 00:05:23.170\nthe programmable logical controllers that\nallow managers to have remote access.\n\n107\n00:05:23.170 --> 00:05:26.717\nWell if it's a hard coded default password\nchances are it's gonna be a little bit\n\n108\n00:05:26.717 --> 00:05:27.925\nharder to change, right.\n\n109\n00:05:27.925 --> 00:05:30.190\nSo we have to worry\nabout things like that.\n\n110\n00:05:30.190 --> 00:05:33.878\nThe other thing that we have to keep\nin mind too is the fact that well,\n\n111\n00:05:33.878 --> 00:05:37.653\nthey're very susceptible to things\nlike zero day attacks, right.\n\n112\n00:05:37.653 --> 00:05:42.380\nAn attack, like Cherokee just mentioned,\nwhere we were like this can really happen.\n\n113\n00:05:42.380 --> 00:05:45.020\nI mean it did happen it kind\nof takes you by surprise.\n\n114\n00:05:45.020 --> 00:05:47.450\nBut again it's something that\nyou have to be aware of.\n\n115\n00:05:47.450 --> 00:05:52.582\nAnd any kind of security considerations\nneed to be taken in place as these\n\n116\n00:05:52.582 --> 00:05:55.900\nSCADA systems are brought up just because\nof the fact that they can have very,\n\n117\n00:05:55.900 --> 00:05:58.520\nvery long life cycles, all right.\n\n118\n00:05:58.520 --> 00:06:01.930\nSome of the other things that they call\nout when it comes to embedded systems we\n\n119\n00:06:01.930 --> 00:06:05.480\nhave things like for\ninstance smart devices, IoT.\n\n120\n00:06:05.480 --> 00:06:07.535\nThis is the big buzz word out there.\n\n121\n00:06:07.535 --> 00:06:10.665\nAnd in fact just recently and\nI think we've mentioned this before too.\n\n122\n00:06:10.665 --> 00:06:14.775\nCherokee I think you've mentioned it that\nIoT attacks actually took down a great\n\n123\n00:06:14.775 --> 00:06:18.570\nportion of the northeastern DNS\nsystem that we have out there.\n\n124\n00:06:18.570 --> 00:06:21.880\nAnd this just became a massive\ndenial of service attack.\n\n125\n00:06:21.880 --> 00:06:23.270\nAnd why is that?\n\n126\n00:06:23.270 --> 00:06:27.757\nWell again people were using things\nlike IoT, like smart devices.\n\n127\n00:06:27.757 --> 00:06:30.381\nAnd these embedded chips that are in them.\n\n128\n00:06:30.381 --> 00:06:34.351\nThey were susceptible to attacks\nthat people weren't away existed.\n\n129\n00:06:34.351 --> 00:06:37.442\nAnd it kinda understand too\nit's a newer technology,\n\n130\n00:06:37.442 --> 00:06:41.688\nit's the new buzz word everybody wants\nthings like hole amount of nation.\n\n131\n00:06:41.688 --> 00:06:45.608\nYou want things like for instance\nyour wearable technologies, right.\n\n132\n00:06:45.608 --> 00:06:49.625\nWell the more these devices that you have\nthe more the necessities to secure them.\n\n133\n00:06:50.810 --> 00:06:55.150\n&gt;&gt; Wes I really just don't think people\nreally expect their light bulbs to be\n\n134\n00:06:55.150 --> 00:06:58.530\na weakness or a vulnerability\nin the design of their network.\n\n135\n00:06:58.530 --> 00:07:03.659\nActually there's an older Garfield episode\nwhere there's a home automation system.\n\n136\n00:07:03.659 --> 00:07:09.388\nAnd she turns evil and they're trying\nto kill the characters John and\n\n137\n00:07:09.388 --> 00:07:13.165\nOdie with a toaster and things like that.\n\n138\n00:07:13.165 --> 00:07:14.525\nAnd it's kind of like a joke.\n\n139\n00:07:14.525 --> 00:07:17.665\nBut [LAUGH] we're not\nkilling people with toasters.\n\n140\n00:07:17.665 --> 00:07:21.546\nBut the fact of the matter is you really\nneed to focus on these IoT devices,\n\n141\n00:07:21.546 --> 00:07:23.746\nperhaps put them in a segmented network.\n\n142\n00:07:23.746 --> 00:07:28.973\nOr maybe not even use them,\nbecause it's not something that really is\n\n143\n00:07:28.973 --> 00:07:35.539\nfully in our control if the manufacturers\nreally don't beef up their responsibility.\n\n144\n00:07:35.539 --> 00:07:40.140\nAnd really test for those vulnerabilities\nwithin the source code for those devices.\n\n145\n00:07:40.140 --> 00:07:42.940\n&gt;&gt; Most definitely some of the things that\nyou have to worry about with IoT have got\n\n146\n00:07:42.940 --> 00:07:47.070\nsome popular types of vulnerabilities\nthat you have to worry about,\n\n147\n00:07:47.070 --> 00:07:49.430\nthings like insecure web interfaces,\nright?\n\n148\n00:07:49.430 --> 00:07:51.730\nSome of these things you need to control,\nyou need to configure, right.\n\n149\n00:07:51.730 --> 00:07:53.190\nThey give you some kind\nof little web server.\n\n150\n00:07:53.190 --> 00:07:56.305\nIt's not really a web server like we\nwould think like an Apache server.\n\n151\n00:07:56.305 --> 00:07:58.880\nBut it's the fact that I can get in and\nI can manage the device.\n\n152\n00:07:58.880 --> 00:08:01.612\nBut the interface itself\nagain might not be secure and\n\n153\n00:08:01.612 --> 00:08:04.231\nthat lends a problem because\nif you can get into it.\n\n154\n00:08:04.231 --> 00:08:06.626\nSomebody else can get into it, right.\n\n155\n00:08:06.626 --> 00:08:08.732\nThings like insufficient\nauthentication and\n\n156\n00:08:08.732 --> 00:08:11.770\nauthorization to the different\nresources within the device.\n\n157\n00:08:11.770 --> 00:08:15.430\nAnd you say, well, wait a second,\nlike Cherokee's saying, a little toaster.\n\n158\n00:08:15.430 --> 00:08:17.675\nWell, or something like a smart TV.\n\n159\n00:08:17.675 --> 00:08:19.040\nSmart TVs are all the craze.\n\n160\n00:08:19.040 --> 00:08:23.280\nThey're an Interneted thing type device\nwhere they're connected to the internet.\n\n161\n00:08:23.280 --> 00:08:27.934\nThey can potentially have cameras that are\nin use that people could piggy back off\n\n162\n00:08:27.934 --> 00:08:29.585\nand spy on you, if you will.\n\n163\n00:08:29.585 --> 00:08:32.215\nThings like insecure network services.\n\n164\n00:08:32.215 --> 00:08:35.946\nThis is something that we have to worry\nabout, if I connect my smart TV to my\n\n165\n00:08:35.946 --> 00:08:39.100\nnetwork and I do a scan of my network,\nI can see the TV is there.\n\n166\n00:08:39.100 --> 00:08:42.281\nBut what can I do to secure\nthe communications that my TV has with\n\n167\n00:08:42.281 --> 00:08:43.550\nthe rest of the network?\n\n168\n00:08:43.550 --> 00:08:46.862\nSo we have to see if we can\nimplement things like that.\n\n169\n00:08:46.862 --> 00:08:49.163\nAnd if we can't and\nyou need a truly secure network,\n\n170\n00:08:49.163 --> 00:08:52.146\nthen maybe you have to take Cherokee's\nadvice and just not use these\n\n171\n00:08:52.146 --> 00:08:56.250\ndevices because of the fact that they\nare a point of entry into your network.\n\n172\n00:08:56.250 --> 00:08:58.870\nThings like lack of transport encryption.\n\n173\n00:08:58.870 --> 00:09:03.273\nIf you think about it, I'm communicating\nwith these IoT devices whether it happens\n\n174\n00:09:03.273 --> 00:09:06.886\nbe a refrigerator, whether it\nhappens to be the automation system.\n\n175\n00:09:06.886 --> 00:09:10.667\nIs that information between whatever\nthe management device is and\n\n176\n00:09:10.667 --> 00:09:11.930\nthe managed device?\n\n177\n00:09:11.930 --> 00:09:14.030\nIs that communication encrypted?\n\n178\n00:09:14.030 --> 00:09:15.905\nChances are, probably not.\n\n179\n00:09:15.905 --> 00:09:21.390\nSome of these systems don't have a lot of\nCPU strength, and that would cost more.\n\n180\n00:09:21.390 --> 00:09:25.485\nSo if we put a CPU in it that's capable\nof doing cryptographic operations,\n\n181\n00:09:25.485 --> 00:09:27.565\nwell, then your price is gonna go up.\n\n182\n00:09:27.565 --> 00:09:31.591\nAnd the whole thing with the IoT is to\nkeep it relatively cheap, if you will, so\n\n183\n00:09:31.591 --> 00:09:33.770\nthat average person can afford it.\n\n184\n00:09:33.770 --> 00:09:34.770\nAnd again, remember,\n\n185\n00:09:34.770 --> 00:09:39.280\nconvenience versus security,\nthey are not friends with each other.\n\n186\n00:09:39.280 --> 00:09:41.380\nThe more convenience you have,\nthe lower the security.\n\n187\n00:09:41.380 --> 00:09:43.360\nThe more security,\nthe lower the convenience.\n\n188\n00:09:44.460 --> 00:09:48.190\nSo we think about that fine balance.\n\n189\n00:09:48.190 --> 00:09:49.890\nWhat are some other things\nthat we have to worry about?\n\n190\n00:09:49.890 --> 00:09:53.010\nWell, we have to worry about lack of\ntransport encryption verification\n\n191\n00:09:53.010 --> 00:09:53.800\ninformation.\n\n192\n00:09:53.800 --> 00:09:56.669\nWe also have to worry about\nthings like privacy concerns.\n\n193\n00:09:56.669 --> 00:10:02.330\nIf I can ease drop on that information,\n\n194\n00:10:02.330 --> 00:10:06.000\nthen it's not private.\n\n195\n00:10:06.000 --> 00:10:08.300\nThrough due diligence to make sure.\n\n196\n00:10:08.300 --> 00:10:10.730\nLike we've talked about,\nthings like trusted operating systems.\n\n197\n00:10:10.730 --> 00:10:13.720\nTrusted operating systems are called\nsuch because of the fact that\n\n198\n00:10:13.720 --> 00:10:16.630\nthey have multiple layers of\nsecurity that you can implement.\n\n199\n00:10:16.630 --> 00:10:20.493\nAnd it allows you through those multiple\nlayers of security to adhere to things\n\n200\n00:10:20.493 --> 00:10:21.909\nlike compliance concerns.\n\n201\n00:10:21.909 --> 00:10:25.372\nYou might not have that in the operating\nsystem, the very small footprint,\n\n202\n00:10:25.372 --> 00:10:29.230\noptimized operating system that is running\nin one of these small devices like that.\n\n203\n00:10:30.510 --> 00:10:32.600\nThings like just, and that lends itself,\n\n204\n00:10:32.600 --> 00:10:35.750\nif you will, to things like\ninsufficient security configurability.\n\n205\n00:10:35.750 --> 00:10:38.000\nMaybe I can't implement\na security on these devices.\n\n206\n00:10:38.000 --> 00:10:41.890\nAnd again, that becomes a challenge and\na problem within our modern networks.\n\n207\n00:10:41.890 --> 00:10:44.630\nLet's say, and\njust poor physical security in general.\n\n208\n00:10:44.630 --> 00:10:46.670\nThink about a wearable device.\n\n209\n00:10:46.670 --> 00:10:52.680\nThink about maybe putting it down on your\ndesk if you will and walking away from it.\n\n210\n00:10:52.680 --> 00:10:56.380\nI think I've actually guilty at this\none right here maybe I shouldn't\n\n211\n00:10:56.380 --> 00:10:57.800\nbe telling you guys this on camera,\n\n212\n00:10:57.800 --> 00:11:02.400\nbut I've got a rest verify, I've got\na few rest very twice within my network.\n\n213\n00:11:02.400 --> 00:11:03.938\nNow, understand physical security.\n\n214\n00:11:03.938 --> 00:11:06.840\nIf somebody's already got access\nto your network, physically, then\n\n215\n00:11:06.840 --> 00:11:09.410\nsome of these concerns are some of the\nlast things that you have to worry about.\n\n216\n00:11:09.410 --> 00:11:12.340\nYou have to look at your physical\nsecurity, but think about it.\n\n217\n00:11:12.340 --> 00:11:14.060\nRaspberry Pi just sitting\nthere on the wall,\n\n218\n00:11:14.060 --> 00:11:15.890\nmay be attached to the back of a monitor.\n\n219\n00:11:15.890 --> 00:11:17.450\nWe walk into the lobby.\n\n220\n00:11:17.450 --> 00:11:18.798\nWe walk into the lobby of a place,\n\n221\n00:11:18.798 --> 00:11:21.505\npeople have attached these small\nRaspberry Pis to the back of TVs.\n\n222\n00:11:21.505 --> 00:11:24.800\nCuz they can do things like stream media.\n\n223\n00:11:24.800 --> 00:11:27.850\nWell, it's too hard to walk back there and\nmaybe plug something into one.\n\n224\n00:11:27.850 --> 00:11:31.977\nSo lack of poor physical security, too.\n\n225\n00:11:31.977 --> 00:11:36.375\nSome of the other big embedded systems\nthat we definitely have inside of just\n\n226\n00:11:36.375 --> 00:11:40.771\nabout any server, closet server room\nis things like HVAC systems, right,\n\n227\n00:11:40.771 --> 00:11:42.711\nheating and ventilation and AC.\n\n228\n00:11:42.711 --> 00:11:48.040\nOur server rooms, they need environmental\ncontrols, we gotta keep them cool.\n\n229\n00:11:48.040 --> 00:11:51.970\nThe problem is things like something\nas simple as copper thieves.\n\n230\n00:11:51.970 --> 00:11:54.950\nI know that working\nconstruction many years,\n\n231\n00:11:54.950 --> 00:11:57.880\nthat there were quite a few people that\nwent, I mean, they weren't thieves.\n\n232\n00:11:57.880 --> 00:12:00.670\nBut what they would do, is they'd go to\nthe trash piles and they'd pick up some of\n\n233\n00:12:00.670 --> 00:12:03.910\nthe copper and they'd start saving\nit over time and go cash it in.\n\n234\n00:12:03.910 --> 00:12:06.620\nNow, that's perfectly legal, but how about\nthe person that wants to do that, and\n\n235\n00:12:06.620 --> 00:12:08.710\nthey're looking at the copper\ncoming out of the HVAC system.\n\n236\n00:12:08.710 --> 00:12:11.618\nAnd if you don't have physical security\nsecurity, somebody could get in there and\n\n237\n00:12:11.618 --> 00:12:12.751\njust start ripping things out.\n\n238\n00:12:12.751 --> 00:12:15.720\nAnd again, physical security,\nif they can get access to your network,\n\n239\n00:12:15.720 --> 00:12:19.080\nchances are it's no longer your network,\nso do keep that in mind.\n\n240\n00:12:19.080 --> 00:12:23.530\n&gt;&gt; Wes, if we look at big examples\nof this type of HVAC systems,\n\n241\n00:12:23.530 --> 00:12:26.540\nlike Target,\nwe're talking 40 million credit card and\n\n242\n00:12:26.540 --> 00:12:29.900\ndebit card pieces of\ninformation that were released.\n\n243\n00:12:29.900 --> 00:12:34.960\nAnd that was simply because they had\ngiven external access to their network.\n\n244\n00:12:34.960 --> 00:12:36.260\nI'm pretty sure,\nI don't remember the details.\n\n245\n00:12:36.260 --> 00:12:39.410\nYou guys can look it up, it's a huge\nexample of this type of situation,\n\n246\n00:12:39.410 --> 00:12:44.300\nwhere I don't think they had\nsegmented that HVAC control.\n\n247\n00:12:44.300 --> 00:12:49.400\nAnd they were just literally giving\ncredentials to their internal network,\n\n248\n00:12:49.400 --> 00:12:52.940\nwhich obviously didn't end too well for\neveryone.\n\n249\n00:12:52.940 --> 00:12:54.600\n&gt;&gt; Most definitely, and\nyou know what it was?\n\n250\n00:12:54.600 --> 00:12:58.072\nIt was a HVAC system too, it was a third\nparty that was providing services for\n\n251\n00:12:58.072 --> 00:12:59.710\nthe HVAC system that they gave you.\n\n252\n00:12:59.710 --> 00:13:02.730\nJust like you said,\nthey just didn't use authentication.\n\n253\n00:13:02.730 --> 00:13:05.350\nAnd they gave that company\naccess to their HVAC system, and\n\n254\n00:13:05.350 --> 00:13:07.290\nthey believe that's where\nthe exploit started.\n\n255\n00:13:07.290 --> 00:13:13.390\nSo that's a classic example of an exploit\nthat cost the company millions of dollars,\n\n256\n00:13:13.390 --> 00:13:16.930\njust because they weren't doing\nthings like logging visitor access.\n\n257\n00:13:16.930 --> 00:13:20.420\nPaying attention, making sure that your\ncontractors are licensed, bonded, and\n\n258\n00:13:20.420 --> 00:13:21.790\ninsured.\n\n259\n00:13:21.790 --> 00:13:25.680\nMaking sure that you have secure\nauthentication within a system like that.\n\n260\n00:13:25.680 --> 00:13:30.177\nAnother one too, back in 2014,\nWells said that there were more than\n\n261\n00:13:30.177 --> 00:13:34.908\n55,000 HVAC systems that were\ndirection connected to the Internet.\n\n262\n00:13:34.908 --> 00:13:36.573\n&gt;&gt; Nice.\n&gt;&gt; Think about that, right?\n\n263\n00:13:36.573 --> 00:13:37.303\nThat's a little scary.\n\n264\n00:13:37.303 --> 00:13:38.884\n&gt;&gt; And 2013 was the target.\n\n265\n00:13:38.884 --> 00:13:41.074\nSo you would think even\nafter that had happened.\n\n266\n00:13:41.074 --> 00:13:44.220\nSo 2014,\nthey were still directly connected.\n\n267\n00:13:44.220 --> 00:13:45.730\n&gt;&gt; Still hadn't even learned,\nthat's right.\n\n268\n00:13:45.730 --> 00:13:48.820\nSo we've gotta be careful,\ncuz when it comes to the HVAC systems,\n\n269\n00:13:48.820 --> 00:13:51.070\nthey can get you in some\ntrouble real quick.\n\n270\n00:13:51.070 --> 00:13:52.860\nSo what are some of\nthe things that you can do?\n\n271\n00:13:52.860 --> 00:13:55.630\nFirst of all,\nimplement security controls like alarms.\n\n272\n00:13:55.630 --> 00:14:00.221\nI've seen one good one where\nthe documentation said, put cameras,\n\n273\n00:14:00.221 --> 00:14:04.270\nalarms and even strobe lights\nout there by your HVAC system.\n\n274\n00:14:04.270 --> 00:14:06.560\nSo if the alarm triggers\nthe strobe lights go off and\n\n275\n00:14:06.560 --> 00:14:11.430\nyou know exactly the location within\nthe zone that this problem is happening.\n\n276\n00:14:11.430 --> 00:14:15.630\nJust keep in mind, alarms don't\nstop people from doing anything.\n\n277\n00:14:15.630 --> 00:14:19.320\nI don't even know if they're a deterrent,\nbut at least it makes people aware.\n\n278\n00:14:19.320 --> 00:14:22.677\nSo if there's a security guard\nthey can respond in real time.\n\n279\n00:14:22.677 --> 00:14:24.959\n&gt;&gt; It's great that you\nmentioned strobe lights, and\n\n280\n00:14:24.959 --> 00:14:27.570\nthis I just happened to notice\nwalking into a gas station.\n\n281\n00:14:27.570 --> 00:14:29.570\nThere was a security camera.\n\n282\n00:14:29.570 --> 00:14:32.840\nWell, the first thing obviously that\ncaught my attention was a strobe light.\n\n283\n00:14:32.840 --> 00:14:36.600\nAnd I turned my face to the actual\nstrobe light to see what's going on.\n\n284\n00:14:36.600 --> 00:14:40.220\nAs you're walking in, there's a security\ncamera with a light next to it so\n\n285\n00:14:40.220 --> 00:14:44.075\nthat they could get a good, get my face\non camera, which is a pretty smart idea.\n\n286\n00:14:44.075 --> 00:14:45.790\n&gt;&gt; And it also brings awareness, too.\n\n287\n00:14:45.790 --> 00:14:47.900\nI think a lot of times with\nthe strobe lights, I know exactly,\n\n288\n00:14:47.900 --> 00:14:51.890\ncuz I've been to a couple gas\nstations that do exactly that.\n\n289\n00:14:51.890 --> 00:14:55.390\nIs the fact that they're making people\naware that you're being monitored.\n\n290\n00:14:55.390 --> 00:14:57.700\nYou know that those strobe lights\nare right by those cameras.\n\n291\n00:14:57.700 --> 00:15:01.841\nSo people can say, well,\nif I do something shady here,\n\n292\n00:15:01.841 --> 00:15:04.941\nI can see that I better\nsmile cuz I'm on CCTV.\n\n293\n00:15:04.941 --> 00:15:07.000\nSo what are some of the other things,\ntoo, that you can do?\n\n294\n00:15:07.000 --> 00:15:09.329\nLog all visitors arriving and\nleaving the building.\n\n295\n00:15:09.329 --> 00:15:12.098\nJust log access.\n\n296\n00:15:12.098 --> 00:15:14.620\nIf you had a technician\nthat's gonna visit.\n\n297\n00:15:14.620 --> 00:15:16.900\nAnd again, remember,\nit could be remote technician.\n\n298\n00:15:16.900 --> 00:15:21.162\nMake sure that you're doing things,\nyou're confirming the internal contact.\n\n299\n00:15:21.162 --> 00:15:25.890\nEnsure that some kind of\nemployee escorts the technician.\n\n300\n00:15:25.890 --> 00:15:28.160\nDon't just let him roam\naround your building.\n\n301\n00:15:28.160 --> 00:15:30.150\nSo you're ensuring that\nthey're doing their job.\n\n302\n00:15:30.150 --> 00:15:32.990\nNow, that might seem a little overbearing.\n\n303\n00:15:32.990 --> 00:15:36.471\nBut I'm sure Target, looking back,\nhindsight's lesson learned,\n\n304\n00:15:36.471 --> 00:15:39.952\nwould have somebody monitoring,\neven if they had to literally escort\n\n305\n00:15:39.952 --> 00:15:43.621\nthe person around the building the entire\ntime they were in the building.\n\n306\n00:15:43.621 --> 00:15:47.051\n&gt;&gt; Wes, we might even create\nparticular physical security zones and\n\n307\n00:15:47.051 --> 00:15:49.990\nhave a public area where guests\nare able to roam freely.\n\n308\n00:15:49.990 --> 00:15:52.440\nBut where our sensitive information is for\nsure.\n\n309\n00:15:52.440 --> 00:15:55.797\nDefinitely implement some\nkinda escorting process.\n\n310\n00:15:55.797 --> 00:15:57.749\n&gt;&gt; And if it comes to remote access,\n\n311\n00:15:57.749 --> 00:16:01.669\nmake sure you thoroughly document\nwhat level of access they have.\n\n312\n00:16:01.669 --> 00:16:03.597\nI need to get into your system.\n\n313\n00:16:03.597 --> 00:16:05.383\nWhat do you need to do?\n\n314\n00:16:05.383 --> 00:16:07.158\nRight, and\nremember principle are least privilege.\n\n315\n00:16:07.158 --> 00:16:10.128\nWe shouldn't give anybody remove\naccess that doesn't belong there.\n\n316\n00:16:10.128 --> 00:16:14.560\nAnd again, some of this seem obvious,\nbut you can see that even big companies,\n\n317\n00:16:14.560 --> 00:16:18.863\nmulti billion dollar, multi million\ndollar companies are even take this for\n\n318\n00:16:18.863 --> 00:16:20.035\ngranted sometime.\n\n319\n00:16:20.035 --> 00:16:23.430\nOther things that they actually call out,\nis SOC.\n\n320\n00:16:23.430 --> 00:16:26.090\nAgain, another acronym that you\nguys have to understand, and\n\n321\n00:16:26.090 --> 00:16:27.705\nmaybe you've already heard of this.\n\n322\n00:16:27.705 --> 00:16:31.185\nThis actually kinda falls right in place\nwith things like embedded systems and\n\n323\n00:16:31.185 --> 00:16:31.845\nIoT, right?\n\n324\n00:16:31.845 --> 00:16:34.200\nWe're talking about system on a chip,\nright,\n\n325\n00:16:34.200 --> 00:16:36.700\nthe entire system is\nbuilt into a single chip.\n\n326\n00:16:36.700 --> 00:16:40.280\nRaspberry Pi is an example of\none that is using one of those,\n\n327\n00:16:40.280 --> 00:16:42.370\nI wanna say it's a Snapdragon processor.\n\n328\n00:16:42.370 --> 00:16:43.571\nI might have that\na little bit wrong there.\n\n329\n00:16:43.571 --> 00:16:45.555\nBut some of you guys-\n&gt;&gt; I've even seen some that are the size\n\n330\n00:16:45.555 --> 00:16:48.000\nof a quarter,\nsmaller than the Raspberry Pi, it's crazy.\n\n331\n00:16:48.000 --> 00:16:48.930\n&gt;&gt; Yeah, most definitely.\n\n332\n00:16:48.930 --> 00:16:50.749\nWell you think, for instance, Snapdragon.\n\n333\n00:16:50.749 --> 00:16:53.376\nWe're talking about mobile processors, but\n\n334\n00:16:53.376 --> 00:16:56.080\nthe entire system can\nreside within that chip.\n\n335\n00:16:56.080 --> 00:17:00.170\nYour graphics, right,\nyour network controller, your CPU, right?\n\n336\n00:17:00.170 --> 00:17:01.580\nAll in a single chip.\n\n337\n00:17:01.580 --> 00:17:03.440\nAnd the other thing we have to\nworry about, are things like, and\n\n338\n00:17:03.440 --> 00:17:04.810\nwe've talked about this before, too.\n\n339\n00:17:04.810 --> 00:17:06.300\nSupply chain attacks.\n\n340\n00:17:06.300 --> 00:17:07.351\nWhere are you getting those chips from?\n\n341\n00:17:07.351 --> 00:17:07.870\n&gt;&gt; Right.\n\n342\n00:17:07.870 --> 00:17:09.009\n&gt;&gt; Is it a reputable source?\n\n343\n00:17:09.009 --> 00:17:11.530\nAnd again,\nI'm not picking on China when I say this.\n\n344\n00:17:11.530 --> 00:17:14.991\nIs it coming out of China\non undocumented sources?\n\n345\n00:17:14.991 --> 00:17:17.938\nThey could have something\nbaked into the malware, or\n\n346\n00:17:17.938 --> 00:17:19.910\nmalware baked into those systems.\n\n347\n00:17:19.910 --> 00:17:22.937\nAnd when the manufacturer starts\nto put these components together,\n\n348\n00:17:22.937 --> 00:17:25.454\nthey already have things like\nmalware preceded in them.\n\n349\n00:17:25.454 --> 00:17:28.720\nSo, we do have to keep\nthat in mind as well.\n\n350\n00:17:29.870 --> 00:17:32.260\nSome of the other things that they call\nout, this is kinda an interesting one.\n\n351\n00:17:32.260 --> 00:17:33.910\nThey call out what's known as RTOS.\n\n352\n00:17:33.910 --> 00:17:36.960\nAll right, so what is RTOS?\n\n353\n00:17:36.960 --> 00:17:39.500\nThat is real-time operating system, okay?\n\n354\n00:17:39.500 --> 00:17:42.000\nSo, what is the difference between\na real time operating system and\n\n355\n00:17:42.000 --> 00:17:44.140\ngeneral purpose operating system,\nall right?\n\n356\n00:17:44.140 --> 00:17:49.480\nWell, when we talk about general\npurpose operating systems,\n\n357\n00:17:49.480 --> 00:17:51.518\nthey do things like multitasking today.\n\n358\n00:17:51.518 --> 00:17:53.910\nAnd it's kinda interesting\nbecause the cores of the CPUs,\n\n359\n00:17:53.910 --> 00:17:56.380\nthey can really only do\none function at one time.\n\n360\n00:17:56.380 --> 00:17:58.420\nBut what they do is they do scheduling,\nright?\n\n361\n00:17:58.420 --> 00:18:02.730\nAnd the scheduling makes it appear as\nmultiple things are happening over and\n\n362\n00:18:02.730 --> 00:18:03.940\nover and over, all right?\n\n363\n00:18:03.940 --> 00:18:07.190\nSo again, they utilize the scheduler,\n\n364\n00:18:07.190 --> 00:18:08.970\nthat gives them the appearance\nof multi tasking.\n\n365\n00:18:08.970 --> 00:18:14.740\nRTOS, they try to do some kind\nof predictability to guess\n\n366\n00:18:14.740 --> 00:18:19.380\nwhat is happening next, in order to\nserve up things in real time, right?\n\n367\n00:18:19.380 --> 00:18:23.340\nPredictability to satisfy\nreal time requirements.\n\n368\n00:18:23.340 --> 00:18:26.450\nSo, these are also systems\nthat we have to make sure\n\n369\n00:18:26.450 --> 00:18:29.270\nthat we are that we're protecting.\n\n370\n00:18:30.322 --> 00:18:32.180\nAll right, so some of the other\nthings that they're calling out, too.\n\n371\n00:18:32.180 --> 00:18:35.260\nThey call out printers and\nMFDs, multi-function devices.\n\n372\n00:18:35.260 --> 00:18:39.430\nAgain, we've kinda talked\nabout this before too.\n\n373\n00:18:39.430 --> 00:18:42.920\nRemember, with a printer, even mid-range\nprinters typically have things like hard\n\n374\n00:18:42.920 --> 00:18:48.720\ndrives, RAM if you will, network\nconnectivity, and an OS, all right.\n\n375\n00:18:48.720 --> 00:18:51.530\nHere's another problem is there's\nreally no consistency when it comes\n\n376\n00:18:51.530 --> 00:18:52.200\ninto printers.\n\n377\n00:18:52.200 --> 00:18:55.956\nSo, the one way that you protect one\nprinter is probably not the same way that\n\n378\n00:18:55.956 --> 00:18:58.674\nyou're going to completely\nsecure another printer.\n\n379\n00:18:58.674 --> 00:19:00.606\nThey're very proprietary in nature and\n\n380\n00:19:00.606 --> 00:19:04.770\nevery manufacturer even between models can\nmanufacture them a little bit different.\n\n381\n00:19:04.770 --> 00:19:09.110\nSo, it is important that we keep in mind\nwe have things like sending in private\n\n382\n00:19:09.110 --> 00:19:11.710\ndocuments, right,\nimportant documents over to that printer.\n\n383\n00:19:11.710 --> 00:19:14.150\nThere's network communications\nthat we need to worry about,\n\n384\n00:19:14.150 --> 00:19:15.870\nthere's things like the print queue,\nright?\n\n385\n00:19:15.870 --> 00:19:18.180\nThe print queue's stored in memory, right?\n\n386\n00:19:18.180 --> 00:19:21.080\nOr it's spooled to the hard drive, and\nif it's spooled to the hard drive and\n\n387\n00:19:21.080 --> 00:19:24.090\nI can gain access through the network\nto the hard drive of that machine.\n\n388\n00:19:24.090 --> 00:19:27.450\nI can gain access to the documents that\nyou're sending to a printer, right?\n\n389\n00:19:27.450 --> 00:19:29.980\nThere's a reason that we have\nthings like privacy laws that say,\n\n390\n00:19:29.980 --> 00:19:32.350\nwhen you print something out to a printer,\nyou don't leave it at the printer.\n\n391\n00:19:32.350 --> 00:19:36.420\nThe person that's printing the document is\nright there to grab that information so\n\n392\n00:19:36.420 --> 00:19:37.920\nnobody else can see it.\n\n393\n00:19:37.920 --> 00:19:40.080\nWell, you've done a good\njob if you've done that.\n\n394\n00:19:40.080 --> 00:19:42.760\nBut the problem is you haven't\ncleared it on for the spool, right, or\n\n395\n00:19:42.760 --> 00:19:44.540\noff the disk itself.\n\n396\n00:19:44.540 --> 00:19:46.090\nThat information's still there.\n\n397\n00:19:46.090 --> 00:19:48.220\nAnd it means if somebody\ncan gain access to it,\n\n398\n00:19:48.220 --> 00:19:50.570\nthey can gain access to\nvery sensitive information.\n\n399\n00:19:50.570 --> 00:19:52.701\n&gt;&gt; Wes,\nI can't even stress how important this is.\n\n400\n00:19:52.701 --> 00:19:54.920\nAnd it's something that a lot of\npeople might really not think about.\n\n401\n00:19:54.920 --> 00:19:56.430\nEspecially, let's say you're traveling,\n\n402\n00:19:56.430 --> 00:19:58.370\nand you have some documents\nyou wanna print at the hotel.\n\n403\n00:19:58.370 --> 00:19:59.600\nIf they have a print service set up,\n\n404\n00:19:59.600 --> 00:20:04.050\njust like you were explaining, you\nreally don't want to just hit print and\n\n405\n00:20:04.050 --> 00:20:08.810\nassume, that everyone has configured\nthose devices in a proper way.\n\n406\n00:20:08.810 --> 00:20:11.910\nAnd if it is a real concern for\nyour security, for\n\n407\n00:20:11.910 --> 00:20:13.500\nexample I worked at a company.\n\n408\n00:20:13.500 --> 00:20:16.790\nAnd I just set the printer\nright up in behind lock and\n\n409\n00:20:16.790 --> 00:20:21.390\ndoor, behind a closed door in\nthe HR department's office.\n\n410\n00:20:21.390 --> 00:20:25.047\nBecause you don't want employees to be\nable, especially if you're doing things\n\n411\n00:20:25.047 --> 00:20:28.228\nlike, maybe in the accounting department,\nprinting out paychecks.\n\n412\n00:20:28.228 --> 00:20:31.840\nAnd you don't want them to have\naccess to those individual printers.\n\n413\n00:20:31.840 --> 00:20:35.018\nSo, you just have to think about\nthat because these devices also,\n\n414\n00:20:35.018 --> 00:20:38.423\nthe devices themselves, not,\nwe're not talking a print server, but\n\n415\n00:20:38.423 --> 00:20:40.943\nan actual printer like Wes\nwas saying can be hacked.\n\n416\n00:20:40.943 --> 00:20:45.635\nI don't know I think it was a Canon camera\nthat was hacked with the Doom character on\n\n417\n00:20:45.635 --> 00:20:48.838\nthe display and\nthen people kind of paid homage to that.\n\n418\n00:20:48.838 --> 00:20:53.263\nAnd started hacking these Canon\nprinters to be able to actually play or\n\n419\n00:20:53.263 --> 00:20:58.070\nshow portions of the video game on\nthe little LCD screens that they now have.\n\n420\n00:20:58.070 --> 00:21:01.510\nSo, it's possible,\nit's not just theoretical at this point.\n\n421\n00:21:01.510 --> 00:21:05.773\n&gt;&gt; Yeah, and if you look at the popularity\nof even things like wireless printing\n\n422\n00:21:05.773 --> 00:21:06.698\ntoday, right.\n\n423\n00:21:06.698 --> 00:21:10.064\nWe talk about network based printers and\nsome of you might think hey,\n\n424\n00:21:10.064 --> 00:21:12.043\nplug in cable into the wall-\n&gt;&gt; Good point.\n\n425\n00:21:12.043 --> 00:21:15.387\n&gt;&gt; But we have wireless printers, right\nand wireless printers are always emanating\n\n426\n00:21:15.387 --> 00:21:17.960\nanything wireless is always\nemanating information, right?\n\n427\n00:21:17.960 --> 00:21:19.540\nEven if it's just control information or\n\n428\n00:21:19.540 --> 00:21:23.000\nresponding to access points,\nif we can intercept that information,\n\n429\n00:21:23.000 --> 00:21:25.580\nI don't even have to have access\nto your physical network, right?\n\n430\n00:21:25.580 --> 00:21:27.460\nI just have to have proximity access and\n\n431\n00:21:27.460 --> 00:21:30.595\nthat's a lot of different than actually\nhaving physical access into your building.\n\n432\n00:21:30.595 --> 00:21:33.525\n&gt;&gt; And it take even a step further, you'll\nlook up things like Google print and\n\n433\n00:21:33.525 --> 00:21:36.485\na lot of these services that we can\nprint from really anywhere in the world.\n\n434\n00:21:36.485 --> 00:21:40.645\nI can send a document to Wes\nprinter when I'm in vacation and\n\n435\n00:21:40.645 --> 00:21:42.960\nanother state or country or whatever.\n\n436\n00:21:42.960 --> 00:21:45.946\nBut the actual protocols that they\nuse to transmit that information,\n\n437\n00:21:45.946 --> 00:21:47.117\nthey're just using HTTP.\n\n438\n00:21:47.117 --> 00:21:49.860\nThey're not encrypting that,\nso be aware of that as well.\n\n439\n00:21:49.860 --> 00:21:51.867\n&gt;&gt; Yeah, IPP,\nthe internet pretty protocol.\n\n440\n00:21:51.867 --> 00:21:53.210\n&gt;&gt; Pretty protocol.\n\n441\n00:21:53.210 --> 00:21:54.280\n&gt;&gt; Yep, that's exactly it.\n\n442\n00:21:54.280 --> 00:21:55.630\nIt goes over TCP/IP network.\n\n443\n00:21:55.630 --> 00:21:59.728\nSo, now what you're doing is you're using\nsomething that is using basic protocols,\n\n444\n00:21:59.728 --> 00:22:02.997\nand now the attackers can use all\nthe protocols that they're using.\n\n445\n00:22:02.997 --> 00:22:06.058\nThe methods if you will that they're\nusing to attack things like your\n\n446\n00:22:06.058 --> 00:22:07.440\nnetworking communications.\n\n447\n00:22:07.440 --> 00:22:09.615\nBe careful with your printing, and\n\n448\n00:22:09.615 --> 00:22:14.109\nbe mindful of what thier located too,\njust in physical aspect, I work for\n\n449\n00:22:14.109 --> 00:22:19.220\na company too that would put a printer\nin it's own separate room, if you will.\n\n450\n00:22:19.220 --> 00:22:23.480\nCuz if you think about it, if somebody's\napplying for a loan, there could be credit\n\n451\n00:22:23.480 --> 00:22:26.630\ninformation, credit card information on\nthere, so it could be very sensitive.\n\n452\n00:22:26.630 --> 00:22:30.140\nIt's not just necessarily printing\nout Grandma's recipe on Friday so\n\n453\n00:22:30.140 --> 00:22:32.650\nyou can get it baked before you\nget there on Saturday [LAUGH].\n\n454\n00:22:32.650 --> 00:22:36.840\n&gt;&gt; Have you seen The Office episode where\neach individual employee hasa printer code\n\n455\n00:22:36.840 --> 00:22:40.540\nso that there aren't documents just\nsitting and laying in that printing tray,\n\n456\n00:22:40.540 --> 00:22:44.190\nbut it's like, I don't know,\nridiculous like 30 numbers long.\n\n457\n00:22:44.190 --> 00:22:47.006\nAnd poor Kevin, he couldn't remember\na single number to save his life.\n\n458\n00:22:47.006 --> 00:22:48.305\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH] That's right, so\n\n459\n00:22:48.305 --> 00:22:50.631\nwe implement things\nlike time restrictions.\n\n460\n00:22:50.631 --> 00:22:54.450\nAfter a certain time of the day,\nno printing.\n\n461\n00:22:54.450 --> 00:22:56.140\nNo printing anymore, right.\n\n462\n00:22:56.140 --> 00:22:58.280\nWe also have Bluetooth printing\nwe have to worry about.\n\n463\n00:22:58.280 --> 00:22:59.520\nSo if you are using again,\n\n464\n00:22:59.520 --> 00:23:03.070\nif you are using Bluetooth now,\nyou are using a communication that\n\n465\n00:23:03.070 --> 00:23:06.210\ntechnically can be hacked just like\nany other Bluetooth device can.\n\n466\n00:23:06.210 --> 00:23:10.850\nSo again, notice convenience, wireless\nprinting, Bluetooth, so easy to set up,\n\n467\n00:23:10.850 --> 00:23:14.360\nconvenience keeps going up, and\nwell security keeps dropping, right?\n\n468\n00:23:14.360 --> 00:23:16.982\nSo, we gotta make sure that\nwe implement some things so\n\n469\n00:23:16.982 --> 00:23:20.751\nwe're not tipping the scales too much\nwhen it comes to lowering our security.\n\n470\n00:23:20.751 --> 00:23:25.386\nNow, the next one that they want us to\nknow about is, one, that some of you guys\n\n471\n00:23:25.386 --> 00:23:30.188\n[LAUGH] are probably already aware out\nthere, and that's Cameras, IP cameras.\n\n472\n00:23:30.188 --> 00:23:31.642\nLet's say camera systems but\n\n473\n00:23:31.642 --> 00:23:34.610\nyou gotta understand that most\nlikely talking about CCTV and\n\n474\n00:23:34.610 --> 00:23:38.290\nIP based cameras and there are plenty\nof websites that you can go out there.\n\n475\n00:23:38.290 --> 00:23:41.607\nI'm not gonna mention any you guys find\nthem, there's plenty of websites out there\n\n476\n00:23:41.607 --> 00:23:44.880\nwhere I could actually open the browser,\n&gt;&gt; Pretty deplorable, pretty sad,\n\n477\n00:23:44.880 --> 00:23:47.834\nI've seen those before, [LAUGH]\n&gt;&gt; Where you can actually go and\n\n478\n00:23:47.834 --> 00:23:51.772\nyou can watch different companies and\nlocations out there on the Internet that\n\n479\n00:23:51.772 --> 00:23:54.590\nhave their cameras attached\nto the CCPIP base network.\n\n480\n00:23:54.590 --> 00:23:57.272\nSo be careful, right?\n\n481\n00:23:57.272 --> 00:23:59.810\nI mean be careful,\nyou have to protect these devices and\n\n482\n00:23:59.810 --> 00:24:03.267\nthese cameras embedded into themselves\nmight not have a lot of security, So\n\n483\n00:24:03.267 --> 00:24:06.417\nthat's why we wanna use things like\na layer defense system, right?\n\n484\n00:24:06.417 --> 00:24:09.994\nIt's all the other communication\ntechnologies that maybe we can\n\n485\n00:24:09.994 --> 00:24:14.644\nhelp to secure to ensure that things like\nour IP cameras aren't taken advantage of.\n\n486\n00:24:14.644 --> 00:24:17.070\n&gt;&gt; Well obviously in companies\nit's pretty important,\n\n487\n00:24:17.070 --> 00:24:21.870\nbut Wes even think about how popular are\nWiFi cameras are for home based security.\n\n488\n00:24:21.870 --> 00:24:25.890\nAnd so people were using these products\nthinking that it's helping them when in\n\n489\n00:24:25.890 --> 00:24:28.940\nfact they could be broadcasting\nwhen they're home,\n\n490\n00:24:28.940 --> 00:24:31.240\nwhat they're doing while\nthey're home to the attackers.\n\n491\n00:24:31.240 --> 00:24:35.670\n&gt;&gt; Definitely, I actually use\nWiFi cameras in my house too.\n\n492\n00:24:35.670 --> 00:24:37.610\nSo I have to worry about it, right?\n\n493\n00:24:37.610 --> 00:24:40.400\nIt's one of those things that\nwhen I'm leaving I try to\n\n494\n00:24:40.400 --> 00:24:42.120\ndisable if I need to at times.\n\n495\n00:24:42.120 --> 00:24:46.220\nBut I digress here, so some of the other\nthings we have to worry about.\n\n496\n00:24:46.220 --> 00:24:47.889\nThey talk about some\nspecial purpose devices so\n\n497\n00:24:47.889 --> 00:24:49.146\nI just want to kind of mention this.\n\n498\n00:24:49.146 --> 00:24:50.656\nMedical devices, right?\n\n499\n00:24:50.656 --> 00:24:54.297\nThere's been a proof of concept\nthat things like pace makers can be\n\n500\n00:24:54.297 --> 00:24:55.411\nattacked, right?\n\n501\n00:24:55.411 --> 00:24:57.620\nAnd you gotta think about what\nthat pace maker's doing, right?\n\n502\n00:24:57.620 --> 00:25:02.129\nThis is a very, very serious thing\nthat you can attack somebody's\n\n503\n00:25:02.129 --> 00:25:05.684\nmedical device that's\nreally keeping them alive.\n\n504\n00:25:05.684 --> 00:25:07.496\nSo you have to worry\nabout things like that.\n\n505\n00:25:07.496 --> 00:25:11.892\nBig thing that's been in the media is how\nvulnerable are things like your cars,\n\n506\n00:25:11.892 --> 00:25:13.280\nyour vehicles, right?\n\n507\n00:25:13.280 --> 00:25:17.460\nThere's a lot of people that do\nproof of concept that you can\n\n508\n00:25:17.460 --> 00:25:20.270\nattack the embedded systems\nthat are within cars.\n\n509\n00:25:20.270 --> 00:25:21.400\n&gt;&gt; It's absolutely horrifying.\n\n510\n00:25:21.400 --> 00:25:22.806\n&gt;&gt; So yeah,\nwe have to worry about the fact that\n\n511\n00:25:22.806 --> 00:25:24.024\nsomebody could turn off your brakes.\n\n512\n00:25:24.024 --> 00:25:24.666\n&gt;&gt; Yeah.\n&gt;&gt; Right,\n\n513\n00:25:24.666 --> 00:25:26.970\nyou're coming up to a red light and\nyou have no more brakes.\n\n514\n00:25:26.970 --> 00:25:28.550\nSo we have to worry\nabout things like that.\n\n515\n00:25:28.550 --> 00:25:29.700\nAnd then aircraft, right,\n\n516\n00:25:29.700 --> 00:25:32.690\naircraft is obviously something\nthat we have to worry about.\n\n517\n00:25:32.690 --> 00:25:35.320\nBut more so, things like the drones today.\n\n518\n00:25:35.320 --> 00:25:39.700\nThey call out UAV, Unmanned Aerial\nVehicles, well think about drones, right?\n\n519\n00:25:39.700 --> 00:25:43.730\nDrones in and of themselves can\nbe a security vulnerability if\n\n520\n00:25:43.730 --> 00:25:45.820\nthey're in the wrong hands, right?\n\n521\n00:25:45.820 --> 00:25:48.470\nBut then you talk about\nthe communications being intercepted and\n\n522\n00:25:48.470 --> 00:25:52.390\nbeing maybe modified, if you will.\n\n523\n00:25:52.390 --> 00:25:55.577\nAnd then you got a drone that's no longer\nin the control of the original owner.\n\n524\n00:25:55.577 --> 00:25:59.032\nSo we have to keep this is mind, that\nthere are a lot of different specialty\n\n525\n00:25:59.032 --> 00:26:02.825\ndevices out there, like things like\nvehicles and like things like your drones,\n\n526\n00:26:02.825 --> 00:26:04.720\nthat you really have to be careful with,\n\n527\n00:26:04.720 --> 00:26:08.569\nbecause of the fact that they do have a\npotential, that they have vulnerabilities\n\n528\n00:26:08.569 --> 00:26:12.196\nin them that are not even discovered yet,\nthat people can further exploit.\n\n529\n00:26:12.196 --> 00:26:14.382\nAnd anytime we talk\nabout zero day threats,\n\n530\n00:26:14.382 --> 00:26:17.110\nthese threats become very real and\nthey can get scary.\n\n531\n00:26:17.110 --> 00:26:20.340\nSo those are some of the things in the\nembedded systems that's we want you to be\n\n532\n00:26:20.340 --> 00:26:23.760\naware of,\nwe want you to keep in mind that there\n\n533\n00:26:23.760 --> 00:26:26.160\nmany different things that\nyou can do to secure them.\n\n534\n00:26:26.160 --> 00:26:27.209\nDo your research and\n\n535\n00:26:27.209 --> 00:26:31.226\nbe aware of them so that these devices\ndon't become a threat on your network.\n\n536\n00:26:31.226 --> 00:26:35.125\n&gt;&gt; There really is so much to think about\nWes, all these different potential venues\n\n537\n00:26:35.125 --> 00:26:38.907\nfor attackers to take advantage of, so\nwe never said that working as a security\n\n538\n00:26:38.907 --> 00:26:42.720\nprofessional would be for the faint of\nheart, because it definitely isn't.\n\n539\n00:26:42.720 --> 00:26:44.345\nThere's a lot for you, like Wes said,\n\n540\n00:26:44.345 --> 00:26:47.710\ndo your research before you implement\na lot of these embedded systems.\n\n541\n00:26:47.710 --> 00:26:50.480\nBut that is it for this particular\nepisode, so we're gonna go ahead and\n\n542\n00:26:50.480 --> 00:26:51.130\nsign off.\n\n543\n00:26:51.130 --> 00:26:53.170\nRemember, I'm your show host,\nCherokee Boose.\n\n544\n00:26:53.170 --> 00:26:54.020\n&gt;&gt; And I'm Wes Bryan.\n\n545\n00:26:54.020 --> 00:26:57.060\n&gt;&gt; See you next time here at ITProTV.\n\n546\n00:26:57.060 --> 00:27:02.940\n[MUSIC]\n\n547\n00:27:02.940 --> 00:27:06.507\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "213664903"
        },
        {
          "description": "In this episode, Daniel and Wes explain the development and deployment of secure applications. Here they explore development life-cycle models like Waterfall and Agile. They also discuss secure DevOps, version control and change management, secure coding techniques, code quality and testing, and compiled vs. runtime code.",
          "length": "1991",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-6-secure_app_development_and_deployment-050217-PGM.00_38_19_13.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-6-secure_app_development_and_deployment-050217-PGM.00_38_19_13.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-6-secure_app_development_and_deployment-050217-PGM.00_38_19_13.Still001-sm.jpg",
          "title": "Secure App Development and Deployment",
          "transcript": "WEBVTT\n\n1\n00:00:00.306 --> 00:00:02.645\nWelcome to ITPROTV, I'm your host.\n\n2\n00:00:02.645 --> 00:00:07.946\n&gt;&gt; [CROSSTALK].\n\n3\n00:00:07.946 --> 00:00:10.730\n&gt;&gt; You're watching ITPROTV.\n\n4\n00:00:10.730 --> 00:00:12.495\n[MUSIC]\n\n5\n00:00:12.495 --> 00:00:14.586\n&gt;&gt; All right, greetings everyone.\n\n6\n00:00:14.586 --> 00:00:16.940\nWelcome to another exciting\nepisode of ITPROTV.\n\n7\n00:00:16.940 --> 00:00:18.280\nI'm your host, Daniel Lowrie.\n\n8\n00:00:18.280 --> 00:00:19.585\nAnd in today's episode, well,\n\n9\n00:00:19.585 --> 00:00:22.320\nwe're coming back at you with\nmore on our Security+ series.\n\n10\n00:00:22.320 --> 00:00:23.900\nAnd of course,\nlike a day without sunshine,\n\n11\n00:00:23.900 --> 00:00:26.940\nwhat would it be if we didn't have Mr.\nWes Bryan joining us as well?\n\n12\n00:00:26.940 --> 00:00:27.780\nWes, welcome back, sir.\n\n13\n00:00:27.780 --> 00:00:28.880\nWe're so glad to have you again.\n\n14\n00:00:28.880 --> 00:00:29.997\n&gt;&gt; Hey, thanks for having me here, man.\n\n15\n00:00:29.997 --> 00:00:31.151\nHe set that bar kinda high.\n\n16\n00:00:31.151 --> 00:00:32.157\n&gt;&gt; [LAUGH]\n&gt;&gt; Hopefully,\n\n17\n00:00:32.157 --> 00:00:34.774\nI can help you keep that bar up there,\nfor sure.\n\n18\n00:00:34.774 --> 00:00:36.464\nThat's right,\nwe're gonna be looking at some, well,\n\n19\n00:00:36.464 --> 00:00:37.530\nsome interesting concepts today.\n\n20\n00:00:37.530 --> 00:00:40.330\nWe're gonna be looking at application\ndevelopment and deployment.\n\n21\n00:00:40.330 --> 00:00:43.970\nNow you might be asking yourself, well,\nI'm not a programmer, not a developer.\n\n22\n00:00:43.970 --> 00:00:47.490\nWell, remember this is gonna be about\nhow you can secure that environment.\n\n23\n00:00:47.490 --> 00:00:52.400\nAnd some of the concepts that really just\nrevolve around securing some kind of\n\n24\n00:00:52.400 --> 00:00:53.450\ndeveloped environment,\n\n25\n00:00:53.450 --> 00:00:56.340\nand they do have a few objectives\nthat we have to be aware of.\n\n26\n00:00:56.340 --> 00:00:59.340\nSo that is what we're gonna\nlook at in this episode.\n\n27\n00:00:59.340 --> 00:01:02.690\nStarting out, let's go ahead and\ntalk about what the objective is,\n\n28\n00:01:02.690 --> 00:01:06.300\nsummarize secure application\ndevelopment and deployment concepts.\n\n29\n00:01:06.300 --> 00:01:11.400\nSo keep in mind that on the exam, they're\nnot gonna ask you to understand PHP,\n\n30\n00:01:11.400 --> 00:01:13.410\nor C++, or any of the coding languages.\n\n31\n00:01:13.410 --> 00:01:18.010\nThey're just gonna see if you understand\nsome of the concepts about securing\n\n32\n00:01:18.010 --> 00:01:22.160\nthe environments of people that\ndo work in those languages.\n\n33\n00:01:22.160 --> 00:01:25.900\nOne of the first things they talk about\nare development lifecycle models.\n\n34\n00:01:25.900 --> 00:01:30.220\nYou might hear this called because, again,\nremember in security or in networking,\n\n35\n00:01:30.220 --> 00:01:32.325\neverything has to be an acronym, right?\n\n36\n00:01:32.325 --> 00:01:37.970\nSo you might hear of the term SDLC,\nright, Software Development Lifecycle.\n\n37\n00:01:37.970 --> 00:01:40.928\nAnd there are a few models, there\nare four of them that I can think of,\n\n38\n00:01:40.928 --> 00:01:41.746\noff top of my head.\n\n39\n00:01:41.746 --> 00:01:44.974\nBut thanks goodness, they only want you\nto know two different models, right?\n\n40\n00:01:44.974 --> 00:01:48.803\nThey call out what's known\nas the Waterfall SDLC and\n\n41\n00:01:48.803 --> 00:01:50.986\nthey call out the Agile SDLC.\n\n42\n00:01:50.986 --> 00:01:55.861\nFor those of you that are maybe going\nto higher levels of certifications,\n\n43\n00:01:55.861 --> 00:01:59.332\nmaybe you might include\nthings like the iterative.\n\n44\n00:01:59.332 --> 00:02:00.803\nI can say that eventually well.\n\n45\n00:02:00.803 --> 00:02:01.829\n&gt;&gt; Yeah. [LAUGH] &gt;&gt; Thank you.\n\n46\n00:02:01.829 --> 00:02:02.568\nWoo, got that one out.\n\n47\n00:02:02.568 --> 00:02:03.333\n&gt;&gt; That's the word.\n\n48\n00:02:03.333 --> 00:02:05.538\n&gt;&gt; I was gonna say thank goodness,\nthey're not saying that one in there,\n\n49\n00:02:05.538 --> 00:02:06.440\ncuz I can't either.\n\n50\n00:02:06.440 --> 00:02:10.170\nSo iterative, as well as V-shaped.\n\n51\n00:02:10.170 --> 00:02:13.470\nBut again, those are for\nanother day and another certification.\n\n52\n00:02:13.470 --> 00:02:16.740\nSo let's go ahead and start with\nthe first one, waterfall, right?\n\n53\n00:02:16.740 --> 00:02:18.975\nWhat is this?\nWell, this isn't an avalanche, right,\n\n54\n00:02:18.975 --> 00:02:20.143\nthat we're talking about.\n\n55\n00:02:20.143 --> 00:02:22.485\nWe certainly don't want\nanything destructive.\n\n56\n00:02:22.485 --> 00:02:26.629\nBut what this basically is,\nis it's a sequential process, right,\n\n57\n00:02:26.629 --> 00:02:29.900\nin the development lifecycle and\nthe whole process.\n\n58\n00:02:29.900 --> 00:02:31.370\nAnd in fact, for both of these models,\n\n59\n00:02:31.370 --> 00:02:35.110\nthe process is divided up\ninto individual stages.\n\n60\n00:02:35.110 --> 00:02:38.810\nEach phase has to be completed in\nthe waterfall model before you\n\n61\n00:02:38.810 --> 00:02:41.160\nmove to the next stage.\n\n62\n00:02:41.160 --> 00:02:46.340\nKeep in mind that one of the things to\nconsider about the waterfall model is\n\n63\n00:02:46.340 --> 00:02:52.400\nthe fact that any delivery of a product is\nusually late in the development lifecycle.\n\n64\n00:02:52.400 --> 00:02:56.550\nAnd another thing to keep in mind\nis that after you finish a phase,\n\n65\n00:02:56.550 --> 00:02:58.190\nit's very difficult to go back a phase.\n\n66\n00:02:58.190 --> 00:02:59.170\nLet me show you what I mean here.\n\n67\n00:02:59.170 --> 00:03:01.630\nThere's a few different phases\nin the design here, right?\n\n68\n00:03:01.630 --> 00:03:04.560\nSo, first you have step one, right?\n\n69\n00:03:04.560 --> 00:03:07.170\nThat is Requirement Analysis, right?\n\n70\n00:03:07.170 --> 00:03:12.560\nAll requirements are captured inside of\nthis phase of the software development.\n\n71\n00:03:12.560 --> 00:03:16.010\nThings like your walkthroughs,\nyour brainstorming, your roundtables where\n\n72\n00:03:16.010 --> 00:03:19.850\nwe're having discussions, if you will,\nto understand what those requirements are.\n\n73\n00:03:19.850 --> 00:03:21.610\nAnd then producing, see,\n\n74\n00:03:21.610 --> 00:03:25.220\nwe're gonna try to tell you what you\nshould be producing at each stage, too.\n\n75\n00:03:25.220 --> 00:03:28.160\nProducing the requirement\ndocumentation that you need.\n\n76\n00:03:28.160 --> 00:03:30.800\nNow once that's done,\nyou move to the next phase.\n\n77\n00:03:30.800 --> 00:03:32.310\nAnd you'll see I drew the arrows so\n\n78\n00:03:32.310 --> 00:03:34.910\nyou can kind of see why they\ncall it the waterfall model.\n\n79\n00:03:34.910 --> 00:03:37.950\nJust see how it just everything\ntrickles down to the final process of\n\n80\n00:03:37.950 --> 00:03:39.750\nMaintenance, right?\n\n81\n00:03:39.750 --> 00:03:42.530\nIn step two, we have system design, right?\n\n82\n00:03:42.530 --> 00:03:44.176\nWhen we talk about system design,\n\n83\n00:03:44.176 --> 00:03:48.339\nwe're talking about now capturing the\nhardware and software requirements, right?\n\n84\n00:03:48.339 --> 00:03:51.859\nDefining what the system architecture\nis going to be, and then,\n\n85\n00:03:51.859 --> 00:03:54.230\nat the end, what are we producing, right?\n\n86\n00:03:54.230 --> 00:03:55.425\nWhat are we doing here?\n\n87\n00:03:55.425 --> 00:03:58.518\nWe’re producing the design documentation,\nand\n\n88\n00:03:58.518 --> 00:04:02.720\nfinalizing that step in this process\nas we move into the next stage.\n\n89\n00:04:02.720 --> 00:04:07.254\nAnd that next step, or stage three,\nis the implementation.\n\n90\n00:04:07.254 --> 00:04:11.340\nAll right, now implementation is usually\nwhere you start creating the code.\n\n91\n00:04:11.340 --> 00:04:15.945\nAnd a lot of times when your developments\nor developers are doing the code,\n\n92\n00:04:15.945 --> 00:04:19.893\nwhat they do is they basically\ncreate code in small increments,\n\n93\n00:04:19.893 --> 00:04:22.840\nsmall programs and\nthese are called the units.\n\n94\n00:04:22.840 --> 00:04:26.020\nYou might hear the term unit-testing,\nright?\n\n95\n00:04:26.020 --> 00:04:27.307\nAnd that's what we're gonna do.\n\n96\n00:04:27.307 --> 00:04:30.703\nIn this step, we're gonna\nproduce the unit test cases and\n\n97\n00:04:30.703 --> 00:04:33.698\nwe're gonna document\nthe results of those tests.\n\n98\n00:04:33.698 --> 00:04:36.630\nAnd then, we move in to step four.\n\n99\n00:04:36.630 --> 00:04:40.210\nNow, step four, I've seen a couple of\ndifferent explanations to this model.\n\n100\n00:04:40.210 --> 00:04:41.980\nSome people might say testing.\n\n101\n00:04:41.980 --> 00:04:45.230\nSome people might say testing and\nintegration, right?\n\n102\n00:04:45.230 --> 00:04:49.710\nAnd this is where we're taking those\ntested units, right, from the last step.\n\n103\n00:04:49.710 --> 00:04:56.090\nAnd we're ensuring that every single unit\nworks as we expected it to work, right.\n\n104\n00:04:56.090 --> 00:05:00.983\nSo, again that's the testing phase, and\nwe document things like anomalies, right?\n\n105\n00:05:00.983 --> 00:05:04.756\nIn this testing phase,\nyou might do security checkpoints, right?\n\n106\n00:05:04.756 --> 00:05:08.662\nAnd in fact, honestly in the design\nyou might do a security audit, right,\n\n107\n00:05:08.662 --> 00:05:09.965\na security checkpoint.\n\n108\n00:05:09.965 --> 00:05:12.361\nSo, if we're in the testing phase,\nwhat do we wanna do?\n\n109\n00:05:12.361 --> 00:05:15.450\nWe wanna stress test\nwhere we're at right now.\n\n110\n00:05:15.450 --> 00:05:16.560\nMaybe do a little fuzzing.\n\n111\n00:05:16.560 --> 00:05:17.751\nMaybe do a little vulnerability testing.\n\n112\n00:05:17.751 --> 00:05:21.230\nMaybe do a pen testing on it before we\nmove into the deployment phase, right?\n\n113\n00:05:21.230 --> 00:05:24.170\nAnd then we document those audits.\n\n114\n00:05:24.170 --> 00:05:30.190\nWhat did we find, confirming, or\neither if we can move into the next phase.\n\n115\n00:05:30.190 --> 00:05:34.774\nSo again, production on this one producing\ntest cases in the test reports as part of\n\n116\n00:05:34.774 --> 00:05:36.944\nthe testing and integration process.\n\n117\n00:05:36.944 --> 00:05:42.200\nStep five, again, this is going to be\nthe deployment phase, right, we deploy.\n\n118\n00:05:42.200 --> 00:05:46.419\nThis is where we are basically,\nit's performed after the functional and\n\n119\n00:05:46.419 --> 00:05:48.745\nnon-functional testing is finished.\n\n120\n00:05:48.745 --> 00:05:51.868\nWe're making sure that\nthe environment is up and\n\n121\n00:05:51.868 --> 00:05:55.764\nrunning that the software needs\nto be deployed to and run in.\n\n122\n00:05:55.764 --> 00:05:58.981\nAnd again, we could be doing things\nlike deploying to the market or\n\n123\n00:05:58.981 --> 00:06:01.060\na customer environment.\n\n124\n00:06:01.060 --> 00:06:06.000\nFinally, what this does is it produces the\nenvironment definitions or specifications.\n\n125\n00:06:06.000 --> 00:06:07.970\nThe last one is maintenance, and\n\n126\n00:06:07.970 --> 00:06:10.370\nmaintenance is always an ongoing thing,\nright?\n\n127\n00:06:10.370 --> 00:06:12.070\nYou think about your operating system,\nright,\n\n128\n00:06:12.070 --> 00:06:13.880\nhow many upgrades have you probably seen?\n\n129\n00:06:13.880 --> 00:06:15.870\nHow many updates to an operating system,\nDan,\n\n130\n00:06:15.870 --> 00:06:19.380\nhave you seen, let's say to Windows,\nin the last ten years?\n\n131\n00:06:19.380 --> 00:06:20.440\n&gt;&gt; Thousands upon thousands.\n\n132\n00:06:20.440 --> 00:06:22.180\n&gt;&gt; That was a bad question, right?\n\n133\n00:06:22.180 --> 00:06:22.710\n&gt;&gt; Yeah.\n[LAUGH]\n\n134\n00:06:22.710 --> 00:06:24.485\n&gt;&gt; There's just no way to document.\n\n135\n00:06:24.485 --> 00:06:29.535\nSo that's ongoing maintenance of a classic\nexample of a piece of software, right?\n\n136\n00:06:29.535 --> 00:06:32.935\nNotepad ++, I think of one,\nwe use it a lot here within the studios.\n\n137\n00:06:32.935 --> 00:06:36.035\nMany different revisions and\nversions of that.\n\n138\n00:06:36.035 --> 00:06:37.470\nAnd what are they doing?\n\n139\n00:06:37.470 --> 00:06:38.920\nBug fixes, right?\n\n140\n00:06:38.920 --> 00:06:40.900\nAnd implementing additional\nfunctionality too.\n\n141\n00:06:40.900 --> 00:06:45.278\nSo maintenance isn't a very important\nprocess and, it might be application\n\n142\n00:06:45.278 --> 00:06:50.012\nenhancements to incorporate some kind of\nfeature or functionality down the road.\n\n143\n00:06:50.012 --> 00:06:53.655\nHow about this, if the user\nexperiences some kind of issue, right?\n\n144\n00:06:53.655 --> 00:06:57.535\nAnd we have to document that and\nthen we have to apply a fix, if you will,\n\n145\n00:06:57.535 --> 00:06:58.900\nto those issues.\n\n146\n00:06:58.900 --> 00:07:01.760\nAll right, and\nthat's what this step produces, right?\n\n147\n00:07:01.760 --> 00:07:04.940\nIt produces the fix issues and\ncreates a new list of features that could\n\n148\n00:07:04.940 --> 00:07:09.870\npotentially be deployed to that\napplication as it matures.\n\n149\n00:07:09.870 --> 00:07:14.450\nSo that, and you could see, just each\nstep as we go through this lifecycle,\n\n150\n00:07:14.450 --> 00:07:17.610\nit's one of the reasons\nthey call it the waterfall.\n\n151\n00:07:17.610 --> 00:07:21.740\nNow, the other one that they call out,\nthey call out something known as Agile and\n\n152\n00:07:21.740 --> 00:07:24.500\nboy, this doesn't look like Agile at all,\ndoes it?\n\n153\n00:07:24.500 --> 00:07:26.175\n&gt;&gt; Man, that's a little bit more\ncomplex than what you just showed us.\n\n154\n00:07:26.175 --> 00:07:28.161\n[LAUGH]\n&gt;&gt; That's right, that's right.\n\n155\n00:07:28.161 --> 00:07:31.672\nSo, why would we use something like\nthis that looks a lot more complex?\n\n156\n00:07:31.672 --> 00:07:37.297\nAll right, well, the Agile one treats\nevery individual product, if you will,\n\n157\n00:07:37.297 --> 00:07:42.524\nevery project, it divides it into\nsmaller tasks and smaller timeframes.\n\n158\n00:07:42.524 --> 00:07:46.010\nSee, one of the drawbacks to\nthe waterfall model is the fact that,\n\n159\n00:07:46.010 --> 00:07:50.430\nnotice how late in that model before\nwe ever got a deployment, right?\n\n160\n00:07:50.430 --> 00:07:51.542\nThat's not good for managers.\n\n161\n00:07:51.542 --> 00:07:53.650\nThe C-level people say,\nwell, where's my product?\n\n162\n00:07:53.650 --> 00:07:56.690\nWell, we're not at that phase,\nwe got six more phases to go, right?\n\n163\n00:07:56.690 --> 00:08:01.837\nSo, what this does is it really tries to-\n&gt;&gt; It's a people pleaser.\n\n164\n00:08:01.837 --> 00:08:02.607\n[LAUGH]\n&gt;&gt; It is,\n\n165\n00:08:02.607 --> 00:08:04.209\nit's an adaptive approach, right?\n\n166\n00:08:04.209 --> 00:08:05.944\nAnd we break down each step, right?\n\n167\n00:08:05.944 --> 00:08:09.997\nResource requirements are minimized\nin this kind of level.\n\n168\n00:08:09.997 --> 00:08:12.545\nAnd it delivers a partial working\n\n169\n00:08:12.545 --> 00:08:18.060\nsolution very early on in\nthe software development lifecycle.\n\n170\n00:08:18.060 --> 00:08:20.750\nKeep in mind, this might not\nbe something that's ideal for\n\n171\n00:08:20.750 --> 00:08:23.990\nhandling large complex dependencies.\n\n172\n00:08:23.990 --> 00:08:28.380\nBut you can see, we still have planning,\nand we have analysis, right?\n\n173\n00:08:28.380 --> 00:08:33.310\nBut then when we go into the first\niteration, right, that smaller project,\n\n174\n00:08:33.310 --> 00:08:38.000\nwe get our design, development, testing,\nand analysis, and deployment, right?\n\n175\n00:08:38.000 --> 00:08:42.720\nSo we have a faster time to deployment,\nand then we might have, well,\n\n176\n00:08:42.720 --> 00:08:47.420\nmaybe that doesn't work, we go into\niteration two, and we do the same thing.\n\n177\n00:08:47.420 --> 00:08:50.760\nAgain we have design,\ndevelopment, test, and analysis.\n\n178\n00:08:50.760 --> 00:08:52.480\nAnd then we deploy, right?\n\n179\n00:08:52.480 --> 00:08:56.610\nAnd then finally the life cycle\nbasically repeats itself,\n\n180\n00:08:56.610 --> 00:08:59.060\nright, until maybe we\nhave a final iteration.\n\n181\n00:08:59.060 --> 00:09:02.658\nBut if you notice it's treating\neach individual project,\n\n182\n00:09:02.658 --> 00:09:06.780\nright, where we're just breaking\nit down and we are deploying.\n\n183\n00:09:06.780 --> 00:09:10.330\nAnd we have some kind\nof functional product\n\n184\n00:09:10.330 --> 00:09:14.190\nbefore the absolute end of\nthat development lifecycle.\n\n185\n00:09:15.290 --> 00:09:16.530\nAll right.\nSo\n\n186\n00:09:16.530 --> 00:09:21.900\nthat is an example of some of the SDLCs\nthat you need to be aware of for the exam.\n\n187\n00:09:23.100 --> 00:09:26.770\nNow, some of the other things\nthat they call out, and really,\n\n188\n00:09:26.770 --> 00:09:30.520\nthis kind of coincides with everything\nwe've already been talking about.\n\n189\n00:09:30.520 --> 00:09:36.670\nIn fact, Dan and I were talking about\nthis before we went on camera here.\n\n190\n00:09:36.670 --> 00:09:40.430\nAnd Dan was mentioning the fact that,\nwell Dan, you were mentioning the fact,\n\n191\n00:09:40.430 --> 00:09:45.270\nnot everybody wants just one specific\nrole within your company today.\n\n192\n00:09:45.270 --> 00:09:46.920\nIt's more of what, it's all inclusive?\n\n193\n00:09:46.920 --> 00:09:50.600\n&gt;&gt; Yeah, we're seeing a definite trend\nin the business toward what's known as\n\n194\n00:09:50.600 --> 00:09:55.210\ndev ops, where you have\npeople that are multifaceted.\n\n195\n00:09:55.210 --> 00:09:56.810\nThey're not just security administrators.\n\n196\n00:09:56.810 --> 00:09:58.570\nThey're not just systems administrators.\n\n197\n00:09:58.570 --> 00:10:01.250\nThey're not just a network administrator.\n\n198\n00:10:01.250 --> 00:10:06.740\nThey do all of those jobs plus doing some\ncoding, maybe working with databases.\n\n199\n00:10:06.740 --> 00:10:09.070\nThey want you to have a well\nrounded knowledge base.\n\n200\n00:10:09.070 --> 00:10:12.340\nWe're seeing a very good push\ntoward that here lately.\n\n201\n00:10:12.340 --> 00:10:13.820\nAnd DevOps is what they tend to call that.\n\n202\n00:10:13.820 --> 00:10:17.480\nAnd that's why probably they're\nshowing up here on this exam.\n\n203\n00:10:17.480 --> 00:10:19.140\n&gt;&gt; That's exactly it, and\nthat's what I was gonna say.\n\n204\n00:10:19.140 --> 00:10:23.360\nThat's why we're seeing things like this\nbecause it isn't just that cookie cutter\n\n205\n00:10:24.750 --> 00:10:26.330\ndepartment that you work in anymore.\n\n206\n00:10:26.330 --> 00:10:29.050\nSo, they do call out things\nlike Secure DevOps and\n\n207\n00:10:29.050 --> 00:10:32.920\nsome of the things they call out are\nthings like security automation, right?\n\n208\n00:10:32.920 --> 00:10:37.375\nAutomation in general, one of the things\nthat it does, is it reduces the time that\n\n209\n00:10:37.375 --> 00:10:41.897\nit takes to perform some action, right,\nand reduces the administrative effort if\n\n210\n00:10:41.897 --> 00:10:46.570\nyou will, and could potentially drive down\ncost, if you will, if it's automated.\n\n211\n00:10:46.570 --> 00:10:50.570\nSecurity automation making sure\nthat we do have security deployed\n\n212\n00:10:50.570 --> 00:10:53.330\nin a way that can also reduce\nthings like human error.\n\n213\n00:10:53.330 --> 00:10:56.350\nThey also call out things\nlike continuous integration.\n\n214\n00:10:56.350 --> 00:11:00.180\nWhen we talk about continuous integration\njust a development practice, if you will,\n\n215\n00:11:00.180 --> 00:11:02.960\nthat requires the development teams\n\n216\n00:11:02.960 --> 00:11:05.890\nto store their code into\na centralized repository.\n\n217\n00:11:05.890 --> 00:11:10.390\nAnd they use things like version control\nmanagement software, if you will,\n\n218\n00:11:10.390 --> 00:11:12.100\nlike Git.\n\n219\n00:11:12.100 --> 00:11:14.770\nAnd basically all\nthe changes are isolated,\n\n220\n00:11:14.770 --> 00:11:19.780\ntested immediately throughout\nan automatic build process.\n\n221\n00:11:19.780 --> 00:11:23.160\nWhat that allows us to do is it's\neasier to spot errors, if you will,\n\n222\n00:11:23.160 --> 00:11:27.420\nin the code and correct them as soon\nas possible, rather than reviewing that\n\n223\n00:11:27.420 --> 00:11:31.610\ncode all of the way at the end\nof the deployment life cycle and\n\n224\n00:11:31.610 --> 00:11:36.210\nhaving a lot more code to review and\nthen potentially a lot more bugs to fix.\n\n225\n00:11:36.210 --> 00:11:38.600\nOther things we have, base lining.\n\n226\n00:11:38.600 --> 00:11:41.870\nBase lining allows you to build your\nbusiness case essentially where\n\n227\n00:11:41.870 --> 00:11:43.320\nyou can apply targets and\n\n228\n00:11:43.320 --> 00:11:48.130\ngoals, and you can turn around and\nyou can measure the level of progress.\n\n229\n00:11:48.130 --> 00:11:49.000\nImmutable systems.\n\n230\n00:11:49.000 --> 00:11:53.870\nImmutable systems are components basically\nthat are replaced and they aren't changed.\n\n231\n00:11:53.870 --> 00:11:57.930\nAgain, applications and services basically\n\n232\n00:11:57.930 --> 00:12:02.500\nare redeployed rather than\nreconfigured when a change occurs.\n\n233\n00:12:02.500 --> 00:12:04.130\nThat's an immutable system.\n\n234\n00:12:05.230 --> 00:12:09.540\nThe other thing that they call out too\nare things like infrastructure as a code.\n\n235\n00:12:09.540 --> 00:12:12.090\nAnd we're seeing a lot of this and\nbasically what it does,\n\n236\n00:12:12.090 --> 00:12:16.300\nis it treats your infrastructure as\nsoftware, essentially that can be managed\n\n237\n00:12:16.300 --> 00:12:20.420\nwith tools, the same thing that\nyour software developers use.\n\n238\n00:12:20.420 --> 00:12:23.190\nInfrastructure changes can be made easily.\n\n239\n00:12:23.190 --> 00:12:27.630\nThey can be made faster and at the same\ntime, still maintaining the reliability.\n\n240\n00:12:27.630 --> 00:12:30.557\nSo remember infrastructure as a code,\nagain,\n\n241\n00:12:30.557 --> 00:12:34.151\nit just it does make infrastructure\nchanges a lot easier.\n\n242\n00:12:34.151 --> 00:12:38.289\nNow I kinda mentioned in some of this when\nwe were talking about secure dev ops,\n\n243\n00:12:38.289 --> 00:12:42.255\nwe talk about things like version\ncontrol and change management, right?\n\n244\n00:12:42.255 --> 00:12:45.375\nMost software developers are gonna\nwork in a group of teams.\n\n245\n00:12:45.375 --> 00:12:48.565\nAnd these teams are constantly\nwriting to the code.\n\n246\n00:12:48.565 --> 00:12:50.445\nAll right, version control software,\n\n247\n00:12:50.445 --> 00:12:55.100\nwhat it does is it maintains\nrecords of changes to the code.\n\n248\n00:12:55.100 --> 00:12:58.720\nAnd if a mistake is made,\nwouldn't it be nice to just go ahead and\n\n249\n00:12:58.720 --> 00:13:02.240\nkind of rollback to\nan earlier point in time?\n\n250\n00:13:02.240 --> 00:13:05.520\nThink of your virtualization\nsoftware that we use.\n\n251\n00:13:05.520 --> 00:13:07.840\nWe talk about using VM Snapshots.\n\n252\n00:13:07.840 --> 00:13:08.690\nAnd what is a snapshot?\n\n253\n00:13:08.690 --> 00:13:13.010\nIt's a point in time configuration,\nor a point in time copy, if you will,\n\n254\n00:13:13.010 --> 00:13:17.790\ncarbon copy of the configuration state\nof that virtual machine at the time.\n\n255\n00:13:17.790 --> 00:13:20.625\nWell Wes is good at building labs and\nbringing down networks, so\n\n256\n00:13:20.625 --> 00:13:25.440\n[LAUGH] if I bring down a network as I'm\ndeveloping a lab to show you guys, and\n\n257\n00:13:25.440 --> 00:13:28.710\nI make a mistake,\nI can just revert the changes, right?\n\n258\n00:13:28.710 --> 00:13:29.500\nAnd we could start over.\n\n259\n00:13:29.500 --> 00:13:31.415\nAnd that's one of the things\nthat version control does,\n\n260\n00:13:31.415 --> 00:13:34.790\nis that if those mistakes are made or\nif a bug is found,\n\n261\n00:13:34.790 --> 00:13:38.710\nit does allow the developers that can\nroll back to a previous version and\n\n262\n00:13:38.710 --> 00:13:42.470\nessentially do a comparison and\na correction if it's necessary.\n\n263\n00:13:42.470 --> 00:13:44.690\nSo again, that's version control and\nmanaging.\n\n264\n00:13:44.690 --> 00:13:48.790\nOne of the great things about this\nis the fact that it minimizes your\n\n265\n00:13:48.790 --> 00:13:51.990\ninterruptions and\nit eliminates things like file locking.\n\n266\n00:13:51.990 --> 00:13:55.550\nIt's kind of a pain to do file locking,\nright?\n\n267\n00:13:55.550 --> 00:13:56.840\nSorry, I'm making a change, hold on.\n\n268\n00:13:56.840 --> 00:13:58.970\nThe whole team's gotta stop\nbecause I'm making the change.\n\n269\n00:13:58.970 --> 00:14:00.765\nLet's just put that on hold.\n\n270\n00:14:00.765 --> 00:14:01.745\nWe really can't do that,\n\n271\n00:14:01.745 --> 00:14:05.975\nespecially when you talk about multiple\nteams working in different units, doing\n\n272\n00:14:05.975 --> 00:14:09.995\nunit testing, version control becomes\nsomething that is very, very important.\n\n273\n00:14:09.995 --> 00:14:14.395\n&gt;&gt; Yeah, change management can really\nmake or break a system because if Wes and\n\n274\n00:14:14.395 --> 00:14:17.085\nI are working on a project and\nWes is making changes,\n\n275\n00:14:17.085 --> 00:14:20.625\nand I have no idea that those changes are\nbeing made, or that he's the one that did\n\n276\n00:14:20.625 --> 00:14:24.380\nthem, then I have to look and\ngo hmm, what's going on here.\n\n277\n00:14:24.380 --> 00:14:28.460\nWe kind of got to play detective to figure\nout where the change problem came from,\n\n278\n00:14:28.460 --> 00:14:30.510\nreverse back to where it was before that.\n\n279\n00:14:30.510 --> 00:14:32.950\nSo keeping a change management\nsystem in play where\n\n280\n00:14:32.950 --> 00:14:35.650\nWes has to get approval\nbefore he makes a change.\n\n281\n00:14:35.650 --> 00:14:36.880\nThen the change gets approved.\n\n282\n00:14:36.880 --> 00:14:37.720\nIt's inspected.\n\n283\n00:14:37.720 --> 00:14:41.390\nIt's looked up by someone who is\nover him watching the project.\n\n284\n00:14:41.390 --> 00:14:44.400\nAnd then saying, yes, let's make that,\nI think this will be a good change, Wes\n\n285\n00:14:44.400 --> 00:14:48.700\nmake this change, then submits the fact\nthat it was changed, and when that becomes\n\n286\n00:14:48.700 --> 00:14:53.540\nthe standard, the change is now over, now\nwe have a new set of equilibriums to date.\n\n287\n00:14:53.540 --> 00:14:58.150\nIt helps keep your projects in check,\nso that they don't continue too far\n\n288\n00:14:58.150 --> 00:15:01.750\nout into the weeds, if that's where\nthey're going, helps keeps us safe.\n\n289\n00:15:01.750 --> 00:15:04.080\n&gt;&gt; Definitely, and especially if you're\npushing it to a production environment.\n\n290\n00:15:04.080 --> 00:15:05.513\n&gt;&gt; Yeah.\n&gt;&gt; You wanna have all those checks and\n\n291\n00:15:05.513 --> 00:15:07.915\nbalances before you ever push to\nthe [LAUGH] production environment.\n\n292\n00:15:07.915 --> 00:15:09.140\n&gt;&gt; Yeah.\n&gt;&gt; So, that's a good thing.\n\n293\n00:15:09.140 --> 00:15:12.200\nThey also talk about things like\nprovisioning and deprovisioning.\n\n294\n00:15:12.200 --> 00:15:16.020\nAgain, this can become kind of\nan administrative complexity, right?\n\n295\n00:15:16.020 --> 00:15:19.510\nWe think of like, for instance, I always\ncompare it to things like VMs, right?\n\n296\n00:15:19.510 --> 00:15:22.440\nAnd the reason I'm comparing it to\nVMs is because inside of development\n\n297\n00:15:22.440 --> 00:15:25.890\ntoday we have a virtualized type\ninfrastructure called containers.\n\n298\n00:15:25.890 --> 00:15:29.940\nYou pull down a container, pull down\nan application, pulls down your programing\n\n299\n00:15:29.940 --> 00:15:34.060\nenvironment, and then the problem\nis with improper provisioning and\n\n300\n00:15:34.060 --> 00:15:37.880\ndeprovisioning, we can get what\na condition that's known as sprawl.\n\n301\n00:15:37.880 --> 00:15:42.404\nAll right, in virtualization software,\nwe call sprawl is the fact that it's so\n\n302\n00:15:42.404 --> 00:15:44.430\neasy to just spin up a VM.\n\n303\n00:15:44.430 --> 00:15:48.860\nRight, well what if you've got\na centralized server that's running all of\n\n304\n00:15:48.860 --> 00:15:51.570\nyour virtual machines, and you've\ngot everybody all over your network,\n\n305\n00:15:51.570 --> 00:15:53.970\njust has the ability to bring up VMs.\n\n306\n00:15:53.970 --> 00:15:55.730\nAnd what if they don't de-provision them?\n\n307\n00:15:55.730 --> 00:15:57.190\nWell it's the same thing with containers.\n\n308\n00:15:57.190 --> 00:16:00.313\nSo you have to make sure that there\nare appropriate provisioning and\n\n309\n00:16:00.313 --> 00:16:03.344\nde-provisioning scenarios,\nif you will, or documentation.\n\n310\n00:16:03.344 --> 00:16:06.456\nSo you can help things like\ncontainer sprawl, if you will, and\n\n311\n00:16:06.456 --> 00:16:09.054\nagain it becomes more of\na nightmare to understand.\n\n312\n00:16:09.054 --> 00:16:12.696\nWhat are the resources I have available,\nversus what are the resources That I've\n\n313\n00:16:12.696 --> 00:16:14.978\nused, versus what is\nthe cost of those resources.\n\n314\n00:16:14.978 --> 00:16:18.992\nSo again making sure that\nwe have that in place.\n\n315\n00:16:18.992 --> 00:16:21.899\nNow, Dan, some of the last few\nthings that they talk about,\n\n316\n00:16:21.899 --> 00:16:24.356\nthey kinda get into\nthe secure coding techniques.\n\n317\n00:16:24.356 --> 00:16:29.527\nAnd I know this guy over here,\nlet me get my right from my left,\n\n318\n00:16:29.527 --> 00:16:34.401\nI know this guy over here just\ndrools when he sees a database\n\n319\n00:16:34.401 --> 00:16:37.508\nthat isn't theoretically secure.\n\n320\n00:16:37.508 --> 00:16:41.425\nSo we have to make sure that we have\ngood secure coding techniques, right,\n\n321\n00:16:41.425 --> 00:16:45.404\nbecause we have to protect against people\nthat might attack things like your\n\n322\n00:16:45.404 --> 00:16:46.535\ndatabases, right?\n\n323\n00:16:46.535 --> 00:16:50.424\n&gt;&gt; Even databases, even just applications\nin general, if you guys are developing\n\n324\n00:16:50.424 --> 00:16:54.316\nan application of some sort that maybe\njust does some stand-alone thing that's\n\n325\n00:16:54.316 --> 00:16:58.320\na line of business type of software,\nmaybe not even connected to a database.\n\n326\n00:16:58.320 --> 00:17:01.090\nBut databases are always\nreally nice to have, right.\n\n327\n00:17:01.090 --> 00:17:05.850\nYou have to protect them cuz if\nthey're hooking into the system and\n\n328\n00:17:05.850 --> 00:17:11.555\nthen I'm able to compromise that\napplication, I then compromise the system.\n\n329\n00:17:11.555 --> 00:17:15.173\nBecause I'm allowed access to the system\nthrough the insecure application.\n\n330\n00:17:15.173 --> 00:17:18.762\nSo secure coding procedure\nis a very important and\n\n331\n00:17:18.762 --> 00:17:21.158\nvital aspect of your lifecycle.\n\n332\n00:17:21.158 --> 00:17:22.758\n&gt;&gt; Most definitely.\nI'll give you an example, right.\n\n333\n00:17:22.758 --> 00:17:24.211\nSo he's talking about\nthe application itself.\n\n334\n00:17:24.211 --> 00:17:26.949\nHow about proper error handling, right?\n\n335\n00:17:26.949 --> 00:17:28.570\nWe do fuzzing, right, we do fuzzing.\n\n336\n00:17:28.570 --> 00:17:31.376\nCuz we can send that application all\nthe random information you can, and\n\n337\n00:17:31.376 --> 00:17:32.890\nlet's see what it does.\n\n338\n00:17:32.890 --> 00:17:37.314\nWell if there's an error that\ncomes back that says sorry,\n\n339\n00:17:37.314 --> 00:17:40.850\nthat username's password was wrong, what?\n\n340\n00:17:40.850 --> 00:17:44.005\nWell you've told me that the username was\nright, but now I don't have to guess that\n\n341\n00:17:44.005 --> 00:17:46.367\nanymore, now I just have to\nfigure out the password, right?\n\n342\n00:17:46.367 --> 00:17:48.581\nOr that user account is disabled.\n\n343\n00:17:48.581 --> 00:17:52.611\nRight, proper error handling, we wanna\nmake sure that if an error is encountered,\n\n344\n00:17:52.611 --> 00:17:55.648\nyou don't give the attacker more\ninformation than they need.\n\n345\n00:17:55.648 --> 00:17:58.082\nAn error occurred, that's good enough.\n\n346\n00:17:58.082 --> 00:18:00.305\nSomething didn't go right,\nthat's all we need to know.\n\n347\n00:18:00.305 --> 00:18:01.379\nWe don't need to know any,\n\n348\n00:18:01.379 --> 00:18:04.156\nthe attacker doesn't need to know\nanything other than that, right?\n\n349\n00:18:04.156 --> 00:18:08.276\n&gt;&gt; You also have to worry about,\nwhen it comes to error handling,\n\n350\n00:18:08.276 --> 00:18:13.175\nproper error handling, if you have\na username field or a password field and\n\n351\n00:18:13.175 --> 00:18:16.590\nI can just put in 10,000 capital As.\n\n352\n00:18:16.590 --> 00:18:18.240\nHow does the program handle that, right?\n\n353\n00:18:18.240 --> 00:18:19.970\nDoes it just crash?\n\n354\n00:18:19.970 --> 00:18:23.560\nOr does it say,\nyou've put in an improper string for\n\n355\n00:18:23.560 --> 00:18:27.078\na username or password,\nand that's not allowed?\n\n356\n00:18:27.078 --> 00:18:31.938\nThat's proper error handling,\nI expect to see this type of input, and\n\n357\n00:18:31.938 --> 00:18:35.267\nif I don't see that,\nI'm not going to allow it.\n\n358\n00:18:35.267 --> 00:18:36.890\nThat's proper error handling.\n\n359\n00:18:36.890 --> 00:18:40.615\nSo if I can do things like fuzzing,\nif you don't do proper error handling,\n\n360\n00:18:40.615 --> 00:18:42.937\nbecause then I can send that 10,000 As.\n\n361\n00:18:42.937 --> 00:18:46.874\nAnd if it crashes your system, well,\nnow I'm on my way to doing something like\n\n362\n00:18:46.874 --> 00:18:51.185\na buffer overflow and compromising the\nentire application, maybe even the system.\n\n363\n00:18:51.185 --> 00:18:54.322\n&gt;&gt; Absolutely, denial of service attacks,\nand now you've got availability,\n\n364\n00:18:54.322 --> 00:18:56.948\nlet alone what he's talking about,\nintegrity of your data too.\n\n365\n00:18:56.948 --> 00:18:59.707\nSo we're talking about some problems,\nso how do we do that, right?\n\n366\n00:18:59.707 --> 00:19:03.078\nWell, that leads us to the next\ntopic of proper coding and\n\n367\n00:19:03.078 --> 00:19:06.810\ntechniques is proper input validation,\nright?\n\n368\n00:19:06.810 --> 00:19:09.630\nJust like Dan said,\nwhat do I expect to have in my database?\n\n369\n00:19:09.630 --> 00:19:12.128\nWhatever I expect is the only\nthing that I should allow.\n\n370\n00:19:12.128 --> 00:19:15.420\nIf I don't expect to have that, it should\nnever make it to that database, right?\n\n371\n00:19:15.420 --> 00:19:16.650\nSo that is important.\n\n372\n00:19:16.650 --> 00:19:19.710\nThere's other things that you can do that\nwe've talked about in other episodes as\n\n373\n00:19:19.710 --> 00:19:24.540\na way to secure things like databases,\nis normalization, right?\n\n374\n00:19:24.540 --> 00:19:29.220\nAgain, one of the examples I give is,\nright,\n\n375\n00:19:29.220 --> 00:19:34.050\nmaybe on your web application you have\na value that could be entered in upper or\n\n376\n00:19:34.050 --> 00:19:38.730\nlower case, but on the back end it's\nexpecting to have all upper case letters,\n\n377\n00:19:38.730 --> 00:19:40.730\nright, that's what it expects.\n\n378\n00:19:40.730 --> 00:19:43.910\nBut on your web front end you\ncould do either or, right?\n\n379\n00:19:43.910 --> 00:19:46.604\nWell, what happens when that\ndata makes it into the database?\n\n380\n00:19:46.604 --> 00:19:48.122\nWell, I'm not sure, right?\n\n381\n00:19:48.122 --> 00:19:51.539\nSo we do data normalization, and what\nthat does is it can make sure that when\n\n382\n00:19:51.539 --> 00:19:54.160\nthe data reaches in the backend\nin an unexpected format.\n\n383\n00:19:54.160 --> 00:19:58.231\nWe normalize it and transfer it, or\ntransform it if you will, mutate it,\n\n384\n00:19:58.231 --> 00:20:00.940\ninto something that we're expecting,\nright?\n\n385\n00:20:01.950 --> 00:20:06.049\nSo any data received on the front end,\nin whatever state it may be,\n\n386\n00:20:06.049 --> 00:20:09.286\nis run through another\nprogram that normalizes it.\n\n387\n00:20:09.286 --> 00:20:13.507\nAnd it essentially turns the data into the\nvalues that are expected to be received on\n\n388\n00:20:13.507 --> 00:20:15.160\nthe back end.\n\n389\n00:20:15.160 --> 00:20:18.880\nOther things too, like stored procedures,\nwe have stored procedures.\n\n390\n00:20:18.880 --> 00:20:23.870\nThey implement basically a group of SQL\nStatements, SQL Statements if you will.\n\n391\n00:20:23.870 --> 00:20:28.110\nThey formed some kind of logical group,\nright, and they perform a task.\n\n392\n00:20:28.110 --> 00:20:31.580\nAnd one of the things that we can do\nis we can lock these down to ensure\n\n393\n00:20:31.580 --> 00:20:34.840\nthat we can't perform things\nlike SQL Injection attacks.\n\n394\n00:20:34.840 --> 00:20:36.710\n&gt;&gt; But they're so fun.\n\n395\n00:20:36.710 --> 00:20:37.450\n&gt;&gt; Yeah, exactly.\n\n396\n00:20:37.450 --> 00:20:39.510\nI'm gonna ruin this guy's fun here.\n\n397\n00:20:39.510 --> 00:20:42.690\nHe's gonna leave this episode and\nsay, aw darn.\n\n398\n00:20:42.690 --> 00:20:43.510\nJust kidding guys.\n\n399\n00:20:43.510 --> 00:20:45.204\nThis is all theoretical, right?\n\n400\n00:20:45.204 --> 00:20:49.290\n[LAUGH] The next thing that they call\nout are things like code signing, right?\n\n401\n00:20:49.290 --> 00:20:52.464\nCode signing's about integrity,\nit's a couple of things, right?\n\n402\n00:20:52.464 --> 00:20:56.175\nIt's about integrity, right,\nit's about authenticity, and\n\n403\n00:20:56.175 --> 00:20:58.547\nit's about non-repudiation, right.\n\n404\n00:20:58.547 --> 00:20:59.416\nSo what do I mean, right?\n\n405\n00:20:59.416 --> 00:21:04.575\nIntegrity, when we do code signing, if I\ncode sign or use a certificate, right.\n\n406\n00:21:04.575 --> 00:21:07.657\nWe do code signing and I hand that\nportion of the application over to Dan.\n\n407\n00:21:07.657 --> 00:21:10.998\nDan can verify with the certificate\nthat we've used to do the digital\n\n408\n00:21:10.998 --> 00:21:14.117\ncode signing that, hey,\nthe integrity hasn't been changed.\n\n409\n00:21:14.117 --> 00:21:15.665\nNothing's been modified, right.\n\n410\n00:21:15.665 --> 00:21:19.190\nBut in doing code signing,\nhe can also prove that, hey, it was me.\n\n411\n00:21:19.190 --> 00:21:20.817\nIt was whoever the author or\n\n412\n00:21:20.817 --> 00:21:24.637\npublisher of that software that not\nonly did it make it over to his\n\n413\n00:21:24.637 --> 00:21:29.199\ncomputer in a unmodified state, but\nthat it came from the original source.\n\n414\n00:21:29.199 --> 00:21:31.753\nAnd then we have non repudiation\ncuz there's no way I could say,\n\n415\n00:21:31.753 --> 00:21:32.614\nthat's not my code.\n\n416\n00:21:32.614 --> 00:21:34.884\nWell, I had to sign in in the first place,\nright?\n\n417\n00:21:34.884 --> 00:21:38.423\nSo I can't turn around and refute\nlater the fact that that was my data.\n\n418\n00:21:38.423 --> 00:21:41.572\nSo code signing, right,\nyou can see that in a lot of places.\n\n419\n00:21:41.572 --> 00:21:44.086\nFor instance, think about driver\nsigning inside of Windows, right?\n\n420\n00:21:44.086 --> 00:21:46.068\nWhy do we do digital driver signing?\n\n421\n00:21:46.068 --> 00:21:48.877\nWell, think about what those drivers do,\nit's a piece of code, but\n\n422\n00:21:48.877 --> 00:21:50.531\nit operates in the kernel mode, right?\n\n423\n00:21:50.531 --> 00:21:54.074\nDown there in the lower portions of\nthe operating system that if it gets\n\n424\n00:21:54.074 --> 00:21:56.189\nhosed up can really cause some problems.\n\n425\n00:21:56.189 --> 00:22:01.913\nWe digitally sign that code so\nwe can prove who the publisher was.\n\n426\n00:22:01.913 --> 00:22:05.278\nWe can prove that the drivers in\nthemselves haven't been modified, right?\n\n427\n00:22:05.278 --> 00:22:08.402\nSo it gives us the stability and\ngives us security and\n\n428\n00:22:08.402 --> 00:22:12.806\nwe can be confident that it is coming\nfrom the source that it reports to be.\n\n429\n00:22:12.806 --> 00:22:14.079\nEncryption, right?\n\n430\n00:22:14.079 --> 00:22:16.934\nEncryption, when you're storing your code,\nright.\n\n431\n00:22:16.934 --> 00:22:18.365\nMaybe you've got trade secrets.\n\n432\n00:22:18.365 --> 00:22:20.964\nMaybe you've got something patented\nthat you're working on, right?\n\n433\n00:22:20.964 --> 00:22:24.360\nStoring your code in encrypted format so\nthat you have confidentiality.\n\n434\n00:22:24.360 --> 00:22:26.216\nSo unauthorized partners or\n\n435\n00:22:26.216 --> 00:22:29.550\njust unauthorized users\ndon't gain access to it.\n\n436\n00:22:29.550 --> 00:22:32.241\nWe talked-\n&gt;&gt; I was gonna say maybe even your code\n\n437\n00:22:32.241 --> 00:22:35.582\nmakes a network call and\nsends data across the network.\n\n438\n00:22:35.582 --> 00:22:39.364\nMaybe you want to employ encryption\nthrough your code, not necessarily,\n\n439\n00:22:39.364 --> 00:22:43.324\nyou can encrypt your code and encrypt\nthe data that's passing from your code,\n\n440\n00:22:43.324 --> 00:22:47.370\nfrom your application, to something else,\nlike a server-client type deal.\n\n441\n00:22:47.370 --> 00:22:50.786\n&gt;&gt; Definitely, so we keep that,\nif it hits the network and\n\n442\n00:22:50.786 --> 00:22:52.968\nyou don't want anybody seeing it,\n\n443\n00:22:52.968 --> 00:22:57.497\nthe only way to prevent eavesdropping\nis to do end-to-end encryption.\n\n444\n00:22:57.497 --> 00:23:01.688\nThe other thing they call out is\nobfuscation, right, camouflage and this\n\n445\n00:23:01.688 --> 00:23:06.289\nagain this is kind of security through\nobsecurity, we gotta be careful, right.\n\n446\n00:23:06.289 --> 00:23:08.602\nRemember security through obscurity right?\n\n447\n00:23:08.602 --> 00:23:13.883\nIf I put the key under the mat,\nwell, it's kind of secure right.\n\n448\n00:23:13.883 --> 00:23:16.940\nWe just hope that the attacker doesn't\nknow to look under the mat right?\n\n449\n00:23:16.940 --> 00:23:19.050\n&gt;&gt; It's secure against anybody that\ndoesn't think to look under the mat.\n\n450\n00:23:19.050 --> 00:23:19.980\n[LAUGH]\n&gt;&gt; Exactly, right, so\n\n451\n00:23:19.980 --> 00:23:21.730\nit's not truly secure right?\n\n452\n00:23:21.730 --> 00:23:24.034\nWe've kind of obscured\nthe fact that it's there, but\n\n453\n00:23:24.034 --> 00:23:26.399\nif somebody knows where to look,\nit does them nothing.\n\n454\n00:23:26.399 --> 00:23:29.265\nSo this is more about, if you will,\n\n455\n00:23:29.265 --> 00:23:33.575\ntrying to make sure that\nthe code isn't easily read.\n\n456\n00:23:33.575 --> 00:23:35.544\nWe obfuscate it if you will,\n\n457\n00:23:35.544 --> 00:23:39.981\nand it might help to mask what\nthe purpose of the code is, right.\n\n458\n00:23:39.981 --> 00:23:42.082\nIf you're just trying\nto protect your code,\n\n459\n00:23:42.082 --> 00:23:45.085\nyou don't want people to easily\nbe able to reverse engineer it.\n\n460\n00:23:45.085 --> 00:23:46.489\nWell easiest way is just to encrypt it,\n\n461\n00:23:46.489 --> 00:23:48.200\nthen they can't see\nthe information anyways.\n\n462\n00:23:48.200 --> 00:23:52.929\nBut if the information has to remain in\nsome kind of open format, then you're\n\n463\n00:23:52.929 --> 00:23:57.512\njust kind of camouflaging maybe what\nthe use of that piece of code might be in\n\n464\n00:23:57.512 --> 00:24:01.843\norder to kind of make it a little bit\nharder to reverse engineer right?\n\n465\n00:24:01.843 --> 00:24:03.840\nWhat else do we got there?\n\n466\n00:24:03.840 --> 00:24:06.620\nCode reuse, dead code, right?\n\n467\n00:24:06.620 --> 00:24:07.425\nIt isn't.\n\n468\n00:24:07.425 --> 00:24:10.004\n&gt;&gt; Sounds like a Stephen King novel,\nThe Dead Code.\n\n469\n00:24:10.004 --> 00:24:11.124\n&gt;&gt; [LAUGH]\n&gt;&gt; That's right, it is.\n\n470\n00:24:11.124 --> 00:24:15.357\nAnd if I'm not careful we can definitely\nmake it as long as a Stephen King novel,\n\n471\n00:24:15.357 --> 00:24:15.935\nfor sure.\n\n472\n00:24:15.935 --> 00:24:18.019\nSo when we talk about code reuse, right?\n\n473\n00:24:18.019 --> 00:24:21.898\nThis is something where if you've got\na functionality that it is used in one\n\n474\n00:24:21.898 --> 00:24:22.707\napplication.\n\n475\n00:24:22.707 --> 00:24:26.255\nAnd that same functionality is\nneeded in another application,\n\n476\n00:24:26.255 --> 00:24:27.640\nwhy reinvent the wheel?\n\n477\n00:24:28.690 --> 00:24:31.540\nCopy the code from one\napplication to the next, right?\n\n478\n00:24:31.540 --> 00:24:34.570\nWell the problem is with that code reuse,\nright?\n\n479\n00:24:34.570 --> 00:24:37.990\nYou can carry over flaws,\nyou can carry over vulnerabilities.\n\n480\n00:24:37.990 --> 00:24:41.940\nAnd now the vulnerabilities were\nin the code that you reused\n\n481\n00:24:41.940 --> 00:24:45.390\nare now in the application that\nyou're trying to deploy, right?\n\n482\n00:24:45.390 --> 00:24:50.400\nThe OWASP, what is it,\nthe Open Web Application Security Project.\n\n483\n00:24:50.400 --> 00:24:53.310\nThey called that one of their ten,\n\n484\n00:24:53.310 --> 00:24:58.740\nten top application vulnerabilities\nin their list is the reuse of code.\n\n485\n00:24:58.740 --> 00:25:02.940\nAgain, you're reusing code,\nyou can carry those functionality and\n\n486\n00:25:02.940 --> 00:25:05.610\nflaws over and vulnerabilities.\n\n487\n00:25:05.610 --> 00:25:10.150\nDead code is another one, sections of\ncode that result in the program never\n\n488\n00:25:10.150 --> 00:25:12.290\neven using that functionality.\n\n489\n00:25:12.290 --> 00:25:13.390\nWhat's this about?\n\n490\n00:25:13.390 --> 00:25:14.807\nWell, it could be flaws, but\n\n491\n00:25:14.807 --> 00:25:18.470\nreally it could be just nothing\nmore than wasted processing cycles.\n\n492\n00:25:18.470 --> 00:25:21.500\nIf I've got it performing a function,\nand it never even uses that function.\n\n493\n00:25:21.500 --> 00:25:24.780\nWell, you're wasting the CPU and\nthe processing power, right?\n\n494\n00:25:24.780 --> 00:25:26.820\nKeep in mind availability, as well.\n\n495\n00:25:28.280 --> 00:25:30.740\nAll right,\nnow they call out some other topics too.\n\n496\n00:25:30.740 --> 00:25:34.154\nThey call out things like,\nfor instance, server-side and\n\n497\n00:25:34.154 --> 00:25:38.220\nclient-side execution and validation.\n\n498\n00:25:38.220 --> 00:25:40.721\nAgain, if we talk about\nserver-side validation, right,\n\n499\n00:25:40.721 --> 00:25:42.890\nwe're talking about\nvalidating on the back-end.\n\n500\n00:25:42.890 --> 00:25:46.540\nAnd this is validating through things like\nscripting languages like ASP.NET and PHP.\n\n501\n00:25:46.540 --> 00:25:50.190\nAnd then the feedback is\nsent back to the client.\n\n502\n00:25:50.190 --> 00:25:53.700\nKeep in mind that the server-side\nvalidation is a little bit slower.\n\n503\n00:25:53.700 --> 00:25:57.318\nCuz think about it, from the perspective\nof the end user accessing\n\n504\n00:25:57.318 --> 00:25:59.394\nthe server typically for a resource.\n\n505\n00:25:59.394 --> 00:26:01.923\nIf that server is busy doing\nserver-side validation,\n\n506\n00:26:01.923 --> 00:26:03.926\nit might slow the process\ndown a little bit.\n\n507\n00:26:03.926 --> 00:26:06.460\nBut typically it's\na little bit more secure.\n\n508\n00:26:06.460 --> 00:26:07.450\nWhy do I say that?\n\n509\n00:26:07.450 --> 00:26:11.187\nWell client-side validation is done\nby the browser, and the browser has\n\n510\n00:26:11.187 --> 00:26:15.360\na trust relationship with whatever the\napplication is that it's connecting to.\n\n511\n00:26:15.360 --> 00:26:19.350\nSo we have to make sure that\nthe validation is done prior to sending\n\n512\n00:26:19.350 --> 00:26:23.080\nthe data, again,\nwe get better performance.\n\n513\n00:26:23.080 --> 00:26:24.620\nCuz the server isn't doing it, right?\n\n514\n00:26:24.620 --> 00:26:26.793\nThe browser's done it on\nbehalf of the server, so\n\n515\n00:26:26.793 --> 00:26:28.878\nthe end user experiences\nbetter performance.\n\n516\n00:26:28.878 --> 00:26:31.810\nBut remember when we talk\nabout convenience, right.\n\n517\n00:26:31.810 --> 00:26:34.100\nAnd we've talked about it\na lot throughout this series.\n\n518\n00:26:34.100 --> 00:26:35.480\nThe more you're convenience goes up,\n\n519\n00:26:35.480 --> 00:26:38.720\na lot of times your security can\nkinda start to lax a little bit.\n\n520\n00:26:38.720 --> 00:26:41.811\nSo do keep that in mind too.\n\n521\n00:26:41.811 --> 00:26:44.840\nMemory management,\nthis is a big one as well, right?\n\n522\n00:26:44.840 --> 00:26:48.980\nMaking sure that memory that's\nfreed up is truly freed up,\n\n523\n00:26:48.980 --> 00:26:53.840\nright, not just left empty to where\nhackers or attackers that are really,\n\n524\n00:26:53.840 --> 00:26:55.800\nreally technical and know the code.\n\n525\n00:26:55.800 --> 00:26:59.951\nCan turn around and slip some of their\nmalicious code into those portions\n\n526\n00:26:59.951 --> 00:27:04.392\nof memory that were freed up, but\nweren't really let go by the application.\n\n527\n00:27:04.392 --> 00:27:07.482\nThings like memory leaks, right, we have\nto worry about things like memory leaks.\n\n528\n00:27:07.482 --> 00:27:10.996\nAnd get an application continuing\nto consume too much memory and\n\n529\n00:27:10.996 --> 00:27:14.586\nit can go up to as far as doing\nthings like denial-of-services.\n\n530\n00:27:14.586 --> 00:27:17.918\nDan already mentioned, one, crashing your\nsystem is a denial-of-service attack.\n\n531\n00:27:17.918 --> 00:27:20.457\nAnd you mention things like\nbuffer overflows, right,\n\n532\n00:27:20.457 --> 00:27:22.410\nproper memory management, right?\n\n533\n00:27:22.410 --> 00:27:24.883\nSome of the things that we implement\ninside of memory management,\n\n534\n00:27:24.883 --> 00:27:25.909\nare they No-eXecute bit?\n\n535\n00:27:25.909 --> 00:27:30.626\nThe NX technology that says, this portion\nof memory is isolated for code, but\n\n536\n00:27:30.626 --> 00:27:32.820\nit can't be executed, right?\n\n537\n00:27:32.820 --> 00:27:34.790\nA lot of your web browsers\nwill do the same thing,\n\n538\n00:27:34.790 --> 00:27:38.680\nwhere they'll have a reserved portion of\nmemory that's marked as non executable.\n\n539\n00:27:38.680 --> 00:27:41.660\nAgain, that's up to the application\ndeveloper to make sure and\n\n540\n00:27:41.660 --> 00:27:45.660\nensure that that is used properly,\nso proper memory management.\n\n541\n00:27:46.990 --> 00:27:50.770\nSome of the other things,\nuse of third party libraries and\n\n542\n00:27:50.770 --> 00:27:52.709\nsoftware development kits.\n\n543\n00:27:52.709 --> 00:27:56.336\nOne of the things that we have to worry\nabout is if you are using a third party\n\n544\n00:27:56.336 --> 00:27:59.880\nlibrary, it could contain security\nvulnerabilities and flaws.\n\n545\n00:27:59.880 --> 00:28:03.763\nAnd security issues that aren't\nrecognized by your company, again,\n\n546\n00:28:03.763 --> 00:28:07.011\nbecause it's a third party\nthat manages and maintains it.\n\n547\n00:28:07.011 --> 00:28:09.760\nAnd then, of course, we always\nhave to worry about data exposure.\n\n548\n00:28:09.760 --> 00:28:11.620\nAnd we've kinda talked\nabout data exposure.\n\n549\n00:28:11.620 --> 00:28:14.310\nOne of the things that you can do\nto ensure that it doesn't happen is\n\n550\n00:28:14.310 --> 00:28:16.470\nencryption of your information.\n\n551\n00:28:16.470 --> 00:28:19.540\nSo that you make sure that\nit remains confidential.\n\n552\n00:28:19.540 --> 00:28:22.220\n&gt;&gt; So Wes,\nhow the heck do we actually make sure\n\n553\n00:28:22.220 --> 00:28:23.800\nthat these things are being done?\n\n554\n00:28:23.800 --> 00:28:27.090\n&gt;&gt; Well, the audits,\nsecurity audits and reviews, for sure.\n\n555\n00:28:27.090 --> 00:28:29.705\nQuality testing,\nthat's one of the things that you can do.\n\n556\n00:28:29.705 --> 00:28:34.240\nAgain, code quality and\ntesting, if you will.\n\n557\n00:28:34.240 --> 00:28:36.180\nThings like static code analyzers, right?\n\n558\n00:28:36.180 --> 00:28:40.600\nWell, what do we mean by we say,\nstatic code analyzers?\n\n559\n00:28:40.600 --> 00:28:43.220\nWell, how about analyzing\nthe code before it's running?\n\n560\n00:28:43.220 --> 00:28:45.590\nBefore it's in its runtime environment,\nright?\n\n561\n00:28:45.590 --> 00:28:47.500\nUncompile code if you will, right?\n\n562\n00:28:47.500 --> 00:28:51.870\nSo we can basically analyze that\ncode without ever executing it.\n\n563\n00:28:51.870 --> 00:28:53.869\nThere are a few different\nexamples out there.\n\n564\n00:28:53.869 --> 00:28:57.357\nI've kind of written down some,\nso I can remember them,\n\n565\n00:28:57.357 --> 00:29:02.240\nthings like Google's Code Pro Analytics,\nVisual Code Grepper is one of them.\n\n566\n00:29:02.240 --> 00:29:05.730\nOWASP has one, Lapse Plus,\nRips, DevBug, so\n\n567\n00:29:05.730 --> 00:29:09.320\nyou do have software out\nthere that will do this.\n\n568\n00:29:09.320 --> 00:29:13.160\nIt will run through the code,\nagain, before it's ever running.\n\n569\n00:29:13.160 --> 00:29:15.955\nSo again static code analysis just\nmeans it's not being executed.\n\n570\n00:29:15.955 --> 00:29:20.821\nUnlike dynamic analysis,\ndynamic analysis is basically testing and\n\n571\n00:29:20.821 --> 00:29:26.500\nevaluating a program that is going\nthrough its real-time execution.\n\n572\n00:29:26.500 --> 00:29:30.890\nIf you think about it,\nfuzzing is a dynamic analysis, right?\n\n573\n00:29:30.890 --> 00:29:35.030\nI'm sending information at\nthe application, as it's in run time, so\n\n574\n00:29:35.030 --> 00:29:36.970\nwe can see how does it handle it, right?\n\n575\n00:29:36.970 --> 00:29:42.380\nStress testing that application,\nand basically unit testing.\n\n576\n00:29:42.380 --> 00:29:44.930\nUnit testing is an example of\ndynamic code testing, right?\n\n577\n00:29:44.930 --> 00:29:46.920\nYou're breaking it down\ninto smaller components,\n\n578\n00:29:46.920 --> 00:29:50.150\nand each unit test becomes\na dynamic analysis.\n\n579\n00:29:50.150 --> 00:29:53.680\nAnd it allows you to do things like\nIdentifying vulnerabilities if you will.\n\n580\n00:29:53.680 --> 00:29:56.784\nDependencies, identifying errors,\nerror handling events,\n\n581\n00:29:56.784 --> 00:29:58.510\nare they happening properly?\n\n582\n00:29:58.510 --> 00:30:04.478\nAnd any defects too, again, stress testing\nis another one which we could do, too.\n\n583\n00:30:04.478 --> 00:30:07.696\nAnd, again, it allows the developer\nthe ability to test the software,\n\n584\n00:30:07.696 --> 00:30:08.658\nits effectiveness.\n\n585\n00:30:08.658 --> 00:30:13.930\nAnd how does the program run under\nunfavorable conditions, right?\n\n586\n00:30:13.930 --> 00:30:15.220\nIf we have an application,\n\n587\n00:30:15.220 --> 00:30:18.960\nand it need such and such memory,\nwell let's reduce the memory.\n\n588\n00:30:18.960 --> 00:30:21.720\nLet's put it in a VM, reduce\nthe memory and see how it runs, right?\n\n589\n00:30:21.720 --> 00:30:24.010\nSo, again, stress testing that,\nwe can measure things like errors.\n\n590\n00:30:24.010 --> 00:30:27.760\nWe can measure things like crashes.\n\n591\n00:30:27.760 --> 00:30:32.020\nAnd it does, even though we\nmight get unpredictable results.\n\n592\n00:30:32.020 --> 00:30:34.720\nThe goal here is to try to mitigate or\n\n593\n00:30:34.720 --> 00:30:38.090\nto reduce the unpredictable\nnature of the program.\n\n594\n00:30:38.090 --> 00:30:40.565\nBy throwing everything you can at it,\nright?\n\n595\n00:30:40.565 --> 00:30:42.370\nAs well as things like Sandboxing,\n\n596\n00:30:42.370 --> 00:30:45.370\nsandboxing is another one\nthat we have to worry about.\n\n597\n00:30:45.370 --> 00:30:48.480\nAnd this is great because what you do,\nis you can experiment with your code from\n\n598\n00:30:48.480 --> 00:30:54.270\nan isolated environment that is kept away\nfrom the production environment, right?\n\n599\n00:30:54.270 --> 00:30:56.909\nWe do this a lot in\nvirtualization in general, right?\n\n600\n00:30:56.909 --> 00:30:59.354\nWe spin up a virtual machine,\nand then, we test our code..\n\n601\n00:30:59.354 --> 00:31:02.436\nWhile that does require you to\nspin up an entire virtual machine.\n\n602\n00:31:02.436 --> 00:31:05.770\nAnd that's one of the great things\nabout things like containers.\n\n603\n00:31:05.770 --> 00:31:08.510\nContainers mean I can have\na single operating system, and\n\n604\n00:31:08.510 --> 00:31:11.900\nmultiple virtualized spaces\nwithin a single operating system.\n\n605\n00:31:11.900 --> 00:31:14.970\nBut, they're isolated and\nthey don't affect each other.\n\n606\n00:31:14.970 --> 00:31:20.089\nSo that's a great way that we can\nimplement experimental code testing.\n\n607\n00:31:21.400 --> 00:31:24.100\nLet's see a couple of\nthe last things here.\n\n608\n00:31:24.100 --> 00:31:27.770\nModel verification as well\nthat we have to consider.\n\n609\n00:31:27.770 --> 00:31:33.970\nCompiled versus runtime code, again,\ncompiled code is code that is ready.\n\n610\n00:31:33.970 --> 00:31:37.260\nWe're ready to use it versus\nsomething that is actually\n\n611\n00:31:37.260 --> 00:31:39.790\nrunning inside the processor at the time.\n\n612\n00:31:39.790 --> 00:31:44.390\nAgain, compared to static\nanalysis versus dynamic analysis.\n\n613\n00:31:44.390 --> 00:31:47.070\nAgain, where is that code and\nwhat state is the code?\n\n614\n00:31:47.070 --> 00:31:51.534\nBut a lot of different things that you\nhave to consider when it comes to secure\n\n615\n00:31:51.534 --> 00:31:53.506\napplication development guys.\n\n616\n00:31:53.506 --> 00:31:55.842\nAnd I know we've mentioned a lot, but\n\n617\n00:31:55.842 --> 00:31:59.060\nkeep in mind it is important\nin today's day and age.\n\n618\n00:31:59.060 --> 00:32:02.795\nWhere like Dan's mentioned where one\nperson is wearing multiple hats within\n\n619\n00:32:02.795 --> 00:32:03.836\nthat organization.\n\n620\n00:32:03.836 --> 00:32:07.598\nThat you do understand at least some of\nthe concepts behind secure application\n\n621\n00:32:07.598 --> 00:32:09.380\ndevelopment and deployment.\n\n622\n00:32:09.380 --> 00:32:12.680\nSo that when you take the Security+ exam,\nif they ask you questions\n\n623\n00:32:12.680 --> 00:32:15.460\nabout these concepts,\nyou'll be able to answer them correctly.\n\n624\n00:32:15.460 --> 00:32:17.520\n&gt;&gt; That's good stuff\nright there Mr Wes Bryan.\n\n625\n00:32:17.520 --> 00:32:19.818\nWe do thank you for\njoining us today in the studio.\n\n626\n00:32:19.818 --> 00:32:23.630\nCuz you guys gotta remember we are trying\nto become security professionals.\n\n627\n00:32:23.630 --> 00:32:28.360\nAnd that does, well,\nsometimes bleed over into development.\n\n628\n00:32:28.360 --> 00:32:31.840\nIf you have a development team,\nif you're making in house products.\n\n629\n00:32:31.840 --> 00:32:35.190\nOr that's what your company does,\nthey create applications for a living for\n\n630\n00:32:35.190 --> 00:32:36.240\nother people to buy.\n\n631\n00:32:36.240 --> 00:32:38.174\nWell, you gotta make sure\nthose things are secure.\n\n632\n00:32:38.174 --> 00:32:41.044\nAnd that your customers aren't\ngonna come screaming at you going,\n\n633\n00:32:41.044 --> 00:32:44.260\nI've been completely compromised,\ncuz we didn't do security testing.\n\n634\n00:32:44.260 --> 00:32:47.065\nSo, just to understand that that\ncould be a part of your job.\n\n635\n00:32:47.065 --> 00:32:50.990\nThat being said, it does look like we\nhave run out of time for this episode.\n\n636\n00:32:50.990 --> 00:32:53.640\nWe do thank you for watching though,\nsigning off for ITProTV.\n\n637\n00:32:53.640 --> 00:32:55.070\nI've been your host, Daniel Lowrie.\n\n638\n00:32:55.070 --> 00:32:55.750\n&gt;&gt; And I'm Wes Bryan.\n\n639\n00:32:55.750 --> 00:32:58.298\n&gt;&gt; And we'll see you next time.\n\n640\n00:32:58.298 --> 00:33:04.234\n[MUSIC]\n\n641\n00:33:04.234 --> 00:33:07.641\nThank you for watching ITProTV.\n\n",
          "vimeoId": "216164594"
        },
        {
          "description": "In this episode, Daniel and Wes introduce you to different cloud and virtualization concepts. Here you will learn about Hypervisors, Cloud Storage, and Cloud deployment models like IaaS, SaaS, and PaaS. They also discuss the difference between On-premise vs. hosted vs. cloud and start their look into VDI/VDE.",
          "length": "1647",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-7-cloud_and_virtualization_concepts-050417-PGM.00_27_13_18.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-7-cloud_and_virtualization_concepts-050417-PGM.00_27_13_18.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-7-cloud_and_virtualization_concepts-050417-PGM.00_27_13_18.Still001-sm.jpg",
          "title": "Cloud and Virtualization Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:03.794\nWelcome to ITProTV I'm\nyour host Don Pezet.\n\n2\n00:00:03.794 --> 00:00:06.570\n[CROSSTALK]\n\n3\n00:00:06.570 --> 00:00:08.514\n[MUSIC]\n\n4\n00:00:08.514 --> 00:00:12.005\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.005 --> 00:00:14.129\n&gt;&gt; All right, greetings everyone and\n\n6\n00:00:14.129 --> 00:00:17.210\nwelcome back to another\ngreat episode of ITProTV.\n\n7\n00:00:17.210 --> 00:00:20.060\nI'm your host Daniel Lowrie,\nand in today's episode, well,\n\n8\n00:00:20.060 --> 00:00:20.910\nI hope you're ready for it.\n\n9\n00:00:20.910 --> 00:00:22.478\nBecause if you thought you were here for\nA+,\n\n10\n00:00:22.478 --> 00:00:24.135\nthen you're wrong, cuz it's security plus.\n\n11\n00:00:24.135 --> 00:00:25.858\nIt's what we're doing today\nLearning all about security.\n\n12\n00:00:25.858 --> 00:00:29.889\nAnd joining us to help teach us those\nsecurity concepts and practices,\n\n13\n00:00:29.889 --> 00:00:31.850\nour good friend, Mr. Wes Bryan.\n\n14\n00:00:31.850 --> 00:00:32.840\nWes, welcome back, man.\n\n15\n00:00:32.840 --> 00:00:33.574\n&gt;&gt; Hey, man, thanks for having me back.\n\n16\n00:00:33.574 --> 00:00:35.550\nWait, this isn't A+?\n\n17\n00:00:35.550 --> 00:00:37.790\n&gt;&gt; I thought it was Net+ no,\nit's the wrong building.\n\n18\n00:00:37.790 --> 00:00:39.700\n&gt;&gt; No, we're just kidding, it is the-\n&gt;&gt; Security+.\n\n19\n00:00:39.700 --> 00:00:40.860\nThat's right\n&gt;&gt; [LAUGH]\n\n20\n00:00:40.860 --> 00:00:42.500\n&gt;&gt; And we're gonna be looking at well,\n\n21\n00:00:42.500 --> 00:00:43.920\nvirtualization concepts and\n\n22\n00:00:43.920 --> 00:00:48.440\nit is important inside of well your\nenvironments today and it's definitely\n\n23\n00:00:48.440 --> 00:00:51.740\nimportant to understand some of the\nsecurity benefits that you get for this.\n\n24\n00:00:51.740 --> 00:00:54.360\nAnd for the exam which is why we are here.\n\n25\n00:00:54.360 --> 00:00:55.630\nWe want you to pass that exam.\n\n26\n00:00:55.630 --> 00:01:00.410\nSo let's go ahead and we're gonna\ndive right in to virtualization.\n\n27\n00:01:00.410 --> 00:01:02.460\nWhat are some of the benefits\nof virtualization?\n\n28\n00:01:02.460 --> 00:01:06.144\nWell, the main thing about virtualization\nis the fact that you get better allocation\n\n29\n00:01:06.144 --> 00:01:08.200\nof the resources that you\nhave within a system.\n\n30\n00:01:08.200 --> 00:01:10.306\nLet's take virtualization out of it, and\n\n31\n00:01:10.306 --> 00:01:15.070\nlet's say that you've got a system that\nhas, let's say, eight gigs of RAM.\n\n32\n00:01:15.070 --> 00:01:17.237\nGot a multicore processor like\nmost of them do today and\n\n33\n00:01:17.237 --> 00:01:18.330\nyou got plenty of storage.\n\n34\n00:01:18.330 --> 00:01:23.281\nIf you install a single operating system\non that machine, that means that operating\n\n35\n00:01:23.281 --> 00:01:27.800\nsystem takes all of those resources and\nit uses it just for itself.\n\n36\n00:01:27.800 --> 00:01:31.770\nBut imagine the ability to maybe\nallocate those resources to\n\n37\n00:01:31.770 --> 00:01:33.530\nmultiple operating systems and\n\n38\n00:01:33.530 --> 00:01:38.160\nallow them to run simultaneously on\na single physical device, right?\n\n39\n00:01:38.160 --> 00:01:42.260\nIn the earlier days, the way we would do\nthat is through, well, multi-boot, right?\n\n40\n00:01:42.260 --> 00:01:43.437\nBut keep in mind,\n\n41\n00:01:43.437 --> 00:01:49.249\nmulti-boot doesn't allow you to run the\noperating systems simultaneously, right?\n\n42\n00:01:49.249 --> 00:01:51.280\nSo what do I have to do?\n\n43\n00:01:51.280 --> 00:01:53.670\nI have to, first of all,\nI have to partition my machine.\n\n44\n00:01:53.670 --> 00:01:56.490\nI have to install the operating\nsystem on one partition and\n\n45\n00:01:56.490 --> 00:02:00.040\nthe second operating system has to be\ninstalled on the second partition.\n\n46\n00:02:00.040 --> 00:02:03.730\nBut even at that, keep in mind, it's still\nonly a single operating system that is\n\n47\n00:02:03.730 --> 00:02:05.720\ncontrolling the hardware at one time.\n\n48\n00:02:05.720 --> 00:02:09.297\nSo that's one of the big things that\nvirtualization allows us to do, all right.\n\n49\n00:02:09.297 --> 00:02:14.161\nThe other thing is,\ntwo is virtualization allows us to isolate\n\n50\n00:02:14.161 --> 00:02:20.060\napplications making sure that we run\nan application on on virtual machine.\n\n51\n00:02:20.060 --> 00:02:22.720\nIt does not interfere\nwith the information or\n\n52\n00:02:22.720 --> 00:02:25.522\nthe applications running\non another machine.\n\n53\n00:02:25.522 --> 00:02:28.060\nIn fact I got a little diagram here.\n\n54\n00:02:28.060 --> 00:02:30.870\nSo if we look at a non\nvirtualized environment, right,\n\n55\n00:02:30.870 --> 00:02:34.080\nyou have multiple applications, they're\nrunning on a single operating system.\n\n56\n00:02:34.080 --> 00:02:36.729\nThat single operating system\nhas access to the hardware.\n\n57\n00:02:36.729 --> 00:02:41.250\nBut the problem is, if this application\nbecomes corrupt, it could potentially ruin\n\n58\n00:02:41.250 --> 00:02:45.728\nthe application that are running next to\nit, and even more so the operating system.\n\n59\n00:02:45.728 --> 00:02:50.017\nAnd then what happens when our\nproductivity is gonna start to wane,\n\n60\n00:02:50.017 --> 00:02:55.640\nif you will, because of the fact that\nwe now have a single corrupted machine?\n\n61\n00:02:55.640 --> 00:03:00.990\nImagine the ability, like I said,\nthat we can divide those resources up.\n\n62\n00:03:00.990 --> 00:03:03.702\nAnd what we do is we implement\nwhat's known as a hypervisor.\n\n63\n00:03:03.702 --> 00:03:08.379\nNow the hypervisor sits on top of your\nresource or your resource is being your\n\n64\n00:03:08.379 --> 00:03:13.090\nCPU, your memory and your storage\nif you will, the hardware, right?\n\n65\n00:03:13.090 --> 00:03:14.510\nAnd I mean abstractly.\n\n66\n00:03:14.510 --> 00:03:19.382\nAnd what that how allows us to do,\nit to allows us to install multiple\n\n67\n00:03:19.382 --> 00:03:23.232\noperating systems if you will,\non a single machine.\n\n68\n00:03:23.232 --> 00:03:27.480\nNow, what we get is this isolation, right?\n\n69\n00:03:27.480 --> 00:03:31.810\nThis whole entire VM, like for instance\nwe have what are known as Guest VM's and\n\n70\n00:03:31.810 --> 00:03:34.350\nwe have what are known a guest and\nhost, right?\n\n71\n00:03:34.350 --> 00:03:37.580\nThe host is actually the hypervisor\nthat is running on this machine.\n\n72\n00:03:37.580 --> 00:03:41.180\nIt is the commander in chief, right?\n\n73\n00:03:41.180 --> 00:03:44.327\nAnd it allocates the resources\nto the individual machines.\n\n74\n00:03:44.327 --> 00:03:49.130\nNow, this is what's known\nas a type 1 hypervisor.\n\n75\n00:03:49.130 --> 00:03:54.650\nA type 1 hypervisor you might even\nhear called a bare metal hypervisor.\n\n76\n00:03:54.650 --> 00:03:57.391\nAnd it means in the computing\nlayers you can see that\n\n77\n00:03:57.391 --> 00:03:59.958\nit literally sits right\non top of the hardware.\n\n78\n00:03:59.958 --> 00:04:02.720\nNow, why would we use a type 1?\n\n79\n00:04:02.720 --> 00:04:04.810\nWhere would we use a type 1 hypervisor?\n\n80\n00:04:04.810 --> 00:04:06.700\nWell, these are in your\nproduction environment, right?\n\n81\n00:04:06.700 --> 00:04:10.100\nWe'll talk about another one coming\nup called the type 2 Hypervisor.\n\n82\n00:04:10.100 --> 00:04:13.509\nAnd because we only have fewer\nabstraction layers if you will,\n\n83\n00:04:13.509 --> 00:04:15.517\nwe get better performance, right?\n\n84\n00:04:15.517 --> 00:04:19.220\nWe get the Hypervisor directly\ncommunicating with the hardware.\n\n85\n00:04:20.320 --> 00:04:22.314\nBut there is another type of Hypervisor,\nright, and\n\n86\n00:04:22.314 --> 00:04:23.741\nthat's called a Type 2 Hypervisor.\n\n87\n00:04:23.741 --> 00:04:28.447\nAnd the Type 2 Hypervisor,\nthis is interesting, because what the Type\n\n88\n00:04:28.447 --> 00:04:34.140\n2 Hypervisor does is, unlike a Type 1,\nyou have a host operating system.\n\n89\n00:04:34.140 --> 00:04:40.090\nAnd then inside of the host operating\nsystem, you install the type 2 hypervisor.\n\n90\n00:04:40.090 --> 00:04:43.010\nAnd you have to understand that it\nreally sits on the same level as\n\n91\n00:04:43.010 --> 00:04:47.650\nall the other applications that\nare running on your machine.\n\n92\n00:04:47.650 --> 00:04:49.601\nNow, where is a Type 2\nhypervisor beneficial?\n\n93\n00:04:49.601 --> 00:04:52.770\nWell, we use a Type 2\nhypervisor a lot of times.\n\n94\n00:04:52.770 --> 00:04:55.260\nIn fact, I've got one in\nthe background that we use here.\n\n95\n00:04:55.260 --> 00:04:57.365\nGive you an example, like VMware,\nright, VMware Fusion.\n\n96\n00:04:57.365 --> 00:05:00.188\nThat's an example of a Type 2 hypervisor,\n\n97\n00:05:00.188 --> 00:05:03.760\nbecause I already have my\nMac operating system right?\n\n98\n00:05:03.760 --> 00:05:08.630\nIt's controlling access to the hardware,\nand then I install a type 2 hyper-visor\n\n99\n00:05:08.630 --> 00:05:14.340\nand it acts no different than for instance\nthis diagram software that I have right?\n\n100\n00:05:14.340 --> 00:05:16.800\nThis is great for a testing environment,\n\n101\n00:05:16.800 --> 00:05:21.382\nthis is good because you do get that\nisolation that I can test an application.\n\n102\n00:05:21.382 --> 00:05:23.089\nI can implement things like snapshots.\n\n103\n00:05:23.089 --> 00:05:24.171\nWhat's a snapshot?\n\n104\n00:05:24.171 --> 00:05:29.349\nWell, a snapshot is a point in\ntime copy of the configuration\n\n105\n00:05:29.349 --> 00:05:34.131\nof the state of that machine\nat the time that you take it.\n\n106\n00:05:34.131 --> 00:05:38.106\nAnd if I install an application it\nbecomes problematic, it doesn't give me\n\n107\n00:05:38.106 --> 00:05:41.780\nthe results or I'll give it do\na reconfiguration or likewise is good.\n\n108\n00:05:41.780 --> 00:05:43.072\nI host up the machine completely.\n\n109\n00:05:43.072 --> 00:05:46.760\nWhat I can do is I can revert\nto an earlier point in time.\n\n110\n00:05:46.760 --> 00:05:50.450\nAll right now the reason you wouldn't\nuse this on a production environment,\n\n111\n00:05:50.450 --> 00:05:52.910\nyou can see there's a lot of\ncommunication that has to go.\n\n112\n00:05:52.910 --> 00:05:56.670\nYou have an application,\nthat talks to the guest operating system.\n\n113\n00:05:56.670 --> 00:05:59.550\nThat talks to a hypervisor,\nwhich is really in\n\n114\n00:05:59.550 --> 00:06:03.210\ncontention with all the other applications\nrunning on the operating system.\n\n115\n00:06:03.210 --> 00:06:05.250\nAnd it talks to the host\noperating system and\n\n116\n00:06:05.250 --> 00:06:10.100\nfinally allocates the resources\nto these guest machines.\n\n117\n00:06:10.100 --> 00:06:13.570\nSo, the type one hypervisor is the one\nthat you're gonna use in production.\n\n118\n00:06:13.570 --> 00:06:15.820\nAnd again, you can see it takes\nout one of those layers and\n\n119\n00:06:15.820 --> 00:06:19.370\nyou get better communication with\nthe hardware and better performance.\n\n120\n00:06:20.520 --> 00:06:24.796\nBut we're seeing where spinning up\nan entire virtual machine, right,\n\n121\n00:06:24.796 --> 00:06:26.275\nto test an application.\n\n122\n00:06:26.275 --> 00:06:29.311\nI could test multiple applications and\n\n123\n00:06:29.311 --> 00:06:33.365\nI could spin up multiple virtual machines,\nright.\n\n124\n00:06:33.365 --> 00:06:37.547\nBut that, that doesn't lend itself\nto being the ideal situation for\n\n125\n00:06:37.547 --> 00:06:41.800\ntesting applications and that's why\nthey also call out what are known\n\n126\n00:06:41.800 --> 00:06:44.921\nas application cells or\napplication containers.\n\n127\n00:06:44.921 --> 00:06:49.390\nWe're seeing a lot of this today\nin fact a little bit different.\n\n128\n00:06:49.390 --> 00:06:52.474\nStill uses a virtualized component,\nbut rather than have to spin up\n\n129\n00:06:52.474 --> 00:06:55.453\nan entire operating system,\ninstalling the operating system,\n\n130\n00:06:55.453 --> 00:06:57.903\ngiving it the right access\nto the network if you need.\n\n131\n00:06:57.903 --> 00:07:02.156\nMaking sure that you harden the server,\nmaking sure that you create\n\n132\n00:07:02.156 --> 00:07:06.740\nthe environment that the application's\ngonna run on ahead of time.\n\n133\n00:07:06.740 --> 00:07:08.484\nImagine having that all bundled together,\nright?\n\n134\n00:07:08.484 --> 00:07:11.810\nAnd this is where\ncontainerization comes in, right?\n\n135\n00:07:11.810 --> 00:07:15.510\nContainers are essentially kinda\nlike an isolated virtual machine but\n\n136\n00:07:15.510 --> 00:07:19.000\nthe big difference here is I don't have\nto spin up a virtual machine, right?\n\n137\n00:07:19.000 --> 00:07:20.090\n&gt;&gt; Is this like Docker?\n\n138\n00:07:20.090 --> 00:07:21.150\n&gt;&gt; It's exactly like Docker.\n\n139\n00:07:21.150 --> 00:07:24.210\nDocker's a classic example,\nI'm glad you mentioned it.\n\n140\n00:07:24.210 --> 00:07:27.704\nIt's a classic example of\ncontainerization right,\n\n141\n00:07:27.704 --> 00:07:31.205\nyou end up having is you\nhave a docker engine, right?\n\n142\n00:07:31.205 --> 00:07:35.270\nAnd that docker engine runs on\na single operating system right,\n\n143\n00:07:35.270 --> 00:07:38.300\nnot multiple VEM's spinning up.\n\n144\n00:07:38.300 --> 00:07:40.654\nAnd then it communicates\nwith the different binaries,\n\n145\n00:07:40.654 --> 00:07:42.416\ncould be shared binaries and libraries.\n\n146\n00:07:42.416 --> 00:07:44.631\nBut notice what happens.\n\n147\n00:07:44.631 --> 00:07:50.323\nI get the ability to have these containers\nrunning side by side on a single\n\n148\n00:07:50.323 --> 00:07:56.780\noperating system, and I don't have to\nspin up each additional virtual machine.\n\n149\n00:07:56.780 --> 00:08:01.406\nA virtualization.sounds like it's\nhorrible, virtualization is great and\n\n150\n00:08:01.406 --> 00:08:04.496\nwe use it a lot and\nwe use the type one hyper advisors.\n\n151\n00:08:04.496 --> 00:08:09.062\nBut when you're doing application\ndevelopment this makes it a lot easier\n\n152\n00:08:09.062 --> 00:08:13.039\nright, because it allows for\nmultiple virtual environments,\n\n153\n00:08:13.039 --> 00:08:17.899\nif you will, without the necessity of\nhaving multiple virtual machines, and\n\n154\n00:08:17.899 --> 00:08:20.255\nthat does make it a lot easier.\n\n155\n00:08:20.255 --> 00:08:23.435\nNow there's another thing too,\nthey talk about application cells, and\n\n156\n00:08:23.435 --> 00:08:25.815\nthis is like a form of containerization.\n\n157\n00:08:25.815 --> 00:08:30.740\nYou actually see this in the Android world\nand they do have the ability, if you will,\n\n158\n00:08:30.740 --> 00:08:35.500\nto spin up multiple virtual,\nmobile virtual environments, right?\n\n159\n00:08:35.500 --> 00:08:39.340\nThink of it as those of you guys that are\nfamiliar with your network plus, right?\n\n160\n00:08:39.340 --> 00:08:41.230\nWe talk about multiplexing.\n\n161\n00:08:41.230 --> 00:08:44.950\nWe talk about multiple communications,\nbeing able to be combined and\n\n162\n00:08:44.950 --> 00:08:47.080\ntransmitted over a single wire.\n\n163\n00:08:47.080 --> 00:08:51.850\nImagine multiplexing your kernel, right,\nyou have multiple applications that\n\n164\n00:08:51.850 --> 00:08:55.400\nessentially are multiplexed\non a single kernel.\n\n165\n00:08:55.400 --> 00:08:59.400\nAllowing you these each isolated,\nthink of it as like a virtual phone.\n\n166\n00:08:59.400 --> 00:09:01.780\nRight, for testing and stuff,\ntesting your mobile application.\n\n167\n00:09:01.780 --> 00:09:04.700\nSo we're not just seeing this for\napplication testing that's gonna\n\n168\n00:09:04.700 --> 00:09:07.170\nrun in like a cloud environment or\na web application.\n\n169\n00:09:07.170 --> 00:09:10.460\nAnd there's gonna be things like work\nstations that are connecting to it.\n\n170\n00:09:10.460 --> 00:09:12.400\nWe're also seeing application cells and\n\n171\n00:09:12.400 --> 00:09:15.990\ncontainerization inside of\nyour mobile environments too.\n\n172\n00:09:17.350 --> 00:09:21.425\nAll right, so a couple of things, I will\nsay one, a couple of considerations,\n\n173\n00:09:21.425 --> 00:09:24.025\nwhen you are using containers,\nor containerization.\n\n174\n00:09:24.025 --> 00:09:27.475\nThe first thing you want to ensure is that\nyou're dropping the privileges, right?\n\n175\n00:09:27.475 --> 00:09:30.675\nYou're running services in\nnon-privileged mode, when you can.\n\n176\n00:09:30.675 --> 00:09:32.235\nSometimes you have to run in kernel mode,\n\n177\n00:09:32.235 --> 00:09:34.905\nbecause it's performing\nsome kind of functionality.\n\n178\n00:09:34.905 --> 00:09:38.495\nBut the containers allow you to maximize\nthe amount of applications that\n\n179\n00:09:38.495 --> 00:09:42.045\nare running in a single operating\nsystem on that virtual environment.\n\n180\n00:09:42.045 --> 00:09:45.780\nKeep in mind, without having to\nspin up multiple virtual machines.\n\n181\n00:09:45.780 --> 00:09:50.600\n&gt;&gt; Now Wes, this is a show about\nvirtualization and cloud, right?\n\n182\n00:09:50.600 --> 00:09:54.400\nAnd the two typically go hand in hand\nbecause we use virtualization for\n\n183\n00:09:54.400 --> 00:09:55.870\ncloud services.\n\n184\n00:09:55.870 --> 00:09:57.440\nIt's just how it works,\nit's amazing thing.\n\n185\n00:09:57.440 --> 00:10:00.190\nIt's chocolate and\npeanut butter in IT, right?\n\n186\n00:10:00.190 --> 00:10:02.150\nIt's amazing, it's a lot of fun.\n\n187\n00:10:02.150 --> 00:10:05.720\nBut when we start getting into the cloud,\nusually the first step that people take\n\n188\n00:10:05.720 --> 00:10:08.500\ninto cloud is a lot of times,\njust storage, cloud storage.\n\n189\n00:10:08.500 --> 00:10:10.770\nCan you hold this for me out there, so\n\n190\n00:10:10.770 --> 00:10:14.490\nthat I don't have to pay for\nmulti hard drives here.\n\n191\n00:10:14.490 --> 00:10:17.170\nI just pay for\nthe service of them holding it for me.\n\n192\n00:10:17.170 --> 00:10:18.850\n&gt;&gt; Definitely,\nthink about on-premise, right?\n\n193\n00:10:18.850 --> 00:10:22.680\nAnd again, I know you've worked for\nsome pretty large companies in the past.\n\n194\n00:10:22.680 --> 00:10:25.550\nThink about what you have to do to\nmanage that data on-premise, right?\n\n195\n00:10:25.550 --> 00:10:30.240\nWe have backups, and again backups we have\nto worry about things like bit rot, right?\n\n196\n00:10:30.240 --> 00:10:34.250\nThe fact that you're using magnetic\nmedia and the data could be corrupted.\n\n197\n00:10:34.250 --> 00:10:36.910\nImagine the ability to just say,\nyou know what, take this third party,\n\n198\n00:10:36.910 --> 00:10:38.150\nwe'll pay them.\n\n199\n00:10:38.150 --> 00:10:40.660\nThey're gonna use their infrastructure,\nthey're gonna store their data,\n\n200\n00:10:40.660 --> 00:10:44.340\nthey're gonna charge us a fee, and they\nusually charge us a storage fee, right?\n\n201\n00:10:44.340 --> 00:10:45.770\nAnd then different tiered levels.\n\n202\n00:10:45.770 --> 00:10:49.160\nMaybe I only need ten gigs of storage,\nthat's okay, well you get it.\n\n203\n00:10:49.160 --> 00:10:53.060\nMaybe I need ten terabytes, right, ten\nterabytes, 30 terabytes, and beyond with\n\n204\n00:10:53.060 --> 00:10:56.530\nbig datas, hundreds and hundreds,\nwe're talking about petabytes, right?\n\n205\n00:10:56.530 --> 00:10:59.070\nThat's a lot of information\nto store on-premise and\n\n206\n00:10:59.070 --> 00:11:02.470\nwhen it come to things like redundancy and\nfault tolerance, you\n\n207\n00:11:02.470 --> 00:11:06.860\ncould exponentially increase the cost that\nit takes to maintain that information.\n\n208\n00:11:06.860 --> 00:11:10.830\nSo again,\nimagine the ability to store data and\n\n209\n00:11:10.830 --> 00:11:13.348\naccess it across the Internet too.\n\n210\n00:11:13.348 --> 00:11:16.730\nIf it's on-premise and we want to\naccess it from different locations,\n\n211\n00:11:16.730 --> 00:11:19.160\nwe have to set up things just like VPN,\nright?\n\n212\n00:11:19.160 --> 00:11:24.810\nVPN communication to allow even\njust a single bit of access.\n\n213\n00:11:24.810 --> 00:11:27.690\nIf we increase the amount\nof connections and\n\n214\n00:11:27.690 --> 00:11:31.340\nwe have to add additional technologies\nlike things like VPN concentrators, right?\n\n215\n00:11:31.340 --> 00:11:35.490\nIt seems like it's getting a very\nconvoluted process, right?\n\n216\n00:11:35.490 --> 00:11:38.360\nAnd it's nice to be able to use\nsomebody else's network, and\n\n217\n00:11:38.360 --> 00:11:40.870\njust have them to charge us a fee.\n\n218\n00:11:40.870 --> 00:11:41.800\nGive you an example, right?\n\n219\n00:11:41.800 --> 00:11:43.890\nYou have things that are personal, right?\n\n220\n00:11:43.890 --> 00:11:47.000\nIt doesn't have to be just in business,\nwe have things like OneDrive and Dropbox.\n\n221\n00:11:47.000 --> 00:11:49.550\nI use Dropbox all the time.\n\n222\n00:11:49.550 --> 00:11:53.500\nYou also have things like Carbonate,\nCarbonite is a good solution for backups,\n\n223\n00:11:53.500 --> 00:11:56.810\nright, that I don't have to store and\nmaintain that information on-premise.\n\n224\n00:11:56.810 --> 00:11:59.880\nYou can if you want, but\nyou can also outsource it to them.\n\n225\n00:11:59.880 --> 00:12:01.600\nCarbonite is also an enterprise level too,\n\n226\n00:12:01.600 --> 00:12:04.490\ncuz there's enterprise level\none's too that we have.\n\n227\n00:12:04.490 --> 00:12:07.000\nOneDrive for Business is one of them.\n\n228\n00:12:07.000 --> 00:12:11.150\nMicrosoft's Azure, you can store\nit in the cloud there as well.\n\n229\n00:12:11.150 --> 00:12:13.370\nDropbox for Business,\nthat's one that we use here.\n\n230\n00:12:13.370 --> 00:12:19.020\nAnd there's also things like for instance\nAmazon's S3 or excuse me AWSS3, right?\n\n231\n00:12:19.020 --> 00:12:22.260\nWe can use S3 buckets that we\ncan store that information.\n\n232\n00:12:22.260 --> 00:12:26.180\nAnd it's so really nice to be\nable to sign an SLA, right?\n\n233\n00:12:26.180 --> 00:12:31.000\nWe talked about SLAs in other episodes and\nsay hey I wanna have access to my data,\n\n234\n00:12:31.000 --> 00:12:34.822\nbut even better I wanna have access to my\ndata and all I need is a web browser and\n\n235\n00:12:34.822 --> 00:12:35.821\nan Internet connection.\n\n236\n00:12:35.821 --> 00:12:37.630\nThat is a very good benefit for\nyour company.\n\n237\n00:12:37.630 --> 00:12:41.165\n&gt;&gt; Not only that, the fact that it's\non probably the latest and greatest,\n\n238\n00:12:41.165 --> 00:12:44.555\nbest hardware money can buy because\nthese are large companies that\n\n239\n00:12:44.555 --> 00:12:45.628\nprovide cloud services.\n\n240\n00:12:45.628 --> 00:12:49.241\nYou're getting great hardware,\nyou're getting great support,\n\n241\n00:12:49.241 --> 00:12:52.214\nand for a very small fee when\nit comes to taking a look at it\n\n242\n00:12:52.214 --> 00:12:54.893\nversus something like\nan on-premise solution.\n\n243\n00:12:54.893 --> 00:12:57.485\nVery, very much a cost saver.\n\n244\n00:12:57.485 --> 00:13:01.190\nThat being said, there is also,\nwe've said the words a couple of times,\n\n245\n00:13:01.190 --> 00:13:02.960\ncloud services, right.\n\n246\n00:13:02.960 --> 00:13:07.310\nThis is something that people get tripped\nup on when they try to jump into, okay,\n\n247\n00:13:07.310 --> 00:13:08.820\nwhat are these cloud services?\n\n248\n00:13:08.820 --> 00:13:14.455\nWe see IaaS, SaaS, PaaS, all these\naaS's that are going on out there.\n\n249\n00:13:14.455 --> 00:13:17.555\nThis is where people can get confused,\nWes, can you please remove the vail so\n\n250\n00:13:17.555 --> 00:13:19.795\nthat our lovely viewing audience can see?\n\n251\n00:13:19.795 --> 00:13:20.775\n&gt;&gt; That's right, we can.\n\n252\n00:13:20.775 --> 00:13:23.585\nNow we'll talk about the first\nletters in each one, right,\n\n253\n00:13:23.585 --> 00:13:28.815\nwhen we say s-a-a-s, we got to think\nsoftware, software as a service.\n\n254\n00:13:28.815 --> 00:13:30.235\nSo what does that mean for us?\n\n255\n00:13:30.235 --> 00:13:34.140\nWell you probably have used\nsoftware as a service and\n\n256\n00:13:34.140 --> 00:13:36.430\nmaybe you didn't even realize that,\nthat's what you were using.\n\n257\n00:13:36.430 --> 00:13:38.150\nIf you've ever used\nthings like Google Docs.\n\n258\n00:13:38.150 --> 00:13:40.630\nGoogle Docs is an example\nof software as a service.\n\n259\n00:13:40.630 --> 00:13:44.970\nHow many of you guys out there have\nused some kind of email provider, right?\n\n260\n00:13:44.970 --> 00:13:46.900\nI know I can raise my hand on that one,\nright?\n\n261\n00:13:46.900 --> 00:13:48.450\nActually, I've used quite a few of them.\n\n262\n00:13:48.450 --> 00:13:49.500\nHotmail, right?\n\n263\n00:13:49.500 --> 00:13:51.290\n&gt;&gt; Yeah.\n&gt;&gt; Gmail, Yahoo Mail.\n\n264\n00:13:51.290 --> 00:13:53.320\nThese are all examples as\nSoftware as a Service.\n\n265\n00:13:53.320 --> 00:13:56.170\nIn fact, I got a little diagram here,\nbecause it doesn't just have to be email,\n\n266\n00:13:56.170 --> 00:13:57.810\nit can be a lot of different things,\nright?\n\n267\n00:13:57.810 --> 00:14:00.120\n&gt;&gt; Technically Facebook\nis Software as a Service.\n\n268\n00:14:00.120 --> 00:14:03.200\n&gt;&gt; Exactly, cuz they are providing you\nwith an application service that they\n\n269\n00:14:03.200 --> 00:14:05.460\nare storing in the cloud,\nvery good example.\n\n270\n00:14:05.460 --> 00:14:07.250\nTwitter, Instagram, all of these.\n\n271\n00:14:07.250 --> 00:14:08.860\nYou don't realize it, but\n\n272\n00:14:08.860 --> 00:14:10.920\nthey're providing you a service\nthat they're maintaining.\n\n273\n00:14:10.920 --> 00:14:13.150\nAnd you don't have to store\nanything on-premise, so\n\n274\n00:14:13.150 --> 00:14:15.305\ntechnically that is software as a service.\n\n275\n00:14:15.305 --> 00:14:16.710\n[CROSSTALK]\n&gt;&gt; It's a real easy way to\n\n276\n00:14:16.710 --> 00:14:17.910\ncontextualize SaaS.\n\n277\n00:14:17.910 --> 00:14:21.530\nI mean, all of a sudden you're I've\nbeen doing this for a long time.\n\n278\n00:14:21.530 --> 00:14:23.152\nI know exactly what SaaS is.\n\n279\n00:14:23.152 --> 00:14:26.890\n&gt;&gt; [LAUGH] Yeah, and you get the, what\nis it, the light bulb of understanding.\n\n280\n00:14:26.890 --> 00:14:27.562\n&gt;&gt; Yeah.\n&gt;&gt; Comes on.\n\n281\n00:14:27.562 --> 00:14:28.510\n&gt;&gt; A-ha.\n[LAUGH]\n\n282\n00:14:28.510 --> 00:14:29.430\n&gt;&gt; So keep in mind,\n\n283\n00:14:29.430 --> 00:14:31.210\nDan's already mentioned\nsome of these things.\n\n284\n00:14:31.210 --> 00:14:34.270\nThe infrastructure to support\nthe application is offloaded to\n\n285\n00:14:34.270 --> 00:14:35.130\nthe provider, right.\n\n286\n00:14:35.130 --> 00:14:38.450\nWe don't have to worry about\nthe application in the background, right.\n\n287\n00:14:38.450 --> 00:14:40.510\nAnd we don't have to worry about\nthe support of the application.\n\n288\n00:14:40.510 --> 00:14:42.480\nWe've got frequently\nasked questions sites and\n\n289\n00:14:42.480 --> 00:14:46.460\nsupport sites that we can go to if\nthey're providing us with that service.\n\n290\n00:14:46.460 --> 00:14:48.750\nThe other thing is redundancy and\nrecovery, right?\n\n291\n00:14:48.750 --> 00:14:52.820\nAmazon is the biggest provider,\nwhen it comes to networks,\n\n292\n00:14:52.820 --> 00:14:55.220\nwe're talking about that spans continents,\nright?\n\n293\n00:14:55.220 --> 00:15:00.240\nAnd the chances for their entire\nnetwork to be down, It can happen,\n\n294\n00:15:00.240 --> 00:15:01.870\nbut highly unlikely, all right.\n\n295\n00:15:01.870 --> 00:15:04.010\nThe chances of our exchange server,\n\n296\n00:15:04.010 --> 00:15:07.270\nour web application server\nthat's on-premise of going down?\n\n297\n00:15:07.270 --> 00:15:08.799\nVery likely, right?\n\n298\n00:15:08.799 --> 00:15:13.025\nSo we get the fact that we get things\nlike redundancy and we get recovery, and\n\n299\n00:15:13.025 --> 00:15:14.290\nwe don't even see it.\n\n300\n00:15:14.290 --> 00:15:15.970\nIt's transparent to us.\n\n301\n00:15:15.970 --> 00:15:19.980\nUpdates and maintenance, I don't have to\nworry about the updates to Gmail, right?\n\n302\n00:15:19.980 --> 00:15:21.200\nThey do that on the back end.\n\n303\n00:15:21.200 --> 00:15:23.550\nI don't have to worry about\nupdates to things like Hotmail.\n\n304\n00:15:23.550 --> 00:15:25.240\nThey do that in the background.\n\n305\n00:15:25.240 --> 00:15:28.930\nAnd then there's the ones\nlike Microsoft's Office 365,\n\n306\n00:15:28.930 --> 00:15:31.860\nclassic example of Software as a Service.\n\n307\n00:15:31.860 --> 00:15:37.250\nAnd the great thing is I only need a web\nbrowser and Internet connectivity.\n\n308\n00:15:37.250 --> 00:15:39.390\nNow think about web browsers.\n\n309\n00:15:39.390 --> 00:15:41.810\nEvery operating system you will install.\n\n310\n00:15:41.810 --> 00:15:43.940\nI don't care if it's Linux.\n\n311\n00:15:43.940 --> 00:15:47.520\nI don't care if it's Windows,\nMac, it doesn't matter.\n\n312\n00:15:47.520 --> 00:15:49.991\nThey typically have some\nkind of browser installed.\n\n313\n00:15:49.991 --> 00:15:53.605\n[CROSSTALK] I was going to say, that\nbeing said, if you go terminal only and\n\n314\n00:15:53.605 --> 00:15:57.125\nyou're a power user in Linux,\nyou might lose access to that part of it.\n\n315\n00:15:57.125 --> 00:15:58.393\n&gt;&gt; Link.\n\n316\n00:15:58.393 --> 00:16:00.216\n&gt;&gt; There we go, see I didn't know.\n\n317\n00:16:00.216 --> 00:16:01.975\nThat's good to have a Linux\nguy standing next to you.\n\n318\n00:16:01.975 --> 00:16:04.160\n&gt;&gt; [LAUGH]\n&gt;&gt; But if you think about and\n\n319\n00:16:04.160 --> 00:16:06.460\nI know some of the distros have\nthings like Firefox built in.\n\n320\n00:16:06.460 --> 00:16:09.650\nSo, that's the great thing is\nit's one of the most common\n\n321\n00:16:09.650 --> 00:16:11.520\napplication tools that you use.\n\n322\n00:16:11.520 --> 00:16:13.550\nAnd it's built into your\noperating system and\n\n323\n00:16:13.550 --> 00:16:17.160\nyou could use that to piggyback off and\nuse this infrastructure.\n\n324\n00:16:17.160 --> 00:16:18.254\nSo, a great thing to have.\n\n325\n00:16:18.254 --> 00:16:20.024\nNow the next one that they call out,\n\n326\n00:16:20.024 --> 00:16:22.680\nthey call out what's known\nas platform as a service.\n\n327\n00:16:22.680 --> 00:16:25.087\nNow, platform as a service\nis where we get things like,\n\n328\n00:16:25.087 --> 00:16:28.175\nyou could even incorporate things\nlike containerization in here too.\n\n329\n00:16:28.175 --> 00:16:32.135\nCuz imagine you're developing, right?\n\n330\n00:16:32.135 --> 00:16:37.025\nAnd I want you to think about what it\nmight take and I don't understand code,\n\n331\n00:16:37.025 --> 00:16:39.175\nguys, I can spell C++ on a good day.\n\n332\n00:16:39.175 --> 00:16:40.325\nSo I'm not a developer.\n\n333\n00:16:40.325 --> 00:16:41.389\n&gt;&gt; That's with your cheat sheet, right?\n\n334\n00:16:41.389 --> 00:16:42.436\n&gt;&gt; That's right [LAUGH],\nthat's exactly it.\n\n335\n00:16:42.436 --> 00:16:47.043\nI'm not a developer, I don't understand\nwhat the platform is that it takes to,\n\n336\n00:16:47.043 --> 00:16:50.634\nif I had to construct that platform\nto support things like PHP,\n\n337\n00:16:50.634 --> 00:16:55.270\nthe .NET Framework, ASP and Perl,\nif you will, all this languages out there.\n\n338\n00:16:55.270 --> 00:16:59.768\nSo what platform as a service is, is\nit's an application runtime environment,\n\n339\n00:16:59.768 --> 00:17:02.480\nan execution environment\nthat's already set so\n\n340\n00:17:02.480 --> 00:17:05.540\nthat your developers can\njust start working, right?\n\n341\n00:17:05.540 --> 00:17:06.409\nAnd behind the scenes,\n\n342\n00:17:06.409 --> 00:17:08.934\nwe don't have to worry about\nsupporting that environment, right?\n\n343\n00:17:08.934 --> 00:17:13.361\nYou can use it for things like application\ndevelopment, application, if you will,\n\n344\n00:17:13.361 --> 00:17:14.310\ntesting.\n\n345\n00:17:14.310 --> 00:17:16.500\nAnd one of the great things\nabout platform as a service,\n\n346\n00:17:16.500 --> 00:17:21.800\nis a lot of times, they support all of\nthe common programming languages, right?\n\n347\n00:17:21.800 --> 00:17:24.290\nSo, that's flexibility.\n\n348\n00:17:24.290 --> 00:17:26.420\nThe other thing too is in\napplication development and\n\n349\n00:17:26.420 --> 00:17:29.390\ntesting, we might over provision.\n\n350\n00:17:29.390 --> 00:17:31.300\nWell, that's the great\nbeauty of the cloud.\n\n351\n00:17:31.300 --> 00:17:36.280\nWe talk about elasticity in a prior\nepisode where we don't have to worry so\n\n352\n00:17:36.280 --> 00:17:40.060\nmuch about over provisioning because\nwhen we need the testing environment,\n\n353\n00:17:40.060 --> 00:17:41.350\nwe spin it up, right?\n\n354\n00:17:41.350 --> 00:17:44.860\nWe pull it down, they're taking care\nof everything on the background.\n\n355\n00:17:44.860 --> 00:17:47.740\nOnce the testing is done,\nwe de-provision it.\n\n356\n00:17:47.740 --> 00:17:49.650\nSo we don't have to maintain\nthat environment and\n\n357\n00:17:49.650 --> 00:17:52.190\nkeep that environment up and\nrunning when we're not using it.\n\n358\n00:17:52.190 --> 00:17:56.010\nSo that flexibility of using platform\nas a service is a great thing to have\n\n359\n00:17:56.010 --> 00:17:57.330\ninside of your environments.\n\n360\n00:17:58.410 --> 00:17:59.659\nAll right, what's the last,\nwell, actually,\n\n361\n00:17:59.659 --> 00:18:00.808\nthere's kind of a couple more here, right.\n\n362\n00:18:00.808 --> 00:18:02.200\n&gt;&gt; There's a few.\n\n363\n00:18:02.200 --> 00:18:04.940\n&gt;&gt; We have what's known as\ninfrastructure as a service.\n\n364\n00:18:04.940 --> 00:18:07.440\nAnd when we look at things like\ninfrastructure as your service,\n\n365\n00:18:07.440 --> 00:18:11.700\nI want you to go ahead and\njust kind of just simplify it, all right?\n\n366\n00:18:11.700 --> 00:18:13.963\nThis is your computational power,\nthis is your computing.\n\n367\n00:18:13.963 --> 00:18:19.050\nThat's what I want you to think of as\ninfrastructure as a service, right?\n\n368\n00:18:19.050 --> 00:18:23.018\nIt provides your computing resources\nin the cloud, your computational power,\n\n369\n00:18:23.018 --> 00:18:23.611\nall right?\n\n370\n00:18:23.611 --> 00:18:25.889\nI've got a web application and\n\n371\n00:18:25.889 --> 00:18:31.680\nthat web application is gonna need a lot\nof computational power at a peak time.\n\n372\n00:18:31.680 --> 00:18:34.650\nWell, we can implement things\nthrough infrastructure as a service,\n\n373\n00:18:34.650 --> 00:18:36.060\ncloud bursting.\n\n374\n00:18:36.060 --> 00:18:39.098\nAnd cloud bursting says, I need\nthe computational power right now, right?\n\n375\n00:18:40.270 --> 00:18:44.000\nElasticity, I can send all of\nthat up to their servers and\n\n376\n00:18:44.000 --> 00:18:45.430\ntheir infrastructure, and\n\n377\n00:18:45.430 --> 00:18:49.970\nwe can use those computational resources\nwith them supporting it on the backend.\n\n378\n00:18:49.970 --> 00:18:52.480\nThings like memory,\nthings like your storage, right?\n\n379\n00:18:52.480 --> 00:18:54.320\nWe've mentioned things like cloud storage.\n\n380\n00:18:54.320 --> 00:18:55.540\nWell, believe it or not,\n\n381\n00:18:55.540 --> 00:18:59.180\ncloud storage is a form of infrastructure\nas a service because you're storing your\n\n382\n00:18:59.180 --> 00:19:04.440\ndata on their hard drive, or whatever\nthey're using, on their storage medium.\n\n383\n00:19:04.440 --> 00:19:07.320\nNetwork communications,\nyour operating systems.\n\n384\n00:19:07.320 --> 00:19:10.800\nIf I need to spin up a server, that's\ngonna be infrastructure as a service.\n\n385\n00:19:10.800 --> 00:19:13.440\nSo think about your\ncomputational resources,\n\n386\n00:19:13.440 --> 00:19:15.740\nthat's really a good way\nto think about it, right?\n\n387\n00:19:15.740 --> 00:19:21.660\nThe hardware that you would need to\nimplement could be, if it was physical or\n\n388\n00:19:21.660 --> 00:19:24.970\neven if it is virtualization,\nyou would have to manage and maintain, and\n\n389\n00:19:24.970 --> 00:19:27.710\nagain that would cost you\nadditional resources.\n\n390\n00:19:28.770 --> 00:19:29.959\nYou can do this and\nyou can offload it to a third-party.\n\n391\n00:19:29.959 --> 00:19:34.520\nAnd it's them that manage and\nmaintain that type of infrastructure.\n\n392\n00:19:35.760 --> 00:19:38.760\nThere's one other one\nthat I wanna go ahead and\n\n393\n00:19:38.760 --> 00:19:43.030\nkinda throw in here because it's called\nout in the objectives towards the end.\n\n394\n00:19:43.030 --> 00:19:48.230\nAnd it's called security as a service,\nit's one of these newer ones there,\n\n395\n00:19:48.230 --> 00:19:53.280\nand it's S-E-C-A-A-S, right man,\nsecurity as a service, right?\n\n396\n00:19:53.280 --> 00:19:57.660\nSo, if you see that one out there,\ndon't let it confuse you, right?\n\n397\n00:19:57.660 --> 00:20:00.032\nBasically, what you're doing is\nthe same thing you would be doing here\n\n398\n00:20:00.032 --> 00:20:02.057\nin infrastructure as a service,\nbut it's security based.\n\n399\n00:20:02.057 --> 00:20:05.062\nAnd what you're doing is you're\noutsourcing the security to\n\n400\n00:20:05.062 --> 00:20:06.359\na third-party, right?\n\n401\n00:20:06.359 --> 00:20:11.055\nThe third-party can offer management\nof different things like your policies,\n\n402\n00:20:11.055 --> 00:20:15.267\ncontinuous monitoring, real time IDS and\nIPS solutions, if you will,\n\n403\n00:20:15.267 --> 00:20:17.908\ncontent filtering, application control.\n\n404\n00:20:17.908 --> 00:20:22.950\nThey can offer you things like VPN\nconnections, firewall services.\n\n405\n00:20:22.950 --> 00:20:26.800\nAnd again,\nthe real time monitoring of that is\n\n406\n00:20:26.800 --> 00:20:28.610\njust a way that you can outsource it.\n\n407\n00:20:28.610 --> 00:20:33.031\nAnd you can make it a lot easier on\nyour company rather than having somebody\n\n408\n00:20:33.031 --> 00:20:37.599\ninternally in your company on-premise\nhaving to constantly monitor these\n\n409\n00:20:37.599 --> 00:20:38.476\noperations.\n\n410\n00:20:38.476 --> 00:20:43.190\nNow, they also call out a couple of other\nmodels that I kinda wanna talk about.\n\n411\n00:20:43.190 --> 00:20:47.210\nAnd that's the difference between\na public cloud and a private cloud.\n\n412\n00:20:47.210 --> 00:20:50.828\nAll right, well, public cloud is\nthe fact that you can gain access to it.\n\n413\n00:20:50.828 --> 00:20:54.028\nDan, his company comes online,\nthey need to grab a public cloud,\n\n414\n00:20:54.028 --> 00:20:56.470\nthey can go to the public cloud.\n\n415\n00:20:56.470 --> 00:21:00.600\nMultiple organizations can\nuse that service, right?\n\n416\n00:21:00.600 --> 00:21:02.087\nIt doesn't mean that they're\nusing the same cloud.\n\n417\n00:21:02.087 --> 00:21:05.916\nYour environment would be isolated to you\nand my environment would be isolated to\n\n418\n00:21:05.916 --> 00:21:09.100\nme, but\nit's available to the public as a service.\n\n419\n00:21:09.100 --> 00:21:10.600\nPrivate cloud is a little bit different,\nright?\n\n420\n00:21:10.600 --> 00:21:12.120\nPrivate cloud is isolated,\n\n421\n00:21:12.120 --> 00:21:15.730\nthat's typically controlled by\na single organization, right?\n\n422\n00:21:15.730 --> 00:21:18.890\nAnd it's not multiple companies\nthat have access to it.\n\n423\n00:21:18.890 --> 00:21:22.730\nSo, it could be a provider that says,\nhey, we're only giving you access to\n\n424\n00:21:22.730 --> 00:21:25.373\nthe internals of this organization and\nthat's it.\n\n425\n00:21:25.373 --> 00:21:30.540\nSo, that's one that again, is typically\nowned by a single organization.\n\n426\n00:21:30.540 --> 00:21:32.310\nAnd then there's community, right?\n\n427\n00:21:32.310 --> 00:21:36.173\nCommunity is when you have multiple\nentities that own a portion of the cloud.\n\n428\n00:21:36.173 --> 00:21:38.602\nAnd this could be things like,\nfor instance,\n\n429\n00:21:38.602 --> 00:21:42.925\nif you have a doctor's office that also\nworks with an insurance agency, right?\n\n430\n00:21:42.925 --> 00:21:46.440\nAnd they need access to\nprotected health information, so\n\n431\n00:21:46.440 --> 00:21:47.410\nthey have a community cloud.\n\n432\n00:21:47.410 --> 00:21:51.970\nThey have a common goal, if you will, and\nthey need access to common resources,\n\n433\n00:21:51.970 --> 00:21:54.270\nyou can get what's know\nas the community cloud.\n\n434\n00:21:54.270 --> 00:21:55.606\nAnd then we have the Frankenstein.\n\n435\n00:21:55.606 --> 00:21:56.218\n&gt;&gt; Yeah [LAUGH]\n&gt;&gt; Just kidding,\n\n436\n00:21:56.218 --> 00:21:58.300\nthat's not what they call it,\nbut they call it a hybrid.\n\n437\n00:21:58.300 --> 00:22:00.221\nAnd a hybrid is just\na blending of the models.\n\n438\n00:22:00.221 --> 00:22:02.310\nSo, if you're on the exam and say,\n\n439\n00:22:02.310 --> 00:22:06.912\nthey give you a scenario where they're\nsaying that, you have portions of this\n\n440\n00:22:06.912 --> 00:22:11.652\nthat is available just as a single company\nversus a portion of it that's actually\n\n441\n00:22:11.652 --> 00:22:15.530\nthe cloud infrastructure is\naccessible by two companies.\n\n442\n00:22:15.530 --> 00:22:16.510\nThat would be a hybrid, right?\n\n443\n00:22:16.510 --> 00:22:19.410\nYou're mixing a little bit of\nthe community cloud with maybe the private\n\n444\n00:22:19.410 --> 00:22:20.680\ncloud or the public cloud.\n\n445\n00:22:20.680 --> 00:22:22.560\nSo those are your hybrids.\n\n446\n00:22:22.560 --> 00:22:27.580\nAnd unlike some things that we talk\nabout in Network+ where we say\n\n447\n00:22:27.580 --> 00:22:32.950\nsometimes hybrid topologies come by\naccident, acquisitions and mergers.\n\n448\n00:22:32.950 --> 00:22:36.050\nThis isn't really something that's\nan accident, it's not a bad thing.\n\n449\n00:22:36.050 --> 00:22:39.220\nIt's just the fact that you might have to\nblend a little bit of the public cloud\n\n450\n00:22:39.220 --> 00:22:42.860\nwith a little bit of the private cloud,\nif you need, or whatever the case may be.\n\n451\n00:22:42.860 --> 00:22:46.809\nSo just know the hybrid is just using\ncharacteristics from more than one of\n\n452\n00:22:46.809 --> 00:22:47.833\nthe cloud models.\n\n453\n00:22:47.833 --> 00:22:52.443\n&gt;&gt; Yeah, and Wes, that's a really good\nsegue into the idea of the difference\n\n454\n00:22:52.443 --> 00:22:56.043\nbetween on-premises versus\nhosted versus cloud based.\n\n455\n00:22:56.043 --> 00:22:59.731\nAnd you'll see one versus\nthe other with one or the other.\n\n456\n00:22:59.731 --> 00:23:00.482\n&gt;&gt; Yes, absolutely.\n\n457\n00:23:00.482 --> 00:23:01.698\n&gt;&gt; Gonna clear that up.\n\n458\n00:23:01.698 --> 00:23:06.012\n&gt;&gt; No and again, that also lends itself\nto a hybrid model too which is another\n\n459\n00:23:06.012 --> 00:23:08.600\none that you could\nprobably throw in there.\n\n460\n00:23:08.600 --> 00:23:09.783\nI want you to think of on-premise.\n\n461\n00:23:09.783 --> 00:23:13.210\n[LAUGH] On-premise means you\nmanage everything, right?\n\n462\n00:23:13.210 --> 00:23:14.580\nYou're liable for everything.\n\n463\n00:23:14.580 --> 00:23:18.070\nWe're talking about servers and\nstorage units, whether it's SAN, or\n\n464\n00:23:18.070 --> 00:23:21.040\nwhether it's a network attached storage,\nand you control all of it, right?\n\n465\n00:23:21.040 --> 00:23:24.760\n&gt;&gt; Which is why we typically\nsee private clouds on-premise.\n\n466\n00:23:24.760 --> 00:23:25.298\n&gt;&gt; That's exactly it.\n\n467\n00:23:25.298 --> 00:23:31.930\nThe other one, hosted and\ncloud kind of get a little confusing.\n\n468\n00:23:31.930 --> 00:23:37.390\nHosted means that a provider is hosting\nyour cloud and only you, right?\n\n469\n00:23:37.390 --> 00:23:41.860\nUnlike a cloud provider which is\ndoing things like multi-tenancy.\n\n470\n00:23:41.860 --> 00:23:46.176\nAnd it means it's more than one\nperson all using the same hardware,\n\n471\n00:23:46.176 --> 00:23:50.867\nif you will, that's behind the scenes\nversus a hosted cloud says, hey,\n\n472\n00:23:50.867 --> 00:23:54.747\nWe're gonna host this infrastructure for\nyou and only you.\n\n473\n00:23:54.747 --> 00:23:57.192\nToday you could still see that, but\n\n474\n00:23:57.192 --> 00:24:03.146\nwe're really seeing the prevalence of that\nin multi-tenancy type cloud environment\n\n475\n00:24:03.146 --> 00:24:08.219\nwhere you have multiple tenants on\na single cloud provider's solution.\n\n476\n00:24:09.370 --> 00:24:13.730\nAll right, then the next thing we have,\nI tell you what, I look at our clock,\n\n477\n00:24:13.730 --> 00:24:15.090\nwe've got a lot to go through.\n\n478\n00:24:15.090 --> 00:24:20.280\nSo we'll talk a little bit about VDI,\nvirtual desktop infrastructure.\n\n479\n00:24:20.280 --> 00:24:21.830\nWe'll probably have to go into a part two,\n\n480\n00:24:21.830 --> 00:24:24.680\nbecause we got a lot more\nto go through [LAUGH].\n\n481\n00:24:24.680 --> 00:24:27.690\nVirtual desktop infrastructure,\nlet's go ahead and\n\n482\n00:24:27.690 --> 00:24:30.870\nlet's kinda set VDI just to the side for\na second.\n\n483\n00:24:30.870 --> 00:24:34.580\nI want you to think of physical\ndesktop infrastructure.\n\n484\n00:24:34.580 --> 00:24:35.635\nWe'll call it PDI [LAUGH].\n\n485\n00:24:35.635 --> 00:24:37.370\n&gt;&gt; [LAUGH].\n&gt;&gt; I'll make up my on term here,\n\n486\n00:24:37.370 --> 00:24:40.450\nbut if could take a look at\nphysical desktop infrastructure.\n\n487\n00:24:40.450 --> 00:24:44.070\nI want you to think about\nwhat's going on if we aren't\n\n488\n00:24:44.070 --> 00:24:45.840\nusing any kind of virtualized software,\nright?\n\n489\n00:24:45.840 --> 00:24:49.000\nAnd we'll talk about the virtual desktop\ninfrastructure here in a second.\n\n490\n00:24:49.000 --> 00:24:51.610\nYour operating system,\nit's stored locally.\n\n491\n00:24:51.610 --> 00:24:55.310\nYour applications, they're stored on\nthe hard drive of those machines.\n\n492\n00:24:55.310 --> 00:24:59.060\nYour updates can be completely\ndecentralized, right?\n\n493\n00:24:59.060 --> 00:25:02.289\nDeployments, again,\nyou can have deployment challenges.\n\n494\n00:25:02.289 --> 00:25:06.295\nThe other thing is configuration,\na consistency in your configurations,\n\n495\n00:25:06.295 --> 00:25:07.429\ncan be challenging.\n\n496\n00:25:07.429 --> 00:25:11.778\nAnd even more so today, to maintain\na physical environment you have many\n\n497\n00:25:11.778 --> 00:25:14.490\ndifferent types of devices today.\n\n498\n00:25:14.490 --> 00:25:17.590\nSo it can be physically,\nthat can introduce device diversity,\n\n499\n00:25:17.590 --> 00:25:21.790\nis what we call it, that can introduce\nchallenges, management challenges.\n\n500\n00:25:21.790 --> 00:25:26.070\nThat's why we implement something\nlike virtual desktop infrastructure.\n\n501\n00:25:26.070 --> 00:25:31.020\nAnd virtual desktop infrastructure is\na centralized management solution.\n\n502\n00:25:31.020 --> 00:25:35.420\nThe other thing that's great about it is\nits support for multiple platforms, right?\n\n503\n00:25:35.420 --> 00:25:40.050\nImagine the ability to serve up\nsomebody's desktop environment.\n\n504\n00:25:40.050 --> 00:25:42.210\nAnd it doesn't matter if I'm on a laptop,\n\n505\n00:25:42.210 --> 00:25:45.820\nit doesn't matter if Dan's got\na cellphone on him, I've got an iPad.\n\n506\n00:25:45.820 --> 00:25:49.900\nAnd we can just serve that up\nright to whatever that device is.\n\n507\n00:25:49.900 --> 00:25:52.710\nBut it's running on the server, right?\n\n508\n00:25:52.710 --> 00:25:53.990\nThat's a great model to have,\n\n509\n00:25:53.990 --> 00:25:58.570\nbecause what happens is it reduces\npatch management complexities.\n\n510\n00:25:58.570 --> 00:26:00.390\nGuess what?\nBecause I take the desktop,\n\n511\n00:26:00.390 --> 00:26:03.680\nall the desktops for every user,\nsince they're running on the server,\n\n512\n00:26:03.680 --> 00:26:08.640\nI have a single place to do my patch\nmanagement solutions, application updates,\n\n513\n00:26:08.640 --> 00:26:12.530\nand we can rapidly deploy our desktops,\nright?\n\n514\n00:26:12.530 --> 00:26:15.990\nThe other thing is, your operating systems\nare easier to maintain because you can\n\n515\n00:26:15.990 --> 00:26:18.370\nmaintain your images better, right?\n\n516\n00:26:18.370 --> 00:26:20.860\nNow I'm not talking about\nWindows Deployment Services but\n\n517\n00:26:20.860 --> 00:26:24.780\nI'm talking about the fact that you can\nhave everybody connecting into that\n\n518\n00:26:24.780 --> 00:26:28.870\ncentralized server and you can have\ndifferent types of desktops, right?\n\n519\n00:26:28.870 --> 00:26:31.010\nYou can have a standardized desktop for\nyour users.\n\n520\n00:26:31.010 --> 00:26:33.890\nMaybe you've got somebody that needs\nsome kind of productivity software.\n\n521\n00:26:33.890 --> 00:26:36.610\nAnd again,\nall of it is running on the server.\n\n522\n00:26:36.610 --> 00:26:42.420\nBut that just kinda scratches the surface,\nDan, we've got a lot more to talk about\n\n523\n00:26:42.420 --> 00:26:46.360\nwith VDI, things like non-persistent and\npersistent virtual desktop infrastructure.\n\n524\n00:26:46.360 --> 00:26:48.960\nBut I'm looking at that time and I don't\nthink we got enough for this episode.\n\n525\n00:26:48.960 --> 00:26:52.045\n&gt;&gt; Yeah, she's definitely taken away\non us a little quicker than we'd like.\n\n526\n00:26:52.045 --> 00:26:56.180\nBut the good news is we can just make\na part two which we fancy ourselves to do.\n\n527\n00:26:56.180 --> 00:26:57.160\nSo, that's what will happen.\n\n528\n00:26:57.160 --> 00:26:58.900\nWes, thanks for joining us today.\n\n529\n00:26:58.900 --> 00:26:59.470\n&gt;&gt; Sure.\n\n530\n00:26:59.470 --> 00:27:02.441\n&gt;&gt; Getting us a cloud minded,\nvirtualization minded,\n\n531\n00:27:02.441 --> 00:27:04.560\nthat's what this has been all about.\n\n532\n00:27:04.560 --> 00:27:06.180\nWe're gonna continue that\nin our next part two.\n\n533\n00:27:06.180 --> 00:27:07.810\nHopefully, we'll see you good folks there.\n\n534\n00:27:07.810 --> 00:27:11.150\nBut as for this episode we're gonna go\nahead and close down the show for ITProTV.\n\n535\n00:27:11.150 --> 00:27:12.440\nI've been your host Daniel Lowrie.\n\n536\n00:27:12.440 --> 00:27:13.180\n&gt;&gt; And I'm Wes Bryan.\n\n537\n00:27:13.180 --> 00:27:21.509\n&gt;&gt; And we'll see you next time.\n\n538\n00:27:21.509 --> 00:27:24.840\n[MUSIC]\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216502077"
        },
        {
          "description": "In this episode, Daniel and Wes continue their look into Cloud and Virtualization concepts. Here they pick back up with their discussion on Virtual Desktop Infrastructure(VDI/VDE). They also cover cloud access security brokers, VM Sprawl avoidance, and VM escape protections.",
          "length": "1220",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-7-2-cloud_and_virtualization_concepts-050517-PGM.00_23_22_04.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-7-2-cloud_and_virtualization_concepts-050517-PGM.00_23_22_04.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-7-2-cloud_and_virtualization_concepts-050517-PGM.00_23_22_04.Still001-sm.jpg",
          "title": "Cloud and Virtalization Concepts Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:02.463\nWelcome to IT Pro.TV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.463 --> 00:00:08.304\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:08.304 --> 00:00:12.035\n&gt;&gt; You're watching ITPro.TV.\n\n4\n00:00:12.035 --> 00:00:14.166\n&gt;&gt; All right, greetings, everyone, and\n\n5\n00:00:14.166 --> 00:00:17.020\nwelcome back to another\ngreat episode of ITPro.TV.\n\n6\n00:00:17.020 --> 00:00:18.540\nI'm your host, Daniel Lowrie, and\n\n7\n00:00:18.540 --> 00:00:22.940\nin today's episode, well, we're back with\nfour more of our Security Plus series.\n\n8\n00:00:22.940 --> 00:00:26.560\nAnd joining us back again,\nto continue our talk on virtualization and\n\n9\n00:00:26.560 --> 00:00:29.520\ncloud, is our good friend, Mr. Wes Bryan.\n\n10\n00:00:29.520 --> 00:00:30.970\nWes, welcome back, how's it going?\n\n11\n00:00:30.970 --> 00:00:33.672\n&gt;&gt; Hey, it's great,\ngood to be back, that's right, Dan.\n\n12\n00:00:33.672 --> 00:00:36.930\nThat's right, we were talking about\ncloud virtualization in the first part,\n\n13\n00:00:36.930 --> 00:00:39.702\nand I know we had just got into\nvirtual desktop infrastructure, and\n\n14\n00:00:39.702 --> 00:00:41.225\nthe virtual desktop environments.\n\n15\n00:00:41.225 --> 00:00:44.680\nAnd we kind of left you with\na little cliffhanger on that one.\n\n16\n00:00:44.680 --> 00:00:48.120\nSo we're gonna go ahead and revisit that,\nkeep in mind in the first part,\n\n17\n00:00:48.120 --> 00:00:51.750\nwe were talking like Dan said, we were\ntalking about things like cloud storage,\n\n18\n00:00:51.750 --> 00:00:56.210\nthe different cloud base models,\nsoftware as a service,\n\n19\n00:00:56.210 --> 00:00:58.790\ninfrastructure as a service,\nvirtualization.\n\n20\n00:00:58.790 --> 00:01:02.900\nDifference between things like hypervisors\nwhich is what allows us to enjoy cloud\n\n21\n00:01:02.900 --> 00:01:07.560\nservices out there today and take\nthe benefit or enjoy the benefits of them.\n\n22\n00:01:07.560 --> 00:01:09.912\nBut again, we left off with\nvirtual desktop infrastructure.\n\n23\n00:01:09.912 --> 00:01:13.643\nSo, I wanna go ahead and I wanna talk more\nabout that, because there are some details\n\n24\n00:01:13.643 --> 00:01:16.605\nthat you have to understand for\nthe exam, just in case it comes up.\n\n25\n00:01:16.605 --> 00:01:19.342\nSo, one of the things I\nwant you to remember,\n\n26\n00:01:19.342 --> 00:01:22.730\nwhen we talked about virtual\ndesktop infrastructure,\n\n27\n00:01:22.730 --> 00:01:27.341\nkeep in my mind that, unlike having\nto manually deploy operating systems,\n\n28\n00:01:27.341 --> 00:01:32.480\nto different machines across your network,\nwe've been doing this for a long time.\n\n29\n00:01:32.480 --> 00:01:36.497\nBut it can sometimes become a little\nproblematic when it comes to managing\n\n30\n00:01:36.497 --> 00:01:39.349\nthose devices,\nthings like application updates,\n\n31\n00:01:39.349 --> 00:01:41.449\nif you will, licensing compliance.\n\n32\n00:01:41.449 --> 00:01:45.748\nAnd one of the things that virtual desktop\ninfrastructure does is it allows us\n\n33\n00:01:45.748 --> 00:01:48.327\nto deploy our operating system,\nif you will,\n\n34\n00:01:48.327 --> 00:01:52.580\nto pretty much just about any device\nthat supports an internet connection.\n\n35\n00:01:52.580 --> 00:01:58.131\nBecause of the fact that the operating\nsystem, that desktop environment,\n\n36\n00:01:58.131 --> 00:02:03.522\nif you will, that is BVE if you ,will,\nis really being run on the server.\n\n37\n00:02:03.522 --> 00:02:07.118\nAnd one of the great things about that is\nit doesn't matter what the computational\n\n38\n00:02:07.118 --> 00:02:08.433\npower of the application is.\n\n39\n00:02:08.433 --> 00:02:13.796\nBecause if the application is being served\nup over the network to an endpoint,\n\n40\n00:02:13.796 --> 00:02:18.019\nwell, it can be served to something\nas simple as a cell phone,\n\n41\n00:02:18.019 --> 00:02:21.129\nif you will Smartphone, a tablet, laptop.\n\n42\n00:02:21.129 --> 00:02:24.440\nAnd it really doesn't matter what\nthe local resources of the device is,\n\n43\n00:02:24.440 --> 00:02:27.300\nbecause of the fact that it's\nthe server doing all the work.\n\n44\n00:02:27.300 --> 00:02:29.610\nWhat we need is just\na good network connection.\n\n45\n00:02:29.610 --> 00:02:32.220\nSo, for instance, you, kinda,\ngot a little diagram here, and\n\n46\n00:02:32.220 --> 00:02:33.710\nyou can see that, essentially,\n\n47\n00:02:33.710 --> 00:02:38.090\nwhat we're doing is, we're serving up\nthese desktops to multiple machines.\n\n48\n00:02:38.090 --> 00:02:41.080\nAnd again, they're just running\ncentralized on the server and\n\n49\n00:02:41.080 --> 00:02:44.070\nthat's one of the things that's good\nabout virtual desktop infrastructures.\n\n50\n00:02:44.070 --> 00:02:48.380\nRemember, if I have to update things like\nmy applications, if I have to do patch\n\n51\n00:02:48.380 --> 00:02:52.450\nmanagement I can update all of that right\nthere on the server rather than having to\n\n52\n00:02:52.450 --> 00:02:56.410\npush out a group policy, waiting for\nthe group policy to propagate through my\n\n53\n00:02:56.410 --> 00:02:59.950\nnetwork, for waiting to hopefully,\npeople reboot their computers.\n\n54\n00:02:59.950 --> 00:03:01.814\nRight, and this gives a nice,\n\n55\n00:03:01.814 --> 00:03:06.128\neasy streamline way to get people\naccess to that desktop environment.\n\n56\n00:03:06.128 --> 00:03:08.648\nAnd also to control things\nlike inconsistency, so,\n\n57\n00:03:08.648 --> 00:03:12.124\nthat's where we left off and I wanted\nto talk a little bit more about that.\n\n58\n00:03:12.124 --> 00:03:17.006\nWe get the ability, if you will,\nto just centralize the administration\n\n59\n00:03:17.006 --> 00:03:21.577\nof a desktop experience and\nwe can really control the consistency.\n\n60\n00:03:21.577 --> 00:03:25.118\nNow, however one of the things, like I\nsaid, doesn't matter what the device is,\n\n61\n00:03:25.118 --> 00:03:27.408\nit just really needs to\nhave good bandwidth, right.\n\n62\n00:03:27.408 --> 00:03:32.077\nYou can run these thin clients,\nwhich is pretty much close to the old KVM,\n\n63\n00:03:32.077 --> 00:03:35.480\nright, very small,\nsimplistic operating system.\n\n64\n00:03:35.480 --> 00:03:39.040\nThey connect over the network back\nto the server, and what they see,\n\n65\n00:03:39.040 --> 00:03:41.730\nyour end users, from their experience,\nis nothing more\n\n66\n00:03:41.730 --> 00:03:44.560\nthan a desktop that they're used\nto running on, working on locally.\n\n67\n00:03:44.560 --> 00:03:45.740\nBut to them it's no different,\n\n68\n00:03:45.740 --> 00:03:48.870\nright, it's no different than\ntheir traditional environment.\n\n69\n00:03:48.870 --> 00:03:50.540\nBut we know behind the scenes,\n\n70\n00:03:50.540 --> 00:03:55.040\nit gives us a lot better administration\nover that environment and control.\n\n71\n00:03:55.040 --> 00:03:57.483\nNow, speaking of control\nof that environment,\n\n72\n00:03:57.483 --> 00:04:01.785\nyou do have a couple of different types of\nvirtual desktop infrastructures, right.\n\n73\n00:04:01.785 --> 00:04:05.822\nSo when we say VDI and VDE, all right,\nvirtual desktop infrastructure,\n\n74\n00:04:05.822 --> 00:04:09.600\nessentially are all the components\nthat it takes to deliver a virtual\n\n75\n00:04:09.600 --> 00:04:12.421\ndesktop environment,\nthat makes sense, right.\n\n76\n00:04:12.421 --> 00:04:18.321\nSo the VDI are the components that support\nVDE so, again, alphabet soup right away.\n\n77\n00:04:18.321 --> 00:04:19.790\n[LAUGH] So gotta clarify that and\n\n78\n00:04:19.790 --> 00:04:22.920\nhopefully that takes any kind\nof confusion out of that.\n\n79\n00:04:22.920 --> 00:04:26.290\nSo when we're talking about\nthe virtual desktop experience, right,\n\n80\n00:04:26.290 --> 00:04:28.860\nwhat is it that the end user\nthemselves are gonna see?\n\n81\n00:04:28.860 --> 00:04:31.390\nThere's a couple different\nways that we can do this.\n\n82\n00:04:31.390 --> 00:04:34.070\nWe have what's known as\na persistent environment,\n\n83\n00:04:34.070 --> 00:04:36.700\nwe also have what's known as\na non persistent environment.\n\n84\n00:04:36.700 --> 00:04:39.620\nSo let's talk a little bit about\nthe different models, right.\n\n85\n00:04:39.620 --> 00:04:44.160\nIf we talk about a persistent\nvirtual desktop infrastructure,\n\n86\n00:04:44.160 --> 00:04:47.050\nthen what you're talking about is\na very stateful implementation, right.\n\n87\n00:04:47.050 --> 00:04:53.050\nSo it's very consistent implementation in\nthe fact that when an end user logs in,\n\n88\n00:04:53.050 --> 00:04:55.970\nevery time the user logs\ninto the virtual desktop,\n\n89\n00:04:55.970 --> 00:04:59.810\ntheir configurations are gonna\nbe retained, all right.\n\n90\n00:04:59.810 --> 00:05:01.920\nNow there's a challenge with that, right,\n\n91\n00:05:01.920 --> 00:05:04.520\nbecause you get what's known\nas a configuration drift.\n\n92\n00:05:04.520 --> 00:05:08.533\nAnd maybe you've got a security baseline\nthat you set and you want the environment\n\n93\n00:05:08.533 --> 00:05:12.080\nto always be that same way,\ncuz it adheres to a compliance, right.\n\n94\n00:05:12.080 --> 00:05:16.160\nWhen you have a persistent type VDI, where\nwhen the users log into the machines,\n\n95\n00:05:16.160 --> 00:05:19.280\nthey make changes to their desktop, make\nchanges to certain settings that you allow\n\n96\n00:05:19.280 --> 00:05:22.470\nthem to have the privilege of or\nlike their user profile.\n\n97\n00:05:22.470 --> 00:05:26.410\nAnd I log out, next time they log in,\ntheir settings are there.\n\n98\n00:05:26.410 --> 00:05:29.180\nSo that's where you do have\na challenge because you can get some\n\n99\n00:05:29.180 --> 00:05:33.310\nconfiguration drift, cuz you're\nessentially allowing your end users to\n\n100\n00:05:33.310 --> 00:05:37.060\ndo a moderate amount of configuration for\nthe environment that they're working in.\n\n101\n00:05:37.060 --> 00:05:39.860\nHowever, there's also benefits right,\nand we talk about convenience, right.\n\n102\n00:05:39.860 --> 00:05:43.571\nWith that consistent interface\nalways being the same every time,\n\n103\n00:05:43.571 --> 00:05:46.494\nthe user is familiar with the environment,\nright.\n\n104\n00:05:46.494 --> 00:05:52.016\nFamiliarity, if you will,\ncan lead to maybe different productivity.\n\n105\n00:05:52.016 --> 00:05:55.482\nHowever, when it comes to\nthe management side of this,\n\n106\n00:05:55.482 --> 00:05:58.434\nbecause of the fact that\nconfigurations stay,\n\n107\n00:05:58.434 --> 00:06:03.553\nthis is just about as close to a physical\ndesktop infrastructure as you would get.\n\n108\n00:06:03.553 --> 00:06:07.766\nThe image maintenance is a little\nbit more complex on that,\n\n109\n00:06:07.766 --> 00:06:10.725\nthe application state data is retained.\n\n110\n00:06:10.725 --> 00:06:13.780\nSo if an application becomes problematic,\nwell guess what,\n\n111\n00:06:13.780 --> 00:06:16.788\nnext time the user logs in it's\nstill gonna be problematic.\n\n112\n00:06:16.788 --> 00:06:21.488\nSo we do have to consider that,\nthe other thing about persistent desktop\n\n113\n00:06:21.488 --> 00:06:25.430\nsolutions like this is it\naccrues a lot of storage space.\n\n114\n00:06:25.430 --> 00:06:29.630\nWhere you're gonna have to store\nthose configuration files, right,\n\n115\n00:06:29.630 --> 00:06:32.140\nthat configuration data's gonna\nhave to be stored somewhere.\n\n116\n00:06:32.140 --> 00:06:35.627\nSo you can accrue more storage space\nwith these kind of virtual desktop\n\n117\n00:06:35.627 --> 00:06:36.920\ninfrastructure.\n\n118\n00:06:36.920 --> 00:06:40.440\nYou typically have things like larger\nbackups too that you're gonna have to run,\n\n119\n00:06:40.440 --> 00:06:45.160\nbecause again, all that information\nremains stateful, if you will,\n\n120\n00:06:45.160 --> 00:06:48.960\nthrough the duration of however long\nthey are using that desktop environment.\n\n121\n00:06:48.960 --> 00:06:52.543\nAnd that's on like non persistent,\nVDI or VDE if you will,\n\n122\n00:06:52.543 --> 00:06:54.700\nVirtual Desktop Infrastructure.\n\n123\n00:06:54.700 --> 00:06:58.330\nAnd this kinda lends itself to a concept\nthat we've talked about in other episodes,\n\n124\n00:06:58.330 --> 00:07:00.230\nDan, like the Linux live CDs, right.\n\n125\n00:07:00.230 --> 00:07:04.560\nOr like a Win P environment where\nthe operating system is running in RAM.\n\n126\n00:07:04.560 --> 00:07:08.012\nRight, so in this case when the virtual\ndesktop infrastructure is served up,\n\n127\n00:07:08.012 --> 00:07:09.335\nit's no different, right.\n\n128\n00:07:09.335 --> 00:07:11.531\nStill running on the server, all right,\n\n129\n00:07:11.531 --> 00:07:15.486\nbut the difference is it's a stateless\nsolution in the fact that every time\n\n130\n00:07:15.486 --> 00:07:19.883\nthe user logs into that virtual desktop\ninfrastructure they're gonna be served up\n\n131\n00:07:19.883 --> 00:07:22.679\nwith a fresh instance of their experience,\nright.\n\n132\n00:07:22.679 --> 00:07:26.246\nAll the settings are gonna\nbe basically reverted\n\n133\n00:07:26.246 --> 00:07:30.252\nback as if they were logging in for\nthe very first time.\n\n134\n00:07:30.252 --> 00:07:32.937\nNow if you're doing things\nlike photo redirection,\n\n135\n00:07:32.937 --> 00:07:36.757\ntypically were not storing our data,\ndefinitely not storing it locally and\n\n136\n00:07:36.757 --> 00:07:41.430\nthat's one of the benefits of VDIs, you're\nreally not storing anything locally.\n\n137\n00:07:41.430 --> 00:07:44.594\nBut if you're moving your\ndata to another location,\n\n138\n00:07:44.594 --> 00:07:49.588\nthen this really isn't a problem if the\napplications revert themselves to whatever\n\n139\n00:07:49.588 --> 00:07:53.408\nthe state is, if you will,\nthat you set up in your master image.\n\n140\n00:07:53.408 --> 00:07:59.302\nKeep in mind that it requires a user\nstate environment management solution.\n\n141\n00:07:59.302 --> 00:08:03.309\nIf you do wanna maintain\nthose consistent settings.\n\n142\n00:08:03.309 --> 00:08:07.605\nThe storage requirements are a little\nbit smaller here because you're\n\n143\n00:08:07.605 --> 00:08:10.470\nconstantly resetting the information,\nso and\n\n144\n00:08:10.470 --> 00:08:15.268\nresetting that environment you don't\nhave any of those residual settings that\n\n145\n00:08:15.268 --> 00:08:18.147\nare being stored on\nthe drives of your servers.\n\n146\n00:08:18.147 --> 00:08:21.810\nAll right, so\njust know nonpersistent versus persistent.\n\n147\n00:08:21.810 --> 00:08:26.119\nPersistent means that it's really a lot\nlike the physical desktop infrastructure\n\n148\n00:08:26.119 --> 00:08:30.240\nwhere if I've got my laptop, every time\nI log into my laptop it's pretty much in\n\n149\n00:08:30.240 --> 00:08:34.263\nthe state and the configuration that I\nleft it, right, for better or worse.\n\n150\n00:08:34.263 --> 00:08:38.516\nVersus if it's a nonpersistent\nenvironment it means every time I log in,\n\n151\n00:08:38.516 --> 00:08:43.456\nit's a fresh, clean instance of whatever\noperating system you might be deploying or\n\n152\n00:08:43.456 --> 00:08:44.501\nrunning, okay.\n\n153\n00:08:44.501 --> 00:08:48.595\nSo again, keep in mind that they\nboth have their benefits and\n\n154\n00:08:48.595 --> 00:08:50.860\nthey both have their drawbacks.\n\n155\n00:08:52.090 --> 00:08:54.805\nAll right, Dan, so what are some of the\nother things that we're gonna talk about?\n\n156\n00:08:54.805 --> 00:09:00.073\nThey also call out something known as\na cloud access security broker, wow,\n\n157\n00:09:00.073 --> 00:09:05.341\nthat is a very, very hefty term for\nessentially some kind of policy-driven\n\n158\n00:09:05.341 --> 00:09:11.298\ngateway device that controls the access\nthat users have to cloud resources, right.\n\n159\n00:09:11.298 --> 00:09:14.802\nIt's very easy in the cloud to\ngive access to resources, and\n\n160\n00:09:14.802 --> 00:09:18.593\nif you're a diverse company you\ncould have multiple locations.\n\n161\n00:09:18.593 --> 00:09:23.780\nWell how do you keep track, right,\nhow do you keep track of the usage and\n\n162\n00:09:23.780 --> 00:09:27.160\nreally, really control that access?\n\n163\n00:09:27.160 --> 00:09:31.700\nAnd that's where the, what do they\ncall it, CASB, if you will, C-A-S-B.\n\n164\n00:09:31.700 --> 00:09:33.868\nI'm not gonna throw another acronym,\nwell, I just did I guess.\n\n165\n00:09:33.868 --> 00:09:34.610\n&gt;&gt; [LAUGH] Yeah, you just did.\n\n166\n00:09:34.610 --> 00:09:36.010\n&gt;&gt; I just did, but\nI'm not gonna keep using it.\n\n167\n00:09:36.010 --> 00:09:40.345\nAgain, it's common access security broker\nand again, it acts as a gateway or,\n\n168\n00:09:40.345 --> 00:09:44.873\nif you will, the gatekeeper between our\non-premises resources, if you will, and\n\n169\n00:09:44.873 --> 00:09:48.032\nthen the cloud based solutions\nthat we are implementing.\n\n170\n00:09:48.032 --> 00:09:51.908\nOne of the great things\nis it can secure access\n\n171\n00:09:51.908 --> 00:09:55.590\nacross many a different devices, right.\n\n172\n00:09:55.590 --> 00:10:00.221\nIt doesn't matter if it's an MDM solution\nor if it is traditional workstations that\n\n173\n00:10:00.221 --> 00:10:04.331\nyou're connecting to through browser\nbased applications, it is great,\n\n174\n00:10:04.331 --> 00:10:06.370\nif you will, to secure that access.\n\n175\n00:10:06.370 --> 00:10:09.460\nAnd it's typically policy driven, you\ncan implement things like policies that\n\n176\n00:10:09.460 --> 00:10:12.925\ndictate what level of\naccess somebody has and\n\n177\n00:10:12.925 --> 00:10:15.570\nwhat resources they do or\ndo not have access to.\n\n178\n00:10:17.210 --> 00:10:21.350\nAll right, a couple of last little\nthings here that we wanna talk about.\n\n179\n00:10:21.350 --> 00:10:25.090\nWe wanna talk about VM sprawling,\nall right.\n\n180\n00:10:25.090 --> 00:10:28.560\n&gt;&gt; You've mentioned this quite\na bit throughout this little cloud\n\n181\n00:10:28.560 --> 00:10:31.150\nthing we've been talking about,\na real problem.\n\n182\n00:10:31.150 --> 00:10:32.145\n&gt;&gt; It is, and\nthink about the adminstration.\n\n183\n00:10:32.145 --> 00:10:35.812\nWe say how easy it is, and we've talked\nabout it in the first part where we\n\n184\n00:10:35.812 --> 00:10:39.559\nwere talking about spinning up\nan environment for your dev team, right.\n\n185\n00:10:39.559 --> 00:10:43.975\nOr like we do here, we use\ncontainerization using things like Docker,\n\n186\n00:10:43.975 --> 00:10:48.690\nwhere the dev team can pull down\ntheir own isolated environments.\n\n187\n00:10:48.690 --> 00:10:50.338\nSo what happens if Dan\npulls down an environment,\n\n188\n00:10:50.338 --> 00:10:53.298\nhe's got a Linux server cuz he's working\non something, he's studying for something.\n\n189\n00:10:53.298 --> 00:10:57.708\nI'm pulling down a Windows server, I'm\ncreating some Windows machines instance,\n\n190\n00:10:57.708 --> 00:11:01.031\nI'm storing information inside\nof the cloud storage, right.\n\n191\n00:11:01.031 --> 00:11:03.769\nAnd this happens, and\nthat's just a couple of people,\n\n192\n00:11:03.769 --> 00:11:06.403\nimagine if it happens all\nover your network, right.\n\n193\n00:11:06.403 --> 00:11:11.347\nVM sprawl is more about the virtualization\nof VMs, and how easily they can be\n\n194\n00:11:11.347 --> 00:11:16.678\ncreated, and the fact that if you are\nconstantly creating these virtual machines\n\n195\n00:11:16.678 --> 00:11:22.086\nyou could be over-provisioning and you\nwon't even be aware of what's going on and\n\n196\n00:11:22.086 --> 00:11:26.980\nthen the administration becomes really,\nreally hard to maintain.\n\n197\n00:11:26.980 --> 00:11:32.090\nToo many VMs created, or deployed,\non a single resource can cause\n\n198\n00:11:32.090 --> 00:11:36.074\nthings like resource exhaustion that maybe\nthe administrator's not even aware of.\n\n199\n00:11:36.074 --> 00:11:39.822\nSays hey, I got this server's got\nplenty of RAM, got plenty of CPU, and\n\n200\n00:11:39.822 --> 00:11:43.758\nthen over the course of a couple of\nmonths through testing and development,\n\n201\n00:11:43.758 --> 00:11:46.831\nwe find out that that server is\npretty much at the end of its,\n\n202\n00:11:46.831 --> 00:11:49.449\nhow much it can support,\nright, so what do we do?\n\n203\n00:11:49.449 --> 00:11:52.460\nWe have to increase the computational\npower, not too hard,\n\n204\n00:11:52.460 --> 00:11:54.061\ninside of the cloud we can do it.\n\n205\n00:11:54.061 --> 00:11:57.905\nThrow some more CPU at it, right,\nthrow some more memory at it, if you will,\n\n206\n00:11:57.905 --> 00:11:59.890\nincrease the storage size.\n\n207\n00:11:59.890 --> 00:12:01.910\nBut as that keeps happening\nacross your network,\n\n208\n00:12:01.910 --> 00:12:06.260\nif you will, and\noverabundance of virtual machines\n\n209\n00:12:06.260 --> 00:12:10.650\ncan make the administrative complexities,\nexponentially increase.\n\n210\n00:12:10.650 --> 00:12:14.688\nAnd that's what basically VM Sprawl is,\nall right that's what sprawl is, and\n\n211\n00:12:14.688 --> 00:12:17.113\nwhat they want you to\nknow is let's avoid that.\n\n212\n00:12:17.113 --> 00:12:21.039\nVM Sprawl avoidance is just\nhaving proper documentation,\n\n213\n00:12:21.039 --> 00:12:25.042\nhaving things like your cloud\naccess security brokers, and\n\n214\n00:12:25.042 --> 00:12:30.302\nmaking sure that you don't have things\nlike large amounts of storage accrual,\n\n215\n00:12:30.302 --> 00:12:33.928\nthat the administrators\ncan be accountable, right.\n\n216\n00:12:33.928 --> 00:12:37.479\nCuz we have things like chargeback\nthat we have to worry about,\n\n217\n00:12:37.479 --> 00:12:41.499\nwe have to assign some kind of\nresponsibility to the monetary value, or\n\n218\n00:12:41.499 --> 00:12:44.380\nwhatever the resources that we're using.\n\n219\n00:12:44.380 --> 00:12:48.160\nAnd that's one of the things that we wanna\nkind of avoid just these one offs, and\n\n220\n00:12:48.160 --> 00:12:51.470\nkeep one offing virtual machines, and\nbefore you know it you've consumed a lot\n\n221\n00:12:51.470 --> 00:12:54.670\nof resources that can get into thousands\nand thousands of dollars real quick.\n\n222\n00:12:54.670 --> 00:12:57.961\nAnd when the accountability comes\naccountability's even harder,\n\n223\n00:12:57.961 --> 00:12:59.726\nwho do we charge accountability to?\n\n224\n00:12:59.726 --> 00:13:03.056\n&gt;&gt; Right, definitely wanna keep\na lookout for that, super easy to do.\n\n225\n00:13:03.056 --> 00:13:07.691\nLike we said it is a bit of a problem, you\nhave to maintain a healthy environment and\n\n226\n00:13:07.691 --> 00:13:11.723\njust allowing all of these virtual\nmachines to exist because you needed\n\n227\n00:13:11.723 --> 00:13:16.290\nit for a second and then forgot to\ndeprovision them, not a great way to go.\n\n228\n00:13:16.290 --> 00:13:19.840\nAnd then you gotta come into security as\nwell, right Wes, we have to think, I mean\n\n229\n00:13:19.840 --> 00:13:24.090\nthis is Security+, right, so we're gonna\nthrow a dash of security on top of this.\n\n230\n00:13:24.090 --> 00:13:27.130\nOne of the main reasons a lot\nof people don't go to the cloud\n\n231\n00:13:27.130 --> 00:13:29.800\nis because they are hyper-security minded.\n\n232\n00:13:29.800 --> 00:13:34.288\nThey think I have to worry about it\nbecause I'm sharing resources with a cloud\n\n233\n00:13:34.288 --> 00:13:38.865\nprovider on their machine with maybe\nanother person, maybe another entity.\n\n234\n00:13:38.865 --> 00:13:43.449\nAnd how do I know that the RAM\nthat we're sharing is not going\n\n235\n00:13:43.449 --> 00:13:48.322\nto expose my company, or\nmy organization to an exploitation.\n\n236\n00:13:48.322 --> 00:13:51.938\nThis is something that's a real concern,\nit's why a lot of people that are still\n\n237\n00:13:51.938 --> 00:13:54.561\nhesitant to put stuff in\nthe cloud are worried about that.\n\n238\n00:13:54.561 --> 00:13:58.600\nNow, we've tried to address\nthis by isolation, right Wes?\n\n239\n00:13:58.600 --> 00:14:00.810\n&gt;&gt; That's right,\nit's called a multitenancy, right?\n\n240\n00:14:00.810 --> 00:14:02.520\n&gt;&gt; Multitenancy, yes.\n\n241\n00:14:02.520 --> 00:14:05.980\n&gt;&gt; And that's the exact concept\nthat Dan's talking about,\n\n242\n00:14:05.980 --> 00:14:08.610\nit means we've got tenant isolation.\n\n243\n00:14:08.610 --> 00:14:14.870\nMultitenancy means that I have more than\none customer using the same software.\n\n244\n00:14:14.870 --> 00:14:17.910\nAnd again, if you bring in things like\nHIPAA compliance and FIPS compliance,\n\n245\n00:14:17.910 --> 00:14:20.870\nwith a lot of the solutions,\nif you look at their documentation,\n\n246\n00:14:20.870 --> 00:14:22.930\nsay that they do fall\nunder that classification.\n\n247\n00:14:22.930 --> 00:14:25.520\nIt's because they can isolate\nthose portions of memory,\n\n248\n00:14:25.520 --> 00:14:28.580\nmaking sure that we don't\nhave people jumping memory.\n\n249\n00:14:28.580 --> 00:14:31.840\nAnd that's another thing, too,\nthat we have to worry about,\n\n250\n00:14:31.840 --> 00:14:35.090\nthat's something called\nVM escape protection.\n\n251\n00:14:35.090 --> 00:14:39.413\nBut a couple more things I'd like to\nsay about VM sprawl avoidance too.\n\n252\n00:14:39.413 --> 00:14:42.694\nWhen you start to have all these machines,\nright, that are being spun up,\n\n253\n00:14:42.694 --> 00:14:45.559\nwhich ones are for the testing\nenvironments and which ones are for\n\n254\n00:14:45.559 --> 00:14:47.353\nthe production environments, right.\n\n255\n00:14:47.353 --> 00:14:50.175\nIf an administrator doesn't know,\ncould they potentially go in there and\n\n256\n00:14:50.175 --> 00:14:52.770\nsay we're decommissioning this\ncuz it's no longer in use, and\n\n257\n00:14:52.770 --> 00:14:56.070\nwe didn't realize that it's actually a\nserver that's in a production environment.\n\n258\n00:14:56.070 --> 00:14:59.430\nBut their bad configuration management and\nchange management,\n\n259\n00:14:59.430 --> 00:15:03.032\nwe're not even aware of what that\nactually is doing in our company, so\n\n260\n00:15:03.032 --> 00:15:06.120\nyou can see you definitely\nwant to avoid that.\n\n261\n00:15:06.120 --> 00:15:12.480\nNow, kinda what Dan is alluding to is\nwhat we call VM escape, all right.\n\n262\n00:15:12.480 --> 00:15:15.700\nSee when we talk about virtualization,\nwe've talked about the fact that it\n\n263\n00:15:15.700 --> 00:15:18.960\nisolates virtual machines\nbetween each other.\n\n264\n00:15:18.960 --> 00:15:23.477\nSo that, if you will, an application or\nany kind of information that's\n\n265\n00:15:23.477 --> 00:15:27.415\nrunning in an instance of one VM,\ncannot escape to another VM.\n\n266\n00:15:27.415 --> 00:15:31.404\nMore so though than that,\nwe talk about host isolation, right,\n\n267\n00:15:31.404 --> 00:15:34.884\nthe fact that I'm running\nmultiple virtual machines and\n\n268\n00:15:34.884 --> 00:15:38.089\nthey don't have direct access to the host,\nright.\n\n269\n00:15:38.089 --> 00:15:43.405\nWell, when we talk about something\nlike VM escape what happens is,\n\n270\n00:15:43.405 --> 00:15:48.068\nis even though we have that\nisolated environment, the VM,\n\n271\n00:15:48.068 --> 00:15:53.880\nan attacker if you will, breaks\nthe communication boundaries, right.\n\n272\n00:15:53.880 --> 00:15:57.068\nThat isolation, they break out\nof that isolated boundary and\n\n273\n00:15:57.068 --> 00:16:01.251\nit allows for communications with things\nlike First of all, other VMs, right?\n\n274\n00:16:01.251 --> 00:16:04.876\nDan said, hey, I gotta worry about\nmaybe somebody breaking out and\n\n275\n00:16:04.876 --> 00:16:06.540\ngetting into my information.\n\n276\n00:16:06.540 --> 00:16:09.290\nBecause we're both running on\nthe same physical hardware, right?\n\n277\n00:16:09.290 --> 00:16:14.355\nAnd that is something that you have to\nmake sure that you watch your SLAs.\n\n278\n00:16:14.355 --> 00:16:17.596\nNow in just regular virtualization, you\nalso have to [LAUGH] worry about it inside\n\n279\n00:16:17.596 --> 00:16:20.137\nyour own networks,\nif you have on-premise virtualization.\n\n280\n00:16:20.137 --> 00:16:23.443\nBecause, if an attacker attacks one of\nyour virtual machines, that maybe has\n\n281\n00:16:23.443 --> 00:16:27.765\npublic access, can they access now another\nvirtual machine that's in your network?\n\n282\n00:16:27.765 --> 00:16:31.135\nCan they access the host,\nthat that virtual machine is running on?\n\n283\n00:16:31.135 --> 00:16:32.840\nAnd even worse than that,\n\n284\n00:16:32.840 --> 00:16:36.140\ncan they take advantage of the physical\nnetwork adaptor that's on the host?\n\n285\n00:16:36.140 --> 00:16:40.190\nNow, they no longer have just access\nto the virtual machine or the host, but\n\n286\n00:16:40.190 --> 00:16:41.930\nnow they have access to your network.\n\n287\n00:16:41.930 --> 00:16:43.170\nAnd where could they go from that?\n\n288\n00:16:43.170 --> 00:16:44.930\nAgain that's that VM escape.\n\n289\n00:16:46.990 --> 00:16:50.595\nThere is an attack that you might [LAUGH]\nwanna look up and just read about,\n\n290\n00:16:50.595 --> 00:16:54.454\na little scary, it's called VENOM, and\nI love the name cuz I'm a GI Joe fan.\n\n291\n00:16:54.454 --> 00:16:55.904\n&gt;&gt; [LAUGH]\n&gt;&gt; But\n\n292\n00:16:55.904 --> 00:17:02.000\nit is Virtualized Environment Neglected\nOperations Manipulation, okay?\n\n293\n00:17:02.000 --> 00:17:05.201\nDon't worry about the acronym, I just\nthought it was great [LAUGH] because it's\n\n294\n00:17:05.201 --> 00:17:07.130\ndescribing exactly what\nwe are talking about.\n\n295\n00:17:07.130 --> 00:17:11.490\nThe ability to break free from the\nisolated boundaries, make it to another\n\n296\n00:17:11.490 --> 00:17:14.720\nvirtual machine, make it into\nthe memory of the hosts themselves.\n\n297\n00:17:14.720 --> 00:17:18.010\nAnd even worse so, like I said, [LAUGH]\nmaking it to the network adapter where now\n\n298\n00:17:18.010 --> 00:17:22.120\nthey have access to maybe a whole bunch of\n\n299\n00:17:22.120 --> 00:17:26.760\nresources on your network that otherwise\nyou don't want any unauthorized access.\n\n300\n00:17:26.760 --> 00:17:30.916\n&gt;&gt; Well hopefully by the end of this\nepisode and the previous episode that\n\n301\n00:17:30.916 --> 00:17:35.074\nwe've done, you've come to\nthe realization that virtualization,\n\n302\n00:17:35.074 --> 00:17:38.890\nCloud use is something that we\nare gonna probably play a part in.\n\n303\n00:17:38.890 --> 00:17:39.599\nAnd that each,\n\n304\n00:17:39.599 --> 00:17:43.312\nbecause it's a different technology\nthan physical on-premises hardware, or\n\n305\n00:17:43.312 --> 00:17:47.600\nmaybe you're running physical on-premises\nhardware, and doing an on-premises Cloud.\n\n306\n00:17:47.600 --> 00:17:50.510\nWe have to consider these things when\nit comes to our security, right?\n\n307\n00:17:50.510 --> 00:17:55.570\nAnd Wes has gone through a litany of\ndifferent ways in which we can do that.\n\n308\n00:17:55.570 --> 00:17:58.600\nAnd concepts that we just need to\nbe aware of that are happening\n\n309\n00:17:58.600 --> 00:18:01.550\nwhen we employ these\ntechnologies in our environment.\n\n310\n00:18:01.550 --> 00:18:04.850\nBut Wes, I know we've gone through a lot\nof things, just before we close the show,\n\n311\n00:18:04.850 --> 00:18:06.480\nis there any parting words\nyou'd like to give us?\n\n312\n00:18:06.480 --> 00:18:10.149\n&gt;&gt; Yeah, just if you're using Cloud\ntechnologies, pay attention to your SLAs,\n\n313\n00:18:10.149 --> 00:18:12.850\nright, pay attention to your\nservice level agreements.\n\n314\n00:18:12.850 --> 00:18:16.300\nAnd if you're worried about\nthings like security standards or\n\n315\n00:18:16.300 --> 00:18:20.074\nprocessing standards, pay attention\nto the standards in the SLAs,\n\n316\n00:18:20.074 --> 00:18:22.173\nthey don't leave this stuff hidden.\n\n317\n00:18:22.173 --> 00:18:25.457\nIt's gonna be pretty much the neon sign\nsomewhere, you just have to figure out\n\n318\n00:18:25.457 --> 00:18:28.890\nwhere on the website that they're\ngonna give you this documentation.\n\n319\n00:18:28.890 --> 00:18:33.000\nAnd sure, some of the documentation,\nit might read like stereo instructions,\n\n320\n00:18:33.000 --> 00:18:35.630\nbut when it comes to the Cloud,\ndon't shy away from it.\n\n321\n00:18:35.630 --> 00:18:38.910\nDon't think you have to put on your tin\nfoil hat, right, the Cloud is here, and\n\n322\n00:18:38.910 --> 00:18:42.260\nit's here to stay, and\nit is something that isn't going away.\n\n323\n00:18:42.260 --> 00:18:45.850\nSo, you're gonna probably see in the\nfuture that you're gonna require more and\n\n324\n00:18:45.850 --> 00:18:49.280\nmore knowledge,\neven in some of the basic certifications,\n\n325\n00:18:49.280 --> 00:18:51.470\nto be able to show\na competency in this field.\n\n326\n00:18:51.470 --> 00:18:56.610\nJust because like we've seen with mobile\ndevices are very very prevalent now,\n\n327\n00:18:56.610 --> 00:19:01.410\nand then IoT came into it, right,\nthat's another thing that comes into play.\n\n328\n00:19:01.410 --> 00:19:05.090\nNow Cloud is very important, and I'm not\ngiving a timeframe, but you can see all of\n\n329\n00:19:05.090 --> 00:19:10.350\nthese different trends that maybe\na couple years ago weren't high priority.\n\n330\n00:19:10.350 --> 00:19:12.340\nCloud is definitely high priority today,\nand\n\n331\n00:19:12.340 --> 00:19:15.990\nit is something that you have to be aware\nof, be aware of the models, if you will.\n\n332\n00:19:15.990 --> 00:19:20.110\nBe aware of in what scenario you\nwould use one of these models, right?\n\n333\n00:19:20.110 --> 00:19:24.950\nFor instance, understand why you might\nuse a persistent versus a non-persistent\n\n334\n00:19:24.950 --> 00:19:28.190\nvirtual desktop infrastructure,\nkinda understand the benefits,\n\n335\n00:19:28.190 --> 00:19:30.420\nthe centralized model that we have.\n\n336\n00:19:30.420 --> 00:19:35.350\nDon't be scared of it, don't shy away\nfrom it, dive in head first, if you will,\n\n337\n00:19:35.350 --> 00:19:38.060\nand just get acclimated.\n\n338\n00:19:38.060 --> 00:19:41.010\nBe familiar with these concepts,\ndon't let them confuse you,\n\n339\n00:19:41.010 --> 00:19:44.350\ndon't let the acronyms scare you away.\n\n340\n00:19:44.350 --> 00:19:48.182\nAnd certainly, don't shy away from it,\nagain, it's not a tin foil experience,\n\n341\n00:19:48.182 --> 00:19:51.605\nit's just knowing what you have to do\nin order to secure the environment.\n\n342\n00:19:51.605 --> 00:19:53.443\n&gt;&gt; All right, wise words from Mr.\n\n343\n00:19:53.443 --> 00:19:56.654\nWes Bryan,\ndefinitely heed them to act your benefits.\n\n344\n00:19:56.654 --> 00:19:59.408\nThat being said, looks like we\nare out of time for this episode,\n\n345\n00:19:59.408 --> 00:20:00.890\nwe do thank you guys for watching.\n\n346\n00:20:00.890 --> 00:20:03.700\nSigning off for ITProTV,\nI've been your host, Daniel Lowrie.\n\n347\n00:20:03.700 --> 00:20:04.750\n&gt;&gt; And I'm Wes Bryan.\n\n348\n00:20:04.750 --> 00:20:06.725\n&gt;&gt; We'll see you next time.\n\n349\n00:20:06.725 --> 00:20:12.584\n[MUSIC]\n\n350\n00:20:12.584 --> 00:20:16.040\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216665545"
        },
        {
          "description": "In this episode, Daniel and Wes explain how to use automation and resiliency to reduce risk. Here they show you how through the use of standard procedures and automated task you can reduce the amount of common error through human fallibility. Other topics include Elasticity, Scalability, Redundancy, Fault Tolerance, and High Availability.",
          "length": "1831",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-8-using_resiliency_and_automation_to_reduce_risk-050317.00_30_15_18.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-8-using_resiliency_and_automation_to_reduce_risk-050317.00_30_15_18.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-8-using_resiliency_and_automation_to_reduce_risk-050317.00_30_15_18.Still001-sm.jpg",
          "title": "Resiliency and Automation to Reduce Risk",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:06.145\nWelcome to ITProTV,\nI'm your host [CROSSTALK]\n\n2\n00:00:06.145 --> 00:00:08.451\n[MUSIC]\n\n3\n00:00:08.451 --> 00:00:12.031\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.031 --> 00:00:13.943\n&gt;&gt; All right, greetings everyone and\n\n5\n00:00:13.943 --> 00:00:16.691\nwelcome back to another\ngreat episode of ITProTV.\n\n6\n00:00:16.691 --> 00:00:20.335\nI'm your host Daniel Lowrie, and\nin todays' episode we are moving on,\n\n7\n00:00:20.335 --> 00:00:22.146\nmoving forward, trudging ahead.\n\n8\n00:00:22.146 --> 00:00:24.037\nBut more on our Security+ series and\n\n9\n00:00:24.037 --> 00:00:28.180\njoining us here again obviously in this\nstudio which is lovely studio too.\n\n10\n00:00:28.180 --> 00:00:29.410\nI do enjoy being in here.\n\n11\n00:00:29.410 --> 00:00:31.578\nWith you good folks, it's Mr. West Bryan].\n\n12\n00:00:31.578 --> 00:00:32.750\nI'd quit rambling now.\n\n13\n00:00:32.750 --> 00:00:33.760\n[LAUGH] Welcome man.\n\n14\n00:00:33.760 --> 00:00:34.490\nHow's it's going today?\n\n15\n00:00:34.490 --> 00:00:36.315\n&gt;&gt; Man it's.\nIt's going great, it's always fun here.\n\n16\n00:00:36.315 --> 00:00:39.375\nAnd yeah, a lot of fun behind the scenes\nthat you guys don't get to see.\n\n17\n00:00:39.375 --> 00:00:39.895\n&gt;&gt; No.\n\n18\n00:00:39.895 --> 00:00:40.685\n&gt;&gt; But yeah.\n\n19\n00:00:40.685 --> 00:00:42.915\nIt's a great day here at ITProTV and\n\n20\n00:00:42.915 --> 00:00:48.745\nwhat we're gonna be looking at today is\nresiliency and automation to reduce risk.\n\n21\n00:00:48.745 --> 00:00:52.095\nAnd let's kinda tell you what\nthe official objective is,\n\n22\n00:00:52.095 --> 00:00:57.390\nthat is explain how resiliency and\nautomation strategies reduce risk.\n\n23\n00:00:58.560 --> 00:01:01.090\nWe'll it's about consistency,\ncase dismissed.\n\n24\n00:01:01.090 --> 00:01:02.840\nNo just kidding,\nthere's a lot more through it than that,\n\n25\n00:01:02.840 --> 00:01:05.850\nbut one of the things that\nthey first start out with is,\n\n26\n00:01:05.850 --> 00:01:09.070\nthey talk about automation and\nenscripting, right?\n\n27\n00:01:09.070 --> 00:01:14.187\nAnd this really comes down to automating\na course of actions and when you do that,\n\n28\n00:01:14.187 --> 00:01:18.853\nnot only does it become cost effective,\nyour timed, you time to complete\n\n29\n00:01:18.853 --> 00:01:23.319\nthe process a little bit easier maybe\na little bit shorter if you will.\n\n30\n00:01:23.319 --> 00:01:26.607\nJust keep in mind that any kind of\nautomated action is gonna provide\n\n31\n00:01:26.607 --> 00:01:29.142\na consistency and\nit can reduce the human element.\n\n32\n00:01:29.142 --> 00:01:33.866\nAnd what do I mean by the human element,\nbut basically misconfigurations right,\n\n33\n00:01:33.866 --> 00:01:35.713\nif we can script a process out and\n\n34\n00:01:35.713 --> 00:01:39.084\nwe know that it's gonna run\nprovided the script is right.\n\n35\n00:01:39.084 --> 00:01:41.840\n[LAUGH] That it's gonna run\nthe same way each time.\n\n36\n00:01:41.840 --> 00:01:43.700\nAgain we start to get that consistency and\n\n37\n00:01:43.700 --> 00:01:47.600\nit makes it a lot easier\non us as administrators.\n\n38\n00:01:47.600 --> 00:01:50.750\nBut we also have to implement\nthings like the scripting,\n\n39\n00:01:50.750 --> 00:01:52.650\nwe gotta keep with our monitoring, right?\n\n40\n00:01:52.650 --> 00:01:56.780\nWe can't just say, okay,\nthe scripts are in place, they're running.\n\n41\n00:01:56.780 --> 00:01:58.310\nLet's just walk away from it, right.\n\n42\n00:01:58.310 --> 00:02:00.260\nSo it's not complete automation.\n\n43\n00:02:00.260 --> 00:02:01.440\nWe still have to monitor, right.\n\n44\n00:02:01.440 --> 00:02:04.240\nAnd then we have to make\nsure that you do things like\n\n45\n00:02:04.240 --> 00:02:05.670\nconfiguration validation, right.\n\n46\n00:02:05.670 --> 00:02:08.238\nThat's why we have things\nlike security-based lines,\n\n47\n00:02:08.238 --> 00:02:12.820\nconfiguration-based lines that we can run\nand then we can implement on, let's say,\n\n48\n00:02:12.820 --> 00:02:15.360\nfor instance, a server and\nit configures it for us.\n\n49\n00:02:15.360 --> 00:02:18.350\nNow, that automated process,\nwhat does it do?\n\n50\n00:02:18.350 --> 00:02:20.720\nAgain, it helps you to adhere\nto some kind of a template.\n\n51\n00:02:20.720 --> 00:02:22.830\nThat's one of the reasons\nthings like templates are very,\n\n52\n00:02:22.830 --> 00:02:26.530\nvery good especially when you're\ntalking even things in policies.\n\n53\n00:02:26.530 --> 00:02:30.280\nWhen we talk about we use\npolicy templates, right?\n\n54\n00:02:30.280 --> 00:02:34.410\nSo that we ensure that when\na user is signing a policy\n\n55\n00:02:34.410 --> 00:02:38.570\nit's the same one that the other\nusers are signing, if you will.\n\n56\n00:02:38.570 --> 00:02:43.150\nSo again, configuration validation\nthere are baselines that we can put\n\n57\n00:02:43.150 --> 00:02:47.260\ninto place to make sure that\nevery system that we do deploy\n\n58\n00:02:47.260 --> 00:02:50.469\nhas a consistency in things like\nits security configurations.\n\n59\n00:02:51.730 --> 00:02:52.610\nAgain, templates,\n\n60\n00:02:52.610 --> 00:02:56.780\nI've kind of made mention of that,\nthings like configuration baselines.\n\n61\n00:02:56.780 --> 00:03:00.410\nIf I know that I'm going to deploy\na server and it's gonna be used for\n\n62\n00:03:00.410 --> 00:03:03.870\na web application deployment,\nthen if we have a template for that,\n\n63\n00:03:03.870 --> 00:03:08.780\nagain we can implement it and\ndeploy it the same way every time.\n\n64\n00:03:08.780 --> 00:03:12.880\nAnd again, with templates and scripts,\nit helps to eliminate things like,\n\n65\n00:03:12.880 --> 00:03:18.090\nif you will, the human side of things\nwhich is typically misconfiguration and\n\n66\n00:03:18.090 --> 00:03:20.080\nit happens especially when\nyou talk about scalability.\n\n67\n00:03:20.080 --> 00:03:22.780\nRight?\nWe talk about large deployments, right.\n\n68\n00:03:22.780 --> 00:03:27.310\nWe're not maybe talking about\njust a couple of servers.\n\n69\n00:03:27.310 --> 00:03:30.315\nRight, it could be deploying\n500 operating systems,\n\n70\n00:03:30.315 --> 00:03:33.830\n1,000 operating systems inside\nof an enterprise level solution.\n\n71\n00:03:33.830 --> 00:03:36.760\nSo, this is where things like\nimages come in to place.\n\n72\n00:03:36.760 --> 00:03:42.850\nAnd an image can almost be considered kind\nof like a template, if you will, right.\n\n73\n00:03:42.850 --> 00:03:48.400\nSometimes they call out a specific type\nof image and again, what you might\n\n74\n00:03:48.400 --> 00:03:52.930\nhave heard about this before but maybe not\nin the context that CompTIA's putting it.\n\n75\n00:03:52.930 --> 00:03:55.060\nThey call it a master image, right.\n\n76\n00:03:55.060 --> 00:03:59.450\nYou might, if you're doing research,\nyou might hear the term golden image.\n\n77\n00:03:59.450 --> 00:04:01.110\nAnd, again, just kinda use anonymously.\n\n78\n00:04:01.110 --> 00:04:02.250\nSo what is a master image?\n\n79\n00:04:02.250 --> 00:04:06.543\nWell, I want you to think about the time\nthat it takes, right, in the context of\n\n80\n00:04:06.543 --> 00:04:11.820\nautomation, right, the time that it takes\nto install an operating system, all right.\n\n81\n00:04:11.820 --> 00:04:17.880\nInstall, configure the operating system\npost installation configurations, right.\n\n82\n00:04:17.880 --> 00:04:22.540\nAs well as what does it take\nto deploy the applications.\n\n83\n00:04:22.540 --> 00:04:24.230\nInstall the applications,\n\n84\n00:04:24.230 --> 00:04:28.420\nrun the updates to the entire machine\nall its application and to configure it.\n\n85\n00:04:28.420 --> 00:04:31.220\nAnd now we've got an operating\nsystem on one system,\n\n86\n00:04:31.220 --> 00:04:35.720\none machine within our networks that's\nready for your end user to sit down.\n\n87\n00:04:35.720 --> 00:04:37.680\nWouldn't it be better\nif you take a snapshot,\n\n88\n00:04:37.680 --> 00:04:42.320\nyou capture that image in its state,\nand it produces a file that is put on\n\n89\n00:04:42.320 --> 00:04:47.590\na deployment server that you can now\ndeploy out hundred of computers, right?.\n\n90\n00:04:47.590 --> 00:04:49.830\nAnd when they receive\ntheir operating system, or\n\n91\n00:04:49.830 --> 00:04:54.140\ntheir image, it is ready to go, just like\nit would be in a production environment.\n\n92\n00:04:54.140 --> 00:04:56.800\nAnd that is where things like your\nmaster images come into place.\n\n93\n00:04:56.800 --> 00:04:59.120\nNow, does it mean there is gonna\nbe one master image, right?.\n\n94\n00:04:59.120 --> 00:05:00.970\nThere could be multiple of master images.\n\n95\n00:05:00.970 --> 00:05:02.360\nYou well say wait a second here,\nwhat do you mean?.\n\n96\n00:05:02.360 --> 00:05:03.460\nMultiple master images,\n\n97\n00:05:03.460 --> 00:05:07.370\nwell, again the way I deploy the server\nis not I deploy a workstation.\n\n98\n00:05:07.370 --> 00:05:09.360\nSo I can have a master image for\nif you will.\n\n99\n00:05:09.360 --> 00:05:15.900\nLet's say the marketing team has access\nto some productivity application, right?\n\n100\n00:05:15.900 --> 00:05:18.260\nVersus if I'm deploying a server.\n\n101\n00:05:18.260 --> 00:05:21.810\nIf you are deploying a server,\nyou might have a master image for\n\n102\n00:05:21.810 --> 00:05:22.740\nyour servers, right?\n\n103\n00:05:22.740 --> 00:05:26.190\nAnd then may be even different types of\nservers and you can use things like WDS,\n\n104\n00:05:26.190 --> 00:05:29.690\nif you will Windows deployment services\nwhere you can push that out and\n\n105\n00:05:29.690 --> 00:05:31.750\nagain ensure that consistency.\n\n106\n00:05:31.750 --> 00:05:36.820\nThe other thing,\nwhen it comes to having master images,\n\n107\n00:05:36.820 --> 00:05:39.950\nwe talk about to reduce risk, all right?\n\n108\n00:05:39.950 --> 00:05:42.320\nI want you to think of updates, right?\n\n109\n00:05:42.320 --> 00:05:44.580\nI have patch management, right?\n\n110\n00:05:44.580 --> 00:05:47.696\nWe can do centralized patch\nmanagement in a single location and\n\n111\n00:05:47.696 --> 00:05:50.106\nthen just deploy that to\nour operating systems,\n\n112\n00:05:50.106 --> 00:05:54.120\nrather than have to do sneaker net and\ngo to each individual machine doing this.\n\n113\n00:05:54.120 --> 00:05:57.080\nThey start with configuration.\n\n114\n00:05:57.080 --> 00:06:00.870\nWe can make sure that the master\nimage is in a secure state, right,\n\n115\n00:06:00.870 --> 00:06:04.740\nwhen it comes to its configurations\nlet alone consistency.\n\n116\n00:06:04.740 --> 00:06:06.170\nAll right.\n\n117\n00:06:06.170 --> 00:06:10.655\nImages can also be non-persistent as well,\nif we talk about deploying them to\n\n118\n00:06:10.655 --> 00:06:13.305\nthe local hard drives at\nthe machine as a persistent image,\n\n119\n00:06:13.305 --> 00:06:16.445\nit means it's just like any other\noperating system that's installed.\n\n120\n00:06:16.445 --> 00:06:18.675\nBut you could have non-persistent images,\nright?\n\n121\n00:06:18.675 --> 00:06:21.565\nIf you're in something like\na virtual desktop infrastructure,\n\n122\n00:06:21.565 --> 00:06:24.222\nwhere the people connect\nto centralized server.\n\n123\n00:06:24.222 --> 00:06:27.440\nAnd they pull that desktop to whatever\nthere devices while it's running on\n\n124\n00:06:27.440 --> 00:06:28.660\nthe server, right?\n\n125\n00:06:28.660 --> 00:06:30.585\nAnd you can have a non-persistent image,\nright,\n\n126\n00:06:30.585 --> 00:06:33.990\nnon-persistent virtual desktop\ninfrastructure that means when I log in,\n\n127\n00:06:33.990 --> 00:06:38.300\nI can make all the changes and all,\ndo whatever I want to do, right.\n\n128\n00:06:39.330 --> 00:06:42.720\nFirst of all, when I save my information,\nit isn't gonna be saved on that locations,\n\n129\n00:06:42.720 --> 00:06:45.620\nprobably gonna be save on a file\nserver on the backend that maybe users\n\n130\n00:06:45.620 --> 00:06:47.639\naren't aware of, but\nwhen they log out on that machine,\n\n131\n00:06:48.950 --> 00:06:52.120\nit resets itself the next\ntime they connect, right.\n\n132\n00:06:52.120 --> 00:06:55.860\nSo, again, you get a consistency\nin the fact that you don't have to\n\n133\n00:06:55.860 --> 00:06:59.980\nworry about somebody configures this\ndesktop this way, it hosts up the system,\n\n134\n00:06:59.980 --> 00:07:03.050\nsomeone configures this one this way,\nit hosts up the system, the next time they\n\n135\n00:07:03.050 --> 00:07:06.450\nlog in, now you've got security\nvulnerabilities within your networks.\n\n136\n00:07:06.450 --> 00:07:10.540\nWouldn't it be nice the moment they're\ndone with that environment, they log out,\n\n137\n00:07:10.540 --> 00:07:14.960\neverything resets itself back to that\nmaster image in that secure configuration.\n\n138\n00:07:14.960 --> 00:07:18.970\nSo there is benefits to non-persistence\nwhen it comes to these images as well.\n\n139\n00:07:18.970 --> 00:07:23.570\n&gt;&gt; Yeah, we actually, a company I work for\ndeployed this into our in-office users,\n\n140\n00:07:23.570 --> 00:07:25.325\nnot our satellite users.\n\n141\n00:07:25.325 --> 00:07:30.020\nBut our in-office users because they would\ntypically get, my computer stop working\n\n142\n00:07:30.020 --> 00:07:33.480\nand it was super easy to just tell\nher help us, just tell him to reboot.\n\n143\n00:07:33.480 --> 00:07:34.250\nIf they rebooted?\n\n144\n00:07:34.250 --> 00:07:36.290\nWhat they get,\nthey got that non-persistent image.\n\n145\n00:07:36.290 --> 00:07:40.040\nIt was that clean cookie\ncolor just how they need it.\n\n146\n00:07:40.040 --> 00:07:43.690\nSo anything that they did, maybe they\neven downloaded the worst virus, or\n\n147\n00:07:43.690 --> 00:07:47.430\ncrazy bill or encrypted out with\nransomware, doesn't matter.\n\n148\n00:07:47.430 --> 00:07:52.235\nRestart, they get a brand newly built\nimage login everything is fine.\n\n149\n00:07:52.235 --> 00:07:54.774\n&gt;&gt; Definitely and yeah that's some\nof the things they call out to and\n\n150\n00:07:54.774 --> 00:07:57.234\nthis objectives when we're\ntalking about non-persistent.\n\n151\n00:07:57.234 --> 00:08:02.214\nDan mentioned how everything\ngoes back to a previous state.\n\n152\n00:08:02.214 --> 00:08:04.530\nThat is actually called a known state,\nright?\n\n153\n00:08:04.530 --> 00:08:07.220\nYou're rolling back to\na previously known state, and\n\n154\n00:08:07.220 --> 00:08:11.000\nthat could be your secure\nconfiguration baseline, right?\n\n155\n00:08:11.000 --> 00:08:12.463\nI don't have to worry about the viruses,\nright?\n\n156\n00:08:12.463 --> 00:08:16.437\nBecause of the fact that, again\nthe Operating System always rolls back,\n\n157\n00:08:16.437 --> 00:08:17.200\nif you will.\n\n158\n00:08:17.200 --> 00:08:19.584\nRolling back to back to\na known configuration, or\n\n159\n00:08:19.584 --> 00:08:22.671\nreverting back to a known\nconfiguration status, known state.\n\n160\n00:08:22.671 --> 00:08:26.833\nFor instance, let me give you an example\nof maybe a situation where we're using\n\n161\n00:08:26.833 --> 00:08:27.960\nthis individually.\n\n162\n00:08:27.960 --> 00:08:30.820\nIt could be something like\nSystem Restore inside of Windows, right?\n\n163\n00:08:30.820 --> 00:08:35.041\nWe use that because, as we go through our\nlife cycle, we're installing drivers,\n\n164\n00:08:35.041 --> 00:08:38.200\nwe're installing updates,\ninstalling software, right?\n\n165\n00:08:38.200 --> 00:08:41.761\nWe really should be doing this in\na centralized environment, but\n\n166\n00:08:41.761 --> 00:08:44.418\nif we're using something\nlike System Restore,\n\n167\n00:08:44.418 --> 00:08:48.499\nthat is using things like volume shadow\ncopy service that could make a point\n\n168\n00:08:48.499 --> 00:08:51.699\nin time snapshot of the machine's\nconfiguration state.\n\n169\n00:08:51.699 --> 00:08:55.680\nThen if something goes wrong with that, we\ncan always roll back to that known state.\n\n170\n00:08:55.680 --> 00:08:59.950\nAnd then hopefully that help us to,\nensure that our end users maintain there\n\n171\n00:08:59.950 --> 00:09:03.560\nproductivity and availability of\nthe data that they need to work with, so\n\n172\n00:09:03.560 --> 00:09:05.940\nthat our company is successful.\n\n173\n00:09:05.940 --> 00:09:09.672\nSnap Shots they do mention, most of the\npeople that I've talk to that have work\n\n174\n00:09:09.672 --> 00:09:13.579\nwith things like Virtualization platform,\nSnapshots aren't really something\n\n175\n00:09:13.579 --> 00:09:17.600\nthat you're gonna use in a production\nenvironment, it just gets.\n\n176\n00:09:17.600 --> 00:09:21.364\nNow I know they have, they kinda say\nthat there is a live snapshots today in\n\n177\n00:09:21.364 --> 00:09:25.613\nWindows Server, but for the most part,\nsnapshots are great to reduce risk because\n\n178\n00:09:25.613 --> 00:09:28.058\nthey allow you a testing environment,\nright?\n\n179\n00:09:28.058 --> 00:09:31.606\nI could test an application and\nif the application hoses up, the current\n\n180\n00:09:31.606 --> 00:09:35.750\nenvironment that I'm in, just roll it back\nto the snapshot and we could start over.\n\n181\n00:09:35.750 --> 00:09:39.204\nI know I've done a lot a lot right\nhere at ITProTV when we're in\n\n182\n00:09:39.204 --> 00:09:42.670\nthe middle of making some kind\nof demonstration for you guys.\n\n183\n00:09:42.670 --> 00:09:45.227\nDan, I'm sure you probably\nused that a lot in things like\n\n184\n00:09:45.227 --> 00:09:47.634\nyour offensive security training,\nnot offensive.\n\n185\n00:09:47.634 --> 00:09:52.186\nOffensive [LAUGH] security training where\nyou're trying these techniques over, and\n\n186\n00:09:52.186 --> 00:09:54.980\nover, and over, and\nyou miss that one little step.\n\n187\n00:09:54.980 --> 00:09:57.570\nAnd it's like, man,\ndo I really have to go back and\n\n188\n00:09:57.570 --> 00:10:00.190\nundo everything I did to\nget back to where I was?\n\n189\n00:10:00.190 --> 00:10:01.336\nWe could just revert the snapshot.\n\n190\n00:10:01.336 --> 00:10:04.347\n&gt;&gt; Yeah, it's also great for\napplying updates on servers.\n\n191\n00:10:04.347 --> 00:10:07.580\nAnd I don't mean specific like\nWindows update, I mean more like,\n\n192\n00:10:07.580 --> 00:10:10.810\nI have some line of business\nsoftware that runs on a server.\n\n193\n00:10:10.810 --> 00:10:14.180\nI need to do a, [COUGH] excuse me,\nmajor upgrade on that.\n\n194\n00:10:14.180 --> 00:10:17.210\nI can take a snapshot of the machine,\ntry my major upgrade.\n\n195\n00:10:17.210 --> 00:10:20.410\nIf it fails, or\ngoes crazy on me in any way shape or\n\n196\n00:10:20.410 --> 00:10:22.980\nform, just roll back to there, and\nthen I can contact the vendor.\n\n197\n00:10:22.980 --> 00:10:25.790\nWe can schedule another update\ntime attempt to do it again.\n\n198\n00:10:25.790 --> 00:10:28.180\nThose snapshots really help\nout with that kind of thing.\n\n199\n00:10:28.180 --> 00:10:32.690\n&gt;&gt; It definitely, and that lends itself\nto resiliency and redundancy, right?\n\n200\n00:10:32.690 --> 00:10:35.414\n&gt;&gt; Right.\n&gt;&gt; You need to make sure that you can\n\n201\n00:10:35.414 --> 00:10:38.410\nwithstand something like that.\n\n202\n00:10:38.410 --> 00:10:40.520\nNow here's another one that I really like.\n\n203\n00:10:40.520 --> 00:10:44.970\nI've joked around in the past, I say what\ndo you call the Windows recovery disk?\n\n204\n00:10:44.970 --> 00:10:47.790\nLinux Live CD, but Live Boot Media,\nthey talk about that.\n\n205\n00:10:47.790 --> 00:10:52.183\nWhy would Live Boot Media be something\nthat you would be interested in\n\n206\n00:10:52.183 --> 00:10:54.615\nwhen we talk about non-persistent?\n\n207\n00:10:54.615 --> 00:10:57.122\nWell, I want you to think about,\n\n208\n00:10:57.122 --> 00:11:02.380\nif you have a machine that multiple\nend users are utilizing, right?\n\n209\n00:11:02.380 --> 00:11:05.473\nWell wouldn't it be nice to just\nput it in Live Boot Media, and\n\n210\n00:11:05.473 --> 00:11:08.396\nnothing is persistent,\nnothing stays on that computer?\n\n211\n00:11:08.396 --> 00:11:11.662\nAnd you can actually have multiple\nusers using a physical machine, and\n\n212\n00:11:11.662 --> 00:11:14.120\nthey all have their own\nunique environment, right?\n\n213\n00:11:14.120 --> 00:11:17.811\nSo that's one of the great things right,\nthey're memory resonant Operating System.\n\n214\n00:11:17.811 --> 00:11:20.650\nWhich means, if I pull the power or\nshut them down like I should be,\n\n215\n00:11:20.650 --> 00:11:23.672\nthen that Operating System isn't\ninstalled on the local hard drive.\n\n216\n00:11:23.672 --> 00:11:27.543\nAnd this is a good thing, because you\ncould do things like encryption on\n\n217\n00:11:27.543 --> 00:11:29.358\nthe local hard drive if you will.\n\n218\n00:11:29.358 --> 00:11:32.580\nMaybe partition a section off or\nthe other part is encrypted.\n\n219\n00:11:32.580 --> 00:11:35.430\nAnd you can allow multiple users\nto use a single system without\n\n220\n00:11:35.430 --> 00:11:36.950\ninterfering with others.\n\n221\n00:11:36.950 --> 00:11:40.540\nCuz there really isn't a requirement\nto install the Operating System on\n\n222\n00:11:40.540 --> 00:11:41.790\nthe local media.\n\n223\n00:11:41.790 --> 00:11:45.808\nHow about this, Dan was talking about\ntesting out updates with snapshots.\n\n224\n00:11:45.808 --> 00:11:48.380\nHow about testing an Operating System,\nright?\n\n225\n00:11:48.380 --> 00:11:51.600\nMaybe you're gonna roll out some something\nlike your CentOS in your environments.\n\n226\n00:11:51.600 --> 00:11:53.460\nI know that a lot of times\nthey roll out Red Hat, but\n\n227\n00:11:53.460 --> 00:11:56.030\nmaybe you're gonna roll out CentOS, right?\n\n228\n00:11:56.030 --> 00:11:56.710\nIs it good?\n\n229\n00:11:56.710 --> 00:11:59.903\nI don't know.\nWell wouldn't it be nice to use the CentOS\n\n230\n00:11:59.903 --> 00:12:04.859\nlive boot CD or media USB device, so\nthat I can test the Operating System and\n\n231\n00:12:04.859 --> 00:12:06.132\nfind out, right?\n\n232\n00:12:06.132 --> 00:12:09.650\nIs it gonna give me the functionality\nI need, without overriding anything on\n\n233\n00:12:09.650 --> 00:12:12.240\nthe local drive, and more so\nwithout having to install it?\n\n234\n00:12:12.240 --> 00:12:15.732\nSo it's a great way that hey,\nI don't like what I see here.\n\n235\n00:12:15.732 --> 00:12:16.850\nWell shut the machine off.\n\n236\n00:12:16.850 --> 00:12:20.480\nThat's fine, because you can always\ntest another Operating System.\n\n237\n00:12:20.480 --> 00:12:24.673\nAnd again, allowing users to work with\na computer that is not their own,\n\n238\n00:12:24.673 --> 00:12:29.236\nwhile protecting the data that is stored\non the local hard drive, if you will.\n\n239\n00:12:29.236 --> 00:12:31.830\n&gt;&gt; I'm surprised here that they don't call\nus something like cloud infrastructure.\n\n240\n00:12:31.830 --> 00:12:35.340\nBecause its kind of the same idea\nwhere it can be use in the same way,\n\n241\n00:12:35.340 --> 00:12:36.370\nas something like a live feed.\n\n242\n00:12:36.370 --> 00:12:40.550\nIt's not non persistence, yeah, it persist\nuntil I delete it and create a new one.\n\n243\n00:12:40.550 --> 00:12:43.324\nBecause I have the ability to do\nthat in the Cloud is very nice.\n\n244\n00:12:43.324 --> 00:12:46.351\nYes, I'll take a Windows Server\nwith doing this and that.\n\n245\n00:12:46.351 --> 00:12:51.030\nIn this type of an environment, and\nit's easy to build this spin right up.\n\n246\n00:12:51.030 --> 00:12:54.035\nI test things to make sure it works,\nand if I like it I can keep it,\n\n247\n00:12:54.035 --> 00:12:56.116\nif not I blow it away and\ntry something else.\n\n248\n00:12:56.116 --> 00:12:58.490\n&gt;&gt; And absolutely, that's where\nyour templates come in handy too.\n\n249\n00:12:58.490 --> 00:13:02.360\nEspecially at a Cloud-based solution\nwhere you're like, I wanna Linux Box.\n\n250\n00:13:02.360 --> 00:13:04.140\nI need a LAMP server, right?\n\n251\n00:13:04.140 --> 00:13:05.840\n&gt;&gt; Yeah.\n&gt;&gt; Now I've got everything ready there.\n\n252\n00:13:05.840 --> 00:13:08.030\nI don't have to sit there, install Linux.\n\n253\n00:13:08.030 --> 00:13:10.930\nI don't have to install Apache,\nI don't have to install mySQL.\n\n254\n00:13:10.930 --> 00:13:13.850\nLike php is the last\none in LAMP I believe?\n\n255\n00:13:13.850 --> 00:13:16.250\n&gt;&gt; Python.\n&gt;&gt; Perl, it used to be Perl right.\n\n256\n00:13:16.250 --> 00:13:18.220\n&gt;&gt; Now it's Python I think.\n\n257\n00:13:18.220 --> 00:13:20.930\n&gt;&gt; Now we get the whole entire\nenvironment and we can use a template.\n\n258\n00:13:20.930 --> 00:13:23.850\nAnd it makes it It's a lot easier and\nthen couple that with Snap shots.\n\n259\n00:13:23.850 --> 00:13:27.302\nOne of the last thing that you do wanna\nmention that, I though was really,\n\n260\n00:13:27.302 --> 00:13:30.660\nreally interesting in doing some\nstudying when it comes to live CD's.\n\n261\n00:13:30.660 --> 00:13:34.150\nHow about a recovery situation with\nthe host Operating System all boot.\n\n262\n00:13:34.150 --> 00:13:37.490\nBut, you've got important data on that\nmachine that you have to get access to.\n\n263\n00:13:37.490 --> 00:13:41.730\nNow, you should be storing not locally,\nyou should be storing across the network\n\n264\n00:13:41.730 --> 00:13:44.480\non some kind of file server,\nbut what if it happens right?\n\n265\n00:13:44.480 --> 00:13:46.560\nLinux or just Live.\n\n266\n00:13:46.560 --> 00:13:49.660\nI know I keep I saying Linux Live CD,\nall types of them out there, but\n\n267\n00:13:49.660 --> 00:13:52.360\na lot of them are based off of Linux,\nright?\n\n268\n00:13:52.360 --> 00:13:55.450\nCan I can gain access to\ninformation on a drive.\n\n269\n00:13:55.450 --> 00:13:56.680\nBut that's not the only one,\n\n270\n00:13:56.680 --> 00:14:00.140\nright, I would be hard-pressed if\nI didn't mention things like WinP.\n\n271\n00:14:00.140 --> 00:14:03.310\nWinP is another disc that\nallows you memory resonance,\n\n272\n00:14:03.310 --> 00:14:07.020\nvery small footprints I doubt it,\nI don't think it does use.\n\n273\n00:14:07.020 --> 00:14:10.640\nThat might be it and\nwhat's the PE part of that?\n\n274\n00:14:10.640 --> 00:14:12.880\nWe call it the pre-installation\nenvironment, right?\n\n275\n00:14:12.880 --> 00:14:15.150\nIt's not installed, it's in memory.\n\n276\n00:14:15.150 --> 00:14:16.599\nNow Dan mentioned Cloud.\n\n277\n00:14:16.599 --> 00:14:18.640\nI'm surprised they don't mention Cloud.\n\n278\n00:14:18.640 --> 00:14:23.021\nWell, here comes a couple of topics\nthat are right up, right in the Cloud.\n\n279\n00:14:23.021 --> 00:14:25.150\nRight, elasticity, right?\n\n280\n00:14:25.150 --> 00:14:28.190\nThere's a couple of things that they\ncall elasticity and scalability, but\n\n281\n00:14:28.190 --> 00:14:31.350\nwe have to be careful with them.\n\n282\n00:14:31.350 --> 00:14:34.710\nLet me go ahead, and I'm gonna kinda do\nthis a little out of order on you, Dan.\n\n283\n00:14:34.710 --> 00:14:36.730\nI'm gonna do scalability first, right?\n\n284\n00:14:36.730 --> 00:14:39.830\nBecause I want you to see that there is\na little bit of a difference here, right?\n\n285\n00:14:39.830 --> 00:14:44.620\nScalability allows an organization\nto grow, to increase workloads,\n\n286\n00:14:44.620 --> 00:14:46.560\nwhen the demands are needed, right?\n\n287\n00:14:48.520 --> 00:14:51.160\nHowever, right, there's a problem, right.\n\n288\n00:14:51.160 --> 00:14:56.020\nScalability by itself cannot reduce\nthe risk of over provisioning, right.\n\n289\n00:14:56.020 --> 00:14:57.480\nI want you to think about this.\n\n290\n00:14:57.480 --> 00:15:01.160\nIf I buy a server, because we know\nBlack Friday is coming up, right, and\n\n291\n00:15:01.160 --> 00:15:03.240\nthere's gonna be a lot of\npeople hitting our website.\n\n292\n00:15:03.240 --> 00:15:04.429\nSo we plan for it, right.\n\n293\n00:15:05.540 --> 00:15:06.850\nAnd we scale out.\n\n294\n00:15:06.850 --> 00:15:08.350\nAnd I'll talk about\nthe two different types.\n\n295\n00:15:08.350 --> 00:15:09.590\nScale out and scale up.\n\n296\n00:15:09.590 --> 00:15:13.070\nScale out says that we add\nan additional device, so\n\n297\n00:15:13.070 --> 00:15:18.280\nthat when the increased workloads happen,\nwe've got more than one device, right?\n\n298\n00:15:18.280 --> 00:15:22.410\nTo do things like load balancing\nif you will, redundancy.\n\n299\n00:15:22.410 --> 00:15:27.747\nBut the problem is, what happens\nnow Black Friday's come and gone?\n\n300\n00:15:27.747 --> 00:15:30.878\nScalability lends itself to\nover-provisioning, because now you have\n\n301\n00:15:30.878 --> 00:15:33.865\na cost of a server that maybe is not\njustified for the rest of the year.\n\n302\n00:15:33.865 --> 00:15:36.809\nSo scalability is great, right, but\n\n303\n00:15:36.809 --> 00:15:42.336\nagain you could eat the cost of\nwhatever it is that you're scaling out.\n\n304\n00:15:42.336 --> 00:15:45.035\nScaling up is another one.\n\n305\n00:15:45.035 --> 00:15:47.258\nScaling vertically or\nhorizontally if you will.\n\n306\n00:15:47.258 --> 00:15:53.407\nAgain scaling vertically means maybe one\nmachine isn't performing adequately,\n\n307\n00:15:53.407 --> 00:15:58.336\nso I drop a few more CPUs in it,\nright, or I drop a RAM in it, right.\n\n308\n00:15:58.336 --> 00:16:03.145\nBut see Scalability again, it can lead\nto a little bit of downtime potentially,\n\n309\n00:16:03.145 --> 00:16:07.178\nand that's where things like cloud\nbased elasticity comes in, and\n\n310\n00:16:07.178 --> 00:16:11.777\nthat's why I wanted to talk about\nscalability first because elasticity does\n\n311\n00:16:11.777 --> 00:16:13.710\nallow you to scale, all right?\n\n312\n00:16:13.710 --> 00:16:15.140\nBut there's a difference.\n\n313\n00:16:15.140 --> 00:16:19.040\nScalability is not necessarily on demand\nand it does lead itself to a potential of\n\n314\n00:16:19.040 --> 00:16:22.705\nover provisioning elasticity\non the other hand, right?\n\n315\n00:16:22.705 --> 00:16:25.350\nThis allows a company to scale out or\n\n316\n00:16:25.350 --> 00:16:29.400\nup if you will when there's\nincrease demand for resources.\n\n317\n00:16:29.400 --> 00:16:31.390\nSo what's the difference, right?\n\n318\n00:16:31.390 --> 00:16:32.670\nOn demand, right.\n\n319\n00:16:32.670 --> 00:16:36.760\nAnd the other thing is it reduces\nthe risk of over provisioning, right?\n\n320\n00:16:36.760 --> 00:16:41.010\nBecause we can deprovision fast, we can\nprovision on our servers, we can say,\n\n321\n00:16:41.010 --> 00:16:44.415\nokay just they Dan mentioned,\nI need a server in the cloud, right?\n\n322\n00:16:44.415 --> 00:16:46.490\nSpin it up, it's ready to go.\n\n323\n00:16:46.490 --> 00:16:49.840\nBut what happens when it's not,\nit isn't necessary anymore?\n\n324\n00:16:49.840 --> 00:16:52.450\nWell, that's okay, we just deprovision and\nbring it back offline and\n\n325\n00:16:52.450 --> 00:16:53.670\nnow we don't have to eat the cost.\n\n326\n00:16:53.670 --> 00:16:56.710\nI eat the cost that time\nbecause I need the resources.\n\n327\n00:16:56.710 --> 00:16:59.410\nAnd that's one of the benefits\nof elasticity, right?\n\n328\n00:16:59.410 --> 00:17:00.560\nWe scale out, right?\n\n329\n00:17:00.560 --> 00:17:04.800\nLike a rubber band, we stretch it out but\nthen when we don't need it anymore.\n\n330\n00:17:04.800 --> 00:17:07.490\nWe let it stretch back to\nit's original size, right?\n\n331\n00:17:07.490 --> 00:17:11.600\nSo again, it allows for\nrapid deprovisioning as well.\n\n332\n00:17:11.600 --> 00:17:15.460\nAnd that can save you cost when those\nresources are no longer necessary.\n\n333\n00:17:15.460 --> 00:17:19.210\nIt also reduces the risk\nof unavailability, right?\n\n334\n00:17:19.210 --> 00:17:22.070\nIf we know that a time frame is\ncoming up where there's gonna be\n\n335\n00:17:22.070 --> 00:17:25.430\na lot of resources that are necessary\non the back end, maybe our database,\n\n336\n00:17:25.430 --> 00:17:28.630\nmaybe our web application server,\nwe can plan for that.\n\n337\n00:17:28.630 --> 00:17:31.500\nAnd we can have the on demand\nnature that says okay,\n\n338\n00:17:31.500 --> 00:17:33.020\nwe're starting to monitor this, right.\n\n339\n00:17:33.020 --> 00:17:34.942\nContinuous monitoring,\nwe're starting to monitor this,\n\n340\n00:17:34.942 --> 00:17:37.870\nwe're starting to see that\nthe workload that we have right now is\n\n341\n00:17:37.870 --> 00:17:41.590\na little bit more than those\nresources that we have.\n\n342\n00:17:41.590 --> 00:17:44.050\nAgain, we can meet those\nresources when we need to.\n\n343\n00:17:45.530 --> 00:17:48.520\nAll right let's see what\nelse do we got there Dan?\n\n344\n00:17:48.520 --> 00:17:52.530\nThey also talk about redundancy and\ntwo concepts redundancy and\n\n345\n00:17:52.530 --> 00:17:57.050\nfull tolerance, while closely\nrelated they are not the same,\n\n346\n00:17:57.050 --> 00:18:00.645\nredundancy is what allows us to\nachieve full tolerance, all right.\n\n347\n00:18:00.645 --> 00:18:02.615\nRedundancy is having more than one right.\n\n348\n00:18:02.615 --> 00:18:04.535\nRedundancy could be done for\na couple of reasons.\n\n349\n00:18:04.535 --> 00:18:08.225\nIt could be to distribute workloads,\nright?\n\n350\n00:18:08.225 --> 00:18:12.651\nAgain, you could have things like network\nload balancers, but redundancy can also\n\n351\n00:18:12.651 --> 00:18:16.270\nreduce the risk of a total loss of\navailability there's a failure.\n\n352\n00:18:16.270 --> 00:18:19.910\nSo again for\ntolerance again is being able to\n\n353\n00:18:21.550 --> 00:18:25.650\nmaintain access to resources when there's\nsome kind of foreseeable failure, right?\n\n354\n00:18:25.650 --> 00:18:27.580\nIt's not a matter of if\nthings things are gonna fail,\n\n355\n00:18:27.580 --> 00:18:29.800\nit's just a matter of when they fail,\nright?\n\n356\n00:18:29.800 --> 00:18:33.560\nSo keep in mind,\nredundancy is more than one device.\n\n357\n00:18:33.560 --> 00:18:37.070\nIt becomes fault tolerant when\nyou implement the redundancy.\n\n358\n00:18:38.460 --> 00:18:39.710\nNow, what else do we have?\n\n359\n00:18:39.710 --> 00:18:43.360\nWe have high availability and high\navailability is an interesting concept.\n\n360\n00:18:43.360 --> 00:18:49.098\nHigh availability actually is kind of\nlike a metric if you will that denotes\n\n361\n00:18:49.098 --> 00:18:54.849\nhow close we get to 100% up time and\nthere are different measurements.\n\n362\n00:18:54.849 --> 00:18:59.090\nIt really just depends on things like\nyour SLAs, service level agreement.\n\n363\n00:18:59.090 --> 00:19:02.520\nSo if you take something like a cloud\nprovider, right you need high\n\n364\n00:19:02.520 --> 00:19:05.720\navailability, well what is\nthe availability that they are giving you?\n\n365\n00:19:05.720 --> 00:19:09.150\nSometimes they say, you know maybe\nits Gonna be two nines, right?\n\n366\n00:19:09.150 --> 00:19:10.610\nWell, what do we mean by that?\n\n367\n00:19:10.610 --> 00:19:14.070\nGot a little chart right here kinda\nshows you some of these numbers, right?\n\n368\n00:19:15.190 --> 00:19:17.780\nAnd I don't want you to memorize\nall these numbers for the exam, but\n\n369\n00:19:17.780 --> 00:19:21.450\nunderstand the terms,\nthe concepts behind high availability.\n\n370\n00:19:21.450 --> 00:19:26.057\nAgain high availability is based on\nthe concept of how close do we get to 100%\n\n371\n00:19:26.057 --> 00:19:26.621\nup time.\n\n372\n00:19:26.621 --> 00:19:30.360\nCould you achieve 100% up time?\n\n373\n00:19:30.360 --> 00:19:32.860\nSure is you got $5 to 6\nmillions to throw for\n\n374\n00:19:32.860 --> 00:19:36.780\nwherever your project is maybe\nyou could make to 100% up time.\n\n375\n00:19:36.780 --> 00:19:41.639\nThe cost again is so great to get\nthat it's just not realistic, right.\n\n376\n00:19:41.639 --> 00:19:45.403\nSo they give you charts like this and\nif you attention to the SLA and\n\n377\n00:19:45.403 --> 00:19:49.372\nyou can see when we started going up\nin the level of nines that we have,\n\n378\n00:19:49.372 --> 00:19:53.910\naccess to the data, downtime if you will,\nstarts to greatly reduce, right?\n\n379\n00:19:53.910 --> 00:19:59.030\nSo if we say hey 99% of the time,\nyou're gonna have access to your data.\n\n380\n00:19:59.030 --> 00:20:04.160\nWell that does mean that 3.65 days out of\nthe year, you wont have access, right?\n\n381\n00:20:04.160 --> 00:20:06.830\nAnd that's not really a good\navailability if you will,\n\n382\n00:20:06.830 --> 00:20:08.950\nif you think about three days,\nthree and a half days.\n\n383\n00:20:08.950 --> 00:20:12.770\nSo as we start to creep up here,\nthere are whole bunch of them and\n\n384\n00:20:12.770 --> 00:20:14.220\nI just happened to put\nsome of them in here.\n\n385\n00:20:14.220 --> 00:20:16.530\nYou might see things like, 99.9.\n\n386\n00:20:16.530 --> 00:20:20.760\n5%, these are just keeping it\nstrict with all the nines, right?\n\n387\n00:20:20.760 --> 00:20:21.969\nThree nines if you will,\n\n388\n00:20:21.969 --> 00:20:25.410\nnow you see it goes from three\ndays to eight hours roughly.\n\n389\n00:20:25.410 --> 00:20:29.520\nFour nines,\nnow we're down into just under one hour.\n\n390\n00:20:29.520 --> 00:20:35.146\nAnd then five nines, five nines is about\nthe best you can get when it comes\n\n391\n00:20:35.146 --> 00:20:42.078\nto a 100% up time because that's just over\nfive minutes downtime for an entire year.\n\n392\n00:20:42.078 --> 00:20:46.563\nAnd when you look at it you're only\ntalking about 6.05 seconds per week,\n\n393\n00:20:46.563 --> 00:20:50.496\nseconds, right, so it might be\nsomething that you don't notice,\n\n394\n00:20:50.496 --> 00:20:52.570\nit could be something that you do.\n\n395\n00:20:52.570 --> 00:20:55.780\nAnd this more than anything, and that's\nwhy I kinda highlighted this one, this is\n\n396\n00:20:55.780 --> 00:20:58.580\nthe one that I want you to remember,\nthe five nines availability right,\n\n397\n00:20:58.580 --> 00:21:03.430\nit gives you right around five\nminutes downtime in the entire year.\n\n398\n00:21:03.430 --> 00:21:06.290\nAnd you can say once you\nget up to six nines,\n\n399\n00:21:06.290 --> 00:21:09.860\nthat's pretty impressive,\n31.5 seconds per year.\n\n400\n00:21:09.860 --> 00:21:12.940\nNow we're talking in\nmilliseconds per week.\n\n401\n00:21:12.940 --> 00:21:15.110\nSo almost instantaneous failover,\n\n402\n00:21:15.110 --> 00:21:18.140\nsomething that you would probably\nwouldn't even notice on the back end.\n\n403\n00:21:18.140 --> 00:21:24.120\nBut again, the expense behind that and\nthe redundancy and fault tolerance\n\n404\n00:21:24.120 --> 00:21:29.200\nthat you need to achieve that means that\nthe cost is through the roof, right?\n\n405\n00:21:29.200 --> 00:21:33.370\nThat means now we have redundancy\nif you will on our storage devices,\n\n406\n00:21:33.370 --> 00:21:37.480\nour network devices like routers and\nswitches, the routes, right?\n\n407\n00:21:37.480 --> 00:21:42.098\nThrough autonomous systems, network\nload balancers, firewalls if you will,\n\n408\n00:21:42.098 --> 00:21:45.110\nour cabling and connections,\nmultiple redundant connections.\n\n409\n00:21:45.110 --> 00:21:49.610\nIn case one fiber optic link goes down,\nwe've got a back up that is already there,\n\n410\n00:21:49.610 --> 00:21:50.950\nready to go.\n\n411\n00:21:50.950 --> 00:21:53.260\nThings like your access points, right?\n\n412\n00:21:53.260 --> 00:21:54.640\nServices inside, right?\n\n413\n00:21:54.640 --> 00:21:58.400\nNot just the devices themselves, but\nthe services they provide, DNS, right?\n\n414\n00:21:58.400 --> 00:22:00.900\nDNS is a very important\nservice within our network, so\n\n415\n00:22:00.900 --> 00:22:05.485\nmaybe you have redundant DNS servers,\nor redundant DNS providers.\n\n416\n00:22:05.485 --> 00:22:09.295\nI know a lot of the hosts around here\nactually use a couple of different\n\n417\n00:22:09.295 --> 00:22:10.465\nDNS systems, right.\n\n418\n00:22:10.465 --> 00:22:14.957\nThey'll use things like 4.2.2.1 and\n8.8.8.8.\n\n419\n00:22:14.957 --> 00:22:19.075\nWhy, well because they're using\na DNS server in Atlanta versus using\n\n420\n00:22:19.075 --> 00:22:20.925\nGoogle's DNS server.\n\n421\n00:22:20.925 --> 00:22:24.555\nAnd what are the odds that both of\nthose servers are gonna go down at\n\n422\n00:22:24.555 --> 00:22:26.140\nthe same time?\n\n423\n00:22:26.140 --> 00:22:28.760\nWell it can happen, right?\n\n424\n00:22:28.760 --> 00:22:30.510\nIt can happen, but\nit's highly unlikely, and\n\n425\n00:22:30.510 --> 00:22:33.380\nthat's the good thing about\neven having service redundancy.\n\n426\n00:22:33.380 --> 00:22:35.820\nThings like your domain controllers,\nright?\n\n427\n00:22:35.820 --> 00:22:39.730\nIf your users cannot log in that affects\navailability, and productivity, and\n\n428\n00:22:39.730 --> 00:22:43.410\nthat isn't resilient, and\nit certainly could be a major risk.\n\n429\n00:22:44.550 --> 00:22:47.000\nYou might even have multiple\ncloud providers, right?\n\n430\n00:22:47.000 --> 00:22:48.450\nDon't put all your, we joke around,\n\n431\n00:22:48.450 --> 00:22:50.390\ndon't put all your eggs in\nthe same basket, right?\n\n432\n00:22:50.390 --> 00:22:55.390\nMaybe you're using Microsoft Azure\nas well as using AWS, right?\n\n433\n00:22:55.390 --> 00:22:57.630\nSo that if something happens, right?\n\n434\n00:22:57.630 --> 00:22:58.980\nFor anyone reason and\n\n435\n00:22:58.980 --> 00:23:02.510\nAmazon's got one of the biggest if not the\nbiggest the infrastructure in the world.\n\n436\n00:23:02.510 --> 00:23:03.050\n&gt;&gt; It is the biggest.\n\n437\n00:23:03.050 --> 00:23:03.760\n&gt;&gt; Is it the biggest?\n\n438\n00:23:03.760 --> 00:23:08.180\nYeah, thank you So the chances\nare of everything being downs again,\n\n439\n00:23:08.180 --> 00:23:13.430\nnot likely but how close to 100%\navailability do you need to get?\n\n440\n00:23:13.430 --> 00:23:16.090\nAnd again, you can notice that when we\ntalk about these redundancies we're\n\n441\n00:23:16.090 --> 00:23:17.810\ntalking about just throwing\nbuckets of money at it, right?\n\n442\n00:23:17.810 --> 00:23:20.810\nThat can be Can make it available but\nagain it's not always feasible.\n\n443\n00:23:22.050 --> 00:23:24.120\nAll right.\nI know we're kinda coming to the end Dan\n\n444\n00:23:24.120 --> 00:23:27.700\nand one of the last things that\nthey call out here is RAID and\n\n445\n00:23:27.700 --> 00:23:30.160\nRAID we're not talking\nabout bug spray guys.\n\n446\n00:23:30.160 --> 00:23:31.000\nWe're talking about.\n\n447\n00:23:31.000 --> 00:23:32.750\n&gt;&gt; Kills drives dead.\n&gt;&gt; That's right [LAUGH].\n\n448\n00:23:32.750 --> 00:23:37.140\nWe're talking about how we maintain\na redundancy in both tolerance with\n\n449\n00:23:37.140 --> 00:23:39.230\nthe data that is stored\non our drives right?\n\n450\n00:23:40.230 --> 00:23:44.724\nI'd like run through just a couple of\nthem, they call out on the exam, RAID.\n\n451\n00:23:46.295 --> 00:23:48.665\nBut it would be good to know\nthe different types of RAIDs and\n\n452\n00:23:48.665 --> 00:23:49.995\nwhy you might implement them.\n\n453\n00:23:49.995 --> 00:23:51.417\nThe very first one is called RAID 0.\n\n454\n00:23:51.417 --> 00:23:55.225\nUnderstand that RAID is a Redundant Array\nof Independent Disks that\n\n455\n00:23:55.225 --> 00:23:59.567\nused to be called Redundant Array of\nInexpensive Disks Whatever you choose to\n\n456\n00:23:59.567 --> 00:24:01.461\ncall the acronym is fine with me.\n\n457\n00:24:01.461 --> 00:24:04.501\nWith Raid 0, why do they call it 0?\n\n458\n00:24:04.501 --> 00:24:09.452\nOkay, it's because the level 0\nmeans you get no redundancy.\n\n459\n00:24:09.452 --> 00:24:11.620\nSo this is one that it typically done for\nperformance.\n\n460\n00:24:11.620 --> 00:24:14.680\nYou have a read and\nyou have a write speed that increase,\n\n461\n00:24:14.680 --> 00:24:18.380\nbecause of the fact that you\ndo one write to one disk.\n\n462\n00:24:18.380 --> 00:24:21.875\nYou do the second write to the next disk,\nand you keep alternating back and forth.\n\n463\n00:24:21.875 --> 00:24:27.010\nRaid 0 gives you 0 fault tolerance,\nbecause if I lose\n\n464\n00:24:27.010 --> 00:24:31.445\none of these drives, I don't have\naccess to all of my information, okay?\n\n465\n00:24:31.445 --> 00:24:37.225\nAnd that's why they call it Raid level 0,\nso it is important to understand that with\n\n466\n00:24:37.225 --> 00:24:44.985\nthis, that you are not trying to implement\nRaid 0, excuse me, for fault tolerance.\n\n467\n00:24:46.160 --> 00:24:51.900\nIf you need fault tolerance, and\nI might as well say it too, Raid 0 or any\n\n468\n00:24:51.900 --> 00:24:55.140\nof these require a minimum of two disks,\nwe have to make sure that we mention that.\n\n469\n00:24:56.180 --> 00:24:59.733\nNow the first level of redundancy\nyou get is what's known as RAID 1.\n\n470\n00:24:59.733 --> 00:25:01.298\nThis is called mirroring, all right?\n\n471\n00:25:01.298 --> 00:25:05.351\nRaid 1 with, or mirroring if you will.\n\n472\n00:25:05.351 --> 00:25:10.385\nNow mirroring, you take storage capacity\nhit in this, because what you need\n\n473\n00:25:10.385 --> 00:25:15.610\nis essentially two drives to store\nthe exact same information, right?\n\n474\n00:25:15.610 --> 00:25:18.790\nIf we write to one of the disks,\nwe also write to the next disk.\n\n475\n00:25:18.790 --> 00:25:20.893\nAnd you can see we've\ngot double writes here.\n\n476\n00:25:20.893 --> 00:25:24.697\nWe've got everything that's written\non this side is mirrored over to\n\n477\n00:25:24.697 --> 00:25:26.320\na second disk.\n\n478\n00:25:26.320 --> 00:25:31.228\nNow this is where your write speeds,\nthey slow down a little bit, right,\n\n479\n00:25:31.228 --> 00:25:34.490\ncuz you're having to\nwrite information twice.\n\n480\n00:25:34.490 --> 00:25:37.930\nYour read speeds are fine, but\nyour write speeds slow a little bit.\n\n481\n00:25:37.930 --> 00:25:42.570\nBut the good thing about this here is,\nis that if I lose one of the drives,\n\n482\n00:25:42.570 --> 00:25:46.870\nI have a duplicate copy of everything\nthat was written to these drives,\n\n483\n00:25:46.870 --> 00:25:47.780\non a separate disk.\n\n484\n00:25:47.780 --> 00:25:50.770\nAnd again, this is one that\ntakes a minimum of two disks.\n\n485\n00:25:52.270 --> 00:25:55.930\nNow along came a little bit more\nfault tolerance, all right?\n\n486\n00:25:55.930 --> 00:25:57.770\nAnd this is what's known as RAID 5.\n\n487\n00:25:57.770 --> 00:26:01.320\nAnd by the way, I don't know if\nit's important for the exam, but\n\n488\n00:26:01.320 --> 00:26:04.400\nthese are all what they\nare called block level striping.\n\n489\n00:26:04.400 --> 00:26:08.520\nIt's chunks of your information that\nare written across these multiple drives.\n\n490\n00:26:08.520 --> 00:26:13.560\nIn RAID 5, it is called, again,\nRAID 5 with distributed parity.\n\n491\n00:26:13.560 --> 00:26:18.150\nAnd a parity, again, is a calculation\nthat the drive controller makes.\n\n492\n00:26:18.150 --> 00:26:20.810\nAnd it adds that to your data.\n\n493\n00:26:20.810 --> 00:26:23.880\nSo you can say we write once,\nwe write twice.\n\n494\n00:26:23.880 --> 00:26:28.160\nWe write a parity bit,\nthen we write once, we write a parity bit,\n\n495\n00:26:28.160 --> 00:26:30.240\nwe write again across three drives.\n\n496\n00:26:30.240 --> 00:26:34.420\nAgain minimum of three drives to do this,\nand you can see here\n\n497\n00:26:34.420 --> 00:26:39.820\nthat the parity is distributed across all\nof the drives, now why is this important?\n\n498\n00:26:39.820 --> 00:26:43.780\nWell one of the great things about\nlosing one of the drives here,\n\n499\n00:26:43.780 --> 00:26:45.570\nthere's nothing great\nabout losing a drive.\n\n500\n00:26:45.570 --> 00:26:49.050\nBut the good thing about implementing\nthis if you lose a drive,\n\n501\n00:26:49.050 --> 00:26:52.370\nis the fact that if I lose the disk,\nI still have enough\n\n502\n00:26:52.370 --> 00:26:56.080\nparody information that the drive\ncontroller can figure out what's missing.\n\n503\n00:26:56.080 --> 00:26:58.490\nAnd even better,\nis when we restore the disk,\n\n504\n00:26:58.490 --> 00:27:04.760\nit can rebuild the information that\nhas been lost on that first drive.\n\n505\n00:27:04.760 --> 00:27:10.300\nNow you'll hear a lot of people,\nincluding gamers too, that will say,\n\n506\n00:27:10.300 --> 00:27:14.090\nthis isn't the best solution,\nit gives you some fault tolerance.\n\n507\n00:27:14.090 --> 00:27:18.830\nBut as far as performance goes,\nyou take a performance hit on it, why?\n\n508\n00:27:18.830 --> 00:27:22.050\nCuz your driver is constantly\ncalculating parity information.\n\n509\n00:27:22.050 --> 00:27:27.010\nAny time you have to calculate any\nkind of check sum, doesn't matter if\n\n510\n00:27:27.010 --> 00:27:31.190\nit's a CRC 32 cyclic value, doesn't matter\nif it's message authentication code for\n\n511\n00:27:31.190 --> 00:27:37.600\nin checks and sequences, that robs your\nCPU of valuable processing cycles.\n\n512\n00:27:37.600 --> 00:27:40.380\nIn this case, it's the drive\ncontroller that's calculating it,\n\n513\n00:27:40.380 --> 00:27:44.160\nso it's having to calculate this and\nit can slow you down.\n\n514\n00:27:44.160 --> 00:27:47.920\nAnd that's why they came out with\nsomething known as RAID 10, right?\n\n515\n00:27:47.920 --> 00:27:53.004\nNow RAID 10 is one that kind of\ntries to get best of both worlds,\n\n516\n00:27:53.004 --> 00:27:58.140\nright, between your striping and\nbetween your mirroring.\n\n517\n00:27:58.140 --> 00:28:01.770\nNow it's expensive, right,\ncuz it takes a minimum of four disks here.\n\n518\n00:28:01.770 --> 00:28:05.610\nBut what you end up seeing is that\nthe lower RAID here is RAID 1.\n\n519\n00:28:05.610 --> 00:28:08.410\nWe've got two disks and they're mirrored.\n\n520\n00:28:08.410 --> 00:28:10.860\nIdentical rights on them are mirrored.\n\n521\n00:28:10.860 --> 00:28:17.050\nBut then that information starts a stripe\nacross a second block of drives.\n\n522\n00:28:17.050 --> 00:28:21.940\nSo you can see that we have a stripe going\non here, but notice what happens if I\n\n523\n00:28:21.940 --> 00:28:25.037\nlose one of these drives,\nI still have all of my information, right?\n\n524\n00:28:26.830 --> 00:28:27.980\nNow where's the benefit?\n\n525\n00:28:27.980 --> 00:28:31.470\nIf this expensive like I said,\nwhere's the benefit?\n\n526\n00:28:31.470 --> 00:28:33.832\nWhat do you see that it's missing?\n\n527\n00:28:33.832 --> 00:28:37.836\nAnd Dan, I'm gonna throw this one back to\nyou, what is missing between RAID 5 and\n\n528\n00:28:37.836 --> 00:28:38.660\nRAID 10 here?\n\n529\n00:28:38.660 --> 00:28:39.332\n&gt;&gt; There's no parity.\n\n530\n00:28:39.332 --> 00:28:40.124\n&gt;&gt; No parity, right?\n\n531\n00:28:40.124 --> 00:28:42.109\nSo we don't have to\ncalculate that information,\n\n532\n00:28:42.109 --> 00:28:44.310\nso this is kinda like the best of both.\n\n533\n00:28:44.310 --> 00:28:46.430\nBetween you're striping information or\n\n534\n00:28:46.430 --> 00:28:50.290\nyou're striping set up if you will and\nyou RAID 1 set up.\n\n535\n00:28:50.290 --> 00:28:52.660\nSo again keep those in mind.\n\n536\n00:28:52.660 --> 00:28:56.558\nLast one I think all throughout here and\nI didn't even do this.\n\n537\n00:28:56.558 --> 00:29:00.621\nThey are all other kinds,\nthese are called nested RAIDs.\n\n538\n00:29:00.621 --> 00:29:02.535\nThere's also RAID 50 out there.\n\n539\n00:29:02.535 --> 00:29:04.997\nThere's RAID 100 again, [CROSSTALK].\n\n540\n00:29:04.997 --> 00:29:09.460\nYeah there we go, where you do\nthe opposite of this, yes exactly.\n\n541\n00:29:09.460 --> 00:29:12.814\nSo understand that there are nested RAIDs,\nwe just kinda wanted to give you\n\n542\n00:29:12.814 --> 00:29:16.489\nan example of one that you would see in\nthings like databases, databases love this\n\n543\n00:29:16.489 --> 00:29:20.290\nepisode, I have break a lot of\nperformance and a lot of redundancy.\n\n544\n00:29:20.290 --> 00:29:24.180\nAgain resiliency, and again that's what\nwe're trying here with fault tolerance.\n\n545\n00:29:25.382 --> 00:29:28.230\nAll right, we've talked about\na lot of things in here.\n\n546\n00:29:28.230 --> 00:29:29.200\nKeep that in mind.\n\n547\n00:29:29.200 --> 00:29:31.951\nRemember things like elasticity and\nscalability,\n\n548\n00:29:31.951 --> 00:29:34.584\nnice distributed allocation\nof your resources.\n\n549\n00:29:34.584 --> 00:29:38.998\nIt is important, remember using\nthings like nonpersistent images,\n\n550\n00:29:38.998 --> 00:29:43.190\nnonpersistent implementations,\nmaster images, templates and\n\n551\n00:29:43.190 --> 00:29:47.455\nusing scripts for automation,\nremember it's about resiliency or\n\n552\n00:29:47.455 --> 00:29:51.372\nredundancy, fault tolerance,\nand a consistency through.\n\n553\n00:29:51.372 --> 00:29:54.887\nTrying to take some of that human element\nout to reduce the overall risk of the data\n\n554\n00:29:54.887 --> 00:29:57.250\nthat's stored throughout\nyour organization.\n\n555\n00:29:57.250 --> 00:29:57.790\n&gt;&gt; All right, Wes.\n\n556\n00:29:57.790 --> 00:29:59.850\nThat's great stuff today,\nlot of really good stuff for\n\n557\n00:29:59.850 --> 00:30:01.410\nyou guys to sink your teeth into.\n\n558\n00:30:01.410 --> 00:30:04.360\nTake a little time with this, make sure\nyou understand all of those concepts and\n\n559\n00:30:04.360 --> 00:30:06.542\nthen be prepared for that testing booth.\n\n560\n00:30:06.542 --> 00:30:09.923\nThat being said this,\nlooks like we're out of time for today.\n\n561\n00:30:09.923 --> 00:30:11.863\nWe would thank you for joining us.\n\n562\n00:30:11.863 --> 00:30:13.634\nSigning off for ITPRO.TV.\n\n563\n00:30:13.634 --> 00:30:14.771\nI've been you host Daniel Lowrie.\n\n564\n00:30:14.771 --> 00:30:15.456\n&gt;&gt; And I'm Wes Bryan.\n\n565\n00:30:15.456 --> 00:30:18.413\n&gt;&gt; And we'll see you next time.\n\n566\n00:30:18.413 --> 00:30:24.328\n[MUSIC]\n\n567\n00:30:24.328 --> 00:30:27.465\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "217686921"
        },
        {
          "description": "In this episode, Cherokee and Wes stress the importance  of physical security controls. They explain how each layer of security adds complexity. They offer several suggestions that can be implemented to improve an organizations security. Tune in to learn how airgaps, mantraps, lighting and more can help your network!",
          "length": "1489",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-9-1-importance_of_physical_security-041717-PGM.00_24_34_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-9-1-importance_of_physical_security-041717-PGM.00_24_34_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-9-1-importance_of_physical_security-041717-PGM.00_24_34_27.Still001-sm.jpg",
          "title": "Importance of Physical Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.464\nWelcome to ITProTV.\n\n2\n00:00:01.464 --> 00:00:08.442\nI'm your host Don Pezet-\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:08.442 --> 00:00:12.321\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.321 --> 00:00:17.050\n&gt;&gt; Welcome to your CompTIA Security+\nSeries, I'm your show host Cherokee Boose.\n\n5\n00:00:17.050 --> 00:00:20.170\nSo far, up until this point, we've\nreally been focusing on technical and\n\n6\n00:00:20.170 --> 00:00:22.000\nadministrative security controls.\n\n7\n00:00:22.000 --> 00:00:25.160\nBut this episode is all about\nfocusing on the importance\n\n8\n00:00:25.160 --> 00:00:27.025\nof physical security controls.\n\n9\n00:00:27.025 --> 00:00:30.524\nWith this today in studios we have Mr.\nWes Bryan, thank you for joining us Wes.\n\n10\n00:00:30.524 --> 00:00:31.903\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n11\n00:00:31.903 --> 00:00:34.105\nThat's right we are looking\nat what we can do to,\n\n12\n00:00:34.105 --> 00:00:36.050\nthe Tactical Perimeter Defense, right?\n\n13\n00:00:36.050 --> 00:00:39.898\nAnd by perimeter I don't mean perimeter\nnetworks, I do mean the physical\n\n14\n00:00:39.898 --> 00:00:43.572\nimplementation of security around and\nin throughout your building.\n\n15\n00:00:43.572 --> 00:00:46.452\nSo, let's go ahead and\nlet's dive right, and\n\n16\n00:00:46.452 --> 00:00:49.554\nI wanna talk a little bit\nabout defense in-depth.\n\n17\n00:00:49.554 --> 00:00:52.459\nA layered strategic defense mechanism,\nif you will,\n\n18\n00:00:52.459 --> 00:00:55.616\nthat was really started by\nthe United States military, and\n\n19\n00:00:55.616 --> 00:00:58.981\nthen adopted with a lot of the other\nvendors such as Microsoft.\n\n20\n00:00:58.981 --> 00:01:00.425\nI got a little diagram here so\n\n21\n00:01:00.425 --> 00:01:03.503\nwe can can see at what point what\nare we actually focusing on.\n\n22\n00:01:03.503 --> 00:01:07.393\nYou can see that the outer ring here, when\nwe talk about this layered defense system,\n\n23\n00:01:07.393 --> 00:01:11.410\nis really about things like, for instance,\npolicies, procedures, and awareness.\n\n24\n00:01:11.410 --> 00:01:14.560\nBut as we go up the stack,\nright, we get in closer and\n\n25\n00:01:14.560 --> 00:01:16.890\ncloser all the way up until our data,\nright?\n\n26\n00:01:16.890 --> 00:01:17.950\nOur data is,\n\n27\n00:01:17.950 --> 00:01:21.770\nit's really what we really wanna protect\ninside of information security, right?\n\n28\n00:01:21.770 --> 00:01:25.970\nWe talk about information technology, so\nit's all about the information, right?\n\n29\n00:01:25.970 --> 00:01:29.160\nWe also have things like perimeters\nsecurity, right, DMZs ,if you will,\n\n30\n00:01:29.160 --> 00:01:31.020\nEDGE networks, isolation networks.\n\n31\n00:01:31.020 --> 00:01:34.424\nWe also have things like our\ninterior network security, and\n\n32\n00:01:34.424 --> 00:01:38.575\nthen as well as on the host, right,\nwhere does the data actually reside?\n\n33\n00:01:38.575 --> 00:01:42.820\nWell, the host uses applications, if you\nwill, in order to see that data, right, so\n\n34\n00:01:42.820 --> 00:01:46.443\nwe need to make sure that we implement\nthings like application security.\n\n35\n00:01:46.443 --> 00:01:51.345\nAnd then finally, things like ACLs,\npermissions, encryption like EFS inside of\n\n36\n00:01:51.345 --> 00:01:56.398\nMicrosoft, if you will, to make sure that\nour data also maintains security as well.\n\n37\n00:01:56.398 --> 00:01:59.087\nBut more so\nwhat we're gonna be focusing on today, and\n\n38\n00:01:59.087 --> 00:02:03.128\nwe will look at this a little bit more\nin-depth, if you will, in later episodes.\n\n39\n00:02:03.128 --> 00:02:05.940\nBut I do wanna focus on\nthe physical security side, right,\n\n40\n00:02:05.940 --> 00:02:07.695\nthis is where we we're gonna start.\n\n41\n00:02:07.695 --> 00:02:12.516\nAnd, again, you can see, when it comes to\nthis seven-layered approach here, we're\n\n42\n00:02:12.516 --> 00:02:16.765\ntalking about just outside of trading\nyour users, your security policies.\n\n43\n00:02:16.765 --> 00:02:19.980\nAnd just being aware that these\ndifferent attacks, if you will, and\n\n44\n00:02:19.980 --> 00:02:21.430\nthreats exist on our network.\n\n45\n00:02:21.430 --> 00:02:23.910\nSo, when we talk about physical security,\n\n46\n00:02:23.910 --> 00:02:27.020\nsome of the examples that we have when\nit comes to physical security, right?\n\n47\n00:02:27.020 --> 00:02:28.791\nYou can see there are a bunch of them, and\n\n48\n00:02:28.791 --> 00:02:31.567\nthese are just a few of the things\nthat we're gonna talk about.\n\n49\n00:02:31.567 --> 00:02:36.559\nYou can see things like for instance,\nsigns, right, lighting, fences,\n\n50\n00:02:36.559 --> 00:02:40.610\ncages, security guards,\nalarms, if you will, safes.\n\n51\n00:02:40.610 --> 00:02:44.563\nKeep in mind that we can keep things\nlike back-ups, our on-site backups,\n\n52\n00:02:44.563 --> 00:02:48.700\nin things like safes because we do\nhave to keep that information secure.\n\n53\n00:02:48.700 --> 00:02:50.780\nWe have things like mantraps,\nsecurity guards.\n\n54\n00:02:50.780 --> 00:02:54.950\nWe'll talk about protective distribution\nsystems as well as barricades,\n\n55\n00:02:54.950 --> 00:02:57.370\nenvironmental controls, and cable locks.\n\n56\n00:02:57.370 --> 00:02:59.935\nNow, this is just,\nit's not a comprehensive list,\n\n57\n00:02:59.935 --> 00:03:02.030\nit's just kind of a overview\nof what we are gonna see.\n\n58\n00:03:02.030 --> 00:03:06.377\nSo let's go ahead, and let's start with\nthe very first thing lighting, all right?\n\n59\n00:03:06.377 --> 00:03:09.060\nLighting is important in\nphysical security, right?\n\n60\n00:03:09.060 --> 00:03:14.080\nKeep in mind that this isn't really\na psychological deterrent when we talk\n\n61\n00:03:14.080 --> 00:03:19.988\nabout lighting, right, versus like maybe\nsign that says warning, keep out, right?\n\n62\n00:03:19.988 --> 00:03:21.132\nNo trespassing, right,\n\n63\n00:03:21.132 --> 00:03:24.674\nthat's more of a psychological deterrent\nwhen we talk about things like signs.\n\n64\n00:03:24.674 --> 00:03:29.752\nBut lighting, we wanna keep the important\nareas of our building illuminating,\n\n65\n00:03:29.752 --> 00:03:33.271\nright, for instance,\nentry control points, right?\n\n66\n00:03:33.271 --> 00:03:37.661\nWhen we talk about going from a public\naccess area to a secure area, right,\n\n67\n00:03:37.661 --> 00:03:40.182\nthose access control locations, right?\n\n68\n00:03:40.182 --> 00:03:45.428\nCould even be public facing, unsecure\narea leading into a customer area,\n\n69\n00:03:45.428 --> 00:03:49.856\nright, so it'd just be access control,\nif you will, right?\n\n70\n00:03:49.856 --> 00:03:52.906\nWhere else should we put these lights,\nfor instance,\n\n71\n00:03:52.906 --> 00:03:58.040\naround the perimeters of your buildings,\nthe perimeters of your fences, as well.\n\n72\n00:03:58.040 --> 00:04:00.004\nThey are important.\n\n73\n00:04:00.004 --> 00:04:03.146\nOne of the great things about lighting\nin general when we talk about\n\n74\n00:04:03.146 --> 00:04:05.895\nphysical security and\nthe defense around your building,\n\n75\n00:04:05.895 --> 00:04:08.439\nis the fact that they're relatively cheap,\nright?\n\n76\n00:04:08.439 --> 00:04:13.375\nIt's relatively cheap to maintain\nyour lights, so it does make for\n\n77\n00:04:13.375 --> 00:04:17.199\na good,\nflexible first security implementation.\n\n78\n00:04:17.199 --> 00:04:21.213\nKeep in mind, it's more about\nilluminating those important spots.\n\n79\n00:04:21.213 --> 00:04:24.363\n&gt;&gt; And Wes, I know we had spoke about\ndifferent types of security cameras,\n\n80\n00:04:24.363 --> 00:04:28.260\nbefore we were talking about that strobe\nlight placed near them strategically.\n\n81\n00:04:28.260 --> 00:04:32.467\nBut also, if you think about certain\nsecurity cameras don't have any kind\n\n82\n00:04:32.467 --> 00:04:34.154\nof infrared or night vision.\n\n83\n00:04:34.154 --> 00:04:38.043\nSo maybe if you have some lighting\nstrategically placed near your security\n\n84\n00:04:38.043 --> 00:04:41.888\ncameras, just to enhance whatever it\nis that those cameras can capture.\n\n85\n00:04:41.888 --> 00:04:44.832\n&gt;&gt; Most definitely, and not only\nassisting the camera base systems, right,\n\n86\n00:04:44.832 --> 00:04:47.660\nthey can assist the security guards,\nright, who can act at real time.\n\n87\n00:04:47.660 --> 00:04:51.116\nSo keep in mind,\nlighting is very, very important.\n\n88\n00:04:51.116 --> 00:04:53.770\nNow, the next thing that we\ntalk about are signs, right,\n\n89\n00:04:53.770 --> 00:04:55.850\nsigns are important as well, right?\n\n90\n00:04:55.850 --> 00:04:58.700\nKeep in mind that we should\nhave signs around things like\n\n91\n00:04:58.700 --> 00:04:59.870\nauthorized entry points.\n\n92\n00:04:59.870 --> 00:05:04.013\nAnd, again, I'm talking about public\naccess points to a secure access point\n\n93\n00:05:04.013 --> 00:05:06.651\nwhere it's authorized personnel only,\nagain,\n\n94\n00:05:06.651 --> 00:05:08.683\nit could be a controlled entry point.\n\n95\n00:05:08.683 --> 00:05:12.371\nThe difference that I mean cuz when you\ntalk about an authorized entry point,\n\n96\n00:05:12.371 --> 00:05:14.363\nthat's still a controlled entry point.\n\n97\n00:05:14.363 --> 00:05:17.479\nBut I want you to think about,\nfor instance,\n\n98\n00:05:17.479 --> 00:05:20.105\ngoing into maybe an airport, right?\n\n99\n00:05:20.105 --> 00:05:22.497\nThere's still areas that\nare controlled access, but\n\n100\n00:05:22.497 --> 00:05:25.669\nit doesn't mean that unauthorized\npersonnel couldn't go in there just\n\n101\n00:05:25.669 --> 00:05:28.589\nlike there are public areas that\nare still controlled access too.\n\n102\n00:05:28.589 --> 00:05:31.667\nSo it could be public access\nto a customer area, right?\n\n103\n00:05:31.667 --> 00:05:36.107\nWe need to make sure that we have\nsigns that maybe help steer people\n\n104\n00:05:36.107 --> 00:05:38.851\ntowards things like mantraps, right,\n\n105\n00:05:38.851 --> 00:05:43.062\nthose turnstiles that allow us\nto do things like inspection.\n\n106\n00:05:43.062 --> 00:05:43.800\nSigns, again,\n\n107\n00:05:43.800 --> 00:05:46.983\nwarning signs around the perimeters\ntoo are gonna be important as all.\n\n108\n00:05:46.983 --> 00:05:51.280\nAnd they need to be clearly readable,\nright, they need to be understood.\n\n109\n00:05:51.280 --> 00:05:55.879\nIt doesn't need to be a lecture,\nif you will, all written out in the sign,\n\n110\n00:05:55.879 --> 00:05:58.217\njust very simplistic, easily read.\n\n111\n00:05:58.217 --> 00:06:04.225\nAnd viewable, right, so people are aware\nof things like physical hazard areas,\n\n112\n00:06:04.225 --> 00:06:07.024\nthese are important likewise, too.\n\n113\n00:06:07.024 --> 00:06:11.036\nAll right, some of the other things that\nthey call out when we talk about physical\n\n114\n00:06:11.036 --> 00:06:14.460\nsecurity are fences, gates, and\ncages, fences, gates, cages.\n\n115\n00:06:14.460 --> 00:06:19.334\nKeep in mind, fencing, just like lights,\nare probably one of the most\n\n116\n00:06:19.334 --> 00:06:23.248\ncommon security implementations\nthat we have, right?\n\n117\n00:06:23.248 --> 00:06:25.910\nIf you think about it, for instance,\nlet me give you an example here.\n\n118\n00:06:27.650 --> 00:06:29.933\nThere is\nthe United State Geological Survey,\n\n119\n00:06:29.933 --> 00:06:32.867\nthey got what's known as\nthe physical security handbook.\n\n120\n00:06:32.867 --> 00:06:36.306\nAnd you can see that there\nare difference standards out there, and\n\n121\n00:06:36.306 --> 00:06:39.512\nstandardizing the approach of\nthis perimeter type defense.\n\n122\n00:06:39.512 --> 00:06:44.121\nSo, for instance, I think it's, let's see,\nChapter 4-3, that's what I want,\n\n123\n00:06:44.121 --> 00:06:44.820\nright here.\n\n124\n00:06:44.820 --> 00:06:48.978\nAnd you can see, for instance, that they\ncall a standardization of how you're\n\n125\n00:06:48.978 --> 00:06:51.969\nsupposed to secure your\nbuildings physically, right?\n\n126\n00:06:51.969 --> 00:06:55.633\nThey talk about things like fencing,\nright, fencing's the most common perimeter\n\n127\n00:06:55.633 --> 00:06:58.535\nbarrier control, right,\nchain link and barbed fences, right?\n\n128\n00:06:58.535 --> 00:07:03.109\nSo you can see that there\nare standardized approaches for\n\n129\n00:07:03.109 --> 00:07:08.980\nimplementing things like your fencing,\ngates, and cages, right?\n\n130\n00:07:08.980 --> 00:07:11.640\nOne of the things that's interesting\nin here too, we'll say that's\n\n131\n00:07:11.640 --> 00:07:16.270\npart of the fencing too, are things\nlike your automated gates, all right?\n\n132\n00:07:16.270 --> 00:07:18.950\nAnd we talk about gates opening and\nclosing, if you will,\n\n133\n00:07:18.950 --> 00:07:21.534\ncould be one of these that\nmaybe it's not so automatic.\n\n134\n00:07:21.534 --> 00:07:24.867\nMaybe the automatic nature of it's\nactually a security guard going out\n\n135\n00:07:24.867 --> 00:07:26.800\nthere and opening it up.\n\n136\n00:07:26.800 --> 00:07:31.120\nBut sometimes you might have\na layered fencing system, right?\n\n137\n00:07:31.120 --> 00:07:34.850\nYou might have controlled access point\nwhere the first gate opens after there's\n\n138\n00:07:34.850 --> 00:07:37.340\na little preliminary inspection.\n\n139\n00:07:37.340 --> 00:07:40.710\nYou go into the first gate,\nthat gate closes, right, and\n\n140\n00:07:40.710 --> 00:07:43.970\nthen you go into the final authorization\nor access point checklist.\n\n141\n00:07:43.970 --> 00:07:46.670\nAnd then you go through the second gate,\nright, and then it closes.\n\n142\n00:07:46.670 --> 00:07:49.753\nThis would be an example of a mantrap,\nwhich is kinda interesting cuz\n\n143\n00:07:49.753 --> 00:07:52.424\nit's more than just a mantrap,\nit's actually a car trap.\n\n144\n00:07:52.424 --> 00:07:53.418\n&gt;&gt; A vehicle trap, yeah [LAUGH].\n\n145\n00:07:53.418 --> 00:07:57.145\n&gt;&gt; Yeah, [LAUGH] that's right,\nso that when we talk about it,\n\n146\n00:07:57.145 --> 00:07:59.164\nthe concept really is the same.\n\n147\n00:07:59.164 --> 00:08:02.798\nSo, and I will, if you want more\ninformation about this, I will put some of\n\n148\n00:08:02.798 --> 00:08:06.800\nthese links that we're talking about,\nagain, just as access for information.\n\n149\n00:08:06.800 --> 00:08:10.023\nA lot of good information that\nyou can get out there when it\n\n150\n00:08:10.023 --> 00:08:14.793\ncomes to things like fencing, your gates\nif you will, things like your lighting and\n\n151\n00:08:14.793 --> 00:08:16.090\nyour signs and stuff.\n\n152\n00:08:16.090 --> 00:08:20.546\nA lot of great information out there\nto help assist you in your studies.\n\n153\n00:08:20.546 --> 00:08:26.070\nNow, the next thing we talk about are\nthings like security guards, all right?\n\n154\n00:08:26.070 --> 00:08:27.707\nSecurity guards are very,\nvery important, right?\n\n155\n00:08:27.707 --> 00:08:30.587\nAnd, I would say probably,\none of the most important\n\n156\n00:08:30.587 --> 00:08:34.220\nthings is the fact that we have\nreal time monitoring, right?\n\n157\n00:08:34.220 --> 00:08:37.985\nWe implement things in our data\nnetworks and our networks,\n\n158\n00:08:37.985 --> 00:08:42.136\nwe implement things like intrusion\ndetection systems, right?\n\n159\n00:08:42.136 --> 00:08:43.601\nIt's an automated approach.\n\n160\n00:08:43.601 --> 00:08:46.919\nIt's an automated approach to detect\nintrusion events that happen within your\n\n161\n00:08:46.919 --> 00:08:47.421\nnetworks.\n\n162\n00:08:47.421 --> 00:08:50.346\nBut one of the great things\nabout security guards is,\n\n163\n00:08:50.346 --> 00:08:53.013\nas opposed to a traditional IDS system,\nright?\n\n164\n00:08:53.013 --> 00:08:57.082\nWhen you look at traditional IDS system,\nit uses a series of behavior, right?\n\n165\n00:08:57.082 --> 00:09:01.405\nMaybe a database if you will, that's\nstatic and has to be updated from time to\n\n166\n00:09:01.405 --> 00:09:04.411\ntime to kind of find out\nwhat intrusions are, right?\n\n167\n00:09:04.411 --> 00:09:07.873\nAnd it's not really, it can't be\ndynamic but I want you to think\n\n168\n00:09:07.873 --> 00:09:11.481\nabout the human element of having\na security guard there, right?\n\n169\n00:09:11.481 --> 00:09:17.370\nSecurity guards do a great job of reacting\nin real time to intrusioned events.\n\n170\n00:09:17.370 --> 00:09:21.980\nAnd the human element if you will,\nis a little bit more adequate to\n\n171\n00:09:21.980 --> 00:09:26.990\nadjust adaptable to a situation and seeing\nit real time rather than having to use\n\n172\n00:09:26.990 --> 00:09:33.170\nsome kind of computerized logic in order\nto react in real time to these events.\n\n173\n00:09:33.170 --> 00:09:38.132\nIn fact, Sam's out there has got\na pretty good document on this too.\n\n174\n00:09:38.132 --> 00:09:42.265\nIt's Sam's radio room white paper 37-120.\n\n175\n00:09:42.265 --> 00:09:47.440\nAnd more specifically, if you have\ndived down into the chapter here.\n\n176\n00:09:47.440 --> 00:09:49.657\nAgain, you can see 3.3.4, right?\n\n177\n00:09:49.657 --> 00:09:55.000\nThey got a lot of great information on\nintrusion detection, guards and CCTV.\n\n178\n00:09:55.000 --> 00:09:58.100\nAnd guards, again,\ntalking about being a significant\n\n179\n00:09:58.100 --> 00:10:01.330\npart of the intrusion detection system,\neven though we don't consider it that way,\n\n180\n00:10:01.330 --> 00:10:03.560\nwhen we are in security,\nwe think intrusion detection system.\n\n181\n00:10:03.560 --> 00:10:06.450\nA lot of times we're just talking\nabout software that automates\n\n182\n00:10:06.450 --> 00:10:08.140\nthis process behind the scenes.\n\n183\n00:10:08.140 --> 00:10:09.995\nBut you can't eliminate\nthe human aspect or\n\n184\n00:10:09.995 --> 00:10:12.905\nthe fact that humans can be a lot\nmore adaptable in real time to what's\n\n185\n00:10:12.905 --> 00:10:15.133\ngoing on in the events that\nthey see in front of them.\n\n186\n00:10:15.133 --> 00:10:19.308\n&gt;&gt; You know Wes, you brought up a really\ngood point when you mentioned some kind of\n\n187\n00:10:19.308 --> 00:10:23.360\npresence, that psychological presence,\nwhich may just prohibit any kind\n\n188\n00:10:23.360 --> 00:10:26.290\nof incident from occurring\nin the first place.\n\n189\n00:10:26.290 --> 00:10:30.281\nWhich, when we talk about security,\noften a lot of people who aren't\n\n190\n00:10:30.281 --> 00:10:34.964\nin that security mindset may not see the\nvalue in something like a security guard.\n\n191\n00:10:34.964 --> 00:10:38.751\nAnd the ROI is not so imminent and\nintangible there because while we're\n\n192\n00:10:38.751 --> 00:10:43.371\npreventing something that really didn't\nhappen, so how do we measure that, right?\n\n193\n00:10:43.371 --> 00:10:46.561\nSo you just have to think about not\nonly what they do reactively but\n\n194\n00:10:46.561 --> 00:10:47.723\nalso preventatively.\n\n195\n00:10:47.723 --> 00:10:49.230\n&gt;&gt; Most definitely, so take for\n\n196\n00:10:49.230 --> 00:10:52.620\ninstance being in front of that\nclosed circuit TV system, right?\n\n197\n00:10:52.620 --> 00:10:55.400\nYou're looking at different monitoring,\nright?\n\n198\n00:10:55.400 --> 00:11:00.080\nWe have things like our cameras, but our\ncameras sometimes can do us no good if we\n\n199\n00:11:00.080 --> 00:11:04.230\nhave like a remote security team that's\nactually monitoring and viewing it.\n\n200\n00:11:04.230 --> 00:11:08.430\nFor instance, maybe you have, think about\nyour home intrusion type systems, right?\n\n201\n00:11:08.430 --> 00:11:13.332\nWhere maybe you do have a camera out there\nbut the camera alerts maybe the system\n\n202\n00:11:13.332 --> 00:11:17.505\nwhich turns around and alerts maybe,\na law enforcement, right?\n\n203\n00:11:17.505 --> 00:11:20.586\nWhen you have the human nature there,\nagain,\n\n204\n00:11:20.586 --> 00:11:25.200\nyou have almost like your first\nresponder is already there, right?\n\n205\n00:11:25.200 --> 00:11:29.260\nSo keep that in mind, that they can\nact in real time and they can call law\n\n206\n00:11:29.260 --> 00:11:33.810\nenforcement right away, to what they see\nin front of a closed circuit type TV.\n\n207\n00:11:33.810 --> 00:11:39.520\nSo it is important to keep in mind that\nthe guards again are very, very important.\n\n208\n00:11:39.520 --> 00:11:44.370\nAnd it's also great to see because guards\ncan be there too in off hours, right?\n\n209\n00:11:44.370 --> 00:11:47.681\nNot just obviously,\nthe business hours of the day, but\n\n210\n00:11:47.681 --> 00:11:52.401\nthey can also be there in the off hours,\ntoo, giving us the real time reaction to\n\n211\n00:11:52.401 --> 00:11:55.948\nevents as they happen rather\nthan detecting them, right?\n\n212\n00:11:55.948 --> 00:11:57.080\nThink about this.\n\n213\n00:11:57.080 --> 00:11:59.260\nWe talk about IDS systems, right?\n\n214\n00:11:59.260 --> 00:12:03.220\nWe detect or monitor if you will,\ndetect and then alert.\n\n215\n00:12:03.220 --> 00:12:04.650\nWell, that alert could be what?\n\n216\n00:12:04.650 --> 00:12:08.230\nAn email, could be maybe\nan automated text message and\n\n217\n00:12:08.230 --> 00:12:10.660\nthen the response has to happen, right?\n\n218\n00:12:10.660 --> 00:12:14.300\nThen hopefully, we don't have to, but\nmaybe we have to drive a few miles,\n\n219\n00:12:14.300 --> 00:12:16.910\nmaybe we have to wait for\nthe law enforcement to get there.\n\n220\n00:12:16.910 --> 00:12:18.510\nKind of wonder what's going on,\n\n221\n00:12:18.510 --> 00:12:21.770\nyou have to kinda figure out\nwhat exactly is happening.\n\n222\n00:12:21.770 --> 00:12:24.540\nAgain, when you have your security\nguards they can fill in law enforcement\n\n223\n00:12:24.540 --> 00:12:27.490\nright away and say this is exactly\nwhat we see, this is where we see it,\n\n224\n00:12:27.490 --> 00:12:28.830\nthis is what's happening.\n\n225\n00:12:28.830 --> 00:12:31.486\nAnd they can help to respond\nto some kind of situation.\n\n226\n00:12:31.486 --> 00:12:36.010\nNow speaking of which,\nwe also have things like alarms, right?\n\n227\n00:12:36.010 --> 00:12:40.126\nWhen it comes to alarms, again, there's\nnot any one set standard, if you will.\n\n228\n00:12:40.126 --> 00:12:45.469\nBut alarms coupled with some of these\nother technologies that we talk about,\n\n229\n00:12:45.469 --> 00:12:50.237\nagain, alarm might not prevent\nsomebody from stealing anything but\n\n230\n00:12:50.237 --> 00:12:53.956\nit might again allow a reaction\nin real time, right?\n\n231\n00:12:53.956 --> 00:12:56.098\nSo if an alarm goes off, right?\n\n232\n00:12:56.098 --> 00:13:01.868\nYou might get for instance, I think at\nthe home intrusion system ADT, right?\n\n233\n00:13:01.868 --> 00:13:06.337\nIf I get an alarm it usually has to send a\nsignal again and then that signal goes to\n\n234\n00:13:06.337 --> 00:13:10.633\nwhoever is monitoring the system and\nthey call first responders, right?\n\n235\n00:13:10.633 --> 00:13:12.749\nLaw enforcement, EMT,\nfire department, right?\n\n236\n00:13:12.749 --> 00:13:15.261\nAnd there's a lot time that that takes,\nright?\n\n237\n00:13:15.261 --> 00:13:18.224\nWhen you couple alarms with\nsecurity guards, right?\n\n238\n00:13:18.224 --> 00:13:22.185\nAn alarm goes off, an alarm\nsignals some kind of threat event,\n\n239\n00:13:22.185 --> 00:13:27.068\nagain that officer can get it right there\nand you can react to it a lot quicker.\n\n240\n00:13:27.068 --> 00:13:28.220\nSafes.\n\n241\n00:13:29.340 --> 00:13:32.340\nSafes are an adequate portion of\nphysical security because when you\n\n242\n00:13:32.340 --> 00:13:36.050\nhave intellectual property that\ncannot be lose or for instance,\n\n243\n00:13:36.050 --> 00:13:37.740\nI mentioned backups, right?\n\n244\n00:13:37.740 --> 00:13:40.460\nWe do have different types of\nbackups that we use, right?\n\n245\n00:13:40.460 --> 00:13:44.179\nWe might need our partial\nbackups that are on site, right?\n\n246\n00:13:44.179 --> 00:13:46.918\nThat contain a limited\namount of information but\n\n247\n00:13:46.918 --> 00:13:50.941\nwe don't want that information\ngetting into the wrong hands, right?\n\n248\n00:13:50.941 --> 00:13:55.582\nSo you might have your backup operator or\nmaybe your recovery operator.\n\n249\n00:13:55.582 --> 00:13:58.023\nWe've talked about this in the past\nepisodes, separation of duties.\n\n250\n00:13:58.023 --> 00:14:02.438\nMaybe your backup operator isn't the same\nthing as your recovery operator, right?\n\n251\n00:14:02.438 --> 00:14:07.095\nAnd in the case of things like fire or\ndisaster, you can get to some of\n\n252\n00:14:07.095 --> 00:14:12.003\nthose important pieces of information\nwithout having to worry about,\n\n253\n00:14:12.003 --> 00:14:15.000\nthe disaster eradicating the data.\n\n254\n00:14:15.000 --> 00:14:19.076\nOr, even more so, somebody actually\ngetting that information, right?\n\n255\n00:14:19.076 --> 00:14:21.440\nGetting access to that unauthorized.\n\n256\n00:14:21.440 --> 00:14:26.620\nSo, safes are another thing, coupled with\nthings like, well, secure cabinets, right?\n\n257\n00:14:26.620 --> 00:14:28.908\nWe talk about secure cabinets,\nsecured enclosures.\n\n258\n00:14:28.908 --> 00:14:33.148\nI know that for instance, here in the\nbuilding a lot of our cabinets have locks,\n\n259\n00:14:33.148 --> 00:14:35.090\nthey have locks on them, right?.\n\n260\n00:14:35.090 --> 00:14:39.880\nNow that's more for our own personal\nproperty, if you will [LAUGH].\n\n261\n00:14:39.880 --> 00:14:41.140\nTo help keep that locked but\n\n262\n00:14:41.140 --> 00:14:43.960\nif you look at things like\nfinancial institutions, right?\n\n263\n00:14:43.960 --> 00:14:47.465\nYou look at people who have loans and\nstuff, if you will and a lot of those\n\n264\n00:14:47.465 --> 00:14:52.040\ncabinets all have locks on them for\nthe purposes of sealing that information.\n\n265\n00:14:52.040 --> 00:14:55.296\nNot so much so that they can protect\nthe people that we would think of\n\n266\n00:14:55.296 --> 00:14:57.109\nlike in a Mission Impossible movie.\n\n267\n00:14:57.109 --> 00:15:01.381\nBut more so just the casual eavesdropper,\nwho wants to open that information up and\n\n268\n00:15:01.381 --> 00:15:02.915\ncasually browse through it.\n\n269\n00:15:02.915 --> 00:15:06.592\nIt's a way you secure information\nespecially when you have privacy\n\n270\n00:15:06.592 --> 00:15:09.312\nconcerns about data that\nyou might be retaining.\n\n271\n00:15:09.312 --> 00:15:13.598\n&gt;&gt; Yeah, for sure and\nalso we're talking our mobile devices.\n\n272\n00:15:13.598 --> 00:15:16.982\nOur electronics have become so such\nsmaller than they have been in the past\n\n273\n00:15:16.982 --> 00:15:20.110\nthat we're storing that important\npersonal data on those as well.\n\n274\n00:15:20.110 --> 00:15:24.170\nSo having those types of cabinets just,\nwe say are BYOD, but you don't wanna leave\n\n275\n00:15:24.170 --> 00:15:27.425\nthem laying around because that\ncould be a potential risk as well.\n\n276\n00:15:27.425 --> 00:15:31.270\n&gt;&gt; Most definitely, and this goes to back\nto one of the, if you think about it when\n\n277\n00:15:31.270 --> 00:15:35.118\nwe talk about secure enclosures and\nsecure locked cabinets, this goes back to\n\n278\n00:15:35.118 --> 00:15:39.220\nprobably one of the oldest physical\nsecurity implementations at all, right?\n\n279\n00:15:39.220 --> 00:15:40.753\nA lock and key, right?\n\n280\n00:15:40.753 --> 00:15:43.590\n[LAUGH] Don't overlook the good\nold lock and key, right?\n\n281\n00:15:43.590 --> 00:15:46.572\nEvery time we,\na lot of times when we think of security,\n\n282\n00:15:46.572 --> 00:15:48.158\nwe don't think of the lock and\n\n283\n00:15:48.158 --> 00:15:52.099\nkey as being really that secure but\nit can be at least a first stop measure.\n\n284\n00:15:52.099 --> 00:15:54.970\nRemember, we're talking\nabout multiple things\n\n285\n00:15:54.970 --> 00:15:57.839\nnot just any one single\ntechnology in order to make\n\n286\n00:15:57.839 --> 00:16:02.229\nsure that the physical security of our\nbuilding is implemented correctly.\n\n287\n00:16:02.229 --> 00:16:04.306\nAll right, what else do we have?\n\n288\n00:16:04.306 --> 00:16:07.077\nThey also talk about protective cabling,\nright, and\n\n289\n00:16:07.077 --> 00:16:09.660\nthey also talk about\nprotected distribution.\n\n290\n00:16:09.660 --> 00:16:10.590\nYou might hear this.\n\n291\n00:16:10.590 --> 00:16:14.210\nThere is a standard out there called PDS,\nand that's Protected Distribution Systems,\n\n292\n00:16:14.210 --> 00:16:15.812\nand we'll talk about that in a second.\n\n293\n00:16:15.812 --> 00:16:17.745\nWhen we talk about protected cabling,\n\n294\n00:16:17.745 --> 00:16:21.268\nI want you to think about worrying\nabout things like wire taps, right?\n\n295\n00:16:21.268 --> 00:16:24.345\nWhen we talk about twisted\npair implementation,\n\n296\n00:16:24.345 --> 00:16:28.592\nit's very easy if we can gain access\nto network runs to clip a cable and\n\n297\n00:16:28.592 --> 00:16:31.174\njust put an RJ-45 jack on the end of it.\n\n298\n00:16:31.174 --> 00:16:34.633\nSit there and plug it into a laptop\nif you've got access to the physical.\n\n299\n00:16:34.633 --> 00:16:43.558\nBasically, transmit,\n\n300\n00:16:43.558 --> 00:16:48.233\nif you will,\n\n301\n00:16:48.233 --> 00:16:52.908\nunencrypted\n\n302\n00:16:52.908 --> 00:16:59.708\ninformation, but\n\n303\n00:16:59.708 --> 00:17:03.958\nin a way that\n\n304\n00:17:03.958 --> 00:17:09.058\nstill makes it\n\n305\n00:17:09.058 --> 00:17:14.270\nprotected.\n\n306\n00:17:14.270 --> 00:17:20.294\nFor instance,\nI've got one of their documents,\n\n307\n00:17:20.294 --> 00:17:27.755\nthis is actually a military\nProductive Distribution Systems\n\n308\n00:17:27.755 --> 00:17:31.916\ntransmit unencrypted classified\n\n309\n00:17:31.916 --> 00:17:37.270\nNational Security Information, right?\n\n310\n00:17:37.270 --> 00:17:40.906\nAgain, projected distribution systems may\nbe also ones that couple things with error\n\n311\n00:17:40.906 --> 00:17:44.144\ngapping that we talked about, where\nthere's no inbound communications and\n\n312\n00:17:44.144 --> 00:17:45.462\nno outbound communications.\n\n313\n00:17:45.462 --> 00:17:46.748\nAny inbound communications or\n\n314\n00:17:46.748 --> 00:17:49.574\noutbound communications might\nhave to be sneaker netted, right?\n\n315\n00:17:49.574 --> 00:17:52.744\nBecause of the fact that there\nisn't a direct link in and\n\n316\n00:17:52.744 --> 00:17:55.000\nout hence the term air gap.\n\n317\n00:17:55.000 --> 00:17:57.940\nSo that's one of those\nyou can see out there and\n\n318\n00:17:57.940 --> 00:18:02.420\nagain just kinda of recap if you ever\nwanna check this out again it is a.\n\n319\n00:18:26.790 --> 00:18:29.720\nSo we do have to worry about\nprotected distribution systems and\n\n320\n00:18:29.720 --> 00:18:33.840\nalso keep in mind that we have other\ntechnologies, like port security that we,\n\n321\n00:18:33.840 --> 00:18:37.720\nwhen we talk about things like 802.1x,\nbase port security.\n\n322\n00:18:37.720 --> 00:18:40.050\nIt's almost like a physical\nsecurity implementation.\n\n323\n00:18:40.050 --> 00:18:42.110\nWe talk about our network drops,\n\n324\n00:18:42.110 --> 00:18:47.650\nprotecting those drop Connections,\nif you will, the RJ-45\n\n325\n00:18:47.650 --> 00:18:51.910\njacks that are scattered throughout\nyour buildings with covers and stuff.\n\n326\n00:18:51.910 --> 00:18:55.820\nSo that somebody can't just walk right\nby and plug right into your system.\n\n327\n00:18:55.820 --> 00:18:59.360\nNow, we said also too that if you have to\nworry about somebody physically in your\n\n328\n00:18:59.360 --> 00:19:02.480\nbuilding plugging into your systems,\nthen chances are you've got more security\n\n329\n00:19:02.480 --> 00:19:06.090\nconcerns than just some of the things that\nwe're talking about But at least it does,\n\n330\n00:19:06.090 --> 00:19:09.750\nfor instance, in things like public\nareas maybe where a kiosk might be\n\n331\n00:19:09.750 --> 00:19:12.230\nmaking sure that somebody\ndoesn't randomly come by and\n\n332\n00:19:12.230 --> 00:19:14.290\njust plug it into any\nsystem that you have.\n\n333\n00:19:14.290 --> 00:19:17.410\n&gt;&gt; Well Wes if you've seen,\nI can't remember exactly where this was\n\n334\n00:19:17.410 --> 00:19:21.595\nlocated but there's a particular prison\n&gt;&gt; When the inmates got really creative\n\n335\n00:19:21.595 --> 00:19:24.215\nand built their homemade computers and\n\n336\n00:19:24.215 --> 00:19:26.395\nthey were able to tap into\ntheir network systems.\n\n337\n00:19:26.395 --> 00:19:30.465\nSo if they heard a distributed protection\nsystem that perhaps those networks\n\n338\n00:19:30.465 --> 00:19:33.770\nadmin would be downloaded and,\nI don't really know how all,\n\n339\n00:19:33.770 --> 00:19:36.000\n&gt;&gt; Played out after the fact.\n\n340\n00:19:36.000 --> 00:19:38.070\n&gt;&gt; Well, it's kind of interesting\ncause it kind of undoes everything\n\n341\n00:19:38.070 --> 00:19:39.570\nthat we're sitting here talking about.\n\n342\n00:19:39.570 --> 00:19:40.600\nGotta have signs, right?\n\n343\n00:19:40.600 --> 00:19:42.940\nGotta have security guards and\nhere, there you go,\n\n344\n00:19:42.940 --> 00:19:47.239\njust as the example goes,\none minor oversight can cause\n\n345\n00:20:03.770 --> 00:20:08.550\nWithout trained professionals to actually\ntap into some kind of fiber optic line cuz\n\n346\n00:20:08.550 --> 00:20:11.980\nyou think about it, what happens, you cut\na fiber optic line, it's not so easy.\n\n347\n00:20:11.980 --> 00:20:15.380\nYou can't just put electrical tape\naround it, splice an end on it, right?\n\n348\n00:20:15.380 --> 00:20:16.580\nYou have to do a lot more than that.\n\n349\n00:20:16.580 --> 00:20:19.440\nSo even fiber optics\nare a good way to go when\n\n350\n00:20:19.440 --> 00:20:21.520\nyou're worried about things like Wiretaps.\n\n351\n00:20:22.780 --> 00:20:26.240\nAll right, so let's see,\nMiss Cherokee what else do we have?\n\n352\n00:20:26.240 --> 00:20:27.980\nWell, we've got some other things, right?\n\n353\n00:20:27.980 --> 00:20:30.070\nThey talk about mantraps, all right?\n\n354\n00:20:30.070 --> 00:20:34.700\nAnd we've kind of mentioned\nmantraps in the past, but\n\n355\n00:20:34.700 --> 00:20:37.280\nhere at Physical Security I\nwant you to think about,\n\n356\n00:20:37.280 --> 00:20:40.810\nyou have typically If you have\na secure environment, right,\n\n357\n00:20:40.810 --> 00:20:44.170\nan environment that you\nneed authorized access.\n\n358\n00:20:44.170 --> 00:20:47.100\nOne of the things that we wanna protect\nagainst are things like piggyback\n\n359\n00:20:47.100 --> 00:20:48.100\nattacks, right.\n\n360\n00:20:48.100 --> 00:20:53.260\nTailgating attacks,\nwhere we have one person is authorized,\n\n361\n00:20:53.260 --> 00:20:56.500\nthey authenticate against whatever\nthe authenticating mechanism is.\n\n362\n00:20:56.500 --> 00:20:57.950\nThe door opens if you will\n\n363\n00:21:22.210 --> 00:21:23.880\nAssisting somebody, right?\n\n364\n00:21:23.880 --> 00:21:25.070\nAnd if I'm assisting somebody,\n\n365\n00:21:25.070 --> 00:21:28.770\nthen that means I'm an accomplice to\nwhatever the unauthorized access is.\n\n366\n00:21:28.770 --> 00:21:31.860\nBut then there's also people\nthat are the victims, right?\n\n367\n00:21:31.860 --> 00:21:33.710\nSocial engineering attacks, right?\n\n368\n00:21:33.710 --> 00:21:37.430\nWell, human nature says that we\nreally wanna help people out, right?\n\n369\n00:21:37.430 --> 00:21:40.980\nIf I seen Cherokee coming up to the front\ndoor and she's got maybe some books or\n\n370\n00:21:40.980 --> 00:21:43.400\nsomething like some notes,\nand she starts to I mean how?\n\n371\n00:21:43.400 --> 00:21:44.470\n&gt;&gt; You're gonna need help.\n\n372\n00:21:44.470 --> 00:21:46.620\nRight?\nBecause it's a human nature, well for\n\n373\n00:21:46.620 --> 00:21:47.340\nmost of us.\n\n374\n00:21:47.340 --> 00:21:48.980\nThere are some people out\nthere that care less.\n\n375\n00:21:48.980 --> 00:21:51.240\n&gt;&gt; Exceptions, yeah.\n&gt;&gt; There's always exceptions in the role\n\n376\n00:21:51.240 --> 00:21:52.100\nthat might.\n\n377\n00:21:52.100 --> 00:21:56.350\nmight tought I'm gonna help her,\nlet me get that door for you.\n\n378\n00:21:56.350 --> 00:21:58.320\nRight?\nWell what if it's the same thing with\n\n379\n00:21:58.320 --> 00:22:00.450\nsomebody that's still a social\nengineering went out maybe\n\n380\n00:22:00.450 --> 00:22:05.340\nthrough a United States postal service\nuniform or IPS uniform and I'm not.\n\n381\n00:22:05.340 --> 00:22:09.710\nSaying anything about UPS, but it's brown\nuniform on, starts to do the same thing,\n\n382\n00:22:09.710 --> 00:22:11.470\nfumbles a bunch coming up.\n\n383\n00:22:11.470 --> 00:22:13.330\nOne observation-\n&gt;&gt; Cherries are very trusted.\n\n384\n00:22:13.330 --> 00:22:14.540\n&gt;&gt; That's right, exactly,\n\n385\n00:22:14.540 --> 00:22:18.830\nso playing on that human nature,\nI allow somebody in, right?\n\n386\n00:22:18.830 --> 00:22:21.580\nBut as part of the security team,\n\n387\n00:22:21.580 --> 00:22:26.330\nwe can stop that if we have\nsomething like a man trap, right?\n\n388\n00:22:26.330 --> 00:22:31.100\nAnd in fact, rather than just sit here and\nexplain, let me show you.\n\n389\n00:22:31.100 --> 00:22:34.730\nI actually got a diagram here,\nright So we have the outside.\n\n390\n00:22:34.730 --> 00:22:38.400\nThe outside if you will is\nbasically the unsecure area right.\n\n391\n00:22:38.400 --> 00:22:39.890\nThat's public access.\n\n392\n00:22:39.890 --> 00:22:42.620\nAnd then what we have to do\nis we go through one door.\n\n393\n00:22:42.620 --> 00:22:45.940\nThat door has to shut with\nlocked behind you, and\n\n394\n00:22:45.940 --> 00:22:50.010\nthen you have another secure door that\nleads into the secure access site.\n\n395\n00:22:50.010 --> 00:22:53.520\nCould have some kind of video monitoring\nsystem, probably does if they're gonna go\n\n396\n00:22:53.520 --> 00:22:56.620\nthis far It's gonna have some\nkind of camera access and\n\n397\n00:22:56.620 --> 00:22:59.670\nmaybe in authenticating\nmechanism on this side, right?\n\n398\n00:22:59.670 --> 00:23:04.070\nMaybe multifactor authentication,\nmaybe you're using a door lock like a,\n\n399\n00:23:04.070 --> 00:23:08.620\nan electronic pin code or maybe even\nbiometrics authentication, right?\n\n400\n00:23:08.620 --> 00:23:10.990\nAnd then you authenticate and\nyou go through this door.\n\n401\n00:23:10.990 --> 00:23:15.220\nOnce that door is shut then\nthe next person can walk there.\n\n402\n00:23:15.220 --> 00:23:18.310\nAgain little bit more\nsophisticated are the man trap,\n\n403\n00:23:18.310 --> 00:23:22.330\nwhen you have a secure area,in which you\ndo not want people being over perform\n\n404\n00:23:22.330 --> 00:23:25.460\nthis tail getting attached,\nthe man trap is what you got to do.\n\n405\n00:23:25.460 --> 00:23:30.120\nA simple implementation of man trap\nthat some of your probably seen before,\n\n406\n00:23:30.120 --> 00:23:34.420\nwhen you go to an amusement park Right,\nwhat does that do?\n\n407\n00:23:34.420 --> 00:23:37.540\nGet, now a lot of times what they're\nusing is to count visiter access.\n\n408\n00:23:37.540 --> 00:23:40.800\nBut you have seen in probably where\nsituations where they do stop somebody\n\n409\n00:23:40.800 --> 00:23:44.370\nfrom going through and a security\nguard says no, you stay right there.\n\n410\n00:23:44.370 --> 00:23:46.940\nAnd whatever the access\ncontrol entry point is,\n\n411\n00:23:46.940 --> 00:23:52.099\nmaybe it's TSA checking off\nyour ticket to the next flight.\n\n412\n00:24:06.790 --> 00:24:08.150\nYou can tell that when it closes.\n\n413\n00:24:08.150 --> 00:24:12.580\nThat's the first unauthorized or\nthe public store access to reopen again.\n\n414\n00:24:12.580 --> 00:24:14.130\nSo we do have that as well.\n\n415\n00:24:14.130 --> 00:24:16.630\nNow, I'm looking at this\nlist that Cherokee.\n\n416\n00:24:16.630 --> 00:24:18.670\nI want a lot more to talk about but\n\n417\n00:24:18.670 --> 00:24:20.740\nI think we're running\na little bit low on time.\n\n418\n00:24:20.740 --> 00:24:21.430\nSounds good Wes.\n\n419\n00:24:21.430 --> 00:24:25.740\nWe covered a lot so far but there\nare numerous security implementations,\n\n420\n00:24:25.740 --> 00:24:28.210\nsecurity controls that\nwe can put into place.\n\n421\n00:24:28.210 --> 00:24:31.970\nSo stay tuned ladies and gentleman for\nthis show we'll go ahead and sign off.\n\n422\n00:24:31.970 --> 00:24:33.270\nI'm your host, Cherokee Boose.\n\n423\n00:24:33.270 --> 00:24:34.120\n&gt;&gt; And I am Wes Bryan.\n\n424\n00:24:34.120 --> 00:24:35.371\n&gt;&gt; See you next time at IT pro TV.\n\n425\n00:24:35.371 --> 00:24:43.605\n[MUSIC]\n\n426\n00:24:43.605 --> 00:24:45.649\nThank you for watching ITProTV.\n\n",
          "vimeoId": "214013535"
        },
        {
          "description": "In this episode, Cherokee and Wes continue to explain how physical security is an integral part of an organizations security posture. They begin by discussing Faraday cages, lock types, biometrics and so much more. Tune in to see what else they recommend for network security.",
          "length": "1961",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-9-2-importance_of_physical_security_pt2-041717-PGM.00_32_27_06.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-9-2-importance_of_physical_security_pt2-041717-PGM.00_32_27_06.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-3-9-2-importance_of_physical_security_pt2-041717-PGM.00_32_27_06.Still001-sm.jpg",
          "title": "Importance of Physical Security Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.111 --> 00:00:02.081\nWelcome to ITProTV,\nI'm your host Don Pezet [CROSSTALK]\n\n2\n00:00:02.081 --> 00:00:06.330\n&gt;&gt; You're watching ITProTV.\n\n3\n00:00:12.120 --> 00:00:16.340\nWelcome to your CompTIA Security + series,\nI'm your show host Cherokee Boose.\n\n4\n00:00:16.340 --> 00:00:19.880\nThis is a continuation of part two,\nwhere we will look at\n\n5\n00:00:19.880 --> 00:00:22.770\ndifferent types of physical security\ncontrols that we can implement.\n\n6\n00:00:22.770 --> 00:00:25.650\nAnd really just focus on\nthe importance of them.\n\n7\n00:00:25.650 --> 00:00:28.250\nAnd with us today, we have Mr.\nWes Bryan back in studios.\n\n8\n00:00:28.250 --> 00:00:29.340\nThank you for joining us, Wes.\n\n9\n00:00:29.340 --> 00:00:30.810\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n10\n00:00:30.810 --> 00:00:33.130\nThat's right,\ncontinuation of physical security.\n\n11\n00:00:33.130 --> 00:00:36.670\nLet's go ahead and we'll jump right back\nin, kind of recap some of the things that\n\n12\n00:00:36.670 --> 00:00:39.720\nwe've already taken care of and\nkind of looked at in the past episode.\n\n13\n00:00:39.720 --> 00:00:43.620\nSo remember in the first episode, we had\nthis diagram that we were looking at and\n\n14\n00:00:43.620 --> 00:00:47.720\nwe were talking about a defense\nin-depth situation, right?\n\n15\n00:00:47.720 --> 00:00:49.870\nAnd so if we could take\na look at the diagram here.\n\n16\n00:00:49.870 --> 00:00:52.390\nWe've got physical security\nwas what we were focusing on.\n\n17\n00:00:52.390 --> 00:00:54.600\nKeep in mind,\na layered defense system, but\n\n18\n00:00:54.600 --> 00:00:59.600\nwe're really talking about outside\nour physical building, right?\n\n19\n00:00:59.600 --> 00:01:04.230\nAnd we looked at some different types\nof physical security implementation\n\n20\n00:01:04.230 --> 00:01:07.340\nin the first episode, we looked at\nthings like lighting, signs, fences and\n\n21\n00:01:07.340 --> 00:01:12.260\ncages, security guards, alarms and\ndifferent things like safes and mantraps.\n\n22\n00:01:12.260 --> 00:01:16.020\nIf this is the first time you've heard\n[LAUGH] about those things, go back and\n\n23\n00:01:16.020 --> 00:01:17.420\nwatch the first episode.\n\n24\n00:01:17.420 --> 00:01:21.040\nAnd then come back here and\nwe can pick up where you left off.\n\n25\n00:01:21.040 --> 00:01:25.350\nNow we are going to talk about\nsomething that's been around for\n\n26\n00:01:25.350 --> 00:01:28.610\na good long while, and\nit's something known as a Faraday cage.\n\n27\n00:01:28.610 --> 00:01:31.060\nA Faraday cages are interesting\nin the fact that.\n\n28\n00:01:31.060 --> 00:01:32.200\n&gt;&gt; That's a cool topic.\n\n29\n00:01:32.200 --> 00:01:35.624\n&gt;&gt; It really is, and what's kinda funny is\nI had to make a market in my notes that\n\n30\n00:01:35.624 --> 00:01:38.420\nsaid, okay, and\nI wanna mention this to you.\n\n31\n00:01:38.420 --> 00:01:40.350\nTime for the tinfoil hat, right?\n\n32\n00:01:40.350 --> 00:01:42.830\nNow we're really getting\na little bit crazy.\n\n33\n00:01:42.830 --> 00:01:44.107\n&gt;&gt; Wes, I know-\n&gt;&gt; With our security controls.\n\n34\n00:01:44.107 --> 00:01:47.457\n&gt;&gt; I know, it is kind of crazy but\nthey do have their place.\n\n35\n00:01:47.457 --> 00:01:50.847\nAnd Wes,\nI know you have watched Breaking Bad and\n\n36\n00:01:50.847 --> 00:01:55.973\nthere's like that spin off that\nare called Saul, but I won't spoil it for\n\n37\n00:01:55.973 --> 00:02:00.990\nyou but there's a funny,\nthe very last episode of season two.\n\n38\n00:02:00.990 --> 00:02:01.760\nCheck that out.\n\n39\n00:02:01.760 --> 00:02:02.420\n&gt;&gt; Most definitely.\n\n40\n00:02:02.420 --> 00:02:05.082\nThere's a gentleman in there that has,\nwhat is it?\n\n41\n00:02:05.082 --> 00:02:08.071\nAn enhanced-\n&gt;&gt; EMI intolerance or\n\n42\n00:02:08.071 --> 00:02:11.211\nsome kind of sensitivity.\n\n43\n00:02:11.211 --> 00:02:16.630\n&gt;&gt; And that's the word I was looking for,\nEMI, electromagnetic interference.\n\n44\n00:02:16.630 --> 00:02:19.067\nNow, when we talk about\nelectromagnetic interference,\n\n45\n00:02:19.067 --> 00:02:21.960\nwe talk about things like\nelectromagnetic emissions, right.\n\n46\n00:02:21.960 --> 00:02:26.751\nWhen we talk about interference, it's\nsomething that hampers the signals that\n\n47\n00:02:26.751 --> 00:02:30.380\nyou were trying to send across\nto our data networks, right?\n\n48\n00:02:30.380 --> 00:02:35.211\nBut when we talk about Faraday cages,\nFaraday cages essentially what they do is\n\n49\n00:02:35.211 --> 00:02:38.818\nthey put a shield around\nsensitive equipment, right, and\n\n50\n00:02:38.818 --> 00:02:43.470\nwhat they prevent is the electromagnetic\nadmission, if you will.\n\n51\n00:02:43.470 --> 00:02:47.318\nNow, you're probably wondered,\nwell, why am I so\n\n52\n00:02:47.318 --> 00:02:52.430\nworried about Electromagnetic admissions,\nif you will?\n\n53\n00:02:52.430 --> 00:02:56.060\nAnd that's because Fields they allow for\n\n54\n00:02:56.060 --> 00:02:57.970\nwhat are known as side-channel attacks,\nright?\n\n55\n00:02:57.970 --> 00:03:03.740\nThey allow us potentially to glean\nthat information that is coming off\n\n56\n00:03:03.740 --> 00:03:09.580\nof things like your displays or even kind\nof finding out what data's going across\n\n57\n00:03:09.580 --> 00:03:14.600\nthings like integrated circuits, just by\ngathering or scraping that information.\n\n58\n00:03:14.600 --> 00:03:17.080\nWhere if we can capture\nenough information,\n\n59\n00:03:18.090 --> 00:03:21.560\nthe attacker can possibly\ndeduce what kind of data\n\n60\n00:03:21.560 --> 00:03:25.130\nis actually being processed at\nthe time which is kind of scary.\n\n61\n00:03:25.130 --> 00:03:27.920\nLike I said,\nthis lens itself to the tinfoil hat.\n\n62\n00:03:27.920 --> 00:03:31.660\nBut it is something that we definitely\nhave to worry about inside of our\n\n63\n00:03:31.660 --> 00:03:32.930\nnetworks today.\n\n64\n00:03:32.930 --> 00:03:36.710\nThere are different attacks,\nagain different side channel attacks.\n\n65\n00:03:36.710 --> 00:03:40.020\nOne of the attacks is actually called,\nhas a specific name and\n\n66\n00:03:40.020 --> 00:03:42.610\nit's called Van Eck phreaking.\n\n67\n00:03:42.610 --> 00:03:45.700\nAnd again it's just a side\nchannel attack where you\n\n68\n00:03:45.700 --> 00:03:49.560\nare able to deduce the information that's\nbeing processed across an integrated\n\n69\n00:03:49.560 --> 00:03:53.520\ncircuit based on the electromagnetic\nfields that you can capture.\n\n70\n00:03:53.520 --> 00:03:58.600\nImplement a Faraday cage and the goal\nis to try to reduce that emanation.\n\n71\n00:03:58.600 --> 00:04:01.640\n&gt;&gt; Now those types of side channel\nattacks, that's another really cool topic,\n\n72\n00:04:01.640 --> 00:04:06.430\nbecause it's just so impressive how\nindividuals are able to extract then,\n\n73\n00:04:06.430 --> 00:04:12.540\njust obtain that information from\nthese very interesting methods.\n\n74\n00:04:12.540 --> 00:04:16.020\n&gt;&gt; Most definitely, in fact, so what are\nsome of the things that are susceptible?\n\n75\n00:04:16.020 --> 00:04:18.635\nThe first thing I think of is my wallet,\nright?\n\n76\n00:04:18.635 --> 00:04:20.090\nWait a second, your wallet?\n\n77\n00:04:20.090 --> 00:04:23.720\nWell, I want you to think of the EMV card,\nthe chip that's on it,\n\n78\n00:04:23.720 --> 00:04:24.800\nI believe it's EMV, right?\n\n79\n00:04:24.800 --> 00:04:27.650\nThe little chip that's on your,\nfor instance, your credit cards.\n\n80\n00:04:27.650 --> 00:04:29.170\n&gt;&gt; Wes, do you have a metal wallet?\n\n81\n00:04:29.170 --> 00:04:30.491\n&gt;&gt; I do not have a metal wallet.\n\n82\n00:04:30.491 --> 00:04:31.688\n&gt;&gt; [LAUGH]\n&gt;&gt; Not yet.\n\n83\n00:04:31.688 --> 00:04:33.550\nI might after I end up\nexplaining all of this.\n\n84\n00:04:33.550 --> 00:04:35.650\nIt might give me a little paranoia, right?\n\n85\n00:04:35.650 --> 00:04:37.963\nJust because I think everybody's after me,\ndoesn't mean they are not,\n\n86\n00:04:37.963 --> 00:04:38.868\njust kidding, guys [LAUGH].\n\n87\n00:04:38.868 --> 00:04:39.707\n&gt;&gt; [LAUGH]\n&gt;&gt; But\n\n88\n00:04:39.707 --> 00:04:41.728\nwe look at things like some\nof the different types,\n\n89\n00:04:41.728 --> 00:04:43.891\nright, just basics of integrated circuits,\nright,\n\n90\n00:04:43.891 --> 00:04:47.080\nbecause we got integrated circuits in\na lot of different things today, right?\n\n91\n00:04:47.080 --> 00:04:50.530\nWe have things like we've talked about,\nSOCs, system on a chip.\n\n92\n00:04:50.530 --> 00:04:53.120\nCherokee, I know you've mentioned\nin the past things like ASICs,\n\n93\n00:04:53.120 --> 00:04:56.230\napplication specific integrated circuitry.\n\n94\n00:04:56.230 --> 00:05:01.030\nWell, if it's performing a specific\napplication functionality,\n\n95\n00:05:01.030 --> 00:05:05.210\nimagine somebody being able to\ncapture the electronic or, again,\n\n96\n00:05:05.210 --> 00:05:08.930\nelectromagnetic fields that\nare coming off of that device, right?\n\n97\n00:05:08.930 --> 00:05:11.950\nSo things like IoTs are very,\nvery susceptible from it.\n\n98\n00:05:11.950 --> 00:05:13.810\nMy cellphone, cellphone's another thing.\n\n99\n00:05:13.810 --> 00:05:17.910\nIn fact, before you think that\nwe're just completely paranoid and\n\n100\n00:05:17.910 --> 00:05:20.190\nthrowing our paranoia back at you,\nlet me show you here.\n\n101\n00:05:20.190 --> 00:05:23.210\nI've actually got something as small as a,\n\n102\n00:05:23.210 --> 00:05:26.430\non my screen here,\na little Faraday cage, right?\n\n103\n00:05:26.430 --> 00:05:30.030\nIt's nothing more than just putting\nyour phone in this little bag, right?\n\n104\n00:05:30.030 --> 00:05:33.090\nAnd what it does is it prevents\nthe things like tracking and\n\n105\n00:05:33.090 --> 00:05:37.850\neavesdropping on those Fields.\n\n106\n00:05:37.850 --> 00:05:41.480\nIt is not something that,\nlike I said, is the tinfoil hat.\n\n107\n00:05:41.480 --> 00:05:42.420\nWell, maybe close.\n\n108\n00:05:42.420 --> 00:05:45.440\nBut at least these tinfoil hats\nare being sold on Amazon, right?\n\n109\n00:05:45.440 --> 00:05:50.610\nSo for instance, you can see things like\nRFID Blocking Faraday Cage Privacy, right?\n\n110\n00:05:50.610 --> 00:05:52.240\nBLACKOUT make some of them, right?\n\n111\n00:05:52.240 --> 00:05:55.585\nEven have things like, for instance,\nmaking your own shields, right?\n\n112\n00:05:55.585 --> 00:05:56.804\nI guess that's a nice fun DIY project.\n\n113\n00:05:56.804 --> 00:05:59.618\n[LAUGH]\n&gt;&gt; [LAUGH] Haven't seen that one on\n\n114\n00:05:59.618 --> 00:06:00.393\nPinterest yet.\n\n115\n00:06:00.393 --> 00:06:01.447\n&gt;&gt; Come on honey.\n\n116\n00:06:01.447 --> 00:06:02.002\n&gt;&gt; But I'm sure it's there.\n\n117\n00:06:02.002 --> 00:06:04.030\n&gt;&gt; I was gonna say that's one for\nthe kids for sure.\n\n118\n00:06:04.030 --> 00:06:07.330\nCome on kids, we're gonna secure\nall of the cellphones today.\n\n119\n00:06:07.330 --> 00:06:11.950\nBut and again keeping things\nlike Key FOBs guarded, right?\n\n120\n00:06:11.950 --> 00:06:14.960\nThings like, and\nI don't have it on me as I look around,\n\n121\n00:06:14.960 --> 00:06:17.740\nthings like your access cards because\nI want you to think about it.\n\n122\n00:06:17.740 --> 00:06:22.210\nIf it's a proximity card, what does\na proximity card get coupled with?\n\n123\n00:06:22.210 --> 00:06:23.980\nA proximity reader, right?\n\n124\n00:06:23.980 --> 00:06:27.200\nWhat says that the proximity reader\nhas to be a trusted one from like\n\n125\n00:06:27.200 --> 00:06:28.460\na company like HID.\n\n126\n00:06:28.460 --> 00:06:30.850\nWhat's to say that it's not a,\nfor instance,\n\n127\n00:06:30.850 --> 00:06:33.190\nlike a credit card skimmer, right?\n\n128\n00:06:33.190 --> 00:06:37.160\nAgain, information like that is\nemanating out and if I can grab,\n\n129\n00:06:37.160 --> 00:06:41.160\nthat's the whole premise\nof the credit card skimmer.\n\n130\n00:06:41.160 --> 00:06:44.254\nIs the fact that you have\na chip that is being sent or\n\n131\n00:06:44.254 --> 00:06:48.539\ninformation's being sent back and\nforth between a reader, right?\n\n132\n00:06:48.539 --> 00:06:52.381\nAnd if I can intercept that information,\nthen we can potentially deduce, well,\n\n133\n00:06:52.381 --> 00:06:55.290\nyour credit card information let\nalone a lot of other things.\n\n134\n00:06:55.290 --> 00:06:59.044\nSo you can see that while we do joke\naround and we're having fun here,\n\n135\n00:06:59.044 --> 00:07:01.247\nthese are something that are serious and\n\n136\n00:07:01.247 --> 00:07:05.360\nthey are implemented on a daily basis\nin certain highly secure areas.\n\n137\n00:07:05.360 --> 00:07:06.000\nFor sure, Wes.\n\n138\n00:07:06.000 --> 00:07:10.310\nI mean, we wouldn't see these items\nbeing sold online if there wasn't really\n\n139\n00:07:10.310 --> 00:07:12.050\na practical use for them.\n\n140\n00:07:12.050 --> 00:07:14.360\nI mean, even if you think about\nour different types of cabling,\n\n141\n00:07:14.360 --> 00:07:19.620\nlike the TEMPEST we've mentioned that\nhave their own manufacturing design\n\n142\n00:07:19.620 --> 00:07:25.230\nto prevent that EMI, the leakage there,\nto prevent any type of eavesdropping.\n\n143\n00:07:25.230 --> 00:07:28.150\n&gt;&gt; And I'm glad you mentioned that\ntoo because it's not called out on\n\n144\n00:07:28.150 --> 00:07:29.880\nthe objectives next to Faraday cage.\n\n145\n00:07:29.880 --> 00:07:31.280\nBut I would almost say that it should be.\n\n146\n00:07:31.280 --> 00:07:32.340\nThe TEMPEST SHIELD, right?\n\n147\n00:07:32.340 --> 00:07:33.450\nDoing the exact same thing, and\n\n148\n00:07:33.450 --> 00:07:37.400\nagain just like Cherokee said, preventing\nelectromagnetic emanation, right?\n\n149\n00:07:37.400 --> 00:07:39.520\nSo also keep in mind,\nI'm glad you did mention it.\n\n150\n00:07:39.520 --> 00:07:43.710\nBecause again, it really isn't in\nthe objectives here at this point.\n\n151\n00:07:43.710 --> 00:07:45.829\nBut it is something that stands\nup next to the Faraday cage.\n\n152\n00:07:45.829 --> 00:07:48.977\nNow, something else that we\nhave to worry about, right?\n\n153\n00:07:48.977 --> 00:07:50.555\nWe've talked about,\nwhat have we talked about?\n\n154\n00:07:50.555 --> 00:07:52.861\nWe've talked about some of\nthe traditional things like lighting.\n\n155\n00:07:52.861 --> 00:07:54.456\nFencing and security guards.\n\n156\n00:07:54.456 --> 00:07:59.704\nBut how about the old tried and true,\nprobably a few thousand years old,\n\n157\n00:07:59.704 --> 00:08:03.480\nbasic physical security implementation.\n\n158\n00:08:03.480 --> 00:08:05.120\nRight, we talk about locks.\n\n159\n00:08:05.120 --> 00:08:09.500\nLocks are definitely something\nthat are important, right now.\n\n160\n00:08:09.500 --> 00:08:12.450\nI don't have to sit here and give you guys\na lecture too much about locks, cuz I'm\n\n161\n00:08:12.450 --> 00:08:16.840\nsure that most of you have seen one or two\nor a hundred of these in your lifetime.\n\n162\n00:08:16.840 --> 00:08:19.350\nBut there are different types of\nlocks that we have to keep in mind.\n\n163\n00:08:19.350 --> 00:08:20.660\nThere are traditional locks and\n\n164\n00:08:20.660 --> 00:08:22.920\nthen there are what are known\nas keyless entry based locks.\n\n165\n00:08:22.920 --> 00:08:24.930\nAnd a lot of times in\nour commercial systems,\n\n166\n00:08:24.930 --> 00:08:27.410\nthat's where you can find things\nlike both of them, right?\n\n167\n00:08:27.410 --> 00:08:29.780\nYour traditional locks and\nkeyless entry systems.\n\n168\n00:08:29.780 --> 00:08:32.670\nSo, when I talk about traditional locks,\nwhat do I mean?\n\n169\n00:08:32.670 --> 00:08:38.180\nAgain, when I say traditional locks,\nI'm talking about lock and key, right?\n\n170\n00:08:38.180 --> 00:08:41.920\nWe're talking about things like deadbolts,\nlike padlocks, right?\n\n171\n00:08:41.920 --> 00:08:46.630\nKnob locks, again just a normal knob\nthat you put the key in and you undo and\n\n172\n00:08:46.630 --> 00:08:48.030\nyou pull open, right.\n\n173\n00:08:48.030 --> 00:08:50.140\nThings like lever locks,\nyou've probably seen it before.\n\n174\n00:08:50.140 --> 00:08:54.460\nIn fact, we got them on every door to\nthe studios within ITProTV, right.\n\n175\n00:08:54.460 --> 00:08:56.290\nThese are your traditional locks.\n\n176\n00:08:56.290 --> 00:09:00.390\nAnd don't overlook them as being\na valid security implementation.\n\n177\n00:09:00.390 --> 00:09:04.662\nHowever, we also have what are known as\nelectronic or keyless entry locks, and\n\n178\n00:09:04.662 --> 00:09:08.058\nthey're also very common inside\nof a security environments.\n\n179\n00:09:08.058 --> 00:09:13.692\nSo for instance, I got one pulled up here,\nthis is the pin lock, right, the keypad,\n\n180\n00:09:13.692 --> 00:09:18.935\nyou may have seen some of these i fact,\nwe have one of these on our server closet,\n\n181\n00:09:18.935 --> 00:09:22.016\nright, not quite the same but\nclose, right.\n\n182\n00:09:22.016 --> 00:09:26.634\nAnd I have to have some kind of numeric\npin to be able to access this latch I've\n\n183\n00:09:26.634 --> 00:09:31.553\nlocked, but I want you to notice\nsomething, notice that there's two, right?\n\n184\n00:09:31.553 --> 00:09:33.260\nThis could be multi-factor.\n\n185\n00:09:33.260 --> 00:09:34.910\nWe could require multi-factor, right?\n\n186\n00:09:34.910 --> 00:09:37.280\nWe could require a key and a pin.\n\n187\n00:09:37.280 --> 00:09:40.950\nIn this case because we had one of these\nin our restaurant that I used to work for\n\n188\n00:09:40.950 --> 00:09:43.240\nwhich is kinda interesting\nleading into the kitchen area,\n\n189\n00:09:43.240 --> 00:09:46.390\nI know that the key lock\nactually bypasses the pin too.\n\n190\n00:09:46.390 --> 00:09:48.860\nSo, this one really isn't multi-factor,\nbut\n\n191\n00:09:48.860 --> 00:09:51.330\nit could implement\nmulti-factor authentication.\n\n192\n00:09:51.330 --> 00:09:53.750\nWe'll talk about that\ncoming up here in a second.\n\n193\n00:09:53.750 --> 00:09:55.940\nAll right, what are some of\nthe other ones that we have?\n\n194\n00:09:55.940 --> 00:09:59.150\nThings like for instance,\ncard door locks, right?\n\n195\n00:09:59.150 --> 00:10:00.860\nYou may have seen these before, right?\n\n196\n00:10:00.860 --> 00:10:03.200\nA card that is swiped across the top.\n\n197\n00:10:03.200 --> 00:10:05.750\nNow, this is a keyless lock, all right?\n\n198\n00:10:05.750 --> 00:10:10.420\nBut we have to be careful on what\ntype of card lock it is, right?\n\n199\n00:10:10.420 --> 00:10:11.960\nIf it's a smart card type lock,\n\n200\n00:10:11.960 --> 00:10:14.680\nthen typically what it's gonna\nhave is some kinda token.\n\n201\n00:10:14.680 --> 00:10:19.130\nA token that contains user authentication\nand identification information, right?\n\n202\n00:10:19.130 --> 00:10:22.810\nNow, let's be careful what identification\nand authentication, right?\n\n203\n00:10:22.810 --> 00:10:26.420\nAuthentication is just a validation\nof a set of credentials, right?\n\n204\n00:10:26.420 --> 00:10:29.400\nIdentification is making sure that\nthe person that holds those credentials\n\n205\n00:10:29.400 --> 00:10:32.130\nis the true person that should hold those,\nokay?\n\n206\n00:10:33.360 --> 00:10:37.330\nThey could be contact-based,\nright words actually a magnetic strip\n\n207\n00:10:37.330 --> 00:10:41.010\nthat has to be slid across kinda like\na credit card reader, if you will.\n\n208\n00:10:41.010 --> 00:10:43.018\nThey could be proximity cards.\n\n209\n00:10:43.018 --> 00:10:45.910\nBasically, used on RFID where\nthere are contact list and\n\n210\n00:10:45.910 --> 00:10:47.920\nyou just get close to them.\n\n211\n00:10:47.920 --> 00:10:50.360\nThat goes back to the priority\ncage that we're talking about and\n\n212\n00:10:50.360 --> 00:10:53.390\nthings like tempest to make\nsure that if it is proximity,\n\n213\n00:10:53.390 --> 00:10:55.590\nwhat if I can get in\nbetween the proximity card?\n\n214\n00:10:55.590 --> 00:10:58.400\nWell, I can probably scrape some of\nthat information if the attacker\n\n215\n00:10:58.400 --> 00:11:00.250\nhas the knowledge to do so.\n\n216\n00:11:00.250 --> 00:11:05.570\nAll right, so\nagain even these contactless cards aren't\n\n217\n00:11:05.570 --> 00:11:08.140\nimmune from different types of attacks.\n\n218\n00:11:08.140 --> 00:11:11.440\n&gt;&gt; And you know, Wes, I just think it's\nonly a matter of time before we start\n\n219\n00:11:11.440 --> 00:11:16.600\nseeing more of kinda of like NFC-type\ncompromises on the forefront here, because\n\n220\n00:11:16.600 --> 00:11:22.000\nit's being used more often so of course\nit always kind of comes after that but.\n\n221\n00:11:22.000 --> 00:11:24.620\n&gt;&gt; That's right and that's why they\nstepped it up a little bit more with\n\n222\n00:11:24.620 --> 00:11:27.400\nthings like for instance,\nbiometrics authentication.\n\n223\n00:11:27.400 --> 00:11:29.970\nAll right, when we talk about\nbiometrics-based doors, right,\n\n224\n00:11:29.970 --> 00:11:33.040\nwhat are we talking about when\nwe say biometrics, right?\n\n225\n00:11:33.040 --> 00:11:34.240\nSome of the basic ones.\n\n226\n00:11:34.240 --> 00:11:37.160\nMaybe you've probably seen a couple\nof these even built into things like\n\n227\n00:11:37.160 --> 00:11:39.120\nyour smart phones and\nyour PCs today, right,\n\n228\n00:11:39.120 --> 00:11:42.900\nthings like facial recognition,\nface recognition, voice recognition.\n\n229\n00:11:44.010 --> 00:11:46.120\nRelatively easy sometimes authorities,\n\n230\n00:11:46.120 --> 00:11:48.920\nbut they are a form of\nbiometrics authentication.\n\n231\n00:11:48.920 --> 00:11:52.000\nRemember, biometrics is about\nsomething you are, right?\n\n232\n00:11:52.000 --> 00:11:54.660\nSome physical aspect of yourself, right?\n\n233\n00:11:54.660 --> 00:11:57.569\nMy voice is a physical aspect of myself,\nright?\n\n234\n00:11:58.610 --> 00:12:01.540\nMy facial recognition,\nface, if you will, for\n\n235\n00:12:01.540 --> 00:12:02.530\nbetter or worse-\n&gt;&gt; [LAUGH]\n\n236\n00:12:02.530 --> 00:12:05.260\n&gt;&gt; Is a physical aspect of myself that we\n\n237\n00:12:05.260 --> 00:12:07.420\ncan use as authentication.\n\n238\n00:12:07.420 --> 00:12:10.980\nYou can use something, in fact, I've\ngot one of these systems right here and\n\n239\n00:12:10.980 --> 00:12:13.960\nsometimes they're not, they aren't cheap.\n\n240\n00:12:13.960 --> 00:12:17.231\nThis one isn't so bad, right, but\na multi-bio face recognition and\n\n241\n00:12:17.231 --> 00:12:19.580\nfingerprint recognition system, right?\n\n242\n00:12:19.580 --> 00:12:23.830\nWhere you can see that this young lady is\nusing a picture, again, in a database,\n\n243\n00:12:23.830 --> 00:12:27.170\nand the capturing of\na current picture of herself\n\n244\n00:12:27.170 --> 00:12:29.710\nin order to login to some kind of system.\n\n245\n00:12:29.710 --> 00:12:32.970\nBut this actually does multi-factor,\nbecause it doesn't just do\n\n246\n00:12:32.970 --> 00:12:36.320\nfacial recognition, you can see the little\nfingerprint scanner here too, so\n\n247\n00:12:36.320 --> 00:12:39.420\nthat's not really multi-factor though,\nwe gotta be careful with that.\n\n248\n00:12:39.420 --> 00:12:40.075\nLet me tell you why.\n\n249\n00:12:40.075 --> 00:12:44.010\nMulti-factor's combining The three\nauthentication factors, right?\n\n250\n00:12:44.010 --> 00:12:47.180\nSomething you have, which can be\na key fob, could be a smart card.\n\n251\n00:12:47.180 --> 00:12:50.710\nSomething you know, a pin,\na password, username, if you will.\n\n252\n00:12:50.710 --> 00:12:53.170\nBiometrics is something you are,\nall right?\n\n253\n00:12:53.170 --> 00:12:56.380\nThe problem is, I gotta correct this,\nthis isn't multi-factor authentication,\n\n254\n00:12:56.380 --> 00:13:01.340\nbecause it's two of the same\nauthentication factors, right?\n\n255\n00:13:01.340 --> 00:13:03.750\nIt's something you are,\na facial recognition.\n\n256\n00:13:03.750 --> 00:13:06.340\nAnd something you are with\na fingerprint scanner.\n\n257\n00:13:06.340 --> 00:13:09.480\nIf this were multi-factor,\nthere might be some kind of PIN code,\n\n258\n00:13:09.480 --> 00:13:12.850\nPIN pad on here, where she's\ngonna use facial recognition or\n\n259\n00:13:12.850 --> 00:13:16.440\na fingerprint scanner, coupled with\nsomething she knows and a PIN.\n\n260\n00:13:16.440 --> 00:13:18.040\nRight?\nGets a little bit more expensive, but\n\n261\n00:13:18.040 --> 00:13:23.280\nin secure areas, a lot of times you'll see\nthat these are multi-factor authentication\n\n262\n00:13:23.280 --> 00:13:28.460\nmechanisms, that could use two or\nmore of those authentication types.\n\n263\n00:13:28.460 --> 00:13:32.650\n&gt;&gt; We live in such an exciting time,\nespecially even on the consumer side of\n\n264\n00:13:32.650 --> 00:13:35.950\nbiometrics has really improved\nover the last few years.\n\n265\n00:13:35.950 --> 00:13:39.310\nAnd as a matter of fact, I just recently\nhad made a trip out to Microsoft.\n\n266\n00:13:39.310 --> 00:13:42.693\nThey're working on so many cool\ngesture type analytics and movements.\n\n267\n00:13:42.693 --> 00:13:43.911\nAt the end of this month,\n\n268\n00:13:43.911 --> 00:13:47.392\nwe actually have someone coming in\nto explain their newer technology,\n\n269\n00:13:47.392 --> 00:13:51.550\ncalled Windows Hello, which is a pretty\ncool feature, so I can't wait for that.\n\n270\n00:13:51.550 --> 00:13:52.160\n&gt;&gt; Most definitely.\n\n271\n00:13:52.160 --> 00:13:55.780\nAnd they've definitely come a long ways in\nwhat is the Windows biometric framework\n\n272\n00:13:55.780 --> 00:13:56.900\nthat they first started.\n\n273\n00:13:56.900 --> 00:14:00.950\nI believe they started at in Windows 8,\nI think there was\n\n274\n00:14:00.950 --> 00:14:03.750\nremnants of it in Windows 7, but yeah,\nthey've definitely come a long way.\n\n275\n00:14:03.750 --> 00:14:05.140\nSo I look forward to seeing that,\n\n276\n00:14:05.140 --> 00:14:08.054\nI'm gonna have to watch that\nepisode [LAUGH] myself.\n\n277\n00:14:08.054 --> 00:14:12.855\nNext thing we kinda look at\nare things like, for instance,\n\n278\n00:14:12.855 --> 00:14:16.234\nthey talk about barricades and bouyers.\n\n279\n00:14:16.234 --> 00:14:18.510\nNow barricades are very,\nvery important, right?\n\n280\n00:14:18.510 --> 00:14:21.500\nAnd one of the things we have to keep\nin mind is that barricades can do\n\n281\n00:14:21.500 --> 00:14:22.430\na couple of things, right?\n\n282\n00:14:22.430 --> 00:14:25.700\nNot only can they, obviously,\nstop traffic from coming in, but\n\n283\n00:14:25.700 --> 00:14:27.010\nthey can also help to guide traffic.\n\n284\n00:14:28.630 --> 00:14:31.860\nThey prevent things like\nvehicular intrusions, right?\n\n285\n00:14:31.860 --> 00:14:37.100\nA lot of times barricades if\nyou will are crash resistant or\n\n286\n00:14:37.100 --> 00:14:39.740\nup to a certain scratch rating, right?\n\n287\n00:14:39.740 --> 00:14:41.820\n&gt;&gt; Schools, armouries,\nyou see this big bolders or\n\n288\n00:14:41.820 --> 00:14:44.280\nany kind of like a, what are those?\n\n289\n00:14:44.280 --> 00:14:46.290\nWhat are the concrete ones?\n\n290\n00:14:46.290 --> 00:14:49.680\n&gt;&gt; Yes, definitely and\nthose are called Jersey barriers.\n\n291\n00:14:49.680 --> 00:14:56.520\nIn fact I've got a picture of\na Jersey barrier up here too, right?\n\n292\n00:14:56.520 --> 00:14:59.240\nThey can be concrete molds,\nthey can also be you know plastic.\n\n293\n00:14:59.240 --> 00:15:01.030\nAnd again plastic is gonna be more for\na guidance,\n\n294\n00:15:01.030 --> 00:15:03.005\nit really isn't gonna stop anything.\n\n295\n00:15:03.005 --> 00:15:06.860\nBut,they could be on hydraulic lifts too.\n\n296\n00:15:06.860 --> 00:15:10.920\nAnd in fact I went out to\nthe airforce base in Montgomery,\n\n297\n00:15:10.920 --> 00:15:12.410\nAlabama, Gunter Air Force Base.\n\n298\n00:15:12.410 --> 00:15:16.560\nAnd they had these hydraulic ones that\nwere put down during the day times.\n\n299\n00:15:16.560 --> 00:15:19.620\nBut then when they didn't want people\nin certain areas they would raise and\n\n300\n00:15:19.620 --> 00:15:22.510\nthey would lift them up during\ncertain hours of the day.\n\n301\n00:15:22.510 --> 00:15:25.800\nSome of them would be always on and\nsome of them would be always down.\n\n302\n00:15:25.800 --> 00:15:29.140\nAnd these would withstand\nthe impact of a freight train.\n\n303\n00:15:29.140 --> 00:15:29.710\n&gt;&gt; Wow.\n\n304\n00:15:29.710 --> 00:15:30.820\n&gt;&gt; Going full speed at them.\n\n305\n00:15:30.820 --> 00:15:31.820\n&gt;&gt; [LAUGH] That's pretty strong.\n\n306\n00:15:31.820 --> 00:15:34.950\n&gt;&gt; Yeah, so you could see that they,\nagain they could be static.\n\n307\n00:15:34.950 --> 00:15:38.470\nLike this one right here is a static\nbarricade that could be hydraulic, right?\n\n308\n00:15:38.470 --> 00:15:41.650\nThey, the Military Air Force\nbase that I was on,\n\n309\n00:15:41.650 --> 00:15:43.800\nthey actually use the combination of both,\nright.\n\n310\n00:15:43.800 --> 00:15:44.585\nThey also have ramps too.\n\n311\n00:15:44.585 --> 00:15:48.346\nAnd the ramps would come up and they would\nbe facing basically the oncoming traffic.\n\n312\n00:15:48.346 --> 00:15:52.689\nSo that if you hit one of these\nBasically gonna sever your car in half.\n\n313\n00:15:52.689 --> 00:15:57.965\nBut, again, they can be crash rated\nto withstand those vehicular impacts,\n\n314\n00:15:57.965 --> 00:16:01.825\nor in cases like military,\ntrain impacts, too [LAUGH].\n\n315\n00:16:01.825 --> 00:16:06.250\nSo they definitely have a place\nin our physical security,\n\n316\n00:16:06.250 --> 00:16:09.370\nespecially at controlled access\npoints where we worry about vehicles\n\n317\n00:16:09.370 --> 00:16:10.717\ncoming in and leaving the building.\n\n318\n00:16:10.717 --> 00:16:13.170\nIt can be coupled with your fences and\nsecurity guards.\n\n319\n00:16:13.170 --> 00:16:16.810\nSo you can start to see\na tying together of\n\n320\n00:16:16.810 --> 00:16:20.760\nsome of these pieces that we've been\ntalking over the past couple of episodes.\n\n321\n00:16:21.860 --> 00:16:25.280\nAll right, so the next thing that they\nmention, too, are things like tokens and\n\n322\n00:16:25.280 --> 00:16:26.150\ncards, all right.\n\n323\n00:16:26.150 --> 00:16:27.280\nWhen we talk about tokens and\n\n324\n00:16:27.280 --> 00:16:30.410\ncards, we've kind of already talked about\nthem as we've gone through the episode.\n\n325\n00:16:30.410 --> 00:16:34.633\nWhen we think of things like key fob\naccess, smart card authentication,\n\n326\n00:16:34.633 --> 00:16:37.643\nkeep in mind that those\nhave little tokens, right.\n\n327\n00:16:37.643 --> 00:16:41.880\nThey can be hardware-based tokens,\nthey can be software-based tokens.\n\n328\n00:16:41.880 --> 00:16:43.981\nI'll give you an example of\na software-based token, right.\n\n329\n00:16:43.981 --> 00:16:47.744\nFor instance, when I log in to\nan Active Directory domain,\n\n330\n00:16:47.744 --> 00:16:50.690\nI am basically given\nan authorization token.\n\n331\n00:16:50.690 --> 00:16:53.478\nAnd we'll talk about things like\nKerberos a little bit later,\n\n332\n00:16:53.478 --> 00:16:55.433\nthat's a software-based token, right.\n\n333\n00:16:55.433 --> 00:16:58.364\nIt resides in Active Directory and\non my computer, if you will,\n\n334\n00:16:58.364 --> 00:16:59.910\nwhile I'm logged in.\n\n335\n00:16:59.910 --> 00:17:03.473\nA hardware-based token would be one that's\nin, for instance, like a key fob, right.\n\n336\n00:17:03.473 --> 00:17:06.350\nA little bit of information that\ncontains identifiable information.\n\n337\n00:17:06.350 --> 00:17:08.952\nIt could even contain things\nlike your authorization levels,\n\n338\n00:17:08.952 --> 00:17:10.972\ndepending on where you're accessing,\nright.\n\n339\n00:17:10.972 --> 00:17:14.260\nIt could be built into cards, it could\nbe built into key fobs, if you will.\n\n340\n00:17:14.260 --> 00:17:18.100\nSo we do have that, so\nkeep in mind tokens and cards.\n\n341\n00:17:18.100 --> 00:17:20.080\nThe other thing I wanna\nmention about tokens,\n\n342\n00:17:20.080 --> 00:17:22.295\njust in case it comes up on the exam.\n\n343\n00:17:22.295 --> 00:17:24.035\nIf you're gonna do smart\ncard authentication,\n\n344\n00:17:24.035 --> 00:17:28.787\none of the protocols that you have to use\nis what is known as EAP-TLS, all right.\n\n345\n00:17:28.787 --> 00:17:31.555\nThe Extensible Authentication\nProtocol Transport Layer Security,\n\n346\n00:17:31.555 --> 00:17:34.625\nit's one of the ways that we do\ncertificate-based authentication,\n\n347\n00:17:34.625 --> 00:17:37.270\nas well as token-based or\nsmart card authentication.\n\n348\n00:17:37.270 --> 00:17:38.940\nSo just kind of throwing\nthat one out there for\n\n349\n00:17:38.940 --> 00:17:44.020\nthe exam just in case it comes up because\nin the context of physical security,\n\n350\n00:17:44.020 --> 00:17:48.010\nif we are using token cards,\nthere is a protocol that supports that.\n\n351\n00:17:48.010 --> 00:17:51.750\nAll right, so other things that we have,\nenvironmental controls, right.\n\n352\n00:17:51.750 --> 00:17:53.760\nWhen we talk about our\nenvironmental controls,\n\n353\n00:17:53.760 --> 00:17:56.110\nwe have talked pretty\nextensively about HVAC systems.\n\n354\n00:17:56.110 --> 00:17:59.313\nHowever, keep in mind HVAC\nsystems have to be monitored and\n\n355\n00:17:59.313 --> 00:18:02.920\nprotected, as we've talked\nabout in other episodes.\n\n356\n00:18:02.920 --> 00:18:05.530\nYou have to worry about things\nlike copper thieves, if you will.\n\n357\n00:18:05.530 --> 00:18:09.818\nIf you're giving a third party remote\naccess, I think it was Cherokee,\n\n358\n00:18:09.818 --> 00:18:13.276\nyou were mentioning the Target\nattack that had happened.\n\n359\n00:18:13.276 --> 00:18:16.657\nIt was a big monetary loss where what\nthey were doing is they had a third\n\n360\n00:18:16.657 --> 00:18:20.056\nparty system that was monitoring,\nif you will, their HVAC system.\n\n361\n00:18:20.056 --> 00:18:24.388\nAnd they gave them remote access,\nunsupervised remote access, and\n\n362\n00:18:24.388 --> 00:18:27.370\nit ended being an avenue for attack.\n\n363\n00:18:27.370 --> 00:18:31.110\nSo we do have to keep\nthose systems secure.\n\n364\n00:18:31.110 --> 00:18:32.620\nAnd we do need those systems, too.\n\n365\n00:18:32.620 --> 00:18:36.760\nSo keep in mind that with your heating,\ncontrol, ventilation and AC, we're talking\n\n366\n00:18:36.760 --> 00:18:41.530\nabout keeping your servers from going into\nthermal temperature shutdowns, right.\n\n367\n00:18:41.530 --> 00:18:44.880\nAnd if you think about that,\nthat can corrupt your information and\n\n368\n00:18:44.880 --> 00:18:46.950\nthat can lead to an availability loss,\nright.\n\n369\n00:18:46.950 --> 00:18:48.280\nSo right now-\n&gt;&gt; Integrity also.\n\n370\n00:18:48.280 --> 00:18:52.810\n&gt;&gt; That's right, yeah, so if you corrupt\nyour information, the integrity loss,\n\n371\n00:18:52.810 --> 00:18:56.530\nthere's one of the CIA gone,\nCIA triad gone, right.\n\n372\n00:18:56.530 --> 00:18:58.520\nThen if the servers shut down,\n\n373\n00:18:58.520 --> 00:19:00.710\nnow we got the availability\npart that we've lost, too.\n\n374\n00:19:00.710 --> 00:19:02.823\nSo environmental controls-\n&gt;&gt; Not a good day at the office.\n\n375\n00:19:02.823 --> 00:19:03.357\n&gt;&gt; No it's not.\n\n376\n00:19:03.357 --> 00:19:05.090\n[LAUGH]\n&gt;&gt; Remember, like I said,\n\n377\n00:19:05.090 --> 00:19:07.070\nas long as the printer's working,\nthen you can print your resume.\n\n378\n00:19:08.240 --> 00:19:09.780\nWe gotta keep in mind things like, for\n\n379\n00:19:09.780 --> 00:19:12.850\ninstance, static charge\ninside of our server closets.\n\n380\n00:19:12.850 --> 00:19:17.385\nYou might think, well, wait a second, Wes,\nthis really isn't an A+ class, right.\n\n381\n00:19:17.385 --> 00:19:18.942\nWell, no, you're right, it's not.\n\n382\n00:19:18.942 --> 00:19:23.414\nBut electrostatic discharge is just as\nimportant to prevent inside of your server\n\n383\n00:19:23.414 --> 00:19:27.040\nclosets at the server level as it\nis when you talk about doing things\n\n384\n00:19:27.040 --> 00:19:31.162\nlike help desk and break, fix\ntechnicians working on computers, right.\n\n385\n00:19:31.162 --> 00:19:34.860\nI have to worry about moisture,\nalso, getting too much\n\n386\n00:19:34.860 --> 00:19:39.125\nmoisture inside of a server closet because\nlet's look at the spectrum, right.\n\n387\n00:19:39.125 --> 00:19:41.770\nToo dry air leads to\nstatic charge generation,\n\n388\n00:19:41.770 --> 00:19:45.650\nthat leads to ESD, right, and\nthat's static charge damage.\n\n389\n00:19:45.650 --> 00:19:49.280\nAnd it's very hard to detect that,\nor fix it for that matter.\n\n390\n00:19:49.280 --> 00:19:50.130\n&gt;&gt; Here in Florida.\n\n391\n00:19:50.130 --> 00:19:50.745\n&gt;&gt; That's right.\n\n392\n00:19:50.745 --> 00:19:52.660\n&gt;&gt; [LAUGH] We have the opposite problem.\n\n393\n00:19:52.660 --> 00:19:53.420\n&gt;&gt; Yeah, most definitely.\n\n394\n00:19:53.420 --> 00:19:56.023\nSo the opposite problem is\ntoo much moisture, right.\n\n395\n00:19:56.023 --> 00:19:57.883\nWe're very humid, right.\n\n396\n00:19:57.883 --> 00:20:00.030\nAnd like Cherokee said,\nif you go out to Florida,\n\n397\n00:20:00.030 --> 00:20:02.535\nat any point of the summer you\ncan probably open the door and\n\n398\n00:20:02.535 --> 00:20:05.350\nyou can feel the humidity\njust hit you in the face.\n\n399\n00:20:05.350 --> 00:20:08.710\nWell, we don't want that humidity\ninside of our server closets either.\n\n400\n00:20:08.710 --> 00:20:11.510\nSo that's why it is important to\nkeep in mind that we also need to\n\n401\n00:20:11.510 --> 00:20:15.570\nmaintain a level of moisture,\nright, making sure that, again,\n\n402\n00:20:15.570 --> 00:20:17.660\nwe don't have static charge generation.\n\n403\n00:20:17.660 --> 00:20:22.010\nBut at the same time, too much humidity\nleads to condensation and short circuits.\n\n404\n00:20:22.010 --> 00:20:24.022\n&gt;&gt; Corrosion,\nall sorts of good stuff [LAUGH].\n\n405\n00:20:24.022 --> 00:20:25.111\n&gt;&gt; Corrosion, most definitely.\n\n406\n00:20:25.111 --> 00:20:28.233\nSo what are some of the other things that\nwe do inside of our environment controls?\n\n407\n00:20:28.233 --> 00:20:29.911\nWe use things like hot aisles,\ncold aisles.\n\n408\n00:20:29.911 --> 00:20:31.607\nI got a little diagram here.\n\n409\n00:20:31.607 --> 00:20:33.620\nAnd if you look inside of a data center,\n\n410\n00:20:33.620 --> 00:20:36.429\na lot of times what you have\nare raised floors, right.\n\n411\n00:20:36.429 --> 00:20:39.188\nAnd they strategically place vents and\n\n412\n00:20:39.188 --> 00:20:44.790\nventilation systems across the data center\nto move the air through the aisles,\n\n413\n00:20:44.790 --> 00:20:48.813\nbasically dissipating hot air and\nbringing in cold air.\n\n414\n00:20:48.813 --> 00:20:53.725\nKeeping that in mind, it's a strategic\nplacing to move the hot air and\n\n415\n00:20:53.725 --> 00:20:56.900\ncold air through the aisles\nof a data center.\n\n416\n00:20:56.900 --> 00:20:58.930\nThat's why we call it hot aisle,\ncold aisle, and\n\n417\n00:20:58.930 --> 00:21:01.140\nit's something to be aware of on the exam.\n\n418\n00:21:01.140 --> 00:21:02.640\n&gt;&gt; Well, Wes, like you had mentioned,\n\n419\n00:21:02.640 --> 00:21:07.170\nkind of just touching back on some of\nthose A+ objectives, the reason that we\n\n420\n00:21:07.170 --> 00:21:10.460\nmight want to mention them again is\nbecause the same concepts apply.\n\n421\n00:21:10.460 --> 00:21:15.086\nAnd even in A+, you think about\nthe chassis design of a desktop computer,\n\n422\n00:21:15.086 --> 00:21:18.400\npulling that cold air to\ncool those warm components.\n\n423\n00:21:18.400 --> 00:21:20.604\nSame thing with the design of servers,\nright.\n\n424\n00:21:20.604 --> 00:21:25.947\nSo by placing them strategically like,\nWes had said, we can use science\n\n425\n00:21:25.947 --> 00:21:31.392\nto just really help cool down the server\nroom by placing them face to face.\n\n426\n00:21:31.392 --> 00:21:34.976\nAnd then that hot air's blowing out\nthe back, creating those hot aisles.\n\n427\n00:21:34.976 --> 00:21:37.060\nYeah, science, it's amazing [LAUGH].\n\n428\n00:21:37.060 --> 00:21:42.040\n&gt;&gt; Most definitely, and\nyou've gotta keep your server closets,\n\n429\n00:21:42.040 --> 00:21:46.016\nyou got to keep the environment safe,\nif you will.\n\n430\n00:21:46.016 --> 00:21:49.643\nOther things they call out, too,\nare fire suppression, right.\n\n431\n00:21:49.643 --> 00:21:51.687\nWe have to have fire suppression systems.\n\n432\n00:21:51.687 --> 00:21:54.641\nAnd there are a lot of different\nstandards that are out there.\n\n433\n00:21:54.641 --> 00:21:58.311\nIn fact, one, the National FIre\nProtection Agency, has one.\n\n434\n00:21:58.311 --> 00:22:00.646\nIt's called Nafta 75.\n\n435\n00:22:00.646 --> 00:22:03.771\nIn fact I've got kind of a documentation\nhere if you ever wanna check some\n\n436\n00:22:03.771 --> 00:22:06.400\ninformation out and\nkinda look at the different standards.\n\n437\n00:22:06.400 --> 00:22:09.510\nThis is the Standard for Fire Protection\nof Information Technology Equipment.\n\n438\n00:22:09.510 --> 00:22:13.780\nA lot of good information in there, and\nbasically just covers the requirements for\n\n439\n00:22:13.780 --> 00:22:16.120\nprotection of information\ntechnology equipment.\n\n440\n00:22:16.120 --> 00:22:18.397\nIncluding things like\nthe associated effects,\n\n441\n00:22:18.397 --> 00:22:20.791\nthere's the corrosion\nthat you were mentioning.\n\n442\n00:22:20.791 --> 00:22:21.729\nSmoke, right.\n\n443\n00:22:21.729 --> 00:22:23.040\nFor instance, heat and water.\n\n444\n00:22:23.040 --> 00:22:27.760\nSo it is important to make sure that\nwe have fire prevention systems inside\n\n445\n00:22:27.760 --> 00:22:29.298\nof our systems, as well.\n\n446\n00:22:29.298 --> 00:22:34.300\nAll right, there are also some\nother ones out there, too.\n\n447\n00:22:34.300 --> 00:22:39.185\nFor instance, you can have managed systems\nwhen it comes to environmental controls.\n\n448\n00:22:39.185 --> 00:22:42.312\nThere's one out there\nthat is called AVTECH.\n\n449\n00:22:42.312 --> 00:22:47.933\nAVTECH is one that does third\nparty monitoring, for instance.\n\n450\n00:22:47.933 --> 00:22:52.439\nIf we can pull this one up here,\ntoo, you can products and stuff for\n\n451\n00:22:52.439 --> 00:22:58.170\nenvironment monitoring of your security,\nor your data centers, if you will.\n\n452\n00:22:58.170 --> 00:23:01.900\nAnd then it also couples with third\nparty monitoring systems, as well.\n\n453\n00:23:01.900 --> 00:23:03.268\nThere are other things out there, too.\n\n454\n00:23:03.268 --> 00:23:08.926\nYou have, for instance, Cisco has some\nvendor documentation as well as how to\n\n455\n00:23:08.926 --> 00:23:14.774\ngo about implementing your network\nequipment inside of data centers, as well.\n\n456\n00:23:14.774 --> 00:23:18.837\nSo also follow things like your vendor\nrecommendations when it comes to\n\n457\n00:23:18.837 --> 00:23:22.031\nmaintaining the equipment\ninside of your data center.\n\n458\n00:23:22.031 --> 00:23:23.450\nAll right, so let's see,\n\n459\n00:23:23.450 --> 00:23:27.353\nwe've got a few more things that we need\nto talk about right here at the end.\n\n460\n00:23:27.353 --> 00:23:29.476\nWe talked about things like cable locks.\n\n461\n00:23:29.476 --> 00:23:33.542\nCable locks are important to make\nsure that you have on things\n\n462\n00:23:33.542 --> 00:23:37.490\nlike your mobile devices and\nyour laptops, right.\n\n463\n00:23:37.490 --> 00:23:42.450\nFor instance, Cherokee and my laptop,\nwe have to watch the proverbial five\n\n464\n00:23:42.450 --> 00:23:45.850\nfinger discount, right, somebody grabbing\nthese devices and walking out with them.\n\n465\n00:23:45.850 --> 00:23:48.490\nAnd what the cable locks\nend up allowing us to do-\n\n466\n00:23:48.490 --> 00:23:49.347\n&gt;&gt; Like a Kensington lock?\n\n467\n00:23:49.347 --> 00:23:50.326\n&gt;&gt; Yeah, the Kensington lock.\n\n468\n00:23:50.326 --> 00:23:54.411\nThere's a few of them like Kensington\nlock, Targus has them out there.\n\n469\n00:23:54.411 --> 00:23:58.728\nIn fact, the traditional Kensington lock,\n\n470\n00:23:58.728 --> 00:24:03.280\nlet's see if I can Find\none of those real quick.\n\n471\n00:24:04.770 --> 00:24:06.960\nYes, can I-\n&gt;&gt; Ken, what is this port for?\n\n472\n00:24:06.960 --> 00:24:07.920\nNothing fits here.\n\n473\n00:24:07.920 --> 00:24:12.110\n&gt;&gt; Yes, yes, yes, the Kensington Lock\nhas been around for awhile, and\n\n474\n00:24:12.110 --> 00:24:18.350\nit's even got Cherokee talking about\na special port on the computer.\n\n475\n00:24:18.350 --> 00:24:23.160\nFor instance,\nlet me show you an example of one here.\n\n476\n00:24:23.160 --> 00:24:27.850\nA Dell lock here, it's not very,\nthere we go, right.\n\n477\n00:24:27.850 --> 00:24:31.118\nYou can see an example of one\nright here as well, right?\n\n478\n00:24:31.118 --> 00:24:35.069\nJust a combination lock, and then you have\na little port on the side of the computer\n\n479\n00:24:35.069 --> 00:24:36.797\nthat this fits in specifically to.\n\n480\n00:24:36.797 --> 00:24:39.200\nNow, what does this do?\n\n481\n00:24:39.200 --> 00:24:44.450\nI mean, could I grab that laptop and\nrip that lock right out?\n\n482\n00:24:44.450 --> 00:24:48.270\nWell, yes, I could, but chances are you're\ngonna make everybody in the building\n\n483\n00:24:48.270 --> 00:24:48.890\naware\n&gt;&gt; [LAUGH]\n\n484\n00:24:48.890 --> 00:24:49.610\n&gt;&gt; That you just\n\n485\n00:24:49.610 --> 00:24:51.410\nripped that computer off of that lock.\n\n486\n00:24:51.410 --> 00:24:54.790\n&gt;&gt; Like that guy who smashed all of\nthe iPad faces in the Apple store,\n\n487\n00:24:54.790 --> 00:24:55.470\ndid you see that?\n\n488\n00:24:55.470 --> 00:24:56.652\n&gt;&gt; Yes, most definitely.\n\n489\n00:24:56.652 --> 00:24:58.637\n&gt;&gt; So,\nthis is not gonna prevent against that.\n\n490\n00:24:58.637 --> 00:25:02.250\n&gt;&gt; No, it will not prevent against damage,\nand it certainly won't prevent against\n\n491\n00:25:02.250 --> 00:25:07.680\nsomebody that is very,\nvery dead set on taking that device.\n\n492\n00:25:07.680 --> 00:25:11.080\nHere's an example of another\nKensington lock, too, and again,\n\n493\n00:25:11.080 --> 00:25:12.620\nthere's all different kinds out here.\n\n494\n00:25:12.620 --> 00:25:15.930\nKensington has just been one of the ones\nthat's kind of revolutionized it.\n\n495\n00:25:15.930 --> 00:25:18.480\nCan I get a better picture of that?\n\n496\n00:25:18.480 --> 00:25:20.400\nAll right, it's kinda hard to see, but\n\n497\n00:25:20.400 --> 00:25:24.620\nthis little metal piece right here\nactually fits into the side of\n\n498\n00:25:24.620 --> 00:25:28.500\na port on the laptop that you can lock\ndown, and again, use the combination lock.\n\n499\n00:25:28.500 --> 00:25:33.200\nReally what it does is it just stops the\npeople from casually swiping your device.\n\n500\n00:25:33.200 --> 00:25:38.280\nThat's where it boils down to is\nkeeping things like laptops from\n\n501\n00:25:38.280 --> 00:25:40.790\njust casually walking out of your building\n&gt;&gt; Kinds\n\n502\n00:25:40.790 --> 00:25:42.110\nof go back what you mentioned earlier, but\n\n503\n00:25:42.110 --> 00:25:44.660\nthis saves in a locking cabinet\n&gt;&gt; Yes, definitely.\n\n504\n00:25:44.660 --> 00:25:50.030\nSo a it sometimes Mm-hm is again\nan inconvenience to some but\n\n505\n00:25:50.030 --> 00:25:52.270\nagain remember where talking\nabout security here, so\n\n506\n00:25:52.270 --> 00:25:55.370\nsecurity sometimes doesnt\noffer you the most.\n\n507\n00:25:55.370 --> 00:25:59.450\nThe best convenience, but again,\nit's about keeping your devices secure.\n\n508\n00:25:59.450 --> 00:26:02.600\nOther things that we have out here as well\nthat we need to worry about are things\n\n509\n00:26:02.600 --> 00:26:05.020\nlike for instance privacy filters.\n\n510\n00:26:05.020 --> 00:26:08.060\nWhen we talk about privacy screens or\nprivacy filters,\n\n511\n00:26:08.060 --> 00:26:12.920\nI want you to think of Let's go back in\ntime when a laptop used to have to sit in\n\n512\n00:26:12.920 --> 00:26:15.310\nthe passive matrix screens, right?\n\n513\n00:26:15.310 --> 00:26:19.030\nYou used to have to sit right in front\nof that laptop to be able to see\n\n514\n00:26:19.030 --> 00:26:20.520\neven what was going on.\n\n515\n00:26:20.520 --> 00:26:22.250\nIf you move just to the side,\n\n516\n00:26:22.250 --> 00:26:26.740\ndidn't matter which side you went to You\ncouldn't see what was on the screen right?\n\n517\n00:26:26.740 --> 00:26:29.410\nWell privacy filters\nare almost about re-initiating\n\n518\n00:26:29.410 --> 00:26:32.140\nold passive matrix screens and\nI say that joking.\n\n519\n00:26:32.140 --> 00:26:33.750\nI've got an example up here on Amazon,\n\n520\n00:26:33.750 --> 00:26:36.580\nwe're gonna spend some of Cherokee's\nmoney, I havent done that lately [LAUGH]\n\n521\n00:26:36.580 --> 00:26:38.270\nTime to do that\n&gt;&gt; Good luck\n\n522\n00:26:38.270 --> 00:26:40.750\n&gt;&gt; Well you can see this young lady,\n\n523\n00:26:40.750 --> 00:26:43.470\nshe's installing\n&gt;&gt; A privacy filter, right?\n\n524\n00:26:43.470 --> 00:26:45.900\nAnd you could see confidential\ninformation right here, right?\n\n525\n00:26:45.900 --> 00:26:51.410\nWell once he installs this, the goal is\nthat this is what we don't see, right?\n\n526\n00:26:51.410 --> 00:26:52.958\nIf we look at this screen here.\n\n527\n00:26:52.958 --> 00:26:54.950\n&gt;&gt; Just severely limiting\nthat [CROSSTALK].\n\n528\n00:26:54.950 --> 00:26:56.070\n&gt;&gt; That's right.\n\n529\n00:26:56.070 --> 00:26:58.340\nAnd it prevents the shoulder\nchaffing attackers.\n\n530\n00:26:58.340 --> 00:26:59.230\nIt well.\n\n531\n00:26:59.230 --> 00:27:00.570\n&gt;&gt; It doesn't prevent it.\n\n532\n00:27:00.570 --> 00:27:04.730\nIt helps to minimize the risk of\na shoulder surfing attack, right?\n\n533\n00:27:04.730 --> 00:27:06.730\nWe don't want somebody being able to look,\n\n534\n00:27:06.730 --> 00:27:08.620\nokay Cherokee I see what\nyour password is there.\n\n535\n00:27:08.620 --> 00:27:10.930\nLet me go ahead and log in to your\nbank account information, right?\n\n536\n00:27:10.930 --> 00:27:12.480\nBecause I've been shoulder surfing.\n\n537\n00:27:12.480 --> 00:27:18.240\nWe can put something on this like that And\nlike I said, to minimize the risk.\n\n538\n00:27:18.240 --> 00:27:20.860\nIt doesn't eliminate it,\nwe can never eliminate all risk,\n\n539\n00:27:20.860 --> 00:27:22.940\nthey only secure networks\nto one that doesn't exist.\n\n540\n00:27:22.940 --> 00:27:25.360\nBut at least they can bring it\ndown to an acceptable level.\n\n541\n00:27:25.360 --> 00:27:27.830\n&gt;&gt; I see why we wanna to spend my money,\nlook at the price on that thing.\n\n542\n00:27:27.830 --> 00:27:28.900\nAgain, that's what I was thinking.\n\n543\n00:27:28.900 --> 00:27:32.590\nI said a piece of plastic for\n60 bucks, but I digress.\n\n544\n00:27:32.590 --> 00:27:34.310\nWe're in the wrong industry.\n\n545\n00:27:34.310 --> 00:27:37.440\nRight?\nSo privacy screens and filters again what\n\n546\n00:27:37.440 --> 00:27:40.790\nthey do is they essentially stop\nyou from those prying eyes.\n\n547\n00:27:41.860 --> 00:27:45.630\nAll right, so that last thing we'll\ntalk about here, as we go through here,\n\n548\n00:27:45.630 --> 00:27:46.700\ncameras.\n\n549\n00:27:46.700 --> 00:27:48.890\nWe've already talked about cameras before.\n\n550\n00:27:48.890 --> 00:27:51.750\nKeep in mind IP based cameras\ncan be a source of attack.\n\n551\n00:27:51.750 --> 00:27:56.110\nSo when you are using them, ensure that\nyou You are securing them as well.\n\n552\n00:27:56.110 --> 00:28:01.090\nNo going to things like [INAUDIBLE]\nout there where you can basically see\n\n553\n00:28:01.090 --> 00:28:05.680\na lot of IP cameras that are basically\nconnected to back bone of the internet or\n\n554\n00:28:05.680 --> 00:28:07.500\nthe internet in general.\n\n555\n00:28:07.500 --> 00:28:08.740\nMotion detection system.\n\n556\n00:28:08.740 --> 00:28:10.860\nWe have to worry about things\nlike motion detection systems.\n\n557\n00:28:10.860 --> 00:28:13.840\nAnd there are few different kinds that\nI kinda wanna just make you aware of.\n\n558\n00:28:13.840 --> 00:28:17.770\nAgain, it's not about being installation\nexperts of these technologies but\n\n559\n00:28:17.770 --> 00:28:19.890\njust knowing some of them that exist,\nright?\n\n560\n00:28:19.890 --> 00:28:23.050\nSo motion detection, we come down to it.\n\n561\n00:28:23.050 --> 00:28:27.020\nThere are, primarily,\nthree different kinds give or take.\n\n562\n00:28:27.020 --> 00:28:30.110\nSome people might go a couple\nof different ways on this one.\n\n563\n00:28:30.110 --> 00:28:34.450\nBut there are active Motion detectors,\n\n564\n00:28:34.450 --> 00:28:37.110\nthese are typically ones that\nare using some kind of radar wave that\n\n565\n00:28:37.110 --> 00:28:41.490\nare constantly throwing out\nsome kind of radar scan.\n\n566\n00:28:41.490 --> 00:28:46.220\nAnd what happens is they're waiting for\na reflection back to the sensor.\n\n567\n00:28:46.220 --> 00:28:49.890\nEssentially, I want you to think\nof giving out radio waves.\n\n568\n00:28:49.890 --> 00:28:53.570\nAnd if somebody walks in between\nthat wave just kind of like a ping,\n\n569\n00:28:53.570 --> 00:28:56.540\nwe talk about sonar The wave\nbounces back to the sensor and\n\n570\n00:28:56.540 --> 00:29:00.770\nthey can tell that something is in\nthe proximity of where that radio wave is.\n\n571\n00:29:00.770 --> 00:29:02.990\nYou also have things\nlike photosensitive ones.\n\n572\n00:29:02.990 --> 00:29:08.010\nPhotosensitive cameras or motion detection\nsystems they use things like lasers and\n\n573\n00:29:08.010 --> 00:29:11.900\nlight sensors in order to\ndetect that motion is there.\n\n574\n00:29:11.900 --> 00:29:13.520\nYou also have things like passive.\n\n575\n00:29:13.520 --> 00:29:17.340\nPassive motion detectors,\nlike they call them PIRs.\n\n576\n00:29:17.340 --> 00:29:18.670\nPassive inferred scanners.\n\n577\n00:29:18.670 --> 00:29:19.610\nRight.\n\n578\n00:29:19.610 --> 00:29:24.220\nThe past of infrared scanner are used\nthe infrared spectrum if you will and\n\n579\n00:29:24.220 --> 00:29:27.590\nwhat they do is they\nbasically detect abrupt\n\n580\n00:29:27.590 --> 00:29:32.530\nchanges in the inferred pattern not\nsettle changes like for instance sunrise.\n\n581\n00:29:32.530 --> 00:29:37.580\nBut a very abrupt changes and\nthe infrared if you will energy\n\n582\n00:29:37.580 --> 00:29:41.040\nin order to detect that\nmotion is there and present.\n\n583\n00:29:41.040 --> 00:29:45.470\nAnd sometimes you can have systems that\ninteger [INAUDIBLE] from a multiply of\n\n584\n00:29:45.470 --> 00:29:50.608\nthese techniques and that's when you need\na call of Mike and Wes to help you out.\n\n585\n00:29:50.608 --> 00:29:52.120\n[LAUGH]\n&gt;&gt; Most definitely.\n\n586\n00:29:52.120 --> 00:29:54.640\nAll right, so\nlet's see what else do we have.\n\n587\n00:29:54.640 --> 00:29:55.710\nWe have logs, all right.\n\n588\n00:29:55.710 --> 00:29:57.300\nLog, logging visitor access.\n\n589\n00:29:57.300 --> 00:30:00.110\nThis is.\nVery, very important you have to keep in\n\n590\n00:30:00.110 --> 00:30:04.820\nmind that not only when we talk about\nlogs for like intrusion event monitoring,\n\n591\n00:30:04.820 --> 00:30:10.070\nmonitoring the people and\nbeing able to uniquely identify and record\n\n592\n00:30:10.070 --> 00:30:15.210\nevery person that is accessing a location,\nall right the other\n\n593\n00:30:15.210 --> 00:30:19.140\nthing that we got keep in mind too is\nthat you are implementing log retention.\n\n594\n00:30:19.140 --> 00:30:21.760\nRight?\nYou want to be able at any point to\n\n595\n00:30:21.760 --> 00:30:26.210\ncall the, audit the logs and\nfind out who has accessed,\n\n596\n00:30:26.210 --> 00:30:29.480\nleft, entered or left the building and\nwhat their purpose were, and\n\n597\n00:30:29.480 --> 00:30:33.720\nthen also make sure that the logs that\nyou have are stored securely, because,\n\n598\n00:30:33.720 --> 00:30:37.490\nremember, hackers or\nattackers typically try to delete logs.\n\n599\n00:30:37.490 --> 00:30:40.660\nDeleting logs tries to\ncover their tracks So,\n\n600\n00:30:40.660 --> 00:30:44.330\nif you are logging visitor access,\nif you will,\n\n601\n00:30:44.330 --> 00:30:48.780\nin some kind of electronic form, make\nsure that those logs do stay protected.\n\n602\n00:30:49.960 --> 00:30:53.760\nAll right, so we, kinda, mentioned\nanother term already, infrared detection.\n\n603\n00:30:53.760 --> 00:30:56.690\nAgain, keep in mind that,\nwhen we talk about infrared detection,\n\n604\n00:30:56.690 --> 00:30:59.740\na lot of these systems come\nwith Two to three beams, right?\n\n605\n00:31:01.020 --> 00:31:05.730\nI get more beams, larger coverage area,\nand a taller beam, if you will,\n\n606\n00:31:05.730 --> 00:31:08.250\nthat makes it a little\nbit harder to bypass.\n\n607\n00:31:08.250 --> 00:31:10.410\n&gt;&gt; And Wes,\nyou did mention the cameras and\n\n608\n00:31:10.410 --> 00:31:11.310\nthe motion detectors\n&gt;&gt; But\n\n609\n00:31:11.310 --> 00:31:15.380\nwe're starting to see some excuse me,\nsome companies integrating the two.\n\n610\n00:31:15.380 --> 00:31:17.590\nI can think of one off the top of my head,\n\n611\n00:31:17.590 --> 00:31:21.050\nthose ring systems with the door bells\nwhere they have the motion detectors\n\n612\n00:31:21.050 --> 00:31:24.400\nthat will initiate when someone\nwalks up to that front door.\n\n613\n00:31:24.400 --> 00:31:28.610\nAnd even if you're not home, you can\nstream video from even a mobile device,\n\n614\n00:31:28.610 --> 00:31:32.140\nan app, to make it to appear\nthere's like a little screen, so\n\n615\n00:31:32.140 --> 00:31:35.180\nwhen they ring the doorbell it looks like\nyou're sitting at your desk to get home,\n\n616\n00:31:35.180 --> 00:31:37.690\nbut the visitor might not know\nwhere you're really sitting.\n\n617\n00:31:37.690 --> 00:31:41.090\nSo it's kind of a cool concept,\nwe'll see how that plays out.\n\n618\n00:31:41.090 --> 00:31:43.550\n&gt;&gt; Hey, nothing like having\na threat to Torrent, right?\n\n619\n00:31:43.550 --> 00:31:47.200\nIt's a very very Good\nthing if you can deter\n\n620\n00:31:47.200 --> 00:31:51.180\nsome kind of event from happening before\nit ever does, by all means implement it.\n\n621\n00:31:51.180 --> 00:31:55.320\nLast thing to talk about is key management\nand again, when it comes to again,\n\n622\n00:31:55.320 --> 00:32:00.630\nkey management in general, just remember,\nkeys falling in the hands of unauthorized\n\n623\n00:32:00.630 --> 00:32:05.550\npersonnel, or giving keys to unauthorized\nperson, again that causes things like.\n\n624\n00:32:06.840 --> 00:32:07.960\nData breaches, all right?\n\n625\n00:32:07.960 --> 00:32:11.080\nSo proper key management is also\nsomething that you have to implement\n\n626\n00:32:11.080 --> 00:32:14.070\nwhen it comes to proper physical security.\n\n627\n00:32:14.070 --> 00:32:15.910\n&gt;&gt; Well,\nwe made it through the entire lists.\n\n628\n00:32:15.910 --> 00:32:16.960\nSo good job, Wes.\n\n629\n00:32:16.960 --> 00:32:19.040\nAnd thank you ladies and\ngentlemen for joining us today.\n\n630\n00:32:19.040 --> 00:32:22.740\nBut stay tuned, we do have more\nCompTIA Security+ headed your way.\n\n631\n00:32:22.740 --> 00:32:24.120\nFor this show,\nwe'll go ahead and sign out.\n\n632\n00:32:24.120 --> 00:32:25.930\nRemember, I'm your host, Cherokee Boose.\n\n633\n00:32:25.930 --> 00:32:26.710\n&gt;&gt; And I'm Wes Bryan.\n\n634\n00:32:26.710 --> 00:32:29.768\n&gt;&gt; See you next time here at ITPRO.TV.\n\n635\n00:32:29.768 --> 00:32:35.750\n[MUSIC]\n\n636\n00:32:35.750 --> 00:32:39.499\nThank you for watching ITPRO.TV.\n\n",
          "vimeoId": "214014024"
        }
      ],
      "title": "Architecture and Design"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Daniel and Wes look into identity and access management concepts. Here they discuss Identification, Authentication/Authorization/Accounting (AAA), and Multi-factor Authentication practices.",
          "length": "1546",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-1-identity_and_access_management_concepts-050117-PGM.00_00_12_07.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-1-identity_and_access_management_concepts-050117-PGM.00_00_12_07.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-1-identity_and_access_management_concepts-050117-PGM.00_00_12_07.Still001-sm.jpg",
          "title": "Identity and Access Management Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:02.989\nWelcome to IT Pro TV,\nI'm your host Don Pezet.\n\n2\n00:00:02.989 --> 00:00:06.045\n[CROSSTALK]\n\n3\n00:00:06.045 --> 00:00:08.418\n[MUSIC]\n\n4\n00:00:08.418 --> 00:00:12.461\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.461 --> 00:00:14.359\n&gt;&gt; All right, greetings everyone, and\n\n6\n00:00:14.359 --> 00:00:16.679\nwelcome to another great\nepisode of ITProTV.\n\n7\n00:00:16.679 --> 00:00:19.309\nI'm your host Daniel Lowrie and\nin today's episode,\n\n8\n00:00:19.309 --> 00:00:23.436\nwe're coming back at you with more in our\nSecurity + series, welcome back for that.\n\n9\n00:00:23.436 --> 00:00:26.940\nAnd joining us in the studio,\nour bother-in-arms, Mr Wes Bryan.\n\n10\n00:00:26.940 --> 00:00:27.813\nWes, welcome back, man, how's it going?\n\n11\n00:00:27.813 --> 00:00:29.120\n&gt;&gt; Hey, thanks for having me back, Dan.\n\n12\n00:00:29.120 --> 00:00:29.860\nIt's great to be here.\n\n13\n00:00:29.860 --> 00:00:34.800\nThat's right, we are looking at, well,\na modern buzzword today, and that is IAM.\n\n14\n00:00:34.800 --> 00:00:37.820\nThat's right, Identity and access manager.\n\n15\n00:00:37.820 --> 00:00:39.338\n&gt;&gt; I thought that was the last\nname of Will [LAUGH].\n\n16\n00:00:39.338 --> 00:00:46.418\n&gt;&gt; That's right [LAUGH] it's concept that\nyou have to know the different components.\n\n17\n00:00:46.418 --> 00:00:50.890\nBecause identity management, if you have\na small home office type environment where\n\n18\n00:00:50.890 --> 00:00:54.100\nmaybe you've got five users,\nyou know all those identities.\n\n19\n00:00:54.100 --> 00:00:57.270\nAnd for the most part, you might even\nspeak to them on a daily basis, but\n\n20\n00:00:57.270 --> 00:01:02.750\nas your companies grow, and as the pool\nof identities that you have to manage,\n\n21\n00:01:02.750 --> 00:01:04.390\nif you will, can become more complex.\n\n22\n00:01:04.390 --> 00:01:07.340\nSo we're gonna go ahead and we're\ngonna talk about our several different\n\n23\n00:01:07.340 --> 00:01:11.720\nconcepts around just the basic management,\nif you will, of those identities.\n\n24\n00:01:11.720 --> 00:01:15.107\n&gt;&gt; So, Wes, when you say identities\nyou mean this is my user account,\n\n25\n00:01:15.107 --> 00:01:18.380\nthe group I'm in, things of that nature,\nsomething that identifies me as me.\n\n26\n00:01:18.380 --> 00:01:19.450\n&gt;&gt; That's right, absolutely.\n\n27\n00:01:19.450 --> 00:01:20.530\nAnd there's a process too.\n\n28\n00:01:20.530 --> 00:01:24.360\nI'm glad you mentioned that,\nthat there is a process when it comes\n\n29\n00:01:24.360 --> 00:01:28.270\nto giving authorization, or\ngiving access to within your resources.\n\n30\n00:01:28.270 --> 00:01:32.600\nAnd what they call out on the exam is\nthey call out that AAA model, right?\n\n31\n00:01:32.600 --> 00:01:34.700\nNow the triple AAA, if you will,\n\n32\n00:01:34.700 --> 00:01:38.630\nis the authentication,\nauthorization and accounting.\n\n33\n00:01:38.630 --> 00:01:40.762\nNow they also call out\nthe very first step,\n\n34\n00:01:40.762 --> 00:01:45.150\nall right, even though it's not in the\nacronym AAA, and that's identification.\n\n35\n00:01:45.150 --> 00:01:48.150\nBecause we do have to understand\nthat there's a difference between\n\n36\n00:01:48.150 --> 00:01:52.070\nidentification and then authentication,\nand they are separate.\n\n37\n00:01:52.070 --> 00:01:55.900\nA lot of times or sometimes people\ntry to use them interchangeably and\n\n38\n00:01:55.900 --> 00:01:58.200\nthat's really just not the way it is.\n\n39\n00:01:58.200 --> 00:02:00.560\nAnd let me give you an example, right?\n\n40\n00:02:00.560 --> 00:02:03.910\nLet's say I've been shoulder surfing\nDan's computer for awhile and\n\n41\n00:02:03.910 --> 00:02:08.190\nI happen to see and\njust happen to get his password, right?\n\n42\n00:02:08.190 --> 00:02:11.470\nWell, if I know the naming convention in\nthe company, and let's say it's gonna\n\n43\n00:02:11.470 --> 00:02:14.900\nbe like D Lowrie, like first name\nlast name and I've got his password.\n\n44\n00:02:14.900 --> 00:02:18.220\nWell, can I authenticate\nagainst the system as him?\n\n45\n00:02:18.220 --> 00:02:19.070\nAnd the answer is, yes.\n\n46\n00:02:19.070 --> 00:02:23.190\nIf I've got the valid password then I can,\nbut that doesn't identify it as Dan,\n\n47\n00:02:23.190 --> 00:02:25.490\nso keep in mind they\nare two separate concepts.\n\n48\n00:02:25.490 --> 00:02:29.940\nIdentification, basically,\nis about presenting a claim, right?\n\n49\n00:02:29.940 --> 00:02:32.630\nWe start with identification,\nyou go through things like the on-boarding\n\n50\n00:02:32.630 --> 00:02:36.560\nprocess, your employer becomes aware\nof who you are, your history, right?\n\n51\n00:02:36.560 --> 00:02:38.660\nIt's all a part of the hiring process,\nright?\n\n52\n00:02:38.660 --> 00:02:41.430\nAnd that could be part of\nthe identification process.\n\n53\n00:02:41.430 --> 00:02:45.410\nNow to an authentication system, the first\npart of identification is, well, you say,\n\n54\n00:02:45.410 --> 00:02:48.930\nhey, I'm Wes Bryan, or\nW Bryan if that's my user name right?\n\n55\n00:02:48.930 --> 00:02:50.620\nThat's your claim,\nthat's your identification, but\n\n56\n00:02:50.620 --> 00:02:52.980\nthen what happens after that?\n\n57\n00:02:52.980 --> 00:02:56.380\nWell, then you go through\nthe authentication process, right?\n\n58\n00:02:56.380 --> 00:03:00.620\nWhatever the system is that you\nare presenting that claim to,\n\n59\n00:03:00.620 --> 00:03:01.260\nhey, I'm W Bryan.\n\n60\n00:03:01.260 --> 00:03:02.400\nIt's going to challenge you, right?\n\n61\n00:03:02.400 --> 00:03:03.750\nAnd what are they going to do?\n\n62\n00:03:03.750 --> 00:03:06.200\nThey're going to challenge you with,\nwell, prove it.\n\n63\n00:03:06.200 --> 00:03:08.750\nIf you say that your W Bryan, prove it.\n\n64\n00:03:08.750 --> 00:03:10.010\nHow do you prove it, right?\n\n65\n00:03:10.010 --> 00:03:12.220\nWell, that is basically checks and\n\n66\n00:03:12.220 --> 00:03:17.110\nverifies the identity or\nthe claim that the identity is making.\n\n67\n00:03:17.110 --> 00:03:19.775\nIn that case, you're just\nputting in your password, right?\n\n68\n00:03:19.775 --> 00:03:24.600\nAnd that's known as things like\nauthentication as assertion.\n\n69\n00:03:24.600 --> 00:03:27.440\nAll right, so your username,\nthat is your identification.\n\n70\n00:03:27.440 --> 00:03:30.120\nYour authentication says,\nwell, who are you?\n\n71\n00:03:30.120 --> 00:03:32.460\nI mean, you just take authentication,\nand let's just narrow it down.\n\n72\n00:03:32.460 --> 00:03:34.510\nWho are you, and how do you prove that?\n\n73\n00:03:34.510 --> 00:03:36.150\nYou prove that with your password.\n\n74\n00:03:36.150 --> 00:03:39.850\nIf the password is validated,\nwe go to the next step, right?\n\n75\n00:03:39.850 --> 00:03:44.350\nThe next step is authorization,\nnow authorization, if you will,\n\n76\n00:03:44.350 --> 00:03:48.650\nis just determining the actions, if you\nwill, the access level of tasks that that\n\n77\n00:03:48.650 --> 00:03:51.415\nidentity can perform on or\nagainst a resource.\n\n78\n00:03:51.415 --> 00:03:54.750\nWhen I say on or against a resource\ncould be a file, could be a folder,\n\n79\n00:03:54.750 --> 00:03:57.360\ncould be a printer,\ncould be a web application,\n\n80\n00:03:57.360 --> 00:03:59.760\nsomebody signing into web lab application,\nright?\n\n81\n00:03:59.760 --> 00:04:06.710\nSo, authentication, again, who are you,\nand you need to prove that, right?\n\n82\n00:04:06.710 --> 00:04:08.322\nAuthorization, what can you do?\n\n83\n00:04:08.322 --> 00:04:11.850\nAnd I'm very basically, that's what\nauthorization is, what can you do?\n\n84\n00:04:11.850 --> 00:04:16.170\nAnd then we move into,\nwell, the next part.\n\n85\n00:04:16.170 --> 00:04:17.700\nAnd that's accounting.\n\n86\n00:04:17.700 --> 00:04:20.720\nThe accounting is basically just\n\n87\n00:04:20.720 --> 00:04:25.140\nmeasuring the resources that that\nauthorized user consumed, all right?\n\n88\n00:04:25.140 --> 00:04:27.410\nConsumed, consumption, if you will,\njust accessing, all right?\n\n89\n00:04:27.410 --> 00:04:31.190\nIf I access a folder that's on a file\nshare, I'm consuming the file.\n\n90\n00:04:31.190 --> 00:04:32.150\nIt doesn't mean I'm eating it.\n\n91\n00:04:32.150 --> 00:04:35.497\nAlthough if it's a little bit\nbefore lunch, I might [CROSSTALK].\n\n92\n00:04:35.497 --> 00:04:36.276\nThat's right.\n\n93\n00:04:36.276 --> 00:04:39.010\nSo if we take a little recap.\n\n94\n00:04:39.010 --> 00:04:40.510\nDon't let these terms fool you.\n\n95\n00:04:40.510 --> 00:04:42.320\nThey're not really that complex.\n\n96\n00:04:42.320 --> 00:04:47.850\nIdentification is first I have to prove\nwho I am, it could be a drivers license\n\n97\n00:04:47.850 --> 00:04:51.780\npresented, it could be a hiring process\nyou're at, you're proving your identity.\n\n98\n00:04:51.780 --> 00:04:55.860\nWe have authentication, that is proving\nthat you are who you say you are,\n\n99\n00:04:55.860 --> 00:04:57.310\nbased on those credentials.\n\n100\n00:04:57.310 --> 00:04:58.690\nWho are you?\n\n101\n00:04:58.690 --> 00:05:01.330\nThen we have, again, the authorization.\n\n102\n00:05:01.330 --> 00:05:02.640\nWhat ca you do, right?\n\n103\n00:05:02.640 --> 00:05:03.640\nWhat are you allowed to do?\n\n104\n00:05:03.640 --> 00:05:06.156\nAnd then finally, accounting is,\nwell, what did you do?\n\n105\n00:05:06.156 --> 00:05:10.481\nAnd that's tracking those activities as\nyou were logged in to the authenticating\n\n106\n00:05:10.481 --> 00:05:10.991\nsystem.\n\n107\n00:05:10.991 --> 00:05:13.775\n&gt;&gt; So, Wes, if someone says\nsomething about a AAA server,\n\n108\n00:05:13.775 --> 00:05:17.030\nwe now have a better idea of what's\ngoing inside of the AAA server.\n\n109\n00:05:17.030 --> 00:05:21.160\nIt's some sort of authenticating\nmechanism that has a list or\n\n110\n00:05:21.160 --> 00:05:24.860\naccess to a list of users to\nidentify them, authorization,\n\n111\n00:05:24.860 --> 00:05:27.860\nwhat is their actual\naccess into the system?\n\n112\n00:05:27.860 --> 00:05:30.523\nAnd then what can they do and\nlet's take a look at what they do and\n\n113\n00:05:30.523 --> 00:05:31.390\nkeep track of that.\n\n114\n00:05:31.390 --> 00:05:34.709\n&gt;&gt; Most definitely, give me an example\nwhere they bring all of that together?\n\n115\n00:05:34.709 --> 00:05:38.759\nYou can have systems like Active\nDirectory Directory Services database,\n\n116\n00:05:38.759 --> 00:05:43.258\nit does authentication and authorization\nby the object that it's stored inside of\n\n117\n00:05:43.258 --> 00:05:45.070\nthe Active Directory database.\n\n118\n00:05:45.070 --> 00:05:48.410\nAnd, yes, you can turn on auditing and,\nwell, that will give you accounting.\n\n119\n00:05:48.410 --> 00:05:51.230\nBut more commonly,\nwhen we think of a AAA server,\n\n120\n00:05:51.230 --> 00:05:52.540\nwe think it's something like a RADIUS.\n\n121\n00:05:52.540 --> 00:05:56.390\nRADIUS is your classic\ndefinition of a AAA server.\n\n122\n00:05:56.390 --> 00:06:00.380\nYou can think of Cisco,\nCisco has TACACS+, right?\n\n123\n00:06:00.380 --> 00:06:01.280\nA little bit different.\n\n124\n00:06:01.280 --> 00:06:04.230\nAnd we'll talk some of\nthe more specifics of them.\n\n125\n00:06:04.230 --> 00:06:08.980\nBut again,\nthat's an implementation of AAA,\n\n126\n00:06:08.980 --> 00:06:12.780\nhowever, Cisco's implementation does\na good job at breaking them down,\n\n127\n00:06:12.780 --> 00:06:15.450\nvery granular, and\nreally separating all three.\n\n128\n00:06:15.450 --> 00:06:19.190\nSo you can get very fine grain and\nfine tune your infrastructure.\n\n129\n00:06:19.190 --> 00:06:22.870\nBut when it comes down to it,\nagain authentication, remember password,\n\n130\n00:06:22.870 --> 00:06:27.020\nauthorization is what can you do\ndetermined by the permissions or\n\n131\n00:06:27.020 --> 00:06:28.980\nprivileges that you\nare granted to the system.\n\n132\n00:06:28.980 --> 00:06:32.740\nFinally, could be enforced\nwith things like policies.\n\n133\n00:06:32.740 --> 00:06:35.210\nAnd then accounting is what did you do.\n\n134\n00:06:35.210 --> 00:06:38.110\nAnd that's where we have things like\nauditing that leads to logging.\n\n135\n00:06:38.110 --> 00:06:42.040\nAnd you do want to periodically\ndo things like audit reviews,\n\n136\n00:06:42.040 --> 00:06:45.310\nmake sure that you're\nimplementing privileges and\n\n137\n00:06:45.310 --> 00:06:47.760\naccess controls appropriately\nwithin your network.\n\n138\n00:06:47.760 --> 00:06:50.680\n&gt;&gt; Now, Wes, moving along with\nthe idea of authentication.\n\n139\n00:06:50.680 --> 00:06:53.597\nNowadays, the big buzzword, or\nthe big buzz feel something and\n\n140\n00:06:53.597 --> 00:06:57.216\nit's actually really good idea and\nthat's why we continually move toward this\n\n141\n00:06:57.216 --> 00:07:00.638\nmore and more everyday is,\nthat multi-factor authentication, right?\n\n142\n00:07:00.638 --> 00:07:02.401\n&gt;&gt; Most possible.\n&gt;&gt; It's not just I have a password,\n\n143\n00:07:02.401 --> 00:07:05.280\nI need a little more than that for\nmore security, correct?\n\n144\n00:07:05.280 --> 00:07:06.990\n&gt;&gt; Definitely, right,\nwe want to step it up, right?\n\n145\n00:07:06.990 --> 00:07:11.010\nSo if we talk about just a username and\npassword, compared to what Dan is talking\n\n146\n00:07:11.010 --> 00:07:15.738\nabout, that's called simply an SFA,\nsingle factor authentication.\n\n147\n00:07:15.738 --> 00:07:20.780\nHowever, that doesn't necessarily lend\nitself to the greatest security, because,\n\n148\n00:07:20.780 --> 00:07:24.990\nlike I said, if I happen to be the\nmalicious insider that kinda threat actor,\n\n149\n00:07:24.990 --> 00:07:28.190\nwhat I'm trying to, I'm gonna rub\na neck in Dan's computer there and\n\n150\n00:07:28.190 --> 00:07:31.310\nI think I can guess what his password is.\n\n151\n00:07:31.310 --> 00:07:33.712\nI tell you what,\nI think I know what it is,\n\n152\n00:07:33.712 --> 00:07:35.993\nits dot dot dot dot dot dot dot, right?\n\n153\n00:07:35.993 --> 00:07:38.683\nBut the point is if I-\n&gt;&gt; Brilliance.\n\n154\n00:07:38.683 --> 00:07:39.797\n&gt;&gt; You better go change your password.\n\n155\n00:07:39.797 --> 00:07:40.882\n&gt;&gt; Hold on.\n\n156\n00:07:40.882 --> 00:07:41.394\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH]\n\n157\n00:07:41.394 --> 00:07:43.528\n&gt;&gt; The luggage on your password, yeah.\n\n158\n00:07:43.528 --> 00:07:46.507\nSo, we wanna increase the strength of\n\n159\n00:07:46.507 --> 00:07:50.511\nan authentication system\nby adding more than one,\n\n160\n00:07:50.511 --> 00:07:53.021\nright?\nSo, how do we know which one it is\n\n161\n00:07:53.021 --> 00:07:55.903\nthat we're supposed to add, right?\nWhen we get into\n\n162\n00:07:55.903 --> 00:07:58.536\nsomething known as multi-factor\nauthentication, MFA,\n\n163\n00:07:58.536 --> 00:08:01.585\nyou might see It's kind of funny Dan.\nI'm sitting here researching\n\n164\n00:08:01.585 --> 00:08:04.437\na little bit.\nYou try to go over things in your mind\n\n165\n00:08:04.437 --> 00:08:09.219\nas how you can present it here at ITProTV.\nAnd I'm thinking why do we have to have\n\n166\n00:08:09.219 --> 00:08:12.220\nan acronym for everything.\nSingle factor authentication and\n\n167\n00:08:12.220 --> 00:08:15.795\nmulti-factor authentication.\nSo I'm reading the story and it says SFA\n\n168\n00:08:15.795 --> 00:08:19.893\nand it says MFA and I'm like I have no\nclue what these concepts are about.\n\n169\n00:08:19.893 --> 00:08:21.154\nThen they define the acronym and\n\n170\n00:08:21.154 --> 00:08:24.403\nI'm like okay, I know what it is so.\nIf you see those acronyms guys,\n\n171\n00:08:24.403 --> 00:08:27.303\ndon't let it confuse you.\nEverything in IT has to an acronym or\n\n172\n00:08:27.303 --> 00:08:30.331\nit wouldn't be legit, right?\n&gt;&gt; I think we should do a show\n\n173\n00:08:30.331 --> 00:08:34.107\none day of just, where we would\nuse nothing other than acronyms.\n\n174\n00:08:34.107 --> 00:08:35.424\n&gt;&gt; That'll be watched by five people.\n\n175\n00:08:35.424 --> 00:08:36.096\n[LAUGH] So\n\n176\n00:08:36.096 --> 00:08:40.895\nlet's talk about authentication, right?\nAuthentication like we\n\n177\n00:08:40.895 --> 00:08:43.880\nsaid is proving who you are,\nwho you say you are, right?\n\n178\n00:08:43.880 --> 00:08:47.436\nWell, what are additional\nauthentication factors, all right?\n\n179\n00:08:47.436 --> 00:08:51.160\nThat is, authentication factors a lot\nof times come down to three things.\n\n180\n00:08:52.230 --> 00:08:56.300\nHowever, there have been some\nadditional ones that have been added.\n\n181\n00:08:56.300 --> 00:08:59.640\nIt really boils down to knowledge,\npossession and inheritance.\n\n182\n00:08:59.640 --> 00:09:01.745\nI inherit a trait, right?\n\n183\n00:09:01.745 --> 00:09:05.220\nLet's look at the authentication factors\nthat they have and they present for\n\n184\n00:09:05.220 --> 00:09:06.029\nthe exam for you.\n\n185\n00:09:06.029 --> 00:09:09.774\nI got a little slide here on my desktop,\nand you can see,\n\n186\n00:09:09.774 --> 00:09:11.860\nthere are quite a few, right?\n\n187\n00:09:11.860 --> 00:09:15.997\nI will tell you that you will see\na commonality with the first three, right?\n\n188\n00:09:15.997 --> 00:09:17.440\nThe first three are the most common.\n\n189\n00:09:17.440 --> 00:09:18.620\nSomething you know, right?\n\n190\n00:09:18.620 --> 00:09:22.030\nThat is, again,\nsome kind of knowledge of something, and\n\n191\n00:09:22.030 --> 00:09:23.770\nwe'll get into it a little bit more.\n\n192\n00:09:23.770 --> 00:09:26.400\nSomething you have,\nsomething I possess, right?\n\n193\n00:09:26.400 --> 00:09:32.990\nAnd then something you are is typically\nsome behavioral or physiological.\n\n194\n00:09:32.990 --> 00:09:36.470\nThank you I almost said psychology.\n\n195\n00:09:36.470 --> 00:09:38.500\n&gt;&gt; [LAUGH]\n&gt;&gt; But physiological characteristics\n\n196\n00:09:38.500 --> 00:09:39.780\nof yourself.\n\n197\n00:09:39.780 --> 00:09:42.350\nAnd when we talk about\nsomething you know right?\n\n198\n00:09:42.350 --> 00:09:46.320\nWe're talking about a password,\na username and password.\n\n199\n00:09:46.320 --> 00:09:51.230\nBe careful, because if they ask you on\nthe exam is a username and password\n\n200\n00:09:51.230 --> 00:09:55.270\na form of multi-factor authentication and\nthe answer is no, it's not.\n\n201\n00:09:55.270 --> 00:10:01.000\nBecause if you think about it, it only\nfalls under something you know, right?\n\n202\n00:10:01.000 --> 00:10:05.675\nA PIN, Personal Identification Number,\nthat's an example of something you know.\n\n203\n00:10:05.675 --> 00:10:09.099\nMaybe you've been challenged with\na user name and password and\n\n204\n00:10:09.099 --> 00:10:13.042\nthen somebody asks you the challenging\nsystem, wanted to go farther and\n\n205\n00:10:13.042 --> 00:10:16.400\nverify your claim and\nasked you a security question.\n\n206\n00:10:16.400 --> 00:10:18.548\nWell was that multi factor authentication?\n\n207\n00:10:18.548 --> 00:10:21.110\nBe careful with this one,\nbecause it is not, right?\n\n208\n00:10:21.110 --> 00:10:22.550\nAgain, it falls under knowledge.\n\n209\n00:10:22.550 --> 00:10:28.255\nIt is two examples of the same\nauthentication factor if you will.\n\n210\n00:10:28.255 --> 00:10:29.824\nSomething you have, right?\n\n211\n00:10:29.824 --> 00:10:34.108\nSomething you have is like\nan RFID key [INAUDIBLE] or\n\n212\n00:10:34.108 --> 00:10:36.766\nRFID card, a proximity card.\n\n213\n00:10:36.766 --> 00:10:41.310\nWe all carry these here,\nI've got this card right here.\n\n214\n00:10:41.310 --> 00:10:45.960\nI've got one in my wallet that\nallows me just proximity access to,\n\n215\n00:10:45.960 --> 00:10:49.190\nbasically allows me into the gate\nof the apartment complex.\n\n216\n00:10:49.190 --> 00:10:52.180\nAnd again, it is some kind of possession.\n\n217\n00:10:52.180 --> 00:10:55.740\nWhat are some of the other\nthings that we have here?\n\n218\n00:10:55.740 --> 00:10:57.180\nMake sure I didn't forget anything yet.\n\n219\n00:10:57.180 --> 00:11:03.440\nTokens, smart cards, RFID devices,\nkey fobs if you will, proximity cards.\n\n220\n00:11:03.440 --> 00:11:07.300\nThe next thing that we get\ninto is something you are.\n\n221\n00:11:07.300 --> 00:11:10.400\n&gt;&gt; We're not gonna jump into\nmetaphysics area, right?\n\n222\n00:11:10.400 --> 00:11:12.120\n&gt;&gt; Not yet, but I'll tell you\n&gt;&gt; What am I?\n\n223\n00:11:12.120 --> 00:11:13.372\nI'm a being.\n\n224\n00:11:13.372 --> 00:11:16.155\n&gt;&gt; That's right, as long as you\njust hold your hands like this and\n\n225\n00:11:16.155 --> 00:11:17.265\nsay ohm a hundred times.\n\n226\n00:11:17.265 --> 00:11:18.740\n&gt;&gt; Who let you into our system?\n\n227\n00:11:18.740 --> 00:11:19.354\nHow did you know?\n\n228\n00:11:19.354 --> 00:11:21.500\n&gt;&gt; That's right, that's my password.\n\n229\n00:11:21.500 --> 00:11:22.360\nSo something you are.\n\n230\n00:11:22.360 --> 00:11:25.200\nAnd again, this is some physical\ncharacteristic of yourself.\n\n231\n00:11:25.200 --> 00:11:28.280\nAgain, can be behavioral based, right?\n\n232\n00:11:28.280 --> 00:11:30.620\nOr it can be physiological, right?\n\n233\n00:11:30.620 --> 00:11:34.170\nIf it's behavior based,\nit could be something like, I don't know,\n\n234\n00:11:34.170 --> 00:11:37.330\nvoice pattern,\nversus something like a retinal scanner.\n\n235\n00:11:38.410 --> 00:11:43.630\nBehavioral based, again, there's basically\ntwo forms of this something you are.\n\n236\n00:11:43.630 --> 00:11:47.330\nNow, when get into multifactor, and\nwe'll talk about these last two.\n\n237\n00:11:47.330 --> 00:11:50.630\nThese last two are kind cool too cuz\nthey're something that's relatively\n\n238\n00:11:50.630 --> 00:11:53.710\nnewer when it comes to\nbiometrics authentication.\n\n239\n00:11:53.710 --> 00:11:57.460\nAll right, when we talk about\nmulti factor authentication.\n\n240\n00:11:57.460 --> 00:11:59.690\nWe're talking about combining two or\n\n241\n00:11:59.690 --> 00:12:02.970\nmore of any of the ones that\nyou see here on your screen.\n\n242\n00:12:02.970 --> 00:12:05.378\nSo, I want you to remember that for\nthe exam, right?\n\n243\n00:12:05.378 --> 00:12:07.020\nAgain, we've kinda given\nyou the warning here.\n\n244\n00:12:07.020 --> 00:12:10.730\nJust be careful with anything you\nknow falls under a single factor\n\n245\n00:12:10.730 --> 00:12:12.400\nauthentication.\n\n246\n00:12:12.400 --> 00:12:15.580\nBut if I have something like\nan username and password, right?\n\n247\n00:12:15.580 --> 00:12:20.190\nLet's say that our front door\naccess required a pin number, but\n\n248\n00:12:20.190 --> 00:12:21.990\nat the same pin number, that's redundant.\n\n249\n00:12:21.990 --> 00:12:23.215\nA pin if you will.\n\n250\n00:12:23.215 --> 00:12:25.540\n&gt;&gt; [LAUGH]\n&gt;&gt; And then I had to swipe a card, right?\n\n251\n00:12:25.540 --> 00:12:29.076\nThat would be multi factor authentication.\n\n252\n00:12:29.076 --> 00:12:31.660\nIt could be something like the card right?\n\n253\n00:12:31.660 --> 00:12:35.490\nAnd then maybe putting your hand\ndown on a hand geometry scanner.\n\n254\n00:12:35.490 --> 00:12:39.550\nRight now we've got combine something\nyou have with something you are.\n\n255\n00:12:39.550 --> 00:12:42.410\nYou also have what's known as\nthree factor authentication too,\n\n256\n00:12:42.410 --> 00:12:45.090\nwhere maybe you're\ntalking about top secret,\n\n257\n00:12:45.090 --> 00:12:48.870\nthe highest classification of a military\nstandard that you can when it comes to\n\n258\n00:12:48.870 --> 00:12:51.258\ndata classifications maybe\nyou have to do all three.\n\n259\n00:12:51.258 --> 00:12:56.480\nIt's a three-factor authentication, so I\ndo want you to be aware of those as well.\n\n260\n00:12:56.480 --> 00:12:59.416\nOne, two, and\nthree-factor authentications.\n\n261\n00:12:59.416 --> 00:13:03.378\nNow, these next two, again,\nI bring up, because, well,\n\n262\n00:13:03.378 --> 00:13:07.371\nthey are on the exam,\nthey are called out on the objectives.\n\n263\n00:13:07.371 --> 00:13:09.713\nBut, again, they're kinda new.\n\n264\n00:13:09.713 --> 00:13:13.580\nThose first three kinda be in\nthe classics that everybody's own,\n\n265\n00:13:13.580 --> 00:13:16.640\nif people are studying those\nare commonly aware of.\n\n266\n00:13:16.640 --> 00:13:19.910\nSomewhere, let's start\nwith something you do.\n\n267\n00:13:19.910 --> 00:13:23.611\nOkay, something you do is\na characteristic of yourself, and\n\n268\n00:13:23.611 --> 00:13:25.471\nthis is relatively newer one.\n\n269\n00:13:25.471 --> 00:13:28.470\nAnd I want you to think of things\nlike keystroke patterns, right?\n\n270\n00:13:28.470 --> 00:13:31.576\nWe'll talk about how you\ntype on the keyboard.\n\n271\n00:13:31.576 --> 00:13:35.432\nThey could tell right away, they just have\nto check how many errors are outputted on\n\n272\n00:13:35.432 --> 00:13:38.037\nthe keyboard, or\nhow many times you hit the Backspace.\n\n273\n00:13:38.037 --> 00:13:39.946\nI'm convinced it's my\nelectronic white-out.\n\n274\n00:13:39.946 --> 00:13:40.960\n&gt;&gt; [LAUGH]\n&gt;&gt; So\n\n275\n00:13:40.960 --> 00:13:44.290\nthey know it was me just\nby how bad I type, right?\n\n276\n00:13:44.290 --> 00:13:46.947\nSignature analysis,\nwriting your signature down.\n\n277\n00:13:46.947 --> 00:13:49.070\nAnd again,\nthat's something that you do, right?\n\n278\n00:13:50.070 --> 00:13:53.850\nThere's another one that's kind of in\nthe research that I wanna bring out that's\n\n279\n00:13:53.850 --> 00:13:56.830\nkinda interesting, and\nthat's called gait recognition.\n\n280\n00:13:56.830 --> 00:13:59.866\nNow I'm not talking about recognizing\nthe gate that's open or closed,\n\n281\n00:13:59.866 --> 00:14:01.367\nbut we're talking about walking.\n\n282\n00:14:01.367 --> 00:14:05.946\nAs we get more wearable technologies,\nwe have things like Fitbits and\n\n283\n00:14:05.946 --> 00:14:09.040\nstuff, where eventually-\n&gt;&gt; The gait of your stride.\n\n284\n00:14:09.040 --> 00:14:11.651\n&gt;&gt; That's exactly it,\nit's a walking pattern.\n\n285\n00:14:11.651 --> 00:14:14.387\nSo where you have, maybe,\neven the potential for\n\n286\n00:14:14.387 --> 00:14:17.204\nwearable shoes to recognize\nyou are based on that.\n\n287\n00:14:17.204 --> 00:14:19.370\nLike you said, Dan, the walking pattern.\n\n288\n00:14:19.370 --> 00:14:22.149\nAgain, that's just something I\nthrow out there cuz it's fun.\n\n289\n00:14:22.149 --> 00:14:26.600\nWe have accelerometer sensors and all\ndifferent types of devices that could be\n\n290\n00:14:26.600 --> 00:14:30.040\ncarried on you that could\nalso do this as well.\n\n291\n00:14:30.040 --> 00:14:34.886\nNow the next thing and\nfinal thing is somewhere you are, right?\n\n292\n00:14:34.886 --> 00:14:37.570\nYou've probably heard\nthe term geolocation, right?\n\n293\n00:14:37.570 --> 00:14:41.750\nThis is something that is really common\nin mobile device management solutions.\n\n294\n00:14:41.750 --> 00:14:46.549\nIn mobile device management solutions\nwe have the ability to create\n\n295\n00:14:46.549 --> 00:14:50.183\nthese logical geographical boundaries,\nright?\n\n296\n00:14:50.183 --> 00:14:54.066\nThey could be within the proximity of work\nthat says, hey you don't gain access to\n\n297\n00:14:54.066 --> 00:14:57.290\na certain resource until you're\nwithin 50 feet of the building.\n\n298\n00:14:58.300 --> 00:15:02.278\nCould be the fact that you only get\naccess to that resource while you're in\n\n299\n00:15:02.278 --> 00:15:03.121\nthe building.\n\n300\n00:15:03.121 --> 00:15:06.180\nAgain, this is somewhere you are.\n\n301\n00:15:06.180 --> 00:15:07.550\nThis is geolocation.\n\n302\n00:15:07.550 --> 00:15:09.810\nAnd again MDM's are popular for\ndoing that.\n\n303\n00:15:11.890 --> 00:15:14.010\nThis is really good for\nthe road warriors, right?\n\n304\n00:15:14.010 --> 00:15:15.450\nNow I'm not talking Mad Max.\n\n305\n00:15:15.450 --> 00:15:17.160\nMad Max Beyond Thunderdome.\n\n306\n00:15:17.160 --> 00:15:18.560\n&gt;&gt; Two men enter, one man leave.\n\n307\n00:15:18.560 --> 00:15:21.750\n&gt;&gt; That's right, we're talking about\npeople who are commonly travelling.\n\n308\n00:15:21.750 --> 00:15:26.940\nThe travelling salesperson that's on\na lot of different mobile devices.\n\n309\n00:15:26.940 --> 00:15:31.332\nAgain, somewhere you are lends\nitself to geolocation, and\n\n310\n00:15:31.332 --> 00:15:33.913\ncan be a good way for just granting or\n\n311\n00:15:33.913 --> 00:15:38.492\ndenying access to somebody who\nis on the road a lot, all right?\n\n312\n00:15:38.492 --> 00:15:40.630\nSo those are multifactor authentications.\n\n313\n00:15:40.630 --> 00:15:44.060\nKeep in mind what it does\nmean to be single factor or\n\n314\n00:15:44.060 --> 00:15:45.200\nmultifactor authentication.\n\n315\n00:15:48.071 --> 00:15:48.599\nWanted to give them a good breaking point.\n\n316\n00:15:48.599 --> 00:15:51.586\n&gt;&gt; Yeah,\nI thought you were trying to work a spot.\n\n317\n00:15:51.586 --> 00:15:54.052\n&gt;&gt; [COUGH] Thank you,\nthank you, thank you.\n\n318\n00:15:54.052 --> 00:15:57.591\n&gt;&gt; Sorry about that, Titus, I was trying\nto give you a clean break there, bud.\n\n319\n00:15:57.591 --> 00:15:59.094\nAll right thanks.\n\n320\n00:16:02.164 --> 00:16:05.882\nNow, I know this looks like a lot\nhere to go through, but it's not.\n\n321\n00:16:05.882 --> 00:16:08.095\nI can get it in ten minutes or less.\n\n322\n00:16:08.095 --> 00:16:09.087\n&gt;&gt; I don’t.\n\n323\n00:16:09.087 --> 00:16:10.173\n&gt;&gt; I only have this.\n\n324\n00:16:10.173 --> 00:16:12.534\n[LAUGH]\n&gt;&gt; [LAUGH] That's right.\n\n325\n00:16:12.534 --> 00:16:13.817\n&gt;&gt; It doesn't look like a lot to me.\n\n326\n00:16:13.817 --> 00:16:16.616\n[LAUGH]\n&gt;&gt; That's exactly what I want it to.\n\n327\n00:16:16.616 --> 00:16:17.331\n&gt;&gt; Yeah.\n\n328\n00:16:17.331 --> 00:16:19.523\n&gt;&gt; I've been doing that recently,\ndoes that help a little bit?\n\n329\n00:16:19.523 --> 00:16:20.053\n&gt;&gt; Yeah it's fine.\n\n330\n00:16:20.053 --> 00:16:22.054\n&gt;&gt; I mean does it make it a little easier?\n\n331\n00:16:22.054 --> 00:16:24.416\n&gt;&gt; Yeah, yeah, yeah.\n\n332\n00:16:24.416 --> 00:16:25.238\n&gt;&gt; Yeah cuz-\n&gt;&gt; Cuz you got\n\n333\n00:16:25.238 --> 00:16:27.141\nyour major talking points and-\n&gt;&gt; And that's it, those-\n\n334\n00:16:27.141 --> 00:16:28.635\n&gt;&gt; [CROSSTALK] sub points are squares.\n\n335\n00:16:28.635 --> 00:16:32.617\n&gt;&gt; And those are the CAQC information.\n\n336\n00:16:32.617 --> 00:16:36.528\nSo when you say, and the next\nthing we talk about is federation.\n\n337\n00:16:36.528 --> 00:16:37.492\n&gt;&gt; Yeah, gotcha.\n\n338\n00:16:37.492 --> 00:16:38.050\n&gt;&gt; You see what I'm saying?\n\n339\n00:16:38.050 --> 00:16:38.799\n&gt;&gt; Right.\nRight.\n\n340\n00:16:38.799 --> 00:16:40.307\n&gt;&gt; So, it's kind of\n\n341\n00:16:40.307 --> 00:16:41.018\n&gt;&gt; [CROSSTALK]\n&gt;&gt; Fail-safe.\n\n342\n00:16:41.018 --> 00:16:43.364\n&gt;&gt; [CROSSTALK]\n&gt;&gt; Absolutely, it's great.\n\n343\n00:16:43.364 --> 00:16:44.659\n&gt;&gt; Hit the next talking point.\n\n344\n00:16:44.659 --> 00:16:47.856\nWes talks about it, okay now that\nwe're done with that, federation,\n\n345\n00:16:47.856 --> 00:16:48.775\ntell me about that.\n\n346\n00:16:48.775 --> 00:16:50.734\n&gt;&gt; Yes, okay, so I don't need that.\n\n347\n00:16:50.734 --> 00:16:51.933\n&gt;&gt; [INAUDIBLE]\n&gt;&gt; Sir?\n\n348\n00:16:51.933 --> 00:16:52.845\n&gt;&gt; You gonna pick up on Daniel?\n\n349\n00:16:52.845 --> 00:16:54.946\n&gt;&gt; Yeah, gotta pick up on Daniel, yes sir.\n\n350\n00:16:54.946 --> 00:16:57.102\nLet me go ahead and close this,\ngive me one second.\n\n351\n00:16:57.102 --> 00:16:58.937\n&gt;&gt; I'm gonna be like.\n\n352\n00:16:58.937 --> 00:16:59.454\n&gt;&gt; What up?\n\n353\n00:16:59.454 --> 00:17:04.297\n&gt;&gt; [LAUGH]\n&gt;&gt; And I'm gonna get my beak in the way.\n\n354\n00:17:04.297 --> 00:17:06.260\n&gt;&gt; Yeah, yeah there you go.\n\n355\n00:17:06.260 --> 00:17:08.929\nUsed to be drinking coffee\nlike way out there.\n\n356\n00:17:08.929 --> 00:17:11.666\n[LAUGH]\n&gt;&gt; Roxanne!\n\n357\n00:17:11.666 --> 00:17:12.373\nHey, Jessica.\n\n358\n00:17:12.373 --> 00:17:12.986\n&gt;&gt; That was a great movie.\n\n359\n00:17:12.986 --> 00:17:13.980\n&gt;&gt; It was.\n&gt;&gt; I loved that movie.\n\n360\n00:17:13.980 --> 00:17:14.886\n&gt;&gt; It was, it was timeless.\n\n361\n00:17:14.886 --> 00:17:15.932\n&gt;&gt; Morning, Jessica.\n\n362\n00:17:15.932 --> 00:17:16.881\n&gt;&gt; And he’s like 15.\n\n363\n00:17:16.881 --> 00:17:19.483\n[LAUGH]\n&gt;&gt; Kick the crap out of [CROSSTALK] at\n\n364\n00:17:19.483 --> 00:17:20.049\nthe beginning of that movie.\n\n365\n00:17:20.049 --> 00:17:20.944\n&gt;&gt; Yes, he did.\n\n366\n00:17:20.944 --> 00:17:24.496\nI know we can't go into it,\nbut I loved the insults.\n\n367\n00:17:24.496 --> 00:17:25.265\n&gt;&gt; Yeah, yeah, yeah.\n\n368\n00:17:25.265 --> 00:17:26.036\n&gt;&gt; This is [CROSSTALK].\n\n369\n00:17:26.036 --> 00:17:27.132\n&gt;&gt; 20.\n&gt;&gt; I [CROSSTALK] this?\n\n370\n00:17:27.132 --> 00:17:30.240\n&gt;&gt; Yes, and that's the big nose.\n\n371\n00:17:30.240 --> 00:17:33.595\n&gt;&gt; And that's kind of like what\nWilliam Shatner said at the end of his\n\n372\n00:17:33.595 --> 00:17:34.395\ncomedy roast.\n\n373\n00:17:34.395 --> 00:17:38.964\nAnd he was so mad that it became\njust a dig on George Takei and\n\n374\n00:17:38.964 --> 00:17:41.119\nhis outside shenanigans.\n\n375\n00:17:41.119 --> 00:17:42.955\nAnd he's like this is all?\n\n376\n00:17:42.955 --> 00:17:44.045\n&gt;&gt; This is the best you guys have?\n\n377\n00:17:44.045 --> 00:17:47.926\nI gave you so much to work with.\n\n378\n00:17:47.926 --> 00:17:49.994\nYou know, and I was like that's awesome.\n\n379\n00:17:49.994 --> 00:17:50.545\nAll right.\n\n380\n00:17:50.545 --> 00:17:51.534\n&gt;&gt; Left me lying flat.\n\n381\n00:17:51.534 --> 00:17:57.110\n&gt;&gt; [COUGH] I think I'm done coughing.\n\n382\n00:17:57.110 --> 00:17:58.971\nIf not, we'll find out.\n\n383\n00:17:58.971 --> 00:17:59.941\n&gt;&gt; Cuz he'll do it again.\n\n384\n00:17:59.941 --> 00:18:01.344\n&gt;&gt; Yeah [LAUGH].\n\n385\n00:18:01.344 --> 00:18:04.917\n&gt;&gt; If I'm not done coughing,\njust wait five minutes, it'll come back.\n\n386\n00:18:04.917 --> 00:18:05.727\n&gt;&gt; Be a good time.\n\n387\n00:18:05.727 --> 00:18:07.673\n&gt;&gt; All right,\nyou guys really take a [INAUDIBLE].\n\n388\n00:18:07.673 --> 00:18:13.642\n&gt;&gt; Yes, sir.\n\n389\n00:18:13.642 --> 00:18:19.168\nTravelled back in time to save\nan aquatic race from total annihilation.\n\n390\n00:18:19.168 --> 00:18:25.029\nAll right Wes, now let's move on.\n\n391\n00:18:25.029 --> 00:18:29.464\nAnother type of identity, or\nalong that vein, is federated services or\n\n392\n00:18:29.464 --> 00:18:30.853\nfederation, right?\n\n393\n00:18:30.853 --> 00:18:32.333\n&gt;&gt; Federations, that's right.\n\n394\n00:18:32.333 --> 00:18:35.725\nThey're blocking all the trade\nroutes leading off of that planet.\n\n395\n00:18:35.725 --> 00:18:38.742\nWrong type of federation,\nbut fun nonetheless.\n\n396\n00:18:38.742 --> 00:18:40.631\nWhen we talk about federations guys,\n\n397\n00:18:40.631 --> 00:18:44.003\nI want you to think about when you\nhave two separate organizations.\n\n398\n00:18:44.003 --> 00:18:46.640\nFor instance,\nmaybe you have a manufacturer, and\n\n399\n00:18:46.640 --> 00:18:48.364\nmaybe you have a supplier right.\n\n400\n00:18:48.364 --> 00:18:50.866\nManufacture some kind of product but\n\n401\n00:18:50.866 --> 00:18:55.624\nthey also spend a lot of time inside\nof maybe the suppliers databases or\n\n402\n00:18:55.624 --> 00:19:01.446\ninfrastructure right buying the parts that\nthey need to manufacture what they need.\n\n403\n00:19:01.446 --> 00:19:06.260\nWouldn't it be nice to have a way if you\nwill that we can do a federated trust in\n\n404\n00:19:06.260 --> 00:19:11.153\nwhich these two systems can use a single\nidentity management solution Across\n\n405\n00:19:11.153 --> 00:19:13.501\nthese organizational boundaries.\n\n406\n00:19:13.501 --> 00:19:17.060\nAnd that's essentially\nwhat a federation is.\n\n407\n00:19:17.060 --> 00:19:18.961\nWe see these a lot today.\n\n408\n00:19:18.961 --> 00:19:21.575\nThey help us implement things\nlike single sign-ons, right?\n\n409\n00:19:21.575 --> 00:19:25.342\nI don't want to have to enter my\npassword to go into the local.\n\n410\n00:19:25.342 --> 00:19:26.566\nWell, we do that anyways.\n\n411\n00:19:26.566 --> 00:19:28.210\nWe have to log on to our systems at work.\n\n412\n00:19:28.210 --> 00:19:30.654\nBut then,\nI don't want to have to sit there and\n\n413\n00:19:30.654 --> 00:19:32.848\ncontinually log on to the manufacturer or\n\n414\n00:19:32.848 --> 00:19:37.003\nthe supplier's network to every different\nthing that I maybe wanna log into.\n\n415\n00:19:37.003 --> 00:19:40.988\nSo we can implement a federation and\nthat allows us to do a single sign-on.\n\n416\n00:19:40.988 --> 00:19:44.408\nNow, maybe you haven't seen this\ninside of a business environment.\n\n417\n00:19:44.408 --> 00:19:48.738\nBut I would almost be willing to bet that\nyou see this inside of maybe a public\n\n418\n00:19:48.738 --> 00:19:49.644\nenvironment.\n\n419\n00:19:49.644 --> 00:19:53.744\nMaybe you didn't even know that,\nthat was going on behind the scenes.\n\n420\n00:19:53.744 --> 00:19:56.734\nIf any of you out there have\nthings like MSAs all right.\n\n421\n00:19:56.734 --> 00:20:01.937\nWhat I mean by MSA's is again acronyms,\nI'm a culprit of my own demise here.\n\n422\n00:20:01.937 --> 00:20:04.275\nWe talk about the Microsoft account right?\n\n423\n00:20:04.275 --> 00:20:06.351\nWhat does the Microsoft\naccount allow you to do?\n\n424\n00:20:06.351 --> 00:20:09.619\nWell, it allows you to do things\nlike log on to Windows right?\n\n425\n00:20:09.619 --> 00:20:11.489\nBut that's not the only thing\nit allows you to do right?\n\n426\n00:20:11.489 --> 00:20:14.237\nIt allows you to log onto\nthe Windows store as well.\n\n427\n00:20:14.237 --> 00:20:18.238\nAnd then log into your\nXbox Live interface, and\n\n428\n00:20:18.238 --> 00:20:24.056\nthen log into OneDrive, and\nthen log into your online Office suite.\n\n429\n00:20:24.056 --> 00:20:25.819\nBut you only had to enter\nin your password once.\n\n430\n00:20:25.819 --> 00:20:27.465\n&gt;&gt; It seems that this Federation and\n\n431\n00:20:27.465 --> 00:20:29.827\nSingle Sign On idea\nare just married together.\n\n432\n00:20:29.827 --> 00:20:30.893\n&gt;&gt; They absolutely are,\n\n433\n00:20:30.893 --> 00:20:34.383\nFederation is the way that we can\nachieve a form of Single Sign On, right?\n\n434\n00:20:34.383 --> 00:20:36.932\nNow, it's not the only\nmethod of Single Sign On but\n\n435\n00:20:36.932 --> 00:20:39.734\nis one of the ways we can achieve\na form of single sign on.\n\n436\n00:20:39.734 --> 00:20:41.564\nIn fact,\nlet me give you another example here.\n\n437\n00:20:41.564 --> 00:20:44.545\nSo I got a little diagram here.\n\n438\n00:20:44.545 --> 00:20:46.405\nThese are all major players out there.\n\n439\n00:20:46.405 --> 00:20:48.273\nRight, you guys can recognize them.\n\n440\n00:20:48.273 --> 00:20:52.474\nThings like Yahoo!, things like Twitter,\nthings like Google, things like Facebook.\n\n441\n00:20:52.474 --> 00:20:57.020\nHow many applications have you been\nto that haven't been, excuse me,\n\n442\n00:20:57.020 --> 00:21:01.357\ntry a little better English here,\nowned by any of these companies.\n\n443\n00:21:01.357 --> 00:21:02.113\nBut what does it do?\n\n444\n00:21:02.113 --> 00:21:05.594\nWhen you go to log in, it says hey,\nlog in with your Facebook account,\n\n445\n00:21:05.594 --> 00:21:07.666\nlog in with your Google account, right?\n\n446\n00:21:07.666 --> 00:21:08.509\nAnd then what happens?\n\n447\n00:21:08.509 --> 00:21:14.818\nWell, this application here,\nit doesn't have Google's database, right?\n\n448\n00:21:14.818 --> 00:21:18.455\nBut it's using Google's identities\nin order to log you in, right?\n\n449\n00:21:18.455 --> 00:21:21.383\nSo cross those boundaries if you will.\n\n450\n00:21:21.383 --> 00:21:23.858\nAnd that's this,\nessentially what a federated, or\n\n451\n00:21:23.858 --> 00:21:25.233\na federation allows us to do.\n\n452\n00:21:25.233 --> 00:21:29.259\nRight, and this is one, this is\na commonality that you guys are probably\n\n453\n00:21:29.259 --> 00:21:32.499\nseeing out there, or\nmaybe even using right now, right.\n\n454\n00:21:32.499 --> 00:21:35.378\nBut you can also do this through\nthings like active directory,\n\n455\n00:21:35.378 --> 00:21:36.475\nfederation services.\n\n456\n00:21:36.475 --> 00:21:41.132\nIf you have active directory domains, you\ncan set up things like trust federations,\n\n457\n00:21:41.132 --> 00:21:45.595\nor federated trust as they're called, and\nyou can allow one identity management\n\n458\n00:21:45.595 --> 00:21:49.172\nsolution to authenticate even\nif it's outside of your company.\n\n459\n00:21:49.172 --> 00:21:51.858\nSo that's one of the great benefits and\nagain,\n\n460\n00:21:51.858 --> 00:21:54.959\nallowing you that advantage\nof a single sign on right.\n\n461\n00:21:54.959 --> 00:21:59.355\nMakes it a little bit more\nsimplistic to end users.\n\n462\n00:21:59.355 --> 00:22:01.753\nWhat's another thing\nthat federation services.\n\n463\n00:22:01.753 --> 00:22:05.671\nWhy would you like to do some\nkinda Federated service.\n\n464\n00:22:05.671 --> 00:22:07.257\nI want you to think about e-commerce.\n\n465\n00:22:07.257 --> 00:22:09.473\nDan, I don't know about you, bud,\nbut I'll tell you one thing.\n\n466\n00:22:09.473 --> 00:22:14.044\nWhen I have to wait more than like 30\nseconds, maybe even less than that, for\n\n467\n00:22:14.044 --> 00:22:17.876\na form to come, which,\nI've got to fill out all these fields.\n\n468\n00:22:17.876 --> 00:22:20.987\nOkay, now I created my user account and\nI can log in and\n\n469\n00:22:20.987 --> 00:22:23.006\nI could purchase a product right?\n\n470\n00:22:23.006 --> 00:22:23.585\n&gt;&gt; You want patience?\n\n471\n00:22:23.585 --> 00:22:24.303\nBecome a doctor.\n\n472\n00:22:24.303 --> 00:22:26.349\n[LAUGH]\n&gt;&gt; That's right.\n\n473\n00:22:26.349 --> 00:22:27.922\nWell put.\n\n474\n00:22:27.922 --> 00:22:31.800\nSo it does stand to lose you\na little business right?\n\n475\n00:22:31.800 --> 00:22:35.961\nBecause we want to access to things now so\nin speeding up that user experience,\n\n476\n00:22:35.961 --> 00:22:40.183\nin making it convenient for the end user,\nyou can add maybe even gain a little bit\n\n477\n00:22:40.183 --> 00:22:42.914\nmore business than otherwise\nyou would have lost.\n\n478\n00:22:42.914 --> 00:22:47.350\nSo there are business cases for this,\nuse cases that will allow your company\n\n479\n00:22:47.350 --> 00:22:51.924\npotentially to have a little bit more\nrevenue because people are being annoyed\n\n480\n00:22:51.924 --> 00:22:54.696\nby all these little forms\nyou have to fill out and\n\n481\n00:22:54.696 --> 00:22:56.864\nthen they finally just move on, so.\n\n482\n00:22:56.864 --> 00:22:58.441\nIt's a great thing to have.\n\n483\n00:22:58.441 --> 00:23:02.344\nAll right, let's see, and speaking of\nthat, let's talk about single sign on\n\n484\n00:23:02.344 --> 00:23:06.091\nbecause single sign on is another, and\nthis is an example of single sign on.\n\n485\n00:23:06.091 --> 00:23:10.448\nBut, I do want it understood\nthat federated services and\n\n486\n00:23:10.448 --> 00:23:14.277\nfederations are not the only\nsingle sign on okay?\n\n487\n00:23:14.277 --> 00:23:15.634\nIt is a form of single sign on.\n\n488\n00:23:15.634 --> 00:23:17.414\nThe single sign on's\nmore the umbrella term.\n\n489\n00:23:17.414 --> 00:23:18.778\nLet me tell you why.\n\n490\n00:23:18.778 --> 00:23:21.386\nBecause there's other technologies\nthat allow a single sign on.\n\n491\n00:23:21.386 --> 00:23:23.304\nI want you to think of password vaulting,\nall right?\n\n492\n00:23:23.304 --> 00:23:26.057\nPassword vaulting is a commonality today.\n\n493\n00:23:26.057 --> 00:23:30.417\nPassword managers,\nthat's password vaulting, all right?\n\n494\n00:23:30.417 --> 00:23:33.588\nNow, you enter a single master password,\nand\n\n495\n00:23:33.588 --> 00:23:39.299\nthen that software manages the passwords\nand it gets logs on in your behalf, okay?\n\n496\n00:23:39.299 --> 00:23:40.929\nIt is not a federated trust.\n\n497\n00:23:40.929 --> 00:23:43.888\nIt isn't a federated trust\nbecause in this case,\n\n498\n00:23:43.888 --> 00:23:48.398\nlast pass they only have access to the\ndatabases inside any of the password or\n\n499\n00:23:48.398 --> 00:23:52.144\nthe applications that you put in there,\ninto their database.\n\n500\n00:23:52.144 --> 00:23:54.836\nAgain that's password vaulting, right?\n\n501\n00:23:54.836 --> 00:23:59.255\nSome kind of a password management that\nallows you to implement a single sign on.\n\n502\n00:23:59.255 --> 00:24:02.588\nEnter one password go to the all the\nwebsite that you want to Without having\n\n503\n00:24:02.588 --> 00:24:03.943\nto re-enter that password.\n\n504\n00:24:03.943 --> 00:24:07.720\nSo, I just wanted to make sure that\nwe do set the stage with that.\n\n505\n00:24:07.720 --> 00:24:11.930\nJust, it does eliminate some\nof the burden on the end user.\n\n506\n00:24:11.930 --> 00:24:14.960\nI'm not saying anything, or\nthis episode would be over.\n\n507\n00:24:14.960 --> 00:24:19.100\nI signed in one time, and\nI don't have to re-enter my password.\n\n508\n00:24:19.100 --> 00:24:20.920\nFederations are an example.\n\n509\n00:24:20.920 --> 00:24:25.550\nAgain, password managers like LastPass,\nNorton IdentitySafe is one of them,\n\n510\n00:24:25.550 --> 00:24:26.550\nto give you an example.\n\n511\n00:24:26.550 --> 00:24:28.530\nFederations are an example\nthat we mentioned.\n\n512\n00:24:28.530 --> 00:24:33.150\nThings like your Microsoft account,\nFacebook, Google, if you will.\n\n513\n00:24:33.150 --> 00:24:36.460\nThese are all things that\nyou have to keep in mind.\n\n514\n00:24:36.460 --> 00:24:41.150\nThat a single sign on, again, doesn't\njust lend itself to just federations.\n\n515\n00:24:41.150 --> 00:24:41.650\n&gt;&gt; All right.\n\n516\n00:24:41.650 --> 00:24:45.610\n&gt;&gt; All right, last thing,\nlast thing that we gotta do, that's right.\n\n517\n00:24:45.610 --> 00:24:49.060\nThere's one more, before I forget,\nand I will forget it, I tell you.\n\n518\n00:24:49.060 --> 00:24:52.801\nI'm glad I have a neck,\nit was a great design.\n\n519\n00:24:52.801 --> 00:24:55.128\n&gt;&gt; [LAUGH]\n&gt;&gt; Is transitive trust, all right?\n\n520\n00:24:55.128 --> 00:24:59.567\nAnd transitive trust, we can see these\ninside of things like Windows domains,\n\n521\n00:24:59.567 --> 00:25:00.967\nis one classic example.\n\n522\n00:25:00.967 --> 00:25:05.120\nAnd I want you to think of what we have,\nparent-child relationship, right.\n\n523\n00:25:05.120 --> 00:25:06.620\nWe have a domain and a sub-domain.\n\n524\n00:25:06.620 --> 00:25:11.430\nSo for instance we have itpro.tv and\nas we're branching out,\n\n525\n00:25:11.430 --> 00:25:12.826\nwe got a couple of sub-domains.\n\n526\n00:25:12.826 --> 00:25:17.820\nMaybe right, we got east,\nand we got west.itpro.tv.\n\n527\n00:25:17.820 --> 00:25:21.160\nLet's talk about the trust relationship\nbetween parent and child, right?\n\n528\n00:25:21.160 --> 00:25:24.690\nSo if you look at the parent,\nthe parent domain, right?\n\n529\n00:25:24.690 --> 00:25:27.010\nAnd the sub-domain, if you will,\nthat's the child domain.\n\n530\n00:25:28.100 --> 00:25:30.280\nWhen we bring up one of\nthese child domains,\n\n531\n00:25:30.280 --> 00:25:34.000\nit inherently trusts it's parent, right?\n\n532\n00:25:34.000 --> 00:25:35.348\nThat's a trust relationship.\n\n533\n00:25:35.348 --> 00:25:40.230\nIt means that, if I have\nan identity that resides in B here.\n\n534\n00:25:40.230 --> 00:25:43.279\nThat due to that relationship\nbetween the parent and the child.\n\n535\n00:25:43.279 --> 00:25:48.048\nThat means, and you don't have to set it\nup this way, but this is just an example,\n\n536\n00:25:48.048 --> 00:25:48.613\nyou can.\n\n537\n00:25:48.613 --> 00:25:52.381\nThat means that people in\nDomain B would trust, and\n\n538\n00:25:52.381 --> 00:25:58.150\nbe able to access resources in,\nDomain A, and vice versa, right?\n\n539\n00:25:58.150 --> 00:26:02.290\nJust like if we go a little farther,\nand we look at C, west.itpro.tv.\n\n540\n00:26:02.290 --> 00:26:07.260\nSame thing applies, guys,\nthis is just a wash, rinse, repeat.\n\n541\n00:26:07.260 --> 00:26:13.440\nA creates C, so C is going to trust\nA here, because it is the parent.\n\n542\n00:26:13.440 --> 00:26:17.650\nIf I have an identity inside of C, then it\nshould be able to access, doesn't have to.\n\n543\n00:26:17.650 --> 00:26:20.150\nLike I said, you can break\nthese boundaries if you want.\n\n544\n00:26:20.150 --> 00:26:24.550\nBut I should be able to\naccess resources inside of A.\n\n545\n00:26:24.550 --> 00:26:26.370\n&gt;&gt; What about B to C?\n\n546\n00:26:26.370 --> 00:26:29.195\n&gt;&gt; And that is our last one here.\n\n547\n00:26:29.195 --> 00:26:31.093\n[CROSSTALK] Very good, very good.\n\n548\n00:26:31.093 --> 00:26:32.320\nCan't trick this guy over here.\n\n549\n00:26:32.320 --> 00:26:36.200\nI'm trying like heck, let me get to\nthe right side of the river here.\n\n550\n00:26:36.200 --> 00:26:38.370\nBut that's right, so how does that work?\n\n551\n00:26:38.370 --> 00:26:41.586\nSo we say if A trusts B and A trusts C.\n\n552\n00:26:41.586 --> 00:26:44.730\nWell then, shouldn't B trust C, right?\n\n553\n00:26:44.730 --> 00:26:46.960\nAnd that's where you can see\nyour transitive trust here, too.\n\n554\n00:26:46.960 --> 00:26:50.410\nAs well in a more direct example, right?\n\n555\n00:26:50.410 --> 00:26:56.820\nB and C trust each other, because A trusts\nB, B trusts A, A trusts C, and C trusts A.\n\n556\n00:26:56.820 --> 00:26:58.635\nAnd that's it,\nthat's no more math here with\n\n557\n00:26:58.635 --> 00:26:59.930\nalphabetical-\n&gt;&gt; [LAUGH]\n\n558\n00:26:59.930 --> 00:27:01.470\n&gt;&gt; But that, essentially,\n\n559\n00:27:01.470 --> 00:27:03.400\nis what's known as a transitive trust.\n\n560\n00:27:03.400 --> 00:27:06.760\n&gt;&gt; All right, well great stuff today,\ntalking about authentication,\n\n561\n00:27:06.760 --> 00:27:07.850\nidentity management.\n\n562\n00:27:07.850 --> 00:27:09.600\nObviously, there's a lot\ngoing on with this stuff.\n\n563\n00:27:09.600 --> 00:27:13.500\nIt's not just as simple as I've got a user\nname, I've got a password, I sign in.\n\n564\n00:27:13.500 --> 00:27:16.330\nThere's a lot more complexity\nlevels to be had, and\n\n565\n00:27:16.330 --> 00:27:19.280\nto be looked at, and to be understood\nby us, as security professionals.\n\n566\n00:27:19.280 --> 00:27:21.030\nSo definitely take some time with this.\n\n567\n00:27:21.030 --> 00:27:23.600\nThis is gonna be good for\nyou, in your security career,\n\n568\n00:27:23.600 --> 00:27:26.610\nto understand these key concepts very,\nvery well.\n\n569\n00:27:26.610 --> 00:27:29.222\nWes, is there anything you'd like to\nadd before we close the show today?\n\n570\n00:27:29.222 --> 00:27:32.160\n&gt;&gt; Yeah, well, we did have one\nlast question in the chat room.\n\n571\n00:27:32.160 --> 00:27:34.810\nAnd I think it warrants putting\nit in the episode here.\n\n572\n00:27:34.810 --> 00:27:36.310\nWe love our viewers In\nthe chat room out there.\n\n573\n00:27:36.310 --> 00:27:38.750\nAnd that's right,\nthat's called a transitive trust.\n\n574\n00:27:38.750 --> 00:27:42.310\nKeep in mind, that there are also\nthings like transitive trust attacks.\n\n575\n00:27:42.310 --> 00:27:45.210\nWhere, if I can attack\nthe trusts between two domains.\n\n576\n00:27:45.210 --> 00:27:49.000\nAll I need to do is attack one domain, and\nI can make my way to the other one too.\n\n577\n00:27:49.000 --> 00:27:51.700\nSo, that's why I said you\ncan set it up this way.\n\n578\n00:27:51.700 --> 00:27:54.280\nBut sometimes for security purposes,\nyou might not allow it.\n\n579\n00:27:54.280 --> 00:27:56.730\n&gt;&gt; All right,\ngood words of wisdom by Mr. Wes Bryan.\n\n580\n00:27:56.730 --> 00:28:00.390\nWe do thank you for joining us today,\nteaching us about identity management.\n\n581\n00:28:00.390 --> 00:28:03.500\nWe thank you good folks for watching,\nbut it looks like it's that time for\n\n582\n00:28:03.500 --> 00:28:05.080\nus to sign off for ITProTV.\n\n583\n00:28:05.080 --> 00:28:06.730\nI've been your host Daniel Lowrie.\n\n584\n00:28:06.730 --> 00:28:07.520\n&gt;&gt; And I'm Wes Bryan.\n\n585\n00:28:07.520 --> 00:28:10.164\n&gt;&gt; We'll see you next time.\n\n586\n00:28:10.164 --> 00:28:16.074\n[MUSIC]\n\n587\n00:28:16.074 --> 00:28:19.235\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "221332319"
        },
        {
          "description": "In this episode, Daniel and Wes walk you through a litany of Identity and Access services. Here they discuss services like LDAP, Kerberos, PAP/CHAP/MSCHAP, RADIUS/TACACS+, SAML, OpenID Connect, OATH, Shibboleth, and NTLM.",
          "length": "1733",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-2-identity_and_access_management_concepts-050117.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-2-identity_and_access_management_concepts-050117-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-2-identity_and_access_management_concepts-050117-sm.jpg",
          "title": "Identity and Access Services",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:02.273\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.273 --> 00:00:06.359\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.359 --> 00:00:08.356\n[MUSIC]\n\n4\n00:00:08.356 --> 00:00:11.841\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.841 --> 00:00:13.711\n&gt;&gt; All right, greetings everyone and\n\n6\n00:00:13.711 --> 00:00:16.147\nwelcome to another great\nepisode of ITProTV.\n\n7\n00:00:16.147 --> 00:00:20.120\nI'm your host Daniel Lowrie and\nin today's episode guess what?\n\n8\n00:00:20.120 --> 00:00:22.780\nWe have more Security + for you today.\n\n9\n00:00:22.780 --> 00:00:26.480\nAnd, of course, joining us in the studio\nfor that, our good friend Mr. Wes Bryan.\n\n10\n00:00:26.480 --> 00:00:28.060\nWes, glad to have you back man.\n\n11\n00:00:28.060 --> 00:00:29.091\n&gt;&gt; Hey, man thanks for having me back.\n\n12\n00:00:29.091 --> 00:00:29.974\n&gt;&gt; Did you like my pregnant pause?\n\n13\n00:00:29.974 --> 00:00:31.157\n&gt;&gt; Absolutely, I love it man.\n\n14\n00:00:31.157 --> 00:00:32.678\nJust wait, wait for it, wait for it.\n\n15\n00:00:32.678 --> 00:00:33.770\n&gt;&gt; And now, right [LAUGH].\n\n16\n00:00:33.770 --> 00:00:34.429\n&gt;&gt; That's great.\n\n17\n00:00:34.429 --> 00:00:35.183\n[LAUGH] Yeah, that's right.\n\n18\n00:00:35.183 --> 00:00:36.032\nThanks for having me back.\n\n19\n00:00:36.032 --> 00:00:39.527\nYeah, we are gonna be looking at\nsome of the services behind, well,\n\n20\n00:00:39.527 --> 00:00:42.095\njust identities and access in general.\n\n21\n00:00:42.095 --> 00:00:44.045\nAnd there are a handful\nthat they call out, guys,\n\n22\n00:00:44.045 --> 00:00:47.595\nand when it comes to it,\non a scenario that they might give you.\n\n23\n00:00:47.595 --> 00:00:50.710\nThey might give you like a multiple\nchoice question where they say,\n\n24\n00:00:50.710 --> 00:00:54.150\nokay, you need to perform x, y,\nz, which of these protocols, or\n\n25\n00:00:54.150 --> 00:00:57.710\nwhich of these services are an example\nof how you get that done?\n\n26\n00:00:57.710 --> 00:01:00.700\nSo it is gonna be good for\nyou to understand these services and\n\n27\n00:01:00.700 --> 00:01:05.160\nwhere you're gonna find them inside\nof your network infrastructure.\n\n28\n00:01:05.160 --> 00:01:06.940\nSo some of the first\nones that they call out.\n\n29\n00:01:06.940 --> 00:01:09.380\nVery first one they called out\nhas been around for a while and\n\n30\n00:01:09.380 --> 00:01:11.520\nthat's is known as LDAP.\n\n31\n00:01:11.520 --> 00:01:15.080\nThat is the Lightweight\nDirectory Access Protocol, and\n\n32\n00:01:15.080 --> 00:01:17.850\nthis really, when it comes down to it,\nis the protocol that we\n\n33\n00:01:17.850 --> 00:01:21.390\nuse to access information that's\nstored on a directory server.\n\n34\n00:01:21.390 --> 00:01:24.366\nYou might hear terms like X.500,\n\n35\n00:01:24.366 --> 00:01:29.890\nX.500 is an Internet standard,\nif you will, for directory services.\n\n36\n00:01:29.890 --> 00:01:34.641\nAnd X.500 uses the Lightweight\nDirectory Access Protocol to\n\n37\n00:01:34.641 --> 00:01:37.671\naccess directory service information.\n\n38\n00:01:37.671 --> 00:01:42.499\nSo do keep that in mind, anytime you have,\nfor instance, domain controller,\n\n39\n00:01:42.499 --> 00:01:45.310\nthe domain controller is\ngonna be running your\n\n40\n00:01:45.310 --> 00:01:47.847\nLight Weight Directory Acess Protocol.\n\n41\n00:01:47.847 --> 00:01:50.360\nKeep in mind some of the ports\nthat are available for\n\n42\n00:01:50.360 --> 00:01:54.627\nLight Weight Directory Acess Protocol,\nyou say, well, wait a second, is it ports,\n\n43\n00:01:54.627 --> 00:01:55.868\nthere's more than one?\n\n44\n00:01:55.868 --> 00:01:57.693\nWell, technically no, there's one.\n\n45\n00:01:57.693 --> 00:02:02.916\nBut in some instances you might have\nsecure LDAP on your network and\n\n46\n00:02:02.916 --> 00:02:05.350\nit does have a different port.\n\n47\n00:02:05.350 --> 00:02:07.476\nSo let's just keep that in mind,\nwhen you have LDAP,\n\n48\n00:02:07.476 --> 00:02:11.620\nLight Weight Directory Acess Protocol,\nyou're talking about port 389.\n\n49\n00:02:11.620 --> 00:02:16.430\nAnd the reason I do take the time\nto mention the ports is because you\n\n50\n00:02:16.430 --> 00:02:18.880\nmight say, well, wait a second,\nwhy this is not a networking class?\n\n51\n00:02:18.880 --> 00:02:20.020\nThis is a security class.\n\n52\n00:02:20.020 --> 00:02:21.726\nWell, if I'm doing port filtering,\n\n53\n00:02:21.726 --> 00:02:25.140\nif I'm doing port scanning,\nI need to know what those ports are.\n\n54\n00:02:25.140 --> 00:02:29.415\nSo understanding that the ports\nare important on your Security + exam,\n\n55\n00:02:29.415 --> 00:02:30.265\nso port 389.\n\n56\n00:02:30.265 --> 00:02:32.125\nLittle bit of an exam alert on this one,\ntoo.\n\n57\n00:02:32.125 --> 00:02:34.525\nBecause there's another port out there,\njust like so\n\n58\n00:02:34.525 --> 00:02:38.375\nmany things in IT that run really,\nreally close and could trick you.\n\n59\n00:02:38.375 --> 00:02:42.669\nAnd that's the Remote Desktop Protocol,\nRDP's port, that's port 3389.\n\n60\n00:02:42.669 --> 00:02:46.709\nSo you can see that might be something,\nnot so much that they're trying to trick\n\n61\n00:02:46.709 --> 00:02:50.382\nyah, it's just they wanna know,\ndo you know the difference, right?\n\n62\n00:02:50.382 --> 00:02:52.393\nSo LDAP, 389, single 3, right?\n\n63\n00:02:52.393 --> 00:02:55.964\n[LAUGH] RDP is port 3389,\ndo not get those confused.\n\n64\n00:02:55.964 --> 00:03:00.190\nAnd the other one that I mentioned\nis secure LDAP and that is port 636.\n\n65\n00:03:00.190 --> 00:03:02.374\nIn fact,\nI've got a domain controller here,\n\n66\n00:03:02.374 --> 00:03:04.283\nwe can actually kinda see the port here.\n\n67\n00:03:04.283 --> 00:03:06.138\nIf I drop down to my command prompt here.\n\n68\n00:03:06.138 --> 00:03:08.180\nLet's see I believe I got that open.\n\n69\n00:03:08.180 --> 00:03:11.760\nLet's go ahead and\njust clear this real quick.\n\n70\n00:03:11.760 --> 00:03:14.950\nAnd I do something like, for\ninstance, I do a netstat here.\n\n71\n00:03:14.950 --> 00:03:18.490\nYou're gonna see, well,\nI have port 389 is open.\n\n72\n00:03:18.490 --> 00:03:22.390\nAgain, that's because this is a domain\ncontroller, so what is it doing?\n\n73\n00:03:22.390 --> 00:03:26.300\nWhen you're accessing directory\ninformation off of the domain controller,\n\n74\n00:03:26.300 --> 00:03:29.080\nit has to be,\nit's a client-server protocol, right?\n\n75\n00:03:29.080 --> 00:03:31.920\nAnd the server is listening\nout on port 389 to\n\n76\n00:03:31.920 --> 00:03:34.070\nreceive that incoming communication.\n\n77\n00:03:34.070 --> 00:03:36.530\nSo, you can see signs of that there too.\n\n78\n00:03:36.530 --> 00:03:39.920\nI also mentioned X.500 just in case it\n\n79\n00:03:39.920 --> 00:03:44.660\ncomes up on the exam as being an Internet\nstandard for directory services.\n\n80\n00:03:44.660 --> 00:03:48.530\nIt's not something that I would really\nworry about too much other than that but\n\n81\n00:03:48.530 --> 00:03:52.780\nas a little tidbit just in case they\nask you'll be prepared for that.\n\n82\n00:03:52.780 --> 00:03:57.210\nIt runs and coincides with other\nx.standards like X.509 is for\n\n83\n00:03:57.210 --> 00:03:59.240\ncertificate based authentication, right?\n\n84\n00:03:59.240 --> 00:03:59.965\nPublic Key Infrastructure.\n\n85\n00:03:59.965 --> 00:04:02.552\nSo, you could see some\ncommonalities on that.\n\n86\n00:04:02.552 --> 00:04:05.957\nAnd that is a big protocol that we\ndo need to keep in mind because\n\n87\n00:04:05.957 --> 00:04:09.037\nit's very common inside of\nyour domain environments,\n\n88\n00:04:09.037 --> 00:04:12.650\nand very specifically,\non your directory service databases.\n\n89\n00:04:12.650 --> 00:04:14.100\n&gt;&gt; Now, Wes, another big heavy hitter,\n\n90\n00:04:14.100 --> 00:04:17.760\nif you're gonna talk about the big\ndogs in the game, is Kerberos, right?\n\n91\n00:04:17.760 --> 00:04:21.700\nKerberos is one of the most prevalent\ntypes of authenticating systems.\n\n92\n00:04:21.700 --> 00:04:25.920\n&gt;&gt; Yeah, Kerberos is one of those ones\nthat was started up out there at MIT,\n\n93\n00:04:25.920 --> 00:04:30.522\nif you will, by those guys and gals that\ndrink way too much coffee, have no life.\n\n94\n00:04:30.522 --> 00:04:34.010\nI'm convinced are always in\nfront of a computer screen.\n\n95\n00:04:34.010 --> 00:04:36.720\nJust kidding out there, you guys at MIT,\nbrilliant minds out there.\n\n96\n00:04:36.720 --> 00:04:40.817\nAnd they came up with an authentication\nprotocol that helps to protect against\n\n97\n00:04:40.817 --> 00:04:43.590\nsome common attacks that\nwe have to worry about.\n\n98\n00:04:43.590 --> 00:04:45.970\nThings like replay attacks, right?\n\n99\n00:04:45.970 --> 00:04:50.280\nWhere a replay attack is one where\nI gather that information if Dan's\n\n100\n00:04:50.280 --> 00:04:53.610\npassing information between himself and\nanother endpoint, and\n\n101\n00:04:53.610 --> 00:04:57.380\nI've got my protocol analyzer out there\nand I sniff some of that traffic.\n\n102\n00:04:57.380 --> 00:05:00.517\nAnd I grab that information that\nDan's presenting to the server and\n\n103\n00:05:00.517 --> 00:05:03.982\nI hold it, then at a later time what\nwould I do, I pass it back to the server,\n\n104\n00:05:03.982 --> 00:05:05.790\ntrying to impersonate Dan.\n\n105\n00:05:05.790 --> 00:05:08.180\nAnd let's say,\nit's a replay attack, right?\n\n106\n00:05:08.180 --> 00:05:12.760\nAnd if we have things like time stamps,\nsequential values.\n\n107\n00:05:12.760 --> 00:05:17.410\nOther information that identifies\na communication as a part of\n\n108\n00:05:17.410 --> 00:05:19.270\na specific session,\n\n109\n00:05:19.270 --> 00:05:23.030\nthen what we can do is we can ensure that\nthings like replay attack doesn't happen.\n\n110\n00:05:23.030 --> 00:05:26.260\nAnd that's one of the things that\nKerberos helps and allows us to do.\n\n111\n00:05:26.260 --> 00:05:29.300\nIn fact I got a little diagram here\nto kinda walk us through the Kerberos\n\n112\n00:05:29.300 --> 00:05:30.250\nprocess.\n\n113\n00:05:30.250 --> 00:05:32.050\nOr Kerberos, however, you want to say it.\n\n114\n00:05:32.050 --> 00:05:34.900\nI'm not exactly sure how you should\nsay that, but they just pick one.\n\n115\n00:05:36.220 --> 00:05:39.510\nA client goes to log on\nto a Kerberos server.\n\n116\n00:05:39.510 --> 00:05:40.980\nAnd, so what happens?\n\n117\n00:05:40.980 --> 00:05:44.175\nWell, the Kerberos Server inspects\nthe authentication credentials like we've\n\n118\n00:05:44.175 --> 00:05:47.505\ntalked about in other episodes, you've got\nto make sure that you're authenticated\n\n119\n00:05:47.505 --> 00:05:49.650\nfirst, you've typed your password right.\n\n120\n00:05:49.650 --> 00:05:53.840\nBut saying that that has happened and the\nKerberos Server what it does is it passes\n\n121\n00:05:53.840 --> 00:05:57.870\nyou back what's known as a TGT, and\nthat's a ticket granting ticket.\n\n122\n00:05:57.870 --> 00:06:01.660\nNow I want you to understand that your\ncomputer, while you're logged in,\n\n123\n00:06:01.660 --> 00:06:03.956\nis gonna cache that\nticket granting ticket.\n\n124\n00:06:03.956 --> 00:06:06.934\nNow what happens, okay, so\nyou've logged into the machine,\n\n125\n00:06:06.934 --> 00:06:10.136\nyou've logged in the domain,\nin this case your Kerberos server and\n\n126\n00:06:10.136 --> 00:06:12.571\nWindows domain is gonna\nbe the domain controller.\n\n127\n00:06:12.571 --> 00:06:16.911\nAnd now you've got this TGT that's cached,\nthis ticket granting ticket, and\n\n128\n00:06:16.911 --> 00:06:18.674\nit's stored on your computer.\n\n129\n00:06:18.674 --> 00:06:21.090\nSo what do you do with it from then on?\n\n130\n00:06:21.090 --> 00:06:23.180\nWell, it's kinda interesting\nbecause you would think, well,\n\n131\n00:06:23.180 --> 00:06:26.200\nmaybe if I present that ticket\nto the resource, right?\n\n132\n00:06:26.200 --> 00:06:29.170\nLet's say Dan was the resource, I hand\nthat ticket over to him, you might think,\n\n133\n00:06:29.170 --> 00:06:30.280\nwell, you gain access.\n\n134\n00:06:30.280 --> 00:06:32.880\nAnd here's where the clever thing goes on.\n\n135\n00:06:32.880 --> 00:06:35.210\nIt's not the TGT,\nthe ticket granting ticket,\n\n136\n00:06:35.210 --> 00:06:37.950\nthat is ever presented to a resource,\nright?\n\n137\n00:06:37.950 --> 00:06:40.580\nWhat happens is when you\ngo to access a server,\n\n138\n00:06:40.580 --> 00:06:44.580\nthe first thing your\ncomputer does is it presents\n\n139\n00:06:44.580 --> 00:06:49.750\nback to the Kerberos server the client\nTGT, the ticket granting ticket.\n\n140\n00:06:49.750 --> 00:06:50.590\nAnd what happens?\n\n141\n00:06:50.590 --> 00:06:53.380\nWell, the Kerberos server\ninspects the validity.\n\n142\n00:06:53.380 --> 00:06:56.250\nRemember we were talking\nabout replay attacks?\n\n143\n00:06:56.250 --> 00:06:58.140\nWell, what if this is a replay attack?\n\n144\n00:06:58.140 --> 00:07:01.310\nWell, that TGT is kinda\nlike a session ticket for\n\n145\n00:07:01.310 --> 00:07:04.380\nthat time that you're logged in,\nbut it has a timestamp on it.\n\n146\n00:07:04.380 --> 00:07:08.218\nSo when it's presented back\nto the Kerberos server.\n\n147\n00:07:08.218 --> 00:07:11.520\nI know on Windows domain by default it's\nfive minutes, so it can be adjusted, so\n\n148\n00:07:11.520 --> 00:07:14.140\nthis variance might be\na little bit different if it's\n\n149\n00:07:14.140 --> 00:07:15.940\nmanually configured on your network.\n\n150\n00:07:15.940 --> 00:07:19.300\nBut that timestamp has to\nbe within five minutes,\n\n151\n00:07:19.300 --> 00:07:22.940\nif you will,\nof the master clock within the domain.\n\n152\n00:07:22.940 --> 00:07:25.660\nIf not, it's thrown away, right?\n\n153\n00:07:25.660 --> 00:07:28.110\nAgain, it prevents those replay attacks.\n\n154\n00:07:28.110 --> 00:07:31.360\nBut, if it's inspected,\nit's considered valid, it's validated.\n\n155\n00:07:31.360 --> 00:07:34.390\nThen what happens is\nthe Kerberos server issues back\n\n156\n00:07:34.390 --> 00:07:37.370\nto the client what's known\nas a service ticket.\n\n157\n00:07:37.370 --> 00:07:41.780\nAnd this is kind of the fascinating,\nto me, the fascinating part behind it.\n\n158\n00:07:41.780 --> 00:07:46.082\nIs that the client, random text on\nthe screen, the client actually\n\n159\n00:07:46.082 --> 00:07:50.619\npresents the service ticket, and\nthat's presented to the resource.\n\n160\n00:07:50.619 --> 00:07:54.410\nWell, I want you to\nunderstand something that,\n\n161\n00:07:54.410 --> 00:07:58.389\nthat client resource,\nwhy is the ticket trusted?\n\n162\n00:07:58.389 --> 00:08:02.309\nWell, the service ticket is trusted\nbecause the resource server I trust\n\n163\n00:08:02.309 --> 00:08:04.440\nthe authority that issued it, right?\n\n164\n00:08:04.440 --> 00:08:07.850\nSo, it's not the TGT that's\never handed to a resource.\n\n165\n00:08:07.850 --> 00:08:10.830\nThe TGT just grants you a service ticket\n\n166\n00:08:10.830 --> 00:08:14.730\nto access additional resources\ninside of your domain.\n\n167\n00:08:14.730 --> 00:08:16.230\n&gt;&gt; It's like saying, hey, I know a guy.\n\n168\n00:08:16.230 --> 00:08:17.047\n&gt;&gt; That is exactly it.\n\n169\n00:08:17.047 --> 00:08:17.726\n&gt;&gt; You know Paulie?\n\n170\n00:08:17.726 --> 00:08:18.631\nYeah, you're good, right?\n\n171\n00:08:18.631 --> 00:08:19.350\n&gt;&gt; That's right.\n\n172\n00:08:19.350 --> 00:08:21.833\nAnd that's one of the reasons,\nfor instance,\n\n173\n00:08:21.833 --> 00:08:26.181\nlet's kinda take that over into a Windows\ndomain while your computer's time clock\n\n174\n00:08:26.181 --> 00:08:30.490\nhas to be synchronized within five minutes\nof the master time clock on the domain.\n\n175\n00:08:30.490 --> 00:08:31.386\nWhy?\n\n176\n00:08:31.386 --> 00:08:34.823\nWell, because if it doesn't these,\ntimestamps don't match, right?\n\n177\n00:08:34.823 --> 00:08:36.969\nAnd if the timestamps don't match,\nthey're not trusted.\n\n178\n00:08:36.969 --> 00:08:40.931\nAnd you might hear that the computer loses\nits trust relationship with the domain.\n\n179\n00:08:40.931 --> 00:08:44.450\nAnd you have to bring it off of\nthe domain and then rejoin it and\n\n180\n00:08:44.450 --> 00:08:46.039\nit synchronizes its time.\n\n181\n00:08:46.039 --> 00:08:50.763\nSo keep in mind that timestamping inside\nof Kerberos is very sensitive and\n\n182\n00:08:50.763 --> 00:08:52.295\nit's very important.\n\n183\n00:08:52.295 --> 00:08:55.257\nAnd it's one of the things that helps\nprotect us against things like those\n\n184\n00:08:55.257 --> 00:08:55.987\nreplay attacks.\n\n185\n00:08:55.987 --> 00:09:00.038\nThe other thing that I'll\nmention too about Kerberos or\n\n186\n00:09:00.038 --> 00:09:03.755\nKerberos is the fact that\nit operates at port 88.\n\n187\n00:09:03.755 --> 00:09:07.530\nAnd again, one of the reasons that we're\nmentioning these ports is because for\n\n188\n00:09:07.530 --> 00:09:09.841\nother technologies and\nother exam objectives,\n\n189\n00:09:09.841 --> 00:09:13.613\nthe more you know about these ports, the\nmore they can help you fill in blanks and\n\n190\n00:09:13.613 --> 00:09:15.778\nquestions that you might\nget in other areas.\n\n191\n00:09:15.778 --> 00:09:18.749\nEven if they're not directly related\nto what we're talking about right here.\n\n192\n00:09:18.749 --> 00:09:22.781\nSo know the Kerboeros protocol,\nwe're looking at port 88.\n\n193\n00:09:22.781 --> 00:09:23.579\n&gt;&gt; Excellent stuff.\n\n194\n00:09:23.579 --> 00:09:27.945\nAnother one that's can come up when it\ncomes to authentication is an interesting\n\n195\n00:09:27.945 --> 00:09:29.365\none called CHAP, right?\n\n196\n00:09:29.365 --> 00:09:31.820\nI always like this one just\nbecause I like the word chap.\n\n197\n00:09:31.820 --> 00:09:34.138\nIt makes me think of,\na jolly good chap, right?\n\n198\n00:09:34.138 --> 00:09:36.457\nAnd Wes,\ncan you tell us a little more about CHAP?\n\n199\n00:09:36.457 --> 00:09:38.836\n&gt;&gt; Yeah, and you know what,\nI'm gonna leave that one for\n\n200\n00:09:38.836 --> 00:09:41.019\na second to understand why\nwe would even use CHAP.\n\n201\n00:09:41.019 --> 00:09:42.935\nThere was a predecessor before that.\n\n202\n00:09:42.935 --> 00:09:45.102\nAnd I know my notes are a little\nbit out of order, and\n\n203\n00:09:45.102 --> 00:09:47.530\nthat's password authentication protocol.\n\n204\n00:09:47.530 --> 00:09:53.170\nAnd the reason I mention PAP before CHAP\nis so that we realize why CHAP came out.\n\n205\n00:09:53.170 --> 00:09:55.410\nWith a password authentication protocol,\nPAP,\n\n206\n00:09:55.410 --> 00:09:58.090\nin a Windows environment it's\ncalled unencrypted password, right?\n\n207\n00:09:58.090 --> 00:10:00.850\nIt is a plain text\nauthentication protocol, right?\n\n208\n00:10:00.850 --> 00:10:04.960\nSo if, let's say Dan's laptop\nhappens to be the PAP server, and\n\n209\n00:10:04.960 --> 00:10:08.180\nI'm gonna log in, I'm gonna type\nin my username and password.\n\n210\n00:10:08.180 --> 00:10:10.980\nIf Hacker Come Lately's out there on\nthe network, and they intercept that\n\n211\n00:10:10.980 --> 00:10:13.566\ninformation, they can see the username and\npassword in plain text.\n\n212\n00:10:13.566 --> 00:10:16.585\nDoesn't do a lot for\nconfidentiality, does it, right?\n\n213\n00:10:16.585 --> 00:10:18.800\n[LAUGH] So that's a problem.\n\n214\n00:10:18.800 --> 00:10:21.720\nAnd that's where enter\ninto the scene CHAP.\n\n215\n00:10:21.720 --> 00:10:24.335\nThe challenge handshake\nauthentication protocol, right?\n\n216\n00:10:24.335 --> 00:10:27.890\nNow, with the challenge handshake\nauthentication protocol,\n\n217\n00:10:27.890 --> 00:10:31.441\none of the things that's kind of\nvery cool about this protocol,\n\n218\n00:10:31.441 --> 00:10:36.137\nother than the name, it's the fact that\nthe password itself, never hits the wire.\n\n219\n00:10:36.137 --> 00:10:38.373\nAnd that's one of the beauties\nof the challenge handshake\n\n220\n00:10:38.373 --> 00:10:39.471\nauthentication protocol.\n\n221\n00:10:39.471 --> 00:10:42.234\nIn fact, let me kinda walk\nyou through the process here.\n\n222\n00:10:42.234 --> 00:10:45.497\nI got a little diagram, we'll kinda\nzoom in on each little step here.\n\n223\n00:10:45.497 --> 00:10:46.711\nI know it's kinda hard to see.\n\n224\n00:10:46.711 --> 00:10:49.719\nBut it is a multiple step process and\n\n225\n00:10:49.719 --> 00:10:54.090\nI want you to keep in mind a handshake,\nright?\n\n226\n00:10:54.090 --> 00:10:57.610\nHandshaking process, we can see this\nin a lot of different protocols and\n\n227\n00:10:57.610 --> 00:10:58.618\ntechnologies and networks.\n\n228\n00:10:58.618 --> 00:11:01.520\nWhen we talk about transmission control\nprotocol and setting up connection\n\n229\n00:11:01.520 --> 00:11:05.150\noriented services,wWe go through what's\nknown as TCP three-way handshake.\n\n230\n00:11:05.150 --> 00:11:08.600\nSo handshaking isn't something\nthat's unique to CHAP itself.\n\n231\n00:11:08.600 --> 00:11:11.930\nIt's just a mechanism in order\nto do the validation and\n\n232\n00:11:11.930 --> 00:11:14.190\nthe exchange of that\nauthentication information.\n\n233\n00:11:14.190 --> 00:11:17.876\nSo the first thing that happens\nis there's a connection request.\n\n234\n00:11:17.876 --> 00:11:20.026\nOnce the connection request is received,\n\n235\n00:11:20.026 --> 00:11:23.439\nthere's an authentication challenge\nthat happens next, right?\n\n236\n00:11:23.439 --> 00:11:27.199\nAfter that, there's a challenge,\nagain, response.\n\n237\n00:11:27.199 --> 00:11:30.368\nBasically, just a response\nto the initial challenge.\n\n238\n00:11:30.368 --> 00:11:35.143\nAnd then the final process of this is\nthe authentication is either gonna be\n\n239\n00:11:35.143 --> 00:11:37.625\naccepted or it's gonna be rejected.\n\n240\n00:11:37.625 --> 00:11:42.853\nNow if the challenge is received by\nthe CHAP server, and it looks at it.\n\n241\n00:11:42.853 --> 00:11:46.635\nAnd the challenge, either through\nincorrectly typing the password or\n\n242\n00:11:46.635 --> 00:11:50.226\njust typing the wrong password,\ncuz you don't know the password,\n\n243\n00:11:50.226 --> 00:11:53.077\nthen it's going to be\nan authentication rejection.\n\n244\n00:11:53.077 --> 00:11:55.390\nAnd then the connection's\ngonna be terminated.\n\n245\n00:11:55.390 --> 00:11:58.028\nIf it happens to be\nan authentication that's accepted,\n\n246\n00:11:58.028 --> 00:12:03.890\nthen the connection's gonna happen and\nthen communications after that.\n\n247\n00:12:03.890 --> 00:12:05.560\nBut we can dig a little\nbit further down and\n\n248\n00:12:05.560 --> 00:12:09.150\nsee what's going on with this\nCHAP process, all right?\n\n249\n00:12:09.150 --> 00:12:11.630\nThe connection request, just so\nyou guys know, again, for\n\n250\n00:12:11.630 --> 00:12:16.210\nthe exam goes over something known as LCP,\nthat's the link control protocol.\n\n251\n00:12:16.210 --> 00:12:19.620\nNow I wanna talk about that\nthe Authentication Challenge.\n\n252\n00:12:19.620 --> 00:12:22.770\nThe Authentication Challenge\nis just a random string\n\n253\n00:12:22.770 --> 00:12:24.350\nthat the server sends back to the client.\n\n254\n00:12:25.460 --> 00:12:26.200\nHere's the beauty of it.\n\n255\n00:12:26.200 --> 00:12:28.646\nRemember I told you the password\nwe authenticate, but\n\n256\n00:12:28.646 --> 00:12:32.006\nthe password never hits the wire,\nperverbably, never hits the network?\n\n257\n00:12:32.006 --> 00:12:36.928\nWell, that's because here's what\nthe client does with the challenge.\n\n258\n00:12:36.928 --> 00:12:42.547\nIt takes the original challenge,\nit adds the client password.\n\n259\n00:12:42.547 --> 00:12:45.758\nAnd it takes it and it produces\na hashed value of that password,\n\n260\n00:12:45.758 --> 00:12:48.170\nwith the password and the challenge.\n\n261\n00:12:48.170 --> 00:12:51.000\nBut notice it's just a hashed value\nof the combination of the two,\n\n262\n00:12:51.000 --> 00:12:54.710\nit's never the password itself, all right?\n\n263\n00:12:54.710 --> 00:12:56.920\nThat's part of the challenge response.\n\n264\n00:12:56.920 --> 00:12:59.600\nThat information is sent\nback to the server.\n\n265\n00:12:59.600 --> 00:13:03.200\nNow I want you to keep in mind in\nany kinda authentication mechanism,\n\n266\n00:13:03.200 --> 00:13:05.490\nboth ends of the party have the password.\n\n267\n00:13:05.490 --> 00:13:08.120\nIf I am who I say I am,\nthen I have the valid password.\n\n268\n00:13:08.120 --> 00:13:12.370\nAnd the database that I'm authenticating\nagainst also has to have the password, or\n\n269\n00:13:12.370 --> 00:13:14.700\nat least a hashed value of the password.\n\n270\n00:13:14.700 --> 00:13:17.350\nSo with that in mind,\nwhat can the server do?\n\n271\n00:13:17.350 --> 00:13:21.610\nThe server knows what challenge\nit sent initially, it knows that.\n\n272\n00:13:21.610 --> 00:13:23.653\nIt's almost like a session key.\n\n273\n00:13:23.653 --> 00:13:24.895\nIt's a one-time challenge.\n\n274\n00:13:24.895 --> 00:13:29.626\nIt's gonna be unique to every single\ncommunication that tries to happen\n\n275\n00:13:29.626 --> 00:13:32.010\nover a CHAP authentication.\n\n276\n00:13:32.010 --> 00:13:36.530\nAnd it might even be renewed over time\neven in an existing session, right?\n\n277\n00:13:36.530 --> 00:13:40.819\nSo it takes the challenge and it takes\nthe known password of the client and\n\n278\n00:13:40.819 --> 00:13:43.997\nit tries to perform its own hashed value,\nall right?\n\n279\n00:13:43.997 --> 00:13:45.890\nAnd again, just the same fixed length.\n\n280\n00:13:45.890 --> 00:13:51.240\nNow if the value is the same as what\nwas presented to it by the client,\n\n281\n00:13:51.240 --> 00:13:55.440\nthen I can assert you are who you say you\nare because when I challenged you and\n\n282\n00:13:55.440 --> 00:13:58.390\nyou responded back to the challenge,\nI got that same value.\n\n283\n00:13:58.390 --> 00:14:00.006\nYou must've entered the right password,\nright?\n\n284\n00:14:00.006 --> 00:14:03.710\nJust like we talk about hashing values,\none little character changes.\n\n285\n00:14:03.710 --> 00:14:05.459\nI don't care if it's a space in a file,\n\n286\n00:14:05.459 --> 00:14:07.642\nchanges the whole outcome of the value,\nright?\n\n287\n00:14:07.642 --> 00:14:08.864\nSo if the values match,\n\n288\n00:14:08.864 --> 00:14:12.853\nthen it had to be the right password that\nhashed that challenge to begin with.\n\n289\n00:14:12.853 --> 00:14:17.488\nHowever, and that would lead, by the way,\nleading that through to completion,\n\n290\n00:14:17.488 --> 00:14:18.707\nthat thought there.\n\n291\n00:14:18.707 --> 00:14:21.641\nThat would lead to an accepted\nauthentication, right,\n\n292\n00:14:21.641 --> 00:14:24.034\ncommunication happens there after, right?\n\n293\n00:14:24.034 --> 00:14:28.505\nHowever, if the hashed value isn't\nthe same, it's not the same,\n\n294\n00:14:28.505 --> 00:14:32.673\nthen the server can ascert that\nyou aren't who you say you are.\n\n295\n00:14:32.673 --> 00:14:35.090\nOr if you are,\nyou didn't type the password right and\n\n296\n00:14:35.090 --> 00:14:38.436\nthe connection is going to be rejected and\nthe connection is terminated.\n\n297\n00:14:38.436 --> 00:14:41.594\nSo that's kinda one of the values\nof CHAP that I really like.\n\n298\n00:14:41.594 --> 00:14:46.780\nAgain, kind of a cool protocol, and\nI want you to remember this, is the fact\n\n299\n00:14:46.780 --> 00:14:52.230\nthat we don't have to send the physical or\nthe existing password over the wire.\n\n300\n00:14:52.230 --> 00:14:55.990\nBut what we're doing is we're kind of\nusing a combination of the challenge and\n\n301\n00:14:55.990 --> 00:14:59.740\na hashed value, if you will,\nwith the password on the client side.\n\n302\n00:14:59.740 --> 00:15:02.380\n&gt;&gt; Now, Wes, doesn't Microsoft\nhave their own version of CHAP?\n\n303\n00:15:02.380 --> 00:15:05.538\n&gt;&gt; Most definitely, and\nthey've got a couple different versions.\n\n304\n00:15:05.538 --> 00:15:10.215\nAnd really, for the exam, that's what\nI want you to know is that MS CHAP and\n\n305\n00:15:10.215 --> 00:15:11.933\nMS CHAP version 2, okay?\n\n306\n00:15:11.933 --> 00:15:15.293\nMS CHAP was Microsoft's\nfirst implementation,\n\n307\n00:15:15.293 --> 00:15:21.110\nproprietary implementation, implemented\ninside of Windows environments.\n\n308\n00:15:21.110 --> 00:15:23.420\nHowever, it does have some issues.\n\n309\n00:15:23.420 --> 00:15:27.710\nAgain, it's kinda weak,\n\n310\n00:15:27.710 --> 00:15:32.160\npeople have demonstrated feasible\nattacks with common hardware.\n\n311\n00:15:32.160 --> 00:15:37.243\nIt uses a 56 bit DES cipher,\nso not very strong.\n\n312\n00:15:37.243 --> 00:15:42.235\nHowever, MS Chap version 2 is\nthe more common implementation of\n\n313\n00:15:42.235 --> 00:15:45.335\nCHAP in a Microsoft environment today.\n\n314\n00:15:45.335 --> 00:15:49.940\nAnd actually, it's one of the most common\nauthentication mechanisms today inside of\n\n315\n00:15:49.940 --> 00:15:51.338\npassword or protect EAP.\n\n316\n00:15:51.338 --> 00:15:55.852\nAnd sometimes you might even see\nMicrosoft call MS-CHAP protected\n\n317\n00:15:55.852 --> 00:15:58.551\nextensible authentication protocol.\n\n318\n00:15:58.551 --> 00:16:01.567\nBecause what it does is the EAP, or\n\n319\n00:16:01.567 --> 00:16:06.253\nPEAP if you will,\nit's double layer of encryption.\n\n320\n00:16:06.253 --> 00:16:09.072\nIt starts a TLS tunnel that's encrypted.\n\n321\n00:16:09.072 --> 00:16:12.338\nAnd then what they do is they send the\npassword through the encrypted tunnel, so\n\n322\n00:16:12.338 --> 00:16:15.183\nyou got kind of like a [INAUDIBLE]\nDouble encryption if you will there.\n\n323\n00:16:15.183 --> 00:16:17.865\nOne of the best benefits\nto MS-CHAP version two\n\n324\n00:16:17.865 --> 00:16:19.950\nis mutual authentication, right.\n\n325\n00:16:19.950 --> 00:16:24.500\nWe've seen the chat process where it was\njust a server challenging the client.\n\n326\n00:16:24.500 --> 00:16:26.170\nWell what if the client says,\nokay you know what?\n\n327\n00:16:26.170 --> 00:16:28.500\nI'm going to take me and\nmake me a little random challenge and\n\n328\n00:16:28.500 --> 00:16:30.860\nI'm gonna send it back to you server.\n\n329\n00:16:30.860 --> 00:16:32.900\nAnd then you're gonna send\nthat response back to me and\n\n330\n00:16:32.900 --> 00:16:35.480\nI'm gonna see if I can do the same\nthing that you just did for me.\n\n331\n00:16:35.480 --> 00:16:37.280\nSo it's mutual authentication, right?\n\n332\n00:16:37.280 --> 00:16:42.050\nWe can authenticate not only\nthat the server is letting\n\n333\n00:16:42.050 --> 00:16:46.460\na client we expect in, but that the client\nis actually connected to the right server.\n\n334\n00:16:46.460 --> 00:16:49.350\nAnd it's not some kind of spoofing\nattack or man in the middle attack,\n\n335\n00:16:49.350 --> 00:16:51.960\nwhere you think you're going to\nthe right server and it really are.\n\n336\n00:16:51.960 --> 00:16:52.766\nSo MS-CHAP.\n\n337\n00:16:52.766 --> 00:16:57.150\nThe other thing too I just\nwant to make you guys aware.\n\n338\n00:16:57.150 --> 00:17:01.450\nIt is one of the most\ncommon forms of PEAP.\n\n339\n00:17:01.450 --> 00:17:05.300\nAgain the Protected Extensible\nAuthentication Protocol today.\n\n340\n00:17:05.300 --> 00:17:10.560\nThey're support by Apple, support by\nMicrosoft, support by Cisco if you will.\n\n341\n00:17:10.560 --> 00:17:13.430\nAnd so MS-CHAP is a commonality today.\n\n342\n00:17:13.430 --> 00:17:16.920\nThe only one that I believe that\nwould be higher than that is,\n\n343\n00:17:16.920 --> 00:17:19.165\nin commonality is EAPTLS.\n\n344\n00:17:19.165 --> 00:17:24.110\nMS-CHAP version 2,\nactually is second, right?\n\n345\n00:17:24.110 --> 00:17:28.390\nNot quite first place, but more common\nbecause EAPTLS is how you do smart card\n\n346\n00:17:28.390 --> 00:17:31.580\nauthentication, certificate\nbased authentication and token.\n\n347\n00:17:31.580 --> 00:17:36.190\nSo It lends itself to being a more\ncommonality with that one in second place.\n\n348\n00:17:36.190 --> 00:17:37.935\n&gt;&gt; Well,\nthere's nothing wrong with silver, right?\n\n349\n00:17:37.935 --> 00:17:38.540\n[LAUGH]\n&gt;&gt; That's right.\n\n350\n00:17:38.540 --> 00:17:39.610\nThat's pretty good.\n\n351\n00:17:39.610 --> 00:17:40.200\nNot too bad.\n\n352\n00:17:40.200 --> 00:17:41.720\nNow, speaking of authentication,\nobviously,\n\n353\n00:17:41.720 --> 00:17:43.020\nthis is what we're going through.\n\n354\n00:17:43.020 --> 00:17:46.330\nIn networking, a lot of times, and I've\ndone a little bit of networking in my day,\n\n355\n00:17:46.330 --> 00:17:48.890\nwe tend to stand up what's\ncalled a radius server.\n\n356\n00:17:48.890 --> 00:17:50.360\nWe do this in our Cisco equipment.\n\n357\n00:17:50.360 --> 00:17:51.970\nIt's a very handy thing to be able to do.\n\n358\n00:17:51.970 --> 00:17:52.960\nWes, could you tell us more?\n\n359\n00:17:52.960 --> 00:17:54.080\n&gt;&gt; Most definitely.\n\n360\n00:17:54.080 --> 00:17:57.920\nRADIUS was a protocol\nthat was developed by\n\n361\n00:17:57.920 --> 00:18:01.820\nLivingston Enterprises Inc\na long time ago.\n\n362\n00:18:01.820 --> 00:18:05.660\nIt's been pretty much\nan industry wide standard for\n\n363\n00:18:05.660 --> 00:18:10.540\nAAA if you will, Authentication,\nAuthorization and Accounting.\n\n364\n00:18:10.540 --> 00:18:13.200\nIt is a connectionless service.\n\n365\n00:18:13.200 --> 00:18:17.220\nLet's kinda look at the Hierarchy\nhere if you will or\n\n366\n00:18:17.220 --> 00:18:19.240\nthe architecture behind it, right?\n\n367\n00:18:19.240 --> 00:18:23.440\nRADIUS stands for\nthe Remote Access Dial In User Service.\n\n368\n00:18:23.440 --> 00:18:25.680\nAnd it was really started out as a way\n\n369\n00:18:27.740 --> 00:18:32.010\nto authenticate people that were making\nremote connections over dial-up servers.\n\n370\n00:18:32.010 --> 00:18:36.530\nHowever, today even though\nthe specification doesn't call out,\n\n371\n00:18:36.530 --> 00:18:41.170\nwe do have a lot of other remote access\ntypes, if you will, that can use RADIUS.\n\n372\n00:18:41.170 --> 00:18:45.820\nFor instance, you have things like\nyour Dial Up servers, VPN servers, and\n\n373\n00:18:45.820 --> 00:18:48.100\neven 802.1X APs.\n\n374\n00:18:48.100 --> 00:18:52.460\nHowever, keep in mind the 802,1X portbased\nauthentication doesn't specifically call\n\n375\n00:18:52.460 --> 00:18:57.670\nout using radius, but inside of WPA,\nyour Wi-Fi protected access, Wi-Fi\n\n376\n00:18:57.670 --> 00:19:02.350\nprotected access version 2 Enterprise\nEditions calls out using the RADIUS server\n\n377\n00:19:02.350 --> 00:19:07.540\nto perform the authentication,\nthe authorization and accounting.\n\n378\n00:19:07.540 --> 00:19:12.430\nNow I want you to keep in mind that\nwhen somebody makes a remote access or\n\n379\n00:19:12.430 --> 00:19:15.690\nremote connection attempt, they go\nthrough what are known as RADIUS clients,\n\n380\n00:19:15.690 --> 00:19:19.210\nand it gets a little confusing here\nsometimes, because people would say,\n\n381\n00:19:19.210 --> 00:19:23.230\nwell isn't my remote access client,\nwouldn't that be the RADIUS client?\n\n382\n00:19:23.230 --> 00:19:24.590\nAnd technically it's not.\n\n383\n00:19:24.590 --> 00:19:28.440\nWhat you're doing is you're sending\na radius authentication request\n\n384\n00:19:28.440 --> 00:19:30.750\nto what's known as a radius client.\n\n385\n00:19:30.750 --> 00:19:32.400\nThese are your remote access servers and\n\n386\n00:19:32.400 --> 00:19:35.460\nwhat they do is they take your\nauthentication and they encapsulate it,\n\n387\n00:19:35.460 --> 00:19:41.050\nright, in a radius message that can only\nbe processed by the radius server, right?\n\n388\n00:19:41.050 --> 00:19:45.178\nAnd then that is Sent to the radius server\nand its strips off that message and\n\n389\n00:19:45.178 --> 00:19:48.420\neither does the authentication or,\nin this case, if you're going\n\n390\n00:19:48.420 --> 00:19:52.460\nto go through this infrastructure a lot\nof times what you'll have is like an IM,\n\n391\n00:19:52.460 --> 00:19:57.010\nan identity management system like active\ndirectory where the user names and\n\n392\n00:19:57.010 --> 00:19:58.650\nif you will passwords are stored.\n\n393\n00:19:58.650 --> 00:19:59.910\nBut radius, again,\n\n394\n00:19:59.910 --> 00:20:04.080\nis doing that authentication or\ncan do that authentication if you want.\n\n395\n00:20:04.080 --> 00:20:07.190\nSome of the things to keep in mind,\nwe talked about authentication.\n\n396\n00:20:07.190 --> 00:20:09.970\nIt supports all different types\nof authentication mechanisms.\n\n397\n00:20:09.970 --> 00:20:12.470\nIt doesn't call out a specific one.\n\n398\n00:20:12.470 --> 00:20:16.267\nAgain, think about dial-up,\nremote access connections,\n\n399\n00:20:16.267 --> 00:20:19.992\nover the point to point protocol,\nunencrypted passwords,\n\n400\n00:20:19.992 --> 00:20:24.680\nwe really should be using, but\nit supports PAP CHAP, MS-CHAP Version 2.\n\n401\n00:20:24.680 --> 00:20:27.340\nSo, it doesn't actually call out\nwhat specific authentication\n\n402\n00:20:27.340 --> 00:20:28.310\nmechanism it's using.\n\n403\n00:20:29.670 --> 00:20:30.400\nWhat else here?\n\n404\n00:20:30.400 --> 00:20:33.250\nWe gotta look at some ports because you\nnever know if they're gonna ask you about\n\n405\n00:20:33.250 --> 00:20:34.230\nports on the exam.\n\n406\n00:20:34.230 --> 00:20:35.170\nThey like to do this.\n\n407\n00:20:35.170 --> 00:20:39.930\nKeep in mind that it has a couple of\ndifferent series of ports, if you will.\n\n408\n00:20:39.930 --> 00:20:45.468\nGiven the fact that there was\na change in the RFCs so you might see\n\n409\n00:20:45.468 --> 00:20:51.370\nports 1645 and 1812 for\nthe authentication messages.\n\n410\n00:20:51.370 --> 00:20:57.340\nAnd you might see Port 1646 and\n1813 for the accounting side of this.\n\n411\n00:20:57.340 --> 00:20:58.320\nAll right.\n\n412\n00:20:58.320 --> 00:21:02.780\nKind of keep in mind of what's going\non wwhen a radius request is made.\n\n413\n00:21:02.780 --> 00:21:04.940\nI kind of got this broken down\ninto a few different steps.\n\n414\n00:21:04.940 --> 00:21:09.550\nKind of make it a little bit easier,\nif you will, to understand.\n\n415\n00:21:09.550 --> 00:21:13.070\nWhen we talk about a radius attempt,\nright?\n\n416\n00:21:13.070 --> 00:21:17.840\nThen we're gonna talk about an access\nrequest, and then the access request you\n\n417\n00:21:17.840 --> 00:21:23.410\ncan think of it kind of like this\nif you will, who or let me in.\n\n418\n00:21:23.410 --> 00:21:25.640\n[LAUGH] So let me in.\n\n419\n00:21:25.640 --> 00:21:30.580\nThen the identity request could be, you\ncould think of it as something like well,\n\n420\n00:21:30.580 --> 00:21:33.970\nwho are you?\n\n421\n00:21:33.970 --> 00:21:38.480\nAnd then it could be, the third part\nyou're presenting your username,\n\n422\n00:21:38.480 --> 00:21:44.020\ncould be I am and\nthen who ever the user name is right?\n\n423\n00:21:44.020 --> 00:21:49.140\nAnd then the authentication\nchallenge is well, prove it.\n\n424\n00:21:49.140 --> 00:21:51.532\nYou say that you are who, well prove it.\n\n425\n00:21:51.532 --> 00:21:54.650\nI'm gonna basically issue you a challenge.\n\n426\n00:21:54.650 --> 00:21:57.790\nThe challenge response\nmight be something like,\n\n427\n00:21:57.790 --> 00:22:02.970\nwell here is my proof, right?\n\n428\n00:22:02.970 --> 00:22:04.720\nWe send the password, right?\n\n429\n00:22:04.720 --> 00:22:05.620\nWe authenticate.\n\n430\n00:22:05.620 --> 00:22:10.670\nAnd then, again, authentication can either\nbe successful or it can be a failure based\n\n431\n00:22:10.670 --> 00:22:15.540\non whether you typed the password right or\nyou're actually an authorized user or not.\n\n432\n00:22:15.540 --> 00:22:18.670\nSo, that is your radius implementation.\n\n433\n00:22:18.670 --> 00:22:21.520\nI will mention even though\nI don't have a diagram for\n\n434\n00:22:21.520 --> 00:22:24.380\nit because they do call\nout TAC ACS as well.\n\n435\n00:22:24.380 --> 00:22:29.940\nKeep in mind, that TAC ACS is the terminal\naccess control access control system.\n\n436\n00:22:29.940 --> 00:22:32.270\nIt wasn't originally designed.\n\n437\n00:22:32.270 --> 00:22:35.520\nIt's actually designed I\nbelieve by the government but\n\n438\n00:22:35.520 --> 00:22:38.245\nCISCO got a hold of it and\nthey made some improvement and\n\n439\n00:22:38.245 --> 00:22:41.830\nthey made some modifications that it\nsteered so far away from the original\n\n440\n00:22:41.830 --> 00:22:46.070\nTAC ACS that it became TAC ACS Plus\nin their proprietary implementation.\n\n441\n00:22:46.070 --> 00:22:50.290\nSee this radius process\nisn't an encrypted process.\n\n442\n00:22:50.290 --> 00:22:56.490\nSo what it does, is it uses the connection\nlist UDP, however TAC ACS uses TCP and\n\n443\n00:22:56.490 --> 00:22:59.610\nthe whole entire process,\nusername, password and\n\n444\n00:22:59.610 --> 00:23:02.500\nany additional attributes that they\nwanna throw in there is encrypted.\n\n445\n00:23:02.500 --> 00:23:06.260\nSo it is considered a little bit more\nsecure and it is connection oriented.\n\n446\n00:23:06.260 --> 00:23:11.240\nHowever, the focus on TAC ACS is more\ncontrolling access to for instance,\n\n447\n00:23:11.240 --> 00:23:12.690\nthings like network devices.\n\n448\n00:23:14.350 --> 00:23:17.400\nAll right, so I did have to mention\na little bit about TAC ACS.\n\n449\n00:23:17.400 --> 00:23:22.620\nSome of the last things that we talk\nabout are some of the various things for\n\n450\n00:23:22.620 --> 00:23:27.670\nsingle sign-on implementations that\nI want you to be aware of today.\n\n451\n00:23:27.670 --> 00:23:29.590\nWe've kind of talked about other episodes,\n\n452\n00:23:29.590 --> 00:23:34.520\nyou know when we talk about things like\nfederations and federated services, right?\n\n453\n00:23:34.520 --> 00:23:42.630\nHow is it, if you will, that we can\nadminister, if you will, to our identities\n\n454\n00:23:42.630 --> 00:23:45.440\nif we have things like applications\nthat people need access to, right?\n\n455\n00:23:45.440 --> 00:23:48.190\nIf people need access to\na multitude of applications, well,\n\n456\n00:23:48.190 --> 00:23:53.220\nwe could have things like user databases\nfor each individual application.\n\n457\n00:23:53.220 --> 00:23:57.069\nBut the problem with that is that the\nadministration of those databases becomes\n\n458\n00:23:57.069 --> 00:23:58.397\nchallenging, all right.\n\n459\n00:23:58.397 --> 00:24:03.248\nSo, wouldn't it be nice if we could\ntake a company that has a database\n\n460\n00:24:03.248 --> 00:24:07.348\nof millions of users,\nuse them as an identity provider and\n\n461\n00:24:07.348 --> 00:24:11.950\nhave them support, if you will,\nManaging those databases, and\n\n462\n00:24:11.950 --> 00:24:16.840\nthat's were something known\nas OpenID Connect comes in.\n\n463\n00:24:16.840 --> 00:24:21.220\nAnd what this allows us to do is\nperform those federated services.\n\n464\n00:24:21.220 --> 00:24:23.840\nAnd so, for instance,\nlet me give you an example, here.\n\n465\n00:24:23.840 --> 00:24:30.280\nSo, if we're in enterprise, and we need\nto maintain user identities, right?,\n\n466\n00:24:30.280 --> 00:24:34.420\nif we've got a series of applications,\nwell, we could have a database for\n\n467\n00:24:34.420 --> 00:24:37.570\neach individual application of\nthe users and their identities.\n\n468\n00:24:37.570 --> 00:24:40.240\nAgain, starts to become a little complex.\n\n469\n00:24:40.240 --> 00:24:44.100\nAnd not to mention, if we bring in\n\n470\n00:24:44.100 --> 00:24:48.740\nat that enterprise level we bring in\nadditional infrastructure, right?\n\n471\n00:24:48.740 --> 00:24:52.970\nWe bring in additional infrastructure and,\nnow, managing of those usernames and\n\n472\n00:24:52.970 --> 00:24:57.590\ndatabases, if you will, identities,\ncould become a nightmare.\n\n473\n00:24:57.590 --> 00:25:00.455\nVery, very challenging for\nyour companies, right?\n\n474\n00:25:00.455 --> 00:25:03.415\nSo, again,\nwouldn't it be nice if we could use\n\n475\n00:25:03.415 --> 00:25:05.485\nsomething like an identity provider,\nright?\n\n476\n00:25:05.485 --> 00:25:08.835\nAnd when I say, identity provider, there\nare many companies out there like Google,\n\n477\n00:25:08.835 --> 00:25:14.342\nlike Facebook, like Twitter they all ready\nhave millions of users in their database.\n\n478\n00:25:14.342 --> 00:25:18.842\nWell, they can provide it's called an IDP\nan identity provider as a solution that\n\n479\n00:25:18.842 --> 00:25:22.472\nyou can use their databases to log in\nif you will to their applications.\n\n480\n00:25:22.472 --> 00:25:26.860\nThat's how we get the ability\nyou've got under some websites and\n\n481\n00:25:26.860 --> 00:25:30.720\nseen where they've said, just use\nyour Facebook to log into this app,\n\n482\n00:25:30.720 --> 00:25:33.230\njust use your google to log into this app,\nright?\n\n483\n00:25:33.230 --> 00:25:37.400\nWell, that's because that company as\na service provider, they're providing you\n\n484\n00:25:37.400 --> 00:25:42.270\nwith the service their application, they\nuse an identity provider on the back end,\n\n485\n00:25:42.270 --> 00:25:47.250\nif you will, and it allows them,\nif you will, to ease the management\n\n486\n00:25:47.250 --> 00:25:52.170\nof those identities, essentially going\nthrough them as an identity provider.\n\n487\n00:25:52.170 --> 00:25:55.820\nOpen connect ID is a way\nthat we can do that,\n\n488\n00:25:55.820 --> 00:26:00.430\nit's one of the technologies\nthat allows us, for instance,\n\n489\n00:26:00.430 --> 00:26:04.860\nIDPs can receive a request, they can\ncreate what's known as a secure token,\n\n490\n00:26:04.860 --> 00:26:08.170\nsecure ID token, and they can hand it\nback to the application on behalf of\n\n491\n00:26:08.170 --> 00:26:10.430\nthe provider, and\nthey don't have to manage these.\n\n492\n00:26:10.430 --> 00:26:13.280\nSo, kind of a very, very cool technology.\n\n493\n00:26:13.280 --> 00:26:17.050\nOpen ID connect is based off of OAuth.\n\n494\n00:26:17.050 --> 00:26:18.930\nOAuth is the technology.\n\n495\n00:26:18.930 --> 00:26:22.590\nAgain, it's an open standard, if you will.\n\n496\n00:26:22.590 --> 00:26:25.295\nAnd you can go out to things like HTTP,\n\n497\n00:26:25.295 --> 00:26:29.760\nOAuth.net and\nyou can read more about this if you want.\n\n498\n00:26:30.830 --> 00:26:34.230\nLet's see, I know, we're running\na little bit short on time here,\n\n499\n00:26:34.230 --> 00:26:37.930\nthere is one, a couple last\nones that I'd like to mention.\n\n500\n00:26:37.930 --> 00:26:39.649\nAnd that's Shible F, again,\n\n501\n00:26:39.649 --> 00:26:44.120\nis another very common federated SSO\nimplementation that's out there.\n\n502\n00:26:44.120 --> 00:26:47.230\nBe aware of what it is for the exam.\n\n503\n00:26:47.230 --> 00:26:51.600\nIt uses a language called the security\nassertion mark up language, SAML.\n\n504\n00:26:51.600 --> 00:26:55.810\nAs we're passing information between\nthese identity providers if you will,\n\n505\n00:26:55.810 --> 00:26:59.600\nin their applications we need a secure\nway to be able to gain access to that\n\n506\n00:26:59.600 --> 00:27:00.490\ninformation, right?\n\n507\n00:27:00.490 --> 00:27:04.340\nThat's where SAML comes in, again\nthe security and social mark up language.\n\n508\n00:27:04.340 --> 00:27:07.166\nAnd again Shible F is one that does that.\n\n509\n00:27:07.166 --> 00:27:09.325\n&gt;&gt; It sounds like an agent hebrew-\n&gt;&gt; It really does.\n\n510\n00:27:09.325 --> 00:27:12.123\n&gt;&gt; [SOUND] [LAUGH]\n&gt;&gt; That's exactly what I was thinking.\n\n511\n00:27:12.123 --> 00:27:13.284\n&gt;&gt; Open the Ark of the Covenant.\n\n512\n00:27:13.284 --> 00:27:16.153\n&gt;&gt; That's right, at the end we're\ngonna go [FOREIGN], definitely.\n\n513\n00:27:16.153 --> 00:27:19.679\nBut it's open source,\nit's under the Apache Software License,\n\n514\n00:27:19.679 --> 00:27:22.720\nand it has three different versions there.\n\n515\n00:27:22.720 --> 00:27:25.890\nLast, but no least,\nthere's one that has been around for\n\n516\n00:27:25.890 --> 00:27:28.310\na long time and that's NT Land Manager.\n\n517\n00:27:28.310 --> 00:27:33.090\nGood old Microsoft's authentication\nmechanism that's been around for\n\n518\n00:27:33.090 --> 00:27:37.180\na long time, and it could still\nbe used in Windows's domains, but\n\n519\n00:27:37.180 --> 00:27:39.690\nif you're inside of a Windows's\ndomain a lot of times today,\n\n520\n00:27:39.690 --> 00:27:41.810\nwhat you're really gonna\nwanna be using is Kerberos.\n\n521\n00:27:41.810 --> 00:27:46.240\nAnd, again, just because NT Land Manager,\nif you If you will is susceptible\n\n522\n00:27:46.240 --> 00:27:51.310\nto the fact that if I can gain that\nfile with all of those password hashes,\n\n523\n00:27:51.310 --> 00:27:53.510\nthen we can do things like\ncollision attacks against it.\n\n524\n00:27:53.510 --> 00:27:58.370\nSo, again, NTLM is more of a proprietory\nimplementation inside of a Windows\n\n525\n00:27:58.370 --> 00:28:03.856\nenvironment and, again, it is one that is\nconsidered a little bit less secure today.\n\n526\n00:28:03.856 --> 00:28:07.097\n&gt;&gt; All right,\na lot to do when it comes to access.\n\n527\n00:28:07.097 --> 00:28:11.390\nThere's many different protocols, and\ntypes and which ways we can do that.\n\n528\n00:28:11.390 --> 00:28:13.470\nWes has just given you a litany of them.\n\n529\n00:28:13.470 --> 00:28:17.240\nA lot of information there definitely\ntake some time to understand each one,\n\n530\n00:28:17.240 --> 00:28:19.580\nhow they are working, what they work with.\n\n531\n00:28:19.580 --> 00:28:21.490\nWhere you might see them,\nmight encounter them, so\n\n532\n00:28:21.490 --> 00:28:24.110\nthat you can answer those questions\naccordingly on your exam.\n\n533\n00:28:24.110 --> 00:28:27.170\nThat being said, Wes, it looks like we're\nout of time for today, but, I think,\n\n534\n00:28:27.170 --> 00:28:29.490\nyou made it through your list,\nso good job on you.\n\n535\n00:28:29.490 --> 00:28:31.920\nThat being said, looks like I said,\nwe're out of time.\n\n536\n00:28:31.920 --> 00:28:33.830\nSo, thank you so much for watching.\n\n537\n00:28:33.830 --> 00:28:36.450\nBut for ITProTV,\nI've been your host Daniel Lowry.\n\n538\n00:28:36.450 --> 00:28:37.360\n&gt;&gt; And I'm Wes Bryan.\n\n539\n00:28:37.360 --> 00:28:39.636\n&gt;&gt; We'll see you next time.\n\n540\n00:28:39.636 --> 00:28:45.640\n[MUSIC]\n\n541\n00:28:45.640 --> 00:28:48.578\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216500578"
        },
        {
          "description": "In this episode, Daniel and Wes dive into common Identity and Access Management Controls covered in the Security+ exam. Here you'll learn about access control models like MAC, DAC, RBAC, and ABAC. They also cover physical access, certificate-based controls, and biometric factors.",
          "length": "1574",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-3-1-identity_and_access_management_controls-050117-PGM.00_00_11_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-3-1-identity_and_access_management_controls-050117-PGM.00_00_11_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-3-1-identity_and_access_management_controls-050117-PGM.00_00_11_27.Still001-sm.jpg",
          "title": "Identity and Access Management Controls",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:01.570\nWelcome to ITProTV I'm your host.\n\n2\n00:00:01.570 --> 00:00:06.336\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.336 --> 00:00:08.453\n[MUSIC]\n\n4\n00:00:08.453 --> 00:00:12.189\n&gt;&gt; You're watching ITPRO.TV.\n\n5\n00:00:12.189 --> 00:00:14.093\n&gt;&gt; All right, greetings everyone, and\n\n6\n00:00:14.093 --> 00:00:17.240\nwelcome to another exciting\nepisode of ITPRO.TV.\n\n7\n00:00:17.240 --> 00:00:18.640\nI'm your host Daniel Lowrie, and\n\n8\n00:00:18.640 --> 00:00:23.690\nin today's episode we're coming back at\nyou with more on our Security+ series.\n\n9\n00:00:23.690 --> 00:00:24.870\nAnd joining us in the studio, yet\n\n10\n00:00:24.870 --> 00:00:28.850\nagain, continuing to walk and\nhold our little hands down that road so\n\n11\n00:00:28.850 --> 00:00:32.750\nwe can eventually pass our Security+ exam,\nour good friend Wes Bryan.\n\n12\n00:00:32.750 --> 00:00:33.276\nWes, welcome back man, how's it going?\n\n13\n00:00:33.276 --> 00:00:36.849\n&gt;&gt; Man, I tell you, every time I come\nin here it sounds like we're good and\n\n14\n00:00:36.849 --> 00:00:37.930\nready for a journey.\n\n15\n00:00:37.930 --> 00:00:41.280\nLet's just hope that journey leads\nto clarity and understanding,\n\n16\n00:00:41.280 --> 00:00:43.810\nnot confusion and whatever else.\n\n17\n00:00:43.810 --> 00:00:44.992\n&gt;&gt; That's the goal, right?\n\n18\n00:00:44.992 --> 00:00:46.530\n[LAUGH]\n&gt;&gt; That's right, absolutely, so\n\n19\n00:00:46.530 --> 00:00:50.178\nthat's right guys we're looking at\nidentity and access management controls.\n\n20\n00:00:50.178 --> 00:00:53.516\nAnd we've really over the past\ncouple episodes that we've done,\n\n21\n00:00:53.516 --> 00:00:56.971\nand if you're just joining us right\nnow we've got a few more that have\n\n22\n00:00:56.971 --> 00:01:00.680\ndealt with things like identity access,\nsome of the services behind it.\n\n23\n00:01:00.680 --> 00:01:03.990\nSome of the concepts and components well,\nwe're continuing on here but\n\n24\n00:01:03.990 --> 00:01:06.870\nnow we're gonna talk about\nare the controls behind this.\n\n25\n00:01:06.870 --> 00:01:11.150\nAnd one of the very first things that\nthey call out are access control types.\n\n26\n00:01:11.150 --> 00:01:16.240\nAnd with access control types,\nsince I've been around the CompTIA and\n\n27\n00:01:16.240 --> 00:01:19.020\nthe Security+ exams, if you will, and\n\n28\n00:01:19.020 --> 00:01:23.140\nobjectives, they really called\nout three different kinds.\n\n29\n00:01:23.140 --> 00:01:25.510\nThey call out what's known\nas discretionary access.\n\n30\n00:01:25.510 --> 00:01:26.760\nIn fact, let me just go ahead and\nshow you.\n\n31\n00:01:26.760 --> 00:01:29.443\nGot a little diagram here that's\njust got a listing of them,\n\n32\n00:01:29.443 --> 00:01:32.245\nand we're gonna go through pretty\nmuch the majority of these.\n\n33\n00:01:32.245 --> 00:01:36.932\nAnd you could see, well, we're not\nshy of alphabet soup here at all,\n\n34\n00:01:36.932 --> 00:01:40.281\nin fact we're starting\nout with alphabet soups.\n\n35\n00:01:40.281 --> 00:01:44.043\nSo, you'll see MAC, DAC, RBAC, ABAC, and\n\n36\n00:01:44.043 --> 00:01:49.875\nwell there is another RBAC and\nwe'll get to that confusion on that one.\n\n37\n00:01:49.875 --> 00:01:50.638\n&gt;&gt; [LAUGH]\n&gt;&gt; Not a typo.\n\n38\n00:01:50.638 --> 00:01:52.240\n&gt;&gt; [LAUGH]\n&gt;&gt; Believe it or not.\n\n39\n00:01:52.240 --> 00:01:53.921\nYou might have said, well, you copy and\n\n40\n00:01:53.921 --> 00:01:57.590\npasted a little too much there, but-\n&gt;&gt; A little trigger happy with\n\n41\n00:01:57.590 --> 00:01:58.650\nthe Ctrl+C there, is that it?\n\n42\n00:01:58.650 --> 00:01:59.610\n&gt;&gt; Yeah, that's exactly it.\n\n43\n00:01:59.610 --> 00:02:02.880\nAnd this is actually, this is\nintentional and we'll come back and\n\n44\n00:02:02.880 --> 00:02:04.040\nI'll show you why here.\n\n45\n00:02:04.040 --> 00:02:07.380\nSo let's go ahead and let's talk about\nthese different access control methods.\n\n46\n00:02:07.380 --> 00:02:09.310\nKeep in mind we're\ntalking about identities.\n\n47\n00:02:09.310 --> 00:02:11.570\n&gt;&gt; And we're talking about resources,\nright?\n\n48\n00:02:11.570 --> 00:02:14.920\nAnd these models,\nthese control types if you will define\n\n49\n00:02:14.920 --> 00:02:18.020\nhow we regulate access to those resources,\nright?\n\n50\n00:02:18.020 --> 00:02:19.470\nAgain access control.\n\n51\n00:02:19.470 --> 00:02:23.190\nSo let's go ahead and\nstart out with Mandatory Access Control.\n\n52\n00:02:23.190 --> 00:02:26.130\nThis is one that maybe you're\nfamiliar with, maybe you're not.\n\n53\n00:02:26.130 --> 00:02:29.300\nNo, I know Dan, I know you've got\na military background here, so\n\n54\n00:02:29.300 --> 00:02:32.190\nyou might have seen this once or\ntwice in your history.\n\n55\n00:02:32.190 --> 00:02:34.000\nAnd this is Mandatory Access Control.\n\n56\n00:02:34.000 --> 00:02:36.910\nAnd the big thing that I want you\nto take away from this right away\n\n57\n00:02:36.910 --> 00:02:41.210\nis the fact that we've got a couple\nof security designations, right,\n\n58\n00:02:41.210 --> 00:02:45.230\nthe security classifications or\ndescriptors, if you will, all right?\n\n59\n00:02:45.230 --> 00:02:50.020\nWe typically have our identities, and\nthey have a security classification.\n\n60\n00:02:50.020 --> 00:02:54.415\nWe then have a resource that has\nanother security designation right,\n\n61\n00:02:54.415 --> 00:02:56.305\nor classification if you will.\n\n62\n00:02:56.305 --> 00:03:02.437\nIn order for access to be granted both of\nthose classifications have to match right?\n\n63\n00:03:02.437 --> 00:03:09.575\nSo in this example this soldier here\nnotice has restricted clearance all right.\n\n64\n00:03:09.575 --> 00:03:11.665\nIf the soldier has\nrestricted clearance and\n\n65\n00:03:11.665 --> 00:03:16.400\nthe resource has restricted clearance,\nwell they gain access.\n\n66\n00:03:16.400 --> 00:03:19.450\nAnother thing that you can\nthink of when it comes to\n\n67\n00:03:19.450 --> 00:03:23.000\nmandatory access control is well, right?\n\n68\n00:03:23.000 --> 00:03:25.501\nWe think about restricted access, well,\n\n69\n00:03:25.501 --> 00:03:29.260\nwhat does restricted access also\ngive this identity access to.\n\n70\n00:03:29.260 --> 00:03:31.170\nWell everything below that as well.\n\n71\n00:03:31.170 --> 00:03:32.234\nThings like official and classified.\n\n72\n00:03:32.234 --> 00:03:37.450\nAnd there are other classifications,\ndata classifications as well.\n\n73\n00:03:37.450 --> 00:03:39.258\nI just put some of the common\nones that you see out here.\n\n74\n00:03:39.258 --> 00:03:44.140\nAgain, you have unofficial as well,\nconfidential.\n\n75\n00:03:44.140 --> 00:03:46.490\nAnd you can see, but\nthese are the majority of them.\n\n76\n00:03:46.490 --> 00:03:48.096\n&gt;&gt; There's one called cosmic.\n\n77\n00:03:48.096 --> 00:03:49.849\n&gt;&gt; That's interesting.\n&gt;&gt; That the UN uses, yeah.\n\n78\n00:03:49.849 --> 00:03:50.926\n&gt;&gt; That's very good.\n\n79\n00:03:50.926 --> 00:03:52.203\n&gt;&gt; It's like the ultimate in top secret.\n\n80\n00:03:52.203 --> 00:03:56.277\n&gt;&gt; Perfect, just in case you're having to\naccess anything from Star Wars, right?\n\n81\n00:03:56.277 --> 00:03:57.840\n&gt;&gt; [LAUGH]\n&gt;&gt; But\n\n82\n00:03:57.840 --> 00:04:02.700\nnotice that again, the big thing\nto take away from mandatory access\n\n83\n00:04:02.700 --> 00:04:08.000\ncontrol is there are two different\nsecurity classifications, right?\n\n84\n00:04:08.000 --> 00:04:10.630\nThere's one on the user themselves and\n\n85\n00:04:10.630 --> 00:04:14.980\nthere's a classification on the resource\nin may have to match, right?\n\n86\n00:04:14.980 --> 00:04:16.560\nGive you another example of this, right?\n\n87\n00:04:16.560 --> 00:04:20.715\nLet's go ahead, let's say that\nwe've got two identities, right?\n\n88\n00:04:20.715 --> 00:04:25.971\nNotice that if that person,\nthe identity itself has a classification,\n\n89\n00:04:25.971 --> 00:04:29.515\nthe resource has to match\nthat classification.\n\n90\n00:04:29.515 --> 00:04:33.850\nNotice let say, it's one of the higher\nups in the military, right.\n\n91\n00:04:33.850 --> 00:04:35.740\nMaybe has top secret classification.\n\n92\n00:04:35.740 --> 00:04:41.390\nWell that means, if the resource\nhas top secret classification, then\n\n93\n00:04:41.390 --> 00:04:46.850\nthe person that's accessing it also has to\nhave the security descriptor that matches.\n\n94\n00:04:46.850 --> 00:04:48.970\nAll right, so\nthat's mandatory access control.\n\n95\n00:04:48.970 --> 00:04:53.520\nAnd keep in mind the basics for this is\nthat mandatory access control has two\n\n96\n00:04:53.520 --> 00:04:59.290\ndifferent identifiers that have to match,\nfor access to be granted, right?\n\n97\n00:04:59.290 --> 00:05:02.600\nAnd that's unlike something like\ndiscretionary access control, right?\n\n98\n00:05:02.600 --> 00:05:04.220\nDiscretionary access control,\n\n99\n00:05:04.220 --> 00:05:08.790\nyou might consider it as non-mandatory\n[LAUGH] access control if you will.\n\n100\n00:05:08.790 --> 00:05:13.460\nAnd a lot of times I hear people give\nit an explanation that just says,\n\n101\n00:05:13.460 --> 00:05:19.280\nthis is the owner giving an identity\naccess based at their discretion, right?\n\n102\n00:05:19.280 --> 00:05:23.150\nSo for instance, mandatory access control\nis typically set up by an administrator,\n\n103\n00:05:23.150 --> 00:05:25.460\nand then the permissions\nare delegated by the administrator.\n\n104\n00:05:26.540 --> 00:05:28.240\nIn discretionary access control,\n\n105\n00:05:28.240 --> 00:05:32.220\nit's the owner of the object that actually\nissues and delegates the permissions.\n\n106\n00:05:32.220 --> 00:05:36.100\nNow keep in mind administrators,\nthey always have access to documents and\n\n107\n00:05:36.100 --> 00:05:40.780\nthat's not something that even the owner\nof the document can take away.\n\n108\n00:05:40.780 --> 00:05:46.890\nBut notice that it's based access is based\non the user's identity in relation to\n\n109\n00:05:46.890 --> 00:05:52.360\na series of tasks that may or\nmay not be allowed on that resource right.\n\n110\n00:05:52.360 --> 00:05:55.890\nSo for instance the user\nidentity here is student01.\n\n111\n00:05:55.890 --> 00:05:59.562\nWell if student 01 is in what's known\nas an access control list, right,\n\n112\n00:05:59.562 --> 00:06:02.379\na little bit of metadata\nthat's on the resource itself.\n\n113\n00:06:02.379 --> 00:06:07.722\nWe find that identity, that username in\nthere, and then the access control list\n\n114\n00:06:07.722 --> 00:06:13.160\nhas what are known as ACEs, access control\nentries, that tell us what can you do.\n\n115\n00:06:13.160 --> 00:06:16.692\nI know who you are and the list says,\nhey you're on the list,\n\n116\n00:06:16.692 --> 00:06:20.370\nnow I gotta determine what\nlevel of access do you have.\n\n117\n00:06:20.370 --> 00:06:23.090\nAnd we could control that through\nthings like permissions, right?\n\n118\n00:06:23.090 --> 00:06:26.680\nSo a person can read the document, but\nthey can't make modifications through\n\n119\n00:06:26.680 --> 00:06:32.090\na Write command or a Write operation\nif it happens to be an application.\n\n120\n00:06:32.090 --> 00:06:35.020\nIf they don't have the Execute permission,\nagain,\n\n121\n00:06:35.020 --> 00:06:38.090\nthey're not gonna be allowed\nto execute the applications.\n\n122\n00:06:38.090 --> 00:06:41.357\nSo you can see that with\ndiscretionary access control,\n\n123\n00:06:41.357 --> 00:06:44.913\nagain it's about giving access\nbased on the user identity.\n\n124\n00:06:44.913 --> 00:06:49.293\nUnlike mandatory access control where\nit's a security classification that\n\n125\n00:06:49.293 --> 00:06:52.880\nthe identity has to match as well\nas the resource has to match.\n\n126\n00:06:52.880 --> 00:06:56.200\nSo a little bit different\nthere if you will.\n\n127\n00:06:56.200 --> 00:07:00.030\nAll right, now the next thing\nthat we have is what is known\n\n128\n00:07:00.030 --> 00:07:03.630\nas role based access control.\n\n129\n00:07:03.630 --> 00:07:05.420\nThis is the first of the RBACs.\n\n130\n00:07:05.420 --> 00:07:07.030\nI'll get to that second\none here in a second.\n\n131\n00:07:07.030 --> 00:07:07.635\nI swear.\n\n132\n00:07:07.635 --> 00:07:09.590\n&gt;&gt; [LAUGH]\n&gt;&gt; That isn't a typo [LAUGH].\n\n133\n00:07:09.590 --> 00:07:13.824\nBut the next one is role based\naccess control, all right?\n\n134\n00:07:13.824 --> 00:07:17.166\nAnd with role based access control,\nlet's get this X out of here, just for\n\n135\n00:07:17.166 --> 00:07:17.945\na second here.\n\n136\n00:07:17.945 --> 00:07:19.455\nWith role based access control,\n\n137\n00:07:19.455 --> 00:07:22.355\nI want you to think of pre-determined\nroles within your company, right?\n\n138\n00:07:22.355 --> 00:07:26.295\nYou know that maybe in a company you're\ngonna have administrators, right?\n\n139\n00:07:26.295 --> 00:07:28.905\nAnd you might be able to say\njust generically standard users,\n\n140\n00:07:28.905 --> 00:07:31.265\nbut there's a lot of standard\nusers in your company, right?\n\n141\n00:07:31.265 --> 00:07:33.835\nEverybody else that's not administrators\nshould be a standard user.\n\n142\n00:07:33.835 --> 00:07:35.800\nBut we break standard users up.\n\n143\n00:07:35.800 --> 00:07:37.568\nTypically in the roles of\nthe jobs that they perform right?\n\n144\n00:07:37.568 --> 00:07:40.893\n&gt;&gt; Someone might have like an HR standard\nuser versus a sales standard user.\n\n145\n00:07:40.893 --> 00:07:42.880\n&gt;&gt; Very good analogy there.\n\n146\n00:07:42.880 --> 00:07:44.530\nSo for instance, developers right?\n\n147\n00:07:44.530 --> 00:07:46.258\nThey get access to the Dev environment,\nall right.\n\n148\n00:07:46.258 --> 00:07:50.760\nYou wanna know what happens if Wes\ngets access to the Dev environment?\n\n149\n00:07:50.760 --> 00:07:51.314\nYou don't have a Dev\nenvironment anymore right?\n\n150\n00:07:51.314 --> 00:07:54.976\n&gt;&gt; [LAUGH]\n&gt;&gt; So that's not my role right?\n\n151\n00:07:54.976 --> 00:07:57.999\nI'm not in development,\nI don't understand coding,\n\n152\n00:07:57.999 --> 00:08:01.166\nso I might be in something like\na help desk position right?\n\n153\n00:08:01.166 --> 00:08:02.425\nAnd in a help desk position,\n\n154\n00:08:02.425 --> 00:08:05.787\nI certainly don't want the help desk\nto have access to the dev environment.\n\n155\n00:08:05.787 --> 00:08:10.778\nThat's not what their role or\nwhat they're performing is, okay,\n\n156\n00:08:10.778 --> 00:08:15.695\nbut I do want them to have access\nto the help desk ticketing system.\n\n157\n00:08:15.695 --> 00:08:18.476\nRight, if a ticket comes in,\nthey need to be able to respond to it.\n\n158\n00:08:18.476 --> 00:08:21.562\nSo I'm gonna give them access to\nthe ticketing system based on the role,\n\n159\n00:08:21.562 --> 00:08:24.380\nthat they're performing\nwithin the company.\n\n160\n00:08:24.380 --> 00:08:26.250\nAnd we can go down a little\nfarther from that too,\n\n161\n00:08:26.250 --> 00:08:28.030\nright, Dan mentioned sales, right.\n\n162\n00:08:28.030 --> 00:08:32.460\nWell I don't want maybe sales to have\naccess to the help desk ticketing system.\n\n163\n00:08:32.460 --> 00:08:35.860\nAnd by analogy and\nmaybe not the dev environment either.\n\n164\n00:08:35.860 --> 00:08:39.720\nBy I certainly want them to have\naccess to the customer relationship\n\n165\n00:08:39.720 --> 00:08:40.570\nmanagement, right.\n\n166\n00:08:40.570 --> 00:08:43.980\nCustomer relations management\ndatabase where they are, hopefully,\n\n167\n00:08:43.980 --> 00:08:46.325\ngetting us more sales into our company,\nright.\n\n168\n00:08:46.325 --> 00:08:51.077\nSo when you look at roll based access\ncontrol, all right, I want you to think of\n\n169\n00:08:51.077 --> 00:08:55.830\na logical grouping of identities,\nif you will, with similar affiliations.\n\n170\n00:08:55.830 --> 00:09:01.257\nAnd they usually group together based on\na similar amount of access that they need,\n\n171\n00:09:01.257 --> 00:09:01.810\nright.\n\n172\n00:09:01.810 --> 00:09:06.360\nYou might even hear this called group\nbased access control too, again,\n\n173\n00:09:06.360 --> 00:09:07.860\ncuz what are you doing?\n\n174\n00:09:07.860 --> 00:09:10.790\nYou're logically grouping these\nidentities together based on the role\n\n175\n00:09:10.790 --> 00:09:13.910\nthat they're performing within your\ncompany that dictates the level of access\n\n176\n00:09:13.910 --> 00:09:15.249\nthey need to different resources.\n\n177\n00:09:16.290 --> 00:09:19.280\nAll right, so that is one,\nnow I don't have, for\n\n178\n00:09:19.280 --> 00:09:22.420\nthe last two, I don't have any slides so\nI wanna kinda talk about them\n\n179\n00:09:22.420 --> 00:09:27.530\nbecause there's another one out there that\nwe talked about briefly and that was ABAC.\n\n180\n00:09:27.530 --> 00:09:32.450\nAnd Dan and I were kinda joking around\nabout this one before we started and\n\n181\n00:09:32.450 --> 00:09:35.440\nthe A in that stands for\nattributes, right.\n\n182\n00:09:35.440 --> 00:09:38.570\nSo I want you to think about, like for\ninstance, in Active Directory Domain,\n\n183\n00:09:38.570 --> 00:09:41.300\nso when we do things like\nrole based access control,\n\n184\n00:09:41.300 --> 00:09:46.060\nright, we say okay, you're part of this\ngroup, you gain access to the resource.\n\n185\n00:09:46.060 --> 00:09:47.700\nWe do discretionary access control,\n\n186\n00:09:47.700 --> 00:09:51.870\nwe use an identity,\nwe give you access based on your identity.\n\n187\n00:09:51.870 --> 00:09:54.930\nWhat about additional attributes, let's\nsay that are in a Windows domain, right,\n\n188\n00:09:54.930 --> 00:09:58.390\nyou're part of the marketing group but\n\n189\n00:09:58.390 --> 00:10:02.660\nyour location is East, or\nyour location is West, right.\n\n190\n00:10:02.660 --> 00:10:07.560\nSo imagine being able to grant\npeople access based on attributes.\n\n191\n00:10:07.560 --> 00:10:11.570\nWe do this with things like claims,\nright, claims of where applications\n\n192\n00:10:11.570 --> 00:10:14.520\nauthenticate people, if you will,\nbased on a claim within a token.\n\n193\n00:10:14.520 --> 00:10:18.500\nAnd that claim doesn't necessarily\nhave to be just an identity, right.\n\n194\n00:10:18.500 --> 00:10:22.000\nIt could be multiple different things,\nit could be a street name, right,\n\n195\n00:10:22.000 --> 00:10:25.730\nit could be a location\nwithin the building, right.\n\n196\n00:10:25.730 --> 00:10:30.630\nAnd so additional attributes we can\ngive you access to, or, give you access,\n\n197\n00:10:30.630 --> 00:10:32.050\nbased on that.\n\n198\n00:10:32.050 --> 00:10:36.890\nThe last RB AC, double acronym right, we\ngotta love that when we have things like\n\n199\n00:10:36.890 --> 00:10:39.420\nMAC right, well what does MAC mean right?\n\n200\n00:10:39.420 --> 00:10:44.710\nMedia Access Control, Mandatory Access\nControl, or Message Authentication Code.\n\n201\n00:10:44.710 --> 00:10:46.110\nBoy, that's a lot, right?\n\n202\n00:10:46.110 --> 00:10:47.650\nSo what we-\n&gt;&gt; My brain just exploded.\n\n203\n00:10:47.650 --> 00:10:48.430\n&gt;&gt; Yeah that's right.\n\n204\n00:10:48.430 --> 00:10:48.930\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n205\n00:10:48.930 --> 00:10:50.150\n&gt;&gt; Just gone, right, so\n\n206\n00:10:50.150 --> 00:10:51.980\nlet's help you out with the last one.\nIn fact,\n\n207\n00:10:51.980 --> 00:10:57.590\nthere are some terms that they try to\nthrow out there to distinguish these.\n\n208\n00:10:57.590 --> 00:11:01.480\nIn this context it's called rule based\naccess control, all right firewalls,\n\n209\n00:11:01.480 --> 00:11:05.610\nI want you to think about a firewall,\nyou're allowed access, traffic is allowed\n\n210\n00:11:05.610 --> 00:11:09.740\nthrough the firewall based on\na predetermined criteria, right, a rule.\n\n211\n00:11:09.740 --> 00:11:13.570\nWell think about giving users access\non a pre-determined rule, right, so,\n\n212\n00:11:13.570 --> 00:11:14.730\nyou have business hours.\n\n213\n00:11:14.730 --> 00:11:19.150\nYou're allowed to access\nthe building between 8 and 5,\n\n214\n00:11:19.150 --> 00:11:22.710\nright, well, we're gonna give you\naccess based on your identity.\n\n215\n00:11:22.710 --> 00:11:24.660\nBut it also has to adhere to the rule, or\n\n216\n00:11:24.660 --> 00:11:27.250\nyou don't gain access,\nright, it's 9 o'clock\n\n217\n00:11:27.250 --> 00:11:31.419\nwell the rule states you have to gain\naccess during the business hours, right.\n\n218\n00:11:32.460 --> 00:11:37.900\nRemote communications cannot be made\nthrough a public network like a hotspot.\n\n219\n00:11:37.900 --> 00:11:41.400\nIt's a rule, right, so\nunderstand there's rule access control,\n\n220\n00:11:41.400 --> 00:11:44.345\nsometimes they call it role\nset based access control.\n\n221\n00:11:44.345 --> 00:11:46.435\nAnd that's just a,\n\n222\n00:11:46.435 --> 00:11:49.705\nto me just a feeble attempt to try to\nmake the acronyms a little bit different.\n\n223\n00:11:49.705 --> 00:11:52.215\nBut again,\nremember role based access control,\n\n224\n00:11:52.215 --> 00:11:55.165\ngrouping identities together based\non the level of access they need.\n\n225\n00:11:55.165 --> 00:11:59.747\nVersus rule based access control where you\nhave a predetermined set of criteria that\n\n226\n00:11:59.747 --> 00:12:02.404\nhave to be matched in order for\naccess to happen.\n\n227\n00:12:02.404 --> 00:12:06.163\nThink of a, for instance, if you're\ninside of a Windows environment and\n\n228\n00:12:06.163 --> 00:12:08.720\nyou're doing remote access services,\nright.\n\n229\n00:12:08.720 --> 00:12:13.900\nYou might have a connection request that\ncomes from a specific type of server.\n\n230\n00:12:13.900 --> 00:12:16.860\nMaybe you don't wanna allow that\nconnection request from that specific type\n\n231\n00:12:16.860 --> 00:12:17.540\nof server, right.\n\n232\n00:12:17.540 --> 00:12:20.350\nIt's not based on identity,\nit's based on the rule itself, so\n\n233\n00:12:20.350 --> 00:12:24.890\nagain, we can implement this through\nthings like policies, likewise.\n\n234\n00:12:24.890 --> 00:12:26.990\n&gt;&gt; Well Wes,\nnow that you've turned our brains into so\n\n235\n00:12:26.990 --> 00:12:30.770\nmuch wet spaghetti, now we'll have\nto get that straight in our minds.\n\n236\n00:12:30.770 --> 00:12:32.580\nMake sure that you follow those down,\n\n237\n00:12:32.580 --> 00:12:35.720\nunderstand each one of those different\nacronyms, what they mean, and\n\n238\n00:12:35.720 --> 00:12:38.190\nobviously there's two that\nhave the exact same thing.\n\n239\n00:12:38.190 --> 00:12:42.230\nSo be prepared for a question like that in\nyour exam, cuz they're probably gonna try\n\n240\n00:12:42.230 --> 00:12:45.020\nto hit you with a nice little\ncurveball in that sense.\n\n241\n00:12:45.020 --> 00:12:47.810\nBut that being said, digital systems\nare not the only thing that we have to\n\n242\n00:12:47.810 --> 00:12:49.540\nworry about when it comes to access.\n\n243\n00:12:49.540 --> 00:12:53.010\nWe also have physical systems, right,\nwe have buildings, we have rooms, and\n\n244\n00:12:53.010 --> 00:12:55.470\nwe need to control the access\nto those as well, right Wes?\n\n245\n00:12:55.470 --> 00:12:57.850\n&gt;&gt; Definitely, so\nwhen we talk about physical controls,\n\n246\n00:12:57.850 --> 00:13:00.760\nin another episode we talked about\nthe importance of physical controls.\n\n247\n00:13:00.760 --> 00:13:04.940\nBut now we're talking about those same\nphysical controls in the context of who\n\n248\n00:13:05.960 --> 00:13:07.560\ngains access or not, right.\n\n249\n00:13:07.560 --> 00:13:10.490\nSo they do call out a couple of things,\nand again, some of these things that we've\n\n250\n00:13:10.490 --> 00:13:14.540\nkind of talking about already,\nproximity cards, right.\n\n251\n00:13:14.540 --> 00:13:18.370\nProximity card, again, is one that well,\nyou get close to it and\n\n252\n00:13:18.370 --> 00:13:22.370\nit has a little token in it, right,\nand the token can authenticate you.\n\n253\n00:13:22.370 --> 00:13:28.605\nThings like smart cards are another one,\nRFID, again, basic card-based access.\n\n254\n00:13:28.605 --> 00:13:32.643\nNow they also call out and I'm gonna go\nahead and include this one with physical\n\n255\n00:13:32.643 --> 00:13:36.880\naccess as well cuz they call out things\nlike certificate based authentication.\n\n256\n00:13:36.880 --> 00:13:40.371\nI want you to understand certificate\nbased authentication, and\n\n257\n00:13:40.371 --> 00:13:43.417\nthis is an exam alert,\nhappens because of the extensible\n\n258\n00:13:43.417 --> 00:13:46.351\nAuthentication Protocol\nTransport Layer Security.\n\n259\n00:13:46.351 --> 00:13:50.276\nI went ahead and\npronounced the acronym out but it EAPTLS,\n\n260\n00:13:50.276 --> 00:13:54.120\nnow to give you an example of\nsome of those technologies,\n\n261\n00:13:54.120 --> 00:13:58.606\na couple of them are industry\nstandards inside of like for instance\n\n262\n00:13:58.606 --> 00:14:03.760\ngovernment institutes, institutions\nif you will federal institutions.\n\n263\n00:14:03.760 --> 00:14:08.351\nLike so for instance they call\nout the PIV and the CAC, or\n\n264\n00:14:08.351 --> 00:14:12.761\ncommonly called the CAC card,\nright, the CAC card.\n\n265\n00:14:12.761 --> 00:14:17.368\nPIV is a personal identification\nverification card, right, and again,\n\n266\n00:14:17.368 --> 00:14:21.683\nit falls under FIPS, the federal\ninformation protection standard,\n\n267\n00:14:21.683 --> 00:14:23.670\nI believe is what it's called.\n\n268\n00:14:23.670 --> 00:14:27.878\nAnd it's for Federal employees,\nif you will, and federal agencies.\n\n269\n00:14:27.878 --> 00:14:31.350\nNow the CAC card's a little bit different,\nright,\n\n270\n00:14:31.350 --> 00:14:33.962\nthis is given to active military, right.\n\n271\n00:14:33.962 --> 00:14:37.130\nThat's a common access card,\nit's also a DOD standard, and\n\n272\n00:14:37.130 --> 00:14:40.950\nit works much the same\nway as a smart card does.\n\n273\n00:14:40.950 --> 00:14:45.890\nBasically it contains a lot of information\nabout the holder that is using it.\n\n274\n00:14:45.890 --> 00:14:48.610\nSo definitely know what the PIV card is,\nagain,\n\n275\n00:14:48.610 --> 00:14:50.480\npersonal identification verification card,\n\n276\n00:14:50.480 --> 00:14:52.990\nwhich is just an industry-wide\nstandard for government employees.\n\n277\n00:14:52.990 --> 00:14:55.678\nVersus the CAC card,\nwhich is kinda like the same thing,\n\n278\n00:14:55.678 --> 00:14:58.211\nonly it's given typically\nto your active military.\n\n279\n00:14:58.211 --> 00:15:01.680\nLet's see,\ncertificate based authentication,\n\n280\n00:15:01.680 --> 00:15:04.623\nwhat other things do\nwe have to talk about?\n\n281\n00:15:04.623 --> 00:15:09.009\nWell, 802.1X,\n802.1 X is port based authentication and\n\n282\n00:15:09.009 --> 00:15:11.968\nit originally started\nas a wired technology.\n\n283\n00:15:11.968 --> 00:15:16.985\nI know it's common in wireless\ncommunications too but it actually started\n\n284\n00:15:16.985 --> 00:15:21.919\nas a land based communication,\nthen it was extended later on to the IEEE,\n\n285\n00:15:21.919 --> 00:15:27.674\nextended the functionality, if you will,\nto the 802.11 standard likewise.\n\n286\n00:15:27.674 --> 00:15:31.676\nAnd 802.1x essentially is port-based\nauthentication, and it's almost\n\n287\n00:15:31.676 --> 00:15:35.317\nlike a physical layer of the OSI model,\nif you will, security that says,\n\n288\n00:15:35.317 --> 00:15:38.760\nhey, if Dan's trying to get into\nthe network, what's he gonna do?\n\n289\n00:15:38.760 --> 00:15:41.226\nWell, the port is gonna shut\ndown on the switch, and\n\n290\n00:15:41.226 --> 00:15:45.226\nit's not gonna allow him to communicate,\nand he's gonna ask for authentication.\n\n291\n00:15:45.226 --> 00:15:49.609\nAnd again, once that authentication is\ndone, or given the switch opens up, and\n\n292\n00:15:49.609 --> 00:15:53.099\nit passes that through to whatever\nthe authenticating body is.\n\n293\n00:15:53.099 --> 00:15:56.460\nBut essentially it's kinda like\na pass through if you will, and\n\n294\n00:15:56.460 --> 00:15:57.838\nit's a way to close down.\n\n295\n00:15:57.838 --> 00:16:01.454\nA port on a switch until the\nauthentication is validated and verified.\n\n296\n00:16:01.454 --> 00:16:04.347\nAnd then the port opens up and\nit allows people on the network.\n\n297\n00:16:04.347 --> 00:16:08.706\nYou see commonly 802.1x involved\n\n298\n00:16:08.706 --> 00:16:13.250\nin WPA Enterprise, WPA2 Enterprise.\n\n299\n00:16:13.250 --> 00:16:15.420\nAnd a lot of times it's\ncoupled with Radius.\n\n300\n00:16:15.420 --> 00:16:20.279\nHowever, keep in mind though even\nthough they say things like Wi-Fi\n\n301\n00:16:20.279 --> 00:16:26.560\nprotected access, we use an 802.1x\ncompliant wireless access point.\n\n302\n00:16:26.560 --> 00:16:29.960\nThe protocol doesn't specify radius.\n\n303\n00:16:29.960 --> 00:16:30.890\nIt's just a commonality.\n\n304\n00:16:30.890 --> 00:16:36.580\nIt works really well with radius, so\n802.1x is port based authentication.\n\n305\n00:16:36.580 --> 00:16:41.676\nAnd again, it can be done on wired and\nwireless networks,\n\n306\n00:16:41.676 --> 00:16:45.004\nhowever pay attention, if you will,\n\n307\n00:16:45.004 --> 00:16:50.318\nto the difference between 802.11X and\n802.1X.\n\n308\n00:16:50.318 --> 00:16:55.052\nOkay, when we say 802.11x, a lot of times,\nx is just a variable that says\n\n309\n00:16:55.052 --> 00:16:59.873\neverything in the 802.11 wireless\nlocal area network standard, right?\n\n310\n00:16:59.873 --> 00:17:02.477\nA, b, g, what?\n\n311\n00:17:02.477 --> 00:17:05.630\nN, a, c, a, d,\nwe just say hey, all of them.\n\n312\n00:17:05.630 --> 00:17:07.196\nWe just x is a variable, right?\n\n313\n00:17:07.196 --> 00:17:08.625\nBut it's 11x.\n\n314\n00:17:08.625 --> 00:17:10.820\n802.1X, is the IEEEs implementation or\n\n315\n00:17:10.820 --> 00:17:14.290\nstandardization of port\nbased authentication.\n\n316\n00:17:15.910 --> 00:17:17.700\n&gt;&gt; Excellent.\nVery, very important distinction.\n\n317\n00:17:17.700 --> 00:17:21.270\nDon't make that mistake if they ask you\nabout something like that on the exam.\n\n318\n00:17:21.270 --> 00:17:23.630\nDon't choose the wrong one,\nget the right one there.\n\n319\n00:17:23.630 --> 00:17:25.570\nThat being said,\nwe're moving into what I like, right?\n\n320\n00:17:25.570 --> 00:17:28.120\nThis is kind of the high\ntech hardware stuff.\n\n321\n00:17:28.120 --> 00:17:31.320\nAnd it is the actual biometrics, right?\n\n322\n00:17:31.320 --> 00:17:34.840\nCool things like iris scanners,\npalm scanners, face scanners, you name it.\n\n323\n00:17:34.840 --> 00:17:36.730\nScanners, scanners, scanners,\nmy uncle actually does this for a living.\n\n324\n00:17:36.730 --> 00:17:40.510\nHe owns his own company and\nit creates these portable biometrics for\n\n325\n00:17:40.510 --> 00:17:41.450\nthe military.\n\n326\n00:17:41.450 --> 00:17:43.280\nIt's very hush hush and cool stuff.\n\n327\n00:17:43.280 --> 00:17:46.300\nBut Wes, you're gonna tell us a little\nmore about what we can expect with that\n\n328\n00:17:46.300 --> 00:17:48.740\nand some of the caveats that we\nneed to know, as well, right?\n\n329\n00:17:48.740 --> 00:17:50.450\n&gt;&gt; Yeah, this is a great topic,\ntoo, as well, Dan.\n\n330\n00:17:50.450 --> 00:17:51.360\nBecause you know what,\n\n331\n00:17:51.360 --> 00:17:54.350\nit's about increasing the security\nof your organization.\n\n332\n00:17:54.350 --> 00:17:56.875\nAnd if you think about it,\npassword, right?\n\n333\n00:17:56.875 --> 00:18:00.757\nPasswords are very susceptible\nto the human nature, right?\n\n334\n00:18:00.757 --> 00:18:04.592\nWhether it be social engineering, whether\nit be password attacks, just many many\n\n335\n00:18:04.592 --> 00:18:08.747\nthings out there that we have to worry\nabout when it comes to passwords, right?\n\n336\n00:18:08.747 --> 00:18:13.297\nWell imagine having a form of\nauthentication, if you will,\n\n337\n00:18:13.297 --> 00:18:17.037\nthat uses a physical characteristic\nthat's not really hard.\n\n338\n00:18:17.037 --> 00:18:19.762\nI mean, it's kind of hard,\ndifficult if you will, to spoof, right?\n\n339\n00:18:19.762 --> 00:18:21.747\nThat's one of the things that\nbiometrics lends itself.\n\n340\n00:18:21.747 --> 00:18:25.910\nNow, two or three years ago, when we were\ndoing this episode, I might say, well,\n\n341\n00:18:25.910 --> 00:18:29.680\nbiometrics is very expensive and that's\nwhy it's a limited implementation, and\n\n342\n00:18:29.680 --> 00:18:33.522\nwe have it now on just about every mobile\ndevice there is, [LAUGH] right, so-\n\n343\n00:18:33.522 --> 00:18:34.374\n&gt;&gt; It's pretty ubiquitous now.\n\n344\n00:18:34.374 --> 00:18:35.035\n&gt;&gt; It has, right?\n\n345\n00:18:35.035 --> 00:18:39.622\nIt's come a long way and it's getting\na little less cost-heavy, if you will,\n\n346\n00:18:39.622 --> 00:18:44.780\nbecause of the fact that you're seeing\nthings like fingerprint scanners, right?\n\n347\n00:18:44.780 --> 00:18:48.790\nI know the iOS devices have fingerprint\nscanners that you touch the home button\n\n348\n00:18:48.790 --> 00:18:52.020\nand it allows you to login, right?\n\n349\n00:18:52.020 --> 00:18:54.070\nI think I've got a pixel here, and\n\n350\n00:18:54.070 --> 00:18:57.410\nthe background it's got\nthe fingerprint recognition system.\n\n351\n00:18:57.410 --> 00:18:59.410\nSo you're seeing things like that, right?\n\n352\n00:18:59.410 --> 00:19:05.270\nAgain, using some physical characteristic\nof yourself, or some behavioral trait.\n\n353\n00:19:05.270 --> 00:19:06.520\nThey call out a few of them.\n\n354\n00:19:06.520 --> 00:19:09.110\nFirst one,\nthere is the fingerprint scanner.\n\n355\n00:19:09.110 --> 00:19:12.768\nThey call out a couple of different\nones related to your eye, if you will,\n\n356\n00:19:12.768 --> 00:19:15.315\nretinal scanners versus an iris scanner,\nright?\n\n357\n00:19:15.315 --> 00:19:18.452\nThe blood vessels,\nversus the little center ring,\n\n358\n00:19:18.452 --> 00:19:20.956\nif you will, in the patterns in the iris.\n\n359\n00:19:20.956 --> 00:19:25.211\nProbably one of the more expensive ones,\nthose two right there, because the quality\n\n360\n00:19:25.211 --> 00:19:28.830\nof the cameras that they have to have,\nso we do have to keep those in mind.\n\n361\n00:19:28.830 --> 00:19:33.020\nVoice recognition systems,\nagain this is one that for\n\n362\n00:19:33.020 --> 00:19:36.110\nbetter or worse,\nmight be the weaker of them.\n\n363\n00:19:36.110 --> 00:19:38.820\nBut again voice recognition again,\na vocal pattern, right?\n\n364\n00:19:38.820 --> 00:19:44.450\nSo it's more of a behavioral\ntype biometrics implementation.\n\n365\n00:19:44.450 --> 00:19:49.360\nAll right, so those are a few of\nthose types that we have to look at.\n\n366\n00:19:49.360 --> 00:19:52.860\nHowever, there are some things that they\ndo call out that you have to be aware of\n\n367\n00:19:52.860 --> 00:19:59.880\nwhen it comes to the characteristics of\nthese biometrics devices, if you will.\n\n368\n00:19:59.880 --> 00:20:03.940\nOne of the things that they call\nout is false rejection rate and\n\n369\n00:20:03.940 --> 00:20:05.500\nfalse acceptance rate.\n\n370\n00:20:05.500 --> 00:20:09.230\nNow, I'm gonna go ahead and I'm gonna take\nthe jargon completely out of this and\n\n371\n00:20:09.230 --> 00:20:12.740\nlet's talk about something that\nwe've already seen in this series.\n\n372\n00:20:12.740 --> 00:20:16.670\nFalse positive and false negative, right?\n\n373\n00:20:16.670 --> 00:20:19.330\nThis terminology is just\nrelated to biometrics, but\n\n374\n00:20:19.330 --> 00:20:21.560\nit means the exact same thing.\n\n375\n00:20:21.560 --> 00:20:26.460\nAnd you can see, that depends\non what you need to accomplish\n\n376\n00:20:26.460 --> 00:20:30.280\nas to which ones of these you're gonna try\nto peak and tweak your systems, right?\n\n377\n00:20:30.280 --> 00:20:33.200\nIt's one of the things we try to\ndo with our biometric systems.\n\n378\n00:20:33.200 --> 00:20:37.590\nWe wanna kinda peak and tweak them so\nthat what we have lower error rate.\n\n379\n00:20:37.590 --> 00:20:39.500\nIn fact,\nDan made a good comment off stage,\n\n380\n00:20:39.500 --> 00:20:42.250\nI wish you would've made that on stage,\nand said, hey, errors are errors, right?\n\n381\n00:20:42.250 --> 00:20:46.100\nThe less errors a system has,\ndoesn't matter how you classify it,\n\n382\n00:20:46.100 --> 00:20:47.040\nit's still an error, right?\n\n383\n00:20:47.040 --> 00:20:50.960\nThe less errors, the more accurate\nthe system, and that's a very valid point.\n\n384\n00:20:50.960 --> 00:20:53.750\nSo, keep in mind that\nyou're gonna peak and\n\n385\n00:20:53.750 --> 00:20:56.510\ntweak your system there to\ntry to reduce these errors,\n\n386\n00:20:56.510 --> 00:21:00.360\nwhich regardless of what side\nthe tracks are that you're looking at.\n\n387\n00:21:00.360 --> 00:21:02.090\nBut let me give you\na couple scenarios here.\n\n388\n00:21:02.090 --> 00:21:05.400\nSo when we talk about a false\nrejection rate, or FRR,\n\n389\n00:21:05.400 --> 00:21:10.960\nthis is the likelihood that\na biometric system will not\n\n390\n00:21:10.960 --> 00:21:14.480\nID an authorized user and\nreject them access, right?\n\n391\n00:21:14.480 --> 00:21:18.960\nSo I want you to think about availability,\nright?\n\n392\n00:21:18.960 --> 00:21:21.770\nSo this scenario affects availability.\n\n393\n00:21:21.770 --> 00:21:26.560\nWell, if a user that's supposed to be\nin the system can't gain access to it,\n\n394\n00:21:26.560 --> 00:21:28.300\nwhy would something like that happen?\n\n395\n00:21:28.300 --> 00:21:29.090\nWell all right,\n\n396\n00:21:29.090 --> 00:21:33.530\nI want you to think about sensitivity\nlevels on your biometrics, right?\n\n397\n00:21:33.530 --> 00:21:38.090\nIf we're going for security and we wanna\nmake sure that it's secure, right?\n\n398\n00:21:38.090 --> 00:21:41.790\nRemember we've been talking about through\nthe serious security and convenience.\n\n399\n00:21:41.790 --> 00:21:44.480\nMore convenience,\nsecurity it lowers, right.\n\n400\n00:21:44.480 --> 00:21:47.062\nThe more secure sometimes\nconvenience lowers.\n\n401\n00:21:47.062 --> 00:21:49.940\nWell, what if our security\nis exactly what we want?\n\n402\n00:21:49.940 --> 00:21:52.590\nWe want to make sure that it's secure and\nthat's how we're peaking and\n\n403\n00:21:52.590 --> 00:21:54.860\ntweaking the biometric system.\n\n404\n00:21:54.860 --> 00:22:00.620\nWell, the more you increase the security,\nthe more sensitive, it lowers things like\n\n405\n00:22:00.620 --> 00:22:05.790\nunauthorized access cuz the sensitivity of\nthe confidence level has been increased.\n\n406\n00:22:07.170 --> 00:22:12.590\nMore secure, but that also leads to\na higher level of false rejection,\n\n407\n00:22:12.590 --> 00:22:15.130\nif you will, false rejection rates.\n\n408\n00:22:15.130 --> 00:22:17.860\nBecause now people who are authorized,\nbecause it is so\n\n409\n00:22:17.860 --> 00:22:21.040\nsensitive, are incorrectly\nidentified as unauthorized.\n\n410\n00:22:21.040 --> 00:22:25.590\nSo again,\nmore secure leads to less convenience.\n\n411\n00:22:25.590 --> 00:22:29.400\nNow the other side of that fact\nis one that you could see as\n\n412\n00:22:29.400 --> 00:22:33.580\nprobably being the worse of the two,\nand that's the false acceptance rate.\n\n413\n00:22:33.580 --> 00:22:37.050\nNow the false acceptance\nrate is again where it\n\n414\n00:22:38.050 --> 00:22:42.960\nidentifies an unauthorized person as being\nauthorized and accepts them in, right?\n\n415\n00:22:42.960 --> 00:22:43.700\n&gt;&gt; That's bad.\n\n416\n00:22:43.700 --> 00:22:45.360\n&gt;&gt; That's very bad, right?\n\n417\n00:22:45.360 --> 00:22:49.070\nSo, what might be a scenario in there?\n\n418\n00:22:49.070 --> 00:22:52.240\nSo the likelihood that the authentication\nsystem will incorrectly ID\n\n419\n00:22:52.240 --> 00:22:56.200\nan unauthorized person and\nallow them access, all right?\n\n420\n00:22:56.200 --> 00:22:57.460\nWell how can that increase?\n\n421\n00:22:57.460 --> 00:22:59.330\nWell, maybe you're wanting convenience.\n\n422\n00:22:59.330 --> 00:23:02.450\nYou got that complaining user, if you\nwill, that's complaining about always\n\n423\n00:23:02.450 --> 00:23:06.500\nbeing locked out of their system because\nthe system is incorrectly IDing them as\n\n424\n00:23:06.500 --> 00:23:09.340\nsomebody that shouldn't be there or\ndoesn't even recognize them at all.\n\n425\n00:23:09.340 --> 00:23:11.080\nSo what do you do?\n\n426\n00:23:11.080 --> 00:23:12.850\nYou lower to confidence\nlevel of the system or\n\n427\n00:23:12.850 --> 00:23:15.210\nyou lower the confidence sensitivity,\nif you will.\n\n428\n00:23:15.210 --> 00:23:17.310\nYou lower the sensitivity, right?\n\n429\n00:23:17.310 --> 00:23:20.960\nBut the problem is, in lowering the\nsensitivity you've increased availability,\n\n430\n00:23:20.960 --> 00:23:24.140\nbut you've also decreased security because\nnow you have the potential that you could\n\n431\n00:23:24.140 --> 00:23:29.260\nlet people in that are incorrectly\nidentified as authorized, right?\n\n432\n00:23:29.260 --> 00:23:31.820\nSo which one do we want?\n\n433\n00:23:31.820 --> 00:23:35.550\nWell that can't be said,\nit's not a one size fits all.\n\n434\n00:23:35.550 --> 00:23:41.210\nIt depends on looking at the value of what\nyou're protecting, and your risk profile.\n\n435\n00:23:41.210 --> 00:23:43.270\nHow much risk can you afford to have?\n\n436\n00:23:43.270 --> 00:23:46.300\nSo again, there's no right or wrong.\n\n437\n00:23:46.300 --> 00:23:50.410\nBut they do call out a value\nthat's called the CER, and\n\n438\n00:23:50.410 --> 00:23:52.370\nagain, that's the Crossover Error Rate.\n\n439\n00:23:52.370 --> 00:23:54.670\nYou might hear it also called EER, and\n\n440\n00:23:54.670 --> 00:23:57.465\nthat's the Equal Error Rate,\nbecause of what it does, all right?\n\n441\n00:23:57.465 --> 00:24:02.710\nSo that just gives you a way to\nquantify the accuracy of a system.\n\n442\n00:24:02.710 --> 00:24:06.854\nThat's all it really boils down to,\nhow can I tell how accurate the system is?\n\n443\n00:24:06.854 --> 00:24:09.541\nAnd that's based on\nthe Crossover Error Rate.\n\n444\n00:24:09.541 --> 00:24:13.610\nI got an example here, so on a diagram,\nwhen you're doing a measurement, right?\n\n445\n00:24:13.610 --> 00:24:16.930\nAnd you've got your false acceptance rate,\nright?\n\n446\n00:24:16.930 --> 00:24:19.650\nYou have maybe sensitivity versus errors.\n\n447\n00:24:19.650 --> 00:24:21.030\nAnd as these go up,\n\n448\n00:24:21.030 --> 00:24:24.660\nnotice that there's a point in time\nwhere the paths cross and they're equal.\n\n449\n00:24:24.660 --> 00:24:27.170\nWell that's called your\nCrossover Error Rate.\n\n450\n00:24:27.170 --> 00:24:29.710\nAnd again, like I said,\nit's also called, I like this term\n\n451\n00:24:29.710 --> 00:24:32.400\nbetter than the one that's in\nthe objectives, is the Equal Error Rate.\n\n452\n00:24:32.400 --> 00:24:33.820\nThey're equal, right?\n\n453\n00:24:33.820 --> 00:24:37.290\nAnd that's what you striving for\nis a lower CER.\n\n454\n00:24:37.290 --> 00:24:39.866\nSo if we look at two systems here, right?\n\n455\n00:24:39.866 --> 00:24:46.177\nNotice System 1, notice where it's\nCrossover Error Rate is in the graph,\n\n456\n00:24:46.177 --> 00:24:53.670\nversus System 2, notice System 2,\nit's CER or Crossover Error Rate is lower.\n\n457\n00:24:53.670 --> 00:24:58.440\nBecause of the quantification of this\nwe can see that System 2 has a higher\n\n458\n00:24:58.440 --> 00:25:00.660\naccuracy than System 1, right?\n\n459\n00:25:00.660 --> 00:25:05.640\nIt's just, again, know the terms just\nin case they ask you on the exam.\n\n460\n00:25:05.640 --> 00:25:10.910\nIt might be something where they ask you\nto point where your false rejection and\n\n461\n00:25:10.910 --> 00:25:14.950\nyour false acceptance rates are equal\nwould be something as the CER.\n\n462\n00:25:14.950 --> 00:25:19.430\nAnd again, this is nothing more than\ncalculations of false positives and\n\n463\n00:25:19.430 --> 00:25:23.350\nfalse negatives spoken in\nthe context of a biometric system.\n\n464\n00:25:23.350 --> 00:25:24.090\n&gt;&gt; Excellent stuff.\n\n465\n00:25:24.090 --> 00:25:26.004\nDefinitely something we\nhave to take into account.\n\n466\n00:25:26.004 --> 00:25:30.145\nUsing these systems, like you say, you\nwant the more accurate of the two systems,\n\n467\n00:25:30.145 --> 00:25:33.000\nor five systems or\nhow many other systems are available.\n\n468\n00:25:33.000 --> 00:25:35.270\nYou want the most accurate that\nyou can get your hands on, so\n\n469\n00:25:35.270 --> 00:25:39.710\nthat you will not have to endure these\nfalse positives and false negatives.\n\n470\n00:25:39.710 --> 00:25:42.710\nThey're a lot of pain for us,\na big pain sticking point.\n\n471\n00:25:42.710 --> 00:25:46.130\nNow Wes that being said, I know that we\nhave a little bit more to go on, but I'm\n\n472\n00:25:46.130 --> 00:25:49.070\nlooking at our clock and we've definitely\nrun out of time for this episode.\n\n473\n00:25:49.070 --> 00:25:51.630\nSo we'll just have to roll this\ninto one of our famous part twos.\n\n474\n00:25:51.630 --> 00:25:53.396\n&gt;&gt; Sounds good.\n&gt;&gt; We do thank you for joining us today.\n\n475\n00:25:53.396 --> 00:25:56.412\nWe thank our good audience for\njoining us as well, but signing off for\n\n476\n00:25:56.412 --> 00:25:58.600\nITPro.TV I've been your host,\nDaniel Lowrie.\n\n477\n00:25:58.600 --> 00:25:59.360\n&gt;&gt; And I'm Wes Bryan.\n\n478\n00:25:59.360 --> 00:26:01.589\n&gt;&gt; And we'll see you next time.\n\n479\n00:26:01.589 --> 00:26:07.890\n[MUSIC]\n\n480\n00:26:07.890 --> 00:26:11.028\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "216501689"
        },
        {
          "description": "In this episode, Daniel and Wes continue looking at common Identity and Access Management controls. Here they cover the use of Token based systems, (both hardware and software), file system security, and database security.",
          "length": "999",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-3-2-identity_and_access_management_controls_pt2-050117-PGM.00_21_10_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-3-2-identity_and_access_management_controls_pt2-050117-PGM.00_21_10_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-3-2-identity_and_access_management_controls_pt2-050117-PGM.00_21_10_02.Still001-sm.jpg",
          "title": "Identity and Access Management Controls Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.250 --> 00:00:03.391\nWelcome to ITProTV,\nI'm your host Don [CROSSTALK]\n\n2\n00:00:03.391 --> 00:00:04.075\n&gt;&gt; Coming at you live from\n\n3\n00:00:04.075 --> 00:00:04.835\nSan Francisco [CROSSTALK]\n\n4\n00:00:04.835 --> 00:00:06.175\n[MUSIC]\n\n5\n00:00:06.175 --> 00:00:10.649\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:10.649 --> 00:00:12.977\n&gt;&gt; All right, greeting everyone, and\n\n7\n00:00:12.977 --> 00:00:16.960\nwelcome back to another\ngreat episode of ITProTV.\n\n8\n00:00:16.960 --> 00:00:20.990\nI'm your host Daniel Lowrie, and\nin today's episode, well let's see here,\n\n9\n00:00:20.990 --> 00:00:23.830\nwe got the plus at the end of it,\nand it is security.\n\n10\n00:00:23.830 --> 00:00:26.430\nSecurity, put them together,\nit's Security+ it's what we're here for.\n\n11\n00:00:26.430 --> 00:00:30.410\nJoining us back in the studio yet again,\nour friend and mentor, Mr. Wes Bryan.\n\n12\n00:00:30.410 --> 00:00:31.230\nWes, welcome back sir.\n\n13\n00:00:31.230 --> 00:00:32.223\n&gt;&gt; Hey, thanks for having me back,\n\n14\n00:00:32.223 --> 00:00:34.037\napparently [LAUGH] I talked way\ntoo much in the first episode.\n\n15\n00:00:34.037 --> 00:00:34.646\n&gt;&gt; It does happen.\n\n16\n00:00:34.646 --> 00:00:36.740\n&gt;&gt; Which is why we're back\nhere with a part two.\n\n17\n00:00:36.740 --> 00:00:39.700\nNow, guys, we've got some\n[LAUGH] loose ends to tie up.\n\n18\n00:00:39.700 --> 00:00:42.880\nWe do have some additional\nof the access and\n\n19\n00:00:42.880 --> 00:00:46.300\nmanagement concepts that we\nneed you guys to be aware of.\n\n20\n00:00:46.300 --> 00:00:51.164\nSo, in the first part, we talked about\nmany different types of concepts,\n\n21\n00:00:51.164 --> 00:00:55.194\nwe ended up talking about\nthe difference between FAR and FRR.\n\n22\n00:00:55.194 --> 00:00:59.304\nAnd it wouldn't be a good Security+\nepisode if I didn't hit you with acronyms\n\n23\n00:00:59.304 --> 00:01:00.984\nright out the gate, but again,\n\n24\n00:01:00.984 --> 00:01:04.803\nremember that's the false acceptance\nrate versus the rejection rate.\n\n25\n00:01:04.803 --> 00:01:09.343\nAnd then the point in a graph where those\ntwo become equal is called the crossover\n\n26\n00:01:09.343 --> 00:01:13.710\nerror rate, and a lower crossover error\nrate means a more accurate system.\n\n27\n00:01:13.710 --> 00:01:16.617\nSo that is where we left off, if any\nof that doesn't sound familiar to you,\n\n28\n00:01:16.617 --> 00:01:18.601\ngo ahead and jump back and\nwatch the first part, and\n\n29\n00:01:18.601 --> 00:01:20.100\nthen we'll see you back here in a few.\n\n30\n00:01:20.100 --> 00:01:23.701\nBut for those of you that have watched\nthe first part, we're gonna talk about,\n\n31\n00:01:23.701 --> 00:01:25.060\nwell, another technology.\n\n32\n00:01:25.060 --> 00:01:28.383\nAnd that technology Technology is tokens,\nall right?\n\n33\n00:01:28.383 --> 00:01:30.677\nNow when we talk about tokens,\n\n34\n00:01:30.677 --> 00:01:36.780\ntokens are used as an access control\nmethod in many different scenarios, right?\n\n35\n00:01:36.780 --> 00:01:41.400\nSo for instance you could have things like\nkey fobs that actually do token-based\n\n36\n00:01:41.400 --> 00:01:42.210\nauthentication.\n\n37\n00:01:42.210 --> 00:01:46.783\nWhere it's just a hardware chip that\nstores a little bit of information in it,\n\n38\n00:01:46.783 --> 00:01:51.514\nand when you touch some kind of secure\naccess door, it checks that information.\n\n39\n00:01:51.514 --> 00:01:55.713\nWe talked about things like\nthe military's common access card, or\n\n40\n00:01:55.713 --> 00:01:59.998\nC-A-C card, CAC card, actually has\na token built into it as well.\n\n41\n00:01:59.998 --> 00:02:03.966\nSo you can see that these tokens come\nin many different shapes and sizes,\n\n42\n00:02:03.966 --> 00:02:07.390\nthey can be software-based or\nthey can be hardware-based.\n\n43\n00:02:07.390 --> 00:02:10.980\nI'll give you an example\nof a hardware-based token,\n\n44\n00:02:10.980 --> 00:02:14.640\none of the companies that's out there, in\nfact I think we've got a couple of hosts,\n\n45\n00:02:14.640 --> 00:02:17.910\nat least one of the hosts here\nat ITPro TV that use these.\n\n46\n00:02:17.910 --> 00:02:22.189\nAnd it comes from a company called Yubico,\nthey make what's known as the Yubikey, and\n\n47\n00:02:22.189 --> 00:02:24.311\nI've actually got their website up here.\n\n48\n00:02:24.311 --> 00:02:28.691\nAnd this is great, cuz we talk about\nthings like multi-factor authentication,\n\n49\n00:02:28.691 --> 00:02:31.809\nand wouldn't it be nice to\nhave a little hardware device?\n\n50\n00:02:31.809 --> 00:02:33.974\nIn fact, if we kinda look the products up,\n\n51\n00:02:33.974 --> 00:02:36.600\nyou can see the YUBIKEYS\nhere as an example.\n\n52\n00:02:36.600 --> 00:02:39.910\nWouldn't it be nice to have something\non you that you could use for\n\n53\n00:02:39.910 --> 00:02:41.560\na multi-factor authentication?\n\n54\n00:02:41.560 --> 00:02:42.787\nAnd even though these are token-based, and\n\n55\n00:02:42.787 --> 00:02:44.601\nwe're really not talking about\nmulti-factor authentication.\n\n56\n00:02:44.601 --> 00:02:49.784\nIt's one of the things that allows us\nto do that very thing, that universal,\n\n57\n00:02:49.784 --> 00:02:53.955\nor if you will,\nthat second factor authentication, right?\n\n58\n00:02:53.955 --> 00:02:59.066\nSo if, for instance, we've got this key,\nwe can plug it in, we can press the thumb\n\n59\n00:02:59.066 --> 00:03:03.795\nprint on it, if you will, and you can\nalso do things like enter a password.\n\n60\n00:03:03.795 --> 00:03:07.979\nOr if you have a key that generates\na little numeric number on the outside of\n\n61\n00:03:07.979 --> 00:03:10.015\nit, that is time-based, right?\n\n62\n00:03:10.015 --> 00:03:15.625\nAnd that time based, if you will, token,\nit's gonna change every few seconds,\n\n63\n00:03:15.625 --> 00:03:21.093\nor whatever, 30 seconds, and it helps\nto strengthen your authentication.\n\n64\n00:03:21.093 --> 00:03:24.981\nBecause of the fact that, now you're\nnot only using something you know,\n\n65\n00:03:24.981 --> 00:03:26.170\nlike a password.\n\n66\n00:03:26.170 --> 00:03:30.945\nBut now you also have in your possession\nsomething that's also gonna be\n\n67\n00:03:30.945 --> 00:03:35.652\ncombined to perform, or to form,\na multi-factor authentication.\n\n68\n00:03:35.652 --> 00:03:38.890\nNow other examples of that we have as\nwell, maybe you've seen this one, Dan,\n\n69\n00:03:38.890 --> 00:03:40.330\nI know I've used this one before.\n\n70\n00:03:40.330 --> 00:03:44.559\nAnd this is something like, for instance,\nthe Google Authenticator, right?\n\n71\n00:03:44.559 --> 00:03:47.333\nThis is a software-based token system,\n\n72\n00:03:47.333 --> 00:03:52.578\nwhere I actually have a code that's\ndelivered, you have to set it up, right?\n\n73\n00:03:52.578 --> 00:03:57.027\nYou set it up and it synchronizes between\nthe provider and your device, and\n\n74\n00:03:57.027 --> 00:03:58.366\nthen I have a code, and\n\n75\n00:03:58.366 --> 00:04:02.473\nthe code can be put into an authentication\nmechanism if you set it up.\n\n76\n00:04:02.473 --> 00:04:07.007\nYou can see for instance in Yubico's\nproducts, right, we could use this for\n\n77\n00:04:07.007 --> 00:04:11.702\na lot of different online services as\na form of multi-factor authentication.\n\n78\n00:04:11.702 --> 00:04:14.646\nWell, you can do the same thing\nwith Google Authenticator,\n\n79\n00:04:14.646 --> 00:04:16.204\nin fact is kind of interesting,\n\n80\n00:04:16.204 --> 00:04:20.200\nLastPass is one of the first places\nI ever used the Google Authenticator.\n\n81\n00:04:20.200 --> 00:04:23.898\nAnd that would just requires you,\nthey had LastPass doing password vaulting,\n\n82\n00:04:23.898 --> 00:04:25.897\nright, I have to enter a master password.\n\n83\n00:04:25.897 --> 00:04:28.968\nBut then I also have to enter\nthe little characters that\n\n84\n00:04:28.968 --> 00:04:33.376\nI see that the Google Authenticator is\ngenerating to give you that strength and\n\n85\n00:04:33.376 --> 00:04:37.620\nsecurity, if you will, by forming\nthat multi-factor authentication.\n\n86\n00:04:37.620 --> 00:04:42.052\nSo, those are tokens, guys,\nwhen it comes to certificate-based\n\n87\n00:04:42.052 --> 00:04:47.339\nauthentication in tokens, I want you to\nremember that one of the protocols we use\n\n88\n00:04:47.339 --> 00:04:52.266\nto implement token-based authentication\nis transport layer security.\n\n89\n00:04:52.266 --> 00:04:56.005\nAnd more specifically, EAP,\nthe Extensible Authentication Protocol,\n\n90\n00:04:56.005 --> 00:05:00.157\ntacks on TLS at the end to allow us to do\nthings like token-based authentication and\n\n91\n00:05:00.157 --> 00:05:02.202\ncertificate-based authentication.\n\n92\n00:05:02.202 --> 00:05:06.774\nAll right, so a couple other things that\nthey call out to, one time passwords,\n\n93\n00:05:06.774 --> 00:05:09.243\nright, OTPs you might hear these called.\n\n94\n00:05:09.243 --> 00:05:13.803\nAnd there are a couple of different forms\nof one time passwords, they call out\n\n95\n00:05:13.803 --> 00:05:18.385\nwhat's known as an HMAC OTP, [LAUGH] and\nthat's a very long acronym, right?\n\n96\n00:05:18.385 --> 00:05:23.869\nThat's a hashed message authentication\ncode one time password, [LAUGH] all right?\n\n97\n00:05:23.869 --> 00:05:28.116\nSo yeah, don't try to say that ten times\nfast, I could barely even say it once.\n\n98\n00:05:28.116 --> 00:05:33.079\nBut again, what it does is it\ntakes a secret key, if you will,\n\n99\n00:05:33.079 --> 00:05:37.381\nand it performs a hashing\nalgorithm on the password.\n\n100\n00:05:37.381 --> 00:05:41.005\nAnd again, the one time password\nis mixed with a counter, but\n\n101\n00:05:41.005 --> 00:05:44.502\nthere is a little bit of a drawback\nto the one time password.\n\n102\n00:05:44.502 --> 00:05:47.342\nSee, the one time password\nis used where they\n\n103\n00:05:47.342 --> 00:05:49.970\ndon't want you being able to guess a key.\n\n104\n00:05:49.970 --> 00:05:53.350\nIf I've got a static password right,\nrather than one time, right,\n\n105\n00:05:53.350 --> 00:05:56.670\nit gives the attackers all the time\n\n106\n00:05:56.670 --> 00:05:59.140\nessentially that they need to\ntry to break the password.\n\n107\n00:05:59.140 --> 00:06:02.370\nIt's one of the reasons we\nimplement password policies, right?\n\n108\n00:06:02.370 --> 00:06:07.310\nComplexity requirements,\ngiving the passwords shorter life cycles,\n\n109\n00:06:07.310 --> 00:06:08.370\n30 days, 60 days.\n\n110\n00:06:08.370 --> 00:06:12.370\nBut even at that, that gives it a lot\nof time for attackers to maybe or\n\n111\n00:06:12.370 --> 00:06:14.670\npotentially compromise those passwords.\n\n112\n00:06:14.670 --> 00:06:18.505\nSo imagine a password that is only\ngonna be used once, right, and\n\n113\n00:06:18.505 --> 00:06:21.946\nthen once it's used,\nit's never re-used, all right?\n\n114\n00:06:21.946 --> 00:06:24.599\nAnd then you move into a different\nsession, different communication,\n\n115\n00:06:24.599 --> 00:06:27.347\nthat password's gone, it's invalidated,\nand it's never used again.\n\n116\n00:06:27.347 --> 00:06:30.650\nWell that shortens, right,\n[LAUGH] the time that\n\n117\n00:06:30.650 --> 00:06:34.850\nan attacker would have in order\nto try to break that password.\n\n118\n00:06:34.850 --> 00:06:37.865\nBut there is a little bit of a drawback\nto the HOTPs, is the fact that,\n\n119\n00:06:37.865 --> 00:06:41.410\nlet's say that I was\nthe authenticating system.\n\n120\n00:06:41.410 --> 00:06:45.039\nAnd I was issuing out\nthe one time passwords,\n\n121\n00:06:45.039 --> 00:06:48.730\nright, and Dan got one, but\nhe didn't use it right away.\n\n122\n00:06:48.730 --> 00:06:52.890\nWell, that password's still valid,\nand one of the problems with\n\n123\n00:06:52.890 --> 00:06:57.660\nthe hash one time passwords, is just\nthe fact they're valid until they're used.\n\n124\n00:06:58.880 --> 00:07:03.085\nSo a step up from that is what's\nknown as a timed OTP, right?\n\n125\n00:07:03.085 --> 00:07:05.822\nAgain, one time password, they're\ngenerated pretty much the same exact way,\n\n126\n00:07:05.822 --> 00:07:07.564\nbut there's a little bit of a difference,\nright?\n\n127\n00:07:07.564 --> 00:07:12.004\nYes, they've got a sequential value\non them, but they're now time based,\n\n128\n00:07:12.004 --> 00:07:12.700\nall right?\n\n129\n00:07:12.700 --> 00:07:16.508\nWhich means now let me give you another\nexample, say I issued Dan one of these\n\n130\n00:07:16.508 --> 00:07:21.110\ntimed one time passwords, and\nwe say it expires in one hour.\n\n131\n00:07:21.110 --> 00:07:24.020\nSo now what we've done is yeah,\nwe've got a one time password, but\n\n132\n00:07:24.020 --> 00:07:28.100\nthen if it's not used, it can't just\nsit in the recipient's possession,\n\n133\n00:07:28.100 --> 00:07:30.250\ngiving somebody a chance to steal it.\n\n134\n00:07:30.250 --> 00:07:32.540\nBecause what happens if I'm the attacker,\nright,\n\n135\n00:07:32.540 --> 00:07:35.280\nsay it's a completely different\nauthentication system,\n\n136\n00:07:35.280 --> 00:07:39.930\ngives Dan the hashed one time password,\nand he stores it or caches it.\n\n137\n00:07:39.930 --> 00:07:43.110\nWhat's to say that I couldn't get into\nthat machine potentially, and steal that\n\n138\n00:07:43.110 --> 00:07:47.540\npassword, if it's never been used, it's\nstill good, and then I could use it right?\n\n139\n00:07:47.540 --> 00:07:51.246\nBut if we have a time based,\nagain it shortens the life cycle right,\n\n140\n00:07:51.246 --> 00:07:52.948\nwhat do they say, ephemeral?\n\n141\n00:07:52.948 --> 00:07:53.826\n&gt;&gt; Yeah.\n\n142\n00:07:53.826 --> 00:07:55.679\n&gt;&gt; Very short lived I believe, so\n\n143\n00:07:55.679 --> 00:07:59.610\nagain that's one of the benefits\nof the timed one time password.\n\n144\n00:07:59.610 --> 00:08:03.464\n&gt;&gt; So if an attacker wants to get in,\nthey've gotta really do their business and\n\n145\n00:08:03.464 --> 00:08:07.455\ngrab ahold of that password, use it within\nthe time frame and then gain access.\n\n146\n00:08:07.455 --> 00:08:10.703\nCuz if they don't, just shortening\nthat amount of time makes it so\n\n147\n00:08:10.703 --> 00:08:14.242\nmuch more difficult for them to use\nyour authentication to gain access.\n\n148\n00:08:14.242 --> 00:08:16.154\n&gt;&gt; Most definitely, and\nhere's where we get back to,\n\n149\n00:08:16.154 --> 00:08:19.408\nlike we talked in the first part of\nthis episode, convenience and security.\n\n150\n00:08:19.408 --> 00:08:24.760\nWell, yeah,\na HOTP is convenient in the fact that\n\n151\n00:08:24.760 --> 00:08:28.978\nit takes a little bit less manage\ncuz a key can sit there for a bit.\n\n152\n00:08:28.978 --> 00:08:33.480\nThe timed password increases the security,\nbut it decreases the convenience,\n\n153\n00:08:33.480 --> 00:08:36.920\nbecause of the fact that if a key\nisn't used within its life cycle,\n\n154\n00:08:36.920 --> 00:08:39.840\nit's invalidated and\nrejected or thrown away.\n\n155\n00:08:39.840 --> 00:08:44.030\nSo you could see things like that too.\n\n156\n00:08:44.030 --> 00:08:45.600\nSome of the last things\nthat they talk about,\n\n157\n00:08:45.600 --> 00:08:47.480\nthey talk about file system security.\n\n158\n00:08:47.480 --> 00:08:51.030\nAnd when it comes to file system security,\nguys, it [LAUGH] really depends on what\n\n159\n00:08:51.030 --> 00:08:53.760\nfile system you have, and\nthere are many of them out there.\n\n160\n00:08:53.760 --> 00:08:57.362\n&gt;&gt; Are we talking encryption, or\nare we talking using access control?\n\n161\n00:08:57.362 --> 00:09:01.343\n&gt;&gt; Dan, that's a good question, cuz they\njust kinda label it file system security.\n\n162\n00:09:01.343 --> 00:09:04.000\nSo I'm going say, we're gonna do both,\nright, we'll talk about both.\n\n163\n00:09:04.000 --> 00:09:05.225\n&gt;&gt; We're gonna take it\nout of the computer,\n\n164\n00:09:05.225 --> 00:09:07.151\nwe're going to stick it in a locked vault,\nand put a key on it and-\n\n165\n00:09:07.151 --> 00:09:07.751\n&gt;&gt; That's right-\n\n166\n00:09:07.751 --> 00:09:08.496\n&gt;&gt; Bury it in the dirt, right,\n\n167\n00:09:08.496 --> 00:09:09.031\n[CROSSTALK] Secure.\n\n168\n00:09:09.031 --> 00:09:13.012\n&gt;&gt; The most protected file of all\nis the one that doesn't exist-\n\n169\n00:09:13.012 --> 00:09:13.725\n&gt;&gt; That's right [LAUGH]\n\n170\n00:09:13.725 --> 00:09:15.621\n&gt;&gt; But when it comes down to it,\n\n171\n00:09:15.621 --> 00:09:19.290\nit really depends on what\nfile system you even have.\n\n172\n00:09:19.290 --> 00:09:23.870\nFor instance, inside of Windows, primarily\nwe have NTFS and have for a long time.\n\n173\n00:09:23.870 --> 00:09:26.973\nNow most of these operating\nsystems that I'll mention support\n\n174\n00:09:26.973 --> 00:09:30.609\nmultiple file systems, like for\ninstance, Windows supports FAT32.\n\n175\n00:09:30.609 --> 00:09:34.365\nYou don't wanna use something like FAT32,\nit doesn't matter what system you're in.\n\n176\n00:09:34.365 --> 00:09:38.798\nDoesn't matter if you're Linux, Unix, Mac,\nbecause of the fact that while in FAT32,\n\n177\n00:09:38.798 --> 00:09:40.020\nyou don't have ACL's.\n\n178\n00:09:40.020 --> 00:09:42.430\nI can't say,\nwell this person has this permission,\n\n179\n00:09:42.430 --> 00:09:45.170\nthis person has this permission and\nthat permission.\n\n180\n00:09:45.170 --> 00:09:49.580\nSo it isn't a secure file system, in\nfact if you have a server, let's say for\n\n181\n00:09:49.580 --> 00:09:50.840\ninstance you have a Window server and\n\n182\n00:09:50.840 --> 00:09:53.680\nyou run something like this\nSecurity Configuration Wizard.\n\n183\n00:09:53.680 --> 00:09:57.187\nOr if you run something like\nthe Microsoft Baseline Security Analyzer,\n\n184\n00:09:57.187 --> 00:10:01.040\nit's gonna set up a red flag when it\nsees a FAT32 drive or a FAT32 partition,\n\n185\n00:10:01.040 --> 00:10:04.223\njust because of the fact that you\ncan't set permissions on them.\n\n186\n00:10:04.223 --> 00:10:07.444\nThe other things that you get with\nthings like NTFS inside of Windows,\n\n187\n00:10:07.444 --> 00:10:11.112\nyou get the encrypted file system, and\nthis is where we talk about encryption.\n\n188\n00:10:11.112 --> 00:10:14.819\nNow guys keep in mind there are other\nencryption technologies out there,\n\n189\n00:10:14.819 --> 00:10:16.865\nI'm just kinda familiar with Windows.\n\n190\n00:10:16.865 --> 00:10:19.643\nIf you're on a Linux operating system,\nright,\n\n191\n00:10:19.643 --> 00:10:22.301\nyou have permissions as\nwell that you can set.\n\n192\n00:10:22.301 --> 00:10:26.424\nKinda adheres more to the Unix based\npermissions, right, we have read, write,\n\n193\n00:10:26.424 --> 00:10:27.920\nand execute.\n\n194\n00:10:27.920 --> 00:10:29.110\nWhere in Windows, you\n\n195\n00:10:30.920 --> 00:10:35.670\ngot a little bit more permissions if\nyou will, you can get really granular.\n\n196\n00:10:35.670 --> 00:10:39.750\nBut that's one of the things to keep in\nmind, regardless of the operating system\n\n197\n00:10:39.750 --> 00:10:44.190\nthat you're in, use permission,\nuse your access control list, right?\n\n198\n00:10:44.190 --> 00:10:47.280\nIf you want somebody to\nhave access to a file,\n\n199\n00:10:47.280 --> 00:10:50.010\nimplement things like the principle\nof least privilege, right?\n\n200\n00:10:50.010 --> 00:10:52.550\nIf they only need to read the document,\n\n201\n00:10:52.550 --> 00:10:55.480\nthey have to make zero modifications,\nright?\n\n202\n00:10:55.480 --> 00:10:58.340\nWell then if I'm in something like,\na Linux system,\n\n203\n00:10:58.340 --> 00:11:01.420\nI'm only gonna give them read, I'm not\ngonna give them write and execute, right?\n\n204\n00:11:01.420 --> 00:11:04.740\nCuz I don't want them making\nmodifications to the document.\n\n205\n00:11:04.740 --> 00:11:07.940\nIf I'm inside of a Windows environment,\nI might give them the read permission,\n\n206\n00:11:07.940 --> 00:11:11.040\nand then exclude something like read and\nexecute.\n\n207\n00:11:11.040 --> 00:11:13.892\nBut again,\nthere's just no one size fits all too.\n\n208\n00:11:13.892 --> 00:11:16.950\nAlso keep in mind that when we\ntalk about file system security,\n\n209\n00:11:16.950 --> 00:11:19.440\nwe also have to worry about availability,\nright?\n\n210\n00:11:19.440 --> 00:11:23.948\nSo we talk about confidentiality, making\nsure only authorized users have access,\n\n211\n00:11:23.948 --> 00:11:25.630\nagain this is access control.\n\n212\n00:11:25.630 --> 00:11:29.390\nWe also have to make sure that\nthe authorized users have access as well.\n\n213\n00:11:29.390 --> 00:11:32.440\nAgain, you can get a little bit too\nsecure, you get so secure, even your users\n\n214\n00:11:32.440 --> 00:11:37.110\ncan't get the jobs done, and that's not\nexactly what we want inside of security.\n\n215\n00:11:37.110 --> 00:11:38.129\nIt's a healthy balance, and\n\n216\n00:11:38.129 --> 00:11:40.862\nI couldn't tell you where the balance is,\nbecause that's something that most\n\n217\n00:11:40.862 --> 00:11:42.921\nsecurity professionals in\nthe world today struggle with.\n\n218\n00:11:42.921 --> 00:11:47.022\nIs that fine line between making sure\nthat you don't overburden your users, but\n\n219\n00:11:47.022 --> 00:11:49.573\nat the same time you don't\ncompromise security.\n\n220\n00:11:49.573 --> 00:11:51.363\nSo do keep that in mind as well.\n\n221\n00:11:51.363 --> 00:11:56.538\nOne of the last things they call out is,\nif you will, database security,\n\n222\n00:11:56.538 --> 00:12:00.760\nand we've kinda talked about\ndatabase attacks and stuff.\n\n223\n00:12:00.760 --> 00:12:04.843\nFor instance, we have to worry about\ninjection attack, SQL injection attacks.\n\n224\n00:12:04.843 --> 00:12:07.566\n&gt;&gt; Yeah you do [LAUGH]\n&gt;&gt; Especially if there's a database on my\n\n225\n00:12:07.566 --> 00:12:10.090\nmachine, and\nI got this guy standing next to me or\n\n226\n00:12:10.090 --> 00:12:13.799\nthis guy over here [LAUGH] standing\nnext to me depending on where view is.\n\n227\n00:12:13.799 --> 00:12:18.698\nBecause, right,\npeople just wanna do things right?\n\n228\n00:12:18.698 --> 00:12:22.085\nThey either wanna take your information,\nmodify your information, or\n\n229\n00:12:22.085 --> 00:12:23.830\njust ruin your information.\n\n230\n00:12:23.830 --> 00:12:26.758\nThere are things that you have to do in\norder to keep those databases secure.\n\n231\n00:12:26.758 --> 00:12:29.081\n&gt;&gt; Well, databases,\nwhen it comes to the criminal element,\n\n232\n00:12:29.081 --> 00:12:30.899\ndatabase is one of the mountain tops,\nright?\n\n233\n00:12:30.899 --> 00:12:34.263\nThey want your data because they\ncan sell it, they can use it,\n\n234\n00:12:34.263 --> 00:12:36.350\nthey can blackmail you with it.\n\n235\n00:12:36.350 --> 00:12:38.115\nWhatever they wanna do,\n\n236\n00:12:38.115 --> 00:12:43.000\nthat is one of the best golden keys\nthat they can grab if they can grab.\n\n237\n00:12:43.000 --> 00:12:46.790\nSo access to your database is a very\nimportant thing when it comes to security.\n\n238\n00:12:46.790 --> 00:12:50.610\n&gt;&gt; Most definitely, so what are some\nthings that we can do when it comes to\n\n239\n00:12:51.720 --> 00:12:53.650\nbasically protecting your databases?\n\n240\n00:12:53.650 --> 00:12:56.670\nFirst things that they say\nis good implementation,\n\n241\n00:12:56.670 --> 00:12:59.720\nif you have a web application server\nthat's using a database, guess what?\n\n242\n00:12:59.720 --> 00:13:02.990\nThat database shouldn't be on\nthat web application server, why?\n\n243\n00:13:02.990 --> 00:13:05.742\nWell, I want you to think about it,\na lot of times,\n\n244\n00:13:05.742 --> 00:13:09.276\nyour web application servers have\na public facing side, right?\n\n245\n00:13:09.276 --> 00:13:12.244\nWhere somebody is connecting to it,\nmaybe filling out a web form,\n\n246\n00:13:12.244 --> 00:13:15.240\nmaybe buying something,\nand they're entering data.\n\n247\n00:13:15.240 --> 00:13:18.151\nThat data shouldn't be stored locally\non that machine, usually we call that\n\n248\n00:13:18.151 --> 00:13:21.037\na back-end server, right, it sends\nthat data to the back-end database.\n\n249\n00:13:21.037 --> 00:13:25.020\nSo that's one of the most basic things\nyou can do, is just don't keep your\n\n250\n00:13:25.020 --> 00:13:28.955\napplication server and your database\nserver on the same type of server.\n\n251\n00:13:28.955 --> 00:13:33.347\nNow, you might be a small environment, and\nif you've got complete air gapped in your\n\n252\n00:13:33.347 --> 00:13:35.728\nnetwork, that might be fine for\nyou, right?\n\n253\n00:13:35.728 --> 00:13:39.706\nIf you don't have any outbound\nconnections, that's a rarity, [LAUGH] but\n\n254\n00:13:39.706 --> 00:13:44.079\nif you don't have any outbound connections\nwell, maybe you're okay with that.\n\n255\n00:13:44.079 --> 00:13:46.305\nOther things, right we're talking\nabout SQL injection attacks,\n\n256\n00:13:46.305 --> 00:13:48.817\nDan talks about that being the golden\negg that you're looking for, right?\n\n257\n00:13:48.817 --> 00:13:52.620\nWell, I want you to think\nabout input validation, right?\n\n258\n00:13:52.620 --> 00:13:55.840\nMake sure that you're doing\nuser input validation,\n\n259\n00:13:55.840 --> 00:13:58.930\nwhat data do you expect\nto be in that database?\n\n260\n00:13:58.930 --> 00:14:01.380\nThat should be the only thing that\npeople can enter in those fields.\n\n261\n00:14:01.380 --> 00:14:04.430\nWe don't want things like executable\nstrings being able to make it towards\n\n262\n00:14:04.430 --> 00:14:05.680\nthe back-end.\n\n263\n00:14:05.680 --> 00:14:08.360\nOther things that you can do too,\nis data normalization, and\n\n264\n00:14:08.360 --> 00:14:13.140\nthere's a couple different reasons why\nyou might do data normalization, right?\n\n265\n00:14:13.140 --> 00:14:16.930\nFirst of all, normalization makes\nconsistency in your database.\n\n266\n00:14:16.930 --> 00:14:20.600\nI don't have duplicate entries, and\nI don't have all these redundant tables\n\n267\n00:14:20.600 --> 00:14:25.000\nleading to different data that\nyou're trying to retrieve,\n\n268\n00:14:25.000 --> 00:14:26.490\nright, it leads to an inconsistency.\n\n269\n00:14:26.490 --> 00:14:32.170\nSo we normalize it, and we try to remove\nthat redundancy, redundant entries.\n\n270\n00:14:32.170 --> 00:14:36.060\nThe other thing it does is it makes sure\nthat, let's say on the front-end, your web\n\n271\n00:14:36.060 --> 00:14:39.480\napplication is allowing you to do,\nlet's say uppercase and lowercase letters.\n\n272\n00:14:39.480 --> 00:14:44.130\nBut your database is only expecting,\nor maybe it is case-sensitive, right?\n\n273\n00:14:44.130 --> 00:14:49.850\nWell, as that data is brought from\nthe front-end web server into the database\n\n274\n00:14:49.850 --> 00:14:52.573\nserver, you might even have something\nlike a third party that says hey,\n\n275\n00:14:52.573 --> 00:14:55.010\nwe're gonna normalize that data.\n\n276\n00:14:55.010 --> 00:14:58.640\nBasically transforming it into\nwhatever came of the front-end,\n\n277\n00:14:58.640 --> 00:15:00.990\ninto what the back-end expects, right?\n\n278\n00:15:00.990 --> 00:15:04.020\nSo it's other ways that you\ncan secure that database.\n\n279\n00:15:04.020 --> 00:15:05.820\nSo reducing things like duplication,\n\n280\n00:15:05.820 --> 00:15:08.090\nmaintaining the integrity\nof your database.\n\n281\n00:15:08.090 --> 00:15:10.960\nNormalizing the information for\nthe purposes of making sure everything\n\n282\n00:15:10.960 --> 00:15:14.590\nthat's coming into the databases\nare the values that you expect.\n\n283\n00:15:14.590 --> 00:15:17.200\nAnd then well, some of the most obvious,\n\n284\n00:15:17.200 --> 00:15:21.580\nmaybe not obvious, so\nlet me not be so quick to say that.\n\n285\n00:15:21.580 --> 00:15:24.490\nWhen I say redundancy,\nI mean redundancy of of your databases,\n\n286\n00:15:24.490 --> 00:15:26.200\nright, availability, right?\n\n287\n00:15:26.200 --> 00:15:28.823\nBackups, backups are another\nthing that is very,\n\n288\n00:15:28.823 --> 00:15:31.761\nvery important when it comes\nto securing your database.\n\n289\n00:15:31.761 --> 00:15:34.231\nSo keep that in mind,\ndatabase servers, very,\n\n290\n00:15:34.231 --> 00:15:37.082\nvery important that we keep what is so\ncrucial, right?\n\n291\n00:15:37.082 --> 00:15:39.052\nWe're talking about\ninformation technology,\n\n292\n00:15:39.052 --> 00:15:42.810\nand more importantly in this course,\nwe're talking about information security.\n\n293\n00:15:42.810 --> 00:15:46.444\nWell if the information's stored in the\ndatabase, and the database isn't secure,\n\n294\n00:15:46.444 --> 00:15:48.220\nyou're not really doing your [LAUGH] job.\n\n295\n00:15:48.220 --> 00:15:51.470\nSo keep in mind, keep those databases\nsafe, keep them protected so\n\n296\n00:15:51.470 --> 00:15:54.530\nthat your company stays in business.\n\n297\n00:15:54.530 --> 00:15:55.600\n&gt;&gt; Alright, great stuff Wes,\n\n298\n00:15:55.600 --> 00:15:58.670\nwe do appreciate you lending\nyour time to us today.\n\n299\n00:15:58.670 --> 00:16:01.850\nI know this was a bit of a shorter\nepisode, but it was just a few odds and\n\n300\n00:16:01.850 --> 00:16:04.410\nends that we wanted to make sure\nto throw on top of there for you.\n\n301\n00:16:04.410 --> 00:16:07.780\nSo that you're a, prepared for the exam,\nand that you have a more well rounded\n\n302\n00:16:07.780 --> 00:16:09.530\nknowledge base,\nthat's what it's all about.\n\n303\n00:16:09.530 --> 00:16:12.370\nThat being said, that is going to go\nahead and close our show off for the day.\n\n304\n00:16:12.370 --> 00:16:16.600\nWe do appreciate you joining us though,\nwe hope you got a lot out of this little\n\n305\n00:16:16.600 --> 00:16:18.610\nshow we did for you,\nit's always a fun time.\n\n306\n00:16:18.610 --> 00:16:20.580\nWe do thank you, Wes,\nwe thank you again, and\n\n307\n00:16:20.580 --> 00:16:23.364\nsigning off for ITProTV,\nI've been your host Daniel Lowrie.\n\n308\n00:16:23.364 --> 00:16:24.682\n&gt;&gt; And I'm Wes Bryan.\n\n309\n00:16:24.682 --> 00:16:26.759\n&gt;&gt; And we'll see you next time.\n\n310\n00:16:26.759 --> 00:16:32.655\n[MUSIC]\n\n311\n00:16:32.655 --> 00:16:34.977\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216501922"
        },
        {
          "description": "In this episode, Daniel and Wes explore common account management practices. Here they will review the different account types like user accounts, service accounts, and privileged accounts.",
          "length": "1505",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-4-account_management_practices-050217-PGM.00_24_50_11.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-4-account_management_practices-050217-PGM.00_24_50_11.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-4-account_management_practices-050217-PGM.00_24_50_11.Still001-sm.jpg",
          "title": "Account Management Practices",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:06.560\nWelcome to ITPro.TV.\n\n2\n00:00:06.560 --> 00:00:08.184\n[MUSIC]\n\n3\n00:00:08.184 --> 00:00:12.005\n&gt;&gt; You're watching ITPro.TV.\n\n4\n00:00:12.005 --> 00:00:13.928\n&gt;&gt; All right, greetings everyone and\n\n5\n00:00:13.928 --> 00:00:16.590\nwelcome to another great\nepisode of ITPro.TV.\n\n6\n00:00:16.590 --> 00:00:17.830\nI'm your host Daniel Lowrie, and\n\n7\n00:00:17.830 --> 00:00:21.760\nin today's episode we are taking a look\nat more on our Security+ series.\n\n8\n00:00:21.760 --> 00:00:22.740\nAnd joining us in the studio,\n\n9\n00:00:22.740 --> 00:00:25.710\nlending his expertise on that topic,\nour good friend Mr. Wes Bryan.\n\n10\n00:00:25.710 --> 00:00:28.210\nWes, we're so glad to have you\nback again today, how's it going?\n\n11\n00:00:28.210 --> 00:00:29.420\n&gt;&gt; Man, it's going great, thanks.\n\n12\n00:00:29.420 --> 00:00:32.750\nIt's always good to be here with\nthe ITProTV crew in the studios.\n\n13\n00:00:32.750 --> 00:00:36.840\nThat's right, we're gonna be looking at,\nwell, common account management practices.\n\n14\n00:00:36.840 --> 00:00:42.020\nWe do have to keep in mind that any\ntime we have a platform we're gonna\n\n15\n00:00:42.020 --> 00:00:46.140\nhave different types of users, and we have\nto be able to distinguish those user types\n\n16\n00:00:46.140 --> 00:00:49.650\nand some of the roles that they can and\ncannot perform inside of our networks.\n\n17\n00:00:49.650 --> 00:00:52.930\nAnd it doesn't matter if we're\ntalking about a workgroup environment,\n\n18\n00:00:52.930 --> 00:00:56.660\nif we're talking about a home environment,\nor if we're talking about having some kind\n\n19\n00:00:56.660 --> 00:01:00.950\nof enterprise IAM, or identity\naccess management solution, right.\n\n20\n00:01:00.950 --> 00:01:03.270\nA lot of times, when you have users,\n\n21\n00:01:03.270 --> 00:01:06.840\nthey usually can be classified as\na few different account types.\n\n22\n00:01:06.840 --> 00:01:10.560\nAnd we have to be aware of those account\ntypes, because when it comes down to it,\n\n23\n00:01:10.560 --> 00:01:15.560\nany kind of account you have, right,\nkind of jumping out of order with my notes\n\n24\n00:01:15.560 --> 00:01:20.826\nhere, we have to be thinking about\nthe principle of least privilege, right.\n\n25\n00:01:20.826 --> 00:01:25.910\nOnly giving your users exactly the level\nof access they need, the level\n\n26\n00:01:25.910 --> 00:01:30.270\nof rights or privileges on or to a system\nthat they need to perform their job.\n\n27\n00:01:30.270 --> 00:01:34.956\nNo more, right, because then it becomes\na potential security vulnerability, and\n\n28\n00:01:34.956 --> 00:01:38.920\nno less because that affects\nproductivity and hinders availability.\n\n29\n00:01:38.920 --> 00:01:44.010\nRemember, as we've been just kinda\nchugging through the Security+ training,\n\n30\n00:01:44.010 --> 00:01:48.630\nkeep in mind we've been emphasizing that\nCIA triad, confidentiality, integrity and\n\n31\n00:01:48.630 --> 00:01:50.990\navailability, and\navailability is one of them.\n\n32\n00:01:50.990 --> 00:01:53.110\nSo I got a little diagram here, and\n\n33\n00:01:53.110 --> 00:01:57.515\nit kinda just outlines the different\nuser types that they're talking about.\n\n34\n00:01:57.515 --> 00:01:58.020\nWell, and\n\n35\n00:01:58.020 --> 00:02:02.290\nyou can see that they call out about\nfive of these user account types, right.\n\n36\n00:02:02.290 --> 00:02:06.360\nNow with user accounts, this really\ndepends, I mean that's kind of generic.\n\n37\n00:02:06.360 --> 00:02:09.590\nBut we can see that you typically have\nthings like administrative users,\n\n38\n00:02:09.590 --> 00:02:11.970\nif you will, and\nyou have standard users, right.\n\n39\n00:02:11.970 --> 00:02:13.920\nWhen we talk about just\na basic user account,\n\n40\n00:02:13.920 --> 00:02:16.580\ntypically what we're talking\nabout is the fact that a user,\n\n41\n00:02:16.580 --> 00:02:21.490\nthey can perform most of the basic\nday-to-day actions, right, and tasks.\n\n42\n00:02:21.490 --> 00:02:25.260\nBut one of the things that they can't do\nis make modifications to the core settings\n\n43\n00:02:25.260 --> 00:02:29.390\nwithin the operating system, right,\nthat takes a Windows administrator, or\n\n44\n00:02:29.390 --> 00:02:32.420\nif you're in a nix based system,\nright, that takes your root user.\n\n45\n00:02:32.420 --> 00:02:35.380\nAnd they can't make things\nlike modifications to the key\n\n46\n00:02:35.380 --> 00:02:36.768\nsecurity settings.\n\n47\n00:02:36.768 --> 00:02:42.780\nThey also, a user again can be denied\naccess to privileged applications such\n\n48\n00:02:42.780 --> 00:02:47.420\nas some of the administrative tools that\nyou have inside of your operating system.\n\n49\n00:02:47.420 --> 00:02:49.947\nIn fact let me go and\nkinda switch over to Windows here, and\n\n50\n00:02:49.947 --> 00:02:51.970\nyou'll see I'm logged\nin as a standard user.\n\n51\n00:02:51.970 --> 00:02:55.178\nI'm actually logged in myself, and\nI've got myself set up as a standard user.\n\n52\n00:02:55.178 --> 00:02:58.240\nAnd if I do something as simple\nas right clicking on my little\n\n53\n00:02:58.240 --> 00:03:02.850\nWindows Start button icon here, and notice\nwe have two different PowerShells, right.\n\n54\n00:03:02.850 --> 00:03:04.981\nIf I launch PowerShell by itself,\n\n55\n00:03:04.981 --> 00:03:08.360\nwell I get in here no problem and\nwe can do things like for\n\n56\n00:03:08.360 --> 00:03:12.711\ninstance I can see the directories and\nstuff, that's not a big deal.\n\n57\n00:03:12.711 --> 00:03:17.556\nBut notice what happens when we\nchoose a privileged application,\n\n58\n00:03:17.556 --> 00:03:20.419\nright, you see the little Admin here.\n\n59\n00:03:20.419 --> 00:03:24.643\nAnd I launch it, notice that in this\ncase the dynamic security technology is\n\n60\n00:03:24.643 --> 00:03:28.603\nthe user account control, right,\nand it's letting me know that hey,\n\n61\n00:03:28.603 --> 00:03:32.629\nyou have to enter an admin, username,\nor password, or no food for you,\n\n62\n00:03:32.629 --> 00:03:35.540\nright, you don't get to\nlaunch this application.\n\n63\n00:03:35.540 --> 00:03:39.079\nAnd again, that's one of the things\nthat differentiates a standard user\n\n64\n00:03:39.079 --> 00:03:43.260\nfrom an administrative-type user, right,\nwell that is a privileged application.\n\n65\n00:03:43.260 --> 00:03:45.255\nLet's go a little bit farther there, and\n\n66\n00:03:45.255 --> 00:03:48.276\nremember that when you install\nan application inside of a, for\n\n67\n00:03:48.276 --> 00:03:52.323\ninstance a Windows environment, it makes\nmodifications to the registry, right,\n\n68\n00:03:52.323 --> 00:03:55.686\nthose are core settings within\nthe configuration settings, right.\n\n69\n00:03:55.686 --> 00:03:58.715\nSo if I have something as\nsimple as Notepad++ right here,\n\n70\n00:03:58.715 --> 00:04:01.563\nnotice the little shield right there,\nthat lets me know\n\n71\n00:04:01.563 --> 00:04:05.400\nthat this takes an administrative level\nprivilege in order to install it.\n\n72\n00:04:05.400 --> 00:04:09.440\nAnd if I run this it does the same\nthing even though this is just,\n\n73\n00:04:09.440 --> 00:04:12.960\nyou might say well, Notepad++,\nit's just a word processor, right.\n\n74\n00:04:12.960 --> 00:04:15.214\nBut it's not really\nabout that application,\n\n75\n00:04:15.214 --> 00:04:19.145\nonce it's installed you're good, but\nthe installation process does make some\n\n76\n00:04:19.145 --> 00:04:23.039\nmodifications down there in the registry\nand Windows is aware of that, right.\n\n77\n00:04:23.039 --> 00:04:26.848\nThat would be no different than if I was\nmaybe logged into something like a Linux\n\n78\n00:04:26.848 --> 00:04:30.482\nbased system and I make a change to\none of the configuration files, right,\n\n79\n00:04:30.482 --> 00:04:32.407\ndown in network scripts or something.\n\n80\n00:04:32.407 --> 00:04:35.130\nAnd what does it do,\nit says access denied and\n\n81\n00:04:35.130 --> 00:04:39.645\nI have to either have a root based account\nor I have to enter it in superuser,\n\n82\n00:04:39.645 --> 00:04:42.820\nright, I have to do a superuser do,\na sudo, right.\n\n83\n00:04:42.820 --> 00:04:45.830\nAgain, and that's the operating\nsystem protecting itself,\n\n84\n00:04:45.830 --> 00:04:50.580\nit's protecting itself from a user\nversus an administrative user.\n\n85\n00:04:50.580 --> 00:04:55.880\nCuz very easily could you get into\na situation where your standard users\n\n86\n00:04:55.880 --> 00:04:59.830\ncan cause problems if they're not aware\nof what they're doing, all right, so\n\n87\n00:04:59.830 --> 00:05:02.480\nthey typically cannot make modifications.\n\n88\n00:05:02.480 --> 00:05:05.850\nNow the other one that we have,\nright, they talk about shared and\n\n89\n00:05:05.850 --> 00:05:06.878\ngeneric accounts.\n\n90\n00:05:06.878 --> 00:05:11.650\nAnd, really, with the shared and\ngeneric accounts there could be a problem.\n\n91\n00:05:11.650 --> 00:05:15.680\nOne of the things that comes to\nmind is the cousin to the CIA triad\n\n92\n00:05:15.680 --> 00:05:18.400\nthat we've been mentioning, right,\nwe say confidentiality, integrity, and\n\n93\n00:05:18.400 --> 00:05:22.748\navailability, well there's also a fourth\none that kinda isn't included in that.\n\n94\n00:05:22.748 --> 00:05:27.160\nThat's called non-repudiation, right,\nhow do you audit a generic account, right.\n\n95\n00:05:27.160 --> 00:05:30.922\nIf Dan, myself, and some of the other\nhosts, we all share a single account and\n\n96\n00:05:30.922 --> 00:05:33.608\nsomebody logs in,\nhow do we know who logged in, right.\n\n97\n00:05:33.608 --> 00:05:37.512\nHow do we know who performed those tasks,\nhow do we audit that and\n\n98\n00:05:37.512 --> 00:05:40.491\ntie those tasks back to a specific user,\nright.\n\n99\n00:05:40.491 --> 00:05:45.650\nSo shared and generic accounts, it can\nbe a problem, they can lead to increased\n\n100\n00:05:45.650 --> 00:05:50.508\nrisk of compromise cuz anybody in that\nchain that is sharing that account.\n\n101\n00:05:50.508 --> 00:05:54.740\nI'm not saying amongst the hosts, but\nif that becomes a standard practice within\n\n102\n00:05:54.740 --> 00:05:57.450\nyour company who is it that\ncompromised the system?\n\n103\n00:05:57.450 --> 00:05:59.942\nAnd again, with lack of an audit\ntrail you wouldn't be able to,\n\n104\n00:05:59.942 --> 00:06:01.660\nyou'd have to do a lot\nmore detective work.\n\n105\n00:06:01.660 --> 00:06:06.940\nSo the management of these type of\naccounts can cause problems too.\n\n106\n00:06:08.100 --> 00:06:09.190\nThen there's guest accounts.\n\n107\n00:06:10.420 --> 00:06:13.300\nGuest accounts has to be used sparingly,\nall right, and\n\n108\n00:06:13.300 --> 00:06:16.960\nthe reason I say that is because guest\naccounts are a lot of times they're\n\n109\n00:06:16.960 --> 00:06:19.850\nan optional account,\nthey need to be used with caution.\n\n110\n00:06:19.850 --> 00:06:22.650\nAnd what you need to do is if you\nare going to implement them and\n\n111\n00:06:22.650 --> 00:06:27.120\nuse them, then you reduce their privilege\nset, right, you reduce their permission\n\n112\n00:06:27.120 --> 00:06:30.615\nset down to almost minimalistic,\nalmost to nothing, right.\n\n113\n00:06:30.615 --> 00:06:33.043\n&gt;&gt; [CROSSTALK] very similar to\nthe generic accounts actually.\n\n114\n00:06:33.043 --> 00:06:37.207\n&gt;&gt; They really do, and the big difference\nhere is maybe there's an account to\n\n115\n00:06:37.207 --> 00:06:41.171\na web application that we have to log\ninto and we wanna see the front end so\n\n116\n00:06:41.171 --> 00:06:43.830\nwhat do they do, right,\nwe have a sales team.\n\n117\n00:06:43.830 --> 00:06:46.862\nSales team maybe wants\nto test a user account,\n\n118\n00:06:46.862 --> 00:06:50.371\nright now they all share\nthe same exact user account.\n\n119\n00:06:50.371 --> 00:06:54.426\nWell, that is a generic shared account,\nbut it's not necessarily a guest account,\n\n120\n00:06:54.426 --> 00:06:55.958\nlet me show what I mean, right.\n\n121\n00:06:55.958 --> 00:06:59.345\nWe could set those up inside of Windows,\nbut Windows is one of these ones,\n\n122\n00:06:59.345 --> 00:07:02.734\nif I drill down in here to Computer\nManagement I'm gonna find out how much I\n\n123\n00:07:02.734 --> 00:07:04.335\ncan do as a standard user, right.\n\n124\n00:07:04.335 --> 00:07:08.654\nAnd I look at, for instance, local users\nin groups, right, the guest account by\n\n125\n00:07:08.654 --> 00:07:12.911\ndefault for a while in Windows, I think\ngoing back to Windows Vista if I believe,\n\n126\n00:07:12.911 --> 00:07:16.541\nright, when they went to the standard\nuser security architecture,\n\n127\n00:07:16.541 --> 00:07:19.090\nthe guest account is disabled.\n\n128\n00:07:19.090 --> 00:07:23.300\nRight, so guest accounts again are one\nof those type of accounts that,\n\n129\n00:07:23.300 --> 00:07:27.652\njust like Dan said, they do kinda\ncoincide with each other in the fact that\n\n130\n00:07:27.652 --> 00:07:30.910\nyou don't get access to non-repudiation.\n\n131\n00:07:30.910 --> 00:07:34.470\nAnd sometimes it's very hard to do an\naudit trail on these guest accounts, and\n\n132\n00:07:34.470 --> 00:07:35.870\na lot of times they're disabled.\n\n133\n00:07:35.870 --> 00:07:39.590\nSo one of the things that you wanna do is,\nif you are using the guest account,\n\n134\n00:07:39.590 --> 00:07:44.670\nis just use it cautiously, very sparingly,\nand make sure that you're reducing\n\n135\n00:07:44.670 --> 00:07:50.360\nits privilege or permission set to\njust exactly what they need access to.\n\n136\n00:07:50.360 --> 00:07:56.317\nAll right, and you can see for security\npurposes it is disabled inside of Windows.\n\n137\n00:07:56.317 --> 00:07:59.269\nThen we have other things too,\nand again service accounts.\n\n138\n00:07:59.269 --> 00:08:02.066\nAnd when it comes to service accounts,\n\n139\n00:08:02.066 --> 00:08:06.060\nthese These can be\nan administrative nightmare right?\n\n140\n00:08:06.060 --> 00:08:08.720\nThey can introduce\nmanagement complexities.\n\n141\n00:08:08.720 --> 00:08:13.100\nAnd one of the biggest things with service\naccounts, one of the administrative\n\n142\n00:08:13.100 --> 00:08:17.800\nmanagement complexities that you\nhave is password management, right?\n\n143\n00:08:17.800 --> 00:08:20.940\nWhen you have a service account again,\nit needs to authenticate.\n\n144\n00:08:20.940 --> 00:08:24.200\nA lot of times it's gonna fall\nunder some kind of password policy.\n\n145\n00:08:24.200 --> 00:08:28.750\nLet's say it's out of a Windows domain in\nwhere the password is gonna change, right.\n\n146\n00:08:28.750 --> 00:08:31.890\nWell, sometimes people might say,\nwell you know what, let's go ahead and\n\n147\n00:08:31.890 --> 00:08:34.660\ngo into the properties that\nservice account will uncheck\n\n148\n00:08:34.660 --> 00:08:36.049\nthat the password needs to be changed.\n\n149\n00:08:37.120 --> 00:08:39.300\nWell that right there is\na security vulnerability right?\n\n150\n00:08:39.300 --> 00:08:42.830\nSo password management really with these\nservice accounts is one of the things that\n\n151\n00:08:42.830 --> 00:08:45.960\nreally becomes the complexity and\nit can lead to things like compromise and\n\n152\n00:08:45.960 --> 00:08:47.436\nvulnerabilities within your systems.\n\n153\n00:08:47.436 --> 00:08:52.230\nAgain, one of the things that you can do\n\n154\n00:08:52.230 --> 00:08:56.880\nis they do have managed\nservice account services.\n\n155\n00:08:56.880 --> 00:09:00.990\nI know that's kind of redundant there but\na managed service account, right?\n\n156\n00:09:00.990 --> 00:09:05.290\nAnd what I mean by that let's take for\ninstance inside a Windows here.\n\n157\n00:09:05.290 --> 00:09:06.700\nWhere is my browser?\n\n158\n00:09:06.700 --> 00:09:08.440\nOne of the browsers round here somewhere.\n\n159\n00:09:08.440 --> 00:09:09.510\nThere we go.\n\n160\n00:09:09.510 --> 00:09:14.080\nSo for instance, because of this\ncomplexity of managing the passwords in\n\n161\n00:09:14.080 --> 00:09:17.101\na service account,\nWindows did something, and\n\n162\n00:09:17.101 --> 00:09:21.252\nthey introduced managed Service\naccounts and virtual accounts.\n\n163\n00:09:21.252 --> 00:09:25.905\nAnd essentially what this does is\nthis allows the operating system\n\n164\n00:09:25.905 --> 00:09:30.073\nenvironment to manage\nthe passwords with these accounts.\n\n165\n00:09:30.073 --> 00:09:33.377\nBecause if you think about one,\nthat's okay, but what if you're\n\n166\n00:09:33.377 --> 00:09:37.566\nan enterprise level corporation that has\n15 different application servers, and\n\n167\n00:09:37.566 --> 00:09:39.820\nyou have hundreds of services?\n\n168\n00:09:39.820 --> 00:09:41.390\nWell, that really becomes a complexity.\n\n169\n00:09:41.390 --> 00:09:45.270\nWe're just talking about, it's complex\nabout to manage one or two of these,\n\n170\n00:09:45.270 --> 00:09:51.630\nlet alone if there's 15, 20, 30, 40,\nhundreds of this accounts, right?\n\n171\n00:09:51.630 --> 00:09:55.490\nBut maybe that's still too much\nof a complexity to you, right?\n\n172\n00:09:55.490 --> 00:09:59.060\nWell, you've got things like Thycotic out\nthere as an example of an actual service\n\n173\n00:09:59.060 --> 00:10:00.110\nprovider, if you will.\n\n174\n00:10:00.110 --> 00:10:03.265\nAnd what they do is offer you\nservices in the background,\n\n175\n00:10:03.265 --> 00:10:07.520\n[LAUGH] is to secure and automate\nservice Is account management, right?\n\n176\n00:10:07.520 --> 00:10:08.870\nAnd again, what's the challenge?\n\n177\n00:10:08.870 --> 00:10:11.500\nSo you will see on their website\nthey talked about money different\n\n178\n00:10:11.500 --> 00:10:14.420\napplications across the IT systems.\n\n179\n00:10:14.420 --> 00:10:18.190\nAnd again it becomes a very difficult\ncomplexity in order to manage these.\n\n180\n00:10:18.190 --> 00:10:21.290\nSo you can follow things like your\nsecurity configuration best practices\n\n181\n00:10:21.290 --> 00:10:25.190\nPractices like Microsoft has, where\nthey introduce managed service accounts.\n\n182\n00:10:25.190 --> 00:10:26.950\nBack in Windows 7 and Server 2008,\n\n183\n00:10:26.950 --> 00:10:31.205\nI wanna say it was 2008 R2 or you can\nget a service like this, you can pay.\n\n184\n00:10:31.205 --> 00:10:36.640\nYou might see that the risk of having\nthese and managing these internally is so\n\n185\n00:10:36.640 --> 00:10:40.600\ngreat that it justifies allowing\nsomebody else to do this for you.\n\n186\n00:10:40.600 --> 00:10:44.200\nAll right so what's the last\naccounts that they talked about?\n\n187\n00:10:44.200 --> 00:10:47.550\nWell they talked about privileged accounts\nall right and privileged accounts we've\n\n188\n00:10:47.550 --> 00:10:51.810\nalready kind of kind of mentioned your\nadministrator, your windows administrator\n\n189\n00:10:51.810 --> 00:10:57.500\naccount that is a privileged account\ninside of your operating system.\n\n190\n00:10:57.500 --> 00:11:00.940\nThere are other account types right for\nif the nick based systems,\n\n191\n00:11:00.940 --> 00:11:02.910\nunit Linux right we have he root user.\n\n192\n00:11:02.910 --> 00:11:06.210\nThat is a could be a privileged account.\n\n193\n00:11:06.210 --> 00:11:10.910\nYou also have service accounts that are\nmanaged by the system themselves, right.\n\n194\n00:11:10.910 --> 00:11:12.960\nI'm not talking about\na managed service account but\n\n195\n00:11:12.960 --> 00:11:16.230\nI'm talking about an account\nlike the system account, right.\n\n196\n00:11:16.230 --> 00:11:19.830\nThe network account, right,\nthat are running in the background.\n\n197\n00:11:19.830 --> 00:11:22.160\nAnd again,\nwe have to keep these protected.\n\n198\n00:11:22.160 --> 00:11:26.890\nBut more so than anything is making sure\nthat your administrative level accounts,\n\n199\n00:11:26.890 --> 00:11:30.040\nthe ones that have those privileges\nagain are used sparingly.\n\n200\n00:11:30.040 --> 00:11:33.800\nAnd they're only used where that\nlevel of access is needed right.\n\n201\n00:11:33.800 --> 00:11:36.710\nIt's easy to say okay let's make\neverybody be a domain admin and\n\n202\n00:11:36.710 --> 00:11:41.350\nthat handles getting calls from the help\ndesk when they need to do something.\n\n203\n00:11:41.350 --> 00:11:43.870\nThey get tired of filling out\na help desk ticket on something,\n\n204\n00:11:43.870 --> 00:11:47.290\nso we'll just make it easy,\nwe'll let them take care of it, right?\n\n205\n00:11:47.290 --> 00:11:49.140\nThat's not how you implement it.\n\n206\n00:11:49.140 --> 00:11:52.510\nYou always implement\nthe principle of least privilege.\n\n207\n00:11:54.040 --> 00:11:57.025\nAll right, so that takes care of\nthe account accounts that we have here.\n\n208\n00:11:57.025 --> 00:11:59.915\nAgain, these accounts be aware\nof what these accounts are and\n\n209\n00:11:59.915 --> 00:12:02.885\nbe aware of some of the things\nthat you can do in order to reduce\n\n210\n00:12:02.885 --> 00:12:05.885\nthe vulnerabilities or\nthe security compromises that you\n\n211\n00:12:05.885 --> 00:12:09.395\nmight have inside of your systems when it\ncomes to using the different accounts.\n\n212\n00:12:09.395 --> 00:12:12.540\n&gt;&gt; Yeah, that's a really good\nsegue too Wes to a question.\n\n213\n00:12:12.540 --> 00:12:13.300\nHow do we do that?\n\n214\n00:12:13.300 --> 00:12:16.080\nWhat are some of\nthe common best practices?\n\n215\n00:12:16.080 --> 00:12:19.060\nI've got this different accounts,\nI need to keep them secure.\n\n216\n00:12:19.060 --> 00:12:22.840\nI now know what each one of them are,\nwhat they do, what their role is.\n\n217\n00:12:22.840 --> 00:12:25.680\nAre there differences in the way in\nwhich we would secure those different\n\n218\n00:12:25.680 --> 00:12:26.640\ntypes of accounts?\n\n219\n00:12:26.640 --> 00:12:27.660\nIf so, what are they?\n\n220\n00:12:27.660 --> 00:12:30.300\nIt's a lot of questions that come to mind\n\n221\n00:12:30.300 --> 00:12:32.220\nwhen it comes to how we\nactually secure these things.\n\n222\n00:12:32.220 --> 00:12:33.030\n&gt;&gt; Most definitely and\n\n223\n00:12:33.030 --> 00:12:35.540\none of the great things is we have\na lot of different techniques.\n\n224\n00:12:35.540 --> 00:12:36.610\nWe have a lot of options and\n\n225\n00:12:36.610 --> 00:12:39.887\nit's very important just to know those\noptions exist and what the options are.\n\n226\n00:12:39.887 --> 00:12:43.471\nLike for instance, one of the first\nthings that they call out, and\n\n227\n00:12:43.471 --> 00:12:47.761\nI had to start the whole entire account\nmanagement episode with the principle of\n\n228\n00:12:47.761 --> 00:12:49.260\nleast privilege, right.\n\n229\n00:12:49.260 --> 00:12:52.040\nWe talk about giving, again,\nlowering that privilege to\n\n230\n00:12:52.040 --> 00:12:56.940\njust what the end user needs to get their\njob accomplished, no more, no less,\n\n231\n00:12:56.940 --> 00:12:59.600\nso principle of least privilege, right.\n\n232\n00:12:59.600 --> 00:13:03.170\nWe also have things like onboarding and\noffboarding policies right,\n\n233\n00:13:03.170 --> 00:13:06.440\nthat we have to potentially,\nfollow and implement, as well.\n\n234\n00:13:06.440 --> 00:13:09.800\nSo, when we talk about things\nlike onboarding, right.\n\n235\n00:13:09.800 --> 00:13:12.720\nThe onboarding process,\nright, is the hiring process.\n\n236\n00:13:12.720 --> 00:13:15.920\nAnd, maybe, you've never thought about\nthe onboarding process as being something\n\n237\n00:13:15.920 --> 00:13:17.360\nlike like that, right?\n\n238\n00:13:17.360 --> 00:13:22.640\nSomething like for instance a the fact\nthat you're hiring somebody,\n\n239\n00:13:22.640 --> 00:13:25.430\nI want you to think about when your\nhiring somebody what are you doing?\n\n240\n00:13:25.430 --> 00:13:28.150\nRight, your company is considering\n\n241\n00:13:28.150 --> 00:13:31.380\nentering into a trust\nrelationship with a stranger.\n\n242\n00:13:32.490 --> 00:13:34.500\nThat's what the on\nboarding process is right?\n\n243\n00:13:34.500 --> 00:13:38.044\nSomebody comes to get hired with you,\nyou're basically trusting a stranger.\n\n244\n00:13:38.044 --> 00:13:41.249\nYou don't have a trust relationship with\nthem the first time that they come on\n\n245\n00:13:41.249 --> 00:13:42.246\nboard to your company.\n\n246\n00:13:42.246 --> 00:13:46.820\nSo an onboarding process is very,\nvery important, right.\n\n247\n00:13:46.820 --> 00:13:50.190\nWe have things like documentation, right,\nwe document things like onboarding\n\n248\n00:13:50.190 --> 00:13:52.780\nprocess, we have templates for\nconsistency.\n\n249\n00:13:52.780 --> 00:13:56.080\nSo if Dan's hired in the onboarding\nprocess and then I turn around and\n\n250\n00:13:56.080 --> 00:13:59.350\nI'm hired on the onboarding process,\nI can't sit there and say,\n\n251\n00:13:59.350 --> 00:14:02.220\nwell, Dan didn't have to go\nthrough that but I did, right?\n\n252\n00:14:02.220 --> 00:14:04.340\nSo we use things like documentation,\npolicies and\n\n253\n00:14:04.340 --> 00:14:08.160\ntemplates to ensure that\nthere's consistency, right?\n\n254\n00:14:08.160 --> 00:14:11.965\nHow about things like this,\nnondisclosure agreements right,\n\n255\n00:14:11.965 --> 00:14:15.210\nNDAs maybe be part of\nthe onboarding process is an NDA.\n\n256\n00:14:15.210 --> 00:14:17.780\nMaybe you are working with material,\n\n257\n00:14:17.780 --> 00:14:21.350\nsensitive material that maybe somebody\nelse can't be privy to right.\n\n258\n00:14:21.350 --> 00:14:25.190\nSo we implement things like NDAs as\npart of the on boarding process so\n\n259\n00:14:25.190 --> 00:14:28.710\nwe don't have information\nthat's being exfiltrated or\n\n260\n00:14:29.880 --> 00:14:34.180\njust exposed to unauthorized viewers or\nconsumers, right?\n\n261\n00:14:34.180 --> 00:14:36.880\n&gt;&gt; Using the power of the sword of law\n\n262\n00:14:36.880 --> 00:14:40.250\nto enforce the fact that you can't talk\nabout things we tell you not to talk.\n\n263\n00:14:40.250 --> 00:14:41.720\nNo, first rule of fight club is, right?\n\n264\n00:14:41.720 --> 00:14:43.280\n&gt;&gt; You never talk about fight club.\n\n265\n00:14:43.280 --> 00:14:44.270\nThat's right.\n\n266\n00:14:44.270 --> 00:14:48.010\nThings like, for instance, AUPs,\nacceptable use policies, right?\n\n267\n00:14:48.010 --> 00:14:50.160\nHow are you gonna use\nthe wireless network?\n\n268\n00:14:50.160 --> 00:14:53.310\nIf you're going to use your own device,\nright, BYOD.\n\n269\n00:14:53.310 --> 00:14:55.610\nWhat's the acceptable use of BYOD?\n\n270\n00:14:55.610 --> 00:15:00.150\nIf you're in an environment where you're\nHIPAA compliant, can you pull that data\n\n271\n00:15:00.150 --> 00:15:03.180\nfrom a server down to your phone and\nleave the network with it, right?\n\n272\n00:15:03.180 --> 00:15:04.649\nRight?\nSo that needs to be clearly\n\n273\n00:15:04.649 --> 00:15:07.260\nestablished in the onboarding process too.\n\n274\n00:15:07.260 --> 00:15:12.020\nHow we secure things like PII or\npersonal identifiable information or\n\n275\n00:15:12.020 --> 00:15:14.120\npersonal healthcare information, right?\n\n276\n00:15:14.120 --> 00:15:15.610\nAll part of the on boarding process.\n\n277\n00:15:15.610 --> 00:15:21.290\nSo we set clear expectations from\nthe moment that the employee clocks in for\n\n278\n00:15:21.290 --> 00:15:23.680\nthe very first time,\neven if they are salary.\n\n279\n00:15:24.910 --> 00:15:26.800\nThen we have things like\nthe offboarding process, right.\n\n280\n00:15:26.800 --> 00:15:33.272\nAnd the offboarding process could be\nthings like exit interviews, right.\n\n281\n00:15:33.272 --> 00:15:36.200\nBut offboarding process\naccount management,\n\n282\n00:15:36.200 --> 00:15:38.020\nwe have to think about account management,\nright?\n\n283\n00:15:38.020 --> 00:15:40.370\nThat's what basically this\nwhole entire episode is.\n\n284\n00:15:40.370 --> 00:15:41.370\nAnd what I mean by that,\n\n285\n00:15:42.720 --> 00:15:45.700\nthere might be an account management\npolicy that you have to follow, right?\n\n286\n00:15:45.700 --> 00:15:47.400\nBecause I want you to think about this.\n\n287\n00:15:47.400 --> 00:15:48.630\nDo you disable the account?\n\n288\n00:15:48.630 --> 00:15:49.890\nDo you delete the account?\n\n289\n00:15:49.890 --> 00:15:50.760\nRight?\n\n290\n00:15:50.760 --> 00:15:52.210\nNot necessarily.\n\n291\n00:15:52.210 --> 00:15:54.010\nThere's not a right or wrong answer.\n\n292\n00:15:54.010 --> 00:15:55.450\nBut remember,\n\n293\n00:15:55.450 --> 00:15:58.580\ndisabling the account a lot of times\nis better than deleting the account.\n\n294\n00:15:58.580 --> 00:16:00.931\nBecause deleting the account and\nthen recreating the account,\n\n295\n00:16:00.931 --> 00:16:01.811\nthat's not recovery.\n\n296\n00:16:01.811 --> 00:16:05.181\nAnd if you delete the account as\npart of the offboarding process,\n\n297\n00:16:05.181 --> 00:16:09.411\nthen you could potentially lose access to\na lot of the information that that person\n\n298\n00:16:09.411 --> 00:16:12.250\nthat was working within your company,\nhad access to.\n\n299\n00:16:14.633 --> 00:16:15.695\nDo we have to perform?\n\n300\n00:16:15.695 --> 00:16:20.122\nAgain, disabling the account as part\nof the offboarding process, and\n\n301\n00:16:20.122 --> 00:16:23.660\nthen we do data recovery and\nreassignment, right.\n\n302\n00:16:23.660 --> 00:16:24.770\nIt might be something like that.\n\n303\n00:16:24.770 --> 00:16:25.880\nDisable the account so\n\n304\n00:16:25.880 --> 00:16:28.300\nthe person no longer has access\nto get in to your network.\n\n305\n00:16:29.420 --> 00:16:33.480\nRecover any data that they\nmight have been privy to, and\n\n306\n00:16:33.480 --> 00:16:36.590\nthey only have access to,\nwith that account.\n\n307\n00:16:36.590 --> 00:16:40.040\nSo you do the data recovery,\nif you will, and then reassignment.\n\n308\n00:16:40.040 --> 00:16:42.620\nI assign it to Dan,\nDan's still working with the company.\n\n309\n00:16:42.620 --> 00:16:47.077\nI know that he can have access to that\ninformation and then once that's done\n\n310\n00:16:47.077 --> 00:16:50.915\nmaybe then I delete the account\nthat is inside of our directory.\n\n311\n00:16:50.915 --> 00:16:53.715\nWe also have to worry about things\nlike data eradication, right,\n\n312\n00:16:53.715 --> 00:16:56.050\nas part of the offboarding process.\n\n313\n00:16:56.050 --> 00:16:58.420\nThat's why we have containerization.\n\n314\n00:16:58.420 --> 00:17:01.410\nWhen we talk about containerization\nwe talk about the difference between\n\n315\n00:17:01.410 --> 00:17:04.450\ncontaining that information as\nthe personal information versus\n\n316\n00:17:04.450 --> 00:17:05.800\nwhat is the business information.\n\n317\n00:17:05.800 --> 00:17:10.930\nAnd making sure that the two\ndon't conflict with each other.\n\n318\n00:17:10.930 --> 00:17:12.490\nSo BYOD, right?\n\n319\n00:17:12.490 --> 00:17:14.150\nIf you're part of the offboarding process,\n\n320\n00:17:14.150 --> 00:17:16.950\nare you actually going\nto do a remote wipe?\n\n321\n00:17:16.950 --> 00:17:20.470\nRight, do you have the technologies in\nplace to do data classification that says,\n\n322\n00:17:20.470 --> 00:17:22.730\nhey, that's sensitive\nbusiness information.\n\n323\n00:17:22.730 --> 00:17:25.389\nAnd as part of the onboarding\nprocess since you were using BYOD,\n\n324\n00:17:25.389 --> 00:17:27.620\nwe need to eradicate the data\nthat's on that device.\n\n325\n00:17:27.620 --> 00:17:31.740\nThat is part of the intellectual property\nof the company that you're working for.\n\n326\n00:17:31.740 --> 00:17:34.498\nSo, things like that for\ninstance, as well.\n\n327\n00:17:34.498 --> 00:17:37.540\nThey also talk about, some of the other\ngeneral concepts that they talk\n\n328\n00:17:37.540 --> 00:17:41.170\nabout are things like permission auditing,\nand reviewing, right?\n\n329\n00:17:41.170 --> 00:17:45.340\nPermission auditing, reviewing, really\ncould be basic, it could be very complex.\n\n330\n00:17:45.340 --> 00:17:48.420\nYou actually have something inside of\nWindows that allow you to do this.\n\n331\n00:17:48.420 --> 00:17:53.020\nIn fact, if we pull up my screen here,\nand I'll just give you a real basic,\n\n332\n00:17:53.020 --> 00:17:57.900\nwhere you can do, like,\nbasic permission audit, right.\n\n333\n00:17:57.900 --> 00:18:00.670\nI can right click on any folder or\nfile, if you will.\n\n334\n00:18:00.670 --> 00:18:02.050\nIt's inside of a Window's environment.\n\n335\n00:18:02.050 --> 00:18:05.760\nI could choose the properties and\nI can go to the security tab, right.\n\n336\n00:18:05.760 --> 00:18:08.049\nNow, this is a little\nbit decentralized model.\n\n337\n00:18:08.049 --> 00:18:11.300\nWe do have software out there that could\ndo this across your entire organization.\n\n338\n00:18:11.300 --> 00:18:15.927\nBut it kinda gives you an opportunity\nto see what level of access\n\n339\n00:18:15.927 --> 00:18:18.870\nan entity has to a different resource.\n\n340\n00:18:18.870 --> 00:18:21.430\nBut you can go even farther than that.\n\n341\n00:18:21.430 --> 00:18:24.620\nIf we click the Advanced button,\nthen what we can do, and\n\n342\n00:18:24.620 --> 00:18:28.280\nI really like this software, I've had to\nuse it before, is this Effective Access.\n\n343\n00:18:28.280 --> 00:18:31.589\nI want to know what an entity has, right.\n\n344\n00:18:31.589 --> 00:18:33.880\nPermission-wise I need to\ndo a review on that, and\n\n345\n00:18:33.880 --> 00:18:36.170\nfind out what they have access to.\n\n346\n00:18:36.170 --> 00:18:40.150\nWell, I can do effective access, right,\nand I can select a user here and\n\n347\n00:18:40.150 --> 00:18:42.380\nlet's say wbryan, right?\n\n348\n00:18:42.380 --> 00:18:47.780\nWe'll do a check names here,\noops, and there I am.\n\n349\n00:18:47.780 --> 00:18:53.720\nWe put this as the security principle and\nwe view the effective access, right?\n\n350\n00:18:53.720 --> 00:18:55.370\nNow I'm the creator owner of this.\n\n351\n00:18:55.370 --> 00:18:57.410\nThis is discretionary access control, so\n\n352\n00:18:57.410 --> 00:18:59.300\nI would hope that I have\nfull control over it.\n\n353\n00:18:59.300 --> 00:19:01.802\nBut, that might not be\nsomething that you want right?\n\n354\n00:19:01.802 --> 00:19:03.360\nAgain, principle of least privilege.\n\n355\n00:19:03.360 --> 00:19:06.630\nMaybe you want somebody to have the\nability to do things like read, to write,\n\n356\n00:19:06.630 --> 00:19:07.670\nread permissions.\n\n357\n00:19:07.670 --> 00:19:09.787\nBut we set read permissions\nkind of generically, right.\n\n358\n00:19:09.787 --> 00:19:12.164\nWe set read, but we didn't realize,\n\n359\n00:19:12.164 --> 00:19:15.380\nthat read was made up of\na sub-set of permissions.\n\n360\n00:19:15.380 --> 00:19:18.250\nList folder, data, read attributes,\nread extended attributes.\n\n361\n00:19:18.250 --> 00:19:19.770\nSo there's a lot more to it than that.\n\n362\n00:19:20.900 --> 00:19:23.710\nSo maybe the generic permissions,\nthe standard permissions, aren't enough.\n\n363\n00:19:23.710 --> 00:19:24.600\nAnd you need to tailor,\n\n364\n00:19:24.600 --> 00:19:28.950\nyou need to reduce the level of\naccess that somebody has, even more.\n\n365\n00:19:28.950 --> 00:19:31.990\nWell if you're not doing permission\nreviews like we're talking about, and\n\n366\n00:19:31.990 --> 00:19:33.800\nauditing, you're never\ngonna be aware of that.\n\n367\n00:19:33.800 --> 00:19:38.381\nSo that's where that comes into play for\nus, as well.\n\n368\n00:19:38.381 --> 00:19:40.830\nNow there are other things again,\nthat you can do.\n\n369\n00:19:40.830 --> 00:19:43.910\nUsage auditing and reviews, right?\n\n370\n00:19:43.910 --> 00:19:46.140\nAnd this is kinda something\nthat I really like.\n\n371\n00:19:46.140 --> 00:19:47.400\nSo for instance, let's go ahead and\n\n372\n00:19:47.400 --> 00:19:50.280\nswitch over to the domain\ncontroller this time, right.\n\n373\n00:19:50.280 --> 00:19:54.070\nAnd maybe I wanna do something like, for\ninstance, I wanna go a little bit farther.\n\n374\n00:19:54.070 --> 00:19:58.438\nWell, inside of Windows or\nan Active Directory domain,\n\n375\n00:19:58.438 --> 00:20:01.081\nyou could do something like this.\n\n376\n00:20:01.081 --> 00:20:05.518\nWhere you pull up your group policy\nmanagement and you say you know what,\n\n377\n00:20:05.518 --> 00:20:10.770\nI want to audit access to, let's say,\nthe files within our domain, right.\n\n378\n00:20:10.770 --> 00:20:15.790\nSo we could do something like\ncreating a File Object group policy.\n\n379\n00:20:15.790 --> 00:20:19.820\nI've already created it here but\nlet me go ahead and edit this out.\n\n380\n00:20:19.820 --> 00:20:22.990\nAnd to show you that we could come\ndown in here, we could get very,\n\n381\n00:20:22.990 --> 00:20:25.270\nvery granular on what\nwe're actually auditing.\n\n382\n00:20:25.270 --> 00:20:27.990\nAnd usage auditing could\nbe the consumption\n\n383\n00:20:27.990 --> 00:20:30.088\nof the files within your organization.\n\n384\n00:20:30.088 --> 00:20:33.118\nSo we can go down to Policies here,\n\n385\n00:20:33.118 --> 00:20:38.140\nwe can expand out things like\nWindows Settings, right.\n\n386\n00:20:38.140 --> 00:20:40.044\nWe have some security settings in here,\n\n387\n00:20:40.044 --> 00:20:42.289\nwe have account policies\nthat we can do as well.\n\n388\n00:20:42.289 --> 00:20:46.144\nAnd I believe they got audit policies\njust on the local policies as well, but\n\n389\n00:20:46.144 --> 00:20:48.204\nwe can go a little bit farther than that.\n\n390\n00:20:48.204 --> 00:20:51.164\nAnd if we want, we can come,\nI believe it's in here.\n\n391\n00:20:51.164 --> 00:20:52.498\nThere we go, down here at the bottom.\n\n392\n00:20:52.498 --> 00:20:55.677\nNotice it says Advanced Audit\nPolicy Configuration, right.\n\n393\n00:20:55.677 --> 00:20:59.714\nSo we can implement policies\ninside of our domains that\n\n394\n00:20:59.714 --> 00:21:02.883\nactually dictate what we can or cannot do.\n\n395\n00:21:02.883 --> 00:21:06.330\nAnd let me go ahead and expand this\nout and we'll look at it over here.\n\n396\n00:21:06.330 --> 00:21:10.360\nSo account logons, we can do things like\naccount management, detailed tracking.\n\n397\n00:21:10.360 --> 00:21:12.668\nAnd this is the one I like,\nright, object access.\n\n398\n00:21:12.668 --> 00:21:18.536\nSo, anytime somebody accesses a file here,\nright.\n\n399\n00:21:18.536 --> 00:21:24.210\nLet's see here, there we go, let me go\nahead and pull up that setting there.\n\n400\n00:21:25.710 --> 00:21:28.680\nAnd notice we're doing Audit File System,\nright?\n\n401\n00:21:28.680 --> 00:21:32.724\nAnd I can do successes or failures,\nand then I could turn around, and\n\n402\n00:21:32.724 --> 00:21:36.019\nonce this is set in place I\ncould link this to the domain.\n\n403\n00:21:36.019 --> 00:21:40.776\nAnd then what this would do is,\nevery user that accesses a computer inside\n\n404\n00:21:40.776 --> 00:21:44.920\nof the domain,\nwe can track what they're doing, right.\n\n405\n00:21:44.920 --> 00:21:49.830\nWe can come in for as simple as something\nlike event viewer, in this case.\n\n406\n00:21:49.830 --> 00:21:55.490\nI can pull up event viewer and\nI can expand out the windows logs.\n\n407\n00:21:55.490 --> 00:22:00.100\nWe can go to security there, right?\n\n408\n00:22:00.100 --> 00:22:03.490\nAnd I can see a whole\nbunch of information.\n\n409\n00:22:03.490 --> 00:22:07.450\nNotice I have a successful audit here,\nright?\n\n410\n00:22:07.450 --> 00:22:09.096\nNotice what it tells me.\n\n411\n00:22:09.096 --> 00:22:11.180\nA handle to an object was requested.\n\n412\n00:22:11.180 --> 00:22:13.740\nI can see the exact\nperson that requested it.\n\n413\n00:22:13.740 --> 00:22:16.780\nI can even see the time\nthat this was logged.\n\n414\n00:22:16.780 --> 00:22:20.940\nI can see that it was a failed attempt,\nright?\n\n415\n00:22:20.940 --> 00:22:24.540\nI can also see, that's a success attempt,\nlet me try the failed attempt.\n\n416\n00:22:24.540 --> 00:22:25.840\nThere we go.\n\n417\n00:22:25.840 --> 00:22:27.873\nSo I can see the difference\nbetween the failures,\n\n418\n00:22:27.873 --> 00:22:32.170\nright, I can see where it was located,\nright?\n\n419\n00:22:32.170 --> 00:22:32.810\nAs well so\n\n420\n00:22:32.810 --> 00:22:38.470\nyou can do things like that where your\nauditing the access that an end user has.\n\n421\n00:22:38.470 --> 00:22:42.990\nBut I will tell you the one thing to keep\nin mind is, when you're doing auditing,\n\n422\n00:22:42.990 --> 00:22:45.150\nsometimes people say,\nwell what do you want to audit?\n\n423\n00:22:45.150 --> 00:22:46.470\nI want to audit everything.\n\n424\n00:22:47.576 --> 00:22:50.130\nWell If you audit everything,\n\n425\n00:22:50.130 --> 00:22:53.525\nit could be very difficult to find\nthe one thing that you want, right?\n\n426\n00:22:53.525 --> 00:22:55.860\n&gt;&gt; Kinda like looking for\na needle in a stack of needles.\n\n427\n00:22:55.860 --> 00:22:56.620\n&gt;&gt; Yeah definitely.\n\n428\n00:22:56.620 --> 00:22:58.661\nLike data, let's take an example down.\n\n429\n00:22:58.661 --> 00:23:00.611\nI know you're a Linux guy, right?\n\n430\n00:23:00.611 --> 00:23:01.532\nSyslog.\n\n431\n00:23:01.532 --> 00:23:03.720\nHow convoluted can syslog get?\n\n432\n00:23:03.720 --> 00:23:04.590\n&gt;&gt; Yeah, really convoluted.\n\n433\n00:23:04.590 --> 00:23:07.258\nEspecially if you have multiple devices\n\n434\n00:23:07.258 --> 00:23:10.780\nsending their log files\nto your syslog server.\n\n435\n00:23:10.780 --> 00:23:12.428\n&gt;&gt; Yeah,\nI didn't even think of syslog server,\n\n436\n00:23:12.428 --> 00:23:14.640\nthen you've got convolution\non top of convolution, right.\n\n437\n00:23:14.640 --> 00:23:19.708\nSo it is important and I'm not\ntrying to knock syslog by all means,\n\n438\n00:23:19.708 --> 00:23:22.000\nit's used for a reason.\n\n439\n00:23:22.000 --> 00:23:24.132\nThank goodness in Linux, we have Grip,\n\n440\n00:23:24.132 --> 00:23:27.216\nI wish we had a nice powerful\nutility in Windows like that.\n\n441\n00:23:27.216 --> 00:23:29.534\nBut the point is,\nwhen you audit everything,\n\n442\n00:23:29.534 --> 00:23:33.110\nit might be hard to find the one\nspecific thing that you are looking for.\n\n443\n00:23:33.110 --> 00:23:36.170\nAnd the other thing that auditing,\nyou have to kind of worry about too,\n\n444\n00:23:36.170 --> 00:23:40.100\nis the fact that auditing can\nbe a performance hit too, right.\n\n445\n00:23:40.100 --> 00:23:43.010\nIf your log files grow,\nI know they're just text files, but\n\n446\n00:23:43.010 --> 00:23:46.340\nthe more auditing you do,\nthe more storage that's gonna accrue.\n\n447\n00:23:46.340 --> 00:23:50.520\nAnd the more storage capacity that\nyou accrue can lead to performance\n\n448\n00:23:50.520 --> 00:23:51.910\ndegrading within the system.\n\n449\n00:23:51.910 --> 00:23:53.780\nSo just make sure.\n\n450\n00:23:53.780 --> 00:23:55.151\nUse your auditing, right?\n\n451\n00:23:55.151 --> 00:23:57.590\nEnable auditing if you need it.\n\n452\n00:23:57.590 --> 00:23:59.500\nAnd if you need it,\nmake sure you check it.\n\n453\n00:23:59.500 --> 00:24:02.450\nBecause there's no reason to turn it on,\nif you're not gonna turn around and\n\n454\n00:24:02.450 --> 00:24:03.510\ncheck those log files.\n\n455\n00:24:03.510 --> 00:24:04.270\nThat's right.\n\n456\n00:24:04.270 --> 00:24:05.970\nThat's definitely something\nyou wanna get into.\n\n457\n00:24:05.970 --> 00:24:09.590\nAuditing is a fantastic way to make\nsure that things are on the up and up,\n\n458\n00:24:09.590 --> 00:24:10.110\nshall I say.\n\n459\n00:24:10.110 --> 00:24:13.090\nLet's just keep everything above board,\nladies and gentlemen.\n\n460\n00:24:13.090 --> 00:24:15.000\nNow that being said,\nI'm looking at our clock, Wes.\n\n461\n00:24:15.000 --> 00:24:18.990\nWe're very, really short on time and I\nknow you've got quite a few more controls\n\n462\n00:24:18.990 --> 00:24:20.970\nto go through,\nplus a couple of other topics as well.\n\n463\n00:24:20.970 --> 00:24:23.800\nHow would you feel about\nthrowing into a part two?\n\n464\n00:24:23.800 --> 00:24:26.710\n&gt;&gt; Hey, that's sounds really good, I think\nthat's what we should do cuz it'll make it\n\n465\n00:24:26.710 --> 00:24:29.011\na lot easier to get through\nthe rest of this list.\n\n466\n00:24:29.011 --> 00:24:29.967\n[LAUGH]\n&gt;&gt; [LAUGH] Yeah,\n\n467\n00:24:29.967 --> 00:24:32.390\nI can see Wes trying to scramble\nthrough three minutes of.\n\n468\n00:24:32.390 --> 00:24:34.470\nA lot of stuff,\nas I look at our notes here.\n\n469\n00:24:34.470 --> 00:24:36.930\nSo, that's definitely what we'll\ndo when we move into part two.\n\n470\n00:24:36.930 --> 00:24:40.410\nDefinitely join back for that continue\nto look at these control mechanisms\n\n471\n00:24:40.410 --> 00:24:42.500\nplus moving into policy enforcement.\n\n472\n00:24:42.500 --> 00:24:43.890\nThat will be a lot of fun as well.\n\n473\n00:24:43.890 --> 00:24:46.310\nBut that being said,\nit's time for us to sign off.\n\n474\n00:24:46.310 --> 00:24:47.550\nThanks so much for joining us today.\n\n475\n00:24:47.550 --> 00:24:49.070\nI've been your host Daniel Lowrie.\n\n476\n00:24:49.070 --> 00:24:49.880\n&gt;&gt; And I'm Wes Bryan.\n\n477\n00:24:49.880 --> 00:24:52.267\n&gt;&gt; And we'll see you next time.\n\n478\n00:24:52.267 --> 00:24:58.251\n[MUSIC]\n\n479\n00:24:58.251 --> 00:25:01.319\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216165556"
        },
        {
          "description": "In this episode, Daniel and Wes continue discussing common account management practices. They pick back up looking at general security practices like recertification, time restrictions, and group-based access control. They also go over account policy enforcement techniques.",
          "length": "1735",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-4-2-account_management_practices_pt2-050317.00_39_23_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-4-2-account_management_practices_pt2-050317.00_39_23_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-4-4-2-account_management_practices_pt2-050317.00_39_23_27.Still001-sm.jpg",
          "title": "Account Management Practices Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.005 --> 00:00:02.513\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.513 --> 00:00:06.088\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.088 --> 00:00:07.905\n[MUSIC]\n\n4\n00:00:07.905 --> 00:00:11.818\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.818 --> 00:00:13.826\n&gt;&gt; All right, good evening everyone,\n\n6\n00:00:13.826 --> 00:00:16.363\nwelcome to another great\nepisode of ITProTV.\n\n7\n00:00:16.363 --> 00:00:17.848\nI'm your host Daniel Lowrie.\n\n8\n00:00:17.848 --> 00:00:22.110\nAnd in today's, we are coming back\nwith more of our security+ series.\n\n9\n00:00:22.110 --> 00:00:25.600\nAnd joining us in the studio, yet\nagain, our good friend Mr Wes Bryan.\n\n10\n00:00:25.600 --> 00:00:27.140\nWes, welcome back, man, how's it going?\n\n11\n00:00:27.140 --> 00:00:28.120\n&gt;&gt; Man, it's going great, Dan.\n\n12\n00:00:28.120 --> 00:00:28.970\nThanks for having me back.\n\n13\n00:00:28.970 --> 00:00:31.430\nThat's right,\nwe're coming back with a part two on\n\n14\n00:00:31.430 --> 00:00:33.690\ncommon account management practices.\n\n15\n00:00:33.690 --> 00:00:36.395\nAnd we've talked really\nabout a bunch of things.\n\n16\n00:00:36.395 --> 00:00:39.980\nBut we did have some additional things\nthat we couldn't fit in part two here.\n\n17\n00:00:39.980 --> 00:00:41.960\nSo, well we are back.\n\n18\n00:00:41.960 --> 00:00:45.415\nOne of the things that we left off,\nwe were talking about in the last episode,\n\n19\n00:00:45.415 --> 00:00:48.568\nwe were talking about things like\npermission, auditing and review.\n\n20\n00:00:48.568 --> 00:00:51.117\nWe talked about the principle\nlease privilege,\n\n21\n00:00:51.117 --> 00:00:55.285\nmaking sure that the end users that\nyou're supporting you're giving them just\n\n22\n00:00:55.285 --> 00:00:57.413\nwhat they need to do their jobs, right?\n\n23\n00:00:57.413 --> 00:00:59.619\nAvailability but\nnot giving them too much so\n\n24\n00:00:59.619 --> 00:01:02.190\nthat they can get theirselves in trouble,\nright?\n\n25\n00:01:02.190 --> 00:01:05.710\nSo principle, at least privileges,\nreducing the privileges down to\n\n26\n00:01:05.710 --> 00:01:08.930\nan acceptable level that allows\nyour users to get their jobs done,\n\n27\n00:01:08.930 --> 00:01:11.820\nbut doesn't make them administrators.\n\n28\n00:01:11.820 --> 00:01:15.049\nWe also looked at not only\na permission auditing and\n\n29\n00:01:15.049 --> 00:01:19.191\nreview, we talked about usage,\nauditing, and review as well.\n\n30\n00:01:19.191 --> 00:01:23.333\nKeep in mind that if you implement any\ntype of auditing, I think one of the last\n\n31\n00:01:23.333 --> 00:01:27.158\nthings that we were stressing in\nthe first part of this episode here is,\n\n32\n00:01:27.158 --> 00:01:28.497\nthe fact that auditing,\n\n33\n00:01:28.497 --> 00:01:32.382\nif you turn it on make sure that you use\nit cuz its one of those things that,\n\n34\n00:01:32.382 --> 00:01:36.650\nwell if you need it and you don't turn\nit on, well you don't have access to it.\n\n35\n00:01:36.650 --> 00:01:37.400\nBut if you turn it on and\n\n36\n00:01:37.400 --> 00:01:40.930\ndon't use it, it can become a performance\nhindrance inside of your system.\n\n37\n00:01:40.930 --> 00:01:42.555\nSo, do keep that in mind.\n\n38\n00:01:42.555 --> 00:01:45.140\nNow some of the other things\nthat they're calling out,\n\n39\n00:01:45.140 --> 00:01:47.260\nthey call out things like recertification.\n\n40\n00:01:47.260 --> 00:01:51.882\nAnd anytime we're talking about\ncertificates, right, certificate\n\n41\n00:01:51.882 --> 00:01:56.592\nrenewal if you will, this is all\ncontingent on having your PKI in place.\n\n42\n00:01:56.592 --> 00:02:01.170\nSo it's just as simple as,\nit could be online web enrollment.\n\n43\n00:02:01.170 --> 00:02:02.474\nIt could be a process that they have to,\n\n44\n00:02:02.474 --> 00:02:04.265\nmaybe there's paperwork\nthat they have to fill out.\n\n45\n00:02:04.265 --> 00:02:07.722\nIt could be something as simple as\ncalling the boss and sayings, hey,\n\n46\n00:02:07.722 --> 00:02:09.311\ncertificate expired, right?\n\n47\n00:02:09.311 --> 00:02:10.640\n&gt;&gt; You had me scared for a minute there.\n\n48\n00:02:10.640 --> 00:02:13.620\nI thought it was like, all of our users\nhave to be security+ certified, and\n\n49\n00:02:13.620 --> 00:02:14.772\nthey need to recertify every year.\n\n50\n00:02:14.772 --> 00:02:16.400\n[LAUGH]\n&gt;&gt; Well, we do stress training, right?\n\n51\n00:02:16.400 --> 00:02:19.825\n&gt;&gt; That would be some awesome training for\nstandard users.\n\n52\n00:02:19.825 --> 00:02:21.177\n&gt;&gt; [LAUGH]\n&gt;&gt; Everyone that works here for security+.\n\n53\n00:02:21.177 --> 00:02:24.417\n[LAUGH]\n&gt;&gt; [LAUGH] That's right, that's right,\n\n54\n00:02:24.417 --> 00:02:27.062\nwe've got the best security\nposture in any company there.\n\n55\n00:02:27.062 --> 00:02:28.030\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH] That\n\n56\n00:02:28.030 --> 00:02:32.380\nwould probably be over burdening to users\nand well, you'd probably lose half of your\n\n57\n00:02:32.380 --> 00:02:35.982\nstaff [LAUGH] but for the geeks that would\nstay around, you're in the right place.\n\n58\n00:02:35.982 --> 00:02:36.808\n&gt;&gt; You are.\n\n59\n00:02:36.808 --> 00:02:40.857\n&gt;&gt; Some of the other things they call out\nare things like time of day restrictions.\n\n60\n00:02:40.857 --> 00:02:45.580\nAnd these things are things that we can\nimplement inside of things like domain,\n\n61\n00:02:45.580 --> 00:02:47.070\nenvironments, right?\n\n62\n00:02:47.070 --> 00:02:51.690\nBecause you might want to maybe\nreduce a subset of your users down to\n\n63\n00:02:51.690 --> 00:02:54.560\na specific hours that they can\nwork inside of your company.\n\n64\n00:02:54.560 --> 00:02:56.760\nIn fact, let me give you an idea\nwhere you could do that.\n\n65\n00:02:56.760 --> 00:02:59.190\nYou could do that inside of\nan Active Directory environment.\n\n66\n00:02:59.190 --> 00:03:02.821\nI've got a Windows Server\n2016 spawned up here.\n\n67\n00:03:02.821 --> 00:03:04.830\nAnd its got Active Directory installed.\n\n68\n00:03:04.830 --> 00:03:08.860\nSo if we launch out our\nActive Directory users and computers.\n\n69\n00:03:08.860 --> 00:03:12.040\nAnd I'll pick on myself, I've been\npicking on everybody else here, but\n\n70\n00:03:12.040 --> 00:03:13.750\nI'll go ahead and pick on myself.\n\n71\n00:03:13.750 --> 00:03:16.720\nBelieve I have a username,\na user account here.\n\n72\n00:03:16.720 --> 00:03:21.340\nAnd if I just right click on that user\naccount, and I choose Properties.\n\n73\n00:03:21.340 --> 00:03:25.410\nRight, we can do things like go\ninto the Account Attributes.\n\n74\n00:03:25.410 --> 00:03:29.410\nAnd you'll see, under my username that\nthere's these options right here, right,\n\n75\n00:03:29.410 --> 00:03:30.820\nLogon Hours, right?\n\n76\n00:03:30.820 --> 00:03:35.020\nI can click this and if I want, you can\nsee that you can do hours that you're\n\n77\n00:03:35.020 --> 00:03:37.430\npermitted versus hours that you're denied,\nright?\n\n78\n00:03:37.430 --> 00:03:42.142\nSo maybe we wanna set this, maybe we\nwanna deny everything we'll start,\n\n79\n00:03:42.142 --> 00:03:44.199\nwell we'll try to start there.\n\n80\n00:03:44.199 --> 00:03:49.672\nI'll tell you what, How do I wanna do\nthis, trying to make it easy here.\n\n81\n00:03:49.672 --> 00:03:54.020\nLet's see here, we'll go ahead and\nwe'll say that, yep,\n\n82\n00:03:54.020 --> 00:03:59.050\nthat's denied, maybe from midnight\nto maybe six in the morning.\n\n83\n00:03:59.050 --> 00:04:01.140\nMaybe he's gonna be allowed,\nand maybe on Monday too.\n\n84\n00:04:01.140 --> 00:04:04.350\nSo let me go ahead and\ndo this inside of our business hours.\n\n85\n00:04:04.350 --> 00:04:09.300\nMaybe we wanna allow people to work with\ninside of your corporate environment for\n\n86\n00:04:09.300 --> 00:04:13.691\nmaybe about 6 o'clock in the morning\nto 6 o'clock in the afternoon.\n\n87\n00:04:13.691 --> 00:04:15.917\nAnd we can do something as simple as that,\n\n88\n00:04:15.917 --> 00:04:20.052\njust making sure that we're paying\nattention to which one we're using, and\n\n89\n00:04:20.052 --> 00:04:24.120\nwe can see that logins will be\npermitted during this time, all right?\n\n90\n00:04:24.120 --> 00:04:27.185\nAnd again, that could be something\nthat you are implementing, it might be\n\n91\n00:04:27.185 --> 00:04:30.459\nsomething that you're implementing is\nagain those time of day restrictions.\n\n92\n00:04:30.459 --> 00:04:34.706\nAnd that's one easy way that you\ncan do that, just by adjusting\n\n93\n00:04:34.706 --> 00:04:39.290\nthe attributes on the user themselves\ninside of Active Directory.\n\n94\n00:04:39.290 --> 00:04:43.551\nAnd you can see that it lets us know\nthat Sunday from 12 AM to 1 AM, and\n\n95\n00:04:43.551 --> 00:04:45.512\nyou can see the different days.\n\n96\n00:04:45.512 --> 00:04:47.456\nAnd we can get a little bit more or\n\n97\n00:04:47.456 --> 00:04:52.430\nless restrictive depending on what it\nis that we are trying to accomplish.\n\n98\n00:04:52.430 --> 00:04:55.830\nAll right, so we do have things like\ntime of day restrictions and in fact,\n\n99\n00:04:55.830 --> 00:04:59.010\nI'm gonna go ahead and, I tell you what,\nI'm gonna clear all of this here.\n\n100\n00:04:59.010 --> 00:05:02.530\nI don't wanna get myself in trouble\nhere with the rest of this lab, so\n\n101\n00:05:02.530 --> 00:05:05.220\nwe'll go ahead, and\nI'm gonna give myself access again.\n\n102\n00:05:06.460 --> 00:05:07.663\nAll right, there we go.\n\n103\n00:05:07.663 --> 00:05:08.647\nThat'd be great.\n\n104\n00:05:08.647 --> 00:05:12.025\nWe're gonna show blocking yourself\nout of your own domain, right?\n\n105\n00:05:12.025 --> 00:05:12.653\n[LAUGH]\n&gt;&gt; Yeah,\n\n106\n00:05:12.653 --> 00:05:13.536\nhaving to call your own help desk.\n\n107\n00:05:13.536 --> 00:05:15.110\n[LAUGH]\n&gt;&gt; [LAUGH] Yes, definitely.\n\n108\n00:05:15.110 --> 00:05:16.800\nDave can you help me out\nwith my domain here?\n\n109\n00:05:16.800 --> 00:05:18.297\nIt seems I hosed it up.\n\n110\n00:05:18.297 --> 00:05:20.835\n&gt;&gt; [LAUGH]\n&gt;&gt; A time of day restriction there's\n\n111\n00:05:20.835 --> 00:05:22.092\nsomething you can implement.\n\n112\n00:05:22.092 --> 00:05:25.656\nYou see sometimes too, and things like, it\njust basic as printers, right, it doesn't\n\n113\n00:05:25.656 --> 00:05:28.810\nhave to actually be the log on hours,\nthis is one example where you can do that.\n\n114\n00:05:28.810 --> 00:05:32.270\nBut you can also set things like time of\nday restriction for your printers, right?\n\n115\n00:05:32.270 --> 00:05:36.244\nIf you know, you've gotta a subset of\nyour users that print a large documents,\n\n116\n00:05:36.244 --> 00:05:38.082\nright, a lot of printing maybe say,\n\n117\n00:05:38.082 --> 00:05:41.461\nyou gotta come in a little bit earlier\nif you can do a lot of printing,\n\n118\n00:05:41.461 --> 00:05:45.510\nright, because we do not want to\nprint that 800 page document, right?\n\n119\n00:05:45.510 --> 00:05:49.070\nAnd then have everybody else have to wait\nfor the rest of the day while that's\n\n120\n00:05:49.070 --> 00:05:51.740\nchurning through your document\nthat you are printing.\n\n121\n00:05:51.740 --> 00:05:53.150\nSo you do things like that as well.\n\n122\n00:05:54.180 --> 00:05:56.870\nNow they also call out\nan additional concept,\n\n123\n00:05:56.870 --> 00:05:58.810\nstandard naming conventions, all right?\n\n124\n00:05:58.810 --> 00:06:01.640\nSo what is a standard\nnaming convention for us?\n\n125\n00:06:01.640 --> 00:06:06.183\nWell, standard naming convention just\nmeans that, if you are going to,\n\n126\n00:06:06.183 --> 00:06:10.150\nlike for instance, if you are going to\nstart designing your Active Directory,\n\n127\n00:06:10.150 --> 00:06:14.160\nyou might want to find some kind of\nnaming convention that works for you and\n\n128\n00:06:14.160 --> 00:06:15.330\nyour company.\n\n129\n00:06:15.330 --> 00:06:20.210\nRight, it could be something as simple\nas like the last name.first name,\n\n130\n00:06:20.210 --> 00:06:22.140\nfirst name.last name.\n\n131\n00:06:22.140 --> 00:06:27.006\nRight, I know that, for instance,\nhere inside of our company, it's typically\n\n132\n00:06:27.006 --> 00:06:31.890\nfirst name @ and then what the domain name\nis, and we use that pretty consistent.\n\n133\n00:06:31.890 --> 00:06:34.073\nThat's our naming convention\nthat we use in here, and\n\n134\n00:06:34.073 --> 00:06:35.835\nwe use to log into a lot\nof different things.\n\n135\n00:06:35.835 --> 00:06:40.718\nI've worked companies where it's last name\nand then the first initial, right, or\n\n136\n00:06:40.718 --> 00:06:43.140\nactually it's first initial last name.\n\n137\n00:06:43.140 --> 00:06:47.076\nThank you, I always have to remember it,\nI remember it as flast,\n\n138\n00:06:47.076 --> 00:06:48.588\nfirst and last, right?\n\n139\n00:06:48.588 --> 00:06:52.701\nSo it'd be like WBrian, right,\nthat would be my user name.\n\n140\n00:06:52.701 --> 00:06:54.555\nWhen they say a standard\nnaming convention,\n\n141\n00:06:54.555 --> 00:06:58.180\nit doesn't necessarily mean that there's\nsome kind of corporate standard out there.\n\n142\n00:06:58.180 --> 00:06:59.980\nIt just means you want consistency.\n\n143\n00:06:59.980 --> 00:07:03.170\nWe want to not mix and\nmatch different names.\n\n144\n00:07:03.170 --> 00:07:06.095\nBecause then your naming conventions\nbecome very hard to keep track of.\n\n145\n00:07:06.095 --> 00:07:11.845\nSo, the main thing is, if you have\na naming convention, just stick with it.\n\n146\n00:07:11.845 --> 00:07:15.480\nI've seen in the past, a company that I\nworked for, like for instance, when they\n\n147\n00:07:15.480 --> 00:07:19.294\nwere naming there computers, right, and\nthe teaching institute that I worked for.\n\n148\n00:07:19.294 --> 00:07:21.895\nWhat they would have is,\nthey would have multiple domains,\n\n149\n00:07:21.895 --> 00:07:24.150\nit was a multiple domain forest.\n\n150\n00:07:24.150 --> 00:07:27.540\nAnd what they would do is,\nthey would put whatever the domain\n\n151\n00:07:27.540 --> 00:07:30.740\nwas that the computer was located in,\nthat'd be the first three-letter code.\n\n152\n00:07:30.740 --> 00:07:33.340\nLike, well we're in Gainesville,\nright, so it'd be gnv-.\n\n153\n00:07:33.340 --> 00:07:34.656\nStart right there.\n\n154\n00:07:34.656 --> 00:07:37.967\nI could look right at that computer and\nI could tell what domain it's part of\n\n155\n00:07:37.967 --> 00:07:41.136\njust by the three-letter code that's\nat the first part of it, right?\n\n156\n00:07:41.136 --> 00:07:46.050\nThen they would go as far as\nwhat classroom it was in, right?\n\n157\n00:07:46.050 --> 00:07:48.760\nAnd we have ten classrooms or\nnine classrooms, right?\n\n158\n00:07:48.760 --> 00:07:53.510\nSo it would be G and\nV dash CL for classroom.\n\n159\n00:07:53.510 --> 00:07:55.320\nMaybe one or O1, right?\n\n160\n00:07:55.320 --> 00:07:58.773\nSo now, not only in using some kind\nof naming convention like that,\n\n161\n00:07:58.773 --> 00:08:02.488\nI can look right at into the computer,\nI could tell what domain it's in.\n\n162\n00:08:02.488 --> 00:08:03.997\nAnd what classroom it is.\n\n163\n00:08:03.997 --> 00:08:08.773\nAnd we, typically,\nhad about 16, 17 computers per\n\n164\n00:08:08.773 --> 00:08:13.760\nclassroom too, so\nit would be domain-classname-01.\n\n165\n00:08:13.760 --> 00:08:17.601\nSo I would know, it's a domain\ncomputer and the gains for domain,\n\n166\n00:08:17.601 --> 00:08:21.870\nit's in classroom let's say one and\nit's the first computer in the row.\n\n167\n00:08:21.870 --> 00:08:26.120\nSo you kinda get an idea of\nwhere that computer is, right?\n\n168\n00:08:26.120 --> 00:08:29.320\nOther standard naming conventions that\nyou have if you have servers, right?\n\n169\n00:08:29.320 --> 00:08:32.790\nYou don't wanna name your\ncomputer Optimus Prime, right?\n\n170\n00:08:32.790 --> 00:08:34.230\nIt's a great name, why not?\n\n171\n00:08:34.230 --> 00:08:35.530\nBut-\n&gt;&gt; Super awesome.\n\n172\n00:08:35.530 --> 00:08:37.500\n&gt;&gt; Right, you might say well,\nwhat is that?\n\n173\n00:08:37.500 --> 00:08:40.420\nWell, okay I say Dan,\nhere's the name of all my computers.\n\n174\n00:08:40.420 --> 00:08:44.602\nI've got Optimus Prime,\n[CROSSTALK] Bumblebee, Lars Ulrich,\n\n175\n00:08:44.602 --> 00:08:47.632\nright we'll throw some\nband members in here.\n\n176\n00:08:47.632 --> 00:08:50.162\nBut the problem is when Dan\ncomes in he looks at those and\n\n177\n00:08:50.162 --> 00:08:51.650\nsay well those are great names.\n\n178\n00:08:51.650 --> 00:08:52.900\nI recognize all the names, but\n\n179\n00:08:52.900 --> 00:08:57.100\nI can't tell you a single bit of what any\nof those computers do on your network.\n\n180\n00:08:57.100 --> 00:09:00.820\nHowever, if I name it something\nlike DCO1 right away Dan says,\n\n181\n00:09:00.820 --> 00:09:02.170\nthat's the domain controller, right?\n\n182\n00:09:02.170 --> 00:09:05.500\nIf I say ftpsvr, okay,\nthat's a file server, right?\n\n183\n00:09:05.500 --> 00:09:06.620\nIt's running a file server.\n\n184\n00:09:06.620 --> 00:09:10.483\nYou see that not only in following\na standard naming convention.\n\n185\n00:09:10.483 --> 00:09:14.528\nYou want your consistency to be a little\nbit user friendly too because you can be\n\n186\n00:09:14.528 --> 00:09:17.173\nconsistently off and\nI know that from experience.\n\n187\n00:09:17.173 --> 00:09:19.040\n&gt;&gt; And it is funny it is like\nyou might be saying well,\n\n188\n00:09:19.040 --> 00:09:20.625\nit is security through obscurity right.\n\n189\n00:09:20.625 --> 00:09:24.081\nWe're naming these things nobody knows\nwhat the heck they are, so someone is\n\n190\n00:09:24.081 --> 00:09:27.714\nscanning my network and they actually\nfind a naming convention for our servers.\n\n191\n00:09:27.714 --> 00:09:30.796\nThey won't know exactly what they do, a,\nyeah they probably will because if they're\n\n192\n00:09:30.796 --> 00:09:33.130\nscanning it they're gonna see\nwhat services they're running.\n\n193\n00:09:33.130 --> 00:09:39.215\nAnd b, well yeah you got this strange\nnaming convention going on there but\n\n194\n00:09:39.215 --> 00:09:42.860\nit makes it more difficult for you, right?\n\n195\n00:09:42.860 --> 00:09:45.520\nAnd you're not really\nstopping anybody right?\n\n196\n00:09:45.520 --> 00:09:47.729\nThat's the purpose.\n\n197\n00:09:47.729 --> 00:09:50.345\n&gt;&gt; Definitely,\nI think of things like DNS names, right.\n\n198\n00:09:50.345 --> 00:09:52.808\nDNS you've already got\nnames that are stored for\n\n199\n00:09:52.808 --> 00:09:54.760\nyour machine inside a database so.\n\n200\n00:09:54.760 --> 00:09:58.400\nWhen we talked about that, yeah, you might\nstart to reverse engineer what the network\n\n201\n00:09:58.400 --> 00:10:02.410\narchitecture is, but remember,\nif I have physical access To your network,\n\n202\n00:10:02.410 --> 00:10:04.240\nwell that's not really\nyour network anymore.\n\n203\n00:10:04.240 --> 00:10:06.582\nSo there are other things\nthat we really stress,\n\n204\n00:10:06.582 --> 00:10:09.275\nthat layer defense system,\ndefends in depth, right?\n\n205\n00:10:09.275 --> 00:10:12.915\nBut it is very good for consistency,\nease of use if you will and\n\n206\n00:10:12.915 --> 00:10:16.415\nit reduces the overall account\nmaintenance, if you will or\n\n207\n00:10:16.415 --> 00:10:20.805\nthe administrative effort that it\ntakes to maintain these accounts.\n\n208\n00:10:20.805 --> 00:10:24.362\nThey also call out some really\ncool concepts too like group based\n\n209\n00:10:24.362 --> 00:10:25.632\naccess control.\n\n210\n00:10:25.632 --> 00:10:29.582\nAnd really if you go out there and\nyou do a search in\n\n211\n00:10:29.582 --> 00:10:34.940\nany of your search engines out there and\nyou look up group based access control.\n\n212\n00:10:34.940 --> 00:10:38.480\nRight away you're gonna get things\nlike role-based access control, right?\n\n213\n00:10:38.480 --> 00:10:41.360\nThey're kind of close to one and the same.\n\n214\n00:10:41.360 --> 00:10:45.700\nRemember, role-based access\ncontrol defines an action,\n\n215\n00:10:45.700 --> 00:10:49.360\nwhere group-based access\ncontrol defines an identity.\n\n216\n00:10:49.360 --> 00:10:51.460\nHowever, they kinda coincide, right?\n\n217\n00:10:51.460 --> 00:10:54.020\nIf I have an identity of administrators,\nright?\n\n218\n00:10:54.020 --> 00:10:58.400\nGroups, that pretty much defines what\nprivileges and actions they can do,\n\n219\n00:10:58.400 --> 00:10:59.950\nso they kinda run hand in hand there.\n\n220\n00:10:59.950 --> 00:11:03.660\nA little bit different, but\nwhen it comes down to it conceptually,\n\n221\n00:11:03.660 --> 00:11:08.290\nwe're talking about grouping,\na logical grouping of your users together,\n\n222\n00:11:08.290 --> 00:11:10.780\nbased on whatever access levels they need,\nright?\n\n223\n00:11:10.780 --> 00:11:13.850\nIf it's a marketing team, they need\naccess to marketing resources, right?\n\n224\n00:11:13.850 --> 00:11:17.130\nWe group them together based\non that level of access.\n\n225\n00:11:17.130 --> 00:11:19.860\nIf it's administrators obviously\nthey're privileged accounts.\n\n226\n00:11:19.860 --> 00:11:23.700\nThey're going to have access to things\nthat standard users don't have access to.\n\n227\n00:11:23.700 --> 00:11:28.230\nSo again, group based access control and\nrole based access control are really,\n\n228\n00:11:28.230 --> 00:11:29.050\nreally close.\n\n229\n00:11:29.050 --> 00:11:33.210\nAgain, if you really just look\nat the nit-picking there,\n\n230\n00:11:33.210 --> 00:11:35.570\ngroups are identities, roles are actions.\n\n231\n00:11:35.570 --> 00:11:37.710\nHowever, a lot of times\nthey run hand in hand.\n\n232\n00:11:39.050 --> 00:11:41.140\nAll right,\nthey also call out others things too, and\n\n233\n00:11:41.140 --> 00:11:44.210\nyou can see they talk about location,\nbase policies.\n\n234\n00:11:44.210 --> 00:11:46.120\nThis is geo-location, right?\n\n235\n00:11:46.120 --> 00:11:48.860\nWe talked about things like geo-fencing,\ngeolocation.\n\n236\n00:11:48.860 --> 00:11:51.220\nIf you talked about\nlocation-based policies,\n\n237\n00:11:51.220 --> 00:11:54.250\nthese could be things like remote\naccess policies, where's your location?\n\n238\n00:11:54.250 --> 00:11:55.690\nWell, you're not whitin the network,\nright?\n\n239\n00:11:55.690 --> 00:11:57.600\nWe're gonna have maybe some\ndifferent policies for\n\n240\n00:11:57.600 --> 00:12:00.630\npeople that are connecting over\na public network back into our company.\n\n241\n00:12:02.210 --> 00:12:03.730\nVPM communications, right?\n\n242\n00:12:03.730 --> 00:12:06.070\nIs it a required for VPM communications.\n\n243\n00:12:06.070 --> 00:12:08.210\nAnd one thing that I think\nof more than anything today,\n\n244\n00:12:08.210 --> 00:12:13.105\nwas location-based policies is\nthe prevalence of BYOD in our companies.\n\n245\n00:12:13.105 --> 00:12:15.985\nThe fact that we have those\nroad warriors out there.\n\n246\n00:12:15.985 --> 00:12:17.585\nWe have the telecommuters out there.\n\n247\n00:12:17.585 --> 00:12:18.835\nAnd they are all over the place.\n\n248\n00:12:18.835 --> 00:12:20.305\nThey could be traveling everywhere.\n\n249\n00:12:20.305 --> 00:12:22.165\nSo we can do location-based policies and\n\n250\n00:12:22.165 --> 00:12:25.385\nthings like your mobile device\nmanagement solutions as well.\n\n251\n00:12:25.385 --> 00:12:29.445\nTo basically define a level of access\nthey have based on where they're located.\n\n252\n00:12:29.445 --> 00:12:34.250\nYou could say, well when you're at\nwork you have this level of access.\n\n253\n00:12:34.250 --> 00:12:38.055\nThe moment you leave the proximity\nof the work location, well,\n\n254\n00:12:38.055 --> 00:12:41.721\nyou don't have that access or\nif you're in a remote network,\n\n255\n00:12:41.721 --> 00:12:45.807\nyou gonna have maybe a subset of\nthe privileges of permission that you\n\n256\n00:12:45.807 --> 00:12:49.498\nhave when you're inside of\nthe interior network if you will.\n\n257\n00:12:49.498 --> 00:12:53.181\nCouple of concepts to keep in mind\nis group based access control and\n\n258\n00:12:53.181 --> 00:12:54.837\nlocation-based policies.\n\n259\n00:12:56.360 --> 00:13:01.410\nAll right, so the next thing that they\ntalk about, Dan hinted at this at\n\n260\n00:13:01.410 --> 00:13:06.000\nthe end of the first part of this episode\nthat talks about policy enforcement, and\n\n261\n00:13:06.000 --> 00:13:09.660\nthese are really where we can,\nwhen it comes to account management.\n\n262\n00:13:09.660 --> 00:13:14.600\nA lot of these concepts that we're gonna\ntalk about have to do with the individual\n\n263\n00:13:14.600 --> 00:13:18.470\nuser account like instance we\ntalked about credential management.\n\n264\n00:13:18.470 --> 00:13:21.850\nNow, credential management can\nbe done in many different ways,\n\n265\n00:13:21.850 --> 00:13:26.710\nit can be done in a very decentralised and\nmore complex method\n\n266\n00:13:26.710 --> 00:13:30.800\nthat doesn't assist you in any way\nlike a peer to peer type environment.\n\n267\n00:13:30.800 --> 00:13:36.150\nA small home office type network where\nevery individual computer manages and\n\n268\n00:13:36.150 --> 00:13:38.070\nmaintains it's identities.\n\n269\n00:13:38.070 --> 00:13:43.250\nThis becomes a problem, again,\nit's not a scalable solution, right?\n\n270\n00:13:43.250 --> 00:13:46.570\nBecause of each individual computer\nare managing the accounts, or\n\n271\n00:13:46.570 --> 00:13:50.200\ntheir identities, it means you have to\ngo to each computer and configure them.\n\n272\n00:13:50.200 --> 00:13:52.080\nIn order to give multiple\npeople access and\n\n273\n00:13:52.080 --> 00:13:57.190\nagain, that's not a very scalable solution\nand it can become too time consuming.\n\n274\n00:13:57.190 --> 00:13:59.280\nVery prone to configuration errors.\n\n275\n00:13:59.280 --> 00:14:01.230\nYou guys have been watching\nus through the series or\n\n276\n00:14:01.230 --> 00:14:04.870\nme type and you could see I can't\ntype a password to save my life.\n\n277\n00:14:04.870 --> 00:14:07.610\nImagine if you have\nmultitudes of computers and\n\n278\n00:14:07.610 --> 00:14:10.470\nyou have to go to every\nsingle individual computer\n\n279\n00:14:10.470 --> 00:14:15.360\nmanaging multiple identities that's just,\nagain, too complex, to prone to errors.\n\n280\n00:14:15.360 --> 00:14:18.940\nSo that's why we implement things\nlike the client server model, right?\n\n281\n00:14:18.940 --> 00:14:22.610\nThings like directory solutions where\nwe can do centrally management or\n\n282\n00:14:22.610 --> 00:14:26.640\ncentralized management of,\nif you will, credentials, right?\n\n283\n00:14:26.640 --> 00:14:28.140\nAnd what do I mean by that?\n\n284\n00:14:28.140 --> 00:14:31.200\nWell, if we hop back down\nto our server here, right?\n\n285\n00:14:31.200 --> 00:14:36.630\nIf I need to reset a password, again\nif I'm in a decentralized network and\n\n286\n00:14:36.630 --> 00:14:41.560\nI've got say a username for instance, let\nme bring up our Active Directory users and\n\n287\n00:14:41.560 --> 00:14:42.570\ncomputers now.\n\n288\n00:14:42.570 --> 00:14:47.070\nThis is a centralized management,\nbut imagine if I had my username.\n\n289\n00:14:47.070 --> 00:14:51.110\nMy user account and we're talking about\na work group type environment, right?\n\n290\n00:14:51.110 --> 00:14:55.670\nIf I have to change a password I have to\ngo to every single individual computer and\n\n291\n00:14:55.670 --> 00:14:59.450\nchange that password as part of\nthe decentralized environment.\n\n292\n00:14:59.450 --> 00:15:03.470\nHowever, if we're in a centralized\nenvironment like Active Directory it's as\n\n293\n00:15:03.470 --> 00:15:07.970\nsimple as right clicking\non the account itself.\n\n294\n00:15:07.970 --> 00:15:11.390\nAnd you could do something as simple\nas resetting the password right,\n\n295\n00:15:11.390 --> 00:15:13.110\nlike this here.\n\n296\n00:15:13.110 --> 00:15:17.392\nOkay, and so again,\nyou have credential management in\n\n297\n00:15:17.392 --> 00:15:21.227\na much easier solution and\nvery, very scalable.\n\n298\n00:15:21.227 --> 00:15:25.039\nThe other types of credential management\nthat we have we have things like password\n\n299\n00:15:25.039 --> 00:15:28.795\nvaulting that we've talked about\nwhere you have a credential manager.\n\n300\n00:15:28.795 --> 00:15:31.999\nWe typed in one master password and\nthen it allows the manager,\n\n301\n00:15:31.999 --> 00:15:35.755\nallows us to log into different things\nessentially implementing an SSO.\n\n302\n00:15:35.755 --> 00:15:39.647\nSo that it makes a little bit more\nconvenient for your for your own users.\n\n303\n00:15:39.647 --> 00:15:45.814\nSo you do have applications as well,\nsoftware that can do your management too.\n\n304\n00:15:45.814 --> 00:15:48.110\nLet's see here, what else do we have?\n\n305\n00:15:48.110 --> 00:15:50.910\nWe talked a little bit\nabout in past episodes,\n\n306\n00:15:50.910 --> 00:15:53.150\nwe talked a little bit about group policy.\n\n307\n00:15:53.150 --> 00:15:57.630\nGroup policy is a great way that\nwe can control our passwords and\n\n308\n00:15:57.630 --> 00:15:59.530\nthe credential management\nside of things again.\n\n309\n00:15:59.530 --> 00:16:01.698\nBecause it allows for\nthat centralized management effect.\n\n310\n00:16:01.698 --> 00:16:04.855\nLet me go ahead and bring up group\npolicy while we're discussing it.\n\n311\n00:16:04.855 --> 00:16:09.833\nRight, if I open up something like the\nGPMC I can create policies that dictate\n\n312\n00:16:09.833 --> 00:16:14.670\nexactly or how passwords are going to\nbe implemented within our systems.\n\n313\n00:16:14.670 --> 00:16:18.040\nHowever, one of the great things is is\nwhen you bring up a domain controller for\n\n314\n00:16:18.040 --> 00:16:21.660\nthe first time, we already have\nsomething that is set in place for us.\n\n315\n00:16:21.660 --> 00:16:26.090\nAnd it's already actively\ncontrolling our passwords,\n\n316\n00:16:26.090 --> 00:16:28.950\nour credentials, going out the gate.\n\n317\n00:16:28.950 --> 00:16:33.660\nSo if I grab our default domain policy\nhere, and we do a little right-click on\n\n318\n00:16:33.660 --> 00:16:41.210\nhere, you'll see that under Policies &gt;\nWindows Settings &gt; Security Settings.\n\n319\n00:16:41.210 --> 00:16:44.830\nI can go in here, and\nwe can do account management right here.\n\n320\n00:16:44.830 --> 00:16:47.510\nAnd you can see there's Account Policies,\nright?\n\n321\n00:16:47.510 --> 00:16:48.640\nAnd if we expand this out,\n\n322\n00:16:48.640 --> 00:16:51.400\nyou can see we can do all kinds of\ndifferent types of policies here.\n\n323\n00:16:51.400 --> 00:16:53.140\nWe can do the Password Policy, right?\n\n324\n00:16:53.140 --> 00:16:55.230\nSo let's go ahead and\njust look a little bit,\n\n325\n00:16:55.230 --> 00:16:59.560\ncuz they talk about password complexity,\nhistory, reuse, setting,\n\n326\n00:16:59.560 --> 00:17:05.120\nI'm kinda out of order here on you,\nDan, on some of these topics here.\n\n327\n00:17:05.120 --> 00:17:10.310\nBut one of the great things is all of\nthese topics in one little spot, right?\n\n328\n00:17:10.310 --> 00:17:11.740\nWe have password history.\n\n329\n00:17:11.740 --> 00:17:13.310\nWell, what is password history about?\n\n330\n00:17:13.310 --> 00:17:14.940\nWell, I want you to keep in mind, right?\n\n331\n00:17:14.940 --> 00:17:19.760\nIf I've got my favorite password and\nI say okay, the password age is gonna be,\n\n332\n00:17:19.760 --> 00:17:23.130\nthe maximum password age\nis gonna be 42 days, but\n\n333\n00:17:23.130 --> 00:17:24.710\nI don't enforce password history.\n\n334\n00:17:24.710 --> 00:17:28.880\nWell, that means at the end of 42 days,\nwhat can I do?\n\n335\n00:17:28.880 --> 00:17:33.660\nI can change my password to the same\nthing it was, when it expired, right?\n\n336\n00:17:33.660 --> 00:17:36.065\nSo you're not really\nchanging the password.\n\n337\n00:17:36.065 --> 00:17:41.600\nAnd this default setting would\ngive the attacker 84 days\n\n338\n00:17:41.600 --> 00:17:42.830\nto try to crack the password.\n\n339\n00:17:42.830 --> 00:17:46.170\nSo if we enforce password history,\nwe say, no, no, no, no, no.\n\n340\n00:17:46.170 --> 00:17:49.250\nWhat you have to do is you have\nto cycle through, in this case,\n\n341\n00:17:49.250 --> 00:17:53.510\nthe setting is 24 passwords,\nbefore you can have a reuse a password.\n\n342\n00:17:53.510 --> 00:17:56.780\nSo it kinda limits the password reuse,\n\n343\n00:17:56.780 --> 00:17:59.530\nright, to whatever it\nis that you wanna set.\n\n344\n00:17:59.530 --> 00:18:05.020\nSo again, not only password history,\nbut also dictates how you do password,\n\n345\n00:18:05.020 --> 00:18:07.660\nreusing passwords within your networks,\nright?\n\n346\n00:18:07.660 --> 00:18:11.831\nWe also have additional things,\ntoo, password complexity.\n\n347\n00:18:11.831 --> 00:18:16.620\nNow in a non-domain environment\nthis isn't enabled, okay?\n\n348\n00:18:16.620 --> 00:18:18.090\nIn a domain environment, it is.\n\n349\n00:18:18.090 --> 00:18:20.440\nAnd why do we want password complexity,\nright?\n\n350\n00:18:20.440 --> 00:18:24.292\nWe want to, first of all,\nwe want to strengthen a password and\n\n351\n00:18:24.292 --> 00:18:29.272\nwhat I mean by that is strengthen and\nbasically making it a little bit stronger.\n\n352\n00:18:29.272 --> 00:18:33.760\nAnd taking more computational power to\npotentially crack the password, right?\n\n353\n00:18:33.760 --> 00:18:35.320\nAnd we have four different character sets,\n\n354\n00:18:35.320 --> 00:18:37.200\npotential character sets that we can use,\nright?\n\n355\n00:18:37.200 --> 00:18:41.360\nWe can use uppercase letters, we can use\nlowercase letters, we can use numbers, and\n\n356\n00:18:41.360 --> 00:18:43.020\nwe can use special characters.\n\n357\n00:18:43.020 --> 00:18:46.870\nAnd when we implement password complexity\ncoupled with something like password\n\n358\n00:18:46.870 --> 00:18:52.730\nlength, longer passwords, then you get\nthis, in ECC we talk about elliptic curve.\n\n359\n00:18:52.730 --> 00:18:56.840\nYou get this exponential increase\nof the computational power\n\n360\n00:18:56.840 --> 00:18:58.630\nthat it takes to crtack the password.\n\n361\n00:18:58.630 --> 00:18:59.390\nAnd that's what it's about.\n\n362\n00:18:59.390 --> 00:19:04.050\nWhen we say credential management,\nagain, convenience versus security.\n\n363\n00:19:04.050 --> 00:19:04.980\nThis might be something.\n\n364\n00:19:04.980 --> 00:19:06.160\nYou might say, you know what, for\n\n365\n00:19:06.160 --> 00:19:10.010\nour administrators, we're gonna\nhave 15 character passwords, right?\n\n366\n00:19:10.010 --> 00:19:13.650\nWe're only gonna allow them\nto last 30 days, right?\n\n367\n00:19:13.650 --> 00:19:17.570\nNow most administrators probably\nwon't do that, maybe won't do that.\n\n368\n00:19:17.570 --> 00:19:20.220\nBut you might not wanna do\nthat to your end users, right?\n\n369\n00:19:20.220 --> 00:19:23.520\nBecause what happens when you implement\ncharacters that are too long or\n\n370\n00:19:23.520 --> 00:19:26.430\nrequire your passwords to be too complex?\n\n371\n00:19:26.430 --> 00:19:28.408\nYou take a few steps back in security,\nright?\n\n372\n00:19:28.408 --> 00:19:31.840\nCuz people start writing them down because\nit's a burden to try to remember them.\n\n373\n00:19:31.840 --> 00:19:35.160\nSo in essence you're not really\ndoing yourself any justice.\n\n374\n00:19:35.160 --> 00:19:39.670\nSo I don't know where the balance is, but\nat least it does give you the ability to\n\n375\n00:19:39.670 --> 00:19:45.600\ndo this tailormaking, if you will,\nyour passwords to suit the environment and\n\n376\n00:19:45.600 --> 00:19:48.259\nany kind of security requirements\nthat you might need.\n\n377\n00:19:49.790 --> 00:19:50.600\nAll right, let's see.\n\n378\n00:19:50.600 --> 00:19:51.640\nWhat else do we have?\n\n379\n00:19:51.640 --> 00:19:53.540\nPassword expiration, okay.\n\n380\n00:19:53.540 --> 00:19:55.350\nWe've talked about\na little bit about that.\n\n381\n00:19:55.350 --> 00:19:58.220\nThat something that you can set\nhere on the same settings as well.\n\n382\n00:19:58.220 --> 00:20:02.820\nCould be 40 days, could be 30 days,\ncould be 60 days, could be 90 days.\n\n383\n00:20:02.820 --> 00:20:06.330\nAgain, it really just depends on\nwhat your security policy says.\n\n384\n00:20:06.330 --> 00:20:09.080\nAgain, for\nmore privileged accounts you might say,\n\n385\n00:20:09.080 --> 00:20:11.610\nhey this password's gotta be\nchanged a little bit more often\n\n386\n00:20:11.610 --> 00:20:14.290\nthan it does with standard users or\nnon-privileged accounts.\n\n387\n00:20:14.290 --> 00:20:19.770\nAgain, just a, kind of a guideline,\nif you will, or a best practice.\n\n388\n00:20:19.770 --> 00:20:24.120\nIt doesn't necessarily mean that that's\nhow you're gonna implement it inside of\n\n389\n00:20:24.120 --> 00:20:25.270\nyour networks.\n\n390\n00:20:25.270 --> 00:20:28.270\n&gt;&gt; I'll tell you what, no matter what you\nset it to, your users are gonna hate you.\n\n391\n00:20:28.270 --> 00:20:30.177\n&gt;&gt; That's right.\n&gt;&gt; They hate this feature.\n\n392\n00:20:30.177 --> 00:20:32.850\nWhy do I have to continually\nchange my password?\n\n393\n00:20:32.850 --> 00:20:37.250\nBecause if your password was ever stolen\nand compromised they can log in as you and\n\n394\n00:20:37.250 --> 00:20:38.610\ndo a bunch of damage.\n\n395\n00:20:38.610 --> 00:20:39.500\nYeah, that's not gonna happen.\n\n396\n00:20:39.500 --> 00:20:40.266\nYeah, it happens every day.\n\n397\n00:20:40.266 --> 00:20:41.140\n&gt;&gt; [LAUGH]\n&gt;&gt; All the time.\n\n398\n00:20:41.140 --> 00:20:42.550\nSo here's the password.\n\n399\n00:20:42.550 --> 00:20:43.275\n&gt;&gt; That's right.\n\n400\n00:20:43.275 --> 00:20:46.670\n[LAUGH] Some of the other things that they\ncall out down here which I kinda think is\n\n401\n00:20:46.670 --> 00:20:48.030\ninteresting is disablements.\n\n402\n00:20:48.030 --> 00:20:50.370\nAnd there's a couple of different\nreasons that you could get disabled.\n\n403\n00:20:50.370 --> 00:20:53.440\nAnd in fact, let me show you one of\nthe ways that you can get disabled here.\n\n404\n00:20:53.440 --> 00:20:54.725\nYou gotta be very careful with this one.\n\n405\n00:20:54.725 --> 00:20:56.623\nYou talk about [CROSSTALK].\n\n406\n00:20:56.623 --> 00:20:57.548\n&gt;&gt; Absolutely.\n\n407\n00:20:57.548 --> 00:20:58.826\n&gt;&gt; I'm just gonna lock you out.\n\n408\n00:20:58.826 --> 00:21:01.153\n&gt;&gt; Dan, you act like you've\ndone Help Desk once or twice.\n\n409\n00:21:01.153 --> 00:21:03.229\n&gt;&gt; I don't know what you're talking about,\nman.\n\n410\n00:21:03.229 --> 00:21:05.920\nI ain't never done that,\nbut you get on my bad side-\n\n411\n00:21:05.920 --> 00:21:06.755\n&gt;&gt; That's right.\n\n412\n00:21:06.755 --> 00:21:07.360\n&gt;&gt; Real quick.\n\n413\n00:21:07.360 --> 00:21:11.740\n&gt;&gt; That's right, so you can see again and\nthat gives you an example,\n\n414\n00:21:11.740 --> 00:21:15.200\na real world example,\nwhere the complexities and\n\n415\n00:21:15.200 --> 00:21:18.810\nthe convenience, again,\nthere is not a good balance there.\n\n416\n00:21:18.810 --> 00:21:22.520\n&gt;&gt; I can give you an actual real world\nexample where I purposely disabled\n\n417\n00:21:22.520 --> 00:21:25.880\nan account for reasons other than\nthe fact that they left the company or\n\n418\n00:21:25.880 --> 00:21:28.730\nwere fired or whatever the case may be.\n\n419\n00:21:28.730 --> 00:21:32.420\nWe had sent them a new computer cuz\ntheir old computer was garbage and\n\n420\n00:21:32.420 --> 00:21:36.160\nit had ceased its work effectively for\nquite some time ago.\n\n421\n00:21:36.160 --> 00:21:39.430\nAnd they would not change out\nthe new computer that we gave them,\n\n422\n00:21:39.430 --> 00:21:40.070\nwouldn't do it.\n\n423\n00:21:40.070 --> 00:21:44.120\nJust would not do it, so\nwhat I did was I disabled his account.\n\n424\n00:21:44.120 --> 00:21:46.825\nCalled the Help Desk saying, hey,\nI can't log into my computer.\n\n425\n00:21:46.825 --> 00:21:50.650\nWow, hm, I guess that computer you\nhave there finally died on you.\n\n426\n00:21:50.650 --> 00:21:52.550\nWhy don't you go ahead and plug that new\none in and let's see if you can log in?\n\n427\n00:21:52.550 --> 00:21:56.690\nOf course, I undisabled his account and\nhe logs straight in.\n\n428\n00:21:56.690 --> 00:21:57.240\nIt's working great.\n\n429\n00:21:57.240 --> 00:21:59.220\nYeah, just go ahead and\nship that computer back to me.\n\n430\n00:21:59.220 --> 00:22:00.980\nAnd now your new one works fine.\n\n431\n00:22:00.980 --> 00:22:04.570\nSo every now and then you do have to\nbring down the firm hand of the law, and\n\n432\n00:22:04.570 --> 00:22:06.190\ndisabling is a good way to do that.\n\n433\n00:22:06.190 --> 00:22:08.462\n&gt;&gt; That's right, I'm gonna make sure\nthat I don't get on Dan's bad side.\n\n434\n00:22:08.462 --> 00:22:09.391\n&gt;&gt; [LAUGH]\n&gt;&gt; I really like my computer.\n\n435\n00:22:09.391 --> 00:22:10.636\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n436\n00:22:10.636 --> 00:22:12.372\n&gt;&gt; So another thing I was gonna say,\n\n437\n00:22:12.372 --> 00:22:13.990\nthey talk about disablement.\n\n438\n00:22:13.990 --> 00:22:16.330\nAnd again, disablement can happen for\na couple of different reasons,\n\n439\n00:22:16.330 --> 00:22:21.140\nit could be somebody, as an example,\nsomebody's leaving the company and,\n\n440\n00:22:21.140 --> 00:22:22.690\nagain, we have to be careful.\n\n441\n00:22:22.690 --> 00:22:26.540\nThey also call out account recovery,\nand I want you to understand something,\n\n442\n00:22:26.540 --> 00:22:28.050\ndisabling versus deleting?\n\n443\n00:22:28.050 --> 00:22:29.330\nWe've talked about it before, but\n\n444\n00:22:29.330 --> 00:22:33.120\ndisablement's better than deleting\nbecause the user that has used\n\n445\n00:22:33.120 --> 00:22:36.390\nthat account probably has data\nthat's associated with that account.\n\n446\n00:22:36.390 --> 00:22:41.800\nAnd you have to understand that\nre-creation isn't recovery, right?\n\n447\n00:22:41.800 --> 00:22:47.410\nYou have identifiers that are specific,\nif you will, to that account.\n\n448\n00:22:47.410 --> 00:22:49.150\nAnd if you delete that account and\n\n449\n00:22:49.150 --> 00:22:53.780\nrecreate it in every single way,\nthose little identifiers they don't match.\n\n450\n00:22:53.780 --> 00:22:58.025\nAnd you could lock yourself out of\npotential information that your company\n\n451\n00:22:58.025 --> 00:23:02.585\nneeds and it could cause some kind\nof adverse effect on your company.\n\n452\n00:23:02.585 --> 00:23:06.827\nSo if you are going to disable, or if\nyou have an end user that's leaving your\n\n453\n00:23:06.827 --> 00:23:11.272\ncompany, then what you wanna do is you\nwanna disable their account obviously so\n\n454\n00:23:11.272 --> 00:23:15.610\nthey don't have access to your network\nany more cuz they don't work for you.\n\n455\n00:23:15.610 --> 00:23:19.746\nBut then you do data recovery and\nreassignment, right?\n\n456\n00:23:19.746 --> 00:23:22.000\nI'm gonna log in,\nI'm gonna reset the password,\n\n457\n00:23:22.000 --> 00:23:24.390\njust like I can do as an administrator\nhere in Active Directory.\n\n458\n00:23:24.390 --> 00:23:28.020\nWe're gonna open all the documentation\nup that that person had access to.\n\n459\n00:23:28.020 --> 00:23:31.920\nI'm gonna reassign it to Dan, and\nthen I'm gonna delete the account, right?\n\n460\n00:23:31.920 --> 00:23:37.128\nSo that's why Active Directory and other\nsolutions have things like tombstoning so\n\n461\n00:23:37.128 --> 00:23:39.338\nthat you don't delete an account.\n\n462\n00:23:39.338 --> 00:23:40.285\n&gt;&gt; Done that.\n\n463\n00:23:40.285 --> 00:23:42.920\n&gt;&gt; Yeah, you don't delete an account.\n\n464\n00:23:42.920 --> 00:23:46.980\n&gt;&gt; The sweat beads that will roll\noff of your brow when you're like,\n\n465\n00:23:46.980 --> 00:23:49.390\nno, I accidentally deleted that user.\n\n466\n00:23:49.390 --> 00:23:52.710\nI just wanted to disable them cuz you\ngot all jiminy clicking with your mouse.\n\n467\n00:23:52.710 --> 00:23:53.340\n&gt;&gt; Yeah, yeah.\n\n468\n00:23:53.340 --> 00:23:54.052\n&gt;&gt; What am I gonna do?\n\n469\n00:23:54.052 --> 00:23:56.090\nAnd that tombstone feature\nsaved my bacon big time.\n\n470\n00:23:56.090 --> 00:23:57.242\n&gt;&gt; Definitely, and\n\n471\n00:23:57.242 --> 00:24:02.018\nwhen the Active Directory Recycle Bin\ncame out, too, that was a new one.\n\n472\n00:24:02.018 --> 00:24:06.300\nIt was like, okay, at least you give\nme a couple of stages here that if I do\n\n473\n00:24:06.300 --> 00:24:10.517\nhappen to configure Active Directory\nwithout my spectacles [LAUGH] I can\n\n474\n00:24:10.517 --> 00:24:13.843\nat least undo what I've done,\ndamage that I've done.\n\n475\n00:24:13.843 --> 00:24:18.666\nSo again, with disablement, let me show\nShow you another way it can get disabled.\n\n476\n00:24:18.666 --> 00:24:21.780\nYou could be overburdening\nyour end users by this one.\n\n477\n00:24:21.780 --> 00:24:25.033\nBut you could do something like,\nfor instance, the lockout duration,\n\n478\n00:24:25.033 --> 00:24:26.004\nlockout threshold.\n\n479\n00:24:26.004 --> 00:24:30.912\nSo, for instance, I could say,\nhow many invalid login attempts, right?\n\n480\n00:24:30.912 --> 00:24:33.663\nNow, I want you guys to think of\na scenario where you're coming in on\n\n481\n00:24:33.663 --> 00:24:34.397\nMonday morning.\n\n482\n00:24:34.397 --> 00:24:36.930\nI don't know about you guys,\nbut it takes me at least two or\n\n483\n00:24:36.930 --> 00:24:39.379\nthree times to get my password\nright on Monday morning.\n\n484\n00:24:39.379 --> 00:24:40.789\nAnd-\n&gt;&gt; Especially since we made it 15\n\n485\n00:24:40.789 --> 00:24:41.545\ncharacters or more.\n\n486\n00:24:41.545 --> 00:24:42.850\n[LAUGH]\n&gt;&gt; That's right,\n\n487\n00:24:42.850 --> 00:24:45.781\nespecially if it's\nan administrative password, right?\n\n488\n00:24:45.781 --> 00:24:48.454\nSo if I do something like\nthis where I say, okay,\n\n489\n00:24:48.454 --> 00:24:52.119\nthe account's gonna be locked out\nafter three invalid attempts.\n\n490\n00:24:52.119 --> 00:24:55.405\nAnd it's gonna make some adjustments to\nthe other settings to make sure that they\n\n491\n00:24:55.405 --> 00:24:57.430\nall agree and they're consistent.\n\n492\n00:24:57.430 --> 00:24:59.400\nWell, that could be a problem, right?\n\n493\n00:24:59.400 --> 00:25:02.730\nThat could cause us some issues,\nlet me show you what I mean by that.\n\n494\n00:25:02.730 --> 00:25:06.270\nSo, we've applied that at\nthe domain level here, right,\n\n495\n00:25:06.270 --> 00:25:09.280\nand I am just gonna fat finger\nthe keyboard, it's Monday.\n\n496\n00:25:09.280 --> 00:25:15.190\nI'll do it once here, we'll do it twice,\nall right, we'll try it one more time.\n\n497\n00:25:15.190 --> 00:25:18.630\nAll right, so that's my third time,\nlet's see what happens.\n\n498\n00:25:18.630 --> 00:25:22.721\nWell, unfortunately, you'll notice that\nthe reference account is currently locked\n\n499\n00:25:22.721 --> 00:25:24.167\nout and may not be logged into.\n\n500\n00:25:24.167 --> 00:25:29.557\nSo, now this is that time where Dan's\nsaying, man, I just got 50 calls.\n\n501\n00:25:29.557 --> 00:25:34.014\nEvery single user that's on the sales\nfloor is now locked out of their computers\n\n502\n00:25:34.014 --> 00:25:38.750\nbecause of this security setting that you\ndid inside of your Active Directory here.\n\n503\n00:25:38.750 --> 00:25:44.340\nSo now what we have to do is we have to\ngo back in, we have to find the user.\n\n504\n00:25:44.340 --> 00:25:48.330\nIn this case, we'll just go back into\nActive Directory Users and Computers.\n\n505\n00:25:49.340 --> 00:25:54.970\nAnd look for my account, down here at\nthe bottom, and we'll choose properties.\n\n506\n00:25:54.970 --> 00:25:59.440\nAnd you'll notice that it says,\nthis account is currently locked out\n\n507\n00:25:59.440 --> 00:26:03.010\non the Active Directory Domain Controller,\nright?\n\n508\n00:26:03.010 --> 00:26:06.995\nSo, the administrator could come\nin here and have to enable it.\n\n509\n00:26:06.995 --> 00:26:09.908\nOne of the last things I\nwanna say about disablement,\n\n510\n00:26:09.908 --> 00:26:11.728\nthis could be a validity period.\n\n511\n00:26:11.728 --> 00:26:14.964\nAnd let me tell you why you might\ndo something like that, right?\n\n512\n00:26:14.964 --> 00:26:17.507\nIf you have contractors that\nare working within your networks,\n\n513\n00:26:17.507 --> 00:26:18.788\nmaybe they're gonna be there.\n\n514\n00:26:18.788 --> 00:26:22.613\nMaybe you have guests in your networks and\nyou wanna create them an account,\n\n515\n00:26:22.613 --> 00:26:24.800\nyou could have a validity period.\n\n516\n00:26:24.800 --> 00:26:26.720\nAnd if that, oop, sorry, sorry guys.\n\n517\n00:26:26.720 --> 00:26:32.300\nIf that validity period expires, well, the\nproblem is that also disables the account.\n\n518\n00:26:32.300 --> 00:26:35.320\nSo, there are a couple of issues,\nagain, that could arise.\n\n519\n00:26:35.320 --> 00:26:40.026\nKeep in mind that disablement is better\nthan deletion cuz you wanna ensure that\n\n520\n00:26:40.026 --> 00:26:44.310\nthat end user doesn't have data that your\nwaiting to access and you delete them and\n\n521\n00:26:44.310 --> 00:26:46.430\nyou no longer have access\nto that information.\n\n522\n00:26:46.430 --> 00:26:48.760\nSo, those are a few things.\n\n523\n00:26:50.010 --> 00:26:51.390\nExpiration, they talk about,\n\n524\n00:26:51.390 --> 00:26:53.585\nthat's why I wanted to mention\nthe account expires here.\n\n525\n00:26:53.585 --> 00:26:56.920\nThat could be something like a contractor\nwhere the have temporary access to certain\n\n526\n00:26:56.920 --> 00:26:59.090\nlocations within your domain.\n\n527\n00:26:59.090 --> 00:27:01.340\nOnce that account hits that end date,\nagain,\n\n528\n00:27:01.340 --> 00:27:03.970\nit's disables and\nthey no longer have access.\n\n529\n00:27:03.970 --> 00:27:07.480\nSo that's also a good practice to\nimplement if you have somebody that needs\n\n530\n00:27:07.480 --> 00:27:08.550\ntemporary access.\n\n531\n00:27:08.550 --> 00:27:12.060\nThen you don't have to worry\nabout did I disable the account?\n\n532\n00:27:12.060 --> 00:27:14.630\nI can't remember if I disabled the\naccount, I love it if you can set it and\n\n533\n00:27:14.630 --> 00:27:15.360\nforget it, right?\n\n534\n00:27:15.360 --> 00:27:20.330\nAt a certain date it expires, and then\nit's disabled and they don't have access.\n\n535\n00:27:20.330 --> 00:27:24.430\nSo, a few of the account management\nbest practices understand some of these\n\n536\n00:27:24.430 --> 00:27:25.270\nconcepts.\n\n537\n00:27:25.270 --> 00:27:29.730\nSo that if they do set you up on\na scenario in the exam on Security+,\n\n538\n00:27:29.730 --> 00:27:31.820\nyou'll be able to answer them correctly.\n\n539\n00:27:31.820 --> 00:27:35.582\n&gt;&gt; That's right, this is just day to\nday workout ladies and gentlemen.\n\n540\n00:27:35.582 --> 00:27:38.817\nYou get into any kind of IT\nadministration, this is part and\n\n541\n00:27:38.817 --> 00:27:39.862\nparcel of the job.\n\n542\n00:27:39.862 --> 00:27:43.378\nYou gotta be able to work with\nsetting up complexity requirements,\n\n543\n00:27:43.378 --> 00:27:44.558\nlength of passwords.\n\n544\n00:27:44.558 --> 00:27:47.346\nAnd then trying to make your users,\nnot make it so\n\n545\n00:27:47.346 --> 00:27:49.324\ndifficult that they can't do it.\n\n546\n00:27:49.324 --> 00:27:51.667\nYet make it so difficult that a hacker or\n\n547\n00:27:51.667 --> 00:27:55.083\na malicious threat actor would\nnot be able to crack them.\n\n548\n00:27:55.083 --> 00:27:57.910\nAnd it certain amounts to times, it's\nwhy all of these extras come into play.\n\n549\n00:27:57.910 --> 00:28:01.333\nThis is basically a tapestry on\nhow you do account management,\n\n550\n00:28:01.333 --> 00:28:03.861\nspecifically when it\ncomes to the passwords.\n\n551\n00:28:03.861 --> 00:28:06.624\nSo, definitely take a look at that,\nunderstand each one of them and\n\n552\n00:28:06.624 --> 00:28:07.259\nhow they work.\n\n553\n00:28:07.259 --> 00:28:10.225\nAnd then you'll figure out,\ninside of your environment,\n\n554\n00:28:10.225 --> 00:28:13.800\nexactly how they'll work best for\nyou because it's not a one and done.\n\n555\n00:28:13.800 --> 00:28:17.656\nIt's not a one size fits all,\nit's a one size fits one kind of thing, so\n\n556\n00:28:17.656 --> 00:28:18.956\njust keep that in mind.\n\n557\n00:28:18.956 --> 00:28:20.249\nWes, you did a fantastic job of\nexplaining each one of these things.\n\n558\n00:28:20.249 --> 00:28:21.474\n&gt;&gt; Thank you, sir.\n\n559\n00:28:21.474 --> 00:28:24.253\n&gt;&gt; It can definitely be a little\noverwhelming, so take a little time with\n\n560\n00:28:24.253 --> 00:28:27.234\nit and, like I said, make sure you\nunderstand each one of those concepts.\n\n561\n00:28:27.234 --> 00:28:29.761\nAnd you'll be able to slam that exam and\nnot only that, but\n\n562\n00:28:29.761 --> 00:28:31.770\nactually do this in practicality.\n\n563\n00:28:31.770 --> 00:28:34.290\nThat being said, I'm looking at our clock,\nwe're well out of time for this episode.\n\n564\n00:28:34.290 --> 00:28:36.070\nWe do thank you for\njoining us today though.\n\n565\n00:28:36.070 --> 00:28:38.642\nSigning off for ITPro TV,\nI've been your host, Daniel Lowrie.\n\n566\n00:28:38.642 --> 00:28:39.387\n&gt;&gt; And I'm Wes Bryan.\n\n567\n00:28:39.387 --> 00:28:42.067\n&gt;&gt; And we'll see you next time.\n\n568\n00:28:42.067 --> 00:28:47.928\n[MUSIC]\n\n569\n00:28:47.928 --> 00:28:51.393\n&gt;&gt; Thank you for watching ITPRO TV.\n\n",
          "vimeoId": "217729248"
        }
      ],
      "title": "Identity and Access Management"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Daniel and Wes dive into Policies, Plans, and Procedures. Here they cover different agreement types like BPA, SLA, ISA, and MOU/MOA. Then they go over proper personnel management for risk reduction. Other topics covered includes NDAs, Onboarding, and Acceptable Use Policies.",
          "length": "1918",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-1-policies_plans_and_producures-050417-PGM.00_31_43_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-1-policies_plans_and_producures-050417-PGM.00_31_43_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-1-policies_plans_and_producures-050417-PGM.00_31_43_27.Still001-sm.jpg",
          "title": "Policies, Plans and Procedures",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:02.898\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.898 --> 00:00:07.402\n[CROSSTALK]\n\n3\n00:00:07.402 --> 00:00:12.376\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.376 --> 00:00:14.170\n&gt;&gt; All right, greetings everyone, and\n\n5\n00:00:14.170 --> 00:00:16.362\nwelcome to another great\nepisode of ITProTV.\n\n6\n00:00:16.362 --> 00:00:20.751\nI'm your host, Daniel Lowrie and in\ntoday's episode, we are continuing forward\n\n7\n00:00:20.751 --> 00:00:25.040\nwith more on our Security+ series Joining\nus in the studio again, Mr Wes Bryan.\n\n8\n00:00:25.040 --> 00:00:26.049\nWes, welcome back man,\nhow's it going today?\n\n9\n00:00:26.049 --> 00:00:28.450\n&gt;&gt; Man, it's going great, Dan,\nthanks for having me back.\n\n10\n00:00:28.450 --> 00:00:30.220\nThat's right,\nwe're gonna be looking at, well,\n\n11\n00:00:30.220 --> 00:00:32.390\nsome different things inside of Security+.\n\n12\n00:00:32.390 --> 00:00:34.780\nWe're gonna be looking at\nmore of the red tape, right?\n\n13\n00:00:34.780 --> 00:00:37.170\nPolicies, plans, and procedures.\n\n14\n00:00:37.170 --> 00:00:40.810\nI know, when we think of security,\nwe think of, hey, let's attack something,\n\n15\n00:00:40.810 --> 00:00:42.080\nlet's hack something if you will.\n\n16\n00:00:42.080 --> 00:00:44.340\nLet's learn about exploits and\nvulnerabilities, right?\n\n17\n00:00:44.340 --> 00:00:48.120\nWell, you're gonna learn,\na lot of security, a lot of security.\n\n18\n00:00:48.120 --> 00:00:51.050\nAs I know, Dan can attest to,\nthere's a lot of paperwork.\n\n19\n00:00:51.050 --> 00:00:52.220\n&gt;&gt; It's the ugly truth man.\n\n20\n00:00:52.220 --> 00:00:52.890\n&gt;&gt; It really is [CROSSTALK].\n\n21\n00:00:52.890 --> 00:00:56.330\n&gt;&gt; Making sure everybody's doing\nthe thing they're supposed to do.\n\n22\n00:00:56.330 --> 00:00:57.020\n&gt;&gt; That's right.\n\n23\n00:00:57.020 --> 00:00:59.011\n&gt;&gt; And in a way, you want them to do it.\n\n24\n00:00:59.011 --> 00:01:02.631\n&gt;&gt; [LAUGH] And thank goodness, we do have\nsome standardized documents that we're\n\n25\n00:01:02.631 --> 00:01:04.500\nreally gonna be talking about today.\n\n26\n00:01:04.500 --> 00:01:07.840\nFor instance things like\nstandard operating procedure.\n\n27\n00:01:07.840 --> 00:01:10.040\nAnd this can be a little bit different for\nevery company.\n\n28\n00:01:10.040 --> 00:01:13.560\nHowever, there is kind of one\nplumb line here is that it really\n\n29\n00:01:13.560 --> 00:01:16.640\nis a formal documentation of the routines,\n\n30\n00:01:16.640 --> 00:01:21.230\nand the steps that you're employees\ninside of your organization have to\n\n31\n00:01:21.230 --> 00:01:25.110\nfollow in order to get whatever\ntheir task is accomplished, right?\n\n32\n00:01:25.110 --> 00:01:26.810\nSo, SOPs that you might hear.\n\n33\n00:01:26.810 --> 00:01:29.890\nThat's some of the documentation and\npolicies that we talk about.\n\n34\n00:01:29.890 --> 00:01:33.070\nBut here are also things that,\nwhat happens when you have a couple of\n\n35\n00:01:33.070 --> 00:01:35.330\norganizations that\nare collaborating together, right?\n\n36\n00:01:35.330 --> 00:01:38.370\nMaybe collaborating towards a common goal,\nwhatever the goal may be.\n\n37\n00:01:38.370 --> 00:01:40.710\nFor instance,\nyou have a manufacturer and a supplier.\n\n38\n00:01:40.710 --> 00:01:45.329\nThe parts that manufacturer uses, in order\nto accomplish whatever the production is.\n\n39\n00:01:46.350 --> 00:01:47.210\nOf a product, right?\n\n40\n00:01:47.210 --> 00:01:51.680\nSo, when organizations get together,\nthere are some agreement types,\n\n41\n00:01:51.680 --> 00:01:56.020\nagreement plans if you will that we\nhave to be aware of for the exam.\n\n42\n00:01:56.020 --> 00:01:58.560\nAll right, so\nwhat are those agreement types here?\n\n43\n00:01:58.560 --> 00:02:02.410\nGuys, I got kind of a little diagram up\nhere, and we can kinda look at that and\n\n44\n00:02:02.410 --> 00:02:05.010\ntalk about these different ones, right?\n\n45\n00:02:05.010 --> 00:02:08.290\nAnd we'll kinda review them and then we'll\ngo back through them individually, right?\n\n46\n00:02:08.290 --> 00:02:11.804\nWe have a BPA, right?, we're not talking\nabout the stuff that they tell you to stay\n\n47\n00:02:11.804 --> 00:02:15.850\naway from in plastic, we're talking about\nthe Business Partner Agreement, right?\n\n48\n00:02:15.850 --> 00:02:18.500\nSLA, you've probably seen\nan SLA once ,or twice, right?\n\n49\n00:02:18.500 --> 00:02:19.820\nThis is a service level agreement.\n\n50\n00:02:19.820 --> 00:02:25.210\nWe'll talked about SLAs, now, the ISA,\nthe ISA is an interesting one right?.\n\n51\n00:02:25.210 --> 00:02:29.302\nThis is an interconnection site agreement,\nand, again, remember I want you to keep in\n\n52\n00:02:29.302 --> 00:02:33.346\nmind interconnection we are talking about\ntwo organizations that are collaborate and\n\n53\n00:02:33.346 --> 00:02:34.752\nwe are gonna make [CROSSTALK].\n\n54\n00:02:34.752 --> 00:02:37.370\nYeah, [LAUGH] we gonna\nmake our own contribution.\n\n55\n00:02:37.370 --> 00:02:40.760\nThe English language here,\nis they are collaborating together.\n\n56\n00:02:40.760 --> 00:02:43.880\nFor instance, maybe you got a mortgage\ncompany that's gonna look at some\n\n57\n00:02:43.880 --> 00:02:45.850\nmortgages that a bank owns, right?\n\n58\n00:02:45.850 --> 00:02:49.250\nAnd they're gonna have to make inter\nconnections between the two to allow\n\n59\n00:02:49.250 --> 00:02:50.230\nsomething like that to happen.\n\n60\n00:02:50.230 --> 00:02:55.440\nSo, there's a formal documentation,\nin how that's gonna be accomplished.\n\n61\n00:02:55.440 --> 00:02:58.940\nAnd then the last one, sometimes they\ngroup together, and you'll see MOU,\n\n62\n00:02:58.940 --> 00:02:59.610\nMOA, right?\n\n63\n00:02:59.610 --> 00:03:02.690\nSo, memorandum of understanding,\nversus a memorandum of agreement.\n\n64\n00:03:02.690 --> 00:03:04.804\nAnd a lot of times, they kind of lump\nthem together, and that's why you see.\n\n65\n00:03:04.804 --> 00:03:07.710\nYou could see these documented\na couple different ways.\n\n66\n00:03:07.710 --> 00:03:12.560\nYou could see MOU/A,\nmeaning that they're talking about both,\n\n67\n00:03:12.560 --> 00:03:14.490\nand we'll talk about what that means.\n\n68\n00:03:14.490 --> 00:03:17.860\nAll right, so let's go ahead and\nwe'll focus in on the very first one here,\n\n69\n00:03:17.860 --> 00:03:21.070\nwe'll focus in on what is known as\nthe business partner agreement.\n\n70\n00:03:21.070 --> 00:03:24.930\nWith the business partner agreement keep\nin mind that these are really nothing more\n\n71\n00:03:24.930 --> 00:03:30.000\nthan a set of terms and conditions for\npartnership between two organizations.\n\n72\n00:03:30.000 --> 00:03:31.970\nAnd what it does, and\nwhat a lot of these do is,\n\n73\n00:03:31.970 --> 00:03:35.310\nit establishes things like the\nresponsibility of each business partner.\n\n74\n00:03:35.310 --> 00:03:39.430\nSome of the things that you can see in\nhere that they can define, things like for\n\n75\n00:03:39.430 --> 00:03:42.050\ninstance, the duration of the partnership,\nright?\n\n76\n00:03:42.050 --> 00:03:45.614\nIf we have two organizations that\nare collaborating together, and\n\n77\n00:03:45.614 --> 00:03:48.124\nthey enter into a business\npartner agreement.\n\n78\n00:03:48.124 --> 00:03:52.769\nThis could be where we have to\ndocument the length of time, right?,\n\n79\n00:03:52.769 --> 00:03:57.022\nthat that business partnership\nis going to be a handle.\n\n80\n00:03:57.022 --> 00:04:00.370\nThings like the decision making process,\n\n81\n00:04:00.370 --> 00:04:04.290\nright?, in organization, you're gonna\nhave the sea level employers, but\n\n82\n00:04:04.290 --> 00:04:07.610\nyou're going to have two different\nsets of sea levels employers right?,\n\n83\n00:04:07.610 --> 00:04:12.550\nyou CEOs, CIOs, COOs if you will,\nCSOs like your chief security officers.\n\n84\n00:04:12.550 --> 00:04:15.880\nAnd we need to know that\nin these organizations,\n\n85\n00:04:15.880 --> 00:04:17.370\nwhen they start to get together, and\n\n86\n00:04:17.370 --> 00:04:23.505\nthey're basically both heading\ntowards that common, that common goal.\n\n87\n00:04:23.505 --> 00:04:25.665\nWho is it gonna be that's\nmaking the decision process.\n\n88\n00:04:25.665 --> 00:04:29.905\nOf course it can't just be one\norganization, or one set of employees.\n\n89\n00:04:29.905 --> 00:04:34.685\nIt usually has to be a collaborative\neffort and that document can define that.\n\n90\n00:04:34.685 --> 00:04:37.315\nOther things too,\nhow about liabilities, right?\n\n91\n00:04:37.315 --> 00:04:41.075\nNot only the responsibility between the\norganizations and the partners themselves,\n\n92\n00:04:41.075 --> 00:04:42.665\nbut what is the liability?\n\n93\n00:04:42.665 --> 00:04:45.990\nAnd if there is liability who\nis it that's gonna be liable?\n\n94\n00:04:45.990 --> 00:04:48.650\nSo, know what the business\npartner agreement is.\n\n95\n00:04:48.650 --> 00:04:53.080\nThis can be a precursor to\nan overall contract, right?\n\n96\n00:04:53.080 --> 00:04:54.880\nThis can set the stage for\n\n97\n00:04:54.880 --> 00:04:59.710\na larger set of contracts that\nyou could be implementing later.\n\n98\n00:04:59.710 --> 00:05:01.920\nNext one, service level agreement.\n\n99\n00:05:01.920 --> 00:05:03.570\nWhen we talk about SLA, right?\n\n100\n00:05:03.570 --> 00:05:05.560\nYou've probably had one of these,\n\n101\n00:05:05.560 --> 00:05:09.620\nif you watching us now, you've most\nlikely got an internet connection, right?\n\n102\n00:05:09.620 --> 00:05:10.980\nInternet based business.\n\n103\n00:05:10.980 --> 00:05:14.062\nSo, I want you to think about\nyour service provider, your ISP.\n\n104\n00:05:14.062 --> 00:05:19.415\nNow, when you enter into a contract with\nyour service provider, you essentially\n\n105\n00:05:19.415 --> 00:05:24.510\nget a contract between the provider,\nand whoever the customer consumer is.\n\n106\n00:05:24.510 --> 00:05:26.490\nEnd user, could be a business.\n\n107\n00:05:26.490 --> 00:05:31.630\nAnd it defines what the acceptable\nlevel of performance is,\n\n108\n00:05:31.630 --> 00:05:36.060\nand also what the acceptable minimum\nlevel of performance is, right?\n\n109\n00:05:36.060 --> 00:05:39.200\nSo, for instance, if I'm a business,\nand I got an SLA, and\n\n110\n00:05:39.200 --> 00:05:42.730\nthe SLA defines a certain amount\nof high availability, right?\n\n111\n00:05:42.730 --> 00:05:46.330\nDan and I have been talking about cloud\nproviders over the last few episodes,\n\n112\n00:05:46.330 --> 00:05:47.800\nwe've kind of thrown that in there.\n\n113\n00:05:47.800 --> 00:05:51.110\nWe've talked about the high\navailability concept, right?\n\n114\n00:05:51.110 --> 00:05:55.660\nWell, five nines, that's a pretty\nstrict high availability, right?\n\n115\n00:05:55.660 --> 00:06:00.745\nBut a lot of the cloud providers\nwill offer you things like 99.95%.\n\n116\n00:06:00.745 --> 00:06:04.100\nOkay, what happens if they don't hit that?\n\n117\n00:06:04.100 --> 00:06:08.480\nWell, now, we have to define things like\nliability, what is the quality of service,\n\n118\n00:06:08.480 --> 00:06:12.610\nthe availability, and the responsibility\nnot only for the service provider, but\n\n119\n00:06:12.610 --> 00:06:16.790\nalso on the other side of the tracks too,\nthe end user themselves.\n\n120\n00:06:16.790 --> 00:06:19.860\nThings like usage statistics, if you will.\n\n121\n00:06:19.860 --> 00:06:22.120\nHow do we address down time?\n\n122\n00:06:22.120 --> 00:06:24.070\nIf we enter into this agreement that says,\n\n123\n00:06:24.070 --> 00:06:26.490\nthis is the minimum level\nof acceptable performance.\n\n124\n00:06:26.490 --> 00:06:29.130\nWhat happens when that\nperformance isn't hit?\n\n125\n00:06:29.130 --> 00:06:32.260\nHow do they address things like outages,\nif you will.\n\n126\n00:06:32.260 --> 00:06:33.590\nDo you get service credits?\n\n127\n00:06:33.590 --> 00:06:35.280\nDo you get some kind of compensation?\n\n128\n00:06:35.280 --> 00:06:38.880\nAnd a lot of times, in your SLAs,\nyour service level agreements.\n\n129\n00:06:38.880 --> 00:06:41.630\nThat's gonna be thoroughly\ndocumented if you will, so\n\n130\n00:06:41.630 --> 00:06:43.930\nthat later on a business\ncan't turn around, and\n\n131\n00:06:43.930 --> 00:06:47.440\nsue a service provider if they\nhappen to lose money, right?\n\n132\n00:06:47.440 --> 00:06:49.680\nMaybe not a good analogy,\nwhen we're talking about home,\n\n133\n00:06:49.680 --> 00:06:52.150\nor residential SLAs, right?\n\n134\n00:06:52.150 --> 00:06:55.980\nBut definitely in a business SLA where\nyou've got the majority of your resources\n\n135\n00:06:55.980 --> 00:06:57.710\nin the cloud.\n\n136\n00:06:57.710 --> 00:06:59.750\nSLAs definitely come in handy.\n\n137\n00:07:00.910 --> 00:07:04.691\nAll right, so the next thing we'll\ntalke about is what is known as an ISA.\n\n138\n00:07:04.691 --> 00:07:09.277\nAnd an ISA if you will this is\nessentially what's known as an inner-\n\n139\n00:07:09.277 --> 00:07:13.070\nlet's go ahead and\npull one of these up here real quick.\n\n140\n00:07:13.070 --> 00:07:15.360\nIn this has documentation for this.\n\n141\n00:07:15.360 --> 00:07:19.020\nISA is an inner connection\nsite agreements, right?\n\n142\n00:07:19.020 --> 00:07:22.550\nAnd you can see for here if you just\ndo a real quick Google Search, right?\n\n143\n00:07:22.550 --> 00:07:24.707\nYou'll get a calculator\ntoo if you need that.\n\n144\n00:07:24.707 --> 00:07:25.685\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH] But\n\n145\n00:07:25.685 --> 00:07:29.190\nyou'll see a Security Guide for\nInterconnecting, right?\n\n146\n00:07:29.190 --> 00:07:31.520\nAnd this is a valuable documentation.\n\n147\n00:07:31.520 --> 00:07:35.960\nThe reason I say that is, I want to think\nof a situation where, like I've mentioned,\n\n148\n00:07:35.960 --> 00:07:40.360\nyou got a mortgage company, and they're\ngonna Buy some mortgages from a bank.\n\n149\n00:07:40.360 --> 00:07:41.600\nVery sensitive information.\n\n150\n00:07:41.600 --> 00:07:44.700\nTo mention a bank at all\nis a sensitive information.\n\n151\n00:07:44.700 --> 00:07:48.456\nWell, what does the internet, or\nthe interconnection site agreement do?\n\n152\n00:07:48.456 --> 00:07:53.244\nIt essentially defines the technical and\nsecurity requirements if you will,\n\n153\n00:07:53.244 --> 00:07:56.363\nfor these companies establishing,\noperating and\n\n154\n00:07:56.363 --> 00:08:00.006\nmaintaining connections\nbetween the two organizations.\n\n155\n00:08:00.006 --> 00:08:00.692\nRight?\n\n156\n00:08:00.692 --> 00:08:01.586\nThings like.\n\n157\n00:08:01.586 --> 00:08:03.507\nWe have to bring up VPNs.\n\n158\n00:08:03.507 --> 00:08:05.232\nIf we bring up VPN communications,\n\n159\n00:08:05.232 --> 00:08:08.230\nwhat kind of authentication\nprotocols are we gonna be using?\n\n160\n00:08:08.230 --> 00:08:12.420\nWhat are the mechanisms behind the scenes,\nencryption types, right?\n\n161\n00:08:12.420 --> 00:08:16.580\nAre we gonna be using L2TP, if you will,\nwith IPsec encryption as well?\n\n162\n00:08:16.580 --> 00:08:21.147\nIf we use IPsec encryption, are we gonna\nbe using desk, are we gonna be using AES?\n\n163\n00:08:21.147 --> 00:08:25.570\nIf we choose AES, are we gonna be\nusing it with cipher block chaining?\n\n164\n00:08:25.570 --> 00:08:30.439\nSo it defines the technical aspects of,\nagain, bringing that connection online, so\n\n165\n00:08:30.439 --> 00:08:33.788\nthe establishment,\nthe maintaining of that connection.\n\n166\n00:08:33.788 --> 00:08:34.620\nAnd even more so,\n\n167\n00:08:34.620 --> 00:08:38.120\nsometimes you can forget the side of\ntearing down the connection, right?\n\n168\n00:08:38.120 --> 00:08:41.400\nCuz when you tear down that connection\nbetween two public entities like that,\n\n169\n00:08:41.400 --> 00:08:43.070\nthere is risk for vulnerability, right?\n\n170\n00:08:43.070 --> 00:08:46.538\nThere's risk that somebody could exploit\nthat when it's being brought down.\n\n171\n00:08:46.538 --> 00:08:52.400\nSo these interconnection site agreements\nensure that the connection is brought up,\n\n172\n00:08:52.400 --> 00:08:56.030\nmaintained, and\nthen terminated in a secure fashion that\n\n173\n00:08:56.030 --> 00:08:59.415\nprotects the interests of both of\nthe endpoints, or entities, if you will.\n\n174\n00:08:59.415 --> 00:09:03.796\n&gt;&gt; Unless they just seem like, basically,\nkind of a complicated checklist of things\n\n175\n00:09:03.796 --> 00:09:06.750\nfor us to do, walk through,\nokay, make sure you did A.\n\n176\n00:09:06.750 --> 00:09:09.300\nThen you did B, then C, and\nyou check them off as you go.\n\n177\n00:09:09.300 --> 00:09:10.940\nAnd then if you do that,\n\n178\n00:09:10.940 --> 00:09:14.740\nyou should have a high level of\nsecurity inherent to it, right?\n\n179\n00:09:14.740 --> 00:09:16.770\n&gt;&gt; Most definitely and\nminimizing your risk, right?\n\n180\n00:09:16.770 --> 00:09:19.596\nEverything in security is about just,\nyou can't eliminate risk, right?\n\n181\n00:09:19.596 --> 00:09:23.458\nBut what we can do is we can mitigate\nit to an acceptable level where both\n\n182\n00:09:23.458 --> 00:09:26.810\ncompanies agree, okay,\nwe can accept this, XYZ, right?\n\n183\n00:09:26.810 --> 00:09:29.840\nSo that's really what it comes down to,\nyou're right, Dan, is just mitigating\n\n184\n00:09:29.840 --> 00:09:34.790\nthe risk of any kind of data exposure,\nif you will, that can have an adverse\n\n185\n00:09:34.790 --> 00:09:38.320\neffect on the reputation of your company,\nlet alone the legalities behind it too.\n\n186\n00:09:38.320 --> 00:09:40.750\n&gt;&gt; And what's funny is these\nthings seem very, man,\n\n187\n00:09:40.750 --> 00:09:42.651\nI gotta go through that checklist again.\n\n188\n00:09:42.651 --> 00:09:46.075\nI've got to make sure that\nI've crossed all my Ts, and\n\n189\n00:09:46.075 --> 00:09:48.640\ndotted all my lowercase js, right?\n\n190\n00:09:48.640 --> 00:09:52.720\nBut it really is a help\nto the administrators,\n\n191\n00:09:52.720 --> 00:09:55.790\nbecause they can say, look, I did this.\n\n192\n00:09:55.790 --> 00:09:58.960\nI can show with proof that this was done,\n\n193\n00:09:58.960 --> 00:10:01.830\nso if something happened,\nit wasn't because I was negligent.\n\n194\n00:10:01.830 --> 00:10:04.230\nIt was because we just got caught.\n\n195\n00:10:04.230 --> 00:10:06.060\n&gt;&gt; That's right, exactly, and then,\n\n196\n00:10:06.060 --> 00:10:10.400\nagain, you can focus liability\nat that point on who is liable.\n\n197\n00:10:10.400 --> 00:10:14.390\nSo that's a little bit about your ISA,\nInterconnection Site Agreement.\n\n198\n00:10:14.390 --> 00:10:17.280\nAgain, keep in mind that on the exam,\n\n199\n00:10:17.280 --> 00:10:22.020\nif they bring a concept up like that,\nyou're definitely gonna have to be aware.\n\n200\n00:10:22.020 --> 00:10:25.328\nNow there are other types of documents\nthat we have to be aware of, too, and\n\n201\n00:10:25.328 --> 00:10:28.708\nthe last one is what's known as\na memorandum of understanding, all right?\n\n202\n00:10:28.708 --> 00:10:34.950\nThe memorandum of understanding, if you\nwill, or the memorandum of agreement,\n\n203\n00:10:34.950 --> 00:10:40.100\nnow, there are aspects of this\nthat can be legally binding.\n\n204\n00:10:40.100 --> 00:10:42.730\nSometimes your memorandum\nof understandings are not\n\n205\n00:10:42.730 --> 00:10:43.960\nlegally binding, right?\n\n206\n00:10:43.960 --> 00:10:48.480\nIf you have, for instance,\nlet's take it out of the IT world, right?\n\n207\n00:10:48.480 --> 00:10:52.010\nIf you have two different foreign\ngovernments, right, their legal systems\n\n208\n00:10:52.010 --> 00:10:54.470\naren't the same, right,\nthey're not adhering to the same systems.\n\n209\n00:10:54.470 --> 00:10:56.643\nSo how can we have\na legally binding contract,\n\n210\n00:10:56.643 --> 00:10:59.610\nwhen our legalities [LAUGH]\nare completely different, right?\n\n211\n00:10:59.610 --> 00:11:01.010\nOur legal systems are different.\n\n212\n00:11:01.010 --> 00:11:03.980\nSo you'll have things like port\nambassadors that enter into a common\n\n213\n00:11:03.980 --> 00:11:06.590\nagreement between two\nforeign bodies there.\n\n214\n00:11:06.590 --> 00:11:10.957\nBecause, again, you can't bring\nsomebody into court if they're not\n\n215\n00:11:10.957 --> 00:11:13.524\nfollowing whatever your local laws are.\n\n216\n00:11:13.524 --> 00:11:16.571\nIt defines essentially\nthe responsibilities between two parties,\n\n217\n00:11:16.571 --> 00:11:20.120\nif you will, and what they're gonna\ncontribute to the partnership.\n\n218\n00:11:20.120 --> 00:11:23.760\nAgain, one of the differences\nbetween this is that the BPA\n\n219\n00:11:23.760 --> 00:11:28.850\ncan be a precursor to a formal contract,\nand it is legally binding.\n\n220\n00:11:28.850 --> 00:11:34.490\nMemorandums of understanding, they can be\nlegally binding if both entities sign it,\n\n221\n00:11:34.490 --> 00:11:36.040\nright, we could use this.\n\n222\n00:11:36.040 --> 00:11:38.520\nBut this is a nice way\nwhere you can actually,\n\n223\n00:11:38.520 --> 00:11:43.360\nlike I said, a precursor to a formal\ncontract that you can kind of establish.\n\n224\n00:11:43.360 --> 00:11:47.450\nIt could be something as simple as writing\nit down on a napkin, if you will, but\n\n225\n00:11:47.450 --> 00:11:51.850\nagain, memorandum of understanding,\nmake sure that we understand, right?\n\n226\n00:11:51.850 --> 00:11:52.430\nAnd again,\n\n227\n00:11:52.430 --> 00:11:56.220\nit's just literally meant between two\ncompanies that have a common goal.\n\n228\n00:11:56.220 --> 00:11:59.316\nIt's a lot like the business\npartner agreement.\n\n229\n00:11:59.316 --> 00:12:02.730\nBut the memorandum of understanding\ncould actually precede\n\n230\n00:12:02.730 --> 00:12:05.470\nany kind of BPA that you're\ngonna be implementing.\n\n231\n00:12:05.470 --> 00:12:07.431\nAll right, so,\nthose are some of the documents,\n\n232\n00:12:07.431 --> 00:12:09.730\nthose are some of the policies\nthat we have to worry about.\n\n233\n00:12:09.730 --> 00:12:12.430\nI know it doesn't sound like\nthe funnest thing on the exam.\n\n234\n00:12:12.430 --> 00:12:16.390\nBut again, remember, a lot of your\nsecurity is gonna really center\n\n235\n00:12:16.390 --> 00:12:20.920\naround things like policies, training,\nif you will, and adhering to standards.\n\n236\n00:12:20.920 --> 00:12:23.620\n&gt;&gt; Yeah, definitely a part of the job,\nbut what are you gonna do, right?\n\n237\n00:12:23.620 --> 00:12:27.065\nIt's the nature of the beast, so embrace\nit and learn to, well, drink a lot or\n\n238\n00:12:27.065 --> 00:12:28.331\nsomething, I don't know.\n\n239\n00:12:28.331 --> 00:12:29.603\n&gt;&gt; [LAUGH]\n&gt;&gt; Don't do that, that's bad.\n\n240\n00:12:29.603 --> 00:12:31.892\n&gt;&gt; [LAUGH]\n&gt;&gt; Let's see here, moving on, Wes,\n\n241\n00:12:31.892 --> 00:12:34.674\nlet's talk about the people\nin our organization, right?\n\n242\n00:12:34.674 --> 00:12:39.570\nThey always say the weakest link in your\nchain is what's gonna get you, right?\n\n243\n00:12:39.570 --> 00:12:41.740\nAnd usually, that is our end user.\n\n244\n00:12:41.740 --> 00:12:44.150\nSo there's got to be ways\nin which policies and\n\n245\n00:12:44.150 --> 00:12:47.050\nprocedures that we put into\nplace to help manage them.\n\n246\n00:12:47.050 --> 00:12:48.540\nSo that we can mitigate with.\n\n247\n00:12:48.540 --> 00:12:50.280\n&gt;&gt; That's right,\nsecuring from within, right?\n\n248\n00:12:50.280 --> 00:12:53.129\nSometimes we don't have to worry, we\nalways have to worry about external users.\n\n249\n00:12:53.129 --> 00:12:56.049\nBut sometimes, like Dan says,\nsome of the things that\n\n250\n00:12:56.049 --> 00:13:00.600\nwe have to worry about are going to be\ncoming from inside of your organization.\n\n251\n00:13:00.600 --> 00:13:03.253\nSo let's go ahead, we've got a few\nthat we're gonna take a look at here.\n\n252\n00:13:03.253 --> 00:13:07.265\nWell Dan, yeah, we seem to have a few\nthings that we can do [LAUGH] inside to,\n\n253\n00:13:07.265 --> 00:13:09.536\nas far as personnel management, right?\n\n254\n00:13:09.536 --> 00:13:12.820\nAnd we're gonna go ahead, and we'll talk\nabout each one of these individually, so\n\n255\n00:13:12.820 --> 00:13:16.440\nthat you're aware of what they're actually\ndoing for us inside of our company.\n\n256\n00:13:16.440 --> 00:13:18.370\nThe first one is mandatory vacations.\n\n257\n00:13:18.370 --> 00:13:21.050\nNow, a mandatory vacation,\nyou might think, that's nice.\n\n258\n00:13:21.050 --> 00:13:23.210\nThe company's really looking out for me.\n\n259\n00:13:23.210 --> 00:13:25.010\nBut really,\nthis is the company looking out for\n\n260\n00:13:25.010 --> 00:13:26.680\ntheir interests when it comes down to it.\n\n261\n00:13:26.680 --> 00:13:29.954\nBecause I want you to think about\nmaybe somebody that's in a position of\n\n262\n00:13:29.954 --> 00:13:30.728\npower, right?\n\n263\n00:13:30.728 --> 00:13:33.161\nIt doesn't have to be a C level\nemployee like we're talking about,\n\n264\n00:13:33.161 --> 00:13:34.840\nit could be an administrator, right?\n\n265\n00:13:34.840 --> 00:13:39.752\nIt could be a domain admin,\nEnterprise admin, and anybody in between.\n\n266\n00:13:39.752 --> 00:13:43.400\nBut I want you to think about the fact\nthat nobody is taking over their\n\n267\n00:13:43.400 --> 00:13:44.170\njob, right?\n\n268\n00:13:44.170 --> 00:13:47.480\nNobody is auditing what it is that\nthey're doing throughout the year.\n\n269\n00:13:47.480 --> 00:13:49.732\nWell that's where the mandatory\nvacation comes in, right?\n\n270\n00:13:49.732 --> 00:13:51.224\nThe mandatory vacation,\n\n271\n00:13:51.224 --> 00:13:55.835\nits main thing is it's seeking to uncover\nany potential malicious activities,\n\n272\n00:13:55.835 --> 00:14:00.220\nif you will, of the employees that\nwork from within the company.\n\n273\n00:14:00.220 --> 00:14:03.730\nYou might see it, it could be once a year,\nit could be twice a year, right?\n\n274\n00:14:03.730 --> 00:14:07.770\nBut usually what it's gonna be is a\nminimum of five consecutive business days,\n\n275\n00:14:07.770 --> 00:14:11.420\nwork days, right, that a person\nis forced to take a vacation.\n\n276\n00:14:11.420 --> 00:14:14.600\nSo that the company can come in and\nthey can kinda do an audit on what\n\n277\n00:14:14.600 --> 00:14:19.550\nthe activities of that user's been for\nhowever, whatever the duration of time is.\n\n278\n00:14:19.550 --> 00:14:23.350\nAgain, if it's buy annually,\nthen it could be the past six months.\n\n279\n00:14:23.350 --> 00:14:25.904\nIt could be the past year,\nif it's only five days out of the year.\n\n280\n00:14:25.904 --> 00:14:27.782\nSo mandatory vacations, keep in mind,\n\n281\n00:14:27.782 --> 00:14:30.886\nis not about relieving the stress\noff of you [LAUGH], the employee.\n\n282\n00:14:30.886 --> 00:14:35.098\nIt's actually more for internal\nauditing of their activities to try to\n\n283\n00:14:35.098 --> 00:14:37.976\nuncover any security violations,\nif you will,\n\n284\n00:14:37.976 --> 00:14:43.350\nany kind of malicious activity that's\nhappening by that person in power.\n\n285\n00:14:43.350 --> 00:14:46.260\nAll right, so\nthe next one is job rotation, right?\n\n286\n00:14:46.260 --> 00:14:48.940\nSo, job rotation is really interesting.\n\n287\n00:14:48.940 --> 00:14:54.020\nAnd this, again, is more about the company\nprotecting its interests, right?\n\n288\n00:14:54.020 --> 00:14:56.430\nI want you to think about if\nyou've got one person, right,\n\n289\n00:14:56.430 --> 00:14:59.090\nwe talk about the gatekeeper\nholding all the keys, right?\n\n290\n00:14:59.090 --> 00:15:01.910\nAnd that's the only person you\ncan go to to get that key.\n\n291\n00:15:01.910 --> 00:15:07.100\nWell that's a lot of focus, a lot of kinda\npower, if you will, from that one person.\n\n292\n00:15:07.100 --> 00:15:11.273\nBut job rotation is more about making\nsure that people are cross-trained, and\n\n293\n00:15:11.273 --> 00:15:14.380\nthey're crossed-trained, so\nthat if everybody can do\n\n294\n00:15:14.380 --> 00:15:19.540\nindividually a job that no one person\nis the sole asset, if you will.\n\n295\n00:15:19.540 --> 00:15:21.380\nThat if that something\nhappens to that person,\n\n296\n00:15:21.380 --> 00:15:22.920\nnobody else can do their job, right?\n\n297\n00:15:22.920 --> 00:15:24.530\nAnd you've probably\nmaybe seen this before,\n\n298\n00:15:24.530 --> 00:15:26.510\nsome people have,\npower trips, if you will.\n\n299\n00:15:26.510 --> 00:15:28.414\nThey're like no,\nI'm gonna be the only one to do that.\n\n300\n00:15:28.414 --> 00:15:29.388\n&gt;&gt; I'm irreplaceable.\n\n301\n00:15:29.388 --> 00:15:30.460\n&gt;&gt; Right.\n&gt;&gt; Right?\n\n302\n00:15:30.460 --> 00:15:33.108\n&gt;&gt; How about this, Dan, and\nI'm gonna throw this one back to Dan cuz I\n\n303\n00:15:33.108 --> 00:15:35.320\nknow he's been in the industry for\na good long while.\n\n304\n00:15:35.320 --> 00:15:36.790\nHow many times have you,\n\n305\n00:15:36.790 --> 00:15:40.950\nin your experience, had somebody\nmake a bunch of changes on Friday,\n\n306\n00:15:40.950 --> 00:15:43.760\nthey're the only one that understands\nthose changes, and they go on vacation?\n\n307\n00:15:43.760 --> 00:15:44.994\n&gt;&gt; Yeah, that's their favorite\nthing in the world to do.\n\n308\n00:15:44.994 --> 00:15:45.764\n&gt;&gt; [LAUGH]\n&gt;&gt; Right,\n\n309\n00:15:45.764 --> 00:15:49.528\nbecause they think going on vacation,\nI have to get so much done, so\n\n310\n00:15:49.528 --> 00:15:53.823\nthat while I'm gone, things stay together,\nand there's the problem, right?\n\n311\n00:15:53.823 --> 00:15:57.126\nIf the fact that you're gone makes\neverything fall apart, We've got an issue\n\n312\n00:15:57.126 --> 00:16:00.044\nand we need to mitigate that using\nthese type of management changes.\n\n313\n00:16:00.044 --> 00:16:00.977\n&gt;&gt; Most definitely, and\n\n314\n00:16:00.977 --> 00:16:03.980\nthat's where job rotation comes in\nif we have everybody cross trained.\n\n315\n00:16:03.980 --> 00:16:08.000\nIt also brings up the level of the skills\nof the employees within your company too,\n\n316\n00:16:08.000 --> 00:16:10.340\nit gives your employees\na larger skill set too.\n\n317\n00:16:10.340 --> 00:16:13.710\nSo, I would say this is one,\nit's also kinda beneficial for\n\n318\n00:16:13.710 --> 00:16:14.930\nthe employee, too, right?\n\n319\n00:16:14.930 --> 00:16:17.750\nA larger skill-set means potential for\nbetter pay, [LAUGH] right?\n\n320\n00:16:17.750 --> 00:16:21.300\nPotential to climb that ladder inside of\nthe company, but again, keep in mind,\n\n321\n00:16:21.300 --> 00:16:23.800\nthat it's also about that one person.\n\n322\n00:16:23.800 --> 00:16:27.534\nIf they are replaced or if they go\non vacation or if they get hurt,\n\n323\n00:16:27.534 --> 00:16:32.379\nthey don't have the only knowledge that it\ntakes to perform some critical function\n\n324\n00:16:32.379 --> 00:16:33.985\nwithin the organization.\n\n325\n00:16:33.985 --> 00:16:37.041\nAll right, a lot of these kinda\nhold hands together, don't they?\n\n326\n00:16:37.041 --> 00:16:37.710\n&gt;&gt; They do, yeah.\n\n327\n00:16:37.710 --> 00:16:40.150\n&gt;&gt; Like the next one is\nseparation of duties.\n\n328\n00:16:40.150 --> 00:16:44.480\nNow, I can simplify this one,\ntwo keys on the launch pad, right?\n\n329\n00:16:44.480 --> 00:16:45.270\nThink about that, right?\n\n330\n00:16:45.270 --> 00:16:50.510\nYou don't wanna have one person that\nhas all the power, right, if you will.\n\n331\n00:16:50.510 --> 00:16:56.510\nYou need more than one person\nto complete critical tasks,\n\n332\n00:16:56.510 --> 00:16:58.280\ncritical functions within your systems,\nright?\n\n333\n00:16:58.280 --> 00:17:02.970\nFor instance, we give a basics of backup\noperators, backup and restoration, right?\n\n334\n00:17:02.970 --> 00:17:06.880\nThis is a classic example where you\nmight want separation of duties, right?\n\n335\n00:17:06.880 --> 00:17:10.990\nI don't want the backup operator that has\nthe ability to take all of that sensitive\n\n336\n00:17:10.990 --> 00:17:15.320\ninformation, store it in the safe, to\nalso have access to it to turn around and\n\n337\n00:17:15.320 --> 00:17:18.070\nrestore it to a machine.\n\n338\n00:17:18.070 --> 00:17:20.794\nAnd have access to your\nsensitive information, right,\n\n339\n00:17:20.794 --> 00:17:22.450\nit's a little bit too much power.\n\n340\n00:17:22.450 --> 00:17:25.510\nSo, what you'll do is you'll\nseparate those duties, right?\n\n341\n00:17:25.510 --> 00:17:27.500\nYou'll have a backup operator,\n\n342\n00:17:27.500 --> 00:17:33.150\nthey're privileged to take the information\nin a read-only state off of the machine.\n\n343\n00:17:33.150 --> 00:17:36.990\nHowever, they cannot turn around and\nrestore that information\n\n344\n00:17:36.990 --> 00:17:39.950\nback to the machine because then they,\nnot only have access to the data,\n\n345\n00:17:39.950 --> 00:17:42.652\nbut they can move that data\nwherever they want, right?\n\n346\n00:17:42.652 --> 00:17:45.310\nWe kinda talk about things\nlike a VM sprawl, right,\n\n347\n00:17:45.310 --> 00:17:47.970\nwhere people can just spin\nup virtual machines, right?\n\n348\n00:17:47.970 --> 00:17:49.274\nYou just mirror the environment and\n\n349\n00:17:49.274 --> 00:17:51.494\nrestore that information to\nthe virtualized environment,\n\n350\n00:17:51.494 --> 00:17:54.070\nand now that person, potentially,\nhas access to your information.\n\n351\n00:17:54.070 --> 00:17:58.634\nSo remember that, again, separation\nof duties when we talked about is\n\n352\n00:17:58.634 --> 00:18:02.678\nensuring that you have more than\none person to complete a task.\n\n353\n00:18:02.678 --> 00:18:06.197\nAnd it also restricts the power\nthat a single person has, and\n\n354\n00:18:06.197 --> 00:18:09.374\nthat's very important inside\nof your company today.\n\n355\n00:18:09.374 --> 00:18:12.939\nAll right, next one we have is clean desk,\nall right, clean desk policies.\n\n356\n00:18:12.939 --> 00:18:16.447\nAnd clean desk polices are kinda\ninteresting because I want you to\n\n357\n00:18:16.447 --> 00:18:20.483\nthink about a situation where you have\nsomebody that has PII at their desk.\n\n358\n00:18:20.483 --> 00:18:23.212\nNot their own, or maybe their own,\nbut not their own, but\n\n359\n00:18:23.212 --> 00:18:25.840\nother personal identifiable information.\n\n360\n00:18:25.840 --> 00:18:28.300\nOr they have protected\nhealthcare information, right?\n\n361\n00:18:28.300 --> 00:18:31.350\nThis happens and\ncan be a violation of HIPAA.\n\n362\n00:18:31.350 --> 00:18:34.452\nI think we mentioned this in another\nepisode, where you see this a lot, well,\n\n363\n00:18:34.452 --> 00:18:36.897\nhopefully you don't see this a lot,\nbut it does happen a lot.\n\n364\n00:18:36.897 --> 00:18:39.284\nWhere somebody prints personally\nidentifiable information, or\n\n365\n00:18:39.284 --> 00:18:40.268\nhealthcare information.\n\n366\n00:18:40.268 --> 00:18:43.362\nPrints it out on the printer,\nand leaves it there, or worse,\n\n367\n00:18:43.362 --> 00:18:45.218\nthey leave it at their desk, right?\n\n368\n00:18:45.218 --> 00:18:47.970\nWe got all this sensitive information\nthat's all over the desk.\n\n369\n00:18:47.970 --> 00:18:52.020\nSo, the clean desk policy is kind\nof protecting that liability.\n\n370\n00:18:52.020 --> 00:18:53.249\n&gt;&gt; Yeah, interesting story about that.\n\n371\n00:18:53.249 --> 00:18:56.087\nI forget who it was that was telling\nme this, they were an auditor,\n\n372\n00:18:56.087 --> 00:18:57.367\nmay have been Brian O'Hara.\n\n373\n00:18:57.367 --> 00:18:58.989\nThat he was doing an audit and\n\n374\n00:18:58.989 --> 00:19:02.850\nthey had a locked room where someone\nhad a bunch of PII on their desk.\n\n375\n00:19:02.850 --> 00:19:03.910\nHe said, you probably need to clean that.\n\n376\n00:19:03.910 --> 00:19:04.980\nThey said, no, it's a locked room,\n\n377\n00:19:04.980 --> 00:19:07.830\nonly so-and-so has access to it,\nwe're not worried about it.\n\n378\n00:19:07.830 --> 00:19:12.770\nWell, he went to them the next day and\nshowed them copies of that PII, and\n\n379\n00:19:12.770 --> 00:19:14.600\nthey said, how did you get this?\n\n380\n00:19:14.600 --> 00:19:18.270\nHe said, I walked around to the big\npicture window next to the guy's desk.\n\n381\n00:19:18.270 --> 00:19:21.260\nAnd from the outside with my smartphone,\ntook pictures\n\n382\n00:19:21.260 --> 00:19:24.300\nof the documents on his desk, blew them\nup, printed them out, here you go.\n\n383\n00:19:24.300 --> 00:19:24.921\n&gt;&gt; Perfect, right?\n\n384\n00:19:24.921 --> 00:19:30.210\n&gt;&gt; So that's a good reason right there\nalone for making sure you have tidy desks.\n\n385\n00:19:30.210 --> 00:19:33.370\n&gt;&gt; Yes, making sure that that workspace\nhas any of that information locked away.\n\n386\n00:19:33.370 --> 00:19:34.714\nRight, under lock and\n\n387\n00:19:34.714 --> 00:19:39.260\nkey where the average end user can't go\nto a window [LAUGH] and snap a picture.\n\n388\n00:19:39.260 --> 00:19:41.960\nAnd it's a scary thing to think about, but\n\n389\n00:19:41.960 --> 00:19:44.330\nthat can be an instant\nviolation of a policy.\n\n390\n00:19:44.330 --> 00:19:47.360\nWhat if that person happened to be,\nwell, I believe he is an auditor,\n\n391\n00:19:47.360 --> 00:19:50.170\nwhat happen if that happened\nto be a federal auditor?\n\n392\n00:19:50.170 --> 00:19:53.080\nYour company's got a liability on\ntheir hands that they're probably not\n\n393\n00:19:53.080 --> 00:19:55.580\ngonna recover from, or\nit's gonna take a lot of money to do so.\n\n394\n00:19:55.580 --> 00:19:59.150\nSo, keep that in mind, in fact,\nI've got an example here.\n\n395\n00:19:59.150 --> 00:20:02.028\nI've got quite a few examples of\ndifferent documentations, right?\n\n396\n00:20:02.028 --> 00:20:06.230\nThis is actually from SANS, right, so it's\nguidance that says a clean desk policy.\n\n397\n00:20:06.230 --> 00:20:08.430\nAnd they talk about an important tool,\n\n398\n00:20:08.430 --> 00:20:12.600\nensuring that sensitive information\nisn't just left on the desks.\n\n399\n00:20:12.600 --> 00:20:16.400\nSo, acceptable use policies,\nwe had to have them too.\n\n400\n00:20:16.400 --> 00:20:17.920\nAll right, what else do we got, we've got,\n\n401\n00:20:17.920 --> 00:20:19.870\nwell, the good old background check,\nright?\n\n402\n00:20:19.870 --> 00:20:24.510\nBackground Checks are important\nanytime you have an employee\n\n403\n00:20:24.510 --> 00:20:27.000\nthat is in a position of trust.\n\n404\n00:20:27.000 --> 00:20:31.140\nMaybe it's a high security clearance that\nthey need, or you're working for a company\n\n405\n00:20:31.140 --> 00:20:34.040\nthat has trade secrets that is working\nmaybe with the Department of Defense or\n\n406\n00:20:34.040 --> 00:20:35.370\nsomething like that.\n\n407\n00:20:35.370 --> 00:20:40.120\nWell, if they're in that\nhigh degree of security or\n\n408\n00:20:40.120 --> 00:20:43.500\nposition of trust, companies will\nrun background checks, right?\n\n409\n00:20:43.500 --> 00:20:47.570\nThey'll run background checks, checking\nthings like criminality, if you will.\n\n410\n00:20:47.570 --> 00:20:50.847\nChecking to see, as part of\nthe employment screening process-\n\n411\n00:20:50.847 --> 00:20:51.828\n&gt;&gt; If you've ever been\n\n412\n00:20:51.828 --> 00:20:55.180\nconvicted of breaking the Computer Fraud\nand Abuse Act of 1986?\n\n413\n00:20:55.180 --> 00:20:56.314\n&gt;&gt; Yeah, absolutely, that's a great one.\n\n414\n00:20:56.314 --> 00:20:57.820\n&gt;&gt; That might be important.\n[LAUGH] &gt;&gt; [LAUGH] That's very,\n\n415\n00:20:57.820 --> 00:21:00.815\nvery Pacific,\nas a friend of mine would say.\n\n416\n00:21:00.815 --> 00:21:04.171\n[LAUGH] But yeah, so\nyou have to worry about background checks.\n\n417\n00:21:04.171 --> 00:21:07.955\nNow, they also, and I wanna go ahead and\nthrow this in the same thing,\n\n418\n00:21:07.955 --> 00:21:12.019\nkinda jumping out of our notes here\nbecause they call out adverse actions.\n\n419\n00:21:12.019 --> 00:21:14.297\nAnd I kinda put it at\nthe last of the list, but\n\n420\n00:21:14.297 --> 00:21:17.150\nI wanna kind of tie the two together,\nright?\n\n421\n00:21:17.150 --> 00:21:22.130\nAn adverse action can be an existing\nemployee that maybe you're firing for\n\n422\n00:21:22.130 --> 00:21:27.760\na potential, if you will, violation of\nany general policy, a security policy.\n\n423\n00:21:27.760 --> 00:21:32.430\nMaybe they've expose trade information\nout there on social media networks or\n\n424\n00:21:32.430 --> 00:21:34.180\nthrough different applications.\n\n425\n00:21:34.180 --> 00:21:37.320\nMaybe they're using a combination of\ntheir personal email when they should be\n\n426\n00:21:37.320 --> 00:21:38.480\nusing the company's email.\n\n427\n00:21:38.480 --> 00:21:42.490\nWell, adverse actions can also happen\nwhen you do a background check, and\n\n428\n00:21:42.490 --> 00:21:47.315\nyou deny somebody employment based\non the check that you've run.\n\n429\n00:21:47.315 --> 00:21:49.550\nSo, also understand adverse actions.\n\n430\n00:21:49.550 --> 00:21:50.440\nAdverse actions,\n\n431\n00:21:50.440 --> 00:21:54.530\na lot of times when you do a little bit of\nresearch on it you'll see, it can become\n\n432\n00:21:54.530 --> 00:21:58.160\nor it can follow what a company does\nwhen they do a background check.\n\n433\n00:21:58.160 --> 00:22:01.680\nAnd they learn, well, maybe this\nperson isn't to be trusted, right?\n\n434\n00:22:01.680 --> 00:22:05.330\nWhatever we've come acrost in\nthe background check, it didn't pan out.\n\n435\n00:22:05.330 --> 00:22:08.420\nAll right, so\nwhat else do we got there, Dan?\n\n436\n00:22:08.420 --> 00:22:11.160\nWe've got a few more things here,\nwe've got exit interviews, right?\n\n437\n00:22:11.160 --> 00:22:14.050\n&gt;&gt; Speaking of someone being let go or\nleaving the company.\n\n438\n00:22:14.050 --> 00:22:16.486\n&gt;&gt; Yeah, definitely, so exit interviews\nare actually they're a good thing,\n\n439\n00:22:16.486 --> 00:22:18.026\nthey're not supposed to be a bad thing,\nright?\n\n440\n00:22:18.026 --> 00:22:21.730\nIf somebody gets fired and\nthey're disgruntled, if you will,\n\n441\n00:22:21.730 --> 00:22:25.238\nthey probably couldn't care\nless about an exit interview.\n\n442\n00:22:25.238 --> 00:22:27.783\nAnd they're not gonna let the door\nhit them on the way out, right,\n\n443\n00:22:27.783 --> 00:22:28.790\nthey're gonna be gone.\n\n444\n00:22:28.790 --> 00:22:32.010\nSo, this is more about people that\nare leaving your company under\n\n445\n00:22:32.010 --> 00:22:33.710\ngood circumstances, right?\n\n446\n00:22:33.710 --> 00:22:36.524\nThis is a good way for\nthe company to perform,\n\n447\n00:22:36.524 --> 00:22:40.609\njust part of the company or\nthe person leaving the organization.\n\n448\n00:22:40.609 --> 00:22:43.274\nWe get some constructive criticism, right,\n\n449\n00:22:43.274 --> 00:22:46.909\na chance to understand the reason\nthat that person is leaving.\n\n450\n00:22:46.909 --> 00:22:51.009\nAnd maybe the person's leaving under good\nterms and they're going off to a better\n\n451\n00:22:51.009 --> 00:22:53.993\nposition that the company\njust can't offer them, right?\n\n452\n00:22:53.993 --> 00:22:57.200\nNot a bad thing, but maybe the company\nwants to know that, right?\n\n453\n00:22:57.200 --> 00:22:59.270\nIt's kinda like the lesson learned thing.\n\n454\n00:22:59.270 --> 00:23:03.730\nAnd, again, it allows the employee\nas well to leave on a good note so\n\n455\n00:23:03.730 --> 00:23:06.640\nthat they can use them\nas a future reference.\n\n456\n00:23:08.110 --> 00:23:09.649\nAll right, now we got a big one here,\n\n457\n00:23:09.649 --> 00:23:11.854\nthis is the role based awareness training,\nright?\n\n458\n00:23:11.854 --> 00:23:15.650\nAnd I wanna kinda change the name even\nthough that's what the objective is.\n\n459\n00:23:15.650 --> 00:23:20.020\nI want you to think of it as in\nthe context of role-based security\n\n460\n00:23:20.020 --> 00:23:21.560\nawareness training, right?\n\n461\n00:23:21.560 --> 00:23:24.790\nWe have different types of users\nwithin our network, right,\n\n462\n00:23:24.790 --> 00:23:26.690\nwe have data owners, right?\n\n463\n00:23:26.690 --> 00:23:29.229\nNow, a data owner could be\nsomebody that is assigned\n\n464\n00:23:30.440 --> 00:23:32.350\nownership over an asset, right?\n\n465\n00:23:32.350 --> 00:23:34.220\nTypically when we're\ntalking about a data owner,\n\n466\n00:23:34.220 --> 00:23:36.730\nwe're talking about some\nkinda information asset.\n\n467\n00:23:36.730 --> 00:23:39.970\nAnd when they're assign that, they\ndefine what the information is, right?\n\n468\n00:23:39.970 --> 00:23:41.582\nThey assign the value of the data,\n\n469\n00:23:41.582 --> 00:23:44.869\nthey define what level of protection\nneeds to be on that data, right?\n\n470\n00:23:44.869 --> 00:23:49.282\nConfidential information versus top secret\ninformation are gonna be handled a little\n\n471\n00:23:49.282 --> 00:23:52.856\nbit different versus unclassified and\npublic information, right?\n\n472\n00:23:52.856 --> 00:23:55.509\nSo it's up to the data owner\nto understand this and\n\n473\n00:23:55.509 --> 00:23:59.420\nactually define what level of\nprotection it's going to have.\n\n474\n00:23:59.420 --> 00:24:01.950\nOther things like who is going\nto access this information?\n\n475\n00:24:01.950 --> 00:24:04.180\nWho's allowed to access the information?\n\n476\n00:24:04.180 --> 00:24:05.880\nWe also have things like system owners.\n\n477\n00:24:05.880 --> 00:24:08.380\nSystem owners have to understand\nwhat the best practices are.\n\n478\n00:24:08.380 --> 00:24:12.490\nIn another episode, we talked about secure\nconfiguration guides and best practices.\n\n479\n00:24:12.490 --> 00:24:16.960\nIt's up to the system owner to understand\nwhat those best practices are and how you\n\n480\n00:24:16.960 --> 00:24:20.760\nimplement them, and then follow through\nto make sure that they are implemented.\n\n481\n00:24:20.760 --> 00:24:22.700\nVersus a systems administrator, right?\n\n482\n00:24:22.700 --> 00:24:27.610\nThe systems administrator understands\nthe system configuration, understands what\n\n483\n00:24:27.610 --> 00:24:30.830\nlevel of information is within the system\nand how to protect that information.\n\n484\n00:24:30.830 --> 00:24:34.590\nThey're actually\nimplementing this as well.\n\n485\n00:24:34.590 --> 00:24:37.230\nUnderstanding industry wide standards,\nright?\n\n486\n00:24:37.230 --> 00:24:41.310\nIf we have HIPAA compliance,\nPCI compliance, if you will.\n\n487\n00:24:41.310 --> 00:24:42.250\nFIPS compliance.\n\n488\n00:24:42.250 --> 00:24:45.190\nUnderstanding what the industry wide\nstandards are to make sure that\n\n489\n00:24:45.190 --> 00:24:46.779\nthey are adhering to them.\n\n490\n00:24:46.779 --> 00:24:48.480\nUsers, right?\n\n491\n00:24:48.480 --> 00:24:50.650\nUsers have a different role\nwithin our companies, right?\n\n492\n00:24:50.650 --> 00:24:54.940\nThey have to understand basic, and all\nof these really need to understand this,\n\n493\n00:24:54.940 --> 00:24:57.030\nbut computer security basics.\n\n494\n00:24:57.030 --> 00:25:02.390\nAt least once your users to understand\nwhy they shouldn't open e-mails, right?\n\n495\n00:25:02.390 --> 00:25:05.065\nIn fact, kind of an interesting and\n\n496\n00:25:05.065 --> 00:25:08.640\nrelevant to the time\nthat we're shooting this.\n\n497\n00:25:08.640 --> 00:25:10.030\nAnd what is today's date?\n\n498\n00:25:10.030 --> 00:25:14.594\nSo this is May 4th, 2017 here,\nand we just learned today about\n\n499\n00:25:14.594 --> 00:25:18.695\na major phishing scam that's\ngoing through Gmail, right?\n\n500\n00:25:18.695 --> 00:25:20.260\nWhere it looks very, very legit.\n\n501\n00:25:20.260 --> 00:25:24.170\nWell, if your users have\na basic understanding\n\n502\n00:25:24.170 --> 00:25:27.240\nof the role that they have in their\ncompany, how to use their e-mails, why\n\n503\n00:25:27.240 --> 00:25:30.440\nthey shouldn't open those e-mails, if they\ndon't understand who they're coming from.\n\n504\n00:25:30.440 --> 00:25:31.830\nDon't open attachments.\n\n505\n00:25:31.830 --> 00:25:34.720\nDon't enable things like macros in Office,\nright?\n\n506\n00:25:34.720 --> 00:25:39.460\nIf they're not aware of that happening or\nwhat can happen, then you've got a,\n\n507\n00:25:39.460 --> 00:25:42.542\nyou've got some kind of security\nvulnerability inside of your company.\n\n508\n00:25:42.542 --> 00:25:46.965\nAll right, so, and then a couple of\nother things too like privilege users.\n\n509\n00:25:46.965 --> 00:25:48.670\nPrivileged users obviously have access,\n\n510\n00:25:48.670 --> 00:25:51.956\nand a few of these could be combined\ninto privileged users, right?\n\n511\n00:25:51.956 --> 00:25:54.385\nA systems administrator's\ntypically a privilege user, right?\n\n512\n00:25:54.385 --> 00:25:56.598\nThey have access,\na higher level of access and\n\n513\n00:25:56.598 --> 00:26:00.138\na higher level of rights that they can\ndo on the assets within the company.\n\n514\n00:26:00.138 --> 00:26:04.892\nSo they have to understand what their\nrole is inside of the company, too, and\n\n515\n00:26:04.892 --> 00:26:07.964\nhow to ensure that the security\nstays where it is so\n\n516\n00:26:07.964 --> 00:26:13.630\nthat standard users don't get access,\nunauthorized access, if you will.\n\n517\n00:26:13.630 --> 00:26:15.580\nLast one is the executive user.\n\n518\n00:26:15.580 --> 00:26:18.660\nAnd the executive user, they're the,\nwhen we say the top dogs,\n\n519\n00:26:18.660 --> 00:26:21.420\nthey're responsible for\nthings like management, right?\n\n520\n00:26:21.420 --> 00:26:25.950\nUnderstanding compliance, understanding if\nthe company is adhering to the compliance,\n\n521\n00:26:25.950 --> 00:26:28.340\nthe development of the policies, right?\n\n522\n00:26:28.340 --> 00:26:30.880\nAs well as what are the risks factors,\nright?\n\n523\n00:26:30.880 --> 00:26:33.720\nYour standard user doesn't\nknow the risk factors.\n\n524\n00:26:33.720 --> 00:26:36.650\nThey probably haven't looked at\nany risk assessments, right?\n\n525\n00:26:36.650 --> 00:26:38.550\nManagers, executive users, have.\n\n526\n00:26:38.550 --> 00:26:40.940\nThat's part of their role\ninside of your company.\n\n527\n00:26:40.940 --> 00:26:45.280\nSo again, some basic role based\nsecurity awareness training, and\n\n528\n00:26:45.280 --> 00:26:48.910\nunderstanding that we do have\ndifferent levels of users.\n\n529\n00:26:50.072 --> 00:26:53.020\nAll right, lets see a couple of other\nthings that we need to talk about.\n\n530\n00:26:53.020 --> 00:26:57.611\nI know that we're running a little bit\nclose on time here, Dan, but NDA's right?\n\n531\n00:26:57.611 --> 00:27:00.450\nNon-disclosure agreements.\n\n532\n00:27:00.450 --> 00:27:01.930\nThese are important, right?\n\n533\n00:27:01.930 --> 00:27:06.470\nEspecially if you have a company that's\ndealing with products that maybe have yet\n\n534\n00:27:06.470 --> 00:27:08.280\nto be released to market.\n\n535\n00:27:08.280 --> 00:27:12.130\nMaybe even so,\nI know that I had a friend that got,\n\n536\n00:27:12.130 --> 00:27:15.090\nwe both started studying computers and\nstuff at the same time and\n\n537\n00:27:15.090 --> 00:27:18.870\ngetting certifications, and I went off to\nteach and he went off actually to work for\n\n538\n00:27:18.870 --> 00:27:22.290\na company that was working with Department\nof Defense making unmanned spy planes, or\n\n539\n00:27:22.290 --> 00:27:23.410\nunmanned drones, right?\n\n540\n00:27:24.650 --> 00:27:26.620\nAerial vehicles, if you will, right?\n\n541\n00:27:26.620 --> 00:27:27.540\nAUVs, I think\n&gt;&gt; UAVs.\n\n542\n00:27:27.540 --> 00:27:28.460\n&gt;&gt; UAVs, thank you.\n\n543\n00:27:28.460 --> 00:27:31.573\nI'll get that acronym eventually [LAUGH].\n\n544\n00:27:31.573 --> 00:27:35.820\nAnd a part of the Department of Defense\ncompliance was that they had to sign\n\n545\n00:27:35.820 --> 00:27:39.630\nNDAs that said, no, we're not\ngonna discuss out of the company,\n\n546\n00:27:39.630 --> 00:27:41.030\nwhat it is that we're doing right now.\n\n547\n00:27:41.030 --> 00:27:45.700\nSo, non-disclosure agreements ensuring\nthat information that's not public does,\n\n548\n00:27:45.700 --> 00:27:47.560\nor yeah, that's confidential,\nif you will, or\n\n549\n00:27:47.560 --> 00:27:52.000\ntrade secret isn't released to the public\nbefore it's time, or if at all.\n\n550\n00:27:52.000 --> 00:27:54.178\n&gt;&gt; So, NDAs are basically\nthe first two rules of fight club.\n\n551\n00:27:54.178 --> 00:27:55.715\n&gt;&gt; That's right, yeah.\n\n552\n00:27:55.715 --> 00:27:57.988\nNever talk about fight club.\n\n553\n00:27:57.988 --> 00:28:00.172\nNow, the next one we kind of talked about,\n\n554\n00:28:00.172 --> 00:28:04.130\nactually the next two we've kind of\ntalked about in other episodes, right?\n\n555\n00:28:04.130 --> 00:28:05.550\nOn-boarding process.\n\n556\n00:28:05.550 --> 00:28:09.330\nThe on-boarding process is just a very\ndetailed process of how you're essentially\n\n557\n00:28:09.330 --> 00:28:13.030\ntaking a stranger and\ntrusting them in your organization.\n\n558\n00:28:13.030 --> 00:28:14.080\nIf you think about it, that's what you do.\n\n559\n00:28:14.080 --> 00:28:16.690\nWhen you hire an employee,\nyou do these background checks.\n\n560\n00:28:16.690 --> 00:28:19.320\nIt can only tell you so\nmuch about their personality.\n\n561\n00:28:19.320 --> 00:28:21.870\nSo you're essentially\ntaking a stranger and\n\n562\n00:28:21.870 --> 00:28:23.878\nyou're bringing them into\na trust relationship.\n\n563\n00:28:23.878 --> 00:28:28.460\nSo the on-boarding process dictates\nexactly how we bring that person\n\n564\n00:28:28.460 --> 00:28:32.200\ninto the company, which could be followed\nby something else that on our list, right?\n\n565\n00:28:32.200 --> 00:28:32.900\nAUPs.\n\n566\n00:28:32.900 --> 00:28:35.490\nAcceptable use policies, right?.\n\n567\n00:28:35.490 --> 00:28:38.540\nAcceptable behavioral policies as well.\n\n568\n00:28:38.540 --> 00:28:40.080\nHow do we use the wireless network?\n\n569\n00:28:40.080 --> 00:28:42.670\nIf you have BYOD,\nyou're bringing your own phone.\n\n570\n00:28:42.670 --> 00:28:46.900\nCan you access the wireless network and\nturn around and access company assets?\n\n571\n00:28:46.900 --> 00:28:49.720\nI'm not sure,\nit's not a one size fits all, right?\n\n572\n00:28:49.720 --> 00:28:51.610\n&gt;&gt; And if it's not explicitly put in AUP,\n\n573\n00:28:51.610 --> 00:28:55.510\nand they do it, then you have no leg\nto stand on as far as repercussions.\n\n574\n00:28:55.510 --> 00:28:56.182\n&gt;&gt; Yeah, you're liable.\n\n575\n00:28:56.182 --> 00:28:57.970\n&gt;&gt; Yeah.\n&gt;&gt; The company's liable, not, and\n\n576\n00:28:57.970 --> 00:29:01.740\nit could be, cuz remember, not every\nsecurity breach has to intentional.\n\n577\n00:29:01.740 --> 00:29:05.620\nWe always think of, and I always joke\nabout, I always pick on poor Tom Cruise,\n\n578\n00:29:05.620 --> 00:29:06.450\nMission Impossible,\n\n579\n00:29:06.450 --> 00:29:10.030\ncoming down through the ceiling with\na bunch of ropes tied to him, right?\n\n580\n00:29:10.030 --> 00:29:13.030\nBut it doesn't have to be that, right?\n\n581\n00:29:13.030 --> 00:29:17.050\nIt can be something as simple\nas an internal person that\n\n582\n00:29:17.050 --> 00:29:19.230\ndidn't go through continuing education,\nright?\n\n583\n00:29:19.230 --> 00:29:20.760\nContinually aware, right?\n\n584\n00:29:20.760 --> 00:29:23.330\nContinue education is a very\ngood thing because, again,\n\n585\n00:29:23.330 --> 00:29:27.990\nit helps to reduce the amount of security\nbreaches you have through user awareness.\n\n586\n00:29:27.990 --> 00:29:33.130\nBut it's something that, in this industry,\nyou can't stay stagnant, right?\n\n587\n00:29:33.130 --> 00:29:36.600\nBecause what we're telling you today,\neight months from now\n\n588\n00:29:36.600 --> 00:29:38.830\nwe might have additional things\nthat we need to be aware of, right?\n\n589\n00:29:38.830 --> 00:29:45.590\nAnd that's why it promotes things like\ncontinued participation and communication.\n\n590\n00:29:45.590 --> 00:29:48.707\nAgain, the big thing is to\npromote employee awareness and\n\n591\n00:29:48.707 --> 00:29:52.360\na competency on new security threats\nthat are coming out all the time.\n\n592\n00:29:52.360 --> 00:29:54.260\nYou might hear of something called SETA.\n\n593\n00:29:54.260 --> 00:29:55.900\nOr I always want to say SATA.\n\n594\n00:29:55.900 --> 00:29:57.040\nBut we're not talking about hard drives.\n\n595\n00:29:57.040 --> 00:30:00.300\nWe're talking about security,\neducation, and training awareness.\n\n596\n00:30:00.300 --> 00:30:01.460\nLittle acronym there.\n\n597\n00:30:01.460 --> 00:30:04.180\nIf you ever wanna find out\na little bit more information,\n\n598\n00:30:04.180 --> 00:30:06.090\nNIST has this information out there.\n\n599\n00:30:06.090 --> 00:30:07.689\nSo does.\n\n600\n00:30:07.689 --> 00:30:08.972\nGot some great documentation on this.\n\n601\n00:30:08.972 --> 00:30:12.340\nI wouldn't worry too much about\nthe minutiae for the Security Plus exam,\n\n602\n00:30:12.340 --> 00:30:17.200\njust being aware that it is a part of\nour policies and procedures in order to\n\n603\n00:30:17.200 --> 00:30:19.820\nmitigate the risk of these additional\nsecurity vulnerabilities or\n\n604\n00:30:19.820 --> 00:30:20.830\nbreaches that can happen.\n\n605\n00:30:22.090 --> 00:30:23.600\nAll right, Dan, well, I think we got it.\n\n606\n00:30:23.600 --> 00:30:26.430\nJust as a recap real quick,\nyou got a couple other ones, and\n\n607\n00:30:26.430 --> 00:30:27.390\nI kinda included them.\n\n608\n00:30:27.390 --> 00:30:30.790\nRemember the AUP, Acceptable Use Policies,\nand remember adverse actions.\n\n609\n00:30:30.790 --> 00:30:34.950\nAgain, adverse actions can be happening,\nor can happen if an employer\n\n610\n00:30:34.950 --> 00:30:37.445\nrefuses employment based on\na background check, right?\n\n611\n00:30:37.445 --> 00:30:41.285\nIt can also happen inside of your company,\nif you fire somebody for\n\n612\n00:30:41.285 --> 00:30:44.065\na breach of contract,\na breach of a policy, if you will.\n\n613\n00:30:44.065 --> 00:30:46.495\nAgain, like I said,\nusing things like personal e-mails.\n\n614\n00:30:46.495 --> 00:30:48.865\nSo, lot of policies, lot of procedures.\n\n615\n00:30:48.865 --> 00:30:53.160\nI know sometimes it isn't the fun stuff,\nbut it's going to be probably about 80% of\n\n616\n00:30:53.160 --> 00:30:59.340\nyour security days, if you will,\nthat you do inside of your company.\n\n617\n00:30:59.340 --> 00:30:59.880\n&gt;&gt; That's right.\n\n618\n00:30:59.880 --> 00:31:03.420\nA lot of stuff that we have to go through\njust as policies and procedures there.\n\n619\n00:31:03.420 --> 00:31:04.940\nEverywhere we have to pay attention.\n\n620\n00:31:04.940 --> 00:31:08.490\nI know it's extremely, it can be\nfrustrating, it can be a bit boring.\n\n621\n00:31:08.490 --> 00:31:10.718\nIt can be a little magoo, mundane.\n\n622\n00:31:10.718 --> 00:31:14.900\nBut they are important parts of\nour security posture, right?\n\n623\n00:31:14.900 --> 00:31:17.490\nImportant parts of our security\ninside of our company.\n\n624\n00:31:17.490 --> 00:31:18.880\nSo if we don't pay attention to them,\n\n625\n00:31:18.880 --> 00:31:21.100\nwe're setting ourselves up for\na real disaster.\n\n626\n00:31:21.100 --> 00:31:23.600\nSo make sure you understand all\nyour acceptable use policies.\n\n627\n00:31:23.600 --> 00:31:26.980\nIf you got NDAs, read them over,\nknow what you can and cannot do.\n\n628\n00:31:26.980 --> 00:31:29.590\nLearn how to properly\nmanage your personnel, and\n\n629\n00:31:29.590 --> 00:31:33.350\nmake sure that they all have looked at\nproper policy and procedure as well.\n\n630\n00:31:33.350 --> 00:31:35.820\nThat being said, Wes,\nwe've gone through a lot of stuff today.\n\n631\n00:31:35.820 --> 00:31:37.270\nWe've well exhausted our time.\n\n632\n00:31:37.270 --> 00:31:40.770\nWe do thank our audience for joining us,\nbut it is time for us to sign off.\n\n633\n00:31:40.770 --> 00:31:43.040\nFor ITProTV, I've been you host,\nDaniel Lowrie.\n\n634\n00:31:43.040 --> 00:31:43.883\n&gt;&gt; And I'm Wes Bryan.\n\n635\n00:31:43.883 --> 00:31:46.372\n&gt;&gt; And we'll see you next time.\n\n636\n00:31:46.372 --> 00:31:52.476\n[MUSIC]\n\n637\n00:31:52.476 --> 00:31:55.569\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216502494"
        },
        {
          "description": "Wes and Zach cover identifying critical systems, privacy threshold assessments, privacy impact assessments, and mission essential functions.",
          "length": "1723",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-2-impact_business_analysis-050817-PGM.00_28_27_02.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-2-impact_business_analysis-050817-PGM.00_28_27_02.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-2-impact_business_analysis-050817-PGM.00_28_27_02.Still001-sm.jpg",
          "title": "Impact Business Analysis",
          "transcript": "WEBVTT\n\n1\n00:00:00.000 --> 00:00:01.898\nWelcome to ITProTV.\n\n2\n00:00:01.898 --> 00:00:06.473\n&gt;&gt; [CROSSTALK].\n\n3\n00:00:06.473 --> 00:00:08.381\n[MUSIC]\n\n4\n00:00:08.381 --> 00:00:11.947\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.947 --> 00:00:15.129\n&gt;&gt; Hello, and thank you again for\nwatching ITProTV,\n\n6\n00:00:15.129 --> 00:00:17.354\nhelping you learn wherever you go.\n\n7\n00:00:17.354 --> 00:00:22.800\nAnd we're gonna jump into some more\nabout CompTIA Security+ with our IT pro,\n\n8\n00:00:22.800 --> 00:00:23.635\nWes Bryan.\n\n9\n00:00:23.635 --> 00:00:24.493\nWe're not worthy!\n\n10\n00:00:24.493 --> 00:00:26.922\n&gt;&gt; [LAUGH]\n&gt;&gt; I'm not worthy, I don't know.\n\n11\n00:00:26.922 --> 00:00:28.315\n&gt;&gt; Thanks for having me back,\nZach, I do appreciate it.\n\n12\n00:00:28.315 --> 00:00:29.557\nGreat to be here with the ITProTV staff.\n\n13\n00:00:29.557 --> 00:00:32.689\nAnd that's right, we get to look at,\nwell, some more of the red tape, right?\n\n14\n00:00:32.689 --> 00:00:35.343\nWe always like,\nwhen we talk about security,\n\n15\n00:00:35.343 --> 00:00:38.690\nwe like to think about the systems\nthat we have to protect.\n\n16\n00:00:38.690 --> 00:00:42.347\nWe think of things like malware and\npassword cracking, all the fun stuff.\n\n17\n00:00:42.347 --> 00:00:45.081\nAnd then, of course,\nwe have to get into some of the paperwork.\n\n18\n00:00:45.081 --> 00:00:48.117\nKeep in mind that some of your\nsecurity implementations and\n\n19\n00:00:48.117 --> 00:00:51.104\nyour security training is gonna\nbe a lot about paperwork.\n\n20\n00:00:51.104 --> 00:00:52.126\n&gt;&gt; And that's what this is all about.\n\n21\n00:00:52.126 --> 00:00:53.577\nIt's impact business analysis, right?\n\n22\n00:00:53.577 --> 00:00:54.642\n&gt;&gt; That's right.\n\n23\n00:00:54.642 --> 00:00:55.658\nSo, let's go ahead, and\n\n24\n00:00:55.658 --> 00:00:58.313\nlet's dive into some of the components\nthat we have to worry about.\n\n25\n00:00:58.313 --> 00:01:00.329\nImpact, where can we see impact?\n\n26\n00:01:00.329 --> 00:01:04.534\nOne of the ones that they call out is,\nwell, it's really about the impact to\n\n27\n00:01:04.534 --> 00:01:07.969\nthe employee health, and\nspecifically, things like life.\n\n28\n00:01:07.969 --> 00:01:12.269\nWe wanna make sure that we're protecting\nagainst events that could cause,\n\n29\n00:01:12.269 --> 00:01:16.310\nobviously, cause us probably the worst\nimpact there is, human life.\n\n30\n00:01:16.310 --> 00:01:18.381\nOther things is like property.\n\n31\n00:01:18.381 --> 00:01:21.163\nAnd if we have some kind of disaster,\nthis could be a natural disaster.\n\n32\n00:01:21.163 --> 00:01:23.982\nI mean, I don't have to tell the people\nthat are living on the San Andreas Fault\n\n33\n00:01:23.982 --> 00:01:26.940\nthat you have to have things\nlike earthquake insurance.\n\n34\n00:01:26.940 --> 00:01:29.820\nHere in Gainesville, there are certain\nareas within Gainesville that are in\n\n35\n00:01:29.820 --> 00:01:32.000\nflood zones,\nthey have to have extra flood protection.\n\n36\n00:01:32.000 --> 00:01:34.610\nSo, it could be the property themselves.\n\n37\n00:01:34.610 --> 00:01:37.610\nAgain, safety, I guess you could say,\nagain, human safety.\n\n38\n00:01:37.610 --> 00:01:40.682\nI don't care how expensive\nsomething is in your company.\n\n39\n00:01:40.682 --> 00:01:42.730\nNow, you might not wanna tell\nthe C-level employees this.\n\n40\n00:01:42.730 --> 00:01:46.669\nBut I don't care exactly how expensive\nsomething is inside of your network,\n\n41\n00:01:46.669 --> 00:01:48.070\nit can always be replaced.\n\n42\n00:01:48.070 --> 00:01:50.937\nYou can't, you guys are ones in billions.\n\n43\n00:01:50.937 --> 00:01:55.158\nSo there should be something in place to\nprotect the safety of the employees that\n\n44\n00:01:55.158 --> 00:01:57.114\nare working for that organization.\n\n45\n00:01:57.114 --> 00:01:59.409\nIf there's not, run to the hills.\n\n46\n00:01:59.409 --> 00:02:00.304\nNo, just kidding,\n\n47\n00:02:00.304 --> 00:02:03.584\nbut you should definitely consider\nmaybe working somewhere else [LAUGH].\n\n48\n00:02:03.584 --> 00:02:05.999\nFinancial, we always have\nto worry about financial.\n\n49\n00:02:05.999 --> 00:02:09.512\nWe talked in another episode about some of\nthe impacts that you could see on major\n\n50\n00:02:09.512 --> 00:02:12.938\ncompanies who have outages within their\nsystems, Amazon being one of them.\n\n51\n00:02:12.938 --> 00:02:15.979\nBecause Amazon is so huge and\nglobal that, I mean,\n\n52\n00:02:15.979 --> 00:02:18.880\nthey support other large businesses.\n\n53\n00:02:18.880 --> 00:02:23.160\nWhen you're a business that's so big\nthat Google's coming to you to use your\n\n54\n00:02:23.160 --> 00:02:27.710\ninfrastructure, Facebook, Twitter, and\nall these other companies, it's very,\n\n55\n00:02:27.710 --> 00:02:32.540\nvery important that you maintain a certain\nlevel of availability for your services.\n\n56\n00:02:32.540 --> 00:02:36.350\nAnd that can certainly have some\npretty bad financial consequences\n\n57\n00:02:36.350 --> 00:02:37.885\nto your company if you don't.\n\n58\n00:02:37.885 --> 00:02:41.405\nIt could cost you millions\nof dollars an hour.\n\n59\n00:02:41.405 --> 00:02:44.843\nL.L.Bean, and\nI don't know if it's this way today, but\n\n60\n00:02:44.843 --> 00:02:49.450\nI read there was a study where L.L.Bean\nlost access to some of their servers and\n\n61\n00:02:49.450 --> 00:02:53.195\nit was costing them right around\n$1 million an hour downtime.\n\n62\n00:02:53.195 --> 00:02:54.069\n&gt;&gt; Yikes.\n\n63\n00:02:54.069 --> 00:02:57.105\n&gt;&gt; So again, if you think about\ncompanies that are that large,\n\n64\n00:02:57.105 --> 00:02:59.558\nthis could be a lot of\nfinancial repercussions.\n\n65\n00:02:59.558 --> 00:03:04.453\nSo it is important to understand the\nimpact that an incident could happen when\n\n66\n00:03:04.453 --> 00:03:06.956\nit comes to happening to your company.\n\n67\n00:03:06.956 --> 00:03:08.423\n&gt;&gt; A million dollars\nan hour is a lot of parkas!\n\n68\n00:03:08.423 --> 00:03:10.672\n&gt;&gt; [LAUGH] It really is, that's for sure.\n\n69\n00:03:10.672 --> 00:03:13.663\nReputation, that's a big one as well.\n\n70\n00:03:13.663 --> 00:03:15.424\nReputation is important.\n\n71\n00:03:15.424 --> 00:03:16.688\nLet me give you an example now.\n\n72\n00:03:16.688 --> 00:03:20.402\nWell, maybe some of you guys are familiar\nwith the big thing that went on to Target,\n\n73\n00:03:20.402 --> 00:03:24.089\nwhere Target had millions of customer\ninformation that got into the wrong hands.\n\n74\n00:03:24.089 --> 00:03:25.948\nIt cost them millions of dollars, too.\n\n75\n00:03:25.948 --> 00:03:29.900\nBut it also affected\ntheir ongoing reputation.\n\n76\n00:03:29.900 --> 00:03:32.870\nHow many of you guys have seen something\nhappen to a company like that?\n\n77\n00:03:32.870 --> 00:03:36.810\nMaybe some of you guys still\nhear Enron jokes out there.\n\n78\n00:03:36.810 --> 00:03:39.500\nI mean, this is, something happened to\na company, now, theirs was fraudulent,\n\n79\n00:03:39.500 --> 00:03:41.990\nof course, but it affected the employees.\n\n80\n00:03:41.990 --> 00:03:43.760\nSo reputation is a big thing.\n\n81\n00:03:43.760 --> 00:03:46.970\nAnd your reputation can tank and\nyou might never get it back.\n\n82\n00:03:46.970 --> 00:03:50.051\nIf I think about good shoes right now,\nif I was to think, okay,\n\n83\n00:03:50.051 --> 00:03:53.149\nwhat shoes am I gonna go buy if I\nwant really good running shoes?\n\n84\n00:03:53.149 --> 00:03:56.490\nI can think of people like Nike,\nAdidas, Reebok.\n\n85\n00:03:56.490 --> 00:03:59.479\nBecause we trust the brand,\nwe know they make good products.\n\n86\n00:03:59.479 --> 00:04:04.326\nBut you tarnish their image, and that\ntrust that you have in the brand starts to\n\n87\n00:04:04.326 --> 00:04:08.308\nwane, and that causes the company\nmillions of dollars as well.\n\n88\n00:04:08.308 --> 00:04:12.880\n&gt;&gt; And there's even a problem\ntrusting off-site security companies.\n\n89\n00:04:12.880 --> 00:04:14.061\n&gt;&gt; Most definitely.\n&gt;&gt; Because hey,\n\n90\n00:04:14.061 --> 00:04:15.387\nthey can be hacked as well.\n\n91\n00:04:15.387 --> 00:04:17.260\n&gt;&gt; Let me give you an example\nthat's a great example.\n\n92\n00:04:17.260 --> 00:04:20.854\nBack about four years ago,\nan external certificate authority\n\n93\n00:04:20.854 --> 00:04:23.633\nout there on the Internet\nthat is responsible for\n\n94\n00:04:23.633 --> 00:04:28.516\nissuing digital certificates that we trust\nwhen we visit websites for e-commerce,\n\n95\n00:04:28.516 --> 00:04:32.691\ntheir private key was stolen and\nthey tried to brush it under the carpet.\n\n96\n00:04:32.691 --> 00:04:35.215\nWell, that company's no\nlonger in business anymore.\n\n97\n00:04:35.215 --> 00:04:38.389\nAnd again, cuz it was a reputation thing,\nthe reputation,\n\n98\n00:04:38.389 --> 00:04:40.329\nthey could never recover from that.\n\n99\n00:04:40.329 --> 00:04:43.201\nSo again, you have to worry about\nthings like reputation, too,\n\n100\n00:04:43.201 --> 00:04:46.562\nbecause once your reputation's tarnished,\nit is very hard to get it back.\n\n101\n00:04:46.562 --> 00:04:50.661\nAnd like I said, you can see some of the\nrecent things that have happened that have\n\n102\n00:04:50.661 --> 00:04:53.088\ncaused businesses to\nhave reputation issues.\n\n103\n00:04:53.088 --> 00:04:55.679\nAnd a lot of great memes going across\nFacebook, I'm sure [LAUGH], too.\n\n104\n00:04:55.679 --> 00:04:57.354\nSo it is important.\n\n105\n00:04:57.354 --> 00:05:00.520\nSo, let's go ahead and\ntalk about some additional things.\n\n106\n00:05:00.520 --> 00:05:04.777\nFor instance, they call out things\nlike mission-essential functions.\n\n107\n00:05:04.777 --> 00:05:09.451\nAnd this is definitely something we have\nto worry about inside of our environment.\n\n108\n00:05:09.451 --> 00:05:10.395\n&gt;&gt; Yeah, I'd say so.\n\n109\n00:05:10.395 --> 00:05:13.536\nNow, when it comes to\nidentification of critical systems,\n\n110\n00:05:13.536 --> 00:05:15.948\nwhat are some of the things\nthat we can expect?\n\n111\n00:05:15.948 --> 00:05:16.845\n&gt;&gt; Okay.\n\n112\n00:05:16.845 --> 00:05:17.918\n&gt;&gt; And that's what you're leading up to,\nright?\n\n113\n00:05:17.918 --> 00:05:18.736\n&gt;&gt; Yeah, absolutely.\n\n114\n00:05:18.736 --> 00:05:19.698\n&gt;&gt; Okay.\n\n115\n00:05:19.698 --> 00:05:20.546\n&gt;&gt; That's a good question.\n\n116\n00:05:20.546 --> 00:05:24.181\nSo, for instance, understand that your\nfunctions could be services, if you will,\n\n117\n00:05:24.181 --> 00:05:26.413\nthey could be products,\nthey could be operations.\n\n118\n00:05:26.413 --> 00:05:28.976\nIf it's a service,\nit could be a shipping service.\n\n119\n00:05:28.976 --> 00:05:32.699\nIf it's a product, it could be an\ne-commerce product that somebody's buying\n\n120\n00:05:32.699 --> 00:05:34.485\nand now they no longer have access to.\n\n121\n00:05:34.485 --> 00:05:37.923\nIt could be the process of them\nbuying that online, if you will,\n\n122\n00:05:37.923 --> 00:05:39.910\nan operation from beginning to end.\n\n123\n00:05:39.910 --> 00:05:44.121\nA form that's filled out versus\nthe information going across to the back\n\n124\n00:05:44.121 --> 00:05:47.032\nend into a database,\nthat process could be lost.\n\n125\n00:05:47.032 --> 00:05:50.998\nWe also have to understand, if we are\ngoing to analyze this, is there gonna be\n\n126\n00:05:50.998 --> 00:05:54.978\nany chance of a financial loss that\nwould be a mission-essential function?\n\n127\n00:05:54.978 --> 00:05:58.383\nAgain, do any of the components\nthat are in question,\n\n128\n00:05:58.383 --> 00:06:01.647\nany of these functions\nrequire high availability?\n\n129\n00:06:01.647 --> 00:06:04.222\nRemember, high availability we've\ntalked about in other episodes.\n\n130\n00:06:04.222 --> 00:06:07.777\nThat expresses how close\na system gets to 100% uptime.\n\n131\n00:06:07.777 --> 00:06:12.969\nRemember, five nines, that's just over\nfive minutes downtime in an entire year.\n\n132\n00:06:12.969 --> 00:06:18.809\nYou look at a month, I think it's\n605 milliseconds, I think it is.\n\n133\n00:06:18.809 --> 00:06:21.648\nIt might be 6.05, but\nI think it's 605 milliseconds.\n\n134\n00:06:21.648 --> 00:06:26.087\nSo you're talking about a pretty good\nliability if one of these functions that\n\n135\n00:06:26.087 --> 00:06:28.912\ntries to adhere to\na service-level agreement and\n\n136\n00:06:28.912 --> 00:06:31.075\nyou're not meeting that agreement.\n\n137\n00:06:31.075 --> 00:06:33.071\n&gt;&gt; Mm-hm, that's how long it\ntakes me to burn ravioli.\n\n138\n00:06:33.071 --> 00:06:34.200\n&gt;&gt; [LAUGH] Very good.\n\n139\n00:06:34.200 --> 00:06:35.068\n&gt;&gt; For sure.\n\n140\n00:06:35.068 --> 00:06:36.045\n&gt;&gt; Yeah, definitely.\n\n141\n00:06:36.045 --> 00:06:38.669\nMy wife, for me,\nit would be warm brownie delight.\n\n142\n00:06:38.669 --> 00:06:40.491\n&gt;&gt; [LAUGH]\n&gt;&gt; You don't put those in a [LAUGH]\n\n143\n00:06:40.491 --> 00:06:41.432\nmicrowave for ten minutes.\n\n144\n00:06:41.432 --> 00:06:42.791\nAnd that's your lesson learned for today.\n\n145\n00:06:42.791 --> 00:06:43.569\n&gt;&gt; That's it.\n\n146\n00:06:43.569 --> 00:06:46.817\n&gt;&gt; [LAUGH] So\nsome of the other things, too.\n\n147\n00:06:46.817 --> 00:06:49.622\nIf function is lost,\nare there any legal ramifications?\n\n148\n00:06:49.622 --> 00:06:52.180\nAny kind of litigation?\n\n149\n00:06:52.180 --> 00:06:55.347\nLet me give you some other\nexamples of functions.\n\n150\n00:06:55.347 --> 00:07:00.153\nCan't collect payments, these are\nessential functions wIthin your systems.\n\n151\n00:07:00.153 --> 00:07:05.268\nCan't record or process those payments,\nthings like processing credit cards.\n\n152\n00:07:05.268 --> 00:07:09.500\nYou can't track or\nrecord any of your merchandise, or\n\n153\n00:07:09.500 --> 00:07:12.357\nrestock merchandise if you need to.\n\n154\n00:07:12.357 --> 00:07:14.092\nIf you ship products.\n\n155\n00:07:14.092 --> 00:07:16.498\nThink about somebody, and\nI'm picking on Amazon here a lot, but\n\n156\n00:07:16.498 --> 00:07:18.843\nthey've got one of the biggest\ninfrastructures in the world.\n\n157\n00:07:18.843 --> 00:07:20.384\nThey really know what they're doing.\n\n158\n00:07:20.384 --> 00:07:23.328\nImagine them not being able to ship\nproducts for a day, or an hour.\n\n159\n00:07:23.328 --> 00:07:27.081\nHow much money would be lost\non something like that?\n\n160\n00:07:27.081 --> 00:07:32.182\nSo we definitely have to recognize\nthings like mission-essential functions.\n\n161\n00:07:32.182 --> 00:07:33.697\nBut that's not the only\nthing out there too.\n\n162\n00:07:33.697 --> 00:07:35.639\nWe've got critical systems-\n&gt;&gt; Critical systems, right\n\n163\n00:07:35.639 --> 00:07:36.827\n&gt;&gt; That we've got to worry about as well\n\n164\n00:07:36.827 --> 00:07:37.781\n&gt;&gt; Some of the things,\n\n165\n00:07:37.781 --> 00:07:41.321\nwhen it comes to identification of\ncritical systems, again, you asked,\n\n166\n00:07:41.321 --> 00:07:43.639\nwhat are some of the things\nthat we could expect?\n\n167\n00:07:43.639 --> 00:07:46.841\nSo let me kind of help us\nout with just functions and\n\n168\n00:07:46.841 --> 00:07:49.217\ncritical systems lumped together.\n\n169\n00:07:49.217 --> 00:07:51.990\nYou have to have good inventory.\n\n170\n00:07:51.990 --> 00:07:55.457\nYou have to have a good understanding\nof the assets that you have within your\n\n171\n00:07:55.457 --> 00:07:57.782\ncompany and\nan asset management system in place.\n\n172\n00:07:57.782 --> 00:08:01.654\nI don't know what's critical if I\ndon't know what we have in our system.\n\n173\n00:08:01.654 --> 00:08:05.209\nEven if I do know what we have\ninside of our organization,\n\n174\n00:08:05.209 --> 00:08:09.890\nI don't know what is critical if I\ndon't know how much it's used, right?\n\n175\n00:08:09.890 --> 00:08:13.920\nCuz I might have a file server that's\nsomewhere on the back of my network and\n\n176\n00:08:13.920 --> 00:08:17.220\nsomebody visits it once,\ntwice maybe a month.\n\n177\n00:08:17.220 --> 00:08:18.840\nWell, that's not going\nto be mission critical.\n\n178\n00:08:18.840 --> 00:08:21.290\nIf that file server goes offline,\nI'm okay.\n\n179\n00:08:21.290 --> 00:08:23.560\nBut if I see through\nthings like traffic flow,\n\n180\n00:08:23.560 --> 00:08:28.780\nthat I have one database that it's\nhit every single second of the day.\n\n181\n00:08:28.780 --> 00:08:34.750\nAnd we cannot process transactions,\nif that database is not back online.\n\n182\n00:08:34.750 --> 00:08:38.030\nThat would give me an indication that I\nneed to bring that back online within\n\n183\n00:08:38.030 --> 00:08:38.630\nseconds.\n\n184\n00:08:38.630 --> 00:08:41.170\nIf not, have a failover so\nit's almost instantaneous.\n\n185\n00:08:41.170 --> 00:08:46.830\nSo, keep in mind that an identification of\nfunctions and any kind of critical systems\n\n186\n00:08:46.830 --> 00:08:50.980\ngonna come down to asset inventory,\nor inventory and asset management.\n\n187\n00:08:51.990 --> 00:08:54.550\nKnowing the difference between\na work station operating system and\n\n188\n00:08:54.550 --> 00:08:55.770\na server operating system.\n\n189\n00:08:55.770 --> 00:08:57.350\nBut it doesn't just stop there.\n\n190\n00:08:57.350 --> 00:08:58.450\nIt could be vendors.\n\n191\n00:08:58.450 --> 00:09:01.420\nYou could have vendors\nthat are supporting you.\n\n192\n00:09:01.420 --> 00:09:05.560\nYou might have to contact vendors\nas part of this process too.\n\n193\n00:09:05.560 --> 00:09:08.740\nWhen we talk about critical systems\none of the first ones we think of is\n\n194\n00:09:08.740 --> 00:09:10.240\nthings like power.\n\n195\n00:09:10.240 --> 00:09:14.340\nIn Information Technology a lot of our\nstuff isn't written down on pen and\n\n196\n00:09:14.340 --> 00:09:18.610\npaper anymore, right, it's stored\nin some kind of electronic format.\n\n197\n00:09:18.610 --> 00:09:21.030\nWell, in order to view electronic\nformat you need electricity,\n\n198\n00:09:21.030 --> 00:09:22.480\nright, it's electrical, right?\n\n199\n00:09:22.480 --> 00:09:27.080\nSo we need to think about things like\npower grids Having redundant backup power,\n\n200\n00:09:27.080 --> 00:09:28.320\nthinks like UPS.\n\n201\n00:09:28.320 --> 00:09:32.960\nI know one of the facilities out in Utah\nthat Facebook has, kind of interesting\n\n202\n00:09:32.960 --> 00:09:37.720\nZack, they have 13 generators, and each\none of those generators could power 600 to\n\n203\n00:09:37.720 --> 00:09:41.820\n900 homes, I don't have my facts exactly\ncorrect, for upwards of a month.\n\n204\n00:09:41.820 --> 00:09:45.750\nSo, when we talk about backups,\nthey know how to do the backups.\n\n205\n00:09:45.750 --> 00:09:46.520\nYeah, absolutely.\n\n206\n00:09:46.520 --> 00:09:50.140\nAmazon is another one that they have\nredundant entire power grids, right?\n\n207\n00:09:50.140 --> 00:09:52.130\nOn a very large scale.\n\n208\n00:09:52.130 --> 00:09:54.880\nThings like you cabling,\nyour network devices.\n\n209\n00:09:54.880 --> 00:09:57.060\nHow about this,\nInternet service providers, right?\n\n210\n00:09:57.060 --> 00:10:01.550\nIf you are a big company and you need\na presence out there on the Internet,\n\n211\n00:10:01.550 --> 00:10:04.250\nmaybe you can't just stay with one\ninternet service provider because what\n\n212\n00:10:04.250 --> 00:10:06.920\nhappens if that internet service\nprovider's network goes offline?\n\n213\n00:10:06.920 --> 00:10:09.930\nIf you need a high availability you might\nhave to click to a fail over internet\n\n214\n00:10:09.930 --> 00:10:10.670\nservice provider.\n\n215\n00:10:10.670 --> 00:10:13.800\nSo you might need redundancy\nin your ISPs as well.\n\n216\n00:10:13.800 --> 00:10:16.460\nRight, or any service that you've\noutsourced to a third party,\n\n217\n00:10:16.460 --> 00:10:18.980\nyou might have to outsource it\nto more than one person, right?\n\n218\n00:10:18.980 --> 00:10:22.160\nIt's that proverbial saying, you don't\nput all your eggs in one basket, right,\n\n219\n00:10:22.160 --> 00:10:24.030\nbecause what happens if that basket fails?\n\n220\n00:10:24.030 --> 00:10:25.140\nYou lose all your eggs.\n\n221\n00:10:25.140 --> 00:10:27.750\nSo that's one of the big\nthings about this.\n\n222\n00:10:27.750 --> 00:10:31.460\nThings like security systems, right,\ncould be physical, could be logical.\n\n223\n00:10:31.460 --> 00:10:34.380\nWe talk about a physical security system,\nit could be quite literally,\n\n224\n00:10:34.380 --> 00:10:37.170\nyou have a hundred thousand dollar\nelectronic security system that when\n\n225\n00:10:37.170 --> 00:10:40.396\nthe power goes off, it opens all\nthe doors because of a fire code.\n\n226\n00:10:40.396 --> 00:10:44.070\nWell, it opens [LAUGH] all\nthe doors because of the fire code.\n\n227\n00:10:44.070 --> 00:10:47.590\nIt means not only can the firefighters\nget in, but so can anybody else [LAUGH].\n\n228\n00:10:47.590 --> 00:10:48.980\nSo, it could be logical, right?\n\n229\n00:10:48.980 --> 00:10:51.950\nIt could be our firewalls,\nit could be ACLs, right?\n\n230\n00:10:51.950 --> 00:10:54.330\nIt could be biometric systems, right?\n\n231\n00:10:54.330 --> 00:10:56.450\nAnd again, it could be physical or\nit could be logical, but\n\n232\n00:10:56.450 --> 00:10:59.020\nour security systems are important.\n\n233\n00:10:59.020 --> 00:11:00.940\nThings like your datacenters, right?\n\n234\n00:11:00.940 --> 00:11:01.950\nYour databases.\n\n235\n00:11:01.950 --> 00:11:05.260\nStorage solutions are important because\nwhen it comes to a storage solution\n\n236\n00:11:05.260 --> 00:11:07.040\nthink about it in IT.\n\n237\n00:11:07.040 --> 00:11:11.610\nWhat is it that is important\ninformation technology,\n\n238\n00:11:11.610 --> 00:11:14.570\nall the technology send\naround your information.\n\n239\n00:11:14.570 --> 00:11:17.190\nYour storage systems are essential.\n\n240\n00:11:17.190 --> 00:11:18.240\nAnd it's not really that.\n\n241\n00:11:18.240 --> 00:11:21.077\nIt isn't that difficult to make my own\ncontribution to the English language here.\n\n242\n00:11:21.077 --> 00:11:22.032\n&gt;&gt; [LAUGH]\n&gt;&gt; Try to better English here.\n\n243\n00:11:22.032 --> 00:11:24.878\nIt isn't that hard to\nimplement some redundancy,\n\n244\n00:11:24.878 --> 00:11:27.335\nespecially with cloud-based solutions.\n\n245\n00:11:27.335 --> 00:11:31.445\nBut if you're not aware of that,\nand you don't realize the impact of\n\n246\n00:11:31.445 --> 00:11:35.400\nloss of your data is to your business,\nwell then maybe you don't consider it.\n\n247\n00:11:35.400 --> 00:11:37.410\nMaybe you consider it an acceptable risk.\n\n248\n00:11:37.410 --> 00:11:41.140\nSo that's why we have to keep these\nat the forefront of our minds.\n\n249\n00:11:41.140 --> 00:11:43.840\nOther things like\nenvironmental control systems.\n\n250\n00:11:43.840 --> 00:11:45.030\nYou might say well, wait a second.\n\n251\n00:11:45.030 --> 00:11:47.590\nI didn't know I was coming to\nlisten to a Greenpeace episode.\n\n252\n00:11:47.590 --> 00:11:48.810\nWe're not talking about hugging trees.\n\n253\n00:11:48.810 --> 00:11:51.430\nWhen we say environmental controls we're\ntalking about our data centers and\n\n254\n00:11:51.430 --> 00:11:55.910\nmaking sure that moisture is staying at\nthe certain level that's regulated, right?\n\n255\n00:11:55.910 --> 00:11:58.730\nHere in Florida, I don't have to tell\nanybody that's lived in Florida for\n\n256\n00:11:58.730 --> 00:12:02.090\nany amount of time what they feel when\nthey walk out the door in the summer and\n\n257\n00:12:02.090 --> 00:12:04.600\nthey feel that wall of moisture\njust hit them in the face.\n\n258\n00:12:04.600 --> 00:12:08.430\nSo we need to make sure that our\ndata centers have the right ECS,\n\n259\n00:12:08.430 --> 00:12:12.220\nor environmental control systems, in them\nto ensure that we don't have too much\n\n260\n00:12:12.220 --> 00:12:17.210\nhumidity which leads to condensation,\nand again, short circuiting.\n\n261\n00:12:17.210 --> 00:12:18.960\nOr we have too dry of air and\n\n262\n00:12:18.960 --> 00:12:22.320\nit leads the static charge generation\nwhich ultimately leads to electrostatic\n\n263\n00:12:22.320 --> 00:12:26.890\ndischarge and the failure of our\ncomponents through damaging.\n\n264\n00:12:26.890 --> 00:12:28.520\nWhat else here do we have?\n\n265\n00:12:28.520 --> 00:12:29.720\nAnd the other thing, too.\n\n266\n00:12:29.720 --> 00:12:31.330\nWhat systems do we have?\n\n267\n00:12:31.330 --> 00:12:35.650\nAgain, part of a asset inventory\nif you will, or management.\n\n268\n00:12:35.650 --> 00:12:39.680\nBut also things like your vendors, again,\nkeeping documentations about that,\n\n269\n00:12:39.680 --> 00:12:42.880\nyou might have some key vendors that\nare critical to uptime of your company and\n\n270\n00:12:42.880 --> 00:12:44.020\ncontinuity of your company.\n\n271\n00:12:44.020 --> 00:12:49.510\nSo you have to make sure that you have\nplans in place to, again to, discuss\n\n272\n00:12:49.510 --> 00:12:53.660\nwith them or again, communicate with\nthem in case of any kind of incidents.\n\n273\n00:12:53.660 --> 00:12:57.100\nAnd then, interdepartamental policies,\nit could be something.\n\n274\n00:12:57.100 --> 00:13:00.820\nIf you're a big enough company,\nyou might have multiple policies in one or\n\n275\n00:13:00.820 --> 00:13:01.810\nmultiple departments.\n\n276\n00:13:01.810 --> 00:13:06.520\nAnd if one fails, there might be\nan inter-department dependency.\n\n277\n00:13:06.520 --> 00:13:09.230\nOne fails, it affects the other, and\nwe have this domino effect, too.\n\n278\n00:13:09.230 --> 00:13:12.370\nSo you have to keep in mind,\nthat the identification of functions and\n\n279\n00:13:12.370 --> 00:13:16.500\ncritical systems, sometimes can lend\nitself to more than one department.\n\n280\n00:13:16.500 --> 00:13:19.190\nAnd they could be chained together,\neach one depending on the other.\n\n281\n00:13:19.190 --> 00:13:21.170\nAnd if one fails, they all go.\n\n282\n00:13:21.170 --> 00:13:25.580\nSo this is important as part\nof business impact analysis.\n\n283\n00:13:25.580 --> 00:13:26.880\n&gt;&gt; Terrific.\n\n284\n00:13:26.880 --> 00:13:29.530\n&gt;&gt; All right, so let's go ahead.\n\n285\n00:13:29.530 --> 00:13:31.030\nThey talk about a couple of other things.\n\n286\n00:13:31.030 --> 00:13:35.160\nAnd if some of you are coming from A+,\nif you're coming from NetPlus,\n\n287\n00:13:35.160 --> 00:13:38.075\nmaybe you've seen some of the episodes\nthat we have here in Security+,\n\n288\n00:13:38.075 --> 00:13:40.445\nthey talk about a single point of failure.\n\n289\n00:13:40.445 --> 00:13:42.525\nAll right, so let's go back in history and\n\n290\n00:13:42.525 --> 00:13:45.935\nfind out why are we using\nEthernet based networks today?\n\n291\n00:13:45.935 --> 00:13:48.675\nAnd more so,\nthings like switches within our networks.\n\n292\n00:13:48.675 --> 00:13:49.925\nCuz you remember in the earlier days,\n\n293\n00:13:49.925 --> 00:13:52.560\nwe were using Coax the implementations,\nright?\n\n294\n00:13:52.560 --> 00:13:56.670\nAnd if somebody walks over and cuts the\ncable, it brings the entire network down.\n\n295\n00:13:56.670 --> 00:13:58.500\nWell, that's a single point of failure,\nright?\n\n296\n00:13:58.500 --> 00:14:02.320\nSo, for instance, if your company really,\nwell most companies do, but you really,\n\n297\n00:14:02.320 --> 00:14:05.430\nreally relying on DNS and\na DNS server goes offline,\n\n298\n00:14:05.430 --> 00:14:08.750\nnow you can't resolve any of the names\nthat are on your networks, right?\n\n299\n00:14:08.750 --> 00:14:10.410\nIt's a single point of failure.\n\n300\n00:14:10.410 --> 00:14:12.970\nSo any kind of single point of failure,\nif you will,\n\n301\n00:14:12.970 --> 00:14:16.370\nthat does run the risk of\nimpacting your business so\n\n302\n00:14:16.370 --> 00:14:21.710\nseverely that without it, you don't run,\nchances are you're gonna wanna scale out.\n\n303\n00:14:21.710 --> 00:14:22.980\nNow I don't mean scale up, right?\n\n304\n00:14:22.980 --> 00:14:24.940\nRemember there's two types of scaling.\n\n305\n00:14:24.940 --> 00:14:28.470\nThere's scaling horizontally,\nand there's scaling vertically.\n\n306\n00:14:28.470 --> 00:14:30.360\nHorizontally is when I add another device.\n\n307\n00:14:30.360 --> 00:14:32.490\nAnd this is what you're\ngonna be wanting to do.\n\n308\n00:14:32.490 --> 00:14:36.640\nVertically means I just, in upgrade,\nthe one component that I have.\n\n309\n00:14:36.640 --> 00:14:38.100\nUpgrading doesn't give\nyou fault tolerance.\n\n310\n00:14:38.100 --> 00:14:41.705\nSo, scaling up doesn't give you the fault\ntolerance, scaling out does, so\n\n311\n00:14:41.705 --> 00:14:43.835\nyou have to make sure that\nyou have that as well.\n\n312\n00:14:43.835 --> 00:14:48.485\nSingle points of failure, again,\nis any component, any process,\n\n313\n00:14:48.485 --> 00:14:51.355\nany function, any system, that without it,\n\n314\n00:14:51.355 --> 00:14:55.125\nit affects your business critically,\nis going to be a problem.\n\n315\n00:14:55.125 --> 00:14:57.775\nAnd that's why you wanna eliminate\nsingle points of failure by\n\n316\n00:14:57.775 --> 00:14:59.165\nimplementing redundancy.\n\n317\n00:14:59.165 --> 00:15:01.830\nRemember, redundancy and\nfault tolerance are not the same.\n\n318\n00:15:01.830 --> 00:15:04.920\nI know some people are gonna\nprobably challenge me on that but\n\n319\n00:15:04.920 --> 00:15:07.450\nredundancy is the way we\nachieve fault tolerance.\n\n320\n00:15:07.450 --> 00:15:10.980\nWe have more than one and\nthat makes us fault tolerance to failure.\n\n321\n00:15:10.980 --> 00:15:13.260\n&gt;&gt; Well, there's nothing wrong\nwith having a backup of the backup\n\n322\n00:15:13.260 --> 00:15:14.590\nof the backup's backup.\n\n323\n00:15:14.590 --> 00:15:16.180\nI mean, there's nothing even\nwrong with that at all.\n\n324\n00:15:16.180 --> 00:15:17.200\n&gt;&gt; Absolutely not.\n\n325\n00:15:17.200 --> 00:15:19.420\n&gt;&gt; But\nlet's talk about the privacy now too.\n\n326\n00:15:19.420 --> 00:15:21.460\nI know privacy's very important.\n\n327\n00:15:21.460 --> 00:15:24.330\nThere are issues with privacy,\nestablishing privacy.\n\n328\n00:15:24.330 --> 00:15:27.450\nBut there's even issues with\ndisclosing privacy, and\n\n329\n00:15:27.450 --> 00:15:28.810\nprivacy policies, isn't there?\n\n330\n00:15:28.810 --> 00:15:30.980\n&gt;&gt; Most definitely, and\nthat's why we have things like Pi.\n\n331\n00:15:30.980 --> 00:15:33.970\nAnd you're gonna say, now wait a second,\nhere are we talking about And on math,\n\n332\n00:15:33.970 --> 00:15:35.400\nare we talking about something yummy?\n\n333\n00:15:35.400 --> 00:15:36.320\n&gt;&gt; Boysenberry.\n\n334\n00:15:36.320 --> 00:15:37.020\n&gt;&gt; That's right.\n\n335\n00:15:37.020 --> 00:15:37.610\n&gt;&gt; Right?\n\n336\n00:15:37.610 --> 00:15:38.120\nElderberry.\n\n337\n00:15:38.120 --> 00:15:38.847\n&gt;&gt; That's what it is.\n\n338\n00:15:38.847 --> 00:15:39.370\n&gt;&gt; [LAUGH]\n&gt;&gt; And\n\n339\n00:15:39.370 --> 00:15:42.420\nwhat we're talking about is personally\nidentifiable information, right?\n\n340\n00:15:42.420 --> 00:15:45.070\nWe're talking about things like\nprotected healthcare information,\n\n341\n00:15:45.070 --> 00:15:47.840\nas we've been talking\nabout through this series.\n\n342\n00:15:47.840 --> 00:15:51.213\nRemember it's about your data and\nsecuring that information,\n\n343\n00:15:51.213 --> 00:15:55.335\nespecially if that data has revealing\ninformation that could cause harm if you\n\n344\n00:15:55.335 --> 00:15:58.283\nwill to your end users\ndisclosure of that information.\n\n345\n00:15:58.283 --> 00:16:01.708\nSo they do call out\na couple of things here.\n\n346\n00:16:01.708 --> 00:16:05.866\nOne of the first things they call out\nis what's known as a privacy threshold\n\n347\n00:16:05.866 --> 00:16:06.661\nassessment.\n\n348\n00:16:06.661 --> 00:16:08.783\nNow, with the privacy\nthreshold assessments,\n\n349\n00:16:08.783 --> 00:16:12.107\nthis is actually the precursor to\nthe next one that we're gonna talk about.\n\n350\n00:16:12.107 --> 00:16:13.932\nThis is a form, essentially,\n\n351\n00:16:13.932 --> 00:16:18.504\nthat's used to determine whether\na privacy impact assessment is required.\n\n352\n00:16:18.504 --> 00:16:19.028\nOkay, that'll be the next\none that we talk about.\n\n353\n00:16:19.028 --> 00:16:22.870\nBut just understand,\nthat that's what that is.\n\n354\n00:16:22.870 --> 00:16:27.390\nA privacy threshold assessment is\nused to determine if your company\n\n355\n00:16:27.390 --> 00:16:32.110\nNow has to have a privacy\nimpact assessment.\n\n356\n00:16:32.110 --> 00:16:35.080\nNow, what does the privacy threshold do,\nright?\n\n357\n00:16:35.080 --> 00:16:38.897\nIt helps to determine if there's data\nin an information system that includes\n\n358\n00:16:38.897 --> 00:16:41.022\ninformation about individuals, right?\n\n359\n00:16:41.022 --> 00:16:43.170\nWe're at that threshold.\n\n360\n00:16:43.170 --> 00:16:44.010\nHow much information?\n\n361\n00:16:44.010 --> 00:16:47.040\nNow we're seeing what this privacy\nthreshold assessment, hey,\n\n362\n00:16:47.040 --> 00:16:49.100\nwe're hitting that threshold where yes,\n\n363\n00:16:49.100 --> 00:16:51.960\nwe do have personally\nidentifiable information, right?\n\n364\n00:16:51.960 --> 00:16:54.350\nAnd then, we need to do things\nlike identify programs and\n\n365\n00:16:54.350 --> 00:16:57.180\nin systems themselves that\nare privacy sensitive,\n\n366\n00:16:57.180 --> 00:17:01.180\nincluding demonstrate the inclusion\nof privacy considerations.\n\n367\n00:17:01.180 --> 00:17:04.890\nAnd that is very, very important during\nthe review of any program or system.\n\n368\n00:17:04.890 --> 00:17:07.038\nLet's see, what else?\n\n369\n00:17:07.038 --> 00:17:09.316\nAgain, provide a record of the program or\n\n370\n00:17:09.316 --> 00:17:13.036\nsystem in its privacy requirements\nas required by the department.\n\n371\n00:17:13.036 --> 00:17:17.760\nAnd then demonstrate things like\ncompliance with privacy laws, all right.\n\n372\n00:17:17.760 --> 00:17:21.700\nSo keep in mind again,\nthat the privacy impact or excuse me.\n\n373\n00:17:21.700 --> 00:17:25.440\nPrivacy threshold assessment, this is\nassessing a system and saying, hey,\n\n374\n00:17:25.440 --> 00:17:28.800\nit does contain sensitive,\nprivate information.\n\n375\n00:17:28.800 --> 00:17:32.010\nNow we're gonna have to go through\na privacy impact assessment, right?\n\n376\n00:17:32.010 --> 00:17:33.510\nAnd that's the next step, right?\n\n377\n00:17:33.510 --> 00:17:38.744\nSo step one, you get the privacy threshold\nassessment, it evaluate your system and\n\n378\n00:17:38.744 --> 00:17:42.446\nsays okay within the system we\ndo see privacy information.\n\n379\n00:17:42.446 --> 00:17:44.871\nNow we're gonna do an impact assessment.\n\n380\n00:17:44.871 --> 00:17:49.797\nAnd the impact assessment make sure\nthat a company once you determined that,\n\n381\n00:17:49.797 --> 00:17:53.662\nthat privacy information is\nthere Now we have to determine,\n\n382\n00:17:53.662 --> 00:17:57.930\nwhat does the company have to\nsafeguard that information?\n\n383\n00:17:57.930 --> 00:18:00.600\nThat's the privacy impact assessment,\nright?\n\n384\n00:18:00.600 --> 00:18:03.570\nProviding the information about\nthe company's compliance with\n\n385\n00:18:03.570 --> 00:18:04.460\nthe current standards.\n\n386\n00:18:04.460 --> 00:18:09.440\nFirst of all, again, with the threshold,\ndo we even have privacy information?\n\n387\n00:18:09.440 --> 00:18:11.070\nNow when we do the impact assessment,\n\n388\n00:18:11.070 --> 00:18:14.390\nwe have to find out how is\nthe information collected?\n\n389\n00:18:14.390 --> 00:18:17.030\nHow is it stored?\nHow is it protected?\n\n390\n00:18:17.030 --> 00:18:20.150\nAnd if shared, how is it shared and\nhow is it managed, right?\n\n391\n00:18:20.150 --> 00:18:22.538\nIt could be something like a PLA,\nall right?\n\n392\n00:18:22.538 --> 00:18:28.450\nSo it could be a service agreement,\ncould be a privacy level agreement, right.\n\n393\n00:18:28.450 --> 00:18:30.732\nThinking of PLA, Privacy Level Agreement.\n\n394\n00:18:30.732 --> 00:18:34.214\nIt's kinda like adhering to like SLA only\ndealing with your private information.\n\n395\n00:18:34.214 --> 00:18:37.813\nSo for instance, I got a document here and\nthis is one that say privacy and\n\n396\n00:18:37.813 --> 00:18:39.180\nsecurity agreement here.\n\n397\n00:18:39.180 --> 00:18:40.440\nIf we can pull up my screen.\n\n398\n00:18:40.440 --> 00:18:42.660\nAnd you can see that here it is, right?\n\n399\n00:18:42.660 --> 00:18:46.330\nPrivacy and Security Agreement, as made\nof, it's a little out of date there,\n\n400\n00:18:46.330 --> 00:18:48.850\nyou can see 2011,\nprobably wanna update the document.\n\n401\n00:18:48.850 --> 00:18:52.180\nBetween and it says the effective date,\nthe trustees of Myops,\n\n402\n00:18:52.180 --> 00:18:55.990\na business here in the city of Gainsville,\na Gainsville for profit, right?\n\n403\n00:18:55.990 --> 00:18:57.638\nOn behalf of, whatever the department is,\n\n404\n00:18:57.638 --> 00:18:59.561\nand then you walk through this agreement,\nright?\n\n405\n00:18:59.561 --> 00:19:01.890\nAnd it's how is things\nlike security management?\n\n406\n00:19:01.890 --> 00:19:03.820\nHow are we gonna implement that?\n\n407\n00:19:03.820 --> 00:19:05.520\nRisk management, if you will.\n\n408\n00:19:05.520 --> 00:19:09.350\nAnd personal security, so\nyou can see there're physical security,\n\n409\n00:19:09.350 --> 00:19:11.290\ncommunications security, right?\n\n410\n00:19:11.290 --> 00:19:13.340\nSo for instance, we zoom in here,\n\n411\n00:19:13.340 --> 00:19:16.145\nyou could see the Exchange\nof Sensitive Information.\n\n412\n00:19:16.145 --> 00:19:18.963\nAnd if it's over the wire,\nif it's data that's in use,\n\n413\n00:19:18.963 --> 00:19:20.680\nhow are we encrypting it, right?\n\n414\n00:19:20.680 --> 00:19:23.730\nAnd then encryption and\ncommunication, right?\n\n415\n00:19:23.730 --> 00:19:27.093\nProtection of storage media, cuz that\ninformation might need to be retained.\n\n416\n00:19:27.093 --> 00:19:31.331\nAnd you might have some kinda retention\npolicy that says we're gonna retain it up\n\n417\n00:19:31.331 --> 00:19:34.840\nto seven years just if we\ncome across any audit, right?\n\n418\n00:19:34.840 --> 00:19:35.484\nHow do we maintain the integrity?\n\n419\n00:19:35.484 --> 00:19:39.275\nThat's important, too, because if you're\nstoring the information in a protected\n\n420\n00:19:39.275 --> 00:19:42.179\nenvironment, right,\nin a protected media that's encrypted.\n\n421\n00:19:42.179 --> 00:19:47.710\nThat stops the fact that people\ncan view that information.\n\n422\n00:19:47.710 --> 00:19:50.340\nBut what it doesn't stop is\nthe integrity of the information,\n\n423\n00:19:50.340 --> 00:19:52.336\nbecause think about a magnetic media,\nright?\n\n424\n00:19:52.336 --> 00:19:56.380\nNow some of you guys, probably too\nyoung to remember tape cassettes.\n\n425\n00:19:56.380 --> 00:20:00.099\nBut tape cassettes, you used to put\nthem in the dash of your car, right?\n\n426\n00:20:00.099 --> 00:20:02.893\nAnd I don't know about you, Zach,\nbut come back afternoon and\n\n427\n00:20:02.893 --> 00:20:05.280\nthose things would be\na warped mangled mess, right.\n\n428\n00:20:05.280 --> 00:20:07.015\n&gt;&gt; They would melt they would tangle.\n\n429\n00:20:07.015 --> 00:20:09.440\n[LAUGH] And they would demagnatize, too.\n\n430\n00:20:09.440 --> 00:20:11.180\n&gt;&gt; Very good and that's the point.\n\n431\n00:20:11.180 --> 00:20:13.526\nWe also have to worry with data\nrotation processes, right?\n\n432\n00:20:13.526 --> 00:20:15.430\nThat's where the integrity process goes.\n\n433\n00:20:15.430 --> 00:20:18.641\nBecause even in magnetic media\nwe can get things like bit rot.\n\n434\n00:20:18.641 --> 00:20:20.610\nRight Bit Rod is exactly that.\n\n435\n00:20:20.610 --> 00:20:22.900\nIt's like demagnetizing,\nkinda like degaussing.\n\n436\n00:20:22.900 --> 00:20:26.470\nYou have to worry about the data that's\non it just kinda losing its luster and\n\n437\n00:20:26.470 --> 00:20:28.180\ndeteriorating.\n\n438\n00:20:28.180 --> 00:20:30.810\nSo this is something that\nyou could see as well.\n\n439\n00:20:30.810 --> 00:20:32.862\nYou could also have things like for\n\n440\n00:20:32.862 --> 00:20:37.545\ninstance this is a newer thing too with\nthe cloud is a privacy level agreement.\n\n441\n00:20:37.545 --> 00:20:41.406\nYou can see for instance this one\nright here Cloud Security Alliance,\n\n442\n00:20:41.406 --> 00:20:43.930\nthis is their new 2015 one.\n\n443\n00:20:43.930 --> 00:20:46.439\nIt is current and up to date,\neven though it says 2015.\n\n444\n00:20:46.439 --> 00:20:48.540\nTheir earlier one was 2013.\n\n445\n00:20:48.540 --> 00:20:52.412\nAnd again, notice it talks about providing\na compliant, or a compliance tool for\n\n446\n00:20:52.412 --> 00:20:54.779\nproviding cloud services\nin the European Union.\n\n447\n00:20:54.779 --> 00:20:57.770\nSo this a official documentation.\n\n448\n00:20:57.770 --> 00:21:02.580\nAnd you can see what are they\ngoing to be discussing, right?\n\n449\n00:21:02.580 --> 00:21:04.243\nThe cloud customer's internal\ndue diligence, right?\n\n450\n00:21:04.243 --> 00:21:06.317\nWe're expected to do something on our end,\n\n451\n00:21:06.317 --> 00:21:08.980\neven though we've got a cloud provider,\nright?\n\n452\n00:21:08.980 --> 00:21:12.190\nI could say that I call\nan EDT security system, and\n\n453\n00:21:12.190 --> 00:21:15.600\nI'm paying them a price to\nmonitor my house every month.\n\n454\n00:21:15.600 --> 00:21:19.770\nAnd if I get broken into, they probably\nhave some kinda liability documentation.\n\n455\n00:21:19.770 --> 00:21:22.450\nBut if I leave every single\ndoor in my house open,\n\n456\n00:21:23.740 --> 00:21:28.035\nI can't hold ADT responsible\nbecause I left the doors open.\n\n457\n00:21:28.035 --> 00:21:30.940\nSo the customers,\nwhat is the customer's responsibilities?\n\n458\n00:21:30.940 --> 00:21:31.440\nThings like, and\n\n459\n00:21:31.440 --> 00:21:34.670\nyou can see some of the commonalities\nwe've kinda seen in the last document.\n\n460\n00:21:34.670 --> 00:21:36.000\nData transfer.\n\n461\n00:21:36.000 --> 00:21:37.980\nHow is the data gonna be processed.\n\n462\n00:21:37.980 --> 00:21:41.530\nWhat are the security measures for\nsecuring the information.\n\n463\n00:21:41.530 --> 00:21:44.990\nMonitoring that, we have to make\nsure we're constantly in compliance,\n\n464\n00:21:44.990 --> 00:21:49.940\ncontinual compliance, not just measuring\nto a set of compliance to start with.\n\n465\n00:21:49.940 --> 00:21:52.950\nAnd then getting your\nconfiguration drift that goes and\n\n466\n00:21:52.950 --> 00:21:55.820\nsteers away from that compliance initial,\nthe initial baseline.\n\n467\n00:21:55.820 --> 00:21:57.444\nSo, constantly monitoring.\n\n468\n00:21:57.444 --> 00:22:00.370\nPersonal data breach notifications, right?\n\n469\n00:22:00.370 --> 00:22:04.981\nFor instance,\na big corporation notices that their\n\n470\n00:22:04.981 --> 00:22:08.975\nuser databases has been exploited, right?\n\n471\n00:22:08.975 --> 00:22:14.080\nWell we need to make people aware that\nhey, we just lost 2 million user accounts.\n\n472\n00:22:14.080 --> 00:22:16.002\nYou've probably seen this before.\nMany of the big corporations and\n\n473\n00:22:16.002 --> 00:22:19.690\nI'm not picking on anyone cuz it's\nhappened to a few of them, right?\n\n474\n00:22:19.690 --> 00:22:22.370\nAnd most of those companies\nare still in good standing.\n\n475\n00:22:22.370 --> 00:22:25.900\nCuz the moment they found out about it,\nthey made everybody aware that,\n\n476\n00:22:25.900 --> 00:22:28.200\nhey, we're not exactly\nsure what the extent is.\n\n477\n00:22:28.200 --> 00:22:29.370\nBut this is what we're seeing now.\n\n478\n00:22:29.370 --> 00:22:33.319\nSo at least they did their due diligence\nbecause they have a public-facing interest\n\n479\n00:22:33.319 --> 00:22:35.220\nto let the public know what was going on.\n\n480\n00:22:35.220 --> 00:22:36.296\nPortability, again,\n\n481\n00:22:36.296 --> 00:22:39.322\nthis is important because of the fact\nthat we have mobile devices.\n\n482\n00:22:39.322 --> 00:22:43.150\nWe have things like cell phones on our\nnetworks we do have to worry about.\n\n483\n00:22:43.150 --> 00:22:47.560\nHow that impacts privacy as well.\n\n484\n00:22:47.560 --> 00:22:49.680\nHere's the other thing too,\naccountability,\n\n485\n00:22:49.680 --> 00:22:54.510\nwe want things like repudiation and\nauditing or non repudiation, right.\n\n486\n00:22:54.510 --> 00:22:56.980\nWe use things like digital signatures and\nstuff so\n\n487\n00:22:56.980 --> 00:22:59.430\nthat if I send a piece if\ninformation from my self to Zach.\n\n488\n00:22:59.430 --> 00:23:03.340\nZach's computer can check with\na little mathematical algorithm,\n\n489\n00:23:03.340 --> 00:23:06.800\ncan check that file and say,\nwhat was the value you got?\n\n490\n00:23:06.800 --> 00:23:09.300\nOkay, I see the value you got,\nI see the value I got.\n\n491\n00:23:09.300 --> 00:23:10.530\nOkay, they match.\n\n492\n00:23:10.530 --> 00:23:12.238\nOkay, the documents\nmaintained its integrity.\n\n493\n00:23:12.238 --> 00:23:16.396\nHowever, if Zack's computer does that and\nsays, well wait a second, these don't\n\n494\n00:23:16.396 --> 00:23:20.160\nmatch, it's gonna reject the data\nbecause it's not in its original form.\n\n495\n00:23:20.160 --> 00:23:23.680\nWhether it be a transmission error It\ncould be just a transmission error over\n\n496\n00:23:23.680 --> 00:23:24.250\nthe network, right?\n\n497\n00:23:24.250 --> 00:23:24.980\nThe network's at fault.\n\n498\n00:23:24.980 --> 00:23:27.380\nIt could be malicious activity,\nbut it doesn't have to.\n\n499\n00:23:27.380 --> 00:23:28.562\nSo it could be unintentional\nas well as intentional.\n\n500\n00:23:28.562 --> 00:23:32.900\nAnd it needs to cover both aspects.\n\n501\n00:23:32.900 --> 00:23:35.420\nAccountability, who's gonna\nbe liable if something\n\n502\n00:23:35.420 --> 00:23:37.130\nlike that happens especially in the cloud.\n\n503\n00:23:37.130 --> 00:23:40.000\nBecause there is a demarcation point\n\n504\n00:23:40.000 --> 00:23:44.345\nbetween your responsiblity as the customer\nand their responsibility as a provider.\n\n505\n00:23:44.345 --> 00:23:47.670\nCuz I want you to think about this it's\nno different than the ISP bringing in\n\n506\n00:23:47.670 --> 00:23:52.370\ninternet cable to internet if you will\ncable TV and phone to your house, right?\n\n507\n00:23:52.370 --> 00:23:54.229\nYou have a demarcation point\nright outside of your building.\n\n508\n00:23:54.229 --> 00:23:55.616\nAnd what is it?\n\n509\n00:23:55.616 --> 00:23:59.680\nIt's the point where the carrier's network\ncomes into yours and connects to yours.\n\n510\n00:23:59.680 --> 00:24:03.591\nWell on the left hand side,\nlet's say that's the customer's house,\n\n511\n00:24:03.591 --> 00:24:05.621\nResidential area, it's your job.\n\n512\n00:24:05.621 --> 00:24:07.146\nSquirrel start gnawing on the wires,\n\n513\n00:24:07.146 --> 00:24:09.482\nyou're not gonna call the cable\ncompany to replace that,\n\n514\n00:24:09.482 --> 00:24:12.930\nit's not their responsibilities\nthat part of the demarcation point.\n\n515\n00:24:12.930 --> 00:24:15.090\nYou're the home owner, you fix it.\n\n516\n00:24:15.090 --> 00:24:19.140\nHowever, somebody chops up a line that's\ntwo streets over that is part of their\n\n517\n00:24:19.140 --> 00:24:21.040\nnetwork, it's their responsibility.\n\n518\n00:24:21.040 --> 00:24:22.420\nYou don't have to get the backup crew out,\n\n519\n00:24:22.420 --> 00:24:24.570\ngo out and dig out that fiber\noptic line and replace it.\n\n520\n00:24:24.570 --> 00:24:27.030\nSo, you also have to know\nthe point of responsibility.\n\n521\n00:24:27.030 --> 00:24:29.810\nAnd that's why accountability\ndocumentation like that\n\n522\n00:24:29.810 --> 00:24:33.340\ndoes give you a thorough documentation,\nif you will, or\n\n523\n00:24:33.340 --> 00:24:36.690\nthat demarcation point\nbetween responsibility.\n\n524\n00:24:36.690 --> 00:24:40.040\nAnd then, again,\nlegally required disclosure.\n\n525\n00:24:40.040 --> 00:24:42.480\nSo you can see a lot of different\n\n526\n00:24:42.480 --> 00:24:45.600\ngood information inside of this\nthat we have to worry about.\n\n527\n00:24:45.600 --> 00:24:48.020\nWe just have to know where\nthe documentation is, and\n\n528\n00:24:48.020 --> 00:24:50.180\nmake sure that we're planning\nthis ahead of time and\n\n529\n00:24:50.180 --> 00:24:53.270\nwe're not waiting until one\nof these incidents happen,\n\n530\n00:24:53.270 --> 00:24:56.640\nwhether it happens to be a vulnerability,\nwhether it happens to be a disaster.\n\n531\n00:24:56.640 --> 00:25:00.309\nWe don't want to wait till it happens to\nmake sure that we've all ready analyzed\n\n532\n00:25:00.309 --> 00:25:02.610\nand we understand how it's\ngoing to positively or\n\n533\n00:25:02.610 --> 00:25:04.719\nmost likely negatively affect our company.\n\n534\n00:25:04.719 --> 00:25:07.755\n&gt;&gt; Do we have enough time\nto go into what MTBF is?\n\n535\n00:25:07.755 --> 00:25:08.470\n&gt;&gt; That's a good one.\n\n536\n00:25:08.470 --> 00:25:10.690\n&gt;&gt; And yeah, and with the MPTR.\n\n537\n00:25:10.690 --> 00:25:11.350\n&gt;&gt; Yes, we do.\n\n538\n00:25:11.350 --> 00:25:16.270\nSo, Zach said you know what, this episode\ndoesn't have enough alphabets soup in it.\n\n539\n00:25:16.270 --> 00:25:18.270\nSo we're gonna throw some\nat you here at the end,\n\n540\n00:25:18.270 --> 00:25:22.720\nbut these are all parts of\nbusiness impact analysis.\n\n541\n00:25:22.720 --> 00:25:27.360\nAnd the first one he mentioned is what is\nknown as the mean time between failure.\n\n542\n00:25:27.360 --> 00:25:31.380\nAll right, so when we talk about mean time\nbetween failure, it's a basic measurement.\n\n543\n00:25:31.380 --> 00:25:34.970\nIt measures the reliability of a device.\n\n544\n00:25:34.970 --> 00:25:37.990\nAnd there isn't a one size\nfits all on this one, right?\n\n545\n00:25:37.990 --> 00:25:42.300\nIt's typically the total up time\ndivided by the number of failures.\n\n546\n00:25:42.300 --> 00:25:47.400\nAnd that measurement can be a little\nsubjective, it could be developed\n\n547\n00:25:47.400 --> 00:25:51.850\nbased on things like stress testing,\nwe stress test the device until it fails.\n\n548\n00:25:51.850 --> 00:25:56.320\nManufactures do this to find out\nhow far a hard drive's gonna last.\n\n549\n00:25:56.320 --> 00:26:00.780\nBut a hard drive could say 300,000\nhours between failures, right?\n\n550\n00:26:00.780 --> 00:26:02.870\nSo again, it can be a little\nsubjective to the component.\n\n551\n00:26:02.870 --> 00:26:05.870\nCould be experience,\ncould be statistical analysis, right?\n\n552\n00:26:05.870 --> 00:26:07.240\nCuz keep in mind,\n\n553\n00:26:07.240 --> 00:26:11.260\nminutes of downtime can be tremendously-\n&gt;&gt; Costly.\n\n554\n00:26:11.260 --> 00:26:13.090\n&gt;&gt; Yeah, very costly, that's right.\n\n555\n00:26:13.090 --> 00:26:14.920\nAnd it does affect availability.\n\n556\n00:26:14.920 --> 00:26:17.860\nI got a little diagram here, hopefully\nthis will help you out guys when it comes\n\n557\n00:26:17.860 --> 00:26:19.640\nto the mean time between failures.\n\n558\n00:26:19.640 --> 00:26:21.880\nSo we've got a device that's off, right?\n\n559\n00:26:21.880 --> 00:26:24.890\nSo we're not worry if it's off,\nif it's not functioning, but\n\n560\n00:26:24.890 --> 00:26:29.550\nwe've got a functioning period, and\nthen we've got a failure, right?\n\n561\n00:26:29.550 --> 00:26:32.640\nAnd it's failed,\nit's been offline for however long.\n\n562\n00:26:32.640 --> 00:26:34.620\nAnd then there's a repair that's made.\n\n563\n00:26:34.620 --> 00:26:38.590\nBrings it back online,\nbrings us back into our functioning state.\n\n564\n00:26:38.590 --> 00:26:41.680\nIt goes through whatever the life\ncycle is, whatever the device is,\n\n565\n00:26:41.680 --> 00:26:43.490\nthey all have different life cycles,\nright?\n\n566\n00:26:43.490 --> 00:26:45.610\nMeantime between failure,\nthere's another failure.\n\n567\n00:26:46.820 --> 00:26:47.930\nIt's down, it's down.\n\n568\n00:26:47.930 --> 00:26:50.680\nWe end up having another repair\nbrings it back to functionality.\n\n569\n00:26:50.680 --> 00:26:53.340\nNow I want you to know the in-between,\nsee the functionings?\n\n570\n00:26:54.860 --> 00:26:56.010\nAnd see the failures here.\n\n571\n00:26:56.010 --> 00:27:01.490\nWe can probably take something like this,\nif I can do that, right, and\n\n572\n00:27:01.490 --> 00:27:06.860\nunderstand MTBF is the Mean Time Between\nthe Failures, right?\n\n573\n00:27:06.860 --> 00:27:11.440\nNotice the time frame between\ntwo successive failures.\n\n574\n00:27:11.440 --> 00:27:17.150\nAll right, so that's one,\nthe last one is about the repair time.\n\n575\n00:27:17.150 --> 00:27:19.730\n&gt;&gt; So what is MTTR now?\n\n576\n00:27:19.730 --> 00:27:22.430\n&gt;&gt; That's another, that's, we're gonna\nstick an acronym in there right at\n\n577\n00:27:22.430 --> 00:27:24.420\nthe end and we're gonna go safe,\njust kidding.\n\n578\n00:27:24.420 --> 00:27:28.890\nThat is a Mean Time To Repair, so\nthe Mean Time Between Failures,\n\n579\n00:27:28.890 --> 00:27:33.100\nif you'll remember we said that is\nthe length of time between one and\n\n580\n00:27:33.100 --> 00:27:36.760\nsuccessive failures, if you will,\nsequential failures, all right?\n\n581\n00:27:36.760 --> 00:27:38.770\nNow the next one is\nthe Mean Time To Repair.\n\n582\n00:27:38.770 --> 00:27:40.420\nAnd using kinda the same diagram, but\n\n583\n00:27:40.420 --> 00:27:45.020\nslightly modified is now what we're doing\nis we're focusing on the repair time.\n\n584\n00:27:45.020 --> 00:27:48.980\nSo we have a failure, we're not really\nworried about how long the failure is,\n\n585\n00:27:48.980 --> 00:27:53.290\nwe're more focused on what is the time\nthat it takes to go from the failed state\n\n586\n00:27:53.290 --> 00:27:55.180\nback to the functioning state.\n\n587\n00:27:55.180 --> 00:28:00.120\nAll right, so basically, it just\ntakes into account the time that it\n\n588\n00:28:00.120 --> 00:28:02.120\ntakes to repair whatever\nthe failed component is.\n\n589\n00:28:02.120 --> 00:28:08.520\nSo remember, Mean Time Between Failure and\nMean Time To Repair for the exam.\n\n590\n00:28:08.520 --> 00:28:09.680\n&gt;&gt; Awesome, fantastic.\n\n591\n00:28:09.680 --> 00:28:10.485\nHey, thank you so much, Wes.\n\n592\n00:28:10.485 --> 00:28:12.726\n&gt;&gt; Absolutely.\n&gt;&gt; I mean, this was very engaging,\n\n593\n00:28:12.726 --> 00:28:14.015\nI learned an awful lot.\n\n594\n00:28:14.015 --> 00:28:17.318\nImpact business analysis\nwithin CompTIA Security+,\n\n595\n00:28:17.318 --> 00:28:19.925\nand there will be more CompTIA Security+.\n\n596\n00:28:19.925 --> 00:28:23.520\nAnd if you missed something, go back and\nwatch that, I mean I think you should.\n\n597\n00:28:23.520 --> 00:28:25.770\nAnyway, for ITProTV, I'm Zach Memos.\n\n598\n00:28:25.770 --> 00:28:26.760\n&gt;&gt; And I'm Wes Bryan.\n\n599\n00:28:26.760 --> 00:28:28.313\n&gt;&gt; And thank you for watching.\n\n600\n00:28:29.838 --> 00:28:35.822\n[MUSIC]\n\n601\n00:28:35.822 --> 00:28:39.086\nThank you for watching ITProTV.\n\n",
          "vimeoId": "216836000"
        },
        {
          "description": "Wes and Zach explain risk management processes and concepts, what are the components of threat assessments, the differences between internal and external assessments, risk assessment, ALE=SLE *ARO - quantitative assessment, plus risk response techniques (or strategies).",
          "length": "1883",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-3-risk_management_processes_and_concepts-051017-PGM.00_00_11_22.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-3-risk_management_processes_and_concepts-051017-PGM.00_00_11_22.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-3-risk_management_processes_and_concepts-051017-PGM.00_00_11_22.Still001-sm.jpg",
          "title": "Risk Management Processes and Concepts",
          "transcript": "WEBVTT\n\n1\n00:00:00.590 --> 00:00:02.425\nWelcome to ITProTV,\nI'm your host Don Pezet.\n\n2\n00:00:02.425 --> 00:00:07.731\n[CROSSTALK]\n\n3\n00:00:07.731 --> 00:00:11.237\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.237 --> 00:00:16.083\n&gt;&gt; Hello, you have made that\nintelligent choice to watch ITProTV,\n\n5\n00:00:16.083 --> 00:00:17.860\nthank you for that.\n\n6\n00:00:17.860 --> 00:00:20.150\nWe are helping you learn wherever you go.\n\n7\n00:00:20.150 --> 00:00:24.790\nI'm Zach Memos and I'm your host for, as\nwe continue one with CompTIA Security+ and\n\n8\n00:00:24.790 --> 00:00:29.290\nright now we're looking at\nrisk management processes and\n\n9\n00:00:29.290 --> 00:00:32.770\nconcepts with our IT pro, Wes Bryan.\n\n10\n00:00:32.770 --> 00:00:34.205\n&gt;&gt; Hey, thanks for having me back Zach.\n\n11\n00:00:34.205 --> 00:00:36.935\nThat's right we're going to be\nlooking at the bureaucratic red tape.\n\n12\n00:00:36.935 --> 00:00:37.775\nJust kidding.\n\n13\n00:00:37.775 --> 00:00:39.477\n&gt;&gt; Yay.\n&gt;&gt; There are some things that we have to\n\n14\n00:00:39.477 --> 00:00:42.075\nbe aware of when it comes\nto the Security+ exam and\n\n15\n00:00:42.075 --> 00:00:45.325\nsome of the things that they are gonna\nthrow you or throw at you I should say.\n\n16\n00:00:45.325 --> 00:00:46.612\nThey're not going to throw you.\n\n17\n00:00:46.612 --> 00:00:51.282\nThrow at you are different\ncomponents of risk assessment.\n\n18\n00:00:51.282 --> 00:00:55.012\nAnd that's what we are going to be\ntalking about right here in this episode.\n\n19\n00:00:55.012 --> 00:00:56.152\n&gt;&gt; So moving right into it,\n\n20\n00:00:56.152 --> 00:00:59.650\nwhat are some of the areas or\ncomponents of threat assessment?\n\n21\n00:00:59.650 --> 00:01:00.970\n&gt;&gt; Threat assessment, all right?\n\n22\n00:01:00.970 --> 00:01:04.950\nWe do have to understand that there\na lot of different threats out there.\n\n23\n00:01:04.950 --> 00:01:07.710\nSo we can have some different\nassessment types, right?\n\n24\n00:01:07.710 --> 00:01:08.600\nSo let's go ahead and\n\n25\n00:01:08.600 --> 00:01:13.860\nlet's talk about the threat assessment\ntypes that they do call out, right?\n\n26\n00:01:13.860 --> 00:01:15.550\nThey call out, well, three.\n\n27\n00:01:15.550 --> 00:01:19.460\nThey call out, I say three,\nlet me make sure that there are three.\n\n28\n00:01:19.460 --> 00:01:22.350\nThey call out environmental,\nthey call out man made, and\n\n29\n00:01:22.350 --> 00:01:24.450\nthey call out internal versus external.\n\n30\n00:01:24.450 --> 00:01:27.760\nSo let's go ahead let's take each one,\nwe'll kinda break it down here.\n\n31\n00:01:27.760 --> 00:01:29.350\nLet's start out with environmental, right.\n\n32\n00:01:29.350 --> 00:01:34.280\nWell what kind of environmental threats\nmight we be have to assess, right?\n\n33\n00:01:34.280 --> 00:01:35.910\nWell I want you to think first of all,\n\n34\n00:01:35.910 --> 00:01:38.250\none that comes to mind is\nthings like climate control.\n\n35\n00:01:38.250 --> 00:01:41.720\nNow, when I say climate control,\nI'm not talking about climate change here.\n\n36\n00:01:41.720 --> 00:01:45.477\nBut what we're talking about is think\nabout in your data centers, right.\n\n37\n00:01:45.477 --> 00:01:48.030\nYou have 1,000 servers.\n\n38\n00:01:48.030 --> 00:01:50.310\nYou have various racks, right?\n\n39\n00:01:50.310 --> 00:01:55.045\nWe have to make sure that we\nhave good HVAC systems in there.\n\n40\n00:01:55.045 --> 00:01:57.675\n&gt;&gt; Is this where we think about\nclean rooms and things like that?\n\n41\n00:01:57.675 --> 00:02:00.355\n&gt;&gt; It is,\nmaybe not to the extent of a clean room.\n\n42\n00:02:00.355 --> 00:02:04.155\nThe only reason I say that, the only\nreason I say that cuz it's close, is clean\n\n43\n00:02:04.155 --> 00:02:08.515\nrooms are when they are dealing with\nsensitive circuitry and they're dealing\n\n44\n00:02:08.515 --> 00:02:13.080\nwith things that where they're measuring\nin microns, one-millionth of a meter.\n\n45\n00:02:13.080 --> 00:02:15.320\nSo for instance,\nlet me give you a classic example,\n\n46\n00:02:15.320 --> 00:02:19.160\nlike if you work at a hard drive,\nyou're making hard drives.\n\n47\n00:02:19.160 --> 00:02:23.080\nThe actuator arm that goes\nacross those platters sits so\n\n48\n00:02:23.080 --> 00:02:27.330\nclose to I think it's like two or three\nmicrons sitting off of those platters\n\n49\n00:02:27.330 --> 00:02:32.010\nthat even a flick of dust getting\nin between the actuator motor and\n\n50\n00:02:32.010 --> 00:02:34.570\nthe platters themselves could\npermanently damage the system.\n\n51\n00:02:34.570 --> 00:02:36.930\nSo yes, you are thinking about that, but\n\n52\n00:02:36.930 --> 00:02:39.980\nI will tell you other things\nthat the clean rooms do,\n\n53\n00:02:39.980 --> 00:02:43.560\nkind of coincide with our data centers\nare things like electrostatic discharge.\n\n54\n00:02:43.560 --> 00:02:46.340\nWe have to worry about static discharge.\n\n55\n00:02:46.340 --> 00:02:48.970\nWhen it comes to your server environments,\nand I keep looking this way cuz I'm\n\n56\n00:02:48.970 --> 00:02:52.330\nkinda looking over to our server\ncloset off to the side say this.\n\n57\n00:02:52.330 --> 00:02:53.279\n&gt;&gt; Off camera we.\n\n58\n00:02:53.279 --> 00:02:54.630\n&gt;&gt; That's right.\n\n59\n00:02:54.630 --> 00:02:58.410\nWe have to worry about things\nlike it being too humid or\n\n60\n00:02:58.410 --> 00:02:59.390\nnot humid enough, right?\n\n61\n00:02:59.390 --> 00:03:04.330\nSo remember, not really an A+ show here\nbut remember, as you get more humidity,\n\n62\n00:03:04.330 --> 00:03:07.550\nyou have the chance for condensation,\ncondensation, moisture, if you will,\n\n63\n00:03:07.550 --> 00:03:12.500\nleads to short circuiting and\ndamage of your computer circuitry.\n\n64\n00:03:12.500 --> 00:03:15.600\nRemember the opposite side\nof the spectrum here.\n\n65\n00:03:15.600 --> 00:03:18.749\nKeep in mind that when we\nhave too little humidity,\n\n66\n00:03:18.749 --> 00:03:22.055\nwe don't have enough moisture,\nthe air gets drier.\n\n67\n00:03:22.055 --> 00:03:25.553\nThat's where it leads to static charge\ngeneration and remember static charge\n\n68\n00:03:25.553 --> 00:03:28.521\ngeneration turns around and\nleads to electrostatic discharge and\n\n69\n00:03:28.521 --> 00:03:31.330\nthe big thing about this is if\nyou're doing a threat assessment\n\n70\n00:03:31.330 --> 00:03:35.410\nyou're making sure that you have\na good climate control system, right.\n\n71\n00:03:35.410 --> 00:03:37.720\nWhere the humidity isn't too high,\ntoo low or\n\n72\n00:03:37.720 --> 00:03:39.656\nrelatively humidity around\n70 something percent.\n\n73\n00:03:39.656 --> 00:03:44.430\nI've heard 70%, 75%,\nbut relative humidity.\n\n74\n00:03:44.430 --> 00:03:48.330\nTemperature, temperature's another\nthing we have to worry about as well.\n\n75\n00:03:48.330 --> 00:03:52.420\nKeep in mind that all of\nour circuitry's very hot.\n\n76\n00:03:52.420 --> 00:03:53.970\nAll of our servers, very very hot,\n\n77\n00:03:53.970 --> 00:03:57.710\nthat's why have things like our cooling\nsystems internally in the machines.\n\n78\n00:03:57.710 --> 00:04:00.860\nWe also have things like hot aisle,\ncold aisle systems.\n\n79\n00:04:00.860 --> 00:04:05.690\nWe have just air conditioning if you will,\nso\n\n80\n00:04:05.690 --> 00:04:09.110\nalso have to make sure that\ntemperature isn't too hot or too cold.\n\n81\n00:04:09.110 --> 00:04:11.490\nNow in an environmental threat assessment,\n\n82\n00:04:11.490 --> 00:04:15.750\nwe might find that maybe somebody has\nrelatively easy access to the roof.\n\n83\n00:04:15.750 --> 00:04:19.430\nYou might say, well wait a second on the\nroof, they're still outside your building.\n\n84\n00:04:19.430 --> 00:04:22.920\nWell you gotta keep in mind\nWhere is the hot air going\n\n85\n00:04:22.920 --> 00:04:24.100\nthat's in your server closet?\n\n86\n00:04:24.100 --> 00:04:27.680\nIt's being shunted out the vents\ntypically to the ceiling,\n\n87\n00:04:27.680 --> 00:04:29.200\nit could be the side of\nthe building as well.\n\n88\n00:04:29.200 --> 00:04:32.210\n&gt;&gt; Yeah, there was a show I was\nwatching I won't mention the name, but\n\n89\n00:04:32.210 --> 00:04:35.040\nthey did a hack environmentally.\n\n90\n00:04:35.040 --> 00:04:36.970\nThey heated it up and things melted.\n\n91\n00:04:36.970 --> 00:04:39.100\n&gt;&gt; That's exactly it, and\nthat's where I was going with that,\n\n92\n00:04:39.100 --> 00:04:42.868\nif you think about it, if somebody's got\naccess, you do a threat assessment and\n\n93\n00:04:42.868 --> 00:04:46.120\nyou're like well, we've got open\nladders that anybody can get up there.\n\n94\n00:04:46.120 --> 00:04:50.390\nI mean it can be as simple as taking a\nquilt, throwing it over an exhaust fan and\n\n95\n00:04:50.390 --> 00:04:51.510\njust walking away.\n\n96\n00:04:51.510 --> 00:04:54.420\nAnd you're not there in the evening and\nit happens overnight and\n\n97\n00:04:54.420 --> 00:04:57.660\nthen everyone of your devices goes\ninto a thermal temperature shutdown,\n\n98\n00:04:57.660 --> 00:04:58.690\nright, a thermal shutdown.\n\n99\n00:04:58.690 --> 00:05:02.892\nSo we definitely have to\nworry about things like that.\n\n100\n00:05:02.892 --> 00:05:07.130\nThe other things that maybe isn't so\nobvious and will probably make sense\n\n101\n00:05:07.130 --> 00:05:09.990\nhere is things like water leaks,\nwe gotta worry about things like that.\n\n102\n00:05:09.990 --> 00:05:14.000\nAnd again, that could be anywhere\nfrom rain and flooding, right?\n\n103\n00:05:14.000 --> 00:05:18.880\nI know when our new building here,\nwe found that some of the landscaping was\n\n104\n00:05:18.880 --> 00:05:22.810\nlittle bit too high on the building where\nthey had pushed it against the wall.\n\n105\n00:05:22.810 --> 00:05:25.230\nSo what I was doing is I was\nmaking water puddle up and\n\n106\n00:05:25.230 --> 00:05:29.060\nthat water during a heavy rain was\nkinda seeping through the concrete and\n\n107\n00:05:29.060 --> 00:05:32.220\nkinda coming to one of\nthe portions of the building here.\n\n108\n00:05:32.220 --> 00:05:33.760\nSo what did they have to do right?\n\n109\n00:05:33.760 --> 00:05:36.560\nIf that was a threat assessment and\nwe were looking at a threat\n\n110\n00:05:36.560 --> 00:05:40.670\nlike that environmental threat like that,\nwe might find out that, hey, we gotta\n\n111\n00:05:40.670 --> 00:05:44.700\npull the landscaping back off the building\nso that we don't have that happen.\n\n112\n00:05:44.700 --> 00:05:47.240\nSo it doesn't just have to be rain and\nflooding.\n\n113\n00:05:47.240 --> 00:05:49.750\nIt could be things like your plumbing.\n\n114\n00:05:49.750 --> 00:05:52.870\nEspecially when you work at\na multi-level building, right?\n\n115\n00:05:52.870 --> 00:05:55.950\nMaybe you don't own\nthe level that's above you.\n\n116\n00:05:55.950 --> 00:05:57.890\nWell, you have to worry about\nthings like plumbing, as well.\n\n117\n00:05:57.890 --> 00:06:02.190\nBecause what happens if God forbid,\nI mean, somebody flushes a toilet,\n\n118\n00:06:02.190 --> 00:06:04.770\nit overflows and it makes its way\ndown into your data center or\n\n119\n00:06:04.770 --> 00:06:05.690\ninto your server closet.\n\n120\n00:06:05.690 --> 00:06:07.650\n&gt;&gt; Or\nextreme polka dancers right above you.\n\n121\n00:06:07.650 --> 00:06:08.170\n&gt;&gt; Yeah, that's right.\n\n122\n00:06:08.170 --> 00:06:09.590\nYou definitely have to worry about that.\n\n123\n00:06:09.590 --> 00:06:10.540\nI've never seen those but\n\n124\n00:06:10.540 --> 00:06:14.593\nI'm sure it's probably on\nthe conditional clause somewhere.\n\n125\n00:06:14.593 --> 00:06:19.447\nNext one, this is man made.\n\n126\n00:06:19.447 --> 00:06:21.820\nMan made, this can be intentional.\n\n127\n00:06:21.820 --> 00:06:23.020\nIt can be unintentional.\n\n128\n00:06:23.020 --> 00:06:25.080\nWe also have to look at\nunintentional threats.\n\n129\n00:06:25.080 --> 00:06:28.800\nAn intentional threat are some of\nthe obvious ones that we think of,\n\n130\n00:06:28.800 --> 00:06:29.990\ncyber attacks.\n\n131\n00:06:29.990 --> 00:06:31.220\nI'm gonna say malware.\n\n132\n00:06:31.220 --> 00:06:32.600\nAll inclusive.\n\n133\n00:06:32.600 --> 00:06:35.800\nGo back to one of our other episodes\nwhere we kind of defined the different\n\n134\n00:06:35.800 --> 00:06:36.980\ntypes of malware.\n\n135\n00:06:36.980 --> 00:06:38.250\nI'm using it as an umbrella term.\n\n136\n00:06:38.250 --> 00:06:41.510\nIt could be viruses, could be rootkits,\nTrojans, if you will.\n\n137\n00:06:41.510 --> 00:06:46.050\nLogic bombs, botnets, all the things\nthat fall under malware, right?\n\n138\n00:06:46.050 --> 00:06:48.190\nCould be a cybersecurity attack.\n\n139\n00:06:48.190 --> 00:06:50.600\nWe've got to do threat assessments for\ncybersecurity attacks, right?\n\n140\n00:06:50.600 --> 00:06:55.840\nWe could have something like a hactivist,\nif you will, trying to attack our system.\n\n141\n00:06:55.840 --> 00:06:57.110\nSo again, man made.\n\n142\n00:06:57.110 --> 00:06:59.818\nCould be things like physical\nsecurity attacks, right?\n\n143\n00:06:59.818 --> 00:07:02.810\nYou spend $100,000 on your\nsecurity systems right?\n\n144\n00:07:02.810 --> 00:07:06.040\nYou have all these cameras,\nyou have electronic RFID key fobs\n\n145\n00:07:06.040 --> 00:07:08.180\nthat you have to use to get\ninto secure access doors.\n\n146\n00:07:08.180 --> 00:07:11.130\nAnd somebody takes a $0.50\nrubber door stopper and\n\n147\n00:07:11.130 --> 00:07:15.050\nbypasses a whole entire security system\ncuz they propped a door open right?\n\n148\n00:07:15.050 --> 00:07:17.630\nA threat assessment might find\nout that that might be the case.\n\n149\n00:07:17.630 --> 00:07:19.100\nIt might be something that can happen.\n\n150\n00:07:19.100 --> 00:07:23.590\nSo it could be a physical security attack\nthat we're trying to prevent against\n\n151\n00:07:23.590 --> 00:07:26.940\nas part of the man-made threat assessment.\n\n152\n00:07:26.940 --> 00:07:28.090\nHere's one of the big ones.\n\n153\n00:07:28.090 --> 00:07:31.070\nIn fact, OWASP, what is it,\n\n154\n00:07:31.070 --> 00:07:36.300\nOpen Web Application, I can't think\nof what OWASP stand for right now.\n\n155\n00:07:36.300 --> 00:07:38.630\nBut they have one of their big ten lists,\n\n156\n00:07:38.630 --> 00:07:43.570\ntop ten lists, misconfiguration,\nthat happens a lot, right?\n\n157\n00:07:43.570 --> 00:07:48.582\nMisconfiguration of your systems, of your\napplications, ACLs, access control lists.\n\n158\n00:07:48.582 --> 00:07:49.897\nMaybe they're too strict.\n\n159\n00:07:49.897 --> 00:07:54.310\nYou're not giving authorized users access\nor maybe they're not strict enough.\n\n160\n00:07:54.310 --> 00:07:56.137\nYou have unauthorized access.\n\n161\n00:07:56.137 --> 00:07:58.591\nAnd again I can intentional or\ncan be unintentional.\n\n162\n00:07:58.591 --> 00:08:02.101\nSo that's a couple of the ones that\nI would worry about when it comes to\n\n163\n00:08:02.101 --> 00:08:05.380\nenvironmental and it comes to\nthe man made threat assessments.\n\n164\n00:08:05.380 --> 00:08:08.080\n&gt;&gt; So now let's talk about internal and\nexternal.\n\n165\n00:08:08.080 --> 00:08:09.600\nWhat are the differences?\n\n166\n00:08:09.600 --> 00:08:15.130\n&gt;&gt; Very good, so with internal throughout\nassessment, when we talk about that.\n\n167\n00:08:15.130 --> 00:08:19.300\nOne of the easiest ones and,\nI don't know if it's obvious or not,\n\n168\n00:08:19.300 --> 00:08:20.880\nis lack of training.\n\n169\n00:08:20.880 --> 00:08:22.700\nRight?\nLack of training usually equates to some\n\n170\n00:08:22.700 --> 00:08:24.190\nkind of user error.\n\n171\n00:08:24.190 --> 00:08:26.080\nAgain, it doesn't have to be intentional.\n\n172\n00:08:26.080 --> 00:08:31.135\nIf people aren't aware of what\nthey're suppose to be doing as a user,\n\n173\n00:08:31.135 --> 00:08:35.225\nthey're responsible for\na certain portion of security, right?\n\n174\n00:08:35.225 --> 00:08:36.945\nWhat do I mean that\nthey're responsible for?\n\n175\n00:08:36.945 --> 00:08:39.935\nDoes that mean they have to set\nup the RFID key fob system?\n\n176\n00:08:39.935 --> 00:08:40.735\nNo.\nWhat that means,\n\n177\n00:08:40.735 --> 00:08:43.895\nthey need to be trained as why\nthey don't share passwords.\n\n178\n00:08:43.895 --> 00:08:47.855\nThey need to be trained as why\nyou don't hold a door open for\n\n179\n00:08:47.855 --> 00:08:51.040\nsomebody even if they look like\nthey're let's say with the UPS, right?\n\n180\n00:08:51.040 --> 00:08:54.870\nI can go down to any kind of custom\nstore and I can get a UPS shirt on.\n\n181\n00:08:54.870 --> 00:08:57.030\nAnd our human nature says,\nwell guess what?\n\n182\n00:08:57.030 --> 00:08:59.070\nWe wanna help somebody which\nis somebody in trouble right?\n\n183\n00:08:59.070 --> 00:09:04.100\nWe fumble a box as we going towards at\ndoor and I look like I'm a UPS suit.\n\n184\n00:09:04.100 --> 00:09:07.490\nSomebody says, let me hold that door\nopen for you, so remember training.\n\n185\n00:09:07.490 --> 00:09:10.570\nThat's one of the big things\nwith internal threats,\n\n186\n00:09:10.570 --> 00:09:15.250\nis a lot of times, the internal threats\ncould be lack of security training.\n\n187\n00:09:15.250 --> 00:09:20.390\n&gt;&gt; There was an ITPro employee just\ntoday And he, you trying to get in?\n\n188\n00:09:20.390 --> 00:09:21.075\nWho are you?\n\n189\n00:09:21.075 --> 00:09:21.930\n[LAUGH]\n&gt;&gt; Yeah,\n\n190\n00:09:21.930 --> 00:09:22.990\nyeah and-\n&gt;&gt; And\n\n191\n00:09:22.990 --> 00:09:26.530\nhe assessed who I was,\nokay that's just Zach all right fine.\n\n192\n00:09:26.530 --> 00:09:28.680\n&gt;&gt; And\nthat's what a threat assessment might say,\n\n193\n00:09:28.680 --> 00:09:29.310\njust proper-\n&gt;&gt; Right, right.\n\n194\n00:09:29.310 --> 00:09:30.550\nNo, that was the right thing to do,\nI think.\n\n195\n00:09:30.550 --> 00:09:33.380\n&gt;&gt; Yeah, proper vetting of the people that\nare coming in and out of your building.\n\n196\n00:09:33.380 --> 00:09:35.780\n&gt;&gt; Right.\n&gt;&gt; Having some kind of logging system,\n\n197\n00:09:35.780 --> 00:09:39.300\nand remember, it's not about the component\nthat we're putting in place here,\n\n198\n00:09:39.300 --> 00:09:42.900\nit's about realizing if those components\nare in place or are not in place.\n\n199\n00:09:42.900 --> 00:09:48.650\nThe other thing, malicious insider,\nright, disgruntled employee, a person\n\n200\n00:09:48.650 --> 00:09:52.180\nwas passed up on a promotion, sees\nthe person next to them work half the time\n\n201\n00:09:52.180 --> 00:09:56.090\nas they have was promoted to the spot that\nthat person thought they should have.\n\n202\n00:09:56.090 --> 00:09:57.150\nNow you got a disgruntled employee.\n\n203\n00:09:57.150 --> 00:09:59.212\nSo it could be something\nlike a malicious insider.\n\n204\n00:09:59.212 --> 00:10:01.397\nIt could be data leaks.\n\n205\n00:10:01.397 --> 00:10:06.265\nData leaks could be people using mobile\ndevices to access corporate data\n\n206\n00:10:06.265 --> 00:10:09.690\nwhen it's against\nan acceptable use policy.\n\n207\n00:10:09.690 --> 00:10:11.490\nAgain that would go back to training but,\nagain,\n\n208\n00:10:11.490 --> 00:10:14.950\nit doesn't have to be intentional\nCould be intentional, right?\n\n209\n00:10:14.950 --> 00:10:17.960\nIt could be the fact that you don't\nhave defense in depth, right?\n\n210\n00:10:17.960 --> 00:10:19.410\nThat layered defense system, right?\n\n211\n00:10:19.410 --> 00:10:23.820\nPhysical security, network security,\nparameter security, network security,\n\n212\n00:10:23.820 --> 00:10:28.190\nhost security, application security,\nand then data security, right?\n\n213\n00:10:28.190 --> 00:10:30.356\nSo a layer defense system.\n\n214\n00:10:30.356 --> 00:10:34.320\n&gt;&gt; So Wes is it external, is that\noutside of the physical building or\n\n215\n00:10:34.320 --> 00:10:38.830\nthe physical confines of your home or\noffice or business?\n\n216\n00:10:38.830 --> 00:10:39.710\n&gt;&gt; It's interesting,\n\n217\n00:10:39.710 --> 00:10:43.600\nit doesn't have to reduce itself\nto an actual physical location.\n\n218\n00:10:43.600 --> 00:10:46.150\nAnd let me tell you why,\nbecause with things like cloud technology.\n\n219\n00:10:47.330 --> 00:10:50.290\nI'm sure you've logged into your\nemail when you haven't been\n\n220\n00:10:50.290 --> 00:10:52.060\nin this building itself, right?\n\n221\n00:10:52.060 --> 00:10:52.850\n&gt;&gt; Absolutely.\n\n222\n00:10:52.850 --> 00:10:54.670\n&gt;&gt; The email is still\ninternal to the company.\n\n223\n00:10:54.670 --> 00:10:56.380\nDoesn't matter where you log into it.\n\n224\n00:10:56.380 --> 00:11:00.850\nSo, internal could be that you're internal\nto the company regardless of what your\n\n225\n00:11:00.850 --> 00:11:05.650\nphysical location is, right, because If\nwe have cloud based technologies, right?\n\n226\n00:11:05.650 --> 00:11:07.360\nSomebody logs into Office 365,\n\n227\n00:11:07.360 --> 00:11:10.140\nthey don't have to be in this\nbuilding physically to do that.\n\n228\n00:11:10.140 --> 00:11:12.130\nBut if a misuse happens,\n\n229\n00:11:12.130 --> 00:11:18.000\nit doesn't matter where they're located it\ncould cause some kind of threat for us.\n\n230\n00:11:18.000 --> 00:11:19.300\nThen there's external.\n\n231\n00:11:19.300 --> 00:11:23.690\nAnd external again, an external attack,\nthis is where we have things like your\n\n232\n00:11:23.690 --> 00:11:26.550\nhactivitst, could be\nyour nation states right?\n\n233\n00:11:26.550 --> 00:11:30.230\nAdvanced persistent threats,\nif you will, could\n\n234\n00:11:30.230 --> 00:11:34.500\nbe the malicious insider helping somebody\non the outside, so that could happen, too.\n\n235\n00:11:35.500 --> 00:11:38.830\nBusiness data on company devices,\nthat can always be a problem.\n\n236\n00:11:38.830 --> 00:11:40.560\nReputation based attacks.\n\n237\n00:11:40.560 --> 00:11:43.720\nHere's something that you maybe\nhaven't thought about before.\n\n238\n00:11:43.720 --> 00:11:44.310\nSocial media.\n\n239\n00:11:44.310 --> 00:11:44.850\nAll right?\n\n240\n00:11:44.850 --> 00:11:48.443\nNow, I'm sure you thought of social media\nso let me go ahead, and back up, and\n\n241\n00:11:48.443 --> 00:11:49.156\nrestate that.\n\n242\n00:11:49.156 --> 00:11:51.004\n&gt;&gt; [LAUGH]\n&gt;&gt; Is the fact that people can use\n\n243\n00:11:51.004 --> 00:11:53.779\nthe social media to ruin\nthe reputation of your company.\n\n244\n00:11:53.779 --> 00:11:55.410\nIt can be a reputation-based attack.\n\n245\n00:11:55.410 --> 00:11:57.420\nSo that can be an external type of attack,\nas well.\n\n246\n00:11:57.420 --> 00:11:59.310\n&gt;&gt; Back in the day, that was called libel.\n\n247\n00:11:59.310 --> 00:12:05.250\n&gt;&gt; Yeah yep so social media, websites,\nposting to websites, posting to forums.\n\n248\n00:12:05.250 --> 00:12:06.870\nThat says that company's horrible so\n\n249\n00:12:06.870 --> 00:12:09.600\nwe have to worry about\nthings like that as well.\n\n250\n00:12:09.600 --> 00:12:13.000\nOne little category I put\nin here as far as external\n\n251\n00:12:13.000 --> 00:12:15.000\nthreat assessments are things\nlike mobile devices.\n\n252\n00:12:15.000 --> 00:12:18.750\nBecause of the fact that we have so many\nmobile devices that are being used inside\n\n253\n00:12:18.750 --> 00:12:23.060\nof our companies, we are very\nsusceptible to mobile exploitation.\n\n254\n00:12:23.060 --> 00:12:28.050\nSo for instance lack of encryption on\nyour devices, malware, phishing scams,\n\n255\n00:12:28.050 --> 00:12:31.820\nthings like your social media,\nuntrusted application sources.\n\n256\n00:12:31.820 --> 00:12:33.620\nThink about this.\n\n257\n00:12:33.620 --> 00:12:34.180\nA lot of people,\n\n258\n00:12:34.180 --> 00:12:37.910\nmaybe you guys have done this out there\nwhere you turn on the developer options.\n\n259\n00:12:37.910 --> 00:12:41.310\nA lot of fun, but it's not without risk.\n\n260\n00:12:41.310 --> 00:12:45.800\nBecause of your turning these developing,\nsome of these untested settings if you\n\n261\n00:12:45.800 --> 00:12:50.440\nwill on, there could be consequences for\nthat, so do keep that in mind.\n\n262\n00:12:50.440 --> 00:12:53.000\n&gt;&gt; Hey Wes,\ncan we look at the different types of,\n\n263\n00:12:53.000 --> 00:12:55.370\nor different areas of risk assessment?\n\n264\n00:12:55.370 --> 00:12:56.700\n&gt;&gt; Yeah, Zach,\nwhat do you say we go ahead,\n\n265\n00:12:56.700 --> 00:12:59.040\nwe'll look at some of those\nrisk assessment concepts.\n\n266\n00:12:59.040 --> 00:13:00.530\nNow on the exam,\n\n267\n00:13:00.530 --> 00:13:03.410\nkeep in mind that you're just gonna have\nto know some of the basic terminology.\n\n268\n00:13:03.410 --> 00:13:08.840\nAnd of course, we would never be doing\na good Security+ course if well,\n\n269\n00:13:08.840 --> 00:13:10.070\nwe didn't mention some acronyms.\n\n270\n00:13:10.070 --> 00:13:12.768\nSo we're gonna throw a little\nalphabet soup your way, but\n\n271\n00:13:12.768 --> 00:13:15.700\nhopefully we'll hand you a spoon and\nshow you how to eat it too.\n\n272\n00:13:15.700 --> 00:13:17.490\nSo you'll understand it at the end.\n\n273\n00:13:17.490 --> 00:13:18.520\n&gt;&gt; I like that Wes.\n\n274\n00:13:18.520 --> 00:13:22.300\n&gt;&gt; Absolutely, so the first thing they\ncall out is what's known as an SLE,\n\n275\n00:13:22.300 --> 00:13:25.070\nthat is a single loss expectancy.\n\n276\n00:13:25.070 --> 00:13:29.790\nIf a risk event happens one time,\nwhat is it gonna cost the company?\n\n277\n00:13:31.010 --> 00:13:35.780\nWe also have what's known as an ARO,\nthat's your annual rate of occurrence.\n\n278\n00:13:35.780 --> 00:13:38.750\nHow often is that gonna\nhappen within a given year?\n\n279\n00:13:38.750 --> 00:13:41.720\nAnd then the annual loss expectancy.\n\n280\n00:13:41.720 --> 00:13:44.630\nIf if happens once,\nwe know it costs us this.\n\n281\n00:13:44.630 --> 00:13:48.380\nWell, how much is it gonna cost\nus over the course of a year?\n\n282\n00:13:48.380 --> 00:13:52.720\nAnd there is a formula that\nyou can find when it comes to\n\n283\n00:13:52.720 --> 00:13:55.130\nfiguring out what is your\nannual loss expectancy.\n\n284\n00:13:55.130 --> 00:13:58.340\nSo, lets go ahead,\nlet me show you my screen here.\n\n285\n00:13:58.340 --> 00:14:03.940\nALE annual loss expectancy you can\nsee that is equal to your SLE,\n\n286\n00:14:03.940 --> 00:14:09.280\nif you will, times your ARO, all right?\n\n287\n00:14:09.280 --> 00:14:12.180\nThis is how we figure out what\nthe annual loss expectancy is.\n\n288\n00:14:12.180 --> 00:14:14.380\nSo let's give you an example here.\n\n289\n00:14:14.380 --> 00:14:19.210\nSo let's say we buy this unified\nthreat management device, all right?\n\n290\n00:14:19.210 --> 00:14:23.078\nAnd let's say that it costs I don't know,\n\n291\n00:14:23.078 --> 00:14:26.830\nwe'll say $4,000 $4000,\ngreat number there.\n\n292\n00:14:26.830 --> 00:14:28.410\nWe'll say it costs $4000.\n\n293\n00:14:28.410 --> 00:14:31.070\nWas that a good investment?\n\n294\n00:14:32.260 --> 00:14:33.410\nI don't know.\n\n295\n00:14:33.410 --> 00:14:34.410\nDo we spend too much money?\n\n296\n00:14:34.410 --> 00:14:36.270\nDo we spend too little money?\n\n297\n00:14:36.270 --> 00:14:37.170\nI don't know!\n\n298\n00:14:37.170 --> 00:14:39.270\nThat's what this formula is about.\n\n299\n00:14:39.270 --> 00:14:42.950\nDid we get our bang for our buck, if you\nwill, maybe you've heard that before.\n\n300\n00:14:42.950 --> 00:14:46.960\nSo all right, let's say, okay, let's\ngo through some of these numbers here.\n\n301\n00:14:46.960 --> 00:14:49.940\nAnd like I said guys, at a high level,\nthey're really just gonna want you to\n\n302\n00:14:49.940 --> 00:14:54.190\nunderstand what is the ALE,\nwhat is the SLE and what is the ARO?\n\n303\n00:14:54.190 --> 00:14:56.140\nBut, let's give you an example here, okay.\n\n304\n00:14:56.140 --> 00:15:00.880\nSo ALE is usually a measurement,\nright, over 12 months,\n\n305\n00:15:00.880 --> 00:15:05.860\nall right, so 12, oops if I can type,\n12 months, all right.\n\n306\n00:15:05.860 --> 00:15:09.310\nLet's say that a breach happens though.\n\n307\n00:15:09.310 --> 00:15:11.860\nAll right, so,\nlet's say we got a data breach.\n\n308\n00:15:13.620 --> 00:15:19.640\nAnd that data breach\nhappens 6 times per year.\n\n309\n00:15:21.680 --> 00:15:23.900\nOops, year, there we go,\nI swear I can spell.\n\n310\n00:15:25.090 --> 00:15:31.906\nThe data breach,\neach breach costs the company,\n\n311\n00:15:31.906 --> 00:15:35.814\n$1,000, all right?\n\n312\n00:15:35.814 --> 00:15:39.100\nNow, so we've got some data, all right?\n\n313\n00:15:39.100 --> 00:15:42.451\nAnd we've also got monetary\nvalues set to this data as well.\n\n314\n00:15:42.451 --> 00:15:45.248\nThat's what known as\na quantitative assessment.\n\n315\n00:15:45.248 --> 00:15:51.486\nQuantitative assessments try to assign\na monetary value to everything, all right?\n\n316\n00:15:51.486 --> 00:15:55.505\nSo If our ALE is 12 months,\n\n317\n00:15:55.505 --> 00:16:00.990\nour data breach, right, is our ARO.\n\n318\n00:16:00.990 --> 00:16:06.000\nThat is our annual rate of occurrence,\nit's gonna occur six times a year.\n\n319\n00:16:06.000 --> 00:16:11.810\nEach breach costs the company $1,000,\nthat's our single loss expectancy.\n\n320\n00:16:11.810 --> 00:16:14.482\nAll right, so\nlet's see if we can figure this out.\n\n321\n00:16:14.482 --> 00:16:20.256\nAll right, if I take our ALE.\n\n322\n00:16:20.256 --> 00:16:22.817\nWhoops, there we go, let's try that again.\n\n323\n00:16:22.817 --> 00:16:27.850\nIf I take our ALE, and\nour ALE is 12 months.\n\n324\n00:16:27.850 --> 00:16:29.230\nActually, we'll do this\na little bit different.\n\n325\n00:16:29.230 --> 00:16:31.070\nLet's do, our SLE is $1,000.\n\n326\n00:16:31.070 --> 00:16:33.008\nThat's where we wanna be,\nsorry about that, guys.\n\n327\n00:16:33.008 --> 00:16:34.640\nSLE is $1000, right?\n\n328\n00:16:34.640 --> 00:16:38.100\nAnd remember,\nwe said if wanna find out what the ALE is?\n\n329\n00:16:38.100 --> 00:16:41.850\nWe're gonna take our SLE, and\nwe're gonna multiply it by our ARO.\n\n330\n00:16:41.850 --> 00:16:45.350\nAgain, SLE, single loss expectancy,\ntimes our annual rate of occurrence.\n\n331\n00:16:45.350 --> 00:16:48.770\nSo since our SLE is $1,000, all right.\n\n332\n00:16:48.770 --> 00:16:52.840\nOur ARO,\nit's gonna happen six times in a year.\n\n333\n00:16:52.840 --> 00:16:55.070\nThat means we're gonna multiply times six.\n\n334\n00:16:56.170 --> 00:16:58.150\nAll right, and then we'll go ahead and\nget our value.\n\n335\n00:16:58.150 --> 00:16:59.220\nAll right, what do you got there, Zach?\n\n336\n00:16:59.220 --> 00:17:00.230\nCan you help me out with my math?\n\n337\n00:17:00.230 --> 00:17:01.925\nMy math is just as bad as my typing.\n\n338\n00:17:01.925 --> 00:17:03.126\n&gt;&gt; 42.\n&gt;&gt; 42?\n\n339\n00:17:03.126 --> 00:17:05.788\n&gt;&gt; [LAUGH]\n&gt;&gt; He actually got me on that.\n\n340\n00:17:05.788 --> 00:17:06.870\n&gt;&gt; That's the answer for everything!\n\n341\n00:17:06.870 --> 00:17:07.934\n&gt;&gt; That's right, that's not fair, Zack.\n\n342\n00:17:07.934 --> 00:17:10.680\n&gt;&gt; [LAUGH]\n&gt;&gt; So it's gonna be, what, $6,000?\n\n343\n00:17:10.680 --> 00:17:11.400\n&gt;&gt; $6,000.\n\n344\n00:17:11.400 --> 00:17:12.850\n&gt;&gt; $6,000, okay.\n\n345\n00:17:12.850 --> 00:17:15.882\nSo when the company asks us, all right?\n\n346\n00:17:15.882 --> 00:17:20.220\nWe spent $4,000 on a unified\nthreat management device, okay?\n\n347\n00:17:20.220 --> 00:17:23.950\nAnd the company says,\ndid we get our money's worth?\n\n348\n00:17:23.950 --> 00:17:30.230\nWell, the potential for\nthis to cost us $6,000 in damage, in risk.\n\n349\n00:17:30.230 --> 00:17:34.090\nIt's $6,000, is what it's gonna us\nper year, and we invested $4,000.\n\n350\n00:17:34.090 --> 00:17:35.640\nWell, it looks like we're up by $2,000.\n\n351\n00:17:35.640 --> 00:17:36.830\n&gt;&gt; I knew that was a good investment.\n\n352\n00:17:36.830 --> 00:17:40.240\n&gt;&gt; Right, so we have made our money,\nthis was a good investment.\n\n353\n00:17:40.240 --> 00:17:44.960\nAnd again, this is an example of\na quantitative assessment, right.\n\n354\n00:17:44.960 --> 00:17:45.680\nIt's a risk assessment,\n\n355\n00:17:45.680 --> 00:17:50.290\nbut it's giving a monetary value\nto every risk within our company.\n\n356\n00:17:50.290 --> 00:17:53.650\nUnlike what a qualitative\nassessment would be, right?\n\n357\n00:17:53.650 --> 00:17:57.530\nA qualitative assessment's not gonna\nassign things like monetary values, right.\n\n358\n00:17:57.530 --> 00:18:01.340\nIt's gonna assign things like\ndescriptions, if you will.\n\n359\n00:18:01.340 --> 00:18:07.180\nSo are you at Low Risk,\nright, Medium Risk?\n\n360\n00:18:08.940 --> 00:18:11.070\nRight, we might say Medium Risk.\n\n361\n00:18:11.070 --> 00:18:13.760\nWe might say High Risk.\n\n362\n00:18:13.760 --> 00:18:19.161\nAnd this is always and, again with\na qualitative assessment, right?\n\n363\n00:18:19.161 --> 00:18:25.860\nWe're gonna be using different things\nto ensure that we get accurate data.\n\n364\n00:18:25.860 --> 00:18:29.760\nWe're gonna be using things like groups,\nwere gonna be using things like surveys,\n\n365\n00:18:29.760 --> 00:18:30.840\nif you will.\n\n366\n00:18:30.840 --> 00:18:33.100\nQuestions, we're gonna do interviews,\nright.\n\n367\n00:18:33.100 --> 00:18:35.090\nAnd we're going to get that\ninformation back, right.\n\n368\n00:18:35.090 --> 00:18:38.540\nAnd then we're gonna use these\ndescriptors, not monetary values, right.\n\n369\n00:18:38.540 --> 00:18:44.370\nWe might say something like\nLow Risk = Low Impact.\n\n370\n00:18:44.370 --> 00:18:45.410\nAll right, what is impact?\n\n371\n00:18:45.410 --> 00:18:48.639\nImpact is consequences, that's what it\ncomes down to, that's what an impact is.\n\n372\n00:18:48.639 --> 00:18:50.851\nIt's a consequence to your company, right?\n\n373\n00:18:50.851 --> 00:18:54.010\nIf a risk event happens,\nWhat is the impact to your company?\n\n374\n00:18:54.010 --> 00:18:55.160\nWhat's the consequences, right?\n\n375\n00:18:55.160 --> 00:18:57.330\nSo I might say this is Low Impact, right.\n\n376\n00:18:57.330 --> 00:19:02.560\nI might say something like,\nthis is Medium Impact, right.\n\n377\n00:19:02.560 --> 00:19:04.130\nAnd again, what we're talking about.\n\n378\n00:19:04.130 --> 00:19:07.375\nNotice that it's not\nnecessarily a monetary value,\n\n379\n00:19:07.375 --> 00:19:09.865\nas more as it is just a descriptive term.\n\n380\n00:19:09.865 --> 00:19:13.155\nAnd the descriptive terms\ncould be subjective as well.\n\n381\n00:19:13.155 --> 00:19:16.005\nI'll give you one that really\ndoesn't have to do with IT, but\n\n382\n00:19:16.005 --> 00:19:17.135\nI want you to think of it this way.\n\n383\n00:19:17.135 --> 00:19:19.675\nIn fact, Zack and\nI we're talking about this off-camera.\n\n384\n00:19:19.675 --> 00:19:23.535\nImagine if I want to find out\nwhich companies have better fries.\n\n385\n00:19:23.535 --> 00:19:25.215\nLet's say.\nMcDonald's versus Burger King.\n\n386\n00:19:25.215 --> 00:19:27.580\nNow, hold whatever your\nanswer is right now.\n\n387\n00:19:27.580 --> 00:19:32.130\nThere's a couple different ways I could\nfigure out who is liking McDonald's fries,\n\n388\n00:19:32.130 --> 00:19:35.020\nright, versus Burger King, or vice versa.\n\n389\n00:19:35.020 --> 00:19:38.110\nWell, I could say monetary value,\nI wanna see the receipts.\n\n390\n00:19:38.110 --> 00:19:42.100\nLet me see how much sales we had, right.\n\n391\n00:19:42.100 --> 00:19:44.840\nAnd that maybe could be\nthe statistics that I use,\n\n392\n00:19:44.840 --> 00:19:47.350\nto figure out who likes what better,\nright?\n\n393\n00:19:47.350 --> 00:19:50.560\nOr we can do it something\nlittle bit different, right?\n\n394\n00:19:50.560 --> 00:19:54.380\nI can say, Zack,\nwhich one do you feel is better, right?\n\n395\n00:19:54.380 --> 00:19:55.835\nWe can implement surveys and questions.\n\n396\n00:19:55.835 --> 00:19:56.881\n&gt;&gt; [CROSSTALK] Very subjective, as well.\n\n397\n00:19:56.881 --> 00:20:01.025\n&gt;&gt; Exactly, so the qualitative assessment\nis going be a little more subjective.\n\n398\n00:20:01.025 --> 00:20:03.380\nCuz it's going to use terms like,\nI thought they were great.\n\n399\n00:20:03.380 --> 00:20:09.010\nAgain, poor, very poor, good,\nvery good, excellent, right?\n\n400\n00:20:09.010 --> 00:20:10.210\nThe best, if you will.\n\n401\n00:20:10.210 --> 00:20:14.370\n&gt;&gt; You could even take a look at how\nmuch product they go through annually.\n\n402\n00:20:14.370 --> 00:20:15.440\n&gt;&gt; Yes.\n\n403\n00:20:15.440 --> 00:20:19.500\n&gt;&gt; Burger King goes through 14\nbillion pounds of potatoes,\n\n404\n00:20:19.500 --> 00:20:22.010\nas opposed to McDonald's going through 13.\n\n405\n00:20:22.010 --> 00:20:25.390\n&gt;&gt; Yeah, so it's not necessarily\na monetary value, that they're saying.\n\n406\n00:20:25.390 --> 00:20:27.290\nSo do keep that in mind.\n\n407\n00:20:27.290 --> 00:20:31.330\nKnow some of the terms,\nwhen it comes to single loss expectancy.\n\n408\n00:20:31.330 --> 00:20:34.364\nKnow the annual loss expectancy,\nif you will.\n\n409\n00:20:34.364 --> 00:20:37.600\nAnd the annual or\nannualized rate of occurrence.\n\n410\n00:20:37.600 --> 00:20:40.130\nYou might hear it called\nannual rate of occurrence, but\n\n411\n00:20:40.130 --> 00:20:42.360\nyou'll also hear it called\nannualized rate of occurrence.\n\n412\n00:20:42.360 --> 00:20:44.150\nGuys, tomato, tomato on that one.\n\n413\n00:20:44.150 --> 00:20:46.352\nSo don't let that trip you up on the exam.\n\n414\n00:20:46.352 --> 00:20:47.071\n&gt;&gt; Potato, potato.\n\n415\n00:20:47.071 --> 00:20:48.560\n&gt;&gt; That's right, so Zack,\n\n416\n00:20:48.560 --> 00:20:51.400\nyou asked about some of these\nother risk assessment concepts?\n\n417\n00:20:51.400 --> 00:20:52.655\n&gt;&gt; Yeah, like supply chain assessment?\n\n418\n00:20:52.655 --> 00:20:53.875\n&gt;&gt; Supply chain assessment, okay.\n\n419\n00:20:53.875 --> 00:20:56.615\nSo why are we worried about supply chains,\nand\n\n420\n00:20:56.615 --> 00:20:58.795\nwhy would we do an assessment on it,\nalright?\n\n421\n00:20:58.795 --> 00:21:02.997\nWell in another episode, we talked\nabout supply chain attacks, okay.\n\n422\n00:21:02.997 --> 00:21:06.403\nSo there's actually been a couple of\nthese that have happened over the course\n\n423\n00:21:06.403 --> 00:21:08.427\nof the last couple of years.\n\n424\n00:21:08.427 --> 00:21:10.947\nWell, I want you think about\nif you're a manufacturer.\n\n425\n00:21:10.947 --> 00:21:14.467\nAnd you have to go to different\nvendors to buy products,\n\n426\n00:21:14.467 --> 00:21:15.977\nto manufacture your products, right?\n\n427\n00:21:15.977 --> 00:21:17.517\nSo you have a supply chain.\n\n428\n00:21:17.517 --> 00:21:20.447\nYou have a supply chain of vendors that\nare providing you with the parts to\n\n429\n00:21:20.447 --> 00:21:22.677\ncomplete whatever it is\nthat you are working on.\n\n430\n00:21:22.677 --> 00:21:23.177\n&gt;&gt; Your widget.\n\n431\n00:21:24.677 --> 00:21:25.487\n&gt;&gt; That's a great, treat example.\n\n432\n00:21:25.487 --> 00:21:30.860\nAll right, now what happens if,\nin one of the circuitries, your vendor.\n\n433\n00:21:30.860 --> 00:21:34.430\nSomebody slips in some malware,\nand you're not aware of it, right?\n\n434\n00:21:34.430 --> 00:21:37.250\nWell that's a supply chain attack, right.\n\n435\n00:21:37.250 --> 00:21:38.660\nSo supply chain assessments,\n\n436\n00:21:38.660 --> 00:21:42.575\nwe are thoroughly documenting who\nwe're getting our products from.\n\n437\n00:21:42.575 --> 00:21:46.650\nWhere we're thoroughly documenting\nthe vendors that are supplying us with\n\n438\n00:21:46.650 --> 00:21:49.580\nthe products that we need,\nto make whatever our product is.\n\n439\n00:21:49.580 --> 00:21:52.010\nAnd you have heard of things like IoT.\n\n440\n00:21:52.010 --> 00:21:56.160\nThere was a big thing that\nhappened about a year ago.\n\n441\n00:21:56.160 --> 00:21:59.473\nWhere there are a lot of IoT devices out\nthere that were using specific components,\n\n442\n00:21:59.473 --> 00:22:00.759\nand even things like smart TVs.\n\n443\n00:22:00.759 --> 00:22:05.202\nWhere the vendor, one of the manufacturing\ncomponents in there, manufactured\n\n444\n00:22:05.202 --> 00:22:09.530\ncomponents in there, actually had a little\nbit of malware slipped into them.\n\n445\n00:22:09.530 --> 00:22:14.840\nSo supply chain assessments are important\nfor, again, assessing the vendors\n\n446\n00:22:14.840 --> 00:22:18.420\nthat are providing you with whatever\nthe product is, to finish your product.\n\n447\n00:22:18.420 --> 00:22:20.870\nSo it is very, very important Important.\n\n448\n00:22:20.870 --> 00:22:23.460\nSome of the other things that they talk,\nabout are risk registers.\n\n449\n00:22:23.460 --> 00:22:28.550\nA risk register, you might hear\nit also called a risk log, right?\n\n450\n00:22:28.550 --> 00:22:31.110\nIt's a list of identified risks, right.\n\n451\n00:22:31.110 --> 00:22:34.250\nThe identified risks are,\nthey try to describe them\n\n452\n00:22:34.250 --> 00:22:38.340\nwith as much detail as feasible,\nor reasonable, if you will.\n\n453\n00:22:38.340 --> 00:22:41.390\nIt contains things like\nthe description of the risk,\n\n454\n00:22:41.390 --> 00:22:45.910\nthe impact, should this risk event\nactually manifest itself, or happen.\n\n455\n00:22:45.910 --> 00:22:48.320\nIt also can contain things\nlike the list of the plan, or\n\n456\n00:22:48.320 --> 00:22:50.070\nthe potential responses to the risk.\n\n457\n00:22:50.070 --> 00:22:54.360\nSo that's what a risk register is,\nit's a list of the risks, right?\n\n458\n00:22:54.360 --> 00:22:55.828\nAnd then what are the potential,\n\n459\n00:22:55.828 --> 00:23:00.110\nI say countermeasures, or\nresponses to that type of risk?\n\n460\n00:23:00.110 --> 00:23:01.770\nThese are used in different scenarios,\nright?\n\n461\n00:23:01.770 --> 00:23:05.130\nThey're used in things like your projects,\nprograms if you will, and\n\n462\n00:23:05.130 --> 00:23:07.050\ncompanies use them, likewise, as well.\n\n463\n00:23:08.400 --> 00:23:11.760\nOther things that we have,\nthe likelihood of occurrence.\n\n464\n00:23:11.760 --> 00:23:13.630\nWhen we look at the likelihood\nof occurrence, guys,\n\n465\n00:23:13.630 --> 00:23:15.570\nthis is really just about probability,\nright.\n\n466\n00:23:15.570 --> 00:23:18.080\nThe probability of any risk event happens,\nright.\n\n467\n00:23:18.080 --> 00:23:21.480\nIt defines a probability of\na specific threat to an exploit,\n\n468\n00:23:21.480 --> 00:23:22.891\ngiven a vulnerability.\n\n469\n00:23:22.891 --> 00:23:26.416\nAnd a lot of times, it could be based\non things like subjective analysis.\n\n470\n00:23:26.416 --> 00:23:28.090\nYou might hear it also\ncalled something else.\n\n471\n00:23:28.090 --> 00:23:33.350\nLikelihood of probability also might be\ncalled probability of occurrence, right?\n\n472\n00:23:33.350 --> 00:23:35.280\nSo if it's likelihood of occurrence,\n\n473\n00:23:35.280 --> 00:23:38.530\nprobability of occurrence, sometimes\nthey're just used interchangeably.\n\n474\n00:23:38.530 --> 00:23:42.734\n&gt;&gt; So Wes, how about just wrapping\nthis up with risk response techniques?\n\n475\n00:23:42.734 --> 00:23:45.421\n&gt;&gt; All right, yeah,\nabsolutely, we can do that.\n\n476\n00:23:45.421 --> 00:23:49.843\nThey call out four different techniques\nFour different techniques, all right?\n\n477\n00:23:49.843 --> 00:23:52.227\nThey call out accept,\ntransfer, avoid and mitigate.\n\n478\n00:23:52.227 --> 00:23:57.020\nAll right, okay, so\nlet's talk about the first one.\n\n479\n00:23:57.020 --> 00:23:58.870\nYou might also hear\nthese called strategies.\n\n480\n00:23:58.870 --> 00:24:04.825\nAgain, risk response techniques or\nrisk response strategies, right?\n\n481\n00:24:04.825 --> 00:24:07.750\nSo let's talk about the first one,\nthe acceptance, right?\n\n482\n00:24:07.750 --> 00:24:08.565\nAccept strategy.\n\n483\n00:24:08.565 --> 00:24:11.410\nThis is first on the list,\n\n484\n00:24:11.410 --> 00:24:14.290\nit's the last one that you\nactually wanna implement, right?\n\n485\n00:24:14.290 --> 00:24:16.870\nWhen no other strategy is gonna work,\nright?\n\n486\n00:24:16.870 --> 00:24:21.691\nYou sit back and you say, I'll go ahead\nand accept what has happened, right?\n\n487\n00:24:21.691 --> 00:24:25.010\nThat's my risk response is\njust acceptance, right?\n\n488\n00:24:25.010 --> 00:24:26.520\nAnd a lot of times, it's the last one.\n\n489\n00:24:26.520 --> 00:24:28.130\nEven though it's,\nI got it first on the list,\n\n490\n00:24:28.130 --> 00:24:32.490\nit's usually the last one you wanna use\nwhen all other strategies will not work.\n\n491\n00:24:32.490 --> 00:24:34.040\nOne of the good things about acceptance,\nthough,\n\n492\n00:24:34.040 --> 00:24:36.450\nis it doesn't require\nan immediate reaction.\n\n493\n00:24:36.450 --> 00:24:38.620\nAnd that is one thing to keep in mind.\n\n494\n00:24:38.620 --> 00:24:41.510\nTransfer strategies, or\ntechnique if you will.\n\n495\n00:24:41.510 --> 00:24:44.690\nRisk response, we say transfer.\n\n496\n00:24:44.690 --> 00:24:49.400\nIf I have a third party that is\ncompletely capable of accepting\n\n497\n00:24:49.400 --> 00:24:53.560\nthe responsibility for\nthe risk, and they own it.\n\n498\n00:24:53.560 --> 00:24:54.470\nWell, that would be nice.\n\n499\n00:24:54.470 --> 00:24:56.140\nLet's just transfer to a third party.\n\n500\n00:24:56.140 --> 00:24:58.101\nWhere we're gonna pay them, right?\n\n501\n00:24:58.101 --> 00:25:02.803\nCuz they have the resources that they can\nassume, they can accept, if you will,\n\n502\n00:25:02.803 --> 00:25:07.383\nthat responsibility and take that burden\non for themselves at a cost, right?\n\n503\n00:25:07.383 --> 00:25:10.350\nThey're a provider.\n\n504\n00:25:10.350 --> 00:25:14.210\nAgain, any other party that's willing\nto take on the risk responsibility.\n\n505\n00:25:14.210 --> 00:25:17.340\nAnd not only the risk and responsibility,\nbut the management of that risk as well.\n\n506\n00:25:19.170 --> 00:25:23.110\nThe consideration on this one is made on\nwhatever the cost effectiveness is of\n\n507\n00:25:23.110 --> 00:25:23.960\nthe risk, right?\n\n508\n00:25:23.960 --> 00:25:28.280\nYou have to justify the cost,\nthat transference if you will,\n\n509\n00:25:28.280 --> 00:25:30.090\nyou might hear it called\ntransference as well.\n\n510\n00:25:30.090 --> 00:25:31.738\nBut you have to accept that cost, right?\n\n511\n00:25:31.738 --> 00:25:35.032\nCuz you're not gonna\njust basically offload\n\n512\n00:25:35.032 --> 00:25:37.811\nrisk to somebody else without a cost.\n\n513\n00:25:37.811 --> 00:25:42.305\nAnd whatever the impact of that risk is,\nhas to be lower, or no,\n\n514\n00:25:42.305 --> 00:25:46.135\ngreater, excuse me,\nI'm sorry, get it right here,\n\n515\n00:25:46.135 --> 00:25:49.930\ngreater than what it cost\nthem to transfer it to.\n\n516\n00:25:49.930 --> 00:25:53.790\nSo again, that is one thing that's\nbased on cost effectiveness.\n\n517\n00:25:53.790 --> 00:25:56.625\nAll right, I'm gonna go ahead and\ntalk about mitigate.\n\n518\n00:25:56.625 --> 00:25:59.976\nI'm gonna kinda go out of order here,\nbecause I'll put the last one that really\n\n519\n00:25:59.976 --> 00:26:02.996\nshould've been first as I put the first\none that should've been last.\n\n520\n00:26:02.996 --> 00:26:03.948\n&gt;&gt; You mean the culture of avoidance?\n\n521\n00:26:03.948 --> 00:26:05.345\n&gt;&gt; Yeah, that's right.\n\n522\n00:26:05.345 --> 00:26:07.385\nYeah, avoidance actually should\nbe the first one, right?\n\n523\n00:26:07.385 --> 00:26:10.915\nSo I said go ahead and accept it,\nand I said that's first in the list,\n\n524\n00:26:10.915 --> 00:26:12.315\nshould be last in the list.\n\n525\n00:26:12.315 --> 00:26:14.755\nAvoidance is the one that\nreally should be on the first.\n\n526\n00:26:14.755 --> 00:26:17.660\nThis is to just remove\nthe cause of the risk.\n\n527\n00:26:17.660 --> 00:26:18.990\nWell, wouldn't that be great?\n\n528\n00:26:18.990 --> 00:26:22.640\nUnderstand that in risk assessment is\nnot about the elimination of risk.\n\n529\n00:26:22.640 --> 00:26:24.630\nYou cannot eliminate risk.\n\n530\n00:26:24.630 --> 00:26:27.060\nRisk assessment,\nif you want it in a nutshell,\n\n531\n00:26:27.060 --> 00:26:32.030\nis bringing risks down to an acceptable\nlevel, an acceptable tolerance level,\n\n532\n00:26:32.030 --> 00:26:33.900\nwe can accept this much risk.\n\n533\n00:26:33.900 --> 00:26:36.420\nSo again,\navoidance is the best type of strategy,\n\n534\n00:26:36.420 --> 00:26:38.590\njust avoid the risk altogether, right?\n\n535\n00:26:38.590 --> 00:26:43.560\nBut you can’t avoid all risk, you can’t\neliminate, it’s about mitigating.\n\n536\n00:26:43.560 --> 00:26:47.430\nRisk mitigation is about bringing it to\nan acceptable level that the company says,\n\n537\n00:26:47.430 --> 00:26:51.770\nokay, we can accept the cost or\nthe impact or whatever that risk might be.\n\n538\n00:26:51.770 --> 00:26:55.745\nMitigate, that’s essentially the\nmitigation strategy, that’s the last one.\n\n539\n00:26:55.745 --> 00:26:57.540\nSo that’s one that’s common, right?\n\n540\n00:26:57.540 --> 00:27:01.810\nWe try to bring it down to\nan acceptable or tolerable level.\n\n541\n00:27:01.810 --> 00:27:06.150\nWe minimize risks at the same time\ntrying to minimize or reduce the impact.\n\n542\n00:27:07.520 --> 00:27:10.560\nLast but not least is change management,\nwhen we look at change management,\n\n543\n00:27:10.560 --> 00:27:12.922\nchange management is\nan interesting concept, all right?\n\n544\n00:27:12.922 --> 00:27:16.449\nChange management is a process\nin which you try to,\n\n545\n00:27:16.449 --> 00:27:20.962\nif you have to implement changes\nyou want to maintain stability,\n\n546\n00:27:20.962 --> 00:27:26.310\nfunctionality, usability, availability\nif you will and up time, right?\n\n547\n00:27:26.310 --> 00:27:29.860\nNow, if I'm on my computer and\nI'm working on a lab environment, right?\n\n548\n00:27:29.860 --> 00:27:35.550\nI'm spinning up some virtual machines,\nI gotta create an entire network topology.\n\n549\n00:27:35.550 --> 00:27:39.585\nI decide I want to take the DNS server\noffline to do some adjustments to it.\n\n550\n00:27:39.585 --> 00:27:41.190\nDoesn't effect me at all.\n\n551\n00:27:41.190 --> 00:27:45.710\nI don't have to go to our managers\nhere and ask to change anything.\n\n552\n00:27:45.710 --> 00:27:46.579\nI just change it.\nAll right,\n\n553\n00:27:46.579 --> 00:27:48.500\nwe're not talking about\na virtual environment,\n\n554\n00:27:48.500 --> 00:27:50.500\nwe're talking about a company.\n\n555\n00:27:50.500 --> 00:27:54.870\nAnd usually what you have is a whole\nentire process between change management.\n\n556\n00:27:54.870 --> 00:27:57.180\nChange management is just\nthe systematic approaches, or\n\n557\n00:27:57.180 --> 00:28:01.430\nthe changes made on your systems,\nwhile still maintaining up time.\n\n558\n00:28:01.430 --> 00:28:03.430\nWe don't want any interruptions.\n\n559\n00:28:03.430 --> 00:28:05.350\nSo you have a process that happens, right?\n\n560\n00:28:05.350 --> 00:28:09.088\nA lot of times what you do,\nis you'll fill out a change ticket, right?\n\n561\n00:28:09.088 --> 00:28:11.310\nA change request form.\n\n562\n00:28:11.310 --> 00:28:15.750\nAnd then what you do is you\nsubmit that change request form.\n\n563\n00:28:15.750 --> 00:28:19.020\nAnd it goes across what's known as a CAB,\nthat's a change advisory board.\n\n564\n00:28:19.020 --> 00:28:22.320\nChange advisory board could be management,\ncould be, a lot of times it is management.\n\n565\n00:28:22.320 --> 00:28:25.980\nCEO, stakeholders if you will, if you have\na public facing interest in which people\n\n566\n00:28:25.980 --> 00:28:29.440\nare invested into your company,\nthat's your change advisory board.\n\n567\n00:28:29.440 --> 00:28:32.950\nAnd they either approve or\nthey deny it, right?\n\n568\n00:28:32.950 --> 00:28:35.130\nBut, well, let's say they approve it.\n\n569\n00:28:35.130 --> 00:28:36.910\nDo you go out and make the change?\n\n570\n00:28:36.910 --> 00:28:39.660\nNo, you're not ready to\nmake the change yet.\n\n571\n00:28:39.660 --> 00:28:43.210\nYou'll test the change, usually, in an\nisolated lab type environment and see and\n\n572\n00:28:43.210 --> 00:28:44.960\ndocument what the results are.\n\n573\n00:28:46.050 --> 00:28:49.830\nThen, if you have stability,\nthen you make the change, right?\n\n574\n00:28:49.830 --> 00:28:53.400\nSo keep in mind, change management is\na thoroughly documented process and\n\n575\n00:28:53.400 --> 00:28:56.860\nit isn't the process of walking over and\nflipping a light switch.\n\n576\n00:28:57.860 --> 00:29:02.770\nYou request a change, you fill out and\nsubmit the reason for your change.\n\n577\n00:29:02.770 --> 00:29:05.310\nHow is this gonna positively affect?\n\n578\n00:29:05.310 --> 00:29:08.720\nWhat is the end point,\nthe goal that you're trying to achieve?\n\n579\n00:29:08.720 --> 00:29:09.840\nYou submit that to the CAB.\n\n580\n00:29:09.840 --> 00:29:13.020\nThe CAB, change advisory board,\nif you will, they review it.\n\n581\n00:29:13.020 --> 00:29:14.100\nThey either approve or deny it.\n\n582\n00:29:14.100 --> 00:29:16.766\nIf they approve it,\nyou're go into a testing phase.\n\n583\n00:29:16.766 --> 00:29:19.294\nMaybe in an isolated lab type\nenvironment where you doing this\n\n584\n00:29:19.294 --> 00:29:20.567\nin a virtual machine, right?\n\n585\n00:29:20.567 --> 00:29:22.373\nAnd you document the results.\n\n586\n00:29:22.373 --> 00:29:26.441\nYou might have to submit again to a CAB as\nwell, documenting what the results were.\n\n587\n00:29:26.441 --> 00:29:29.030\nBut then, finally,\nyou implement the change and\n\n588\n00:29:29.030 --> 00:29:31.132\nthen you document that change, right?\n\n589\n00:29:31.132 --> 00:29:32.375\nSo change management and\n\n590\n00:29:32.375 --> 00:29:35.580\nconfiguration management really\ncan't go kinda hand in hand.\n\n591\n00:29:35.580 --> 00:29:40.050\nIf I make a change to a system after it's\nbeen approved, I have to turn around and\n\n592\n00:29:40.050 --> 00:29:43.730\nI have to update my configuration\ndocumentation too, all right?\n\n593\n00:29:43.730 --> 00:29:44.630\nWhy is that important?\n\n594\n00:29:44.630 --> 00:29:47.590\nWell, I'll tell you what,\nI'll give you a classic example.\n\n595\n00:29:47.590 --> 00:29:52.500\nI had a friend that worked in the military\nand they were gonna make some repairs\n\n596\n00:29:52.500 --> 00:29:57.600\non one of the naval destroyer or\nwhatever, naval ships.\n\n597\n00:29:57.600 --> 00:30:00.561\nAnd they turned off the power grid,\nall right?\n\n598\n00:30:00.561 --> 00:30:02.353\nAccording to the schematics, right?\n\n599\n00:30:02.353 --> 00:30:04.450\nThey turned off the power grid.\n\n600\n00:30:04.450 --> 00:30:07.580\nAnd when my friend reached out and grabbed\nthat line, he grabbed a live 440 line and\n\n601\n00:30:07.580 --> 00:30:09.160\nit sent him across the room,\nput him in a coma.\n\n602\n00:30:10.210 --> 00:30:11.370\nWhat happened there?\n\n603\n00:30:11.370 --> 00:30:16.240\nWell, probably not following\nstandard operating procedure for\n\n604\n00:30:16.240 --> 00:30:20.440\nmaking a change, and then documenting\nthe change in the configurations, right?\n\n605\n00:30:20.440 --> 00:30:22.420\nSo the schematics were out of date.\n\n606\n00:30:22.420 --> 00:30:26.126\nAgain, you could say that things like\nchange management also run hand in hand\n\n607\n00:30:26.126 --> 00:30:29.848\nwith configuration management, or\nconfiguration documentation as well.\n\n608\n00:30:29.848 --> 00:30:32.350\n&gt;&gt; Document, document, document.\n\n609\n00:30:32.350 --> 00:30:35.800\n&gt;&gt; Yeah, and when you think you haven't\ndocumented enough, document more.\n\n610\n00:30:35.800 --> 00:30:37.589\nBecause remember,\ndocumentation saves a lot of headaches.\n\n611\n00:30:37.589 --> 00:30:41.360\nAnd it's a lot easier to pull down\ndocumentation that's thoroughly documented\n\n612\n00:30:41.360 --> 00:30:42.856\nand you know what's going on and\n\n613\n00:30:42.856 --> 00:30:46.780\nyou're aware of the situation rather\nthan finding it after the fact.\n\n614\n00:30:46.780 --> 00:30:48.750\nAnd then it ends up going into an AAR,\n\n615\n00:30:48.750 --> 00:30:51.240\nyou have to rethink the whole\nprocess to begin with.\n\n616\n00:30:51.240 --> 00:30:53.270\n&gt;&gt; Boy, hey, Wes, thanks very much.\n\n617\n00:30:53.270 --> 00:30:57.413\nYou've made this very enjoyable, this was\nrisk management processes and concepts,\n\n618\n00:30:57.413 --> 00:30:58.899\nand thanks for watching that.\n\n619\n00:30:58.899 --> 00:31:04.307\nAnd I'm Zach Memos, and I'm your host for\ncontinuing on with CompTIA Security+,\n\n620\n00:31:04.307 --> 00:31:07.850\nand for ITProTV, again,\nthanks for watching.\n\n621\n00:31:07.850 --> 00:31:08.900\n&gt;&gt; I'm Wes Bryan.\n\n622\n00:31:08.900 --> 00:31:09.781\n&gt;&gt; And we will see you next time.\n\n623\n00:31:09.781 --> 00:31:17.291\n[MUSIC]\n\n624\n00:31:17.291 --> 00:31:19.746\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217170658"
        },
        {
          "description": "Wes and Zach identify incident types with appropriate response process & measures. Documentation at all levels is emphasized.",
          "length": "1686",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-4-incident_response_procedures-050817-PGM.00_27_51_05.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-4-incident_response_procedures-050817-PGM.00_27_51_05.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-4-incident_response_procedures-050817-PGM.00_27_51_05.Still001-sm.jpg",
          "title": "Incident Response Procedures",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:03.456\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:03.456 --> 00:00:08.852\n[CROSSTALK]\n\n3\n00:00:08.852 --> 00:00:11.574\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.574 --> 00:00:15.260\n&gt;&gt; Hello, and thank you for\nwatching ITProTV.\n\n5\n00:00:15.260 --> 00:00:19.200\nHelping you learn where ever you go,\nI am your host, Zach Memos.\n\n6\n00:00:19.200 --> 00:00:22.140\nAs we continue with CompTIA Security+ and\n\n7\n00:00:22.140 --> 00:00:26.960\nour IT pro, Wes Bryan, is gonna tell us so\nmuch more so stay right where you are.\n\n8\n00:00:26.960 --> 00:00:27.810\n&gt;&gt; Hey, how you doing, Zach?\n\n9\n00:00:27.810 --> 00:00:30.280\nYep.\nGreat to be here with the ITProTV crew.\n\n10\n00:00:30.280 --> 00:00:32.590\nThat's right.\nWe're going to be looking at more security\n\n11\n00:00:32.590 --> 00:00:36.330\nplus and, more specifically, we're gonna\nbe diving in the risk management side.\n\n12\n00:00:36.330 --> 00:00:39.700\nLooking at the incident\nresponse procedures and\n\n13\n00:00:39.700 --> 00:00:43.240\nit is gonna be important\nImportant as we go into the exam,\n\n14\n00:00:43.240 --> 00:00:46.430\nthat you're aware of some of these\nconcepts and some of the categorizations.\n\n15\n00:00:46.430 --> 00:00:49.540\nSo that if they do put you\nin a scenario on the exam,\n\n16\n00:00:49.540 --> 00:00:51.270\nyou'll be able to get those right.\n\n17\n00:00:51.270 --> 00:00:53.795\nSo let's go ahead and\nlet's talk about some of the components\n\n18\n00:00:53.795 --> 00:00:57.485\nthat we need to look at when it comes\nto the different procedures, all right?\n\n19\n00:00:57.485 --> 00:01:01.045\nSo they talked about an incident response\nplan and some of the things that we see\n\n20\n00:01:01.045 --> 00:01:04.095\ninside of an incident response plan\nthere are a whole bunch of things.\n\n21\n00:01:04.095 --> 00:01:06.450\nSo let's kind of look at,\ngo through the list here.\n\n22\n00:01:06.450 --> 00:01:10.030\nWe have documented, incident types,\ncategories and definitions.\n\n23\n00:01:10.030 --> 00:01:12.550\nIt's important to categorize if you will.\n\n24\n00:01:12.550 --> 00:01:14.420\nWe have roles and responsibilities.\n\n25\n00:01:14.420 --> 00:01:18.070\nThat's gonna be important as we walk\nthrough this to understand that there\n\n26\n00:01:18.070 --> 00:01:20.190\nare different roles\nwithin the organization.\n\n27\n00:01:20.190 --> 00:01:23.780\nAnd those roles have a certain\nresponsibilities attached to them and\n\n28\n00:01:23.780 --> 00:01:26.400\ndefining them are gonna be important.\n\n29\n00:01:26.400 --> 00:01:29.350\nWe're also gonna be looking at things\nlike the reporting, requirements and\n\n30\n00:01:29.350 --> 00:01:30.500\nescalation procedures.\n\n31\n00:01:30.500 --> 00:01:34.840\nRemember as we told you in other courses\nlike A+, Net+ and now in Security+.\n\n32\n00:01:34.840 --> 00:01:39.920\nIf you don't have the skill set that\nis needed to respond to some type of\n\n33\n00:01:39.920 --> 00:01:44.970\nincident, it's not a day to say I know it\nall and there's no problem in passing it\n\n34\n00:01:44.970 --> 00:01:49.320\nsomebody that does have those skills that\nare measured to get this accomplished.\n\n35\n00:01:49.320 --> 00:01:52.260\nWe're also gonna talk a little bit\nabout things like cyber incidence\n\n36\n00:01:52.260 --> 00:01:55.690\nresponse teams as well as exercises,\nright?\n\n37\n00:01:55.690 --> 00:01:58.960\nAnd you can probably look at me and\nsee I don't do many exercises.\n\n38\n00:01:58.960 --> 00:02:02.050\nBut we're talking more about\ngoing through the process and\n\n39\n00:02:02.050 --> 00:02:04.285\nmake sure that we're prepared\nin the case of an incident.\n\n40\n00:02:04.285 --> 00:02:07.430\n&gt;&gt; Wes, I disagree, I think you're\na fit human being, I really do.\n\n41\n00:02:07.430 --> 00:02:11.190\nWhen we're talking about incident types,\nwhat are we looking at exactly?\n\n42\n00:02:11.190 --> 00:02:12.400\nCan we break that down a little bit more?\n\n43\n00:02:12.400 --> 00:02:14.160\n&gt;&gt; Absolutely and\nthere are a bunch of them.\n\n44\n00:02:14.160 --> 00:02:16.310\nSo let's give you some examples, right?\n\n45\n00:02:16.310 --> 00:02:18.840\nOne of the things you can think\nof is a compromise systems.\n\n46\n00:02:18.840 --> 00:02:21.660\nCompromise systems,\nthings like your operating systems, right?\n\n47\n00:02:21.660 --> 00:02:24.240\nThings like for instance, hardware, right?\n\n48\n00:02:24.240 --> 00:02:25.960\nCuz when I say operating systems,\n\n49\n00:02:25.960 --> 00:02:29.360\nunderstand you know an operating system\nthat's on a network device like an iOS\n\n50\n00:02:29.360 --> 00:02:32.250\nmachine if you will talking\nabout like Cisco devices, right?\n\n51\n00:02:32.250 --> 00:02:34.040\nThat's gonna be different than\nif you're running Unix or\n\n52\n00:02:34.040 --> 00:02:37.990\nLinux based systems, if you're\nrunning Windows and then as well,\n\n53\n00:02:37.990 --> 00:02:41.190\nare you running these on work stations or\nyou're working on servers, right?\n\n54\n00:02:41.190 --> 00:02:45.230\nSo compromise systems can have\ntheir own set of complexities\n\n55\n00:02:45.230 --> 00:02:48.850\nbehind any incidents that go on.\n\n56\n00:02:48.850 --> 00:02:49.700\nAccounts, right?\n\n57\n00:02:49.700 --> 00:02:50.750\nCompromised accounts.\n\n58\n00:02:50.750 --> 00:02:52.860\nWe really have to worry\nabout this because, well,\n\n59\n00:02:52.860 --> 00:02:55.220\nthat's how we get data leakage.\n\n60\n00:02:55.220 --> 00:02:58.180\nThat's how we get disclosure of\ninformation that potentially is\n\n61\n00:02:58.180 --> 00:02:59.220\nconfidential.\n\n62\n00:02:59.220 --> 00:03:03.650\nThink of a target attack that had happened\na couple of years ago, I think by now.\n\n63\n00:03:03.650 --> 00:03:09.470\nWhere they let a third party organization\nthat was providing HAVAC support for\n\n64\n00:03:09.470 --> 00:03:11.510\nthem, into their systems.\n\n65\n00:03:11.510 --> 00:03:16.330\nAnd that's how they believe that that\ndebacle that they had with a lot of user\n\n66\n00:03:16.330 --> 00:03:18.380\naccounts basically got\ndisclosed to the public.\n\n67\n00:03:18.380 --> 00:03:22.110\nSo we do have to worry about that,\nthings like user counts whether it's user,\n\n68\n00:03:22.110 --> 00:03:25.240\nsystems service accounts,\nprivileged accounts.\n\n69\n00:03:25.240 --> 00:03:30.070\nThese could be incident types, could be\nthings like compromised email systems,\n\n70\n00:03:30.070 --> 00:03:34.160\nor the unauthorized use of email systems.\n\n71\n00:03:34.160 --> 00:03:36.960\nNot using them in an appropriate manner,\nright?\n\n72\n00:03:36.960 --> 00:03:39.730\nMaybe going from your personal\nemail to your work email.\n\n73\n00:03:39.730 --> 00:03:41.540\nAnd if we have things\nlike HIPAA compliance,\n\n74\n00:03:41.540 --> 00:03:44.910\nthat could be a compromise that we\nneed to take into consideration.\n\n75\n00:03:45.950 --> 00:03:46.760\nSpam, right?\n\n76\n00:03:46.760 --> 00:03:48.200\nSpam is a big one, right?\n\n77\n00:03:48.200 --> 00:03:51.520\nThis could lead to all kinds of different\ncompromises including things like\n\n78\n00:03:51.520 --> 00:03:52.680\nattachments in our systems.\n\n79\n00:03:52.680 --> 00:03:55.610\nYou don't want to be opening attachments\nthat are coming from people that\n\n80\n00:03:55.610 --> 00:03:57.570\nyou don't know and It's kinda hard, right?\n\n81\n00:03:57.570 --> 00:04:00.760\nIt's easy to say, hey,\ndon't open attachments.\n\n82\n00:04:00.760 --> 00:04:04.260\nBut if you're in a thing like customer\nrelations management situation, right.\n\n83\n00:04:04.260 --> 00:04:08.560\nYou're working for a CRM database,\na learning management solution.\n\n84\n00:04:08.560 --> 00:04:11.450\nYou're hiring employees or\npart of HR maybe.\n\n85\n00:04:11.450 --> 00:04:15.324\nWell, you're gonna be receiving maybe\na lot of emails that have attachments and\n\n86\n00:04:15.324 --> 00:04:18.440\nthey're legitimate attachments that\nyou need to get your job done.\n\n87\n00:04:18.440 --> 00:04:21.040\nSo we have to make sure that we\nscreen those appropriately so\n\n88\n00:04:21.040 --> 00:04:21.860\nwe don't get viruses.\n\n89\n00:04:21.860 --> 00:04:25.447\n&gt;&gt; And spam's getting a lot\nmore sophisticated these days.\n\n90\n00:04:25.447 --> 00:04:28.220\nI mean,\nI receive some which look legitimate.\n\n91\n00:04:28.220 --> 00:04:30.500\nThey look like it was from\nthe head of the company.\n\n92\n00:04:30.500 --> 00:04:31.800\nBut it was not, it was spam.\n\n93\n00:04:31.800 --> 00:04:33.020\n&gt;&gt; Absolutely, and phishing scams.\n\n94\n00:04:33.020 --> 00:04:33.700\nThat's the other\n\n95\n00:04:33.700 --> 00:04:36.360\none I was gonna throw out there when\nit comes to email compromise, right?\n\n96\n00:04:36.360 --> 00:04:37.890\nSo we have to worry about that.\n\n97\n00:04:37.890 --> 00:04:42.501\nIn fact, Zach, one came across the wire\nnetwork, if you will last week.\n\n98\n00:04:42.501 --> 00:04:45.210\nIt was a big one that went across,\nit was Gmail.\n\n99\n00:04:45.210 --> 00:04:50.050\nAnd people had crafted this email that\nlooks like it's Gmail saying, hey,\n\n100\n00:04:50.050 --> 00:04:51.400\nyou need to reset your password.\n\n101\n00:04:51.400 --> 00:04:52.530\nWell it actually got a lot of people.\n\n102\n00:04:52.530 --> 00:04:55.290\nI think in the first day it\nalmost reached a billion people.\n\n103\n00:04:55.290 --> 00:04:57.250\n&gt;&gt; Goodness.\n&gt;&gt; So it could just show you how\n\n104\n00:04:57.250 --> 00:05:00.290\nfast something like this can\nturn into an incident and\n\n105\n00:05:00.290 --> 00:05:04.940\nhow effective it is in reaching\na lot of people very, very quickly.\n\n106\n00:05:04.940 --> 00:05:09.480\nOther things like your network devices,\nnetwork resources, unauthorized network\n\n107\n00:05:09.480 --> 00:05:13.550\ntraffic, unauthorized network scanning,\nthese could be compromises.\n\n108\n00:05:13.550 --> 00:05:15.060\nDenial of service attacks, and\n\n109\n00:05:15.060 --> 00:05:18.970\nthen a plethora of different malware\ntypes of course we have to worry about.\n\n110\n00:05:18.970 --> 00:05:21.660\nHere's another big one, misconfigurations.\n\n111\n00:05:21.660 --> 00:05:26.800\nIn fact OASP, we talked about it in other\nepisode, looking at web applications\n\n112\n00:05:26.800 --> 00:05:31.375\nsaid I think it was third or fourth in\nthe list was configuration issues, right.\n\n113\n00:05:31.375 --> 00:05:36.920\nMisconfiguration, anonymous log-ins,\nopen systems, these all cause problems.\n\n114\n00:05:36.920 --> 00:05:41.260\nSoftware configuration issues,\nwhere somebody isn't improperly binding\n\n115\n00:05:41.260 --> 00:05:44.470\na certificate to their website and\nnow we have unencrypted traffic.\n\n116\n00:05:44.470 --> 00:05:49.180\nIt could be license violations if you\nhave software license compliant and\n\n117\n00:05:49.180 --> 00:05:55.320\nmaybe it's issued to more than one person\nor more people than the license allocates.\n\n118\n00:05:55.320 --> 00:05:58.290\nYou could have several hundreds of\nthousands of dollars that your company can\n\n119\n00:05:58.290 --> 00:06:01.730\naccrue in some kind of cost basically,\nsome litigation.\n\n120\n00:06:01.730 --> 00:06:04.170\nSo again, these could be issues too.\n\n121\n00:06:04.170 --> 00:06:07.310\nApplications, operating systems,\nfirewalls,\n\n122\n00:06:07.310 --> 00:06:10.200\nmany different things that\ncan lead to incidences.\n\n123\n00:06:10.200 --> 00:06:14.680\nAnd then one of the last ones I might\nmention in this list here is things\n\n124\n00:06:14.680 --> 00:06:16.000\nlike compliance, right.\n\n125\n00:06:16.000 --> 00:06:18.380\nThese could be incidents for you was well.\n\n126\n00:06:18.380 --> 00:06:22.620\nFor instance there is a big trend\ntoday and it's been, I say today,\n\n127\n00:06:22.620 --> 00:06:24.130\nit's actually been out here for\na while now,\n\n128\n00:06:24.130 --> 00:06:27.400\nfive years or better, where people are\nbringing their own device into work right?\n\n129\n00:06:27.400 --> 00:06:30.100\nIt's BYOD, and\nit's the consumerization of IT.\n\n130\n00:06:30.100 --> 00:06:33.280\nIt means I have a device that I'm\nfamiliar with that can make me more\n\n131\n00:06:33.280 --> 00:06:36.050\nproductive in your company, and\nyou don't have to pay for it.\n\n132\n00:06:36.050 --> 00:06:39.550\nEssentially reducing some of those\nmonetary costs that your company would\n\n133\n00:06:39.550 --> 00:06:40.540\naccrue, right?\n\n134\n00:06:40.540 --> 00:06:42.770\nMan, it's a win-win situation.\n\n135\n00:06:42.770 --> 00:06:46.580\nUntil that user brings down that data\nthat falls under HIPAA compliance over\n\n136\n00:06:46.580 --> 00:06:49.740\nthe wireless network on their phone and\nthen leaves your network.\n\n137\n00:06:49.740 --> 00:06:51.870\nAnd now you've got a compliance violation.\n\n138\n00:06:51.870 --> 00:06:55.730\nThings like that, copyright infringement,\n\n139\n00:06:55.730 --> 00:07:00.410\nthings like ethics violations\ncould also be problems.\n\n140\n00:07:00.410 --> 00:07:03.470\nMisuse of personally\nidentifiable information, right?\n\n141\n00:07:03.470 --> 00:07:05.980\nSo, you've got some common examples,\nright?\n\n142\n00:07:05.980 --> 00:07:07.970\nAnd there are tons of and tons more.\n\n143\n00:07:07.970 --> 00:07:10.300\nIn fact Zach,\nI think we could probably go on for\n\n144\n00:07:10.300 --> 00:07:13.030\na week alone in just some of these\nincidences that you could see.\n\n145\n00:07:13.030 --> 00:07:17.340\nBut that is some of the commonalities when\nit comes to incident types if you will,\n\n146\n00:07:17.340 --> 00:07:21.090\nthat we could find within our networks.\n\n147\n00:07:21.090 --> 00:07:23.980\n&gt;&gt; Is there a process we can follow\n\n148\n00:07:23.980 --> 00:07:28.390\nwhen we're actually trying to track\ndown what might be a causative factor?\n\n149\n00:07:28.390 --> 00:07:31.330\n&gt;&gt; Most definitely and\nthat's what they call an IRP.\n\n150\n00:07:31.330 --> 00:07:34.245\nNow be careful because\nan IRP has a couple of,\n\n151\n00:07:34.245 --> 00:07:37.715\nit's feeding you alphabet soup,\nright away here.\n\n152\n00:07:37.715 --> 00:07:40.815\nSo it's incident response procedures and\n\n153\n00:07:40.815 --> 00:07:43.425\nit's actually a part of your\nincident response plan, right?\n\n154\n00:07:43.425 --> 00:07:46.125\nSo keep in mind you have an IRP, and\n\n155\n00:07:46.125 --> 00:07:49.455\nthat defines what the incident\nresponse process is.\n\n156\n00:07:49.455 --> 00:07:53.745\nHowever, we do have a basic set\nof steps that we have to follow.\n\n157\n00:07:53.745 --> 00:07:56.198\nNow It's important to understand\njust what those steps are.\n\n158\n00:07:56.198 --> 00:07:58.466\nUnderstand the adjacencies\nof the ideas too.\n\n159\n00:07:58.466 --> 00:08:02.132\nSo, if they put you in a scenario on the\nexam and they say you're in x scenario.\n\n160\n00:08:02.132 --> 00:08:06.888\nAnd you need to perform y and z,\nall right, which of these answers would be\n\n161\n00:08:06.888 --> 00:08:10.690\nthat next answer that would be valid for\nthat question?\n\n162\n00:08:10.690 --> 00:08:13.190\n&gt;&gt; Like if they threw you\ninto a Kobayashi Maru?\n\n163\n00:08:13.190 --> 00:08:16.780\n&gt;&gt; Absolutely, I'll say God bless you now,\nand then I'll Google it later for\n\n164\n00:08:16.780 --> 00:08:18.390\nsure but yeah, definitely.\n\n165\n00:08:18.390 --> 00:08:22.860\nJust make sure you can identify these for\nthe exam.\n\n166\n00:08:22.860 --> 00:08:25.000\nI have a little bit of a diagram here.\n\n167\n00:08:25.000 --> 00:08:26.890\nI like colored diagrams for sure.\n\n168\n00:08:26.890 --> 00:08:28.770\nThese are the steps that we have.\n\n169\n00:08:28.770 --> 00:08:31.530\nSix steps that they want you to know.\n\n170\n00:08:31.530 --> 00:08:35.180\nThey call out preparation,\nthey call out identification,\n\n171\n00:08:35.180 --> 00:08:40.040\ncontainment, eradication, recovery,\nand lessons learned, all right?\n\n172\n00:08:40.040 --> 00:08:43.050\nSo let's see where things\nlike our roles and\n\n173\n00:08:43.050 --> 00:08:46.520\nresponsibilities, our cyber\nincident response team.\n\n174\n00:08:46.520 --> 00:08:50.320\nLet's see how they fit into the larger\nprocess that we're gonna talk about here.\n\n175\n00:08:50.320 --> 00:08:54.990\nLet's go ahead and what we'll do is\nwe'll start with preparation first.\n\n176\n00:08:54.990 --> 00:08:58.820\nOkay, so with preparation, I've kind\nof outlined just some basics in here.\n\n177\n00:08:58.820 --> 00:09:01.130\nAnd we'll talk about some more of them.\n\n178\n00:09:01.130 --> 00:09:04.080\nKeep in mind that these\nare just commonalities.\n\n179\n00:09:04.080 --> 00:09:05.610\nEvery company is a little bit different.\n\n180\n00:09:05.610 --> 00:09:08.530\nNot every company has\na one size fits right,\n\n181\n00:09:08.530 --> 00:09:13.280\nthe flex fit type hat that is just gonna\nencompass everything that they need to do.\n\n182\n00:09:13.280 --> 00:09:14.660\nSo you might have to pick and choose.\n\n183\n00:09:14.660 --> 00:09:17.670\nBut again, knowing these overall steps\nis gonna be what you need to know for\n\n184\n00:09:17.670 --> 00:09:18.250\nthe exam.\n\n185\n00:09:18.250 --> 00:09:20.080\nSo first, right, assessment.\n\n186\n00:09:20.080 --> 00:09:21.260\nAssessment is important, right?\n\n187\n00:09:21.260 --> 00:09:25.060\nFirst of all, we need to find out\ndo we have the right people, right?\n\n188\n00:09:25.060 --> 00:09:25.690\nWell, first of all,\n\n189\n00:09:25.690 --> 00:09:29.030\nbefore anything happens in\nthe preparation, who has the authority?\n\n190\n00:09:29.030 --> 00:09:30.190\nIt always starts with authority.\n\n191\n00:09:30.190 --> 00:09:32.270\nAny kind of an incident is\ngonna start with authority.\n\n192\n00:09:32.270 --> 00:09:33.970\nWho do we go to first, right?\n\n193\n00:09:33.970 --> 00:09:37.390\nNow I could set myself up for a bad 80s\nreference and say, who you gonna call but\n\n194\n00:09:37.390 --> 00:09:39.433\nwe won't go there even though I just did.\n\n195\n00:09:39.433 --> 00:09:41.060\nBut we do have assessment, right?\n\n196\n00:09:41.060 --> 00:09:45.550\nAnd that's, for instance, the authority,\nthe managers, first responders, right?\n\n197\n00:09:45.550 --> 00:09:47.950\nYour first responders,\nis it a forensics team?\n\n198\n00:09:47.950 --> 00:09:49.750\nIs it a cyber security team?\n\n199\n00:09:49.750 --> 00:09:51.740\nIs it law enforcement, right?\n\n200\n00:09:51.740 --> 00:09:56.550\nIf you have a public facing incident, your\nfirst responders might be law enforcement.\n\n201\n00:09:56.550 --> 00:09:57.850\nThey could be internal.\n\n202\n00:09:57.850 --> 00:09:58.870\nIt could be an IT staff.\n\n203\n00:09:58.870 --> 00:10:00.520\nIt could be a security staff.\n\n204\n00:10:00.520 --> 00:10:02.590\nBut you have to identify that first.\n\n205\n00:10:03.660 --> 00:10:06.670\nNext, determining those roles and\nresponsibilities.\n\n206\n00:10:06.670 --> 00:10:09.880\nAgain, if it's a manager,\nmanagers implement policies.\n\n207\n00:10:09.880 --> 00:10:14.240\nManagers ensure compliance and\nadherence to the policies.\n\n208\n00:10:14.240 --> 00:10:18.630\nIf it's law enforcement, right, we have to\nhave things like contact information for\n\n209\n00:10:18.630 --> 00:10:24.190\neverybody so that's an important,\ncontact information escalation procedures.\n\n210\n00:10:24.190 --> 00:10:27.320\nNow one of the things\nI wanna kinda tell you\n\n211\n00:10:27.320 --> 00:10:32.120\nahead of time is things like team sizing,\ndo we have the right size team?\n\n212\n00:10:32.120 --> 00:10:36.014\nBecause certain incidences,\nif they are an entire site,\n\n213\n00:10:36.014 --> 00:10:38.321\nmight take a good staff of people.\n\n214\n00:10:38.321 --> 00:10:42.368\nIf it's just one localized incident,\nmaybe on a specific system,\n\n215\n00:10:42.368 --> 00:10:47.202\nyou might have a handful of people or less\nthat respond to what that situation is.\n\n216\n00:10:47.202 --> 00:10:51.187\nThings like policy enforcement, right,\nif a service is brought online, or\n\n217\n00:10:51.187 --> 00:10:53.980\noutage I should say, is brought offline.\n\n218\n00:10:53.980 --> 00:10:58.000\nHow do we bring that back online,\nif you will and if we need to adhere to\n\n219\n00:10:58.000 --> 00:11:02.130\nsecurity standard to make sure that we're\nnot exposing information, how do we do it?\n\n220\n00:11:02.130 --> 00:11:07.420\nAgain, things like policy enforcement,\nnot only the right people, under\n\n221\n00:11:07.420 --> 00:11:12.170\nthe people things like on premise verses\noff premise, cloud is prevalent today.\n\n222\n00:11:12.170 --> 00:11:16.830\nSo in part of your And\npart of your first responders\n\n223\n00:11:16.830 --> 00:11:19.410\nmight be going to somebody\nthat's outsourced, right?\n\n224\n00:11:19.410 --> 00:11:22.500\nIt could be a cloud provider, could\nbe a third party that is specific for\n\n225\n00:11:22.500 --> 00:11:26.310\nthings like disaster recovery\nimplementations, if you will.\n\n226\n00:11:26.310 --> 00:11:27.780\nSo keep that in mind too.\n\n227\n00:11:28.960 --> 00:11:31.720\nThe next thing, so that's making\nsure that we get the right people.\n\n228\n00:11:31.720 --> 00:11:35.240\nThe next one is,\ndo we have the right tools, right?\n\n229\n00:11:35.240 --> 00:11:38.660\nThe right tools, or\nthe right processes, if you will.\n\n230\n00:11:38.660 --> 00:11:41.500\nDo we implement right away\nan incident tracking process?\n\n231\n00:11:41.500 --> 00:11:46.620\nSo the moment we know something starts we\nhave through documentation right up until\n\n232\n00:11:46.620 --> 00:11:48.750\nthe incident is closed, right?\n\n233\n00:11:49.800 --> 00:11:52.140\nDo we have a training?\n\n234\n00:11:52.140 --> 00:11:53.040\nRight, that's the big thing.\n\n235\n00:11:53.040 --> 00:11:54.830\nSo, we've got the assessment.\n\n236\n00:11:54.830 --> 00:11:56.400\nDo we have the right people?\n\n237\n00:11:56.400 --> 00:11:57.830\nDo we have the right tools?\n\n238\n00:11:57.830 --> 00:11:59.650\nThen, next is training, right?\n\n239\n00:11:59.650 --> 00:12:01.900\nWe have to make sure\nthat we train the staff.\n\n240\n00:12:01.900 --> 00:12:05.850\nThey have to have understanding of their\nindividual role should an incident be\n\n241\n00:12:05.850 --> 00:12:06.910\ncome up, right?\n\n242\n00:12:06.910 --> 00:12:09.770\nIf it happens to be an incident,\ndo we place a legal hold on the data?\n\n243\n00:12:09.770 --> 00:12:11.410\nBecause if we put a legal\nhold on the data,\n\n244\n00:12:11.410 --> 00:12:14.860\nthen we have to have policies in place\nthat tell the employees not to destroy any\n\n245\n00:12:14.860 --> 00:12:19.470\ninformation, whether it'd be litigation\npurposes or for our own protection.\n\n246\n00:12:19.470 --> 00:12:21.040\nSo, again, things like that.\n\n247\n00:12:21.040 --> 00:12:23.840\nAnd lastly, what it does,\nand this is the big one,\n\n248\n00:12:23.840 --> 00:12:26.230\nis that in the preparation, all right.\n\n249\n00:12:26.230 --> 00:12:29.570\nIt promotes awareness, all right?\n\n250\n00:12:29.570 --> 00:12:30.490\nI didn't say this and\n\n251\n00:12:30.490 --> 00:12:33.700\nI was gonna do this but I decided not\nto cuz it would be very repetitive.\n\n252\n00:12:33.700 --> 00:12:35.690\nBut after every one of those,\n\n253\n00:12:35.690 --> 00:12:40.040\nI wanted to say we get the right\ntools ahead of the incident.\n\n254\n00:12:40.040 --> 00:12:43.034\nWe get the right processes\nahead of the incident, so\n\n255\n00:12:43.034 --> 00:12:46.180\nawareness ahead of the incident, right?\n\n256\n00:12:46.180 --> 00:12:50.600\nI work for a company in which they\nlost access to their servers.\n\n257\n00:12:50.600 --> 00:12:53.270\nAnd the servers went down, and\nthe next morning they couldn't log in,\n\n258\n00:12:53.270 --> 00:12:54.220\nthey couldn't do anything.\n\n259\n00:12:54.220 --> 00:12:56.690\nit wasn't the right time\nto try to figure out,\n\n260\n00:12:56.690 --> 00:13:00.740\nhow are we gonna get our systems back\nonline and there was zero documentation.\n\n261\n00:13:00.740 --> 00:13:05.630\nThank goodness we had a person that was\nat the top of the rebuilding process that\n\n262\n00:13:05.630 --> 00:13:10.990\nsays okay, I recognized when write to\nthe CIO, and said okay, I recognize\n\n263\n00:13:10.990 --> 00:13:14.860\nwhat I consider business critical,\nyou might not consider business critical.\n\n264\n00:13:14.860 --> 00:13:16.790\nSo let's go ahead, let's sit down and\n\n265\n00:13:16.790 --> 00:13:19.410\nfigure out how we're gonna\nget out systems back online.\n\n266\n00:13:19.410 --> 00:13:21.300\nThat was not an example of good planning.\n\n267\n00:13:21.300 --> 00:13:24.790\nThat's why in the very first step,\npreparation is probably one\n\n268\n00:13:24.790 --> 00:13:29.715\nof the most important steps to make sure\neverything after this falls in place.\n\n269\n00:13:29.715 --> 00:13:30.990\n&gt;&gt; Mm-hm an ounce of.\n\n270\n00:13:30.990 --> 00:13:32.460\n&gt;&gt; That's right.\n\n271\n00:13:32.460 --> 00:13:35.140\nDon't wait till after the fact, right?\n\n272\n00:13:35.140 --> 00:13:35.950\nSo the next phase.\n\n273\n00:13:35.950 --> 00:13:38.210\nWe talk about identification, right?\n\n274\n00:13:38.210 --> 00:13:40.350\nWhen we talk about, for\ninstance, questioning, right?\n\n275\n00:13:40.350 --> 00:13:42.810\nDo we move forward in an incident?\n\n276\n00:13:42.810 --> 00:13:44.170\nMaybe there's not an incident.\n\n277\n00:13:44.170 --> 00:13:46.100\nAgain, we have to have\nthorough documentation and\n\n278\n00:13:46.100 --> 00:13:50.270\nthe authority in the first preparation\nphase to make sure somebody\n\n279\n00:13:50.270 --> 00:13:53.040\nhas the authority to claim that\nthere is an incident going on and\n\n280\n00:13:53.040 --> 00:13:55.910\nwe have to continue with this\nincident response process.\n\n281\n00:13:55.910 --> 00:13:58.860\nBecause if there isn't an incident\nwe just go back to monitoring.\n\n282\n00:13:58.860 --> 00:13:59.990\nWe go back to the first part,\n\n283\n00:13:59.990 --> 00:14:02.910\nand thank goodness there isn't\nan incident, we're fine.\n\n284\n00:14:02.910 --> 00:14:04.550\nSo again, you also have to question,\n\n285\n00:14:04.550 --> 00:14:07.910\ndo we more forward it in the incident\nresponse handling process?\n\n286\n00:14:07.910 --> 00:14:09.800\nNext is the determining, all right.\n\n287\n00:14:09.800 --> 00:14:13.430\nDetermination factor says\nhas an incident happened?\n\n288\n00:14:13.430 --> 00:14:16.640\nIf it has,\nis the incident still happening?\n\n289\n00:14:16.640 --> 00:14:19.460\nBecause you could have an active threat.\n\n290\n00:14:19.460 --> 00:14:21.920\nRight now, you are still engaged in it.\n\n291\n00:14:21.920 --> 00:14:26.110\nYou're not sure exactly where it's\ncoming from, but it could be ongoing.\n\n292\n00:14:26.110 --> 00:14:29.690\nSo the determination of if the incident\nhas stopped or if it's ongoing.\n\n293\n00:14:30.770 --> 00:14:32.476\nIdentify, this is big, right?\n\n294\n00:14:32.476 --> 00:14:36.290\nWhen they talk about in the first part we\nmentioned kind of briefly categorizing or\n\n295\n00:14:36.290 --> 00:14:37.900\ncategory definitions.\n\n296\n00:14:37.900 --> 00:14:40.680\nWell categorizing the impact,\nis it a high impact?\n\n297\n00:14:40.680 --> 00:14:42.000\nIs it a medium impact?\n\n298\n00:14:42.000 --> 00:14:43.510\nIs it a low impact?\n\n299\n00:14:43.510 --> 00:14:45.570\nWell I can't give you those answers,\nI'm not sure.\n\n300\n00:14:45.570 --> 00:14:50.050\nIt's important as part of things like\ninventory and asset management that\n\n301\n00:14:50.050 --> 00:14:53.026\nyou have a thorough documentation of\nwhat your critical systems are so\n\n302\n00:14:53.026 --> 00:14:54.939\nthat you're aware of that\nshould an incident happen.\n\n303\n00:14:56.920 --> 00:15:00.020\nAll right,\nlet's see as we move through here.\n\n304\n00:15:00.020 --> 00:15:02.940\nAnd you know what?\nI missed one right here in identification,\n\n305\n00:15:02.940 --> 00:15:04.760\nand that's allocation, right?\n\n306\n00:15:04.760 --> 00:15:09.170\nThe reason we question is\nan incident happened, right?\n\n307\n00:15:09.170 --> 00:15:12.110\nDetermine if it's ongoing or not.\n\n308\n00:15:12.110 --> 00:15:15.740\nIdentify if you will\nthe categorization of this incident.\n\n309\n00:15:15.740 --> 00:15:17.520\nWhy do we categorize?\n\n310\n00:15:17.520 --> 00:15:20.370\nBecause we have to allocate\ncompany personnel and\n\n311\n00:15:20.370 --> 00:15:24.440\nresources to the time that it\ntakes to stop this incident.\n\n312\n00:15:24.440 --> 00:15:25.920\nAnd if it's just a server that went down,\n\n313\n00:15:25.920 --> 00:15:30.580\nthat's a lot different than an entire\nsite, the Gainesville site is offline.\n\n314\n00:15:30.580 --> 00:15:33.730\nThe allocation of resources to\nan entire site going down, is gonna be\n\n315\n00:15:33.730 --> 00:15:37.620\ndifferent than what it would just as\na hard drive in an end users computer.\n\n316\n00:15:39.060 --> 00:15:42.891\nWe have to make sure that identify and\ncategorize it appropriately so\n\n317\n00:15:42.891 --> 00:15:46.194\nthat we can then allocate\nthe personnel and the resources,\n\n318\n00:15:46.194 --> 00:15:49.033\ncuz it's gonna cost your\nbusiness money In order to\n\n319\n00:15:49.033 --> 00:15:52.814\ntry to rectify whatever the situation\nis that we're dealing with.\n\n320\n00:15:52.814 --> 00:15:57.371\nAll right, so and then we go into well,\ncontainment and let me go ahead and\n\n321\n00:15:57.371 --> 00:16:02.168\nmove out of here a little bit there and\nI get my zoom, sorry about that, guys.\n\n322\n00:16:02.168 --> 00:16:05.480\nAll right, so\nthen there's containment, all right?\n\n323\n00:16:05.480 --> 00:16:10.660\nAnd with containment,\ntime effectiveness is important, right?\n\n324\n00:16:10.660 --> 00:16:15.370\nBecause with containment, the longer\nit takes you to contain a situation,\n\n325\n00:16:15.370 --> 00:16:20.360\nit quickly can become very\ncost inefficient, and\n\n326\n00:16:20.360 --> 00:16:25.260\nhave just a very bad adverse\neffect on your company, right?\n\n327\n00:16:25.260 --> 00:16:29.240\nAnd it can drastically or exponentially\nincrease the longer this goes on.\n\n328\n00:16:29.240 --> 00:16:32.550\nSo, it has to be time effective\nin containing the incident.\n\n329\n00:16:32.550 --> 00:16:34.150\nThen, there's isolation.\n\n330\n00:16:34.150 --> 00:16:37.120\nAnd the isolation is important, right?\n\n331\n00:16:37.120 --> 00:16:38.320\nSo let me give you an example.\n\n332\n00:16:38.320 --> 00:16:41.580\nSo if I have, for instance,\nif I have a hard drive that's failing, and\n\n333\n00:16:41.580 --> 00:16:46.270\nit's a single hard drive failing\nwithin a server that we really need,\n\n334\n00:16:46.270 --> 00:16:48.320\nwell I'm not really too\nworried about containment.\n\n335\n00:16:48.320 --> 00:16:51.220\nI might want some redundancy and\nfail over to another server, so\n\n336\n00:16:51.220 --> 00:16:53.490\nthat we can bring this one offline.\n\n337\n00:16:53.490 --> 00:16:59.030\nBut if I've got a worm active in my\nnetwork, and it's consuming the resources\n\n338\n00:16:59.030 --> 00:17:03.810\nof each machine as it passes through and\nthe network devices, this is the time when\n\n339\n00:17:03.810 --> 00:17:07.670\nwe might have to air gap the whole entire\nportion of the network that has a problem.\n\n340\n00:17:07.670 --> 00:17:11.890\nI quite literally mean air gap, no\nphysical inbound or outbound connections.\n\n341\n00:17:11.890 --> 00:17:15.720\nBecause of the fact we want to\ncontain it so it doesn't go further.\n\n342\n00:17:15.720 --> 00:17:18.780\n&gt;&gt; Is this where we might use\na honey pot for instance?\n\n343\n00:17:18.780 --> 00:17:21.780\n&gt;&gt; Absolutely, a honey pot,\nI'm glad you asked that question.\n\n344\n00:17:21.780 --> 00:17:26.372\nA honey pot is good for evaluating\nhow things are gonna happen, and\n\n345\n00:17:26.372 --> 00:17:28.838\nthat I would say part of\nyour preparation phase.\n\n346\n00:17:28.838 --> 00:17:29.360\n&gt;&gt; Right.\n&gt;&gt; Right,\n\n347\n00:17:29.360 --> 00:17:33.610\nbecause after the fact, now if the\nincident, what we think is an incident,\n\n348\n00:17:33.610 --> 00:17:36.940\nhappens in a honey pot, by all means\nthat's great, because it is isolated.\n\n349\n00:17:36.940 --> 00:17:39.760\nBut the honey pot's more about\nthe investigation side, so\n\n350\n00:17:39.760 --> 00:17:42.770\nI would say that would be great\ninside of the preparation phase, so\n\n351\n00:17:42.770 --> 00:17:47.420\nthat we can identify which of\nthose resources are critical.\n\n352\n00:17:47.420 --> 00:17:48.320\nSo, great question there.\n\n353\n00:17:48.320 --> 00:17:49.030\n&gt;&gt; Great.\n\n354\n00:17:49.030 --> 00:17:52.280\n&gt;&gt; All right, so let's see,\nlast thing that I wanted to, isolation,\n\n355\n00:17:52.280 --> 00:17:53.454\nwhat else in isolation here?\n\n356\n00:17:53.454 --> 00:17:55.052\nDo we have to implement firewalls?\n\n357\n00:17:55.052 --> 00:17:59.643\nDo we have to implement things like V\nlens, do we have to close a switch port\n\n358\n00:17:59.643 --> 00:18:03.415\ndown because we need to\nisolate the system, right?\n\n359\n00:18:03.415 --> 00:18:06.805\nThen the last thing that we also wanna\ntalk about is just basic forensics, and\n\n360\n00:18:06.805 --> 00:18:09.435\nthe reason I put forensics\nin the list is because,\n\n361\n00:18:09.435 --> 00:18:14.075\nif forensic investigation needs to go on,\nwhat you do to the company\n\n362\n00:18:14.075 --> 00:18:18.045\nto bring it back online might tamper\nthe evidence that is in question.\n\n363\n00:18:18.045 --> 00:18:20.170\nSo again, it depends, right?\n\n364\n00:18:20.170 --> 00:18:22.730\nForensics can cause your recovery phase,\n\n365\n00:18:22.730 --> 00:18:26.200\nor this whole entire incident\nresponse phase, to take forever.\n\n366\n00:18:26.200 --> 00:18:29.485\nSo you also have to consider as,\nback to part of preparation,\n\n367\n00:18:29.485 --> 00:18:32.454\nif this is an incident, and\nit does require forensics,\n\n368\n00:18:32.454 --> 00:18:35.126\nwe might not be able to\nmanipulate the data at all.\n\n369\n00:18:35.126 --> 00:18:38.572\nWe might not be able to bring the system\nback online if there's some kind of\n\n370\n00:18:38.572 --> 00:18:42.950\nlegality behind it, so that can always\nthrow a damper in the system too.\n\n371\n00:18:42.950 --> 00:18:44.770\nThen we have eradication.\n\n372\n00:18:44.770 --> 00:18:46.080\nThis is the next one, all right.\n\n373\n00:18:46.080 --> 00:18:47.700\nNow with eradication,\n\n374\n00:18:47.700 --> 00:18:51.540\nwe've got a few different things\nthat we need to keep in mind here.\n\n375\n00:18:51.540 --> 00:18:55.430\nAll right, first of all, we have to\nfully understand the attack vector.\n\n376\n00:18:55.430 --> 00:19:01.020\nIt is very, very important that we\nunderstand what's being attacked.\n\n377\n00:19:01.020 --> 00:19:05.550\nWe don't know if we can eradicate it if\nwe're not sure which systems are affected.\n\n378\n00:19:05.550 --> 00:19:08.130\nSo we have to understand\nthings like the attack vector.\n\n379\n00:19:08.130 --> 00:19:11.420\nAnd that also goes along with the scope.\n\n380\n00:19:11.420 --> 00:19:12.910\nIs it effecting one system?\n\n381\n00:19:12.910 --> 00:19:17.280\nIs it a worm that's going through\nconsuming resources on multiple\n\n382\n00:19:17.280 --> 00:19:19.950\ninfected systems?\n\n383\n00:19:19.950 --> 00:19:22.950\nIs it isolated to a geographical area?\n\n384\n00:19:22.950 --> 00:19:26.010\nIf I've got a domain in Gainesville,\nbut I've got a domain in LA, and\n\n385\n00:19:26.010 --> 00:19:27.472\nI've got a domain in Maine up there,\n\n386\n00:19:27.472 --> 00:19:32.010\nlet's say Say in New York, is it\nan entire site that's being affected?\n\n387\n00:19:32.010 --> 00:19:35.910\nIs it something like DNS, where DNS is\naffecting the entire eastern seaboard?\n\n388\n00:19:35.910 --> 00:19:37.300\nSo we need to know the scope.\n\n389\n00:19:37.300 --> 00:19:40.730\nAnd again, that all goes back to how we\nproperly allocate the resources that we\n\n390\n00:19:40.730 --> 00:19:43.950\nhave, to try to eradicate this incident.\n\n391\n00:19:43.950 --> 00:19:45.000\nAnd then again, the tools.\n\n392\n00:19:45.000 --> 00:19:46.720\nWhat tools do we need?\n\n393\n00:19:46.720 --> 00:19:49.940\nNow, these tools could\nbe techniques as well.\n\n394\n00:19:49.940 --> 00:19:52.790\nI didn't put techniques in there, so\nI could say tools and techniques.\n\n395\n00:19:52.790 --> 00:19:54.050\nWhy do I say that?\n\n396\n00:19:54.050 --> 00:19:58.820\nWell, software, tools, any malware,\nany kind of antivirus, anti-spyware,\n\n397\n00:19:58.820 --> 00:20:01.830\nthat's a software, it's a tool.\n\n398\n00:20:01.830 --> 00:20:05.350\nHowever, it could be a technique, like\nformatting, or re-imaging the machine.\n\n399\n00:20:05.350 --> 00:20:08.700\nIf you have something that's an issue\non a machine, and you can afford\n\n400\n00:20:08.700 --> 00:20:12.240\nto just do a re-image of it real quick,\nand reinstall the operating system, and\n\n401\n00:20:12.240 --> 00:20:18.560\nthat eradicates it, that is a great\ntechnique for the eradication.\n\n402\n00:20:18.560 --> 00:20:19.480\nWhat else?\n\n403\n00:20:19.480 --> 00:20:21.510\nLet see, things like patching.\n\n404\n00:20:21.510 --> 00:20:25.520\nMaybe you have an incident, there was\nsome kind of security vulnerability that\n\n405\n00:20:25.520 --> 00:20:28.820\nhappened, and somebody exploited\na system that needs patching.\n\n406\n00:20:28.820 --> 00:20:31.290\nYou might have to go back and look at\nyour patch management system, right,\n\n407\n00:20:31.290 --> 00:20:33.080\nyou've got thorough documentation.\n\n408\n00:20:33.080 --> 00:20:35.900\nCould be things like configuration\nmanagement too that cause you\n\n409\n00:20:35.900 --> 00:20:37.530\nproblems, all right.\n\n410\n00:20:37.530 --> 00:20:39.370\nSo keep in mind eradication.\n\n411\n00:20:40.490 --> 00:20:44.260\nThe last one, well, second to last one\nI should say, is the recovery phase.\n\n412\n00:20:44.260 --> 00:20:47.130\nAnd when we come into the recovery phase,\nwe got a few steps for\n\n413\n00:20:47.130 --> 00:20:49.300\nit as well that we need to look at.\n\n414\n00:20:49.300 --> 00:20:52.060\nFirst of all is bringing\nour systems back online.\n\n415\n00:20:52.060 --> 00:20:54.660\nThat's important, all right.\n\n416\n00:20:54.660 --> 00:20:58.460\nWe ensure that in part of bringing\nthose systems back online,\n\n417\n00:20:58.460 --> 00:21:01.733\nif we discover that we do have\nan imaging process that we need to do,\n\n418\n00:21:01.733 --> 00:21:05.450\nmaybe it is some kind of worm,\nmaybe it is some kind of virus infection\n\n419\n00:21:05.450 --> 00:21:10.370\nthat went from machine to machine to\nmachine through your end users' emails.\n\n420\n00:21:10.370 --> 00:21:13.710\nSo we could have multiple systems that we\nhave to restore and bring them online, and\n\n421\n00:21:13.710 --> 00:21:15.780\na lot of time,\nimaging is the way we can do this, so\n\n422\n00:21:15.780 --> 00:21:18.830\nwe can save ourselves a lot of headache.\n\n423\n00:21:18.830 --> 00:21:21.160\nIt could be the fact that\nwe need to reimage, and\n\n424\n00:21:21.160 --> 00:21:23.610\nthat we need to restore\nour data from backups.\n\n425\n00:21:23.610 --> 00:21:25.930\nSo, that is one of the ways\nthat you can do recovery.\n\n426\n00:21:25.930 --> 00:21:31.550\nA lot of people think of recovery as\nbeing restoring from your backups.\n\n427\n00:21:31.550 --> 00:21:35.040\nBut it could be things like\nredundant power grids, right?\n\n428\n00:21:35.040 --> 00:21:36.620\nPower is a big thing, right?\n\n429\n00:21:36.620 --> 00:21:40.430\nIn Security Plus, we talk about\nconfidentiality, integrity, and\n\n430\n00:21:40.430 --> 00:21:41.670\navailability.\n\n431\n00:21:41.670 --> 00:21:45.070\nAvailability is making sure that the\nauthorized user have access to their data.\n\n432\n00:21:45.070 --> 00:21:47.790\nAnd if the power goes offline,\nthat affects availability.\n\n433\n00:21:47.790 --> 00:21:49.620\nAnd that goes contrary to security, right?\n\n434\n00:21:49.620 --> 00:21:53.550\nSo it could be the simple fact that we\nneed to implement things like redundant\n\n435\n00:21:53.550 --> 00:21:55.920\npower grids if we're going for\nhigh availability.\n\n436\n00:21:55.920 --> 00:21:58.955\nUPS, again uninterruptible power supplies.\n\n437\n00:21:58.955 --> 00:22:02.775\nKeep in mind that restoration of backups\ncould be something that you're doing, but\n\n438\n00:22:02.775 --> 00:22:05.185\nit could be implementing redundancy so\n\n439\n00:22:05.185 --> 00:22:08.115\nthat you have a level of\nfault tolerance afterwards.\n\n440\n00:22:08.115 --> 00:22:08.805\nAnd then,\n\n441\n00:22:08.805 --> 00:22:12.690\nnext thing in your recovery process\nis ongoing auditing and monitoring.\n\n442\n00:22:12.690 --> 00:22:14.280\nRight?\nAnd I didn't know which way to put this.\n\n443\n00:22:14.280 --> 00:22:17.120\nWe could put it in monitoring first,\nwe could put auditing first.\n\n444\n00:22:17.120 --> 00:22:21.070\nBut, monitoring to make sure that\nthe systems have established full\n\n445\n00:22:21.070 --> 00:22:22.640\nfunctionality.\n\n446\n00:22:22.640 --> 00:22:24.140\nAnd ongoing monitoring.\n\n447\n00:22:24.140 --> 00:22:27.040\nIf it happens to be a hard drive issue,\nwe're gonna wanna watch that hard drive\n\n448\n00:22:27.040 --> 00:22:31.730\nand make sure that our system stays and\nremains functional.\n\n449\n00:22:31.730 --> 00:22:33.520\nBut then if it's some\nkind of malicious attack,\n\n450\n00:22:33.520 --> 00:22:35.570\nwe might wanna be checking\nthrough monitoring.\n\n451\n00:22:35.570 --> 00:22:36.860\nWe might wanna check audit logs.\n\n452\n00:22:36.860 --> 00:22:41.490\nAnd when it comes to audit logs,\nwe might see signs of suspicious activity.\n\n453\n00:22:41.490 --> 00:22:42.600\nOr maybe you don't.\n\n454\n00:22:42.600 --> 00:22:47.300\nBut it is good to do an ongoing\nmonitoring process when it comes to this\n\n455\n00:22:47.300 --> 00:22:49.200\nstep here of recovery.\n\n456\n00:22:49.200 --> 00:22:54.890\n&gt;&gt; So Wes, I noticed that on your screen,\neverything seemed to be connected.\n\n457\n00:22:54.890 --> 00:22:55.990\nThere's a connectivity there,\n\n458\n00:22:55.990 --> 00:22:59.100\nthere seemed to be something\nthat's universally going on.\n\n459\n00:22:59.100 --> 00:22:59.960\nWhat's going on there?\n\n460\n00:22:59.960 --> 00:23:01.983\n&gt;&gt; That's my avalanche from\nbeginning to completion.\n\n461\n00:23:01.983 --> 00:23:03.470\n&gt;&gt; Yeah\n&gt;&gt; Just kidding, that's right.\n\n462\n00:23:03.470 --> 00:23:08.060\nBut if you'll notice, after every step\nhere, I didn't really kinda scroll down,\n\n463\n00:23:08.060 --> 00:23:09.080\nbut we have Document.\n\n464\n00:23:09.080 --> 00:23:11.400\nDocumentation, right, and\nthen we have documentation.\n\n465\n00:23:11.400 --> 00:23:15.700\nBecause one of the things that they call\nout are the reporting requirements, and\n\n466\n00:23:15.700 --> 00:23:20.680\nthat is a responsibility that we need\nto implement inside of our networks.\n\n467\n00:23:20.680 --> 00:23:24.170\nAnd as you see,\nthrough every step we're documenting,\n\n468\n00:23:24.170 --> 00:23:27.670\ndocumenting all the way\ndown to the final step.\n\n469\n00:23:27.670 --> 00:23:30.000\nAnd that's why they all\nkinda tie together.\n\n470\n00:23:30.000 --> 00:23:34.040\nAnd that's what that line is\nreally kind of letting us know.\n\n471\n00:23:34.040 --> 00:23:36.450\nThe last step is what's\nknown as lessons learned.\n\n472\n00:23:37.470 --> 00:23:40.870\nThis really is all about stepping back and\nsaying.\n\n473\n00:23:40.870 --> 00:23:43.535\nHey, where is our security?\n\n474\n00:23:43.535 --> 00:23:45.015\nWhere's our security stance right now?\n\n475\n00:23:45.015 --> 00:23:48.959\nSo we're going back through things and\nlooking at the documentation we had in\n\n476\n00:23:48.959 --> 00:23:53.572\nthe preparation phase, the identification\nphase, looking and reviewing the documents\n\n477\n00:23:53.572 --> 00:23:57.049\nthat we have, the documentations\nthrough our containment phase.\n\n478\n00:23:57.049 --> 00:24:01.517\nAnd again, I know it's wash-rinse-repeat\nhere, but the eradication phase,\n\n479\n00:24:01.517 --> 00:24:02.370\nas well as the.\n\n480\n00:24:02.370 --> 00:24:04.094\nThings like the recovery phase\n&gt;&gt; And\n\n481\n00:24:04.094 --> 00:24:08.908\nthere really is no way you can possibly\nsay maybe I played it too safe by\n\n482\n00:24:08.908 --> 00:24:11.900\ncovering yourself this way\n&gt;&gt; Yeah you always\n\n483\n00:24:11.900 --> 00:24:12.780\n&gt;&gt; Document document\n\n484\n00:24:12.780 --> 00:24:13.650\n&gt;&gt; That's right cuz you always\n\n485\n00:24:13.650 --> 00:24:14.458\nlose something.\n\n486\n00:24:14.458 --> 00:24:16.691\nThe devil's in the details\nthey always say.\n\n487\n00:24:16.691 --> 00:24:20.310\nWell we need to be looking at the details\ncuz we need to improve and make sure,\n\n488\n00:24:20.310 --> 00:24:24.890\ncuz for every minute that\nwe're down it costs money.\n\n489\n00:24:24.890 --> 00:24:26.100\nLet me give you an example here.\n\n490\n00:24:27.280 --> 00:24:31.170\nAmazon, a couple of years back\nI wanna say, it's 2017 as the,\n\n491\n00:24:31.170 --> 00:24:34.330\nif you guys are watching this now,\nwhen we're recording.\n\n492\n00:24:34.330 --> 00:24:38.850\nI wanna say it was 2015,\nAmazon was down, I'm not exactly sure\n\n493\n00:24:38.850 --> 00:24:43.386\nhow long they were down But it worked\nout to be, it was a 15 minute downtime.\n\n494\n00:24:43.386 --> 00:24:45.310\nIt cost them $930,000.\n\n495\n00:24:45.310 --> 00:24:49.230\nI think was just under $67,000\nper minute that they were down.\n\n496\n00:24:49.230 --> 00:24:53.380\nSo, when we talk about lessons learned,\nand in context to your question or\n\n497\n00:24:53.380 --> 00:24:56.820\nyour statement,\nyou're absolutely right, minutes count.\n\n498\n00:24:56.820 --> 00:25:00.090\nSo, how can we squeeze the minutes out to\nensure that we don't have some kind of\n\n499\n00:25:00.090 --> 00:25:05.080\nfinancial burden on our plate, because we\nhaven't brought our systems back online?\n\n500\n00:25:05.080 --> 00:25:08.650\nOther things too,\nis more training required?\n\n501\n00:25:08.650 --> 00:25:09.890\nDo we have the adequate training?\n\n502\n00:25:09.890 --> 00:25:14.170\nCuz remember if you're responsible for\nimplementing this, you're responsible for\n\n503\n00:25:14.170 --> 00:25:15.570\nensuring that the employees are trained.\n\n504\n00:25:15.570 --> 00:25:18.530\nThe employees can't perform their tasks if\nthey're not aware of what they need to do.\n\n505\n00:25:18.530 --> 00:25:23.320\nAnd even if you're implementing\na moderate amount of training,\n\n506\n00:25:23.320 --> 00:25:24.510\ndid the training hold up?\n\n507\n00:25:24.510 --> 00:25:27.930\nDid you come to any point\nwithin this process and\n\n508\n00:25:27.930 --> 00:25:32.280\ndid somebody say I wish\nI would have done this.\n\n509\n00:25:32.280 --> 00:25:33.500\nYou need to document that, right?\n\n510\n00:25:33.500 --> 00:25:36.530\nCompliance, has it been met,\nhas it been retained?\n\n511\n00:25:36.530 --> 00:25:40.560\nEspecially when we're talking about things\nlike HIPAA compliance, PCI DSS standards,\n\n512\n00:25:40.560 --> 00:25:42.850\nFIPS standards, these are all important.\n\n513\n00:25:42.850 --> 00:25:44.290\nDo we have enough people?\n\n514\n00:25:44.290 --> 00:25:46.600\nAnd even more so,\ndo we have the right people?\n\n515\n00:25:46.600 --> 00:25:47.570\nThat's important too,\n\n516\n00:25:47.570 --> 00:25:50.410\ncuz you can have enough people and\na whole bunch of people that know nothing\n\n517\n00:25:50.410 --> 00:25:53.540\nare worse off than five people that\nknow their jobs beginning to end.\n\n518\n00:25:53.540 --> 00:25:56.940\nSo, we also have to make sure that\nwe know we have the right people.\n\n519\n00:25:56.940 --> 00:26:01.500\nAnd the last thing, was there any\naccidental collateral damage?\n\n520\n00:26:01.500 --> 00:26:04.200\nDid we damage anything trying to recover?\n\n521\n00:26:04.200 --> 00:26:05.920\nAnd it can happen.\n\n522\n00:26:05.920 --> 00:26:10.380\nOne of the things you might notice too is\nthat incident response, it's our military.\n\n523\n00:26:10.380 --> 00:26:13.870\nIt's our military that started a lot\nof this documentation all, and\n\n524\n00:26:13.870 --> 00:26:15.830\nit's really been brought\ninto the public sector.\n\n525\n00:26:15.830 --> 00:26:18.260\nAnd we're kind of just tailor making it.\n\n526\n00:26:18.260 --> 00:26:21.850\nWe're shaping it and\nmolding it to what IT needs today.\n\n527\n00:26:21.850 --> 00:26:23.520\nSo you can see they do a lot of things,\n\n528\n00:26:23.520 --> 00:26:27.050\nlike in the military I hear they\nhave AARs, after action reviews,\n\n529\n00:26:27.050 --> 00:26:31.190\nwhere we sit down, and we figure out\ndid we do what we were supposed to do?\n\n530\n00:26:31.190 --> 00:26:34.990\nAnd if we're caught in the situation\nagain how can we improve the approach\n\n531\n00:26:34.990 --> 00:26:38.040\nsystematically from beginning to end and\nmake improvements upon it so\n\n532\n00:26:38.040 --> 00:26:39.620\nthat we're always getting better?\n\n533\n00:26:39.620 --> 00:26:43.950\nAnd we're trying to mitigate those\nincidents, or at least like a risk,\n\n534\n00:26:43.950 --> 00:26:48.330\nbring them down to a more acceptable\nlevel and acceptable amount of loss.\n\n535\n00:26:48.330 --> 00:26:48.940\n&gt;&gt; Awesome, well,\n\n536\n00:26:48.940 --> 00:26:52.370\nthis has been Incident Response\nProcedures Inside CompTIA Security +.\n\n537\n00:26:52.370 --> 00:26:54.770\nI have learned so much from you.\n\n538\n00:26:54.770 --> 00:26:57.100\nIn fact, one more little thing I\nwant to mention real quick, too.\n\n539\n00:26:57.100 --> 00:26:59.790\nDidn't we also mention that\nhere at the very end of this,\n\n540\n00:26:59.790 --> 00:27:02.240\nthe culmination,\nthis is where honeypots might also be?\n\n541\n00:27:02.240 --> 00:27:03.990\n&gt;&gt; Yeah, that is a great point.\n\n542\n00:27:03.990 --> 00:27:07.270\nYeah, in our lessons learned\nwe might figure out that, hey,\n\n543\n00:27:07.270 --> 00:27:09.750\nwe probably should have had\na honeypot in the preparation phase.\n\n544\n00:27:09.750 --> 00:27:12.990\nSo that we can figure out and\nlearn if it's an attack,\n\n545\n00:27:12.990 --> 00:27:14.040\nwhat the attackers are using.\n\n546\n00:27:14.040 --> 00:27:15.140\nWhat techniques are they using?\n\n547\n00:27:15.140 --> 00:27:18.640\nAnd that's one of the great things about\nthings like honeynets, an entire network,\n\n548\n00:27:18.640 --> 00:27:21.340\nif you will or\na specific resource, a honeypot.\n\n549\n00:27:21.340 --> 00:27:24.260\nWe might find out in our lessons\nlearned that it's time to include that\n\n550\n00:27:24.260 --> 00:27:28.410\nin our preparation phase so\nthat we can be more aware of what we face.\n\n551\n00:27:28.410 --> 00:27:32.470\nAnd really, what anybody that has\nmalicious activities going on is\n\n552\n00:27:32.470 --> 00:27:34.400\nusing to try to get into our systems.\n\n553\n00:27:34.400 --> 00:27:37.480\nIncident Response Procedures\ninside CompTIA Security +.\n\n554\n00:27:37.480 --> 00:27:38.600\nThank you again, Wes.\n\n555\n00:27:38.600 --> 00:27:39.180\n&gt;&gt; Absolutely.\n&gt;&gt; And\n\n556\n00:27:39.180 --> 00:27:43.370\nthere is more of the CompTIA Security+,\nso stay tuned for that.\n\n557\n00:27:43.370 --> 00:27:45.820\nAnd if you miss something,\ngo on back and watch it, right?\n\n558\n00:27:45.820 --> 00:27:46.420\n&gt;&gt; Absolutely.\n\n559\n00:27:46.420 --> 00:27:49.490\n&gt;&gt; Okay, well, for\nITPro.TV, I'm Zach Memos.\n\n560\n00:27:49.490 --> 00:27:50.330\n&gt;&gt; And I'm Wes Bryan.\n\n561\n00:27:50.330 --> 00:27:53.323\n&gt;&gt; Thank you for watching.\n\n562\n00:27:53.323 --> 00:27:59.235\n[MUSIC]\n\n563\n00:27:59.235 --> 00:28:02.587\nThank you for watching ITProTV.\n\n",
          "vimeoId": "216836617"
        },
        {
          "description": "In this episode, Daniel and Wes begin their discussion of the basics of computer forensics. Topics covered include Order of Volatility, Chain of Custody, Data Acquisition, and Strategic Intelligence Gathering.",
          "length": "1737",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-5-basic_concepts_of_forensics-050517-PGM.00_28_41_10.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-5-basic_concepts_of_forensics-050517-PGM.00_28_41_10.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-5-basic_concepts_of_forensics-050517-PGM.00_28_41_10.Still001-sm.jpg",
          "title": "Basic Concepts of Forensics",
          "transcript": "WEBVTT\n\n1\n00:00:00.334 --> 00:00:02.032\nWelcome to ITPro.TV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.032 --> 00:00:07.821\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:07.821 --> 00:00:12.294\n&gt;&gt; You're watching ITPro.TV.\n\n4\n00:00:12.294 --> 00:00:13.951\n&gt;&gt; All right, greetings everyone, and\n\n5\n00:00:13.951 --> 00:00:16.087\nwelcome to another great\nepisode of ITPro.TV.\n\n6\n00:00:16.087 --> 00:00:18.080\nI'm your host, Daniel Lowrie.\n\n7\n00:00:18.080 --> 00:00:21.860\nAnd in today's episode, well, we are back\nwith more on our Security+ Series.\n\n8\n00:00:21.860 --> 00:00:23.340\nAnd of course,\njoining us in the studio yet\n\n9\n00:00:23.340 --> 00:00:26.540\nagain to lend his expertise on that topic,\nour good friend Mr Wes Bryan.\n\n10\n00:00:26.540 --> 00:00:27.410\nWes, welcome back, sir.\n\n11\n00:00:27.410 --> 00:00:28.000\nI'm glad to have you.\n\n12\n00:00:28.000 --> 00:00:29.180\n&gt;&gt; Hey, thanks for having me here, Dan.\n\n13\n00:00:29.180 --> 00:00:33.620\nAlways good to be with the ITProTV\ncrew in studio two, if I can say that.\n\n14\n00:00:33.620 --> 00:00:37.770\nThat's right, we're gonna be looking\nat basic forensics concepts today.\n\n15\n00:00:37.770 --> 00:00:41.000\nSo we're gonna kinda\nshift gears a little bit.\n\n16\n00:00:41.000 --> 00:00:45.530\nWe're gonna talk about some of the things\nthat you have to be aware of for the exam.\n\n17\n00:00:45.530 --> 00:00:48.020\nIf they put you in a scenario\nwhere they're asking you\n\n18\n00:00:48.020 --> 00:00:51.730\nto do things like recover data for\nmaybe a criminal investigation.\n\n19\n00:00:51.730 --> 00:00:54.930\nNow the great thing is,\nif you are going on to higher levels of\n\n20\n00:00:54.930 --> 00:00:58.800\nsecurity certifications, they really\nget in depth on each processes.\n\n21\n00:00:58.800 --> 00:01:02.490\nThe processes if you will, the utilities\nand the tools that you implement.\n\n22\n00:01:02.490 --> 00:01:05.320\nThe great thing is,\nhere at the Security+ level what\n\n23\n00:01:05.320 --> 00:01:08.140\nthey're really wanting to know is that\ndo you know these individual steps?\n\n24\n00:01:08.140 --> 00:01:10.480\nAnd do you know some of\nthe concepts behind it?\n\n25\n00:01:10.480 --> 00:01:13.520\nAnd if they give you a question or\na scenario,\n\n26\n00:01:13.520 --> 00:01:16.900\ncould you identify where are we in this\nprocess, where do we have to go next?\n\n27\n00:01:16.900 --> 00:01:19.750\nSo, that's one of the things, that's one\nof the many things that we're gonna look\n\n28\n00:01:19.750 --> 00:01:23.730\nat here when it comes to\nthe basics of forensics.\n\n29\n00:01:23.730 --> 00:01:24.900\n&gt;&gt; So Wes, when it comes to forensics,\n\n30\n00:01:24.900 --> 00:01:28.610\nobviously there is a time sensitivity\nfactor that comes into play,\n\n31\n00:01:28.610 --> 00:01:30.950\nwhen it comes to the evidence\nthat we're gonna be working with.\n\n32\n00:01:30.950 --> 00:01:33.870\nObviously, forensics, we're thinking\nevidence, there's something that has\n\n33\n00:01:33.870 --> 00:01:38.670\nhappened, and we have to engage\nthat situation accordingly.\n\n34\n00:01:38.670 --> 00:01:40.780\nAnd like I said, the time sensitivity,\n\n35\n00:01:40.780 --> 00:01:45.740\nhow do we prioritize when it comes\nto the evidence in that factor?\n\n36\n00:01:45.740 --> 00:01:50.340\n&gt;&gt; Very good, so\nprioritization of data acquisition.\n\n37\n00:01:50.340 --> 00:01:51.760\nThat's very, very important.\n\n38\n00:01:51.760 --> 00:01:54.510\nAnd like Dan says, time sensitivity.\n\n39\n00:01:54.510 --> 00:01:55.870\nWhy would it be time sensitive?\n\n40\n00:01:55.870 --> 00:01:57.050\nWell I want you to think about this.\n\n41\n00:01:57.050 --> 00:02:00.520\nFor instance,\nwe have information stored in RAM, right?\n\n42\n00:02:00.520 --> 00:02:02.950\nWell what's so time sensitive about that?\n\n43\n00:02:02.950 --> 00:02:05.680\nWell really, if you're talking about\nsome kind of criminal investigation,\n\n44\n00:02:05.680 --> 00:02:06.640\nit is time sensitive.\n\n45\n00:02:06.640 --> 00:02:08.970\nCuz how quickly can I get over\nto the power button, right?\n\n46\n00:02:08.970 --> 00:02:11.330\nOr pull the power on the computer.\n\n47\n00:02:11.330 --> 00:02:14.590\nAnd then what happens to\nthe information that's stored in RAM?\n\n48\n00:02:14.590 --> 00:02:17.090\nWell, your system memory is\na volatile memory, right?\n\n49\n00:02:17.090 --> 00:02:18.980\nLet's go back to the A+ stage, right.\n\n50\n00:02:18.980 --> 00:02:19.840\nVolatile memory.\n\n51\n00:02:19.840 --> 00:02:22.010\nWe say that it needs\nan electrical current, right?\n\n52\n00:02:22.010 --> 00:02:27.040\nAn electrical refresh to maintain the\ndata, cuz the data is disappearing, right?\n\n53\n00:02:27.040 --> 00:02:29.800\nAnd we hit it with more electricity and\nit re-paints that data and\n\n54\n00:02:29.800 --> 00:02:32.840\nit starts to fade away and\nthen we hit that electricity again.\n\n55\n00:02:32.840 --> 00:02:35.080\nAnd, we're doing that\nprocess constantly for\n\n56\n00:02:35.080 --> 00:02:37.730\ndata retention in that storage location,\nright.\n\n57\n00:02:37.730 --> 00:02:40.090\nAnd that's where something known\nas order of volatility comes in.\n\n58\n00:02:40.090 --> 00:02:43.051\nAnd when we talk about\nthe order of volatility,\n\n59\n00:02:43.051 --> 00:02:46.990\nit is prioritizing what data\nis gonna be lost the quickest.\n\n60\n00:02:46.990 --> 00:02:51.770\nSo what we wanna do is we wanna start with\nthe data that's gonna be lost fastest, so\n\n61\n00:02:51.770 --> 00:02:54.900\nwhen we get to it, we can preserve\nit before it's completely gone.\n\n62\n00:02:54.900 --> 00:02:55.820\nLet me show you what I mean.\n\n63\n00:02:55.820 --> 00:02:58.820\nI've got a little chart, and\nyou guys can see all different charts,\n\n64\n00:02:58.820 --> 00:03:00.765\ntypes of charts when it comes\nto order of volatility,\n\n65\n00:03:00.765 --> 00:03:03.580\nit's kind of like a basic one talking\nabout some of the basic concepts, right.\n\n66\n00:03:03.580 --> 00:03:07.390\nSo, order of volatility, we talk\nabout things like our CPU register,\n\n67\n00:03:07.390 --> 00:03:09.480\ntypically a register\nholds one bit of data.\n\n68\n00:03:09.480 --> 00:03:11.380\nBut again, with power loss,\n\n69\n00:03:11.380 --> 00:03:14.550\nthat information is almost\ninstantaneously erased.\n\n70\n00:03:14.550 --> 00:03:19.050\nWe have things like our caching,\nthink about your caching system, common\n\n71\n00:03:19.050 --> 00:03:24.188\noperations, frequently accessed data is\ngonna be stored in that caching location,\n\n72\n00:03:24.188 --> 00:03:26.540\nhowever, we've got gotta worry about that,\nright?\n\n73\n00:03:26.540 --> 00:03:29.080\nBecause we've gotta get to that\ninformation before the system's\n\n74\n00:03:29.080 --> 00:03:29.940\nturned off.\n\n75\n00:03:29.940 --> 00:03:32.330\nAnd the same thing goes with\nour system memory, right?\n\n76\n00:03:32.330 --> 00:03:35.130\nIf we're storing information in\nnon-volatile regions, right?\n\n77\n00:03:35.130 --> 00:03:36.690\nSo for instance, the page file,\n\n78\n00:03:36.690 --> 00:03:40.220\nwe call it virtual memory,\ndon't think of your physical RAM, right?\n\n79\n00:03:40.220 --> 00:03:44.170\nAt this point, what we're talking about is\nwe're talking about storing information\n\n80\n00:03:44.170 --> 00:03:45.430\nreally on the hard drive.\n\n81\n00:03:45.430 --> 00:03:49.930\nAnd they put that kinda in between your\ndisc drives because it's constantly\n\n82\n00:03:49.930 --> 00:03:51.650\nchanging information, right?\n\n83\n00:03:51.650 --> 00:03:53.390\nIt's not a static file.\n\n84\n00:03:53.390 --> 00:03:55.930\nIt's not like a document\nthat's on your hard drive that\n\n85\n00:03:55.930 --> 00:03:59.690\nreally is only modified when you\nopen it and you make changes to it.\n\n86\n00:03:59.690 --> 00:04:00.780\nA paging system.\n\n87\n00:04:00.780 --> 00:04:02.880\nIt's constantly performing reads and\nwrites.\n\n88\n00:04:02.880 --> 00:04:03.685\nCuz what is it doing, right?\n\n89\n00:04:03.685 --> 00:04:06.827\nIf you remember the paging file,\nessentially when an application\n\n90\n00:04:06.827 --> 00:04:09.980\ncomes online, it doesn't have\ndirect access to memory, right?\n\n91\n00:04:09.980 --> 00:04:13.871\nIt talks to a virtual memory manager and\nthat virtual memory manager ensures that\n\n92\n00:04:13.871 --> 00:04:17.330\nthere's memory regions that can\nbe used actively with the data.\n\n93\n00:04:17.330 --> 00:04:18.398\nAnd if the memory is full,\n\n94\n00:04:18.398 --> 00:04:22.690\nit pulls portions of your data out, blocks\nof it and it writes it to the hard drive.\n\n95\n00:04:22.690 --> 00:04:26.500\nThen, think about this,\nanother application comes online and\n\n96\n00:04:26.500 --> 00:04:29.410\nthat information's pulled off of that\nhard drive and put back into memory.\n\n97\n00:04:29.410 --> 00:04:34.340\nSo you can see, even though, it's kind of\na cross between a volatile scenario, and\n\n98\n00:04:34.340 --> 00:04:39.180\na non-volatile scenario, the fact that\nthe information changes rather quickly\n\n99\n00:04:39.180 --> 00:04:41.860\nis why you see the virtual memory system,\nor\n\n100\n00:04:41.860 --> 00:04:45.755\nthe paging file is a little bit higher\nthan our traditional disk based media.\n\n101\n00:04:45.755 --> 00:04:48.730\nThat also lends itself to\nthe third one in the list, right?\n\n102\n00:04:48.730 --> 00:04:51.430\nWe look at things like our disk drives,\nUSB drive and\n\n103\n00:04:51.430 --> 00:04:54.750\nI just kinda just generically put\nlike SD cards cuz they're common to\n\n104\n00:04:54.750 --> 00:04:59.580\nthings like cameras, your phones if\nyou will, use the micro SD cards.\n\n105\n00:04:59.580 --> 00:05:03.710\nBut guys honestly, any kind of solid\nstate based implementation, right?\n\n106\n00:05:03.710 --> 00:05:05.220\nWhy is that lower on the list?\n\n107\n00:05:05.220 --> 00:05:08.030\nCuz it's a non volatile memory and\nremember,\n\n108\n00:05:08.030 --> 00:05:13.720\nwith non volatile memory If I lose power,\nwell, the data's still there.\n\n109\n00:05:13.720 --> 00:05:17.620\nSo that's why it's not as important\nto get to that as quickly.\n\n110\n00:05:17.620 --> 00:05:22.340\nAnd again, things with SSDs,\nSolid State Drives are up there too.\n\n111\n00:05:22.340 --> 00:05:26.180\nSo removable media,\nwell, it depends, right?\n\n112\n00:05:26.180 --> 00:05:28.860\nUSB drives is a form of removable media.\n\n113\n00:05:28.860 --> 00:05:32.790\nHowever, the data stays on it, we do,\nit's gonna be in the list here.\n\n114\n00:05:32.790 --> 00:05:36.470\nBut it's gonna be unlike the last phase,\nright?\n\n115\n00:05:36.470 --> 00:05:38.910\nOr the last stage,\nthe bottom of the totem pole, if you will.\n\n116\n00:05:38.910 --> 00:05:40.570\nThe bottom, the base of the pyramid.\n\n117\n00:05:40.570 --> 00:05:42.450\nAnd that's things like printed media,\nright.\n\n118\n00:05:42.450 --> 00:05:44.340\nPrinted media isn't changing.\n\n119\n00:05:44.340 --> 00:05:46.990\nThings like your backup media,\nusually that's data at rest, and\n\n120\n00:05:46.990 --> 00:05:49.670\nit doesn't change very often.\n\n121\n00:05:49.670 --> 00:05:52.340\nThings like optical media, right?\n\n122\n00:05:52.340 --> 00:05:56.310\nWith optical media, it's pretty much\ngoing to stay on the media unless I have\n\n123\n00:05:56.310 --> 00:06:00.940\nan overwriter type media that overrides\nthat data right, so rewriter if you will.\n\n124\n00:06:00.940 --> 00:06:04.550\nSo things like your printed media,\nbackup media, optical media,\n\n125\n00:06:04.550 --> 00:06:07.690\nall of these are the bottom of the list.\n\n126\n00:06:07.690 --> 00:06:11.400\nSo it is important to remember\nthat in the order of volatility,\n\n127\n00:06:11.400 --> 00:06:16.330\nyou start at the most volatile regions\ndown to what would be considered not\n\n128\n00:06:16.330 --> 00:06:20.170\nnecessarily nonvolatile but static in that\nfact that it isn't gonna change much.\n\n129\n00:06:20.170 --> 00:06:24.650\nSo again the process goes most volatile,\nlet's access it and\n\n130\n00:06:24.650 --> 00:06:26.270\nget that information quick.\n\n131\n00:06:26.270 --> 00:06:29.010\nLowest bottom of the chain might\nbe something that's done after\n\n132\n00:06:29.010 --> 00:06:29.690\nthe fact, right?\n\n133\n00:06:29.690 --> 00:06:34.550\nWhen we're, as part of our preservation\nof the data acquisition phase.\n\n134\n00:06:34.550 --> 00:06:37.050\n&gt;&gt; All right Wes, when we're talking\nabout collecting evidence and\n\n135\n00:06:37.050 --> 00:06:38.090\ngathering evidence.\n\n136\n00:06:38.090 --> 00:06:42.710\nWe also have to be careful that it does\nnot fall into the wrong hands, as it were.\n\n137\n00:06:42.710 --> 00:06:44.980\nJust become unaccountable, right?\n\n138\n00:06:44.980 --> 00:06:49.700\nThis is a very important concept, and to\nkeep that from happening we use a little\n\n139\n00:06:49.700 --> 00:06:51.910\nthing we like to call\nthe chain of custody, correct?\n\n140\n00:06:51.910 --> 00:06:53.810\n&gt;&gt; Definitely, so imagine this, okay?\n\n141\n00:06:53.810 --> 00:06:58.690\nSo I've got a piece of data that is,\nwe're hoping it's gonna be evidence.\n\n142\n00:06:58.690 --> 00:07:01.700\nWe can't say that it's evidence yet\nbecause we're just saying, okay,\n\n143\n00:07:01.700 --> 00:07:05.720\nwell that storage device has got something\non it, we don't know what it is.\n\n144\n00:07:05.720 --> 00:07:09.500\nHowever, imagine taking\nthat data into custody and\n\n145\n00:07:09.500 --> 00:07:12.250\nthen you present it in a court of law, and\n\n146\n00:07:12.250 --> 00:07:16.190\nthey use things like hashing algorithms\nand they say, well wait a second here.\n\n147\n00:07:16.190 --> 00:07:19.380\nWe know what the data was before\nyou got a hold of it, but\n\n148\n00:07:19.380 --> 00:07:23.060\nnow we're seeing it and\nit seems like there's a mismatch.\n\n149\n00:07:23.060 --> 00:07:27.270\nOr there's a spoilage, or there's\na contamination of the information.\n\n150\n00:07:27.270 --> 00:07:28.990\nWhat happens?\n\n151\n00:07:28.990 --> 00:07:32.490\nWell, the prosecuting attorney is\ngonna have to eventually just throw\n\n152\n00:07:32.490 --> 00:07:36.100\nthe case out or, at least not be able to\nhave that submissible as evidence because\n\n153\n00:07:36.100 --> 00:07:40.850\nit's not the same Information technically,\nthat was basically brought into custody.\n\n154\n00:07:40.850 --> 00:07:44.200\nSo let's go ahead and look at\nthe chain of custody process, right?\n\n155\n00:07:44.200 --> 00:07:44.947\nAnd again,\n\n156\n00:07:44.947 --> 00:07:49.966\nthese are more kinda like a generic as\nfar as the forensic process goes, right?\n\n157\n00:07:49.966 --> 00:07:53.193\nWe start with identification and\nassessing the situation, right?\n\n158\n00:07:53.193 --> 00:07:57.628\nAnd with that starting point of the chain\nof custody, that also revolves around.\n\n159\n00:07:57.628 --> 00:08:02.660\nAuthority, right, we have to find out and\nthings like incident response.\n\n160\n00:08:02.660 --> 00:08:05.840\nWho has the authority to identify and\n\n161\n00:08:05.840 --> 00:08:09.380\nassess the information to do\nthings like classification.\n\n162\n00:08:09.380 --> 00:08:14.100\nAnd say, hey, this is going to be\nthe information that we need to acquiesce.\n\n163\n00:08:14.100 --> 00:08:16.900\nNext is the preservation\nof the information.\n\n164\n00:08:16.900 --> 00:08:18.990\nWe do this, and there's many\ndifferent ways that we do this.\n\n165\n00:08:18.990 --> 00:08:20.370\nWe'll talk about this a little bit more.\n\n166\n00:08:20.370 --> 00:08:24.080\nOne of the main things that we do\nis we take hashing values, right?\n\n167\n00:08:24.080 --> 00:08:26.730\nWe run these message digests\nacross your information\n\n168\n00:08:26.730 --> 00:08:28.400\nthat produces that fixed link value.\n\n169\n00:08:28.400 --> 00:08:32.970\nSo that as we hand that information\nthrough the next phases, right?\n\n170\n00:08:32.970 --> 00:08:37.840\nWe document who handled the information\nand who it went to next.\n\n171\n00:08:37.840 --> 00:08:42.080\nBut it is important in the preservation\nphase that we keep that information in\n\n172\n00:08:42.080 --> 00:08:44.740\nits original state,\nmaintain its integrity.\n\n173\n00:08:44.740 --> 00:08:48.040\nAnd we're documenting this as we\ngo through this later phases so\n\n174\n00:08:48.040 --> 00:08:50.200\nthat when we finally get\nto the reporting phase.\n\n175\n00:08:50.200 --> 00:08:54.430\nWhich you could say is really just\nreporting a presentation in a court of\n\n176\n00:08:54.430 --> 00:08:56.300\nlaw, presenting it as evidence.\n\n177\n00:08:56.300 --> 00:09:00.110\nAgain, preservation of your\ninformation is very, very important.\n\n178\n00:09:00.110 --> 00:09:03.170\nAnd again, we go into the acquire and\ncollection phase.\n\n179\n00:09:03.170 --> 00:09:08.220\nAnd then next is the analysis phase,\nlast being the reporting phase.\n\n180\n00:09:08.220 --> 00:09:11.070\nAnd again, the reporting phase is\nusually when you're presenting it in\n\n181\n00:09:11.070 --> 00:09:11.750\na court of law.\n\n182\n00:09:11.750 --> 00:09:13.600\nSo as a recap, remember chain of custody,\n\n183\n00:09:13.600 --> 00:09:18.050\nhonestly, is just making sure that you\nhave thorough documentation of the data.\n\n184\n00:09:18.050 --> 00:09:20.990\nAnd as it goes through\nthese different processes,\n\n185\n00:09:20.990 --> 00:09:24.390\nif you will, or different stages\nof the forensic life cycle.\n\n186\n00:09:24.390 --> 00:09:27.970\nThat we're thoroughly documenting it,\nso that we know we have accountability.\n\n187\n00:09:27.970 --> 00:09:30.860\nAnd we also make sure that we're\nmaintaining the integrity of the data.\n\n188\n00:09:30.860 --> 00:09:34.620\nSo chain of custody is very\nvery important because\n\n189\n00:09:34.620 --> 00:09:37.960\nit can be just as simple as\na single bit change, right?\n\n190\n00:09:37.960 --> 00:09:41.840\nA simple character change on that data,\nand that changes the overall value of\n\n191\n00:09:41.840 --> 00:09:47.540\nwhatever hashing function that's\nbeen run across that data.\n\n192\n00:09:47.540 --> 00:09:51.040\nSo that when you present it in the court\nof law, again, it's a mismatch,\n\n193\n00:09:51.040 --> 00:09:54.240\nit's gonna be considered spoiled.\n\n194\n00:09:54.240 --> 00:09:56.380\nIt hasn't maintained its integrity, and\n\n195\n00:09:56.380 --> 00:09:58.530\nultimately it can be\nthrown out of a court.\n\n196\n00:09:58.530 --> 00:10:02.264\n&gt;&gt; Man, I'll tell you what, it almost\nfeels like we need to minor in law [LAUGH]\n\n197\n00:10:02.264 --> 00:10:04.295\nto be able to work in digital forensics.\n\n198\n00:10:04.295 --> 00:10:07.091\nBecause there's a lot of legalities,\nlegal terms,\n\n199\n00:10:07.091 --> 00:10:09.893\nlegal terminology that you\nhave to be familiar with.\n\n200\n00:10:09.893 --> 00:10:13.300\nOne of those is a legal hold,\nWesley tells us about that.\n\n201\n00:10:13.300 --> 00:10:15.755\n&gt;&gt; Yeah,\nlegal hold is an interesting concept.\n\n202\n00:10:15.755 --> 00:10:19.092\nSo think about a company that,\nlet's say, for instance,\n\n203\n00:10:19.092 --> 00:10:23.256\none company that maybe some of you guys\nhave been aware of a few years back.\n\n204\n00:10:23.256 --> 00:10:25.810\nI don't know how long,\nit's probably been a long time now.\n\n205\n00:10:25.810 --> 00:10:28.410\nMuch better than a decade,\nbut the Enron scam, right.\n\n206\n00:10:28.410 --> 00:10:33.555\nWhen there is a potential that\nyou know that you might have\n\n207\n00:10:33.555 --> 00:10:39.220\nto present information inside\nof a court of law, right?\n\n208\n00:10:39.220 --> 00:10:43.655\nThis really is the whole process\ncentering around the protection against\n\n209\n00:10:43.655 --> 00:10:45.239\nthe deletion of the data.\n\n210\n00:10:45.239 --> 00:10:49.290\nOr even spoliation of the data\nthat could be considered evidence.\n\n211\n00:10:49.290 --> 00:10:51.979\nSo want you to think about maybe\neven going back to the Watergate\n\n212\n00:10:51.979 --> 00:10:52.799\nscandal, right.\n\n213\n00:10:52.799 --> 00:10:54.699\nWhat were they doing in\nthe Watergate scandal?\n\n214\n00:10:54.699 --> 00:10:59.030\nThey were copying or\ncaught destroying information.\n\n215\n00:10:59.030 --> 00:11:02.500\nSo, if we put a legal hold on that,\nthen what that does\n\n216\n00:11:02.500 --> 00:11:06.590\nis it's a notification from the legal\nteam that tells the employees.\n\n217\n00:11:06.590 --> 00:11:09.870\nInstructing them, if you will,\nto refrain from destroying\n\n218\n00:11:09.870 --> 00:11:13.200\nany data that might later be\nconsidered evidence in a court of law.\n\n219\n00:11:13.200 --> 00:11:17.360\nSo again, you get served a legal hold.\n\n220\n00:11:17.360 --> 00:11:21.540\nEmployees actions on the information\nis stopped, everything is stopped so\n\n221\n00:11:21.540 --> 00:11:23.960\nthat they don't start\ndeleting information.\n\n222\n00:11:25.690 --> 00:11:27.700\nNext thing we have to talk about.\n\n223\n00:11:27.700 --> 00:11:30.088\nWe kind of mentioned a little\nbit about data acquisition.\n\n224\n00:11:30.088 --> 00:11:34.583\nWell they call out quite a few different\ntechniques that you have to go\n\n225\n00:11:34.583 --> 00:11:38.556\nthrough as a part of the data\nacquisition phase, all right.\n\n226\n00:11:38.556 --> 00:11:40.042\nSo I got a little list here,\n\n227\n00:11:40.042 --> 00:11:44.195\nand we'll kind of go through each of\nthese that they call out individually.\n\n228\n00:11:44.195 --> 00:11:47.300\nFirst thing they talk about\nis capturing system images.\n\n229\n00:11:47.300 --> 00:11:52.028\nI want you to think of capturing\nthe system images is really\n\n230\n00:11:52.028 --> 00:11:54.163\nabout data duplication.\n\n231\n00:11:54.163 --> 00:11:58.979\nAnd what we wanna do is we wanna ensure\nthat we get a bit by bit copy of\n\n232\n00:11:58.979 --> 00:12:00.390\nthe information.\n\n233\n00:12:00.390 --> 00:12:01.540\nThat's what a system image is.\n\n234\n00:12:01.540 --> 00:12:05.040\nNow inside of things like deployment\nof operating systems, what do we do?\n\n235\n00:12:05.040 --> 00:12:08.494\nWe install an operating system, we install\nall the applications, and updates.\n\n236\n00:12:08.494 --> 00:12:12.614\nAnd we take a bit by bit copy, and\nthat becomes our system image that we\n\n237\n00:12:12.614 --> 00:12:16.720\ndeploy to other end users or\nto end stations, if you will.\n\n238\n00:12:16.720 --> 00:12:21.210\nIn this aspect that bit by bit copy is so\nthat you do have a copy\n\n239\n00:12:21.210 --> 00:12:24.650\nof the original information, and\nthen you can compare that later.\n\n240\n00:12:24.650 --> 00:12:25.470\nAgain, like we said,\n\n241\n00:12:25.470 --> 00:12:29.510\nmaking sure that the information hasn't\nchanged, even at a bit by bit level, so.\n\n242\n00:12:29.510 --> 00:12:31.350\n&gt;&gt; You use things those write blockers and\n\n243\n00:12:31.350 --> 00:12:31.910\nthings-\n&gt;&gt; That's right.\n\n244\n00:12:31.910 --> 00:12:32.760\n&gt;&gt; When they create these things.\n\n245\n00:12:32.760 --> 00:12:35.540\n&gt;&gt; That's right, hardware based devices,\nand it's, a lot of times,\n\n246\n00:12:35.540 --> 00:12:37.800\na combination of software and hardware.\n\n247\n00:12:37.800 --> 00:12:39.440\nBut if you've got a dedicated device,\n\n248\n00:12:39.440 --> 00:12:44.320\nthey do have dedicated hardware based\ndevices that are very good at doing this.\n\n249\n00:12:44.320 --> 00:12:47.130\nAnd they're streamlined and\noptimized for this process.\n\n250\n00:12:47.130 --> 00:12:50.460\nAnd they also fall under things\nlike legal standards as well.\n\n251\n00:12:50.460 --> 00:12:54.640\nAll right, so whats the next one here,\nnetwork traffic.\n\n252\n00:12:54.640 --> 00:12:58.600\nNetwork traffic is interesting, and we'll\ntalk about the logs here in a second.\n\n253\n00:12:58.600 --> 00:13:02.480\nNetwork traffic is kind of a concept\nof catch it as you go, right?\n\n254\n00:13:02.480 --> 00:13:05.350\nYou kind of, if you will-\n&gt;&gt; It's a moving river.\n\n255\n00:13:05.350 --> 00:13:07.200\n&gt;&gt; It really is, it's a moving target.\n\n256\n00:13:07.200 --> 00:13:09.320\nIf you're gonna grab it,\nyou gotta get it quick.\n\n257\n00:13:09.320 --> 00:13:11.930\nSo, we use things like network analyzers.\n\n258\n00:13:11.930 --> 00:13:15.580\nAnd we can spot things like trends and\nflow patterns, if you will.\n\n259\n00:13:15.580 --> 00:13:18.280\nBut then the logs, now it's important.\n\n260\n00:13:18.280 --> 00:13:22.330\nKeep in mind, when we're talking about\nlogs, you have to enable auditing.\n\n261\n00:13:22.330 --> 00:13:24.180\nWe've talked about auditing\nin other episodes.\n\n262\n00:13:24.180 --> 00:13:27.690\nBut auditing does you absolutely no\ngood if it doesn't produce logs that you\n\n263\n00:13:27.690 --> 00:13:30.260\nare gonna, in turn, view, why?\n\n264\n00:13:30.260 --> 00:13:35.370\nWell, the logs, they have the ability to\nhave some kind of chronological order.\n\n265\n00:13:35.370 --> 00:13:39.160\nAnd that chronological order might\nadhere to a certain timeframe.\n\n266\n00:13:39.160 --> 00:13:44.979\nAnd what you're considering might be\na violation of a security breach, right?\n\n267\n00:13:44.979 --> 00:13:48.852\nBasically they can contain things like\nsensitive information on what a user can\n\n268\n00:13:48.852 --> 00:13:49.850\nor cannot do.\n\n269\n00:13:49.850 --> 00:13:52.481\nAnd maybe lead you in to\nwhat has been done, right?\n\n270\n00:13:52.481 --> 00:13:56.548\nIf my logs contain a record of\nwhat users can and can't do,\n\n271\n00:13:56.548 --> 00:13:58.880\nnow I know what was done, right?\n\n272\n00:13:58.880 --> 00:14:02.750\nSo you gotta make sure that you ensure\nthat you are auditing your systems,\n\n273\n00:14:02.750 --> 00:14:04.190\nwhich produces logs, right?\n\n274\n00:14:04.190 --> 00:14:07.550\nLogging is the result of auditing.\n\n275\n00:14:07.550 --> 00:14:11.040\nAnd you can't review logs if you\ndon't have any to begin with,\n\n276\n00:14:11.040 --> 00:14:13.410\nso keep that in mind.\n\n277\n00:14:13.410 --> 00:14:17.210\nNext thing is capture video,\nyou probably see,\n\n278\n00:14:17.210 --> 00:14:20.060\nI don't know how many people have\nprobably seen this out on YouTube?\n\n279\n00:14:20.060 --> 00:14:22.260\nYou get CCTV, right?\n\n280\n00:14:22.260 --> 00:14:24.320\nThere's a recording of\nwhatever the violation was.\n\n281\n00:14:24.320 --> 00:14:27.440\nA lot of times,\nwe see things like robberies and stuff.\n\n282\n00:14:27.440 --> 00:14:30.164\nThey use those videos,\nright, after the fact,\n\n283\n00:14:30.164 --> 00:14:34.165\nas a way to maybe identify the perpetrator\nor whoever the criminal was.\n\n284\n00:14:34.165 --> 00:14:36.340\nSo that they can go after them, right?\n\n285\n00:14:36.340 --> 00:14:42.590\nSo CCTV, capturing video could\ncapture traces of the crime.\n\n286\n00:14:42.590 --> 00:14:44.190\nAnd you could be able to review that,\nright?\n\n287\n00:14:44.190 --> 00:14:47.080\nWe have things, you've probably seen\nthis all over the place, right?\n\n288\n00:14:47.080 --> 00:14:49.920\nThey have cameras at things like\ntraffic intersections, right, malls and\n\n289\n00:14:49.920 --> 00:14:51.060\nbanks, right?\n\n290\n00:14:51.060 --> 00:14:52.520\nWhy do they use that?\n\n291\n00:14:53.540 --> 00:14:57.110\nIt's not just trying to be a deterrent,\nbut that you can capture that information\n\n292\n00:14:57.110 --> 00:15:01.560\nto review it after the fact\nif something does happen.\n\n293\n00:15:01.560 --> 00:15:07.325\nKeep in mind, too, that the video itself\ncan be in a couple different formats, too.\n\n294\n00:15:07.325 --> 00:15:08.775\nWhich might lead to data spoilage,\n\n295\n00:15:08.775 --> 00:15:11.335\nespecially if you're talking about\ntape rotation methods, right.\n\n296\n00:15:11.335 --> 00:15:14.835\nCould be magnetic media, or a lot of the\ntimes, it's digital formats today, too.\n\n297\n00:15:14.835 --> 00:15:18.350\nSo you have to pay\nattention to that as well.\n\n298\n00:15:18.350 --> 00:15:19.869\nWell, all right, let's see here.\n\n299\n00:15:19.869 --> 00:15:21.985\nIt's interesting,\nwe talk about taking hashes.\n\n300\n00:15:21.985 --> 00:15:24.707\nBut there's one that I don't have\nin here and I should have in here.\n\n301\n00:15:24.707 --> 00:15:25.593\nLet me go ahead and\n\n302\n00:15:25.593 --> 00:15:28.977\njust take a second to talk, and\nthat's recording the time offset.\n\n303\n00:15:30.710 --> 00:15:33.670\nEverything in computers\nis based on timing.\n\n304\n00:15:33.670 --> 00:15:35.370\nEverything you do is based on timing,\n\n305\n00:15:35.370 --> 00:15:40.100\nright down to the heartbeat of a computer\nthat has a clock, a system clock.\n\n306\n00:15:40.100 --> 00:15:44.328\nThat basically times everything kind of\nlike traffic lights do with cars moving\n\n307\n00:15:44.328 --> 00:15:46.105\nacross intersections, right?\n\n308\n00:15:46.105 --> 00:15:47.817\n&gt;&gt; Except in gaming.\n&gt;&gt; Except in games, so that's right.\n\n309\n00:15:47.817 --> 00:15:48.817\n&gt;&gt; They're just random.\n\n310\n00:15:48.817 --> 00:15:50.667\n&gt;&gt; Especially the closer\nwe get to this building.\n\n311\n00:15:50.667 --> 00:15:52.481\n&gt;&gt; Yeah, it's something really weird.\n\n312\n00:15:52.481 --> 00:15:56.636\n&gt;&gt; [LAUGH] But it does,\nit sets the heartbeat of all transactions.\n\n313\n00:15:56.636 --> 00:15:59.506\nAnd it sounds like a bank, but that's\nessentially what you're doing when you're\n\n314\n00:15:59.506 --> 00:16:01.483\nsending information across\nthat mother board, right?\n\n315\n00:16:01.483 --> 00:16:06.744\nYou're sending information from point A to\npoint B, and that time blind, that time\n\n316\n00:16:06.744 --> 00:16:12.023\nframe if you will, needs to be measured\nagainst some kind of time standard, right?\n\n317\n00:16:12.023 --> 00:16:15.943\nSo, we record the offset I think\nthe military calls it Zulu time,\n\n318\n00:16:15.943 --> 00:16:19.100\nsometimes it's called GMT,\nGreenwich Mean Time.\n\n319\n00:16:19.100 --> 00:16:23.500\nSo it might be something like that\nwhere it's a relation to that.\n\n320\n00:16:23.500 --> 00:16:26.837\nYou have a Windows domain, it might\nbe recording the time against your PC\n\n321\n00:16:26.837 --> 00:16:29.753\nemulator which is the master\ntime clock of the domain, right.\n\n322\n00:16:29.753 --> 00:16:35.870\nSo again, recording the time against\na known timing standard is important.\n\n323\n00:16:35.870 --> 00:16:39.643\nNow, that leads us in the next\nconcept here that we have and\n\n324\n00:16:39.643 --> 00:16:41.732\nthat is taking hashes, right?\n\n325\n00:16:41.732 --> 00:16:44.092\nReally, we talk about hash values and\n\n326\n00:16:44.092 --> 00:16:48.824\nother context to making sure that if I\nsend a piece of data from myself to Dan.\n\n327\n00:16:48.824 --> 00:16:51.906\nI can perform a hash algorithm over it and\nI can say hey Dan, here's the file,\n\n328\n00:16:51.906 --> 00:16:54.846\nhere's the algorithm and here's the value\nthat I got, let me go ahead and\n\n329\n00:16:54.846 --> 00:16:56.470\nbundle that and send it to you.\n\n330\n00:16:56.470 --> 00:16:59.640\nDan could say, well, I don't care\nwhat your value is, let me go ahead.\n\n331\n00:16:59.640 --> 00:17:01.530\nOkay, that's the algorithm you used.\n\n332\n00:17:01.530 --> 00:17:05.280\nLet me just put your value to the side\nhere and let me see what I figure out, and\n\n333\n00:17:05.280 --> 00:17:06.630\nthen I compare the two.\n\n334\n00:17:06.630 --> 00:17:10.690\nNow, if the two match, Dan knows that,\nwhether it's network error,\n\n335\n00:17:10.690 --> 00:17:14.685\nor transmission error, or modification,\nit hasn't happened, right?\n\n336\n00:17:14.685 --> 00:17:15.709\nCuz the values are the same.\n\n337\n00:17:16.760 --> 00:17:17.750\nWhen values don't match,\n\n338\n00:17:17.750 --> 00:17:20.660\nthough, it could be network transmission\nerrors that are causing the problem.\n\n339\n00:17:20.660 --> 00:17:22.780\nIt could be some kind of\nmalicious modification, but\n\n340\n00:17:22.780 --> 00:17:27.200\nthe data isn't the same from the one\nthat I sent and it's discarded, right?\n\n341\n00:17:27.200 --> 00:17:31.830\nWell think about that process and\nlet's remove Dan and I and the file.\n\n342\n00:17:31.830 --> 00:17:35.590\nAnd we'll replace myself with the person\nthat's doing the investigation,\n\n343\n00:17:35.590 --> 00:17:38.310\nand Dan is the defense attorney or\n\n344\n00:17:38.310 --> 00:17:40.510\nprosecuting attorney I guess\nis how you would say that.\n\n345\n00:17:40.510 --> 00:17:44.380\nAnd I wanna make sure that\nthe information that I send into court\n\n346\n00:17:45.380 --> 00:17:49.870\nis exactly the same state when we\ntook it into possession, right?\n\n347\n00:17:49.870 --> 00:17:51.960\nWe acquired it, if you will.\n\n348\n00:17:51.960 --> 00:17:55.810\nSo, again, we do something like\ncapturing a complete system image,\n\n349\n00:17:55.810 --> 00:17:58.320\nthe bit by bit copy and\nthen we run a hash value over it.\n\n350\n00:17:58.320 --> 00:17:59.622\nWe take that fixed link,\n\n351\n00:17:59.622 --> 00:18:03.476\nthen we associate it with that data\nwhen it's presented in a court of law.\n\n352\n00:18:03.476 --> 00:18:07.044\nOr it could be as you're moving\nthrough your chain of custody and\n\n353\n00:18:07.044 --> 00:18:11.220\ndocumenting that information that it\nhasn't been modified in the least.\n\n354\n00:18:12.470 --> 00:18:16.250\nNext thing are screenshots, and\nscreenshots are important and really,\n\n355\n00:18:16.250 --> 00:18:22.050\nwhen it comes down to it, if somebody is\nusing or accessing some kind of system.\n\n356\n00:18:22.050 --> 00:18:25.660\nThey should be taking things like\nscreenshots, documenting, right?\n\n357\n00:18:25.660 --> 00:18:28.260\nThis is about documentation, and\ndocumenting what you're doing on that\n\n358\n00:18:28.260 --> 00:18:31.200\nsystem, in order to\nretrieve the information.\n\n359\n00:18:31.200 --> 00:18:33.810\nAnd a lot of times,\nthat can protect you, more so\n\n360\n00:18:33.810 --> 00:18:36.130\nthan it is about protecting\nthe information itself.\n\n361\n00:18:36.130 --> 00:18:39.330\nIs that it's protecting you as\nyou follow through this process.\n\n362\n00:18:39.330 --> 00:18:42.240\nThe last one here is witness interviews.\n\n363\n00:18:42.240 --> 00:18:45.360\nWhen we talk about witness interviews,\nwitness interviews are important because\n\n364\n00:18:45.360 --> 00:18:48.950\nyou can gather information about time\nframes, about things that have happened.\n\n365\n00:18:48.950 --> 00:18:53.603\nIf it happens to be maybe a disgruntled\nemployee, a malicious insider, well,\n\n366\n00:18:53.603 --> 00:18:54.581\nwe know Johnny.\n\n367\n00:18:54.581 --> 00:18:56.605\nJohnny seemed like a quiet guy, but\n\n368\n00:18:56.605 --> 00:19:00.260\nwe noticed that he had a problem\nwith such and such in marketing.\n\n369\n00:19:01.316 --> 00:19:02.052\nReally?\n\n370\n00:19:02.052 --> 00:19:04.960\nOkay, well, maybe we need to\nmark that information down.\n\n371\n00:19:04.960 --> 00:19:08.470\nMaybe it leads to something, maybe it does\nwhat a lot of detective work I hear does,\n\n372\n00:19:08.470 --> 00:19:09.670\nleads to a dead end.\n\n373\n00:19:09.670 --> 00:19:12.820\nBut at least you have witness testimony.\n\n374\n00:19:12.820 --> 00:19:17.850\nAnd even more so, witness testimony\nis applicable in a court setting.\n\n375\n00:19:17.850 --> 00:19:19.460\nLet's call in the witnesses, right?\n\n376\n00:19:19.460 --> 00:19:22.540\nAnd you can use that testimony\nto help whatever the case is.\n\n377\n00:19:22.540 --> 00:19:25.770\nAnd like Dan says, it kinda sounds\nlike you have to have a law degree,\n\n378\n00:19:25.770 --> 00:19:26.610\nbut not really.\n\n379\n00:19:26.610 --> 00:19:28.840\nJust some of those basic concepts,\nbut I don't know,\n\n380\n00:19:28.840 --> 00:19:31.710\nas we go here it sounds like it's\ngonna be an episode of Matlock.\n\n381\n00:19:31.710 --> 00:19:32.470\n&gt;&gt; Yeah, no doubt.\n\n382\n00:19:32.470 --> 00:19:36.900\nWhat's interesting about witness testimony\nis the person that the actual report\n\n383\n00:19:36.900 --> 00:19:40.188\nof the crime might be the person\nthat actually did the crime.\n\n384\n00:19:40.188 --> 00:19:44.758\nSo it's good to start interviewing, look\nfor those inconsistencies in their story,\n\n385\n00:19:44.758 --> 00:19:48.080\nin the timeframes as you look\nthrough the other evidences.\n\n386\n00:19:48.080 --> 00:19:51.880\nMake sure everything lines up cuz if it\ndoesn't, it should send off red flags and\n\n387\n00:19:51.880 --> 00:19:56.510\ngo, hm, I'm thinking there's\na little problem here.\n\n388\n00:19:56.510 --> 00:19:59.193\nAnd now you have those evidences\nthat you can present, and\n\n389\n00:19:59.193 --> 00:20:02.833\nin a court someone will go, yes,\nobviously, you have made that connection.\n\n390\n00:20:02.833 --> 00:20:04.260\nI see that logical leap.\n\n391\n00:20:04.260 --> 00:20:06.400\nAnd there you go,\nyou've found your culprit.\n\n392\n00:20:06.400 --> 00:20:08.159\nWes, where do we move on from here?\n\n393\n00:20:08.159 --> 00:20:12.013\n&gt;&gt; Next one is one that we've also kinda\ntalked about through the whole entire\n\n394\n00:20:12.013 --> 00:20:16.620\nseries, or at least through this episode,\nthat's preservation of your information.\n\n395\n00:20:16.620 --> 00:20:18.488\nAnd this is kind of a rehashing.\n\n396\n00:20:18.488 --> 00:20:21.540\n[CROSSTALK] Rehashing,\nof what we've already talked about,\n\n397\n00:20:21.540 --> 00:20:25.297\nthis just ensures that the data that's\ntaken into custody isn't spoiled,\n\n398\n00:20:25.297 --> 00:20:28.011\nmanipulated, damaged or\nmisrepresented in any way.\n\n399\n00:20:28.011 --> 00:20:32.223\nThat it's the same information\nthat we took into our possession\n\n400\n00:20:32.223 --> 00:20:36.130\nversus the same exact data that\nwe present in a court of law.\n\n401\n00:20:36.130 --> 00:20:37.600\nAnd we do this many different ways, and\n\n402\n00:20:37.600 --> 00:20:40.700\none of the biggest ways is\nrunning things like hash values,\n\n403\n00:20:40.700 --> 00:20:43.690\nensuring that you thoroughly document\nwhere the information is stored.\n\n404\n00:20:43.690 --> 00:20:48.232\nMaking sure that it's stored in a secure\nlocation so that unauthorized people,\n\n405\n00:20:48.232 --> 00:20:51.704\ncan't gain access to it and\nbasically ruin the evidence, and\n\n406\n00:20:51.704 --> 00:20:53.664\nit's no longer called evidence.\n\n407\n00:20:53.664 --> 00:20:58.310\n&gt;&gt; And there's a way that they commonly\nuse to preserve evidence is we'll make\n\n408\n00:20:58.310 --> 00:20:59.712\na one-on-one copy.\n\n409\n00:20:59.712 --> 00:21:03.370\nWe talked about those right blockers and\nmaking those digital copies\n\n410\n00:21:03.370 --> 00:21:07.890\nof using bit by bit copying procedures and\nmechanisms.\n\n411\n00:21:07.890 --> 00:21:11.290\nWe do this, so\nwe keep the original evidence over here.\n\n412\n00:21:11.290 --> 00:21:14.656\nAnd we've ran a hash value on it,\nwe know what it should be.\n\n413\n00:21:14.656 --> 00:21:18.227\nNow, when I make that copy,\nI can run that hash value, it's the same.\n\n414\n00:21:18.227 --> 00:21:20.940\nGood, that means those\nevidences are identical.\n\n415\n00:21:20.940 --> 00:21:23.267\nI can do anything I want to my copy.\n\n416\n00:21:23.267 --> 00:21:27.382\nI'm going to leave the original alone,\nif I ever need to, if I destroyed my copy,\n\n417\n00:21:27.382 --> 00:21:29.545\njust got all jacked up,\nI went crazy on it.\n\n418\n00:21:29.545 --> 00:21:32.272\nI can make another copy,\nrun a hash value on it, and\n\n419\n00:21:32.272 --> 00:21:34.310\nthen continue to work from there.\n\n420\n00:21:34.310 --> 00:21:38.699\nWe hardly ever should I say work on\nthe original evidence until it's\n\n421\n00:21:38.699 --> 00:21:40.551\npresented in a court of law.\n\n422\n00:21:40.551 --> 00:21:45.500\nCuz we want to maintain that integrity cuz\nif we don't that defense attorney will\n\n423\n00:21:45.500 --> 00:21:49.526\nsay well, you can't verify\nthe integrity of that disk, right?\n\n424\n00:21:49.526 --> 00:21:51.270\nYou've done something to it.\n\n425\n00:21:51.270 --> 00:21:55.480\nAnd therefore, so always make sure you\ndo forensically sound procedures on it,\n\n426\n00:21:55.480 --> 00:21:56.800\nand then we leave it alone.\n\n427\n00:21:56.800 --> 00:21:58.180\nWe use our copies instead.\n\n428\n00:21:58.180 --> 00:22:01.484\n&gt;&gt; Most definitely, so the next thing that\nthey call out is, they call out recovery.\n\n429\n00:22:01.484 --> 00:22:05.088\nAnd this really lends itself back to\nwhat we opened this episode with,\n\n430\n00:22:05.088 --> 00:22:06.445\nthe order of volatility.\n\n431\n00:22:06.445 --> 00:22:09.810\nBut I do wanna kinda mention some\nthings to keep in mind with recovery.\n\n432\n00:22:09.810 --> 00:22:13.510\nSo just so you're aware of this\nright we say, basic data recovery.\n\n433\n00:22:13.510 --> 00:22:17.399\nWe've kind of already talked about that,\nbut I want you to keep in mind that\n\n434\n00:22:17.399 --> 00:22:21.823\ndata doesn't always reside in common\nlocations or obvious locations,right?\n\n435\n00:22:21.823 --> 00:22:23.740\nWell, it's on the desktop\nof that computer.\n\n436\n00:22:23.740 --> 00:22:25.060\nWell, not always, right?\n\n437\n00:22:25.060 --> 00:22:28.610\nI want you to think of things like\nhidden files, right, by default.\n\n438\n00:22:28.610 --> 00:22:30.078\nLike for instance in Windows,\n\n439\n00:22:30.078 --> 00:22:33.981\nthere's a lot of files that are hidden by\ndefault and the user never sees, right?\n\n440\n00:22:33.981 --> 00:22:38.601\nOne of the places I can think of is where\nthe temporary files are stored inside of\n\n441\n00:22:38.601 --> 00:22:40.282\na user's profile, right?\n\n442\n00:22:40.282 --> 00:22:43.032\nThings like Internet Explorer,\nif they're using Internet Explorer,\n\n443\n00:22:43.032 --> 00:22:44.300\nit's stored in a temp location.\n\n444\n00:22:44.300 --> 00:22:47.870\nAnd again,\nit's not an obvious location for data.\n\n445\n00:22:47.870 --> 00:22:51.910\nNow it's obvious to the forensics\nanalysis, but again it might not be\n\n446\n00:22:51.910 --> 00:22:55.286\nobvious to just the average person\nif they're not aware to look there.\n\n447\n00:22:55.286 --> 00:22:58.170\nOther places too,\nthings like paging files we talked about,\n\n448\n00:22:58.170 --> 00:23:03.040\nthat is an ever-changing document file,\nsystem file, within the machine.\n\n449\n00:23:03.040 --> 00:23:05.070\nSystem files themselves\nare typically hidden and\n\n450\n00:23:05.070 --> 00:23:07.280\nprotected from average users, right?\n\n451\n00:23:07.280 --> 00:23:09.545\nIt's the operating system's\nway of protecting itself.\n\n452\n00:23:09.545 --> 00:23:12.730\nIt's just no different in Windows\nthan it is in your Linux,\n\n453\n00:23:12.730 --> 00:23:14.330\nUnix based systems, right?\n\n454\n00:23:14.330 --> 00:23:19.090\nIt's the reason you have to do sudo so\nthat you have to elevate your privileges\n\n455\n00:23:19.090 --> 00:23:21.950\nin order to even get access to those\ndifferent locations and settings.\n\n456\n00:23:21.950 --> 00:23:27.540\nSo, again, some of these don't just\npop out and seem obvious, right?\n\n457\n00:23:27.540 --> 00:23:31.801\nDeleted files, right, formatted,\nhigh level formatting.\n\n458\n00:23:31.801 --> 00:23:34.516\nNow, it could be recovered, but\nagain, it's not just obvious and\n\n459\n00:23:34.516 --> 00:23:37.450\nit's not jumping off the page\nat you that it's there.\n\n460\n00:23:37.450 --> 00:23:40.930\nConfiguration files could do things\nlike having meta data in them that\n\n461\n00:23:40.930 --> 00:23:45.480\ntell you the last time an application or\na piece of document was accessed.\n\n462\n00:23:45.480 --> 00:23:46.429\nThis can be something.\n\n463\n00:23:46.429 --> 00:23:50.230\nHere's something that's kinda\ninteresting too, solid state drives.\n\n464\n00:23:50.230 --> 00:23:54.159\nWell, solid state drives implement\nif they're implemented correctly,\n\n465\n00:23:54.159 --> 00:23:56.604\nimplement something\nknown as a trim command.\n\n466\n00:23:56.604 --> 00:24:01.321\nAnd a trim command really is to kinda\npreserve The health of the solid\n\n467\n00:24:01.321 --> 00:24:02.330\nstate drive.\n\n468\n00:24:02.330 --> 00:24:07.177\nAnd I just really want you to understand\nis what SSDs do is the moment you clear\n\n469\n00:24:07.177 --> 00:24:11.798\na bit of data, unlike a mechanical\ndrive that just removes the pointer in\n\n470\n00:24:11.798 --> 00:24:13.313\nthe master file table so\n\n471\n00:24:13.313 --> 00:24:17.605\nthe operating system can't see it and\nit's still there, right?\n\n472\n00:24:17.605 --> 00:24:20.465\nThat's why we say that we have\nto use overwriting technologies.\n\n473\n00:24:20.465 --> 00:24:25.535\nThe TRIM command tries to optimize the\nsolid state drives by zeroing out a cell\n\n474\n00:24:25.535 --> 00:24:27.810\nof information the moment it's deleted.\n\n475\n00:24:27.810 --> 00:24:29.880\nRight, because you can get what's\nknown as garbage collection,\n\n476\n00:24:29.880 --> 00:24:33.580\nif they didn't implement the TRIM\ncommand on solid state drives.\n\n477\n00:24:33.580 --> 00:24:36.700\nWhich means when I delete the information,\nit's still there.\n\n478\n00:24:36.700 --> 00:24:40.960\nBut that is a very bad performance\nhindrance in solid state drives, right?\n\n479\n00:24:40.960 --> 00:24:45.900\nYou have all these cells that basically\ncontain information that you now have\n\n480\n00:24:45.900 --> 00:24:50.670\nto pull out of the cell, erase it,\nand then write the good data, and\n\n481\n00:24:50.670 --> 00:24:52.850\nthen write the data that you're\ntrying to save to the drive, right?\n\n482\n00:24:52.850 --> 00:24:53.628\nThat's way too much.\n\n483\n00:24:53.628 --> 00:24:56.622\nSo they implemented TRIM that just said,\nthe moment you delete something,\n\n484\n00:24:56.622 --> 00:24:59.725\ndon't just delete the pointer\nfrom the operating system.\n\n485\n00:24:59.725 --> 00:25:02.455\nScrub it, get it out of there,\nzero it out, right?\n\n486\n00:25:02.455 --> 00:25:03.515\nWell that's a problem, right?\n\n487\n00:25:03.515 --> 00:25:06.945\nBecause that means if you delete a file,\nthen you could potentially be deleting it\n\n488\n00:25:06.945 --> 00:25:12.850\noff the drive and that could lend itself\nto, you might have to use better or\n\n489\n00:25:12.850 --> 00:25:15.930\nmore state-of-the-art type of\ntechnologies to recover the information.\n\n490\n00:25:17.080 --> 00:25:18.630\nAll right, a couple other things,\n\n491\n00:25:18.630 --> 00:25:21.190\nI know we're running a little\nbit close on time here.\n\n492\n00:25:21.190 --> 00:25:24.840\nThey call out strategic intelligence and\ncounterintelligence gathering.\n\n493\n00:25:24.840 --> 00:25:29.770\nI want you to think about strategic\nintelligence as more of an umbrella term.\n\n494\n00:25:29.770 --> 00:25:34.910\nThink about all the different methods and\ntechniques and activities that we use\n\n495\n00:25:34.910 --> 00:25:40.300\nthat can influence senior decision makers\non how they implement and formulate their\n\n496\n00:25:40.300 --> 00:25:45.370\npolicies, if you will, and procedures,\nright, to secure our environments, right.\n\n497\n00:25:45.370 --> 00:25:49.452\nIf you have this information,\nyou could be more aware on what we might\n\n498\n00:25:49.452 --> 00:25:52.420\nhave to peek and tweak and\nwe might have to change.\n\n499\n00:25:52.420 --> 00:25:55.920\nGive you a classic example,\nmaybe you've seen this.\n\n500\n00:25:55.920 --> 00:26:01.930\nVerizon every year, they're one that is\nreally big on releasing information so\n\n501\n00:26:01.930 --> 00:26:04.830\nyou can see all the different\ntypes of attacks and\n\n502\n00:26:04.830 --> 00:26:07.310\nbreaches that they've\nrecorded that have happened.\n\n503\n00:26:07.310 --> 00:26:09.567\nAnd they've got what's known as the DBIR,\n\n504\n00:26:09.567 --> 00:26:12.129\nthat's the Data Breach\nInvestigative Report and\n\n505\n00:26:12.129 --> 00:26:14.570\nthen they basically\npublish that to the world.\n\n506\n00:26:14.570 --> 00:26:17.030\nIn fact, I've got it right here.\n\n507\n00:26:17.030 --> 00:26:20.487\nIf you ever need to get to it,\njust go to Verizon and look for\n\n508\n00:26:20.487 --> 00:26:24.313\nthe Data Breach Digest, and\nthey say perspective is a reality.\n\n509\n00:26:24.313 --> 00:26:29.470\nBut once you download it, you can see\nthat it's a 100 page document, right?\n\n510\n00:26:29.470 --> 00:26:32.970\nAnd it's really, really good,\nit gives you a lot of review\n\n511\n00:26:32.970 --> 00:26:36.420\non the different things that they\nsee within their networks, right?\n\n512\n00:26:36.420 --> 00:26:39.620\nHuman element, conduit devices,\nconfiguration exploitation.\n\n513\n00:26:39.620 --> 00:26:40.180\nIn fact Dan and\n\n514\n00:26:40.180 --> 00:26:44.020\nI, we were just talking about another\nlist I'm gonna show you is OWASP.\n\n515\n00:26:44.020 --> 00:26:47.840\nAnd as we went through the list, Dan made\na good point, says hey, it looks like,\n\n516\n00:26:47.840 --> 00:26:51.040\nokay some of those, yeah,\nthese take very intelligent hackers.\n\n517\n00:26:51.040 --> 00:26:55.360\nBut a lot of them are just things like\nsecurity misconfigurations, right?\n\n518\n00:26:55.360 --> 00:26:57.990\nAnd you can see things like that,\nconfiguration exploitations,\n\n519\n00:26:57.990 --> 00:27:01.220\nmaybe they're not doing website\ndevelopment, or defacement.\n\n520\n00:27:01.220 --> 00:27:03.040\nMaybe they're not doing\ninput check validation.\n\n521\n00:27:03.040 --> 00:27:07.790\nSo we can gain, in strategic intelligence\nwe can gather all this information.\n\n522\n00:27:07.790 --> 00:27:11.550\nWe can analyze it and that will\ninfluence how we make our policies and\n\n523\n00:27:11.550 --> 00:27:14.260\nprocedures, kinda like\na lessons learned type thing.\n\n524\n00:27:14.260 --> 00:27:19.070\nNow counterintelligence gathering\nreally is just gathering information.\n\n525\n00:27:19.070 --> 00:27:22.134\nCounterintel, if you will,\nis just gathering information and\n\n526\n00:27:22.134 --> 00:27:25.555\nactivities used to stop outside\nintelligence gathering [LAUGH] right?\n\n527\n00:27:25.555 --> 00:27:28.886\nAnd outside maybe sabotage\nthat's happening to you on maybe\n\n528\n00:27:28.886 --> 00:27:32.025\nan organization's behalf,\nright, under the table.\n\n529\n00:27:32.025 --> 00:27:35.970\nSo counterintelligence\ngathering is also important.\n\n530\n00:27:35.970 --> 00:27:38.000\nThe last one that I always\nthink is interesting,\n\n531\n00:27:38.000 --> 00:27:42.710\nthat they put on the forensics basic\nprocess, is called tracking man hours.\n\n532\n00:27:42.710 --> 00:27:46.760\nAnd tracking man hours is really about\nputting a monetary value to the time that\n\n533\n00:27:46.760 --> 00:27:49.720\nyou invest inside of\na forensics investigation.\n\n534\n00:27:49.720 --> 00:27:54.395\nAnd they do call it out and say that it\nis important as part of that process.\n\n535\n00:27:54.395 --> 00:27:58.800\nIs just keeping that information tracking\nat exactly what it's taking to get the job\n\n536\n00:27:58.800 --> 00:28:03.940\ndone so that you do have some kinda\nquantification of what it's gonna cost.\n\n537\n00:28:03.940 --> 00:28:06.304\nWhat is this costing to\nrecover this information?\n\n538\n00:28:06.304 --> 00:28:10.390\nAnd if it's costing a little bit too much,\ndo we have to make cutbacks in some ways?\n\n539\n00:28:10.390 --> 00:28:11.870\nDid we make some bad decisions?\n\n540\n00:28:11.870 --> 00:28:14.830\nDid we use a technology that\ndidn't work and cost too much?\n\n541\n00:28:14.830 --> 00:28:16.310\nBut again, tracking those man hours and\n\n542\n00:28:16.310 --> 00:28:19.860\nexpenses is gonna be important for\nyour overall investigation.\n\n543\n00:28:19.860 --> 00:28:23.390\n&gt;&gt; All right, Wes, there's computer\nforensics wrapped up in a ball.\n\n544\n00:28:23.390 --> 00:28:28.030\nDid a fantastic job of explaining\nthe concepts and practices therein for us.\n\n545\n00:28:28.030 --> 00:28:30.860\nBut, like you said,\nwe kinda ran out of time on this episode.\n\n546\n00:28:30.860 --> 00:28:34.150\nSo we do thank you for joining us,\nhope you got a lot out of this episode.\n\n547\n00:28:34.150 --> 00:28:36.970\nWe'll definitely have more Security+\nto come, so check that out.\n\n548\n00:28:36.970 --> 00:28:40.250\nBut as for today, signing off for ITProTV,\nI've been your host, Daniel Lowrie.\n\n549\n00:28:40.250 --> 00:28:40.970\n&gt;&gt; And I'm Wes Bryan.\n\n550\n00:28:40.970 --> 00:28:41.703\n&gt;&gt; And we'll see you next time.\n\n551\n00:28:41.703 --> 00:28:49.395\n[MUSIC]\n\n552\n00:28:49.395 --> 00:28:51.440\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216665931"
        },
        {
          "description": "Wes and Zach go over options in recovery sites, protocol or order for restoration, plus backup concepts.",
          "length": "1709",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-6-1-disaster_recovery_and_business_continuity-050917.00_28_15_15.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-6-1-disaster_recovery_and_business_continuity-050917.00_28_15_15.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-6-1-disaster_recovery_and_business_continuity-050917.00_28_15_15.Still001-sm.jpg",
          "title": "Disaster Recovery and Business Continuity",
          "transcript": "WEBVTT\n\n1\n00:00:00.002 --> 00:00:06.509\nWelcome to ITPro.Tv, I'm your host-\n&gt;&gt; [CROSSTALK]\n\n2\n00:00:06.509 --> 00:00:08.300\n&gt;&gt; [MUSIC]\n\n3\n00:00:08.300 --> 00:00:12.036\n&gt;&gt; You're watching ITPro.Tv.\n\n4\n00:00:12.036 --> 00:00:16.201\n&gt;&gt; Hello, and thank you for making\nthe intelligent choice to watch ITPro.TV,\n\n5\n00:00:16.201 --> 00:00:18.390\nwhere we help you learn wherever you go.\n\n6\n00:00:18.390 --> 00:00:22.040\nI'm your host Zach Memos, as we'll\ncontinue on with CompTia Security+,\n\n7\n00:00:22.040 --> 00:00:25.870\nand right now we're looking\nat disaster recovery and\n\n8\n00:00:25.870 --> 00:00:30.547\nbusiness continuity with our IT\nprofessional and expert, Wes Bryan.\n\n9\n00:00:30.547 --> 00:00:31.730\n&gt;&gt; Hey, how you doing there Zac?\n\n10\n00:00:31.730 --> 00:00:35.482\nThat's right, these are two concepts\nthat we hope you never have to use.\n\n11\n00:00:35.482 --> 00:00:40.450\nDisaster recovery, this is saying that we\ndon't want any disasters happening to you.\n\n12\n00:00:40.450 --> 00:00:43.329\nAnd business continuity should\nalways be happening, and\n\n13\n00:00:43.329 --> 00:00:47.746\nwe don't want a disaster to happen, so you\nimplement business continuity protection.\n\n14\n00:00:47.746 --> 00:00:51.646\nBut it is important that you have\nplans in place ahead of time.\n\n15\n00:00:51.646 --> 00:00:53.374\nAnd that you understand\nsome of the concepts,\n\n16\n00:00:53.374 --> 00:00:55.380\nespecially when it comes\nto the Security Plus exams.\n\n17\n00:00:55.380 --> 00:00:57.000\nSo that's what we're\ngoing to be looking at.\n\n18\n00:00:57.000 --> 00:01:00.660\nSome of the things that we can do should\nwe be challenged with a disaster.\n\n19\n00:01:00.660 --> 00:01:03.850\nHow we can bring our systems back online,\nand we can make sure\n\n20\n00:01:03.850 --> 00:01:07.980\nthat we have business continuity and\nwe don't go past the point of no return.\n\n21\n00:01:07.980 --> 00:01:12.190\nWe don't have downtime so\nlong well that we can't recover from it.\n\n22\n00:01:12.190 --> 00:01:14.750\nThat's really what these\ntopics are going to be about.\n\n23\n00:01:15.900 --> 00:01:16.425\nYes.\n\n24\n00:01:16.425 --> 00:01:19.300\n&gt;&gt; Yeah, I wanted to ask just real quick,\nrecovery sites.\n\n25\n00:01:19.300 --> 00:01:23.320\nDo we have an option or are there options,\nrecovery sites that we can go to,\n\n26\n00:01:23.320 --> 00:01:24.350\ndifferent types?\n\n27\n00:01:24.350 --> 00:01:27.900\n&gt;&gt; There are, and\nit really depends on a couple of factors.\n\n28\n00:01:27.900 --> 00:01:34.030\nThose factors being cost, and how fast\nyou have to have access to your data.\n\n29\n00:01:34.030 --> 00:01:38.580\nWhen we talk about any kind of fault\ntolerance, redundancy, having more than\n\n30\n00:01:38.580 --> 00:01:43.620\none system, back ups if you will,\nwe can make our systems highly available.\n\n31\n00:01:43.620 --> 00:01:44.250\nHow?\n\n32\n00:01:44.250 --> 00:01:48.870\nWell, we take a big wad of cash, and\nwe throw it right at the problem, right?\n\n33\n00:01:48.870 --> 00:01:53.770\nAnd that works for some companies, but it\ncertainly doesn't work for all companies.\n\n34\n00:01:53.770 --> 00:01:57.400\nSo, we do have to have some of\nthose considerations in place\n\n35\n00:01:57.400 --> 00:01:58.840\nwhen we look at different locations.\n\n36\n00:01:58.840 --> 00:02:00.040\nAnd that's really what this is about.\n\n37\n00:02:00.040 --> 00:02:02.380\nThis is about they call\nout recovery sites.\n\n38\n00:02:02.380 --> 00:02:06.580\nBut you can also hear them called other\nthings too like alternative locations,\n\n39\n00:02:06.580 --> 00:02:09.640\nalternative processing locations,\nlike for instance,\n\n40\n00:02:09.640 --> 00:02:13.710\nif you have a data center, a data\ncenter is processing your information.\n\n41\n00:02:13.710 --> 00:02:16.740\nIf the connections or\nthe access to that setter goes down,\n\n42\n00:02:16.740 --> 00:02:20.180\nthen we're gonna have to do some kind\nof fail over to some alternative,\n\n43\n00:02:20.180 --> 00:02:22.090\nor alternate processing location.\n\n44\n00:02:22.090 --> 00:02:23.440\nSo, this is also,\n\n45\n00:02:23.440 --> 00:02:27.810\nthe first concept we talk about\nhere are what are those site types?\n\n46\n00:02:27.810 --> 00:02:28.900\nWhat are those location types?\n\n47\n00:02:28.900 --> 00:02:31.559\nAnd I've got a little bit of\na diagram here, and again,\n\n48\n00:02:31.559 --> 00:02:33.380\nit's nothing too really fancy here.\n\n49\n00:02:33.380 --> 00:02:38.160\nIt's just the three sites that\nthey call out, all right?\n\n50\n00:02:38.160 --> 00:02:41.760\nHot site, a warm site and a cold site.\n\n51\n00:02:41.760 --> 00:02:45.880\nNow, please keep in mind this\nhas nothing to do temperature.\n\n52\n00:02:45.880 --> 00:02:46.610\nSo, you might think,\n\n53\n00:02:46.610 --> 00:02:50.470\nthe only thing that differs here is\nthe thermal value of the site, right?\n\n54\n00:02:50.470 --> 00:02:52.280\nAnd that’s not really the case here, okay?\n\n55\n00:02:52.280 --> 00:02:55.940\nSo, let’s go ahead and let’s take\nsome time here in this episode and\n\n56\n00:02:55.940 --> 00:02:58.480\nlet's talk about each one\nof these individually.\n\n57\n00:02:58.480 --> 00:03:01.630\nWe're gonna go ahead and\nwe'll start off with the hot site.\n\n58\n00:03:01.630 --> 00:03:04.950\nAll right, so what is it about the hot\nsite that is important, all right?\n\n59\n00:03:04.950 --> 00:03:06.530\nWell, the hot site you have to understand,\n\n60\n00:03:06.530 --> 00:03:10.240\nthis is where we can do fully\nfunctional parallel testing.\n\n61\n00:03:10.240 --> 00:03:11.650\nAnd what I mean by that is,\n\n62\n00:03:11.650 --> 00:03:17.150\nyour hot site is a completely functional\nreplica of what the primary site is.\n\n63\n00:03:17.150 --> 00:03:20.870\nWhen we talk about these location sites, I\nwant you to think of these location sites\n\n64\n00:03:20.870 --> 00:03:23.420\nas alternative to whatever\nyour primary location is.\n\n65\n00:03:23.420 --> 00:03:25.190\nI have a main office.\n\n66\n00:03:25.190 --> 00:03:28.040\nWell, we need to make sure that if I\ndon't have access to the main office, or\n\n67\n00:03:28.040 --> 00:03:32.360\nwhatever its business functionality is,\nthat we can fail over to another location.\n\n68\n00:03:32.360 --> 00:03:35.570\nSo it's really about primary and\nsecondary, and\n\n69\n00:03:35.570 --> 00:03:38.320\nthe secondary site types or\nwhat we're looking at.\n\n70\n00:03:38.320 --> 00:03:40.510\nHot site is a fully functional replica.\n\n71\n00:03:40.510 --> 00:03:41.750\nIn fact, so\n\n72\n00:03:41.750 --> 00:03:45.620\nfunctional that it can do simultaneous\nprocessing of your information.\n\n73\n00:03:45.620 --> 00:03:46.770\nYou might even offload, right?\n\n74\n00:03:46.770 --> 00:03:50.120\nMaybe you have a business spike,\na resource spike and\n\n75\n00:03:50.120 --> 00:03:51.760\nyou're needing it's computational power.\n\n76\n00:03:51.760 --> 00:03:56.040\nWell, because your hot site is\na complete replica of the primary site,\n\n77\n00:03:56.040 --> 00:03:59.450\nyou could even do things like data\nsynchronization between the two.\n\n78\n00:03:59.450 --> 00:04:00.750\nAll right, you have things like for\n\n79\n00:04:00.750 --> 00:04:02.780\ninstance the physical\nstructure is in place.\n\n80\n00:04:02.780 --> 00:04:05.670\nWe have our have accesses,\nwe have network connectivity, we probably,\n\n81\n00:04:05.670 --> 00:04:06.630\nand we've already got and\n\n82\n00:04:06.630 --> 00:04:11.090\nISP, we've got a contractual agreement,\nSLA if you will, in place.\n\n83\n00:04:11.090 --> 00:04:13.880\nSo that if the primary site goes offline,\n\n84\n00:04:13.880 --> 00:04:16.300\nwe have almost instantaneous fail over,\nall right?\n\n85\n00:04:16.300 --> 00:04:19.460\nSo, that's a little about\nwhat a hot side is, right?\n\n86\n00:04:19.460 --> 00:04:22.990\nIt's pre-loaded with things like your\noperating system, your applications,\n\n87\n00:04:22.990 --> 00:04:25.360\nyour hardware,\nyour server room, if you will.\n\n88\n00:04:26.580 --> 00:04:28.920\nHowever, here's where\nthe drawback comes in.\n\n89\n00:04:28.920 --> 00:04:30.290\nJust like we've been talking about Zach,\n\n90\n00:04:30.290 --> 00:04:35.240\nthroughout this episode everything in\nIT is give and take pros and cons.\n\n91\n00:04:35.240 --> 00:04:39.700\nSo the good thing is if I have a failure,\nand we fail over to the secondary site,\n\n92\n00:04:39.700 --> 00:04:43.330\nand it's the hot site,\nyou might not even notice any downtime,\n\n93\n00:04:43.330 --> 00:04:46.580\nyour end user experience,\nthey might notice zero,\n\n94\n00:04:46.580 --> 00:04:49.170\nor if anything it might be\njust a couple of seconds.\n\n95\n00:04:49.170 --> 00:04:54.130\nNow, a couple of seconds can mean maybe\nsome transaction loss in your database,\n\n96\n00:04:54.130 --> 00:04:55.560\nif you've got a transactional log, right.\n\n97\n00:04:55.560 --> 00:04:58.840\nSo I mean, that can have some kind\nof effect, but for the most part,\n\n98\n00:04:58.840 --> 00:05:01.530\nyour end user experience,\nthey're not even gonna notice it.\n\n99\n00:05:01.530 --> 00:05:02.805\nSo that's the benefit.\n\n100\n00:05:02.805 --> 00:05:03.795\nHere's the drawback, right?\n\n101\n00:05:03.795 --> 00:05:07.715\nAlways gotta calm in the mix somewhere,\nright?\n\n102\n00:05:07.715 --> 00:05:10.105\nAnd that's because it's very expensive.\n\n103\n00:05:10.105 --> 00:05:13.375\nI want you to think of your hot site\nas your maintaining two locations.\n\n104\n00:05:13.375 --> 00:05:17.182\nEven though it's called\nyour secondary Location.\n\n105\n00:05:17.182 --> 00:05:19.162\nYou could flip them around and\n\n106\n00:05:19.162 --> 00:05:22.272\nthe secondary could become\nthe primary at any second.\n\n107\n00:05:22.272 --> 00:05:24.692\nAll right, so you have to keep\nin mind that this is a very,\n\n108\n00:05:24.692 --> 00:05:26.722\nvery expensive method.\n\n109\n00:05:26.722 --> 00:05:31.870\nHowever if you're somebody like Amazon,\nwe talked about another episodes, I think\n\n110\n00:05:31.870 --> 00:05:37.531\nZach you were with me when talked about a\nsingle minute costs Amazon, about $67,000.\n\n111\n00:05:37.531 --> 00:05:40.996\n15 minutes of down time costs just\nunder a million dollars, all right?\n\n112\n00:05:40.996 --> 00:05:44.460\nSo when we talk about one million dollars.\n\n113\n00:05:44.460 --> 00:05:48.350\nWell, even though it's expensive\nit might be very adequate.\n\n114\n00:05:48.350 --> 00:05:52.980\nThe expense might be justified if\nit is something as big as Amazon.\n\n115\n00:05:52.980 --> 00:05:57.220\nHowever, if you're a small to medium\ncompany, maybe you can't afford, you know,\n\n116\n00:05:57.220 --> 00:05:59.900\nthe expense that a hot site will give you.\n\n117\n00:05:59.900 --> 00:06:01.650\nSo that's where we go to the warm site,\nright?\n\n118\n00:06:01.650 --> 00:06:04.760\nThe warm site is kind of in between, and\nagain we think of thermal temperature\n\n119\n00:06:04.760 --> 00:06:08.670\nhere, but where it's kind of in between\na cold site and a warm site, or\n\n120\n00:06:08.670 --> 00:06:13.190\na hot site as far as what is\nconfigured within the site, okay?\n\n121\n00:06:13.190 --> 00:06:16.910\nSo, for instance,\nif the hot site is fully functional,\n\n122\n00:06:16.910 --> 00:06:19.740\nthe warm site has your basic\ninfrastructure, right?\n\n123\n00:06:19.740 --> 00:06:24.111\nIt probably has your HVAC system ready to\ngo, probably has a network connection.\n\n124\n00:06:24.111 --> 00:06:26.864\nIt could even have things like just\na couple of systems that are online\n\n125\n00:06:26.864 --> 00:06:27.391\nready to go.\n\n126\n00:06:27.391 --> 00:06:29.843\nBut you might not have operating\nsystems pre-installed or\n\n127\n00:06:29.843 --> 00:06:31.903\nif you have an operating\nsystem pre-installed,\n\n128\n00:06:31.903 --> 00:06:34.760\nmaybe you don't have the applications\nthat are installed, right?\n\n129\n00:06:34.760 --> 00:06:37.860\nSo the warm sites could even contain\nthings like a backup of your\n\n130\n00:06:37.860 --> 00:06:39.070\norganizational data, right?\n\n131\n00:06:39.070 --> 00:06:41.140\nWe talked about offsite backups.\n\n132\n00:06:41.140 --> 00:06:42.790\nWhy do we want offsite backups?\n\n133\n00:06:42.790 --> 00:06:45.980\nWell, I want you to think of\na condition or a state where your\n\n134\n00:06:45.980 --> 00:06:49.250\nprimary site gets completely eradicated,\ncompletely eliminated.\n\n135\n00:06:49.250 --> 00:06:53.610\nNow that's the worst case scenario,\nbut if you don't have any of your data\n\n136\n00:06:53.610 --> 00:06:57.210\noffsite that means your data goes with it\nand recovery is not an option, all right?\n\n137\n00:06:57.210 --> 00:07:00.340\nSo we might have a warm site that's\ncontaining a small amount of\n\n138\n00:07:00.340 --> 00:07:02.160\nyour organizational data.\n\n139\n00:07:02.160 --> 00:07:07.150\nAll right, now, here's where we\nhave to consider things, all right?\n\n140\n00:07:07.150 --> 00:07:11.429\nIt's less expensive than\na full blown hot site, but\n\n141\n00:07:11.429 --> 00:07:15.914\nit also takes a little bit\nmore to get this site online.\n\n142\n00:07:15.914 --> 00:07:21.386\nYou're going to notice a downtime,\nwhen you move from primary to secondary.\n\n143\n00:07:21.386 --> 00:07:22.621\nIt could be measured,\n\n144\n00:07:22.621 --> 00:07:26.976\na warm site bringing it back online can\nbe measured in just a few hours, relative\n\n145\n00:07:26.976 --> 00:07:32.090\nto just the few seconds like the primary\nsite going to a hot site as the secondary.\n\n146\n00:07:32.090 --> 00:07:34.240\nOr it could be measured in a few days.\n\n147\n00:07:34.240 --> 00:07:35.690\nIs that acceptable to you?\n\n148\n00:07:35.690 --> 00:07:40.330\nWell, I'm not sure, it depends on\nwhat your company's needs are, but\n\n149\n00:07:40.330 --> 00:07:42.390\nthe expense is a lot less.\n\n150\n00:07:42.390 --> 00:07:46.443\nThe last one is the cold site, and\nthe cold site you have to be careful with.\n\n151\n00:07:46.443 --> 00:07:51.339\nCold sites a lot of times are used for\na, you never plan for it, or\n\n152\n00:07:51.339 --> 00:07:55.168\nyou do plan for it, but\nyou hope it never happens.\n\n153\n00:07:55.168 --> 00:07:59.569\nA long Period of outage or\ndowntime on your primary site.\n\n154\n00:07:59.569 --> 00:08:01.090\nAlright.\nAgain, they are used for\n\n155\n00:08:01.090 --> 00:08:02.420\nlong-term outages, right.\n\n156\n00:08:02.420 --> 00:08:05.000\nIt might have been,\nmaybe has basic infrastructure.\n\n157\n00:08:05.000 --> 00:08:07.890\nThe Havex system,\nit might have network connectivity,\n\n158\n00:08:07.890 --> 00:08:09.780\nmost likely it doesn't, right.\n\n159\n00:08:09.780 --> 00:08:12.140\nYou might not even be connected\nto an internet service provider.\n\n160\n00:08:12.140 --> 00:08:17.450\nIn fact, you might not have any single\nequipment in that code site at all.\n\n161\n00:08:17.450 --> 00:08:21.350\nAll right so when we talk about\nbringing the time if you will, right?\n\n162\n00:08:21.350 --> 00:08:25.300\nCould be measured in days but\nmost likely it's gonna be weeks.\n\n163\n00:08:25.300 --> 00:08:26.750\nOkay, so think about that.\n\n164\n00:08:26.750 --> 00:08:31.820\nThe expenses,\nthe lowest cost out of all three.\n\n165\n00:08:31.820 --> 00:08:34.210\nIt could be nothing more than\nan alternative location and\n\n166\n00:08:34.210 --> 00:08:36.420\nyou have a contractual\nagreement on that says,\n\n167\n00:08:36.420 --> 00:08:39.000\nwhen we need access to this building,\nwe have it.\n\n168\n00:08:39.000 --> 00:08:42.490\nBut we don't need it yet, just means\nwhen we need it, we have access to it.\n\n169\n00:08:42.490 --> 00:08:45.290\nAgain, you can see that the cost,\nthe maintenance is really, really low.\n\n170\n00:08:45.290 --> 00:08:50.100\nBut the restoration time, that's gonna be,\nwe're very tedious getting it back online.\n\n171\n00:08:50.100 --> 00:08:53.680\nNow, there's one that isn't in the\nobjectives, and I don't want you to worry\n\n172\n00:08:53.680 --> 00:08:58.980\nabout it for the exam, but it is a good\nthing for real world scenarios, all right?\n\n173\n00:08:58.980 --> 00:09:00.510\nBecause you could have a hybrid model.\n\n174\n00:09:00.510 --> 00:09:04.900\nThe hybrid model is not, I threw this in\nhere as an optional thing, right and why?\n\n175\n00:09:04.900 --> 00:09:08.610\nWell, some companies can't justify\nthe cost of a hot site, but\n\n176\n00:09:08.610 --> 00:09:13.180\nat the same time they can not afford\ntheir critical systems to go offline and\n\n177\n00:09:13.180 --> 00:09:15.230\nnot be able to instantly fail over.\n\n178\n00:09:15.230 --> 00:09:18.170\nSo what they might do is something like\nthis, they might do something where they\n\n179\n00:09:18.170 --> 00:09:21.426\nhave a few critical systems inside\nthe warm site, just a handful.\n\n180\n00:09:21.426 --> 00:09:23.356\nOr whatever, it could be one.\n\n181\n00:09:23.356 --> 00:09:26.502\nA few critical systems that are\nprovisioned with their operating systems\n\n182\n00:09:26.502 --> 00:09:29.152\nand the applications ready to\ngo at a moments notice, right.\n\n183\n00:09:29.152 --> 00:09:31.900\nWe flip over to the warm site?\n\n184\n00:09:31.900 --> 00:09:36.220\nSure, we don't have everything in place,\nbut we got the few critical systems that\n\n185\n00:09:36.220 --> 00:09:39.870\nare again the criticality to our business\ncontinuity and functionality is essential.\n\n186\n00:09:39.870 --> 00:09:41.860\nSo you get the hybrid right?\n\n187\n00:09:41.860 --> 00:09:43.540\nWe still get some of the benefits and\n\n188\n00:09:43.540 --> 00:09:47.600\nthe characteristics of a hot site,\nwhile paying the cost of a warm site.\n\n189\n00:09:47.600 --> 00:09:50.140\nSo keep in mind that you could have\na hybrid model, something like that,\n\n190\n00:09:50.140 --> 00:09:54.820\nwhere you're trying to take and leverage\nthe best of both worlds without the cost,\n\n191\n00:09:54.820 --> 00:09:55.385\nif you will.\n\n192\n00:09:55.385 --> 00:09:57.380\n[LAUGH] I've heard some people explain it,\n\n193\n00:09:57.380 --> 00:10:01.550\nthe Cadillac experience, or\nthe Lamborghini experience, if you will.\n\n194\n00:10:01.550 --> 00:10:05.850\nWhen it comes to your end-users and the\ncost behind maintaining high availability.\n\n195\n00:10:05.850 --> 00:10:08.150\n&gt;&gt; As opposed to an AMC Pacer.\n\n196\n00:10:08.150 --> 00:10:09.931\n&gt;&gt; That's right [LAUGH]\n&gt;&gt; But is there an order or\n\n197\n00:10:09.931 --> 00:10:12.920\na protocol to follow when\nit comes to restoration?\n\n198\n00:10:12.920 --> 00:10:17.540\n&gt;&gt; You know, that's a very interesting\nconcept, and I have to tell you I, no.\n\n199\n00:10:17.540 --> 00:10:18.040\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n200\n00:10:18.040 --> 00:10:19.060\n&gt;&gt; No, that's.\n\n201\n00:10:19.060 --> 00:10:21.060\n&gt;&gt; It's not a one size fit all, yeah.\n\n202\n00:10:21.060 --> 00:10:22.500\n&gt;&gt; It really isn't, you know?\n\n203\n00:10:22.500 --> 00:10:24.190\nAnd that's really what it comes down to.\n\n204\n00:10:24.190 --> 00:10:29.170\nIt's not a one size fits all, but\nthere is a consistency in one thing.\n\n205\n00:10:29.170 --> 00:10:32.110\nIf you do asset management,\n\n206\n00:10:32.110 --> 00:10:36.170\ninventory assessment,\nyou know what your critical systems are.\n\n207\n00:10:36.170 --> 00:10:38.110\nThose are gonna come back online, right.\n\n208\n00:10:38.110 --> 00:10:41.156\nWhen we talk about a forensics concept, we\ntalk about the order of volatility, right.\n\n209\n00:10:41.156 --> 00:10:42.946\nAnd the order of volatility says,\n\n210\n00:10:42.946 --> 00:10:47.250\nwhat data do I have to get into\na forensics investigation at first.\n\n211\n00:10:47.250 --> 00:10:51.010\nWe talk about things that are stored in\nRAM right, because if I walk over and\n\n212\n00:10:51.010 --> 00:10:54.700\npull the power on the computer anything\nthat's in RAM is completely lost.\n\n213\n00:10:54.700 --> 00:10:57.080\nIt might corrupt\nthe forensics investigation.\n\n214\n00:10:57.080 --> 00:11:00.390\nNow I want you to think of\nthe criticality of your systems and\n\n215\n00:11:00.390 --> 00:11:02.070\nthat could be a volatile order too.\n\n216\n00:11:02.070 --> 00:11:04.360\nWe bring those systems back online first.\n\n217\n00:11:04.360 --> 00:11:06.820\nSo let me give you kind of an example,\nright.\n\n218\n00:11:06.820 --> 00:11:09.302\nAnd I hate those no,\nthere's not a one size fits all.\n\n219\n00:11:09.302 --> 00:11:13.240\nBut, we'll give you some kind\nof a guideline, if you will.\n\n220\n00:11:13.240 --> 00:11:15.050\nAnd again, these are suggestions.\n\n221\n00:11:15.050 --> 00:11:18.490\nI have to do the little disclaimer\nhere because this might\n\n222\n00:11:18.490 --> 00:11:20.360\nnot be what your company,\nsuitable for your company.\n\n223\n00:11:20.360 --> 00:11:22.880\nSo, first of all,\nwhat do we have to have online?\n\n224\n00:11:22.880 --> 00:11:23.670\nPower.\n\n225\n00:11:23.670 --> 00:11:24.970\nGotta start with power, right?\n\n226\n00:11:24.970 --> 00:11:26.740\nYou can't get anything done\nif you don't have power.\n\n227\n00:11:26.740 --> 00:11:29.100\nSo we need to make sure\nthat we bring the power on.\n\n228\n00:11:29.100 --> 00:11:30.870\nThen what do we have to bring online?\n\n229\n00:11:30.870 --> 00:11:33.678\nWell, we have to bring on some\nclimate control system, right?\n\n230\n00:11:33.678 --> 00:11:35.580\nIt's not gonna do you much good\nif you bring the power on and\n\n231\n00:11:35.580 --> 00:11:36.870\nyou bring your servers offline and\n\n232\n00:11:36.870 --> 00:11:39.000\nevery one of them goes into\na thermal shutdown, right?\n\n233\n00:11:39.000 --> 00:11:41.850\nYou really just created another problem,\nright?\n\n234\n00:11:41.850 --> 00:11:44.890\nSo you might do something like this,\nbring your power grid back on,\n\n235\n00:11:44.890 --> 00:11:50.560\nwhatever your power source is,right, bring\nback on the HVAC system, bring your server\n\n236\n00:11:50.560 --> 00:11:55.960\nroom back online, bring the hardware in\nthe server room online and then secure it.\n\n237\n00:11:55.960 --> 00:11:57.626\nRight?\nGonna be careful because\n\n238\n00:11:57.626 --> 00:12:01.480\nsome people in a recovery situation\nmight not be security minded but\n\n239\n00:12:01.480 --> 00:12:05.620\nin a disaster recovery situation,\nyou're very vulnerable to attack.\n\n240\n00:12:05.620 --> 00:12:08.290\nSo you also have to make sure\nthat you're bringing back online\n\n241\n00:12:08.290 --> 00:12:11.940\neven at the minimalistic, some portion\nof your security infrastructure.\n\n242\n00:12:11.940 --> 00:12:13.440\nThen it might be a connection to the ISP,\n\n243\n00:12:13.440 --> 00:12:16.080\nwe've gotta re-establish\na connection outbound so\n\n244\n00:12:16.080 --> 00:12:20.360\npeople can connect back to us or we can\nconnect to the rest of the world, right.\n\n245\n00:12:20.360 --> 00:12:22.450\nThen you implement your\nsoftware applications.\n\n246\n00:12:22.450 --> 00:12:26.110\nYou bring them back online cuz\nthey process our information.\n\n247\n00:12:26.110 --> 00:12:29.130\nAnd last but not least,\nyou do data restoration.\n\n248\n00:12:29.130 --> 00:12:32.150\nSo again, that just kinda gives you an\nexample of where the critical systems are.\n\n249\n00:12:32.150 --> 00:12:33.690\nCritical, i mean power.\n\n250\n00:12:33.690 --> 00:12:37.420\nWe can't work today in this day and\nage without power.\n\n251\n00:12:37.420 --> 00:12:40.400\nAll the way up to the data\nrestoration process.\n\n252\n00:12:40.400 --> 00:12:41.940\n&gt;&gt; And backup concepts?\n\n253\n00:12:41.940 --> 00:12:43.540\n&gt;&gt; Backup concepts\n&gt;&gt; Moving into that.\n\n254\n00:12:43.540 --> 00:12:44.977\n&gt;&gt; Yeah, exactly, this is down,\n\n255\n00:12:44.977 --> 00:12:48.349\nnow here's another situation where we\nhave different ways to do backups.\n\n256\n00:12:48.349 --> 00:12:50.450\nDifferent backup types.\n\n257\n00:12:50.450 --> 00:12:52.880\nHowever, I will tell you, that again,\n\n258\n00:12:52.880 --> 00:12:57.400\nsome are good in certain situations,\nsome are not good in certain situations.\n\n259\n00:12:57.400 --> 00:12:58.380\nLet me tell you what I mean,\n\n260\n00:12:58.380 --> 00:13:02.860\nso we have three different types\nof backups that they call out.\n\n261\n00:13:02.860 --> 00:13:06.440\nThey call out differential,\nincremental, and a full backup.\n\n262\n00:13:06.440 --> 00:13:09.140\nNow, they also call some\nother technologies,\n\n263\n00:13:09.140 --> 00:13:10.830\nthey call them backup concepts, but\n\n264\n00:13:10.830 --> 00:13:15.380\nwe gotta be careful with this one, cuz\na snapshot, this is what you do to a VM.\n\n265\n00:13:15.380 --> 00:13:20.090\nI put in a point in time configuration,\nthat is not a backup.\n\n266\n00:13:20.090 --> 00:13:20.670\nWhy?\n\n267\n00:13:20.670 --> 00:13:23.130\nBecause that configuration\nis stored on a hard drive.\n\n268\n00:13:23.130 --> 00:13:25.370\nWhat happens if the hard drive fails?\n\n269\n00:13:25.370 --> 00:13:26.740\nYou no longer have your snapshots.\n\n270\n00:13:26.740 --> 00:13:29.340\nSo keep in mind that\nsnapshots are good for\n\n271\n00:13:29.340 --> 00:13:33.030\nreverting a virtual machine\nto an earlier point in time.\n\n272\n00:13:33.030 --> 00:13:36.050\nWe don't use snapshots a lot\nin production because they do,\n\n273\n00:13:36.050 --> 00:13:38.100\nthey're a performance hindrance.\n\n274\n00:13:38.100 --> 00:13:39.800\nSo keep in mind that a snapshot,\n\n275\n00:13:39.800 --> 00:13:44.410\nalthough it does allow you a good way to\nroll back after testing different things,\n\n276\n00:13:44.410 --> 00:13:47.630\nif they go wrong I could roll back\nto that earlier point in time,\n\n277\n00:13:47.630 --> 00:13:51.970\nit doesn't replace the differential,\nincremental, or full backup type.\n\n278\n00:13:51.970 --> 00:13:53.200\nAll right, so let me go ahead and\n\n279\n00:13:53.200 --> 00:13:56.190\nlet's kinda talk about\nthe different types, all right?\n\n280\n00:13:56.190 --> 00:13:59.690\nNow, I've got one here and\nthis is the differential model, all right?\n\n281\n00:13:59.690 --> 00:14:04.030\nLet's go ahead and let's start this\noff right, by letting you know that\n\n282\n00:14:04.030 --> 00:14:07.960\nevery backup type that we will look at,\nstarts with a full backup.\n\n283\n00:14:07.960 --> 00:14:09.780\nWhat does the full backup consist of?\n\n284\n00:14:10.860 --> 00:14:12.810\nEverything that was done the week prior.\n\n285\n00:14:12.810 --> 00:14:16.240\nFriday comes, and we're gonna say this is\na perfect world, I don't know where it is,\n\n286\n00:14:16.240 --> 00:14:19.240\nbut if show me where that perfect\nworld is, I'll join you on a bus and\n\n287\n00:14:19.240 --> 00:14:19.819\nwe'll go there.\n\n288\n00:14:19.819 --> 00:14:21.295\n&gt;&gt; [LAUGH]\n&gt;&gt; But, we'll say that this is a perfect\n\n289\n00:14:21.295 --> 00:14:24.371\nworld, and we don't do any work, I don't\nwant to throw you guys any curve balls,\n\n290\n00:14:24.371 --> 00:14:26.490\nwe don't do any work Saturday or Sunday.\n\n291\n00:14:26.490 --> 00:14:31.440\nFriday at normal time 5PM,\nthat's when work stops it's starts at\n\n292\n00:14:31.440 --> 00:14:35.460\nlets say seven in the morning in Monday,\neight in the morning on Monday, okay.\n\n293\n00:14:35.460 --> 00:14:38.546\nSo when I say that a back up\ntype starts with a full back up,\n\n294\n00:14:38.546 --> 00:14:41.360\nwe're backing up everything\nthat happened last week, so\n\n295\n00:14:41.360 --> 00:14:44.446\nthat when Monday comes we\nhave our full backup ready.\n\n296\n00:14:44.446 --> 00:14:47.700\nI don't care what back up type\nthey give you on the exam.\n\n297\n00:14:47.700 --> 00:14:51.880\nIf it doesn't include a full backup,\npay attention to what your key words are,\n\n298\n00:14:51.880 --> 00:14:55.580\nyou're probably missing the context\nof the question as everyone does.\n\n299\n00:14:55.580 --> 00:14:58.670\nNow differential, how does it work, okay?\n\n300\n00:14:58.670 --> 00:15:06.330\nA differential backs up all the changes\nthat have happened since the full backup.\n\n301\n00:15:06.330 --> 00:15:09.510\nAll right, so let's go ahead and let's\nkinda think about what's going on here.\n\n302\n00:15:09.510 --> 00:15:12.300\nFriday, I run a full backup,\nnothing happens over the weekend.\n\n303\n00:15:12.300 --> 00:15:15.170\nMonday comes in, we're gonna do some work.\n\n304\n00:15:15.170 --> 00:15:18.210\nAll right, in doing some of this work,\nwe're making changes.\n\n305\n00:15:18.210 --> 00:15:20.130\nWell, how are we tracking those changes?\n\n306\n00:15:20.130 --> 00:15:22.530\nHow do we even know what a change is?\n\n307\n00:15:22.530 --> 00:15:24.110\nOr when a change occurs?\n\n308\n00:15:24.110 --> 00:15:26.680\nWell, that goes back to something\nknown as file attributes.\n\n309\n00:15:26.680 --> 00:15:28.670\nMaybe you remember from A Plus, right?\n\n310\n00:15:28.670 --> 00:15:30.740\nMaybe you've even seen it in Netplus too.\n\n311\n00:15:30.740 --> 00:15:37.290\nRemember, an archived bit, attribute on\na file or folder tells a backup system,\n\n312\n00:15:37.290 --> 00:15:39.710\nsomething's been modified since\nthe last time you've run.\n\n313\n00:15:39.710 --> 00:15:41.680\nSo you don't have a current copy of this.\n\n314\n00:15:41.680 --> 00:15:45.680\nWhatever the modification is, could be the\nfact that somebody changed the timestamp.\n\n315\n00:15:45.680 --> 00:15:47.128\nCould be the fact that\nsomebody added one character.\n\n316\n00:15:47.128 --> 00:15:51.148\nBut whatever has changed,\nwas not included in the last full backup.\n\n317\n00:15:51.148 --> 00:15:55.412\nThat lets the backup software know,\nyou've got to include this.\n\n318\n00:15:55.412 --> 00:15:58.584\nNow some backup types what they'll do\nis when they find that data that's\n\n319\n00:15:58.584 --> 00:16:00.550\nbeen modified, that's new.\n\n320\n00:16:00.550 --> 00:16:03.990\nAnd they run the backup,\nit clears the archive bit so\n\n321\n00:16:03.990 --> 00:16:07.540\nthat the next day you come in\neverything's been backed up.\n\n322\n00:16:07.540 --> 00:16:09.188\nBe careful with the differential backup,\n\n323\n00:16:09.188 --> 00:16:13.220\ncuz the differential backup is\nlooking to that archive bit, right?\n\n324\n00:16:13.220 --> 00:16:16.350\nIt says, okay, I see you've made\nsome changes in your work on Monday.\n\n325\n00:16:16.350 --> 00:16:19.640\nAt the end of the day Monday,\nlets figure out what we need to back up.\n\n326\n00:16:19.640 --> 00:16:22.880\nIt says okay I see the archive\nbits on a certain subset of files.\n\n327\n00:16:22.880 --> 00:16:26.580\nThat means they've been changed since the\nlast full backup and we're gonna run them.\n\n328\n00:16:26.580 --> 00:16:28.530\nWe're gonna run the backup.\n\n329\n00:16:28.530 --> 00:16:33.460\nNow when you run that backup,\nthose archived bits, they stay in place.\n\n330\n00:16:33.460 --> 00:16:34.990\nThey don't get cleared.\n\n331\n00:16:34.990 --> 00:16:36.210\nSo what happens?\n\n332\n00:16:36.210 --> 00:16:40.090\nWell when Tuesday comes along,\nvery first thing Tuesday morning,\n\n333\n00:16:40.090 --> 00:16:43.920\nbefore anybody even starts work, I already\ngot archive bits that are present.\n\n334\n00:16:43.920 --> 00:16:45.320\nThose are the ones from Monday.\n\n335\n00:16:45.320 --> 00:16:49.170\nWe backed all that data up, but\nwe didn't clear those bits.\n\n336\n00:16:49.170 --> 00:16:50.930\nWhich means I'm already gonna have,\n\n337\n00:16:50.930 --> 00:16:54.140\nMonday's is gonna be included\nin Tuesday's backup.\n\n338\n00:16:54.140 --> 00:16:56.955\nAnd then as Tuesday goes along we're\ngonna make some changes, right.\n\n339\n00:16:56.955 --> 00:16:58.000\nWe're gonna do our normal day.\n\n340\n00:16:58.000 --> 00:17:00.480\nAnd at the end of the day\nthe backup software is gonna say,\n\n341\n00:17:00.480 --> 00:17:03.860\nlet me look at all the changes\nthe archive bits that are present,\n\n342\n00:17:03.860 --> 00:17:07.530\ntelling me what's changed since\nthat last full backup that started.\n\n343\n00:17:07.530 --> 00:17:09.260\nAnd we're gonna back that information.\n\n344\n00:17:09.260 --> 00:17:10.300\nWe're just gonna back it up.\n\n345\n00:17:10.300 --> 00:17:11.290\nWe're gonna store a copy of it.\n\n346\n00:17:12.700 --> 00:17:14.080\nBut now look what happens.\n\n347\n00:17:14.080 --> 00:17:17.970\nNow come Wednesday because I still\nhave all of Monday's archive bits.\n\n348\n00:17:17.970 --> 00:17:21.920\nI still have all of Tuesday's archive\nbits before I make any changes that day.\n\n349\n00:17:21.920 --> 00:17:24.870\nI've already got all of that data\nthat's going to be included in\n\n350\n00:17:24.870 --> 00:17:26.120\nWednesday's backup.\n\n351\n00:17:26.120 --> 00:17:29.740\nBut then again as we do our changes on\nWednesday we're gonna have things that\n\n352\n00:17:29.740 --> 00:17:31.132\nare unique to Wednesday.\n\n353\n00:17:31.132 --> 00:17:34.004\nWe're gonna run the backup\nsoftware at the end of the day.\n\n354\n00:17:34.004 --> 00:17:38.210\nAnd now not only do we have modifications\nmade on Wednesday, but we got\n\n355\n00:17:38.210 --> 00:17:42.660\nthe modifications left over from Tuesday\nand Monday that we've never cleared.\n\n356\n00:17:42.660 --> 00:17:47.130\nSo the point is, notice that as\nthis goes day by day, alright.\n\n357\n00:17:47.130 --> 00:17:51.440\nThe differential aspect of this says we\njust, we're backing up what's changed,\n\n358\n00:17:51.440 --> 00:17:53.740\nwhat's different from the full backup.\n\n359\n00:17:53.740 --> 00:17:57.140\nBut notice how the data accumulates.\n\n360\n00:17:57.140 --> 00:18:01.420\nNotice that Monday's backup is, what,\none-fifth the size of Friday's backup.\n\n361\n00:18:01.420 --> 00:18:03.420\nSo Friday's backup could\ntake a little while, right?\n\n362\n00:18:03.420 --> 00:18:06.250\nThere's a lot of information that\nwe gotta back up, all right?\n\n363\n00:18:06.250 --> 00:18:08.740\nAnd I'm gonna come back to these and we're\ngonna talk about the benefits, right?\n\n364\n00:18:08.740 --> 00:18:10.840\nNow lets just understand what they are and\nthen we'll compare and\n\n365\n00:18:10.840 --> 00:18:13.030\ncontrast why we would use one or\nthe other.\n\n366\n00:18:13.030 --> 00:18:16.260\nAll right, that's the differential backup.\n\n367\n00:18:16.260 --> 00:18:18.080\nNow the incremental backup.\n\n368\n00:18:18.080 --> 00:18:20.300\nNow I changed the colors around\non this one a little bit so\n\n369\n00:18:20.300 --> 00:18:22.300\nyou can kinda understand\nwhat's going on here.\n\n370\n00:18:22.300 --> 00:18:24.818\nNow, understand what's happening\nwith the incremental backup.\n\n371\n00:18:24.818 --> 00:18:27.790\nIt starts kinda like the differential\nbackup in the fact that\n\n372\n00:18:27.790 --> 00:18:29.760\non Monday same scenario.\n\n373\n00:18:29.760 --> 00:18:33.110\nFriday we've run our full backup,\nnothing's changed over the weekend.\n\n374\n00:18:33.110 --> 00:18:34.970\nMonday we're gonna do some work.\n\n375\n00:18:34.970 --> 00:18:38.580\nAt the end of Monday,\nwe've got some unique attributes, right.\n\n376\n00:18:38.580 --> 00:18:40.200\nWe've got some files\nthat have been modified,\n\n377\n00:18:40.200 --> 00:18:42.120\nwe've got some work that's been done.\n\n378\n00:18:42.120 --> 00:18:44.700\nWe're gonna look back to the full backup.\n\n379\n00:18:44.700 --> 00:18:47.380\nWe're gonna find those attributes\nthat tells us what's changed.\n\n380\n00:18:47.380 --> 00:18:50.190\nAnd then we're gonna back the data up.\n\n381\n00:18:50.190 --> 00:18:51.880\nBut here's the difference.\n\n382\n00:18:51.880 --> 00:18:54.220\nThe incremental backup\nclears the archive bit.\n\n383\n00:18:54.220 --> 00:18:56.600\nSo what does that mean for us?\n\n384\n00:18:56.600 --> 00:18:59.810\nWell, that means when Tuesday comes in,\neverything's fresh.\n\n385\n00:18:59.810 --> 00:19:03.610\nI don't have Monday's archive bits\nin Tuesday because they were cleared\n\n386\n00:19:03.610 --> 00:19:04.130\non Monday.\n\n387\n00:19:05.240 --> 00:19:08.730\nSo what happens is we have just\na little incremental data, right?\n\n388\n00:19:08.730 --> 00:19:10.030\nThat's where we get the name.\n\n389\n00:19:10.030 --> 00:19:11.750\nThat's modified on Tuesday.\n\n390\n00:19:11.750 --> 00:19:14.980\nAnd at the end of the day on Tuesday,\nunlike the differential, when we go to\n\n391\n00:19:14.980 --> 00:19:20.240\nlook at what we need to back up, the only\narchive bits we find are just for Tuesday.\n\n392\n00:19:20.240 --> 00:19:23.820\nCuz remember, when we run the software\nthe prior day, it cleared everything.\n\n393\n00:19:23.820 --> 00:19:25.070\nAll those archive bits are gone.\n\n394\n00:19:25.070 --> 00:19:29.806\nSo, it thinks the only thing that's unique\nto this day is what happened on that day.\n\n395\n00:19:29.806 --> 00:19:36.660\nSame thing for Wednesday, same thing for\nThursday, and same thing for Friday.\n\n396\n00:19:36.660 --> 00:19:38.430\nNotice the difference\nbetween the two here.\n\n397\n00:19:38.430 --> 00:19:42.045\nNotice that my backups are very,\nvery small and incremental.\n\n398\n00:19:42.045 --> 00:19:45.260\nCuz I'm only backing up the changes\nthat happened that day.\n\n399\n00:19:45.260 --> 00:19:47.400\nAnd then we're clearing\nthose archive bits.\n\n400\n00:19:47.400 --> 00:19:49.040\nAll right, last but\n\n401\n00:19:49.040 --> 00:19:54.090\nnot least, this is probably one of\nthe easiest ones to understand.\n\n402\n00:19:54.090 --> 00:19:56.330\nThis is called a full backup type.\n\n403\n00:19:56.330 --> 00:19:58.916\nLet's be careful with this one, right?\n\n404\n00:19:58.916 --> 00:20:03.909\nBecause it's a full backup but every\nbackup type starts with a full backup,\n\n405\n00:20:03.909 --> 00:20:04.910\nall right.\n\n406\n00:20:04.910 --> 00:20:08.841\nWhat this means is that every single\nday we're gonna back up everything.\n\n407\n00:20:08.841 --> 00:20:13.760\nAll right, now what's interesting\nis a full backup type\n\n408\n00:20:13.760 --> 00:20:16.160\ndoesn't look to the archive bit,\ndoesn't look at all.\n\n409\n00:20:16.160 --> 00:20:17.640\nIt says I don't care if it's backed up or\n\n410\n00:20:17.640 --> 00:20:20.630\nnot, I'm running a full\nbackup today regardless.\n\n411\n00:20:20.630 --> 00:20:23.980\nSo what does that mean, right, in reality?\n\n412\n00:20:23.980 --> 00:20:27.324\nThat means on Monday I might have\nsomething that hasn't changed in the last,\n\n413\n00:20:27.324 --> 00:20:29.560\nsince the full back up.\n\n414\n00:20:29.560 --> 00:20:33.420\nAnd they're identical between\nthe full backup and Monday.\n\n415\n00:20:33.420 --> 00:20:36.770\nAnd it doesn't change on Tuesday,\nand it didn't change on Wednesday.\n\n416\n00:20:36.770 --> 00:20:39.320\nNobody's made any modifications,\nbut guess what?\n\n417\n00:20:39.320 --> 00:20:41.710\nEvery single day we're\nbacking it up regardless.\n\n418\n00:20:41.710 --> 00:20:45.140\nCuz a full backup says I don't care what's\ntelling me it needs to be backed up or\n\n419\n00:20:45.140 --> 00:20:46.940\nnot, I'm gonna back up\neverything regardless.\n\n420\n00:20:46.940 --> 00:20:51.020\nSo we could have multiple copies of\nidentical copies in the same backup.\n\n421\n00:20:52.090 --> 00:20:54.090\nNow here's what you have to understand.\n\n422\n00:20:54.090 --> 00:20:58.140\nAny time we run a full backup,\nnow don't worry about type.\n\n423\n00:20:58.140 --> 00:21:02.050\nWhen I run a full backup even though\nit doesn't look to the archive bits,\n\n424\n00:21:02.050 --> 00:21:04.610\nit clears all archive bits.\n\n425\n00:21:04.610 --> 00:21:07.130\nAnd that's an important\nconcept to understand, right?\n\n426\n00:21:07.130 --> 00:21:09.210\nWhy, when we're coming in on Monday,\n\n427\n00:21:09.210 --> 00:21:12.790\ndoesn't matter if it's the incremental or\nif it's the, let me get it right here,\n\n428\n00:21:12.790 --> 00:21:15.910\ndifferential or\nif it's the incremental, right?\n\n429\n00:21:15.910 --> 00:21:20.240\nWhy do we have changes that are gonna\nhave to be backed up on Monday?\n\n430\n00:21:20.240 --> 00:21:23.950\nThat's because when we run the last full\nbackup, it cleared all the archive bits,\n\n431\n00:21:23.950 --> 00:21:25.710\nstarts us off fresh.\n\n432\n00:21:25.710 --> 00:21:28.810\nAgain, keep in mind with a full\nbackup though, when it needs to\n\n433\n00:21:28.810 --> 00:21:31.550\ndetermine what to backup, since I don't\ncare what the archive bits are saying,\n\n434\n00:21:31.550 --> 00:21:33.810\nI'm gonna make a copy regardless.\n\n435\n00:21:33.810 --> 00:21:35.030\nSo what do we mean why, and\n\n436\n00:21:35.030 --> 00:21:38.290\nI told you I take it back to\nsome considerations, all right?\n\n437\n00:21:38.290 --> 00:21:40.010\nWhat are the considerations?\n\n438\n00:21:40.010 --> 00:21:42.940\nWell, if you need some\nkind of metric here,\n\n439\n00:21:42.940 --> 00:21:45.970\ntime to backup versus the time to restore,\nall right?\n\n440\n00:21:47.030 --> 00:21:49.140\nWhy would time to back up be a factor?\n\n441\n00:21:49.140 --> 00:21:53.300\nIf you're an e-commerce site and\nthe sun never sits on your business,\n\n442\n00:21:53.300 --> 00:21:55.110\nyou don't have a lot of downtime for\nyour data.\n\n443\n00:21:55.110 --> 00:21:57.640\nYou don't have a lot of\ntime like Saturday and\n\n444\n00:21:57.640 --> 00:21:59.060\nSunday where your data's doing nothing.\n\n445\n00:21:59.060 --> 00:22:01.630\nIn some businesses that might be the case.\n\n446\n00:22:01.630 --> 00:22:04.535\nSo in that case, a full backup could\ncost you a lot of money, right?\n\n447\n00:22:04.535 --> 00:22:07.790\nCuz you're having to backup everything and\nit could take awhile,\n\n448\n00:22:07.790 --> 00:22:11.640\nyour data's constantly being used,\nall right?\n\n449\n00:22:11.640 --> 00:22:14.760\nSo in this sense,\nyou might use an incremental.\n\n450\n00:22:14.760 --> 00:22:16.620\nWhy would I use an incremental?\n\n451\n00:22:16.620 --> 00:22:20.870\nCuz incremental takes very little\ntime to back up information,\n\n452\n00:22:20.870 --> 00:22:22.940\nto backing up changes, right?\n\n453\n00:22:22.940 --> 00:22:26.970\nSo you might do that for,\nif that's the case with your backup time.\n\n454\n00:22:26.970 --> 00:22:29.380\nNow, however, here's the other\nside of the tracks, right?\n\n455\n00:22:29.380 --> 00:22:32.850\nPros and cons with everything, and\nthis is no exception to the rule.\n\n456\n00:22:32.850 --> 00:22:37.530\nThe time to restore an incremental\ntakes forever, it's the longest, why?\n\n457\n00:22:37.530 --> 00:22:42.390\nWell, let's go back and\nlet's say that on Friday,\n\n458\n00:22:42.390 --> 00:22:46.300\nFriday hasn't happened,\nI have a complete system failure, right?\n\n459\n00:22:46.300 --> 00:22:48.040\nWe'll just go ahead and\nwe'll mark this one.\n\n460\n00:22:48.040 --> 00:22:50.970\nLet's just change this one as a red color,\nright?\n\n461\n00:22:50.970 --> 00:22:52.860\nWe have a complete failure.\n\n462\n00:22:52.860 --> 00:22:54.680\nNow no curve balls.\n\n463\n00:22:54.680 --> 00:22:56.530\nAll the other backups\ncompleted successfully.\n\n464\n00:22:57.630 --> 00:23:03.010\nWhat tapes would I need to fully\nrestore my data for Thursday?\n\n465\n00:23:03.010 --> 00:23:05.360\nAgain Friday we don't have anything.\n\n466\n00:23:05.360 --> 00:23:09.680\nWell if you look at it, that's why I color\ncode it, oops, let me try that again.\n\n467\n00:23:09.680 --> 00:23:14.880\nIf you look at what tapes I need\nto fully restore my information\n\n468\n00:23:14.880 --> 00:23:17.820\nto what it was prior to the failure.\n\n469\n00:23:17.820 --> 00:23:20.530\nNotice how many different\nbackup medias I need.\n\n470\n00:23:20.530 --> 00:23:22.370\nYou always need your full backup.\n\n471\n00:23:22.370 --> 00:23:25.430\nAlways need your full backup, I don't\ncare what the restoration method is.\n\n472\n00:23:25.430 --> 00:23:27.140\nAlways need your full backup.\n\n473\n00:23:27.140 --> 00:23:30.510\nBut notice to restore my data fully\nto the point it was at Thursday,\n\n474\n00:23:30.510 --> 00:23:32.500\nI'd have to have the full backup.\n\n475\n00:23:32.500 --> 00:23:36.770\nMonday's tape, Tuesday's tape,\nWednesday's tape, and Thursday's tape.\n\n476\n00:23:36.770 --> 00:23:39.712\nAnd now I've got a complete\nrebuilding of my information.\n\n477\n00:23:39.712 --> 00:23:44.644\nSo while an incremental doesn't\ntake a long time to back up,\n\n478\n00:23:44.644 --> 00:23:48.317\nit can be a nightmare to restore,\nall right,\n\n479\n00:23:48.317 --> 00:23:51.818\nversus something like the differential.\n\n480\n00:23:51.818 --> 00:23:54.059\nNow the differential's one that's in fact,\nZach and\n\n481\n00:23:54.059 --> 00:23:56.455\nI were kinda discussing this\nbefore we went onto the show.\n\n482\n00:23:56.455 --> 00:23:58.591\nIs that this is kind of\nlike halfway between,\n\n483\n00:23:58.591 --> 00:24:00.457\nit might be considered the sweet spot.\n\n484\n00:24:00.457 --> 00:24:04.600\nIt's halfway between the time it takes to\nback up, and the time it takes to restore.\n\n485\n00:24:04.600 --> 00:24:05.240\nAll right.\n\n486\n00:24:05.240 --> 00:24:08.660\nSo let's say same situation goes on.\n\n487\n00:24:08.660 --> 00:24:10.020\nAgain, no curve balls.\n\n488\n00:24:10.020 --> 00:24:18.188\nWe're gonna say that at some point on,\nFriday If I can do this here,\n\n489\n00:24:18.188 --> 00:24:23.320\nreal quick, this is what you get for\nmodifying slides on the fly.\n\n490\n00:24:23.320 --> 00:24:26.430\nOn Friday, we have a failure, all right.\n\n491\n00:24:26.430 --> 00:24:28.480\nWe don't have any information.\n\n492\n00:24:28.480 --> 00:24:30.890\nSame thing that happened before, okay?\n\n493\n00:24:30.890 --> 00:24:33.820\nSo now what tapes do I need,\nin a differential,\n\n494\n00:24:33.820 --> 00:24:36.490\nin order to get my\ninformation back online?\n\n495\n00:24:36.490 --> 00:24:38.880\nWell the great thing is,\nI only need two tapes.\n\n496\n00:24:38.880 --> 00:24:41.590\nRight I have the last full backup,\nalways need that.\n\n497\n00:24:41.590 --> 00:24:44.420\nDoesn't matter what\nrestoration type you're doing.\n\n498\n00:24:44.420 --> 00:24:47.570\nBut if you notice I can\nachieve the same goal\n\n499\n00:24:48.720 --> 00:24:52.240\nas I did here with a differential\nwith just two tapes.\n\n500\n00:24:54.030 --> 00:24:59.510\nSo the backup time relatively\nmiddle of the road and\n\n501\n00:24:59.510 --> 00:25:03.300\nthe restoration time relatively middle of\nthe road when you look at the other three.\n\n502\n00:25:04.300 --> 00:25:05.400\nNow how about the last one?\n\n503\n00:25:05.400 --> 00:25:07.250\nWhere does the last one come into play?\n\n504\n00:25:07.250 --> 00:25:09.070\nAnd that's the full backup.\n\n505\n00:25:09.070 --> 00:25:12.040\nNow notice in the metric here\nthat I have as an example\n\n506\n00:25:12.040 --> 00:25:17.280\nthe time to backup takes forever,\nright, versus the time to restore.\n\n507\n00:25:17.280 --> 00:25:18.610\nAnd why is that?\n\n508\n00:25:18.610 --> 00:25:23.090\nWell because if we take that same scenario\nand I take Friday out of the picture,\n\n509\n00:25:23.090 --> 00:25:25.390\nwhat tapes do I need to fully\nrestore my information?\n\n510\n00:25:26.590 --> 00:25:28.219\nWell I already have it,\nit's right there on Thursday.\n\n511\n00:25:28.219 --> 00:25:32.940\nI only need to do one tape,\nright, one media backup set.\n\n512\n00:25:32.940 --> 00:25:36.410\nSo again, while it takes forever\nto back this information up and\n\n513\n00:25:36.410 --> 00:25:41.160\nstorage accrual can be horrible,\nthe restoration time is the fastest.\n\n514\n00:25:41.160 --> 00:25:44.840\nSo again, you have to consider when\nyou're doing data restoration,\n\n515\n00:25:44.840 --> 00:25:46.640\nwhich one of these am I gonna use?\n\n516\n00:25:46.640 --> 00:25:49.560\nBecause there is no right and\nwrong answer, it depends.\n\n517\n00:25:49.560 --> 00:25:52.745\nIt depends on what type type of\ninformation you're backing up.\n\n518\n00:25:52.745 --> 00:25:55.085\nWhat kind of devices\ndo you have out there?\n\n519\n00:25:55.085 --> 00:25:57.555\nRemember we talked about\nsecure configuration guides?\n\n520\n00:25:57.555 --> 00:25:59.885\nWell, you have a best practice\nguides out there too, for\n\n521\n00:25:59.885 --> 00:26:01.505\nbacking up your information.\n\n522\n00:26:01.505 --> 00:26:04.930\nAnd the way you back up a web server\nmight be completely different.\n\n523\n00:26:04.930 --> 00:26:07.920\nIt is going to be most likely completely\ndifferent than the way you back up your\n\n524\n00:26:07.920 --> 00:26:09.540\ndata base server, right.\n\n525\n00:26:09.540 --> 00:26:10.740\nCuz the web server's the front end.\n\n526\n00:26:10.740 --> 00:26:12.840\nThat's the pretty stuff\nthat your customer's see.\n\n527\n00:26:12.840 --> 00:26:13.800\nThat goes down a little bit,\n\n528\n00:26:13.800 --> 00:26:16.730\nit might be easier to bring back online\nthan all the information that's stored on\n\n529\n00:26:16.730 --> 00:26:20.180\nthe back end of the database which\nis your bread and butter, right?\n\n530\n00:26:20.180 --> 00:26:21.440\nSo we have to keep that in mind.\n\n531\n00:26:21.440 --> 00:26:27.390\nThere are times when certain of these\nwould be better, one over the other.\n\n532\n00:26:27.390 --> 00:26:30.380\n&gt;&gt; Hey Wes, do we have time to talk\nabout geographic considerations?\n\n533\n00:26:30.380 --> 00:26:31.710\n&gt;&gt; We could talk about some of them, yeah.\n\n534\n00:26:31.710 --> 00:26:33.610\nI don't see why not here.\n\n535\n00:26:33.610 --> 00:26:36.440\nSo geographical, and the other thing too.\n\n536\n00:26:36.440 --> 00:26:39.310\nLet me mention one more thing\nabout backups before we get\n\n537\n00:26:39.310 --> 00:26:41.110\ninto that because this\nis kind of important.\n\n538\n00:26:41.110 --> 00:26:43.790\nWe've already talked about some\nof the considerations right?\n\n539\n00:26:43.790 --> 00:26:45.370\nThere are three other ones\nthat I wanna mention.\n\n540\n00:26:45.370 --> 00:26:49.210\nThey're not called out on the exam\nobjectives but it's a good practice right?\n\n541\n00:26:49.210 --> 00:26:51.243\nSchedule your backups.\n\n542\n00:26:51.243 --> 00:26:52.580\nYou could have a backup plan but\n\n543\n00:26:52.580 --> 00:26:56.540\nif you don't implement it you're wasting\nyour breath, and wasting your time right?\n\n544\n00:26:56.540 --> 00:26:59.260\nThe reason you have meetings to\ndiscuss the backup plans is so\n\n545\n00:26:59.260 --> 00:27:01.150\nyou'll have an action item at the end.\n\n546\n00:27:01.150 --> 00:27:04.440\nIf your meeting doesn't produce an action\nitem, it's a waste of your time.\n\n547\n00:27:04.440 --> 00:27:07.612\nSo scheduling backups are important.\n\n548\n00:27:07.612 --> 00:27:10.280\nBut then it's performing them right?\n\n549\n00:27:10.280 --> 00:27:12.270\nThe last thing is validation.\n\n550\n00:27:12.270 --> 00:27:14.930\nAll right you don't wanna wait\ntil you need your backup data to\n\n551\n00:27:14.930 --> 00:27:18.830\nfind out if the backup job\nsuccessfully completed, right.\n\n552\n00:27:18.830 --> 00:27:20.670\nThat is going to be\na bad day at the office.\n\n553\n00:27:20.670 --> 00:27:24.920\nWhen you say, okay, I've got six months\nof backup media, it's ready to go.\n\n554\n00:27:24.920 --> 00:27:25.880\nYou have a disaster.\n\n555\n00:27:25.880 --> 00:27:29.070\nDo you load all that media and\ndo the data restoration and\n\n556\n00:27:29.070 --> 00:27:32.340\nnot a single one of your data\nbackups survive the corruption.\n\n557\n00:27:33.710 --> 00:27:34.750\nNow you don't have your information.\n\n558\n00:27:34.750 --> 00:27:35.580\nAll that planning's a waste.\n\n559\n00:27:35.580 --> 00:27:38.660\nSo, validation of the backup process.\n\n560\n00:27:38.660 --> 00:27:42.530\nMaybe you have your restoration\noperator remember separation of duties.\n\n561\n00:27:42.530 --> 00:27:45.220\nI take that restoration operator and\n\n562\n00:27:45.220 --> 00:27:49.910\nI allow them to perform a restoration in\na virtualized isolated environment to\n\n563\n00:27:49.910 --> 00:27:53.860\nvalidate that the backups\nare performing successfully all right.\n\n564\n00:27:53.860 --> 00:27:57.650\nNow I know that I did kinda take the last\nfew minutes that we had on the backups.\n\n565\n00:27:57.650 --> 00:27:58.930\nSo Zach how about this?\n\n566\n00:27:58.930 --> 00:28:00.690\nWe'll go ahead and\nmaybe go into a part two.\n\n567\n00:28:00.690 --> 00:28:04.000\n&gt;&gt; Absolutely and in fact disaster\nrecovery business continuity.\n\n568\n00:28:04.000 --> 00:28:06.420\nSo much more to go over and\nthat will be in.\n\n569\n00:28:06.420 --> 00:28:08.700\nHey thank you for watching ITProTV.\n\n570\n00:28:08.700 --> 00:28:09.650\nI'm Zach Memos.\n\n571\n00:28:09.650 --> 00:28:10.440\n&gt;&gt; And I'm Wes Bryan.\n\n572\n00:28:10.440 --> 00:28:17.375\n&gt;&gt; And we'll see you next time.\n\n573\n00:28:17.375 --> 00:28:23.389\n[MUSIC]\n\n574\n00:28:23.389 --> 00:28:23.889\n&gt;&gt; Thank you for watching.\n\n",
          "vimeoId": "217168186"
        },
        {
          "description": "Wes and Zach recap considerations about backup, geographic considerations, legal implications including data sovereignty, and operation planning.",
          "length": "1384",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-6-2-disaster_recovery_and_business_continuity_pt2-050917.00_22_48_27.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-6-2-disaster_recovery_and_business_continuity_pt2-050917.00_22_48_27.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-6-2-disaster_recovery_and_business_continuity_pt2-050917.00_22_48_27.Still001-sm.jpg",
          "title": "Disaster Recovery and Business Continuity Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:01.240\nWelcome to ITPRO TV.\n\n2\n00:00:01.240 --> 00:00:06.455\nI'm you're host- [CROSSTALK]\n\n3\n00:00:06.455 --> 00:00:08.704\n[MUSIC]\n\n4\n00:00:08.704 --> 00:00:12.017\n&gt;&gt; You're watching ITPRO TV.\n\n5\n00:00:12.017 --> 00:00:16.275\n&gt;&gt; Hello and thank you for watch ITPROTV,\nhelping you learn wherever you go.\n\n6\n00:00:16.275 --> 00:00:17.880\nI'm your host Zach Memos.\n\n7\n00:00:17.880 --> 00:00:21.805\nAs we continue with [INAUDIBLE]\nsecurity plus and this is part two\n\n8\n00:00:21.805 --> 00:00:26.635\nof disaster recovery and business\ncontinuity with our IT pro Wes Bryan.\n\n9\n00:00:26.635 --> 00:00:27.275\nHey Wes.\n\n10\n00:00:27.275 --> 00:00:28.895\n&gt;&gt; Hey thanks for having me back, Zach.\n\n11\n00:00:28.895 --> 00:00:29.865\n&gt;&gt; Yeah.\n&gt;&gt; It's great to be here at\n\n12\n00:00:29.865 --> 00:00:30.675\nthe ITPROTV crew.\n\n13\n00:00:30.675 --> 00:00:33.500\nThat's right,\nwell I talked a lot in the first part.\n\n14\n00:00:33.500 --> 00:00:35.110\nWe didn't get through a whole bunch, but\n\n15\n00:00:35.110 --> 00:00:38.120\nwe did talk about some concepts\nthat we want you to be aware of.\n\n16\n00:00:38.120 --> 00:00:41.560\nSo if you're not familiar with what we did\nin the first part, go back and watch that,\n\n17\n00:00:41.560 --> 00:00:42.460\nand come back and join us.\n\n18\n00:00:42.460 --> 00:00:45.970\nKeep in mind that we were talking about\nalternative location types, right,\n\n19\n00:00:45.970 --> 00:00:46.980\nsite types if you will.\n\n20\n00:00:46.980 --> 00:00:49.350\nWe talked about the hot site,\nwarm site and cold site.\n\n21\n00:00:49.350 --> 00:00:53.160\nAnd really, what it comes down\nto which one we're gonna choose,\n\n22\n00:00:53.160 --> 00:00:57.120\nit's about the cost and\nit's about the time to recover.\n\n23\n00:00:57.120 --> 00:01:01.590\nIf you choose a hot site, very expensive,\nfailover's within seconds.\n\n24\n00:01:01.590 --> 00:01:05.550\nIt might not even be applicable,\nit might be just instantaneous.\n\n25\n00:01:05.550 --> 00:01:10.770\nIf you use a warm site, keep in mind\nthat failover to that type of site could\n\n26\n00:01:10.770 --> 00:01:15.380\ntake a few hours, could take a couple of\ndays, depending on how warm the site is.\n\n27\n00:01:15.380 --> 00:01:18.090\nAnd then cold site, could be just nothing\nmore than a prospective building.\n\n28\n00:01:18.090 --> 00:01:22.624\nHowever, with the hot site being\nthe most expensive, least downtime,\n\n29\n00:01:22.624 --> 00:01:27.523\nif you will, warm site kind of be in the\nmedium when it comes to cost or expense,\n\n30\n00:01:27.523 --> 00:01:32.169\nif you will, and the time that it takes\nto bring your systems back online.\n\n31\n00:01:32.169 --> 00:01:35.745\nCold, if you will, is going to be lowest\nof the cost, but it's going to be\n\n32\n00:01:35.745 --> 00:01:39.980\na nightmare bringing this type of site, or\ncould be, bringing this site back online.\n\n33\n00:01:39.980 --> 00:01:41.520\nIt's going to take awhile.\n\n34\n00:01:41.520 --> 00:01:44.720\nWe also talked about snapshot,\nexcuse me, I'm sorry, backup types and\n\n35\n00:01:44.720 --> 00:01:46.650\nthe considerations for each one of them.\n\n36\n00:01:46.650 --> 00:01:50.190\nRemember we talked about differential,\nincremental and the full backup type.\n\n37\n00:01:50.190 --> 00:01:53.460\nWe also talked about snapshots as well.\n\n38\n00:01:53.460 --> 00:01:55.800\nSo if you're not familiar with\nany of those concepts go back and\n\n39\n00:01:55.800 --> 00:01:57.570\ncheck them out and\nthen you guys can come back and\n\n40\n00:01:57.570 --> 00:02:00.850\njoin us here because we are going\nto be picking up where we left off.\n\n41\n00:02:00.850 --> 00:02:01.370\n&gt;&gt; That's right.\n\n42\n00:02:01.370 --> 00:02:03.560\nAnd we're going to be talking\nabout geographic considerations.\n\n43\n00:02:03.560 --> 00:02:05.460\nThere are some geographic\nconsiderations aren't there?\n\n44\n00:02:05.460 --> 00:02:06.460\n&gt;&gt; There definitely is.\n\n45\n00:02:06.460 --> 00:02:09.370\nYou know one of the things we talk about\nwhen it comes to geographical location,\n\n46\n00:02:09.370 --> 00:02:10.670\nright, and the considerations of them.\n\n47\n00:02:10.670 --> 00:02:12.990\nAnd we kind of mentioned this in\nthe first one, but we can go ahead and\n\n48\n00:02:12.990 --> 00:02:13.710\nrecap it here.\n\n49\n00:02:15.225 --> 00:02:19.600\nFor continuation of the exam\nobjectives is off site backups, right?\n\n50\n00:02:19.600 --> 00:02:21.090\nWe have to have off site backups.\n\n51\n00:02:21.090 --> 00:02:22.750\nThey're used in the case of a disaster.\n\n52\n00:02:22.750 --> 00:02:26.720\nIf your primary site fails, then all your\ndata's on that primary site then that\n\n53\n00:02:26.720 --> 00:02:28.370\nmeans your data goes with the site.\n\n54\n00:02:28.370 --> 00:02:34.070\nSo you definitely wanna make sure that it\nrequires a different physical location.\n\n55\n00:02:34.070 --> 00:02:36.391\nAnd that's why it's\na geographical consideration.\n\n56\n00:02:36.391 --> 00:02:40.860\nWhy do we talk about,\nas far as the location.\n\n57\n00:02:40.860 --> 00:02:42.540\nThey also mention location selection.\n\n58\n00:02:42.540 --> 00:02:46.150\nAnd I've got a couple of things here about\nwhen you talk about physical location,\n\n59\n00:02:46.150 --> 00:02:49.530\nI want you to think about\na disaster when it happens, right?\n\n60\n00:02:49.530 --> 00:02:52.300\nHere in Florida, in Gainesville, and\n\n61\n00:02:52.300 --> 00:02:55.770\npretty much everybody up on the Eastern\nSeaboard knows hurricane season, right?\n\n62\n00:02:55.770 --> 00:02:58.950\nSo if I have a disaster that happens\nin Florida, what's to say if my\n\n63\n00:02:58.950 --> 00:03:03.000\nbackup location's in South Carolina,\nNorth Carolina, the Virginias,\n\n64\n00:03:03.000 --> 00:03:07.160\nif you will, that the same disaster's\ngonna happen to their backup location.\n\n65\n00:03:07.160 --> 00:03:10.120\nSo you also have to consider, that's one\nof the things to consider when you think\n\n66\n00:03:10.120 --> 00:03:11.760\nof your location selection, all right?\n\n67\n00:03:11.760 --> 00:03:15.870\nAnd again there's no right,\none size fits all here.\n\n68\n00:03:15.870 --> 00:03:19.100\nI've read documentation\nwhere some say 1,000 miles\n\n69\n00:03:19.100 --> 00:03:21.400\nis the comfort zone in between sites.\n\n70\n00:03:21.400 --> 00:03:23.070\nI've seen some that say 100 miles.\n\n71\n00:03:23.070 --> 00:03:25.720\nSome even reduced it\ndown as much as 25 miles.\n\n72\n00:03:25.720 --> 00:03:28.330\nAgain, I can't say that they're right or\nwrong.\n\n73\n00:03:28.330 --> 00:03:31.720\nBut you have to think of something\nlike that where hurricanes, again,\n\n74\n00:03:31.720 --> 00:03:35.310\nthat aren't typically isolated to\nsingle geographical location, right?\n\n75\n00:03:35.310 --> 00:03:37.840\nI don't have to tell people that if\nyou're watching us from the western\n\n76\n00:03:37.840 --> 00:03:38.510\nseaboard, right?\n\n77\n00:03:38.510 --> 00:03:43.210\nIf you live along the San Andreas fault\nthat's very long spans of land, right?\n\n78\n00:03:43.210 --> 00:03:47.310\nSo you might be thinking, well maybe I\ndon't wanna have both of my primary and\n\n79\n00:03:47.310 --> 00:03:53.130\nsecondary sites on that fault line, you\nknow what I'm saying, or in California.\n\n80\n00:03:53.130 --> 00:03:55.490\nMaybe we want a West Coast,\nEast Coast, right?\n\n81\n00:03:55.490 --> 00:03:58.490\nMaybe we do it regional and\nit's Southeast versus Northeast.\n\n82\n00:03:58.490 --> 00:04:01.130\nAgain, you have to take\nthat into consideration,\n\n83\n00:04:01.130 --> 00:04:04.620\nespecially when you talk about the fact\nthat you have your off site backups and\n\n84\n00:04:04.620 --> 00:04:07.890\nthe hurricane takes a bee line and\ndestroys your secondary site as well.\n\n85\n00:04:07.890 --> 00:04:11.280\nSo it is something that\nyou have to keep in mind.\n\n86\n00:04:11.280 --> 00:04:14.820\nDistance, again like I said,\nthey do mention distance and\n\n87\n00:04:14.820 --> 00:04:18.310\nthat's why I mention things like\nhurricanes, things like our earthquakes,\n\n88\n00:04:18.310 --> 00:04:20.400\nour fault lines,\nbecause a natural disaster,\n\n89\n00:04:20.400 --> 00:04:24.090\nif it happens to the DR site as well,\nwell then you lose everything.\n\n90\n00:04:24.090 --> 00:04:29.310\nSo keep in mind distance can ensure that\nthe disaster itself doesn't affect both\n\n91\n00:04:29.310 --> 00:04:31.340\nprimary and secondary site.\n\n92\n00:04:31.340 --> 00:04:33.820\nHowever, here's a drawback with distance.\n\n93\n00:04:33.820 --> 00:04:35.039\nHere we go with those pros and\ncons, right?\n\n94\n00:04:35.039 --> 00:04:36.555\n&gt;&gt; There they are.\n&gt;&gt; They happen in every single\n\n95\n00:04:36.555 --> 00:04:37.359\nepisode, right?\n\n96\n00:04:38.660 --> 00:04:42.340\nAny time I increase the distance\nwe also increase latency.\n\n97\n00:04:42.340 --> 00:04:45.800\nSo if delay is a consideration of latency,\nright,\n\n98\n00:04:45.800 --> 00:04:48.380\nwe'll make our own contribution\nto the English language.\n\n99\n00:04:48.380 --> 00:04:50.540\nWe'll call it delatency,\ndelay and latency.\n\n100\n00:04:50.540 --> 00:04:52.650\nThen you've got yourself covered.\n\n101\n00:04:52.650 --> 00:04:54.910\nBut if we talk about latency or\ndelay, if you will,\n\n102\n00:04:54.910 --> 00:04:58.740\nthe longer the distance obviously\nyou're gonna incur a lot more latency.\n\n103\n00:04:58.740 --> 00:05:04.880\nSo that could be a factor when it comes to\nlocation selection, distance in general.\n\n104\n00:05:04.880 --> 00:05:08.170\nNow other things that I would say than\nlocation selection that I want you to keep\n\n105\n00:05:08.170 --> 00:05:12.600\naware of is the preparedness\nof the site itself, right?\n\n106\n00:05:12.600 --> 00:05:14.180\nAnd why do I mean that?\n\n107\n00:05:14.180 --> 00:05:18.910\nWell you might have to deploy\na crew to the secondary site.\n\n108\n00:05:18.910 --> 00:05:20.900\nAnd if it takes them a long\ntime to get there, well,\n\n109\n00:05:20.900 --> 00:05:22.170\nare you actually helping yourself?\n\n110\n00:05:22.170 --> 00:05:26.180\nSo you're spending the money on a warm\nsite with some primary functions, but\n\n111\n00:05:26.180 --> 00:05:28.160\nit takes your crew\na while to get there and\n\n112\n00:05:28.160 --> 00:05:31.680\nessentially what you're doing is\nyou're paying for a warm site, but\n\n113\n00:05:31.680 --> 00:05:34.140\nyour reaction time is really\nnothing better than a cold side.\n\n114\n00:05:34.140 --> 00:05:38.400\nSo again you just have to kind of\nweigh the pros and cons of that.\n\n115\n00:05:38.400 --> 00:05:42.385\nObviously location selection that we've\nbeen talking about everything's cost\n\n116\n00:05:42.385 --> 00:05:44.580\n,really everything's cost, right?\n\n117\n00:05:44.580 --> 00:05:47.900\nWe could have a whole bunch\nof secondary sites, right?\n\n118\n00:05:47.900 --> 00:05:50.780\nTertiary sites, we could have all kinds\nof sites if we had money to throw at and\n\n119\n00:05:50.780 --> 00:05:53.810\nsee also to think about the cost as well.\n\n120\n00:05:53.810 --> 00:05:56.505\nAll right,\naccessibility of the site, right?\n\n121\n00:05:56.505 --> 00:06:00.790\nThat is going to also hinder, or you\nshould be taking it into consideration.\n\n122\n00:06:00.790 --> 00:06:02.950\nHow accessible is the secondary site,\nright?\n\n123\n00:06:02.950 --> 00:06:04.590\nWe were kinda joking\naround in the chatroom.\n\n124\n00:06:04.590 --> 00:06:05.840\nWe have a little picture of a mountain.\n\n125\n00:06:05.840 --> 00:06:08.550\nAnd yeah, you were right, we could put\na server closet up on that mountain.\n\n126\n00:06:08.550 --> 00:06:09.380\nBut the problem is,\n\n127\n00:06:09.380 --> 00:06:13.421\nif that's our secondary site,\nhow many people have their hiking license?\n\n128\n00:06:13.421 --> 00:06:14.977\n[LAUGH] Right?\nMaybe not many.\n\n129\n00:06:14.977 --> 00:06:18.870\nSo we've essentially haven't\ndone ourselves a lot of justice.\n\n130\n00:06:18.870 --> 00:06:22.065\nSo again, accessibility is also\nsomething that we have to consider too,\n\n131\n00:06:22.065 --> 00:06:23.480\nbecause if you do have a,\n\n132\n00:06:23.480 --> 00:06:27.080\nmaybe you have a secondary site that's a\nbuilding out in the middle of a cow town.\n\n133\n00:06:27.080 --> 00:06:28.620\nHow long is it gonna\ntake people to get there?\n\n134\n00:06:28.620 --> 00:06:30.620\nHow long is it gonna take people to react,\nright?\n\n135\n00:06:30.620 --> 00:06:32.990\nSo those are considerations too.\n\n136\n00:06:32.990 --> 00:06:35.430\nThe other thing that we have\nto consider too is our RTO.\n\n137\n00:06:35.430 --> 00:06:38.020\nNow this is more in things like\nbusiness impact analysis, but\n\n138\n00:06:38.020 --> 00:06:40.650\nwe also have our recovery time objective,\nright?\n\n139\n00:06:40.650 --> 00:06:44.900\nAnd with our recovery time objective,\nwhat is the ideal time that is needed to\n\n140\n00:06:44.900 --> 00:06:50.780\nrestore a functionality or service\nbefore we just cannot recover, right?\n\n141\n00:06:50.780 --> 00:06:53.724\nBefore the business loses it's continuity,\nright?\n\n142\n00:06:53.724 --> 00:06:55.610\nSo that's your RTO.\n\n143\n00:06:55.610 --> 00:07:00.324\nRTO essentially is the maximum amount of\ntime before an organization is negatively\n\n144\n00:07:00.324 --> 00:07:03.371\nor adversely affected by\nsome kind of interruption.\n\n145\n00:07:03.371 --> 00:07:05.775\nThat's your RTO,\nyour recovery time objective.\n\n146\n00:07:05.775 --> 00:07:08.195\n&gt;&gt; One one hundredth\nof a millionth second.\n\n147\n00:07:08.195 --> 00:07:09.185\n&gt;&gt; That's right, that's right.\n\n148\n00:07:09.185 --> 00:07:10.506\nAnd I can't measure that at all [LAUGH].\n\n149\n00:07:10.506 --> 00:07:12.165\n&gt;&gt; No, I can't.\n\n150\n00:07:12.165 --> 00:07:14.255\n&gt;&gt; The other thing that's also there too,\nagain,\n\n151\n00:07:14.255 --> 00:07:17.055\na lot of times you'll see this more\nin your business impact analysis.\n\n152\n00:07:17.055 --> 00:07:19.835\nBut when we're talking about\nlocations selection recovery and\n\n153\n00:07:19.835 --> 00:07:22.595\nthe time that it takes to recover\nis something that's important.\n\n154\n00:07:22.595 --> 00:07:24.425\nBut you also have your RPO, right?\n\n155\n00:07:24.425 --> 00:07:25.645\nYour recovery point objective.\n\n156\n00:07:25.645 --> 00:07:28.535\nNow your recovery point objective\nbasically is focused on the amount of\n\n157\n00:07:28.535 --> 00:07:31.630\ndata loss that's acceptable or\nallowable, right?\n\n158\n00:07:31.630 --> 00:07:34.320\nAnd what I mean by that is,\ncan you afford?\n\n159\n00:07:34.320 --> 00:07:38.390\nLet's take it back to the first part\nof this episode, where we talked about,\n\n160\n00:07:38.390 --> 00:07:42.100\nI had a failure on Friday, all right?\n\n161\n00:07:42.100 --> 00:07:47.029\nWell, I potentially lost 24 hours of data,\nright?\n\n162\n00:07:47.029 --> 00:07:48.692\nThat's your recovery point objective.\n\n163\n00:07:48.692 --> 00:07:49.622\nIs that allowable?\n\n164\n00:07:49.622 --> 00:07:50.634\nCan you afford?\n\n165\n00:07:50.634 --> 00:07:54.389\nAnd I don't know,\ncan you afford to lose 24 hours of data?\n\n166\n00:07:54.389 --> 00:07:58.528\nMaybe your company is more sensitive and\nyou can only lose four hours, right?\n\n167\n00:07:58.528 --> 00:08:03.493\nSo that means your recovery time objective\nis to make sure that you're backing\n\n168\n00:08:03.493 --> 00:08:06.350\nup every four hours, right?\n\n169\n00:08:06.350 --> 00:08:10.810\nSo again, the maximum tolerable period\nin which data can be lost, right?\n\n170\n00:08:10.810 --> 00:08:12.550\nWhat is your backup frequency?\n\n171\n00:08:12.550 --> 00:08:14.270\nAll things to keep in mind too.\n\n172\n00:08:15.400 --> 00:08:17.764\nAll right, then we have well,\nthe legalities, right.\n\n173\n00:08:17.764 --> 00:08:19.856\n[LAUGH] And legalities can be a problem.\n\n174\n00:08:19.856 --> 00:08:21.050\n&gt;&gt; Bring in the lawyers.\n\n175\n00:08:21.050 --> 00:08:23.567\n&gt;&gt; That's right, we get a team of lawyers,\nwe throw money at it and\n\n176\n00:08:23.567 --> 00:08:24.931\nhopefully everything goes away.\n\n177\n00:08:24.931 --> 00:08:26.714\nBut [LAUGH] all joking aside, guys,\n\n178\n00:08:26.714 --> 00:08:30.518\nprivacy is one thing that becomes a\nchallenge when you talk about things like\n\n179\n00:08:30.518 --> 00:08:33.027\ndata retention and\ngeographical distribution.\n\n180\n00:08:33.027 --> 00:08:35.179\nWatch out,\nI'll give you a case in example, right?\n\n181\n00:08:35.179 --> 00:08:39.676\nJurisdiction changes, depending on\nwhere you're data's at rest, right?\n\n182\n00:08:39.676 --> 00:08:43.435\nSo let's say that we're a company and we\nhave servers in the EU that are controlled\n\n183\n00:08:43.435 --> 00:08:45.135\nand governed by the European Union.\n\n184\n00:08:45.135 --> 00:08:47.020\nWe have some here in the States, right.\n\n185\n00:08:47.020 --> 00:08:49.970\nHIPAA compliance, that has nothing\nto do with the European Union.\n\n186\n00:08:49.970 --> 00:08:53.890\nSo what happens when your data\nis moved between servers?\n\n187\n00:08:53.890 --> 00:08:56.430\nWell, let me give you a reverse scenario,\nright?\n\n188\n00:08:56.430 --> 00:09:01.540\nThat's US going to Europe,\nUK, if you will, all right?\n\n189\n00:09:01.540 --> 00:09:05.490\nSo there is a law, and\nit's still in place,\n\n190\n00:09:05.490 --> 00:09:11.140\nthat European Union says,\nEuropean users cannot have their PII, and\n\n191\n00:09:11.140 --> 00:09:17.480\nI mean personally identifiable information\nstored on foreign servers, all right.\n\n192\n00:09:17.480 --> 00:09:19.450\nWell they tried to kind\nof mitigate this right,\n\n193\n00:09:19.450 --> 00:09:22.830\nso the United States got together with\nthe European Union and they came up for\n\n194\n00:09:22.830 --> 00:09:26.660\nawhile with something known as\nthe USEU Safe Harbor Program.\n\n195\n00:09:26.660 --> 00:09:29.450\nAnd what this meant is\nthat working with the EU,\n\n196\n00:09:29.450 --> 00:09:33.800\nthe US they came up with regulations\nthat said there was allowed\n\n197\n00:09:33.800 --> 00:09:38.460\nstoring of European user's private\ninformation, here's the problem.\n\n198\n00:09:38.460 --> 00:09:42.410\nThis guy by Edward Snowden came out and\nreleased in leaks and\n\n199\n00:09:42.410 --> 00:09:46.840\ndata that the NSA was\nspying on US based servers.\n\n200\n00:09:46.840 --> 00:09:49.310\nWhat do you think the European Union\nhad to say about that?\n\n201\n00:09:49.310 --> 00:09:50.010\n&gt;&gt; They weren't very happy.\n\n202\n00:09:50.010 --> 00:09:51.080\n&gt;&gt; They were not very happy.\n\n203\n00:09:51.080 --> 00:09:53.868\n&gt;&gt; No.\n&gt;&gt; They've invalidated that safe harbor\n\n204\n00:09:53.868 --> 00:09:56.797\nprogram, it's no longer, can not use it.\n\n205\n00:09:56.797 --> 00:09:59.439\nWhen that came to fruition,\nwhen we learned about that,\n\n206\n00:09:59.439 --> 00:10:02.040\neverybody learned about,\nthe world learned about it.\n\n207\n00:10:02.040 --> 00:10:05.043\nThe European Union said, wait a second, so\n\n208\n00:10:05.043 --> 00:10:09.221\nwe got together with you to safe\nharbor this private information and\n\n209\n00:10:09.221 --> 00:10:14.360\nto come up with the standards to\nmake sure that it remained private.\n\n210\n00:10:14.360 --> 00:10:17.270\nAnd you got an organization out there\nthat's spying on all those servers.\n\n211\n00:10:17.270 --> 00:10:20.240\nWell that's a violation of what\nthis agreement was it's invalidate.\n\n212\n00:10:20.240 --> 00:10:22.330\nSo you have to worry about that right?\n\n213\n00:10:22.330 --> 00:10:27.150\nBecause if your data is geographically\ndispersed, you have local laws.\n\n214\n00:10:27.150 --> 00:10:29.300\nYou have state laws, well,\nhere in the United States.\n\n215\n00:10:29.300 --> 00:10:31.330\nAnd then you have federal laws, right?\n\n216\n00:10:31.330 --> 00:10:34.266\nThen you have international laws,\nand then you have foreign laws.\n\n217\n00:10:34.266 --> 00:10:36.690\nWell, what's the difference\nbetween international and foreign?\n\n218\n00:10:36.690 --> 00:10:40.660\nInternational, you can see things like the\nInternational Telecommunications Union,\n\n219\n00:10:40.660 --> 00:10:42.840\nthe International Organization\nof Standardization,\n\n220\n00:10:42.840 --> 00:10:46.060\ninternational bodies that get together and\nthey standardize this.\n\n221\n00:10:46.060 --> 00:10:49.900\nForeign regulations our form to you,\n\n222\n00:10:49.900 --> 00:10:54.430\nthat means there's no inter departmental\nlike interoperability, right?\n\n223\n00:10:54.430 --> 00:10:56.019\nWhy we have international standards?\n\n224\n00:10:56.019 --> 00:10:59.770\nThat means that you're gonna to follow\nwhatever their jurisdictions is.\n\n225\n00:10:59.770 --> 00:11:01.790\nSo that's something that\nwe have keep in mind.\n\n226\n00:11:01.790 --> 00:11:04.480\nAnd privacy is one of the biggest\nconcerns whether become personal\n\n227\n00:11:04.480 --> 00:11:06.040\nidentifiable information.\n\n228\n00:11:06.040 --> 00:11:08.570\nOr things like protected\nhealthcare information, right?\n\n229\n00:11:08.570 --> 00:11:12.862\nThose are two of the biggest\nones that we think about, and\n\n230\n00:11:12.862 --> 00:11:18.333\nthat leads us into the next category\nthat's known as data sovereignty.\n\n231\n00:11:18.333 --> 00:11:20.237\nThe jurisdiction, or if you will,\n\n232\n00:11:20.237 --> 00:11:24.970\nthe protection of that data is really\nbased on the laws of where it resides.\n\n233\n00:11:24.970 --> 00:11:27.400\nAnd why is that such a big deal?\n\n234\n00:11:27.400 --> 00:11:30.390\nWell, I want you to think, you don't have\nto be a big company anymore to have your\n\n235\n00:11:30.390 --> 00:11:33.730\ninformation stored in two completely\ndifferent geographical locations.\n\n236\n00:11:33.730 --> 00:11:35.880\nYou say, well I don't work for\na data center.\n\n237\n00:11:35.880 --> 00:11:36.910\nMaybe you don't.\n\n238\n00:11:36.910 --> 00:11:39.780\nBut do you work for a company that\nstores their data in the cloud?\n\n239\n00:11:39.780 --> 00:11:41.600\nDo you know where those servers are?\n\n240\n00:11:41.600 --> 00:11:48.396\nYou better, because it could have\nimplications on compliance and regulation.\n\n241\n00:11:48.396 --> 00:11:52.861\nSo data sovereignty is essentially the\nconcept that the information that's being\n\n242\n00:11:52.861 --> 00:11:56.941\nconverted or stored in a binary format\nis subject to the laws of the country in\n\n243\n00:11:56.941 --> 00:11:58.760\nwhich it's stored.\n\n244\n00:11:58.760 --> 00:12:01.120\nAll right,\nwhich is also all tied together,\n\n245\n00:12:01.120 --> 00:12:04.720\na lot of these concepts are all\nsitting their shaking hands together.\n\n246\n00:12:04.720 --> 00:12:09.502\nSo that also goes along with things like\nlegal implementation or implications,\n\n247\n00:12:09.502 --> 00:12:10.005\nright?\n\n248\n00:12:10.005 --> 00:12:15.320\nSo do keep those in mind, that it is very,\nvery important where the data resides.\n\n249\n00:12:15.320 --> 00:12:18.360\n&gt;&gt; Which makes it very important that\nyou have a good legal department.\n\n250\n00:12:18.360 --> 00:12:18.960\n&gt;&gt; Yes, you do.\n\n251\n00:12:18.960 --> 00:12:23.585\nAnd we talked about, Zach, in other\nepisodes, about training and awareness.\n\n252\n00:12:23.585 --> 00:12:25.470\n&gt;&gt; Right.\n&gt;&gt; At a very cyclic and redundant process,\n\n253\n00:12:25.470 --> 00:12:27.530\nbecause things are changing every day.\n\n254\n00:12:27.530 --> 00:12:30.741\nA law or a statute that you had\ntoday might be gone tomorrow,\n\n255\n00:12:30.741 --> 00:12:33.311\nmight be adjusted a little\nbit to compensate for\n\n256\n00:12:33.311 --> 00:12:36.475\nmaybe something that wasn't\ntaken into consideration.\n\n257\n00:12:36.475 --> 00:12:39.793\nAnd that's why security training and\nawareness are important,\n\n258\n00:12:39.793 --> 00:12:41.695\nwhich is probably why you're here.\n\n259\n00:12:41.695 --> 00:12:42.398\n[LAUGH]\n&gt;&gt; And\n\n260\n00:12:42.398 --> 00:12:45.790\nit's just like an ounce of\nprevention worth about a cure.\n\n261\n00:12:45.790 --> 00:12:52.269\nWhat's the best way to plan for disaster\nand to plan for business continuity?\n\n262\n00:12:52.269 --> 00:12:55.240\n&gt;&gt; Is using individual methods, right?\n\n263\n00:12:55.240 --> 00:12:58.430\nThere's many different techniques\nthat they have out there.\n\n264\n00:12:58.430 --> 00:13:02.395\nOne of the techniques that they call out\non the exam when it comes to continuity of\n\n265\n00:13:02.395 --> 00:13:05.073\noperations are exercises and\ntable top, all right?\n\n266\n00:13:05.073 --> 00:13:09.000\nTable tops if you will, and\nthey talk about table top, but\n\n267\n00:13:09.000 --> 00:13:11.735\nexercises are more of an umbrella term.\n\n268\n00:13:11.735 --> 00:13:13.195\nAnd there's different types,\n\n269\n00:13:13.195 --> 00:13:15.840\nclassifications of\nexercises you can run into.\n\n270\n00:13:15.840 --> 00:13:17.560\nSo let's go ahead and be generic first.\n\n271\n00:13:17.560 --> 00:13:19.424\nAnd then we'll get a little\nbit more specific or\n\n272\n00:13:19.424 --> 00:13:21.630\npacific, as a friend of mine used to say-\n&gt;&gt; Awesome.\n\n273\n00:13:21.630 --> 00:13:23.810\n&gt;&gt; When it comes to Tabletop, all right?\n\n274\n00:13:23.810 --> 00:13:26.296\nSo exercises, what do they help us do?\n\n275\n00:13:26.296 --> 00:13:29.815\nAll right, well, let's step it back and\nremember maybe some of you out there were\n\n276\n00:13:29.815 --> 00:13:32.008\nin grade school when you\nwere running fire drills,\n\n277\n00:13:32.008 --> 00:13:34.030\nalready running fire drills, right.\n\n278\n00:13:34.030 --> 00:13:38.750\nWell, the patience of saints that\nare called your teachers, right?\n\n279\n00:13:38.750 --> 00:13:42.410\nThat had the patience of saints, wanted\nto get all these unruly kids together,\n\n280\n00:13:42.410 --> 00:13:43.970\nget them in an organized line so\n\n281\n00:13:43.970 --> 00:13:47.850\nthat if they had to vacate the building,\nthey could do it in a timely fashion.\n\n282\n00:13:47.850 --> 00:13:51.390\nWell, that is why you run through\nexercises in business continuity.\n\n283\n00:13:51.390 --> 00:13:55.516\nIt's making sure, if you will, testing out\nyour BCP, your business continuity plan.\n\n284\n00:13:55.516 --> 00:13:58.410\nIn a non-threatening emergency.\n\n285\n00:13:58.410 --> 00:14:01.490\nRemember, you don't want to wait till\nyou need your backups, to find out and\n\n286\n00:14:01.490 --> 00:14:02.840\nvalidate that they're there.\n\n287\n00:14:02.840 --> 00:14:06.694\nYou don't want to wait until there is\na disaster to find out if your disaster\n\n288\n00:14:06.694 --> 00:14:08.468\nrecovery plan as part of your BCP,\n\n289\n00:14:08.468 --> 00:14:12.589\nyour Business Continuity Plan, is going\nto actually work for you, all right?\n\n290\n00:14:12.589 --> 00:14:16.559\nIt's good for among other things,\nemployee training and preparation and\n\n291\n00:14:16.559 --> 00:14:17.700\nawareness, right.\n\n292\n00:14:17.700 --> 00:14:19.600\nWhat do we need to be aware of?\n\n293\n00:14:19.600 --> 00:14:22.330\nWe need to be aware of the roles and\nresponsibilities that each\n\n294\n00:14:22.330 --> 00:14:25.740\nend user might have in the case\nthat a disaster happens, all right.\n\n295\n00:14:25.740 --> 00:14:28.140\nSo that's one of the things, all right?\n\n296\n00:14:28.140 --> 00:14:31.350\nOther things that they're good for\nis evaluation of the effectiveness or\n\n297\n00:14:31.350 --> 00:14:34.610\npreparedness of your BCP,\nyour Business Continuity Plan.\n\n298\n00:14:34.610 --> 00:14:36.050\nHow well are you prepared?\n\n299\n00:14:36.050 --> 00:14:37.300\nWhat's the effectiveness?\n\n300\n00:14:37.300 --> 00:14:38.648\nWhen you implemented it,\n\n301\n00:14:38.648 --> 00:14:42.780\ndid you have any credicalities in\nit that you might need to change?\n\n302\n00:14:42.780 --> 00:14:44.430\nWell, you might have to peek and tweak.\n\n303\n00:14:44.430 --> 00:14:46.870\nIdentifying things like\ndeficiencies within the steps.\n\n304\n00:14:46.870 --> 00:14:51.242\nWithin your, the work flow if you will,\nthe process.\n\n305\n00:14:51.242 --> 00:14:53.670\nAnd again, roles and\nresponsibilities are important.\n\n306\n00:14:53.670 --> 00:14:55.150\nSo it gives you a clear understanding,\n\n307\n00:14:55.150 --> 00:14:58.580\nand your employees a clear understanding\nof what their responsibility is.\n\n308\n00:14:58.580 --> 00:14:59.590\nShould a disaster happen.\n\n309\n00:15:00.670 --> 00:15:04.610\nIn proof coordination, this goes back to\nthe ones we started with the analogy,\n\n310\n00:15:04.610 --> 00:15:07.160\nthe teacher, teachers if you will.\n\n311\n00:15:07.160 --> 00:15:09.970\nThen you got the dean over everybody,\npoor dean trying to\n\n312\n00:15:09.970 --> 00:15:13.070\nfigure out how to get everybody\nout of the building right in time.\n\n313\n00:15:13.070 --> 00:15:15.860\nBut again, that's what it does,\nit helps improve the coordination.\n\n314\n00:15:15.860 --> 00:15:16.380\nAnd finally,\n\n315\n00:15:16.380 --> 00:15:20.700\nit helps you to access the capabilities\nof the existing resources that you have.\n\n316\n00:15:20.700 --> 00:15:22.830\nDo you need to spend\nmoney on more resources?\n\n317\n00:15:22.830 --> 00:15:24.920\nWas your hot site as hot as you thought?\n\n318\n00:15:24.920 --> 00:15:26.060\nAs warm as you thought?\n\n319\n00:15:26.060 --> 00:15:28.440\nDepending, or did you find out\nyou're paying for a warm site, and\n\n320\n00:15:28.440 --> 00:15:30.100\nyou actually got\nthe performance of a cold site?\n\n321\n00:15:31.130 --> 00:15:33.845\nWell now you might have to look at the\nservice level agree with whatever contract\n\n322\n00:15:33.845 --> 00:15:35.675\nyou have cuz they might have to\nrethink the cost, all right?\n\n323\n00:15:35.675 --> 00:15:39.155\nAnd that leads us to table top, right?\n\n324\n00:15:39.155 --> 00:15:45.624\nSo exercises in general, keep in mind they\nare, that's the umbrella term, all right?\n\n325\n00:15:45.624 --> 00:15:50.623\nThey call out tabletops, but you have\nother types of exercises like a functional\n\n326\n00:15:50.623 --> 00:15:53.500\nexercise too to give you\ntwo different kinds.\n\n327\n00:15:53.500 --> 00:15:54.922\nSo what is the tabletop?\n\n328\n00:15:54.922 --> 00:15:58.094\nTabletop is like the round table,\nI want you to think about the Knights of\n\n329\n00:15:58.094 --> 00:16:01.734\nthe Round Table, when King Arthur would\nsit those Knights of the Round Table down,\n\n330\n00:16:01.734 --> 00:16:04.509\nwhat were they doing They were\ndiscussing important matters.\n\n331\n00:16:04.509 --> 00:16:07.207\nWell I want you to think that it's able\nto help exercise that's what it is is,\n\n332\n00:16:07.207 --> 00:16:08.830\nit's an open discussion.\n\n333\n00:16:08.830 --> 00:16:12.560\nRight, it's an informal sessions\nbetween the team members\n\n334\n00:16:12.560 --> 00:16:16.090\nthat are part of the business continuity\nplan and disaster recovery process.\n\n335\n00:16:16.090 --> 00:16:20.090\nIt can be typically completed\nin no more than two hours, and\n\n336\n00:16:20.090 --> 00:16:22.250\nagain these aren't hard\nlimits by any means, but\n\n337\n00:16:22.250 --> 00:16:25.390\nit can be accomplished in\nabout two hours or so, right.\n\n338\n00:16:25.390 --> 00:16:28.590\nAnd you can contrast that to like\na functional exercise, right,\n\n339\n00:16:28.590 --> 00:16:34.280\na functional exercise allows the personal\nto validate each component, right.\n\n340\n00:16:34.280 --> 00:16:39.280\nFunctional exercise, we're validating each\ncomponent of the business continuity plan.\n\n341\n00:16:39.280 --> 00:16:40.120\nWe're in a tabletop.\n\n342\n00:16:40.120 --> 00:16:41.650\nWe're brainstorming.\n\n343\n00:16:41.650 --> 00:16:43.570\nWe've got all the pieces\nup there on table and\n\n344\n00:16:43.570 --> 00:16:46.950\nwe're kind of having open discussion on\nwhat we need to do, what is in place,\n\n345\n00:16:46.950 --> 00:16:50.660\nwhat isn't in place,\nwhat needs to be improved.\n\n346\n00:16:50.660 --> 00:16:55.025\nSo, tabletop exercises are another one\nof those open discussions that happen in\n\n347\n00:16:55.025 --> 00:16:59.131\na non threatening manner so that you\ncan get prepared ahead of the disaster,\n\n348\n00:16:59.131 --> 00:17:01.570\nremember ahead of the disaster.\n\n349\n00:17:01.570 --> 00:17:02.956\nThat's a big thing.\n\n350\n00:17:02.956 --> 00:17:07.332\n&gt;&gt; That's an ounce of prevention,\npound of cure thing again.\n\n351\n00:17:07.332 --> 00:17:10.185\n&gt;&gt; Most definitely you could kind of see\nthat reoccurring theme happening here.\n\n352\n00:17:10.185 --> 00:17:11.276\n&gt;&gt; Grandma was always right.\n\n353\n00:17:11.276 --> 00:17:12.125\n&gt;&gt; Yeah, that's right.\n\n354\n00:17:12.125 --> 00:17:15.611\nExcept for when she was wrong and\nthen that was the second rule that said,\n\n355\n00:17:15.611 --> 00:17:16.534\nrefer to rule one.\n\n356\n00:17:16.534 --> 00:17:18.020\n&gt;&gt; [LAUGH] That's right.\n\n357\n00:17:18.020 --> 00:17:19.350\n&gt;&gt; Next thing they come up with,\n\n358\n00:17:19.350 --> 00:17:23.080\nthis is actually a term I've heard from\nsome of our military vets out there, AARs.\n\n359\n00:17:23.080 --> 00:17:26.707\nIn fact Zack, we were talking about\nthis in an institution that I used\n\n360\n00:17:26.707 --> 00:17:30.667\nto teach for, I had the pleasure of\nworking with some of our military vets.\n\n361\n00:17:30.667 --> 00:17:32.442\nAnd I always talk about debriefing,\n\n362\n00:17:32.442 --> 00:17:36.290\ndebriefing, debriefing then they started\ntalking about AAR AAR, all right?\n\n363\n00:17:36.290 --> 00:17:37.210\nSo what does that mean, right?\n\n364\n00:17:37.210 --> 00:17:39.230\nThat's after action review.\n\n365\n00:17:39.230 --> 00:17:42.070\nIt's essentially like a debriefing, right?\n\n366\n00:17:42.070 --> 00:17:47.170\nImagine having a professional\ndiscussion of an event, right?\n\n367\n00:17:47.170 --> 00:17:52.410\nAnd it's focused on the performance\nof how did we react to that event?\n\n368\n00:17:52.410 --> 00:17:54.280\nAnd how was the performance, right?\n\n369\n00:17:54.280 --> 00:17:58.850\nThink of it as kind of like\nan analytical retrospect, right?\n\n370\n00:17:58.850 --> 00:17:59.522\nAfter action.\n\n371\n00:17:59.522 --> 00:18:02.270\nWe're thinking to what had happened,\nright?\n\n372\n00:18:02.270 --> 00:18:03.880\nWhy did it happen?\n\n373\n00:18:03.880 --> 00:18:05.370\nWhere did it happen?\n\n374\n00:18:05.370 --> 00:18:06.750\nWho did it happen to?\n\n375\n00:18:06.750 --> 00:18:08.590\nAnd how did we react to it?\n\n376\n00:18:08.590 --> 00:18:12.460\nAll right, now a lot of times we\ncan't control the first three, but\n\n377\n00:18:12.460 --> 00:18:15.750\nwe can control the results\nof the fourth one.\n\n378\n00:18:15.750 --> 00:18:18.740\nProvided that we have adequate\ntime to perform things like\n\n379\n00:18:18.740 --> 00:18:22.130\ntable top exercises and AARs.\n\n380\n00:18:22.130 --> 00:18:25.490\nAll right,\nlast one that they talk about, actually,\n\n381\n00:18:25.490 --> 00:18:27.320\nthey talk about a couple of them here too.\n\n382\n00:18:27.320 --> 00:18:31.380\nOne is alternate processing location,\nguys this is just another,\n\n383\n00:18:31.380 --> 00:18:36.590\nreally a term for having an alternate\nlocation, an alternative site.\n\n384\n00:18:36.590 --> 00:18:40.080\nSo again, if you think about it your site\nis a datacenter and you need to process\n\n385\n00:18:40.080 --> 00:18:44.290\ninformation and that datacenter\ngoes offline, what do you do now?\n\n386\n00:18:44.290 --> 00:18:47.560\nWell, you hope you have\nan alternative backup site that\n\n387\n00:18:47.560 --> 00:18:50.330\nyou can continue to\nprocess your information.\n\n388\n00:18:50.330 --> 00:18:54.170\nLast, but not least,\nthey call out alternate business practice.\n\n389\n00:18:54.170 --> 00:18:56.430\nNow, what does this mean for us?\n\n390\n00:18:56.430 --> 00:18:57.820\nWell, I want you to\nthink about a situation.\n\n391\n00:18:57.820 --> 00:19:01.710\nIn fact, I got an example of this one\nwhere we had to do it quite a lot.\n\n392\n00:19:01.710 --> 00:19:06.670\nWhen I was a manager in a fast food\nrestaurant, there would be times when\n\n393\n00:19:06.670 --> 00:19:11.610\nour POS, point of sale system, would fail.\n\n394\n00:19:12.940 --> 00:19:17.330\nAnd you started to realize that there were\na lot of young kids that couldn't do basic\n\n395\n00:19:17.330 --> 00:19:21.290\nmath, right, cause they were\nused to the machine doing it.\n\n396\n00:19:21.290 --> 00:19:24.380\nSo, what does that have to do with\nalternate business practices.\n\n397\n00:19:24.380 --> 00:19:28.530\nWell, my normal business practices, I'd\nhave everybody ringing up on registers.\n\n398\n00:19:28.530 --> 00:19:32.410\nAnd we'd have an information system\nthat we couldn't allow us to handle our\n\n399\n00:19:32.410 --> 00:19:33.070\ntickets, right?\n\n400\n00:19:33.070 --> 00:19:35.560\nWe didn't actually have tickets\nuntil the receipt printed out.\n\n401\n00:19:36.710 --> 00:19:39.050\nBut the system would go offline.\n\n402\n00:19:39.050 --> 00:19:43.600\nSo we had to be flexible in\nchanging our normal day-to-day\n\n403\n00:19:43.600 --> 00:19:48.150\nbusiness operations to handle with,\nin our case, what was a disaster.\n\n404\n00:19:48.150 --> 00:19:51.250\nMaybe not on a large scale, but\nif you had to work for it for a while,\n\n405\n00:19:51.250 --> 00:19:53.900\nyou would know that it is a disaster.\n\n406\n00:19:53.900 --> 00:19:58.360\nSo we had to be flexible and\nflip to an alternative business type.\n\n407\n00:19:58.360 --> 00:20:01.290\nA model that we don't like,\nit's not the most efficient, but\n\n408\n00:20:01.290 --> 00:20:03.590\nremember we're talking about\ncontinuity of operations.\n\n409\n00:20:03.590 --> 00:20:06.630\nEven if you're limping along,\nyou can still get business done.\n\n410\n00:20:06.630 --> 00:20:08.490\nAnd that's one of the things\nyou have to keep in mind,\n\n411\n00:20:08.490 --> 00:20:12.610\nthat as a strategic planning,\nis to make sure that you have\n\n412\n00:20:12.610 --> 00:20:16.750\nan alternate business plan,\nin case you have reduced functionality.\n\n413\n00:20:16.750 --> 00:20:19.410\nHow do you continue with\nminimal functional when\n\n414\n00:20:19.410 --> 00:20:22.050\nyou have that reduction in what\nyour normal processes are?\n\n415\n00:20:22.050 --> 00:20:23.380\nYou have to be aware, and\n\n416\n00:20:23.380 --> 00:20:27.600\nyou have to take steps to make sure\nthat there's some type of continuity.\n\n417\n00:20:27.600 --> 00:20:33.920\nCuz keep in mind, there is a certain time,\na point of no return between a recovery,\n\n418\n00:20:33.920 --> 00:20:38.370\ntrying to recover and after that there\nis no way for your company to regain its\n\n419\n00:20:38.370 --> 00:20:41.500\nreputation and at that point your\ncompany goes out of business.\n\n420\n00:20:41.500 --> 00:20:44.020\nSo these are very important concepts.\n\n421\n00:20:44.020 --> 00:20:46.030\nNot only are the important\nconcepts on the exam,\n\n422\n00:20:46.030 --> 00:20:49.710\nbut they're gonna be important concepts in\nthe real world when it comes to security.\n\n423\n00:20:49.710 --> 00:20:53.400\n&gt;&gt; Awesome, so let's do a wrap-up of\na disaster recovery business continuity,\n\n424\n00:20:53.400 --> 00:20:54.490\njust a real quick wrap-up.\n\n425\n00:20:54.490 --> 00:20:57.250\n&gt;&gt; So keep in mind in this episode,\nwe've been talking a lot about\n\n426\n00:20:57.250 --> 00:21:02.100\nhow your company can continue to operate\neven if it's at a reduced functionality.\n\n427\n00:21:02.100 --> 00:21:03.660\nRemember things like your site types.\n\n428\n00:21:03.660 --> 00:21:06.250\nRemember your backup types for\nthe exam, as well.\n\n429\n00:21:06.250 --> 00:21:09.970\nRemember some of the geographical location\nconsiderations that we told you about.\n\n430\n00:21:09.970 --> 00:21:15.510\nIt is important to maintain a good\nworking knowledge of this on the exam.\n\n431\n00:21:15.510 --> 00:21:19.760\nAlso keep in mind legal implementation\nwhen your data resides across\n\n432\n00:21:19.760 --> 00:21:21.770\ngeographical boundaries.\n\n433\n00:21:21.770 --> 00:21:24.358\nIt is important that you understand\nthat wherever that data resides,\n\n434\n00:21:24.358 --> 00:21:29.160\nit's the local jurisdiction, the local\nlegal system or laws that are going to be\n\n435\n00:21:29.160 --> 00:21:32.900\nthe ones that you have to follow,\nwhen you're on foreign soil.\n\n436\n00:21:32.900 --> 00:21:35.700\nAlso, remember things like\nyour continuity of operations.\n\n437\n00:21:35.700 --> 00:21:38.470\nRemember, exercises, planning, training,\n\n438\n00:21:38.470 --> 00:21:44.080\npreparation, before the incident happens,\nbefore the disaster happens.\n\n439\n00:21:44.080 --> 00:21:47.040\nIt is not a good time to wait\nuntil the disaster happens and\n\n440\n00:21:47.040 --> 00:21:50.660\nthen try to figure out\nunder a lot of stress.\n\n441\n00:21:50.660 --> 00:21:53.140\nUnder a dire situation.\n\n442\n00:21:53.140 --> 00:21:55.320\nWhat it is that we have to do?\n\n443\n00:21:55.320 --> 00:21:59.550\nI would probably say that the last\nthings that I would think about is,\n\n444\n00:21:59.550 --> 00:22:04.960\nmake sure that your company has\nsomething in place to protect you.\n\n445\n00:22:04.960 --> 00:22:07.590\nAnd the reason I say that,\nis you guys are ones in billions.\n\n446\n00:22:07.590 --> 00:22:09.000\nYou can never be replaced.\n\n447\n00:22:09.000 --> 00:22:12.960\nAll of the software, hardware,\nbuildings that can be rebuilt.\n\n448\n00:22:12.960 --> 00:22:15.988\nYou guys cannot be rebuilt, all right?\n\n449\n00:22:15.988 --> 00:22:21.100\nAnd so awareness, preparation,\ntraining, and communication is gonna be\n\n450\n00:22:21.100 --> 00:22:25.450\nkey to the success of your business\nto maintaining its continuity.\n\n451\n00:22:25.450 --> 00:22:28.390\nAnd more importantly,\nwhen the worst happens,\n\n452\n00:22:28.390 --> 00:22:32.900\nhow do we restore our operations to\nnormal daily business functionality?\n\n453\n00:22:32.900 --> 00:22:33.770\n&gt;&gt; Thank you, Wes.\n\n454\n00:22:33.770 --> 00:22:35.700\nLike they say, practice,\npractice, practice.\n\n455\n00:22:35.700 --> 00:22:38.950\nAnd in this case,\ngo back to part one and then part two.\n\n456\n00:22:38.950 --> 00:22:41.530\nDisaster recovery, business continuity.\n\n457\n00:22:41.530 --> 00:22:44.734\nWell, I'm Zach Memos,\nyour host for Comptia Security+.\n\n458\n00:22:44.734 --> 00:22:47.540\nAnd for ITProTV, thanks for watching.\n\n459\n00:22:47.540 --> 00:22:48.190\n&gt;&gt; I'm Wes Bryan.\n\n460\n00:22:48.190 --> 00:22:50.500\n&gt;&gt; And we'll see you next time.\n\n461\n00:22:50.500 --> 00:22:56.601\n[MUSIC]\n\n462\n00:22:56.601 --> 00:22:59.456\nThank you for watching ITProTV.\n\n",
          "vimeoId": "217168951"
        },
        {
          "description": "In this show, Cherokee and Wes explain how to handle data past its useful life and and what one should consider whilst retaining data. They cover digital methods to dispose of data such as formatting and wiping as well as physical destruction methods. Tune in hear them cover other aspects of privacy as well.",
          "length": "1382",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-8-data_security_and_privacy-050317-PGM.00_00_11_22.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-8-data_security_and_privacy-050317-PGM.00_00_11_22.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-5-8-data_security_and_privacy-050317-PGM.00_00_11_22.Still001-sm.jpg",
          "title": "Data Security and Privacy",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:02.445\nWelcome to ITProTV,\nI'm your host, Don Pezet.\n\n2\n00:00:02.445 --> 00:00:05.742\n[CROSSTALK]\n\n3\n00:00:05.742 --> 00:00:08.226\n[MUSIC]\n\n4\n00:00:08.226 --> 00:00:11.651\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:11.651 --> 00:00:15.112\n&gt;&gt; Welcome, ladies and gentlemen,\nto your CompTIA Security+ series.\n\n6\n00:00:15.112 --> 00:00:17.132\nI'm your show host, Cherokee Boose.\n\n7\n00:00:17.132 --> 00:00:20.333\nIn this episode, we're gonna be\ntaking a look at data security and\n\n8\n00:00:20.333 --> 00:00:24.336\nprivacy settings, different types of\npractices that we may encounter when well,\n\n9\n00:00:24.336 --> 00:00:26.840\nwe need to extract of\nget rid of that data.\n\n10\n00:00:26.840 --> 00:00:29.160\nWith us today, back in studios,\nwe have Mr. Wes Bryan.\n\n11\n00:00:29.160 --> 00:00:30.490\nThank you for joining us today, Wes.\n\n12\n00:00:30.490 --> 00:00:31.890\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n13\n00:00:31.890 --> 00:00:37.120\nThat's right, a lot of controversy\naround storing things like\n\n14\n00:00:37.120 --> 00:00:39.690\nprivate health information, right,\npersonal health information,\n\n15\n00:00:39.690 --> 00:00:43.900\nPHI, and private identification\ninformation, right, PII.\n\n16\n00:00:43.900 --> 00:00:47.460\nSo, it's really gonna be just like\nCherokee said, it's gonna be about what we\n\n17\n00:00:47.460 --> 00:00:51.830\ndo with that data as it comes\nto the end of its life cycle.\n\n18\n00:00:51.830 --> 00:00:55.690\nSo we are going to look at things like\nways that we can eradicate the data, so\n\n19\n00:00:55.690 --> 00:00:58.470\nthat it doesn't fall\nin unauthorized hands.\n\n20\n00:00:58.470 --> 00:01:02.188\nOne of the first things that we are gonna\ntalk that is destruction of the media and\n\n21\n00:01:02.188 --> 00:01:04.770\nmedia sanitization, right.\n\n22\n00:01:04.770 --> 00:01:09.020\nWe've talked about, just briefly,\ndata sanitization in other episodes.\n\n23\n00:01:09.020 --> 00:01:11.860\nAnd what it comes down to is that we\n\n24\n00:01:11.860 --> 00:01:15.570\ncould clear our data just by going\ninto your operating system, and\n\n25\n00:01:15.570 --> 00:01:19.620\nwe can right click on a drive, if you're\nin Windows, and you could choose Format.\n\n26\n00:01:19.620 --> 00:01:24.710\nProblem is the high level formatting\ndoesn't really eradicate the data.\n\n27\n00:01:24.710 --> 00:01:26.670\nSee inside of your operating systems,\n\n28\n00:01:26.670 --> 00:01:30.200\nyou have typically what's known\nas a master file table, right.\n\n29\n00:01:30.200 --> 00:01:33.470\nAnd what you're doing when you do a high\nlevel format is you're just removing\n\n30\n00:01:33.470 --> 00:01:34.900\nthe pointer to the file itself.\n\n31\n00:01:34.900 --> 00:01:37.770\nSo it's kinda like the operating\nsystem just being blind to where it's\n\n32\n00:01:37.770 --> 00:01:39.260\nactually located.\n\n33\n00:01:39.260 --> 00:01:42.860\nHowever though, physically on the media,\nthe data is still there.\n\n34\n00:01:42.860 --> 00:01:44.400\nAnd that could be a problem, right?\n\n35\n00:01:44.400 --> 00:01:47.770\nThere's a lot of things that can\nbecome problematic with that,\n\n36\n00:01:47.770 --> 00:01:49.810\nespecially if you have things like,\nHIPAA compliance.\n\n37\n00:01:49.810 --> 00:01:52.570\nWe talked about secure\nstandards in another episode.\n\n38\n00:01:52.570 --> 00:01:54.200\nAnd if you have to follow,\n\n39\n00:01:54.200 --> 00:01:57.750\ncertain compliance regulations, this\ncan really get your company in trouble.\n\n40\n00:01:57.750 --> 00:02:00.410\nSo it's one of the things that we\nreally have to pay attention to.\n\n41\n00:02:00.410 --> 00:02:04.260\n&gt;&gt; Now Wes if we are talking about that\nphysical destruction I know you and\n\n42\n00:02:04.260 --> 00:02:06.800\nI before the show were talking\nabout things like Thermite and\n\n43\n00:02:06.800 --> 00:02:08.490\nsome really extreme measures.\n\n44\n00:02:08.490 --> 00:02:13.530\nBut not everyone has access to those\nlevels of destruction so to speak.\n\n45\n00:02:13.530 --> 00:02:16.820\nSo you got a lot of different\noptions here on the list here.\n\n46\n00:02:16.820 --> 00:02:17.890\n&gt;&gt; Most definitely.\n\n47\n00:02:17.890 --> 00:02:23.240\n&gt;&gt; So what would you recommend depending\non the different regulatory compliance,\n\n48\n00:02:23.240 --> 00:02:24.860\nwhat are we gonna be\ntaking a look at here?\n\n49\n00:02:24.860 --> 00:02:26.250\n&gt;&gt; Well, I tell you what,\nthat's a good start.\n\n50\n00:02:26.250 --> 00:02:28.050\nLet's talk about\nthe regulatory compliance.\n\n51\n00:02:28.050 --> 00:02:31.220\nAgain, keep in mind, as I have been\nstressing as we go through the security\n\n52\n00:02:31.220 --> 00:02:34.120\nclause, we've shown you some different\nstandards that are out there.\n\n53\n00:02:34.120 --> 00:02:35.360\nWe've talked about HIPAA.\n\n54\n00:02:35.360 --> 00:02:39.490\nWe've talked about PIA, TCI DSS and\nI don't think on the exam that they're\n\n55\n00:02:39.490 --> 00:02:42.960\nreally gonna want you to know\nthe specific codes that are out there.\n\n56\n00:02:42.960 --> 00:02:45.190\nBut, what we're trying to do is\nexpose you to the fact that,\n\n57\n00:02:45.190 --> 00:02:47.710\nhey, they are out there and\nthere are federal standards,\n\n58\n00:02:47.710 --> 00:02:51.290\nthere are information standards, and\nyour company might have to follow them.\n\n59\n00:02:51.290 --> 00:02:54.440\nWe've talked about a non-regulatory body,\nright, that NIST.\n\n60\n00:02:54.440 --> 00:02:57.480\nNIST is out there, the National Institute\nfor Standards and Technology.\n\n61\n00:02:57.480 --> 00:03:00.240\nInstitute of Standards and Technology,\nI believe is what it's called.\n\n62\n00:03:00.240 --> 00:03:02.050\nAnd they have some\ndocumentation out there.\n\n63\n00:03:02.050 --> 00:03:05.750\nIn fact, there is this called\nthe 800 series that we had mentioned\n\n64\n00:03:05.750 --> 00:03:07.290\nin a previous episode.\n\n65\n00:03:07.290 --> 00:03:08.940\nI think we were looking at 800-53.\n\n66\n00:03:08.940 --> 00:03:13.330\nWell there's all different codes that\nare at the end of that 800 suite.\n\n67\n00:03:13.330 --> 00:03:18.130\nAnd specifically there's one\nthat is 800-88 and I've actually\n\n68\n00:03:18.130 --> 00:03:21.270\ngot a document here that says, well I\nactually did a little research here.\n\n69\n00:03:21.270 --> 00:03:24.130\nAnd you can see that if you pull\nup things like the NIST 800-88,\n\n70\n00:03:24.130 --> 00:03:27.890\nit does give you the information\nthat you need when\n\n71\n00:03:27.890 --> 00:03:32.240\nit comes to eradicating your data, what\nare some of your requirements behind it,\n\n72\n00:03:32.240 --> 00:03:35.650\nand what is the level of sanitation\nthat you have to perform.\n\n73\n00:03:35.650 --> 00:03:39.735\nSo keep in mind that this is one of\nthe standards that is out there.\n\n74\n00:03:39.735 --> 00:03:42.228\nIn fact, there's other standards too,\nlike, for instance,\n\n75\n00:03:42.228 --> 00:03:44.750\nyou can get software that'll\nhelp you do this as well.\n\n76\n00:03:44.750 --> 00:03:49.400\nOne of the other standards' out there\nis the Department of Defense, and\n\n77\n00:03:49.400 --> 00:03:50.490\nit's the 5220-M standard.\n\n78\n00:03:50.490 --> 00:03:52.050\nAnd for instance, if you go to a third,\n\n79\n00:03:52.050 --> 00:03:56.030\nyou can always go to a third party right,\nand you can, this is, what is this?\n\n80\n00:03:56.030 --> 00:03:59.780\nThis is Active KillDisk, and again,\nthey tell you right away that hey,\n\n81\n00:03:59.780 --> 00:04:04.300\nwe are coming under compliance with\nthe Department of Defense standard.\n\n82\n00:04:04.300 --> 00:04:06.580\nNow what that means is it's a framework,\n\n83\n00:04:06.580 --> 00:04:09.670\nif you will, for\neradicating the information.\n\n84\n00:04:09.670 --> 00:04:14.860\nAnd there really isn't just\none size fits all right.\n\n85\n00:04:14.860 --> 00:04:17.990\nYou can see that they've got different\ntypes of media that they talk about right.\n\n86\n00:04:17.990 --> 00:04:22.630\nSo this is the way we eradicate data on\na magnetic tape might be, is gonna be\n\n87\n00:04:22.630 --> 00:04:26.800\na little bit different between a magnetic\ndisk, optical disk, memory if you will.\n\n88\n00:04:26.800 --> 00:04:30.210\nYou've got memory resident\ninformation as well.\n\n89\n00:04:30.210 --> 00:04:35.360\nSo, with the DoD standard,\nusually what it dictates is\n\n90\n00:04:35.360 --> 00:04:39.520\nthree passes, all right,\nover your magnetic media if you will.\n\n91\n00:04:39.520 --> 00:04:42.650\nAnd what you're doing,\nis you're typically writing a zero to\n\n92\n00:04:42.650 --> 00:04:46.030\nevery location on that platter,\non that physical medium.\n\n93\n00:04:46.030 --> 00:04:48.270\nAnd then you read, make sure,\n\n94\n00:04:48.270 --> 00:04:51.690\nyou verify that the zeroes have\nbeen written to the media.\n\n95\n00:04:51.690 --> 00:04:55.080\nThen, you go through\nthe process of writing a one to\n\n96\n00:04:55.080 --> 00:04:56.890\nevery location on the drive, right?\n\n97\n00:04:56.890 --> 00:04:59.220\nAnd then you do a verification\nthat the one has written, right?\n\n98\n00:04:59.220 --> 00:05:03.360\nWe want to ensure that those bits\nare getting written to the disk properly.\n\n99\n00:05:03.360 --> 00:05:07.406\nAnd then finally what they do is they\nspecify writing a random character to\n\n100\n00:05:07.406 --> 00:05:08.919\nevery portion on the disk.\n\n101\n00:05:08.919 --> 00:05:14.178\nAnd you have to understand that what\nthey're trying to do is they're trying\n\n102\n00:05:14.178 --> 00:05:19.356\nto layer up the information that is there\nso that even to certain extent like\n\n103\n00:05:19.356 --> 00:05:24.965\neven specialized laboratories wouldn't\nbe able to recover this information.\n\n104\n00:05:24.965 --> 00:05:27.885\nCuz like I said, if you think about it,\nif you do an overwrite one time,\n\n105\n00:05:27.885 --> 00:05:31.362\nwhat you're doing is you're just kind of\nlayering information over information.\n\n106\n00:05:31.362 --> 00:05:35.330\nBut if they've got specialized software\nthey can pick back those layers and\n\n107\n00:05:35.330 --> 00:05:37.545\npotentially recover this information.\n\n108\n00:05:37.545 --> 00:05:40.435\nSo this is why they have a standard\nlike that that calls for\n\n109\n00:05:40.435 --> 00:05:45.675\nthose three passes to ensure that even\nunder very specialized circumstances,\n\n110\n00:05:45.675 --> 00:05:48.260\nit's highly unlikely that\nthe data can be recovered.\n\n111\n00:05:48.260 --> 00:05:51.340\n&gt;&gt; Yeah, that's what I was gonna ask\nyou about, why are we doing this?\n\n112\n00:05:51.340 --> 00:05:56.858\nAnd it's because, well, if we think about\nthose clean rooms, that's not an average,\n\n113\n00:05:56.858 --> 00:06:00.610\nrun of the mill type of tool or\ntechnology that you would use,\n\n114\n00:06:00.610 --> 00:06:05.488\nbut in situations like homicides or\neven national national security issues.\n\n115\n00:06:05.488 --> 00:06:12.133\nThen they would be able to not just for\nyour regular data loss type situations but\n\n116\n00:06:12.133 --> 00:06:17.300\nto prevent the actual re,\nwhat's the word I'm looking for?\n\n117\n00:06:17.300 --> 00:06:22.770\nTo be able to obtain that information\nfrom that physically damaged disk.\n\n118\n00:06:22.770 --> 00:06:26.640\nWe need to go ahead and perform,\nmaybe even multiple steps,\n\n119\n00:06:26.640 --> 00:06:28.930\nbefore you physically destruct that disk,\nright?\n\n120\n00:06:28.930 --> 00:06:32.080\n&gt;&gt; That's right, because even a partial\ndestruction, and you're talking about,\n\n121\n00:06:32.080 --> 00:06:34.730\nI believe,\njust reorganizing the data, right?\n\n122\n00:06:34.730 --> 00:06:36.120\nI've got a piece of the information.\n\n123\n00:06:36.120 --> 00:06:37.261\n&gt;&gt; Reorganizing, there you go.\n\n124\n00:06:37.261 --> 00:06:39.037\n[LAUGH]\n&gt;&gt; Kinda transforming it back, and\n\n125\n00:06:39.037 --> 00:06:40.938\ntrying to get that information back and\npiece.\n\n126\n00:06:40.938 --> 00:06:42.109\n&gt;&gt; Yeah, piece it back together.\n\n127\n00:06:42.109 --> 00:06:46.540\n&gt;&gt; Exactly, so you can do that\neven if you're not careful, right?\n\n128\n00:06:46.540 --> 00:06:50.076\nSo what would be a situation in\nwhich I might want to make sure\n\n129\n00:06:50.076 --> 00:06:52.996\nthat the data is thoroughly sanitized,\nright.\n\n130\n00:06:52.996 --> 00:06:55.629\nIf you've got hard drives\nthat are gonna be recycled,\n\n131\n00:06:55.629 --> 00:06:59.350\nif you're gonna turn around and you're\ngonna reuse them in your company then\n\n132\n00:06:59.350 --> 00:07:02.680\nmost likely an overriding\nsolution's gonna do just fine.\n\n133\n00:07:02.680 --> 00:07:05.654\nBut if you're gonna take those drives and\nthey're at the end of their life and\n\n134\n00:07:05.654 --> 00:07:08.418\nlet's say you're gonna donate them\nto some nonprofit organization.\n\n135\n00:07:08.418 --> 00:07:12.958\nThe problem is there's trace remnants of\nthe information there that could be used\n\n136\n00:07:12.958 --> 00:07:15.950\nand could be collected,\nand again, reassembled.\n\n137\n00:07:15.950 --> 00:07:18.180\nI think that's the word we're looking for,\nis reassembled.\n\n138\n00:07:18.180 --> 00:07:22.140\nAnd kind of see, even the trace\nremnants of that information.\n\n139\n00:07:22.140 --> 00:07:24.350\nNow, I mentioned the NIST standard,\n\n140\n00:07:24.350 --> 00:07:27.830\nlet's get a little more specific\nin the NIST standard, right?\n\n141\n00:07:27.830 --> 00:07:32.868\nIt defines sanitation as the process\nto render the access to the target data\n\n142\n00:07:32.868 --> 00:07:39.330\ninfeasible, if you will, for\nany kind of given recovery effort.\n\n143\n00:07:39.330 --> 00:07:44.820\nNow, it also categorizes the actions that\nwe take to sanitize the information and\n\n144\n00:07:44.820 --> 00:07:49.255\nthey really break it down to\nthree different categories.\n\n145\n00:07:49.255 --> 00:07:50.845\nThat's clearing the information.\n\n146\n00:07:50.845 --> 00:07:54.469\nThat's purging the information and\nCherokee kinda hinted to this as well,\n\n147\n00:07:54.469 --> 00:07:57.470\nis the destruction of the physical\ndestruction of the media and\n\n148\n00:07:57.470 --> 00:07:58.785\nthat's destroy, right?\n\n149\n00:07:58.785 --> 00:08:02.620\nSo we have clear, we've got purge and\nwe have destroy, right?\n\n150\n00:08:02.620 --> 00:08:05.605\nClearing the information is\nbasic high level formatting.\n\n151\n00:08:05.605 --> 00:08:09.114\nRight, again, just using any of your\nformatting tools, could be formatting\n\n152\n00:08:09.114 --> 00:08:12.490\ntools that are built right into\nthe operating system themselves, right.\n\n153\n00:08:12.490 --> 00:08:17.815\nAnd the problem with it is, it can be\nrecovered but you have to understand that\n\n154\n00:08:17.815 --> 00:08:22.895\nit's the most non-invasive way to\nclear your media, unlike purging.\n\n155\n00:08:22.895 --> 00:08:26.128\nOkay, now purging, this is where\nthings like overwriters right\n\n156\n00:08:26.128 --> 00:08:28.203\nthat we're talking about come in handy.\n\n157\n00:08:28.203 --> 00:08:33.570\nDegaussers, again is something where\nit's scrambling the magnetic media.\n\n158\n00:08:33.570 --> 00:08:37.670\nAnd again, that applies to physical and\nlogical techniques, if you will,\n\n159\n00:08:37.670 --> 00:08:40.840\nthat basically renders\nthe target data recovery\n\n160\n00:08:42.320 --> 00:08:45.660\ninfeasible with state of\nthe art laboratories, right.\n\n161\n00:08:45.660 --> 00:08:49.410\nOnce we get to purging level, that's\nwhy we have those overwriting rules,\n\n162\n00:08:49.410 --> 00:08:52.480\nright, that says three passes.\n\n163\n00:08:52.480 --> 00:08:56.190\nAnd then lastly is the destruction,\nright, to destroy.\n\n164\n00:08:56.190 --> 00:08:59.590\nAnd what this does is it renders\nthe target data infeasible with state of\n\n165\n00:08:59.590 --> 00:09:04.860\nthe art techniques but with no\nability to continue to use the media.\n\n166\n00:09:04.860 --> 00:09:07.840\nSee, the first two,\nI could still use the media.\n\n167\n00:09:07.840 --> 00:09:10.730\nIf I clear it with high level formatting,\nI can still turn around and\n\n168\n00:09:10.730 --> 00:09:13.850\nput that hard drive back into a system and\nuse it again.\n\n169\n00:09:13.850 --> 00:09:17.300\nIf we do purging,\noverwriting if you will, degaussing.\n\n170\n00:09:17.300 --> 00:09:21.690\nThe data's rendered infeasible to recover\nwith state of the art laboratory, but\n\n171\n00:09:21.690 --> 00:09:23.490\nthe media itself is okay.\n\n172\n00:09:23.490 --> 00:09:26.500\nWe get to the last one,\nthe last one's the highest level\n\n173\n00:09:26.500 --> 00:09:31.020\nof data sanitization because it\nalso destroys the media, right.\n\n174\n00:09:31.020 --> 00:09:33.450\nWe don't wanna just recycle the media,\nin this case.\n\n175\n00:09:33.450 --> 00:09:36.630\nWe want to just completely eradicate it.\n\n176\n00:09:36.630 --> 00:09:40.200\nAll right, so, what are some of the\ntechniques that we have involved in this?\n\n177\n00:09:40.200 --> 00:09:41.570\nWell, we have burning, right?\n\n178\n00:09:41.570 --> 00:09:43.252\nBurning, now.\n\n179\n00:09:43.252 --> 00:09:44.960\nCouple different levels of burning,\nI guess.\n\n180\n00:09:44.960 --> 00:09:46.495\nIf you say burning, it could be paper.\n\n181\n00:09:46.495 --> 00:09:48.040\nPaper-based media, right?\n\n182\n00:09:48.040 --> 00:09:50.550\nAnd if we do paper-based\nmedia this could be burning.\n\n183\n00:09:50.550 --> 00:09:52.870\nIt could be shredding your information,\nright?\n\n184\n00:09:52.870 --> 00:09:53.490\nThere's standards.\n\n185\n00:09:53.490 --> 00:09:57.180\nYou have companies that come out on-site,\nand they literally,\n\n186\n00:09:57.180 --> 00:10:01.890\nthey'll leave you with a collection bin,\nright, that's usually locked.\n\n187\n00:10:01.890 --> 00:10:04.400\nAnd things can go in, but\nthey can't come out of that bin.\n\n188\n00:10:04.400 --> 00:10:07.590\nThey take it, they take it right\nthere in the parking lot sometimes,\n\n189\n00:10:07.590 --> 00:10:09.030\nthey do the destruction of the media.\n\n190\n00:10:09.030 --> 00:10:12.190\nAnd the shredder makes a certain\namount of passes across the paper so\n\n191\n00:10:12.190 --> 00:10:15.793\nthat you can't sit there and, well you\ngotta have a lot of duct tape, right?\n\n192\n00:10:15.793 --> 00:10:16.302\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n193\n00:10:16.302 --> 00:10:17.602\n&gt;&gt; Well, duct tape wouldn't work anyways.\n\n194\n00:10:17.602 --> 00:10:18.222\nYou have to have a lot of\n\n195\n00:10:18.222 --> 00:10:18.733\nScotch tape, right?\n&gt;&gt; [LAUGH]\n\n196\n00:10:18.733 --> 00:10:20.791\n&gt;&gt; To try to put it back together.\n\n197\n00:10:20.791 --> 00:10:22.922\nBut it's quarantined.\n\n198\n00:10:22.922 --> 00:10:24.782\nIt's isolated and quarantined, right?\n\n199\n00:10:24.782 --> 00:10:26.052\nSomebody's not gonna be able to come by\n\n200\n00:10:26.052 --> 00:10:28.132\nand say hey what you doing here?\nLet me go ahead and\n\n201\n00:10:28.132 --> 00:10:31.550\nlook at what you're doing.\nSo it's a very isolated process to ensure\n\n202\n00:10:31.550 --> 00:10:34.745\nthat your information isn't gonna\nend up in unauthorized hands.\n\n203\n00:10:34.745 --> 00:10:35.985\n&gt;&gt; Wes, you bring up a really good point.\n\n204\n00:10:35.985 --> 00:10:40.019\nBecause if we take all these\nprecautions to really secure, and\n\n205\n00:10:40.019 --> 00:10:42.311\nprotect our digital information.\n\n206\n00:10:42.311 --> 00:10:46.163\nThen we just leave any kind of paper,\nphysical information laying around,\n\n207\n00:10:46.163 --> 00:10:49.785\nthen that could be a huge problem,\njust from a little oversight there.\n\n208\n00:10:51.040 --> 00:10:53.345\nSome companies implement\nclean desk policies.\n\n209\n00:10:53.345 --> 00:10:55.415\nSo maybe that's something\nyou'd wanna look at, too.\n\n210\n00:10:55.415 --> 00:10:57.765\n&gt;&gt; Definitely.\nClean desk is one of the ways that you do.\n\n211\n00:10:57.765 --> 00:11:00.210\nWe don't want information\njust laying around.\n\n212\n00:11:00.210 --> 00:11:02.540\nThe other thing that I think of too is,\n\n213\n00:11:02.540 --> 00:11:06.688\nbad techniques where people leave\nsensitive information in a printer, right?\n\n214\n00:11:06.688 --> 00:11:10.380\nThey print to the printer and they walk\naway and somebody else is printing, right?\n\n215\n00:11:10.380 --> 00:11:11.275\nIt's not the only printer,\n\n216\n00:11:11.275 --> 00:11:13.250\n[LAUGH] it's not the only person\nprinting to that printer but\n\n217\n00:11:13.250 --> 00:11:15.840\nyou can have sensitive information\nthat's just left like that.\n\n218\n00:11:15.840 --> 00:11:18.576\nOther things that you can do other than\nshredding they also call out pulping.\n\n219\n00:11:18.576 --> 00:11:22.876\nAnd again, keep in mind, this is a little\nbit different because it's almost boiling\n\n220\n00:11:22.876 --> 00:11:25.730\nthe paper back down into moosh,\nif you will.\n\n221\n00:11:25.730 --> 00:11:29.700\nAgain, just another one of those things\nthat you can do in order to destroy things\n\n222\n00:11:29.700 --> 00:11:31.280\nlike paper media.\n\n223\n00:11:31.280 --> 00:11:33.900\nWe also have the degaussing\nthat I've kind of mentioned.\n\n224\n00:11:33.900 --> 00:11:37.285\nKeep in mind that with degaussing,\nthis is the purging technique, right?\n\n225\n00:11:37.285 --> 00:11:39.910\nDegaussing is a purging sanitization and\n\n226\n00:11:39.910 --> 00:11:42.230\nwhat it does is it typically\nuses a high-powered magnet.\n\n227\n00:11:42.230 --> 00:11:45.135\nSome kind of high-powered magnet or\n\n228\n00:11:45.135 --> 00:11:50.016\nmagnetic wave, if you will,\nin order to eradicate the data.\n\n229\n00:11:50.016 --> 00:11:51.771\nKeep in mind that degaussing?\n\n230\n00:11:51.771 --> 00:11:57.230\nIf we're taking about SSDs,\nyou have to be careful that flash-based\n\n231\n00:11:57.230 --> 00:12:01.772\nstorage the areas of the SSDs\nthat use non magnetic media.\n\n232\n00:12:01.772 --> 00:12:03.515\nThey use electrical media.\n\n233\n00:12:03.515 --> 00:12:07.622\nSo this isn't really a good solution\nif you will, for things, or\n\n234\n00:12:07.622 --> 00:12:10.034\ndata that's stored in\nnon-volatile memory regions.\n\n235\n00:12:11.042 --> 00:12:11.952\nWhat else do we have?\n\n236\n00:12:11.952 --> 00:12:14.565\nWiping, we've talked about that, right.\n\n237\n00:12:14.565 --> 00:12:17.780\nThat's data overwriting.\n\n238\n00:12:17.780 --> 00:12:21.457\nDegaussing can render the media unusable.\n\n239\n00:12:21.457 --> 00:12:24.147\nSo if you're wanting to reuse the media,\nright,\n\n240\n00:12:24.147 --> 00:12:27.616\nyou're in that purging category\nnot quite to the destruction?\n\n241\n00:12:27.616 --> 00:12:28.690\n&gt;&gt; Not a good option for you.\n\n242\n00:12:28.690 --> 00:12:30.590\n&gt;&gt; Probably not a good option,\nthat's right.\n\n243\n00:12:30.590 --> 00:12:34.920\nSo wiping, again,\nis just where it's overwriting, right.\n\n244\n00:12:34.920 --> 00:12:37.080\nWe have actually protocols that\nare built in to the drives,\n\n245\n00:12:37.080 --> 00:12:40.030\nthat allow us to do this as we're\nprovisioning for the first time, right.\n\n246\n00:12:40.030 --> 00:12:44.300\nMaybe you guys, coming over from\nA+ heard of secure erase, right.\n\n247\n00:12:44.300 --> 00:12:47.446\nWe do things like secure\nerase on your SSDs as well,\n\n248\n00:12:47.446 --> 00:12:50.826\nto ensure that the performance\nis a little bit better.\n\n249\n00:12:50.826 --> 00:12:53.672\nSo we have that that we\nhave to worry about, too.\n\n250\n00:12:53.672 --> 00:12:55.310\n&gt;&gt; What about labelling and handling?\n\n251\n00:12:55.310 --> 00:12:59.040\nSo, before we actually have to destroy\nour get rid of this information.\n\n252\n00:12:59.040 --> 00:13:01.015\n&gt;&gt; Yeah, that's a good thing, right?\n\n253\n00:13:01.015 --> 00:13:02.950\nWhat do we have to do\nto get rid of the data?\n\n254\n00:13:02.950 --> 00:13:07.660\nProbably [LAUGH] it depends on what level\nof classification the data is, right?\n\n255\n00:13:07.660 --> 00:13:12.041\nIf it's open, public information,\nunofficial public information that\n\n256\n00:13:12.041 --> 00:13:15.110\nsomebody can get off of a website,\nwell guess what?\n\n257\n00:13:15.110 --> 00:13:17.180\nMaybe we don't have to eradicate it,\nright?\n\n258\n00:13:17.180 --> 00:13:19.230\nMaybe we just throw it in the dumpster.\n\n259\n00:13:19.230 --> 00:13:23.090\nBut there are different levels, for\ninstance they have confidential.\n\n260\n00:13:23.090 --> 00:13:24.970\nWe talk about confidential information,\n\n261\n00:13:24.970 --> 00:13:28.790\nthat's information that is only\nused within the company itself.\n\n262\n00:13:28.790 --> 00:13:32.540\nAll right, now, keep in mind\nthat unauthorized disclosure of\n\n263\n00:13:32.540 --> 00:13:37.350\nconfidential information could have\na serious adverse effect on the company.\n\n264\n00:13:37.350 --> 00:13:42.493\nSome of the examples of\nconfidential-classed information.\n\n265\n00:13:42.493 --> 00:13:47.340\nTrade secrets,\nHIPA information, PII, PCI, and\n\n266\n00:13:47.340 --> 00:13:49.990\nlet me back up with not\nassuming you know the acronyms.\n\n267\n00:13:49.990 --> 00:13:51.620\nI'm feeding everybody alphabet soup, here.\n\n268\n00:13:51.620 --> 00:13:53.100\nJust trying to help you out, right?\n\n269\n00:13:53.100 --> 00:13:56.550\nSo personally identifiable information,\nprivate or\n\n270\n00:13:56.550 --> 00:13:58.480\npersonal healthcare information, right.\n\n271\n00:13:58.480 --> 00:14:03.080\nPCI, DSS, that's payment card industry\nif we're doing credit card transactions.\n\n272\n00:14:03.080 --> 00:14:07.560\nThis is confidential information, and if\nit's disclosed to unauthorized entities it\n\n273\n00:14:07.560 --> 00:14:10.250\ncould cause a serious\nproblem with your company.\n\n274\n00:14:11.810 --> 00:14:13.710\nBut then there's private information,\nright?\n\n275\n00:14:13.710 --> 00:14:17.690\nPrivate classification again is personal\ninformation that you use within inside\n\n276\n00:14:17.690 --> 00:14:19.700\nof the company.\n\n277\n00:14:19.700 --> 00:14:23.450\nDisclosure of this information\ncould affect the company, but\n\n278\n00:14:23.450 --> 00:14:25.820\nit can also affect an individual, right?\n\n279\n00:14:25.820 --> 00:14:31.090\nSo an individual within the company\nas well as the company as a whole.\n\n280\n00:14:31.090 --> 00:14:32.920\nWe've also got the public classification.\n\n281\n00:14:32.920 --> 00:14:35.100\nKeep in mind with\nthe public classification,\n\n282\n00:14:36.120 --> 00:14:41.320\nbasic attempts are made to\nopenly disclose the information.\n\n283\n00:14:41.320 --> 00:14:44.960\nOr not to publicly disclose\nthe information if you will.\n\n284\n00:14:44.960 --> 00:14:49.770\nBut if it is, it won't adversely\naffect the company or its employees.\n\n285\n00:14:49.770 --> 00:14:51.250\nWe've got a couple more, too.\n\n286\n00:14:51.250 --> 00:14:57.378\nProprietary, proprietary is one again that\ncould, if it's disclosed to the public.\n\n287\n00:14:57.378 --> 00:15:00.550\nIt could cost the company a great deal\nof money especially if they're working\n\n288\n00:15:00.550 --> 00:15:01.460\non something.\n\n289\n00:15:01.460 --> 00:15:04.190\nThat is the next latest and\ngreatest thing.\n\n290\n00:15:04.190 --> 00:15:06.660\nAgain, so we have to worry\nabout things like proprietary.\n\n291\n00:15:06.660 --> 00:15:10.640\nOther examples, not just trade secrets,\nthings like programming code.\n\n292\n00:15:10.640 --> 00:15:13.730\nIf you're a software development company,\nyour code, your source code is very,\n\n293\n00:15:13.730 --> 00:15:16.830\nvery important to your company as in\nongoing projects that you're working on.\n\n294\n00:15:16.830 --> 00:15:22.400\nSo, releasing that type of proprietary\ninformation could cause problems.\n\n295\n00:15:22.400 --> 00:15:24.640\nCould give your competitor a leg up.\n\n296\n00:15:24.640 --> 00:15:27.280\nSo, we want to keep that\ninformation secure, as well.\n\n297\n00:15:27.280 --> 00:15:31.060\n&gt;&gt; Now, Wes I know the topic of this\nparticular show it says privacy\n\n298\n00:15:31.060 --> 00:15:31.905\npractices and\n\n299\n00:15:31.905 --> 00:15:36.130\nin other episodes we also have covered a\nlot of things that fall under this realm.\n\n300\n00:15:36.130 --> 00:15:38.990\nFor instance,\nyou talk about this proprietary concept,\n\n301\n00:15:38.990 --> 00:15:42.610\nlike if you're working on iterations of\na new prototype, or something like that.\n\n302\n00:15:43.820 --> 00:15:46.130\nYou also have to think about\nthings like our mobile devices so\n\n303\n00:15:46.130 --> 00:15:49.720\npeople aren't randomly taking pictures and\ngetting information in the background.\n\n304\n00:15:49.720 --> 00:15:51.950\nYou mentioned the printer\nconcepts earlier.\n\n305\n00:15:51.950 --> 00:15:55.650\nSo it's not just one particular realm.\n\n306\n00:15:55.650 --> 00:15:57.938\nWe really have to think Holistically here.\n\n307\n00:15:57.938 --> 00:16:01.381\n&gt;&gt; Yeah, definitely, so\nin places that you don't expect,\n\n308\n00:16:01.381 --> 00:16:05.560\nyou don't look at a printer and\nsay that's a hard drive in it.\n\n309\n00:16:05.560 --> 00:16:09.625\nA lot of people people don't think, unless\nyou're working on them and you know, or\n\n310\n00:16:09.625 --> 00:16:12.212\nyou're working in IT in general,\nyou realize that.\n\n311\n00:16:12.212 --> 00:16:16.148\nBut the average end user doesn't realize\nthat when I print spool or works, spooling\n\n312\n00:16:16.148 --> 00:16:19.650\nthe job means writing it to the hard\ndrive before it's sent to the printer.\n\n313\n00:16:19.650 --> 00:16:20.680\nAnd if it's a network printer,\n\n314\n00:16:20.680 --> 00:16:23.830\nit means that sending it right to\nthe hard drive on the network printer.\n\n315\n00:16:23.830 --> 00:16:26.830\nLet alone the fact that data\ncould be stored in memory too.\n\n316\n00:16:26.830 --> 00:16:29.665\nSo again,\nkeep in mind that you have memory regions,\n\n317\n00:16:29.665 --> 00:16:32.507\nyou have buffers as well\nthat information is stored.\n\n318\n00:16:32.507 --> 00:16:35.030\nIf you have the network\ncommunications that are going on,\n\n319\n00:16:35.030 --> 00:16:38.376\nyou also have to keep in mind, not just\nthe shredding of the information, but\n\n320\n00:16:38.376 --> 00:16:40.450\nactually the consumption\nof the information.\n\n321\n00:16:40.450 --> 00:16:44.030\nYou wanna have things like, VPN\ncommunications and end-to-end encryption.\n\n322\n00:16:44.030 --> 00:16:46.330\nYou wanna make sure that\nyou're implementing ACLs and\n\n323\n00:16:46.330 --> 00:16:52.000\nthings like, not just ACLs, but your\npermissions and then just file encryption.\n\n324\n00:16:53.600 --> 00:16:57.925\nSo a couple of the last things that I\nknow we're coming towards the end here.\n\n325\n00:16:57.925 --> 00:17:02.170\nCouple of the last things that I wanna\nlook at, they talk about data roles and\n\n326\n00:17:02.170 --> 00:17:05.680\nwe have kind of talked about the PII so\nPHI again.\n\n327\n00:17:05.680 --> 00:17:06.620\nRemember PII, I'll go ahead and\n\n328\n00:17:06.620 --> 00:17:08.979\nmention that even though I've\nbeen talking about it a lot.\n\n329\n00:17:09.980 --> 00:17:12.510\nInformation that's used to\nidentify an individual.\n\n330\n00:17:12.510 --> 00:17:18.330\nSocial Security numbers, phone numbers,\naddress, employee information,\n\n331\n00:17:18.330 --> 00:17:22.339\nthe salary within a company, this is all\ninformation that needs to be kept private.\n\n332\n00:17:23.760 --> 00:17:27.090\nProtected health information, I know I\nkeep saying private health information,\n\n333\n00:17:27.090 --> 00:17:28.570\npersonal health information.\n\n334\n00:17:28.570 --> 00:17:32.390\nProtected health information again,\nthis could be your current health status.\n\n335\n00:17:32.390 --> 00:17:34.840\nWhat is your payment or\nbalance for health care.\n\n336\n00:17:34.840 --> 00:17:41.040\nThis is information that also has to be\nkept separate as well, and protected.\n\n337\n00:17:41.040 --> 00:17:44.590\nSo, data roles, we have to know they're\nfew different data roles as well.\n\n338\n00:17:45.830 --> 00:17:48.430\nThree different things here,\nyou have what's known as the owner,\n\n339\n00:17:48.430 --> 00:17:50.320\nyou have what's known as the steward or\n\n340\n00:17:50.320 --> 00:17:55.200\ncustodian of the information,\nyou also have the privacy officer as well.\n\n341\n00:17:55.200 --> 00:17:58.050\nThe data, or the owner if you will.\n\n342\n00:17:58.050 --> 00:18:02.680\nThe owner ensures that there's\nmaintenance or contractual agreements,\n\n343\n00:18:02.680 --> 00:18:04.590\nthat are in place and\nare sufficient if you will,\n\n344\n00:18:04.590 --> 00:18:11.150\nin protecting the confidentiality with\nthe impact of information disclosure.\n\n345\n00:18:11.150 --> 00:18:13.950\nWe have things like the steward and\nthe custodian, if you will.\n\n346\n00:18:13.950 --> 00:18:17.078\nAnd what their job is to\nassure that the appropriate\n\n347\n00:18:17.078 --> 00:18:20.280\nsupervision of on-site media maintenance,\n\n348\n00:18:20.280 --> 00:18:24.930\nwhether it's through a service provider,\nbut it occurs when necessary.\n\n349\n00:18:24.930 --> 00:18:28.340\nRemember that the information steward,\n\n350\n00:18:28.340 --> 00:18:30.920\nshould fully understand\nthe sensitivity of the information.\n\n351\n00:18:30.920 --> 00:18:33.940\nThey have to know what the classifications\nare of this information.\n\n352\n00:18:35.290 --> 00:18:37.280\nLast we have the privacy officer, and\n\n353\n00:18:37.280 --> 00:18:41.910\nthe privacy officer is responsible for\nproviding advice just regarding\n\n354\n00:18:41.910 --> 00:18:47.010\nthe privacy issues that are surrounding\nthe information that we possess.\n\n355\n00:18:47.010 --> 00:18:50.140\nAgain, the media that it's recorded on,\n\n356\n00:18:50.140 --> 00:18:53.570\nprivacy officer is one that\nunderstands all of the aspects.\n\n357\n00:18:53.570 --> 00:18:55.630\nAnd even some of the things,\n\n358\n00:18:55.630 --> 00:18:59.510\nthe results of unauthorized\ndisclosure of this information.\n\n359\n00:18:59.510 --> 00:19:03.110\nSo a few roles that you\ndefinitely have to keep in mind.\n\n360\n00:19:03.110 --> 00:19:07.440\nNow one of the last things that we\nhave to talk about is data retention.\n\n361\n00:19:07.440 --> 00:19:11.360\nData retention is important,\nhow do we store this information?\n\n362\n00:19:12.760 --> 00:19:16.760\nThat a lot times is gonna be for\ninstance stored or\n\n363\n00:19:16.760 --> 00:19:22.590\ndefined clearly in security policy, or a\ncompany's specific data retention policy.\n\n364\n00:19:22.590 --> 00:19:28.050\n&gt;&gt; And, Wes, with the advent of big data,\nwe have these large amounts of data that\n\n365\n00:19:28.050 --> 00:19:32.950\nrequire retention, which also may require\nsecurity during that retention period.\n\n366\n00:19:32.950 --> 00:19:36.590\nSo this is kind of like its own\nlittle sequestered environment, or\n\n367\n00:19:36.590 --> 00:19:39.130\npotentially role within itself.\n\n368\n00:19:39.130 --> 00:19:42.630\nA lot of opportunity there.\n\n369\n00:19:42.630 --> 00:19:43.480\n&gt;&gt; Definitely.\n\n370\n00:19:43.480 --> 00:19:48.150\nI think of things, for instance, if you\nhave payment information, you've got\n\n371\n00:19:48.150 --> 00:19:52.500\na customer base, how long do you carry\nthat customer payment information?\n\n372\n00:19:52.500 --> 00:19:54.170\nDo you have to retain it for seven years?\n\n373\n00:19:54.170 --> 00:19:58.140\nWe think about taxes in a company,\na company's got to retain tax records.\n\n374\n00:19:58.140 --> 00:20:02.090\nThat's a classic example of data\nretention, but the same thing can happen.\n\n375\n00:20:02.090 --> 00:20:04.994\nYou can have some kind of legal,\nor federal,\n\n376\n00:20:04.994 --> 00:20:09.640\nstate compliance that you have to\nimplement in order to retain the data.\n\n377\n00:20:09.640 --> 00:20:12.600\nIf you have it stored on backup media,\nhow is it stored?\n\n378\n00:20:12.600 --> 00:20:16.500\nIs it stored on-site, is it stored\noffsite, is it stored in the cloud?\n\n379\n00:20:16.500 --> 00:20:18.650\nAnd again you have to pay\nattention to the cloud.\n\n380\n00:20:18.650 --> 00:20:22.912\nDoes the cloud provider or the service\nprovider, do they fall under things like,\n\n381\n00:20:22.912 --> 00:20:26.209\nSarbanes-Oxley, HIPAA, and\nagain PCI compliance as well.\n\n382\n00:20:26.209 --> 00:20:29.660\n&gt;&gt; Knowing all those compliance,\nthose regulatory with the laws, and\n\n383\n00:20:29.660 --> 00:20:32.770\nbeing up to date with that, I mean, you\ncan just be a data retention consultant\n\n384\n00:20:32.770 --> 00:20:35.718\nand that would be a pretty\nbig deal right there.\n\n385\n00:20:35.718 --> 00:20:38.020\n&gt;&gt; That could be your service\nthat you're providing, yeah.\n\n386\n00:20:38.020 --> 00:20:42.240\nAnd that's where things like the role\nof the privacy officer comes into play,\n\n387\n00:20:42.240 --> 00:20:45.130\nis that you thoroughly understand this and\n\n388\n00:20:45.130 --> 00:20:49.820\nyou understand what the requirements are,\nhow we meet those requirements.\n\n389\n00:20:49.820 --> 00:20:52.750\nAre we in compliance currently,\ndoing things like audits and\n\n390\n00:20:52.750 --> 00:20:55.770\nreviews to make sure that\nwe stay in compliance.\n\n391\n00:20:55.770 --> 00:21:00.130\nAgain, you also have to worry about with\ndata retention, things like bit rot.\n\n392\n00:21:00.130 --> 00:21:03.300\nIf you're storing information\non magnetic media.\n\n393\n00:21:03.300 --> 00:21:04.310\n&gt;&gt; How long is that gonna last physically?\n\n394\n00:21:04.310 --> 00:21:06.318\n&gt;&gt; Yeah, how long is it gonna\nlast before it's corrupted?\n\n395\n00:21:06.318 --> 00:21:08.640\n&gt;&gt; Are you putting it near the sun,\nwhere are you storing this?\n\n396\n00:21:08.640 --> 00:21:12.370\n&gt;&gt; That's right, are we doing things like\nrunning hashing algorithms over it to make\n\n397\n00:21:12.370 --> 00:21:17.520\nsure that the data that we're storing now\nis the same data that we started with?\n\n398\n00:21:17.520 --> 00:21:20.550\nAgain, because data can deteriorate over\n\n399\n00:21:20.550 --> 00:21:22.930\ntime when it is stored on\ncertain type of media.\n\n400\n00:21:22.930 --> 00:21:24.210\nSo we do have to be aware of that.\n\n401\n00:21:24.210 --> 00:21:26.840\nNow again, keep in mind for the exam,\n\n402\n00:21:26.840 --> 00:21:30.560\nunderstand the different sanitization\ntechniques that we've mentioned.\n\n403\n00:21:30.560 --> 00:21:34.150\nUnderstand the data classifications, and\n\n404\n00:21:34.150 --> 00:21:37.330\nthe last thing I would say is understand\nthose roles, cuz it is important.\n\n405\n00:21:37.330 --> 00:21:40.349\nAnd keep in mind,\nthere's never any one-size-fits-all.\n\n406\n00:21:42.120 --> 00:21:45.570\nThink about optical media,\nhow do we sanitize optical media?\n\n407\n00:21:45.570 --> 00:21:48.580\nThat typically falls under\nthe destruction side of it.\n\n408\n00:21:48.580 --> 00:21:53.446\nThere's not really a way to degauss, it's\nnot gonna do anything of we try to degauss\n\n409\n00:21:53.446 --> 00:21:57.920\noptical media that's been\nwritten with a laser.\n\n410\n00:21:57.920 --> 00:22:01.450\nSo that might something that you're\ndoing physical destruction versus tape\n\n411\n00:22:01.450 --> 00:22:05.040\nbackups if you're doing that and you're\nhaving to eradicate that information.\n\n412\n00:22:05.040 --> 00:22:07.790\nIt might be as simple as you're\ndoing a tape rotation method.\n\n413\n00:22:07.790 --> 00:22:12.070\nTape rotation method you keep backing that\ninformation up that you're using, and\n\n414\n00:22:12.070 --> 00:22:13.770\nit's overwriting older data.\n\n415\n00:22:13.770 --> 00:22:17.570\nSo again, it could be something just it's\nlike a media reuse policy that could be in\n\n416\n00:22:17.570 --> 00:22:21.360\nplace as part of like clearing\nthe information on a higher level if it\n\n417\n00:22:21.360 --> 00:22:24.750\ndoesn't fall under some of the more strict\nclassifications that we've talked about.\n\n418\n00:22:24.750 --> 00:22:28.730\nSo know those different techniques,\nknow declassification and\n\n419\n00:22:28.730 --> 00:22:30.620\nknow those roles for the exam.\n\n420\n00:22:30.620 --> 00:22:32.140\nSo that if a question comes up or\n\n421\n00:22:32.140 --> 00:22:35.220\nscenarios given,\nyou'll be able to answer them correctly.\n\n422\n00:22:35.220 --> 00:22:36.600\n&gt;&gt; Great suggestions Wes.\n\n423\n00:22:36.600 --> 00:22:38.710\nAnd thank you so much for\nthat ladies and gentlemen.\n\n424\n00:22:38.710 --> 00:22:41.860\nAlso stay tuned, we have more security\nplus information headed your way.\n\n425\n00:22:41.860 --> 00:22:43.860\nBut for this show we'll go ahead and\nsign out.\n\n426\n00:22:43.860 --> 00:22:45.410\nRemember I'm your host Cherokee Boose.\n\n427\n00:22:45.410 --> 00:22:46.170\n&gt;&gt; And I'm Wes Bryan.\n\n428\n00:22:46.170 --> 00:22:48.026\n&gt;&gt; See you next time here at ITProTV.\n\n429\n00:22:48.026 --> 00:22:55.450\n[MUSIC]\n\n430\n00:22:55.450 --> 00:22:57.708\nThank you for watching ITProTV.\n\n",
          "vimeoId": "216165729"
        }
      ],
      "title": "Risk Management"
    },
    {
      "episodes": [
        {
          "description": "In this episode, Daniel and Wes go over the basic concepts of Cryptography. Here they look at topics like symmetric/asymmetric algorithms, modes of operation, hashing and salting, which is a method used to increase the defense of hashing.",
          "length": "1163",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-1-data_security_and_privacy_practice-050517-PGM.00_26_05_09.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-1-data_security_and_privacy_practice-050517-PGM.00_26_05_09.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-1-data_security_and_privacy_practice-050517-PGM.00_26_05_09.Still001-sm.jpg",
          "title": "Basic Concepts of Cryptography",
          "transcript": "WEBVTT\n\n1\n00:00:00.250 --> 00:00:01.522\n&gt;&gt; Welcome to ITPRO.TV.\n\n2\n00:00:01.522 --> 00:00:08.399\nI'm your host Don Pezet,\ncoming at you live from San Fransisco.\n\n3\n00:00:08.399 --> 00:00:10.590\n&gt;&gt; You're watching ITPRO.TV.\n\n4\n00:00:12.190 --> 00:00:12.800\n&gt;&gt; All right.\n\n5\n00:00:12.800 --> 00:00:16.554\nGreetings everyone and welcome to\nanother great episode of ITPRO.TV.\n\n6\n00:00:16.554 --> 00:00:19.370\nI'm your host Daniel Lowry and\nin today's episode.\n\n7\n00:00:19.370 --> 00:00:22.930\nWell, brace yourself folks,\ncuz we're back with more security plus.\n\n8\n00:00:22.930 --> 00:00:26.410\nAnd joining us in the studio to land his\nexpertise on that, our good friend, Mr.\n\n9\n00:00:26.410 --> 00:00:27.010\nWes Bryan.\n\n10\n00:00:27.010 --> 00:00:27.920\nWest, welcome back, man.\n\n11\n00:00:27.920 --> 00:00:28.660\nHow's it going?\n\n12\n00:00:28.660 --> 00:00:29.650\n&gt;&gt; Man, it's going all right.\n\n13\n00:00:29.650 --> 00:00:30.537\n&gt;&gt; You thought it was going\n\n14\n00:00:30.537 --> 00:00:31.256\nsomewhere else-\n&gt;&gt; Yeah, I did.\n\n15\n00:00:31.256 --> 00:00:34.005\n&gt;&gt; [LAUGH]\n&gt;&gt; It's great to be here with the ITPRO.TV\n\n16\n00:00:34.005 --> 00:00:35.327\ncrew in the studio too.\n\n17\n00:00:35.327 --> 00:00:36.290\n&gt;&gt; That's right.\n&gt;&gt; We're gonna be talking\n\n18\n00:00:36.290 --> 00:00:38.840\nabout a little bit more about\ncryptography in this episode.\n\n19\n00:00:38.840 --> 00:00:43.320\nAnd we've already got an episode where\nwe talked a lot about things like\n\n20\n00:00:43.320 --> 00:00:47.940\nasymmetric algorithms modes of operations,\nmetric algorithms.\n\n21\n00:00:47.940 --> 00:00:52.045\nSo we're gonna touch base on some of\nthose things, just kind of rehash those.\n\n22\n00:00:52.045 --> 00:00:53.060\n&gt;&gt; [LAUGH]\n&gt;&gt; We're also gonna talk about\n\n23\n00:00:53.060 --> 00:00:54.230\nhash values too.\n\n24\n00:00:54.230 --> 00:00:58.180\nBut we're gonna kind of breeze over some\nof the things that we have talked about,\n\n25\n00:00:58.180 --> 00:01:01.110\nbut we're gonna introduce\nsome new concepts as well.\n\n26\n00:01:01.110 --> 00:01:05.090\nAnd we're gonna kinda do a compare and\ncontrast, right?\n\n27\n00:01:05.090 --> 00:01:06.040\nSo let's go ahead and\n\n28\n00:01:06.040 --> 00:01:11.110\nkind of review symmetric key encryption\nand asymmetric key encryption.\n\n29\n00:01:11.110 --> 00:01:15.200\nIn fact, got a diagram right here\ntalking about symmetric key encryption.\n\n30\n00:01:15.200 --> 00:01:20.222\nKeep in mind that with symmetric key\nencryption, it is the same key that does\n\n31\n00:01:20.222 --> 00:01:25.013\nthe encryption is the same key that's\ngonna do the decryption, right?\n\n32\n00:01:25.013 --> 00:01:28.247\nSo we have to securely transmit\nthe symmetric key, and\n\n33\n00:01:28.247 --> 00:01:31.830\nreally one of the ways that we do\nthat is we could couple things\n\n34\n00:01:31.830 --> 00:01:35.390\nlike asymmetric key encryption and\nsymmetric key.\n\n35\n00:01:35.390 --> 00:01:39.540\nSo that we can securely transfer\na single key over the wire and\n\n36\n00:01:39.540 --> 00:01:40.550\nthat it is encrypted.\n\n37\n00:01:40.550 --> 00:01:42.080\nWe don't have to worry\nabout it eavesdropping.\n\n38\n00:01:42.080 --> 00:01:44.280\nBut keep in mind with\nsymmetric key encryption,\n\n39\n00:01:44.280 --> 00:01:48.410\nit's a single key doing the encryption and\ndecryption.\n\n40\n00:01:48.410 --> 00:01:51.530\nAnd that's unlike asymmetric\nkey encryption, right?\n\n41\n00:01:51.530 --> 00:01:53.650\nOne of the things that I try to,\nwhen I teach this and\n\n42\n00:01:53.650 --> 00:01:56.820\nI tell people is I don't want you to think\nabout your data as just being a file.\n\n43\n00:01:56.820 --> 00:01:59.850\nI want you to think about it\nas being a lockbox, right?\n\n44\n00:01:59.850 --> 00:02:05.290\nAnd the lockbox has two keys, right, and\nthese keys are mathematically aligned,\n\n45\n00:02:05.290 --> 00:02:07.470\nthey are issued at the same time,\nthey're paired up.\n\n46\n00:02:07.470 --> 00:02:09.630\nThat's why we call them key pairs.\n\n47\n00:02:09.630 --> 00:02:13.610\nAnd I want you to understand\nthat one of the keys\n\n48\n00:02:13.610 --> 00:02:16.910\nin this model is gonna\ndo a locking of the box.\n\n49\n00:02:16.910 --> 00:02:20.510\nAnd that's its sole purpose,\njust lock the box, right?\n\n50\n00:02:20.510 --> 00:02:24.505\nThe other key, one that we wanna really\nkeep protected and we don't want anybody\n\n51\n00:02:24.505 --> 00:02:28.635\nto have access to, that's the key that's\nactually we're gonna put it in the box.\n\n52\n00:02:28.635 --> 00:02:30.929\nWe're gonna turn it and\nit's gonna unlock the box so\n\n53\n00:02:30.929 --> 00:02:33.200\nwe can see whatever's inside it, right?\n\n54\n00:02:33.200 --> 00:02:38.192\nAnd that's essentially what\nasymmetric encryption is doing.\n\n55\n00:02:38.192 --> 00:02:41.272\nIt's using two keys, two keys,\none does the encryption,\n\n56\n00:02:41.272 --> 00:02:43.230\nthat's called a public key.\n\n57\n00:02:43.230 --> 00:02:48.040\nThe other one that we need to\nkeep secure is a private key.\n\n58\n00:02:48.040 --> 00:02:52.840\nSo remember what happens is\nwe typically get issued your\n\n59\n00:02:52.840 --> 00:02:57.110\npublic keys through a PKI solution where\na certificate's issues to you, and\n\n60\n00:02:57.110 --> 00:03:00.200\nyou install the private key\non the local machine, right?\n\n61\n00:03:00.200 --> 00:03:02.130\nWe don't want anybody\nhaving access to that,\n\n62\n00:03:02.130 --> 00:03:04.420\nbecause it's gonna do the decryption,\nright?\n\n63\n00:03:04.420 --> 00:03:07.420\nIf I'm sending information\nfrom myself to Dan, right, and\n\n64\n00:03:07.420 --> 00:03:10.980\nsomebody out there on the wire\ncan get access to my private key,\n\n65\n00:03:10.980 --> 00:03:14.410\nthen any encrypted information that I\nsent to Dan somebody else could take that\n\n66\n00:03:14.410 --> 00:03:17.720\nprivate key and make it unlock the box and\nthey can see what's inside of it.\n\n67\n00:03:17.720 --> 00:03:21.620\nSo private key stays private for\na reason, right?\n\n68\n00:03:21.620 --> 00:03:24.320\nRemember that if I want to send or\n\n69\n00:03:24.320 --> 00:03:27.902\nthis gentleman wants to send encrypted\ncommunications to this young lady.\n\n70\n00:03:27.902 --> 00:03:32.375\nShe essentially will obtain his\ncertificate, that is associated,\n\n71\n00:03:32.375 --> 00:03:34.159\nit has the public key in it.\n\n72\n00:03:34.159 --> 00:03:39.590\nAnd then what she does or she takes that\npublic key, right and she locks the box.\n\n73\n00:03:39.590 --> 00:03:41.880\nOkay, and locks it with his public key.\n\n74\n00:03:43.110 --> 00:03:48.010\nShe turns around and she takes that locked\nbox that's been locked with a public key.\n\n75\n00:03:48.010 --> 00:03:52.950\nAnd she transmits the securely locked box,\n\n76\n00:03:52.950 --> 00:03:56.410\nif I can say that, right,\nback to this gentleman.\n\n77\n00:03:56.410 --> 00:04:00.030\nKeep in mind, he has got\nthe mathematically aligned private key,\n\n78\n00:04:00.030 --> 00:04:01.510\nthat never hits the wire,\n\n79\n00:04:01.510 --> 00:04:06.580\nand he uses that key to unlock\nthe box to see what's inside of it.\n\n80\n00:04:06.580 --> 00:04:07.740\nNow again,\n\n81\n00:04:07.740 --> 00:04:12.192\nnow we're kinda thinking of them as lock\nboxes, replace that with file encryption.\n\n82\n00:04:12.192 --> 00:04:16.862\nRight, now we got a file, right,\nit's like in an unlock state, I can take\n\n83\n00:04:16.862 --> 00:04:21.855\na public key and run that operation across\nit and it scrambles the information.\n\n84\n00:04:21.855 --> 00:04:24.012\nIt locks the box, it locks the file.\n\n85\n00:04:24.012 --> 00:04:27.678\nIt is sent over the wire in\nan encrypted format, in this case,\n\n86\n00:04:27.678 --> 00:04:32.121\nthis gentleman receives that file,\ntakes his private key that matches his\n\n87\n00:04:32.121 --> 00:04:35.175\npublic key and\nremoves the encryption, right?\n\n88\n00:04:35.175 --> 00:04:38.445\nDecrypts the information,\nthat's asymmetric key encryption.\n\n89\n00:04:38.445 --> 00:04:41.775\n&gt;&gt; And the brilliance of asymmetric\nkey encryption is that public key,\n\n90\n00:04:41.775 --> 00:04:44.955\nanybody can have that public\nkey just give it out and\n\n91\n00:04:44.955 --> 00:04:48.345\nsomebody can use that key to\nlock up any file that you want.\n\n92\n00:04:48.345 --> 00:04:50.795\nAnd there's only one person\nthat can unlock it and\n\n93\n00:04:50.795 --> 00:04:54.520\nit's that person with the private key\nthat goes along with the public keys.\n\n94\n00:04:54.520 --> 00:04:55.510\nJust keep that in mind.\n\n95\n00:04:55.510 --> 00:04:58.878\nI didn't give up the public key\nI enhanced the term public key.\n\n96\n00:04:58.878 --> 00:05:02.610\n&gt;&gt; Definitely and it's a great,\ngreat solution, right,\n\n97\n00:05:02.610 --> 00:05:06.840\nfor securely transmitting\nencrypted information.\n\n98\n00:05:06.840 --> 00:05:10.401\nNow the other thing that they called out\nwe've looked at this in our other episodes\n\n99\n00:05:10.401 --> 00:05:13.764\ntoo and I really have a slide for that but\nit's called the modes of operation.\n\n100\n00:05:13.764 --> 00:05:17.760\nKeep in mind that the algorithms that we\nused are pretty much known to everybody,\n\n101\n00:05:17.760 --> 00:05:18.780\nAES, right?\n\n102\n00:05:18.780 --> 00:05:23.700\nThe algorithm is the mathematical\nfunction that works on your data.\n\n103\n00:05:23.700 --> 00:05:28.520\nThe mode of operation tells the algorithm\nthis is how you're gonna do it.\n\n104\n00:05:28.520 --> 00:05:34.050\nRemember, we've looked at some, we've\nlooked at things like chain block ciphers.\n\n105\n00:05:34.050 --> 00:05:35.060\nChaining block ciphers.\n\n106\n00:05:35.060 --> 00:05:37.530\nWe've looked at,\nwhat else have we looked at?\n\n107\n00:05:37.530 --> 00:05:41.660\nWe looked at Counter Mode, we looked at\nGalois Counter Mode, we looked at one of\n\n108\n00:05:41.660 --> 00:05:46.620\nthe basic forms that's really, not really\nsecure and that's Electronic Code Book.\n\n109\n00:05:46.620 --> 00:05:51.570\nBut, again, the algorithms that we have,\neverybody knows them.\n\n110\n00:05:51.570 --> 00:05:55.180\nAnd I say knows them, people that have the\nintelligence to figure out the math, and\n\n111\n00:05:55.180 --> 00:05:55.750\nthat's not me.\n\n112\n00:05:56.810 --> 00:06:02.290\nBut when we add the modes,\nwe can modify how that algorithm works,\n\n113\n00:06:02.290 --> 00:06:05.140\nso we can tailor-make it to our needs.\n\n114\n00:06:05.140 --> 00:06:08.800\nWe can add a little bit more\ncomplexity to it if we want and\n\n115\n00:06:08.800 --> 00:06:14.330\notherwise strengthen the algorithm, so\nkeep in mind the modes of operations.\n\n116\n00:06:14.330 --> 00:06:17.450\nWe've talked about hashing algorithms as\nwell, we've talked about those a lot.\n\n117\n00:06:17.450 --> 00:06:22.020\nKeep in mind that encryption is how we\nhandle things like the confidentiality\n\n118\n00:06:22.020 --> 00:06:25.850\naspect of the CIA triad,\nthe three principles of security.\n\n119\n00:06:25.850 --> 00:06:29.631\nRemember that hashing algorithms,\nthe functions that we run across those,\n\n120\n00:06:29.631 --> 00:06:31.736\nit's not really done to conceal the data.\n\n121\n00:06:31.736 --> 00:06:36.654\nIt's done to maintain it's integrity at\nproducers fixed length that I can let's\n\n122\n00:06:36.654 --> 00:06:40.490\nsay for instance I can run\na hash function across the file.\n\n123\n00:06:40.490 --> 00:06:43.278\nI can take that hash function and\nI can put it on that file, and\n\n124\n00:06:43.278 --> 00:06:44.440\nI can send it over to Dan.\n\n125\n00:06:44.440 --> 00:06:48.510\nAnd he can perform the same type of hash\nfunction and compare the two values.\n\n126\n00:06:48.510 --> 00:06:51.844\nThe values match, then then it's\nmaintained its integrity for\n\n127\n00:06:51.844 --> 00:06:55.918\nwhatever reason the data doesn't match or\nthe fix with value doesn't match,\n\n128\n00:06:55.918 --> 00:06:59.516\nthen Dan can assume something's\ngoing wrong with the information.\n\n129\n00:06:59.516 --> 00:07:02.330\nCould be just a simple as\nthe network transmission there.\n\n130\n00:07:02.330 --> 00:07:06.560\nIt could be malicious modification,\nright, unauthorized modification.\n\n131\n00:07:06.560 --> 00:07:08.640\nAnd the reason I say network\ntransmission errors.\n\n132\n00:07:08.640 --> 00:07:11.140\nIf you think about it,\nwe've got a lot of this\n\n133\n00:07:11.140 --> 00:07:15.060\nkind of technology that works passing\ncommunications across network wires.\n\n134\n00:07:15.060 --> 00:07:19.440\nIt's why like a layer two,\nwe have framed checks and sequence.\n\n135\n00:07:19.440 --> 00:07:21.620\nJust a hashing algorithm,\nit's checksums, right?\n\n136\n00:07:21.620 --> 00:07:23.610\nWe have those at layer three as well.\n\n137\n00:07:23.610 --> 00:07:26.410\nWe also have them at TCP,\nas working at layer four, and\n\n138\n00:07:26.410 --> 00:07:31.580\nit's doings segmentation and sequencing,\nin order to, and it will call back\n\n139\n00:07:31.580 --> 00:07:36.790\nif it receives a frame of, or a packet\nof information that's considered bad.\n\n140\n00:07:36.790 --> 00:07:41.243\nIt'll discard it and call back so\nit's connection oriented ensuring not only\n\n141\n00:07:41.243 --> 00:07:44.412\nwe that we rebuild these\npackets in the right order, but\n\n142\n00:07:44.412 --> 00:07:46.781\nthat they maintain their integrity too.\n\n143\n00:07:46.781 --> 00:07:51.653\nSo in cryptography sense keep\nin mind that for file or\n\n144\n00:07:51.653 --> 00:07:54.875\nintegrity verification more so.\n\n145\n00:07:55.915 --> 00:08:01.175\nAll right, so now those are some of the\nconcept that we kinda talked about, and\n\n146\n00:08:01.175 --> 00:08:02.655\nso I just kinda briefed over them.\n\n147\n00:08:02.655 --> 00:08:05.630\nKeep in mind we do talk about\nthem in other episodes as well.\n\n148\n00:08:05.630 --> 00:08:09.880\nBut something that's kind of new,\nthat we didn't talk about,\n\n149\n00:08:09.880 --> 00:08:11.540\nis this concept of salt.\n\n150\n00:08:12.730 --> 00:08:18.520\nIV, or initialization vectors,\nand nuances, a number used once.\n\n151\n00:08:18.520 --> 00:08:20.158\nI want you to keep this in mind.\n\n152\n00:08:20.158 --> 00:08:22.558\nWe kind of talked about\ninitialization vectors when Dan and\n\n153\n00:08:22.558 --> 00:08:26.170\nI were discussing the weaknesses of\nthings like the wired equivalent privacy.\n\n154\n00:08:26.170 --> 00:08:30.150\nSo your initialization vector, right, this\nis a little bit of padding information.\n\n155\n00:08:30.150 --> 00:08:35.520\nIt's added information that we\nadd to all of your plain text.\n\n156\n00:08:35.520 --> 00:08:37.350\nAnd why do we do that, right?\n\n157\n00:08:37.350 --> 00:08:39.860\nWell, I want you to think\nabout it very simply this way.\n\n158\n00:08:39.860 --> 00:08:44.350\nIf I have a hashing algorithm, or excuse\nme, I'm sorry, an encryption algorithm,\n\n159\n00:08:44.350 --> 00:08:48.350\nI have plain text, two pieces of\nplain text that are identical.\n\n160\n00:08:48.350 --> 00:08:50.600\nWe use the same encryption\nalgorithm on that.\n\n161\n00:08:50.600 --> 00:08:54.380\nThat means the output is our cypher text,\nbasics of encryption, but\n\n162\n00:08:54.380 --> 00:08:56.360\nthe cypher text is identical.\n\n163\n00:08:56.360 --> 00:09:01.420\nThe same data's fed in to the encryption\nalgorithm is gonna produce the same\n\n164\n00:09:01.420 --> 00:09:03.710\noutput as far as cipher text.\n\n165\n00:09:03.710 --> 00:09:08.150\nSo what we do is we add a little\nbit of extra data, unique data,\n\n166\n00:09:08.150 --> 00:09:12.040\nto each piece of plain text and\nthen we run it through the algorithm.\n\n167\n00:09:12.040 --> 00:09:15.627\nAnd that ensures, or\nthe goal is, that's the goal,\n\n168\n00:09:15.627 --> 00:09:19.628\nis that it ensures that each\npiece of cipher text is unique.\n\n169\n00:09:19.628 --> 00:09:23.127\nSo that you don't start seeing things like\ndata leakage where you can start to say,\n\n170\n00:09:23.127 --> 00:09:26.860\nthere's a pattern there, there's a pattern\nthere, and there's a pattern there.\n\n171\n00:09:26.860 --> 00:09:29.840\nWell, you can start to reverse engineer\nthings when you see those patterns.\n\n172\n00:09:29.840 --> 00:09:32.520\nSo that's one of the things\nthat we don't want.\n\n173\n00:09:32.520 --> 00:09:35.970\nSalts and\nnuances are the same thing, right?\n\n174\n00:09:35.970 --> 00:09:39.530\nNuances, we talked about inside of\none of the modes of operations called\n\n175\n00:09:39.530 --> 00:09:41.110\ncounter mode, right?\n\n176\n00:09:41.110 --> 00:09:41.700\nCounter mode.\n\n177\n00:09:41.700 --> 00:09:44.460\nI want you to think of a counter, right?\n\n178\n00:09:44.460 --> 00:09:47.010\nOne, two, three, four.\n\n179\n00:09:47.010 --> 00:09:49.970\nSo counter mode, remember,\nwe take a one time value.\n\n180\n00:09:49.970 --> 00:09:50.800\nThe nuance, right?\n\n181\n00:09:50.800 --> 00:09:55.650\nNumber used once and\nwe concatenate it with a counter.\n\n182\n00:09:55.650 --> 00:09:59.041\nWe add that counter,\nwe encrypt our data, right, and\n\n183\n00:09:59.041 --> 00:10:03.614\nthen the next encryption the counter\nprogresses, but it's the nuance,\n\n184\n00:10:03.614 --> 00:10:07.468\nthat one time use value that's\nadded to the counter, right?\n\n185\n00:10:07.468 --> 00:10:12.443\nAnd, again, it's one of these things to\nmaking sure that each of your encrypted\n\n186\n00:10:12.443 --> 00:10:17.000\noutputs is unique across the data\nstream that you might be transmitting.\n\n187\n00:10:17.000 --> 00:10:20.763\nNow salts, they work a lot the same way,\nall right, but they're used for\n\n188\n00:10:20.763 --> 00:10:23.830\na slightly different purpose, all right?\n\n189\n00:10:23.830 --> 00:10:28.270\nI want you to think of the fact\nthat maybe out of how many people?\n\n190\n00:10:28.270 --> 00:10:33.370\nJust take a guess, 1,000 people,\nwhat is the chances that maybe\n\n191\n00:10:33.370 --> 00:10:35.530\nyou've got two people that\nmight use the same password?\n\n192\n00:10:36.550 --> 00:10:37.120\nI don't know.\n\n193\n00:10:37.120 --> 00:10:37.870\nI don't know if you will.\n\n194\n00:10:37.870 --> 00:10:40.940\nBut I can tell you right now that\nthere's a lot of students out there\n\n195\n00:10:40.940 --> 00:10:44.650\nthat use P@ssw0rd, because they're\n\n196\n00:10:44.650 --> 00:10:48.190\nused to be trained in a situation\nwhere it was just a basic password.\n\n197\n00:10:48.190 --> 00:10:52.733\nI want to go ahead and talk about what\na salt is in the context of a basic,\n\n198\n00:10:52.733 --> 00:10:54.891\nsimplistic password like that.\n\n199\n00:10:54.891 --> 00:10:57.580\nFor instance,\nwe've got a little diagram here.\n\n200\n00:10:57.580 --> 00:11:00.241\nWe've got these two users,\nUser 1 and User 2.\n\n201\n00:11:00.241 --> 00:11:04.135\nAll right, what happens if we for\nsay, we take the word password, and\n\n202\n00:11:04.135 --> 00:11:07.501\nagain I'm gonna use one of these\nsuper secret passwords that\n\n203\n00:11:07.501 --> 00:11:09.450\nyou really shouldn't be using.\n\n204\n00:11:09.450 --> 00:11:11.180\nAnd we run it through SHA256.\n\n205\n00:11:12.220 --> 00:11:15.480\nWell, you'll notice, and I don't want\nyou to pay attention to the whole entire\n\n206\n00:11:15.480 --> 00:11:20.090\nvalue, but just kinda zero in\non the last four digits, right?\n\n207\n00:11:20.090 --> 00:11:21.680\nSame password, right?\n\n208\n00:11:21.680 --> 00:11:24.980\nSo same text going into\nthe hashing function.\n\n209\n00:11:24.980 --> 00:11:29.890\nThe values on the outside, the output,\nthey're gonna be identical.\n\n210\n00:11:29.890 --> 00:11:31.290\nSo that's the problem, right?\n\n211\n00:11:31.290 --> 00:11:36.910\nAnytime you have double password,\npasswords that have the same value.\n\n212\n00:11:36.910 --> 00:11:41.000\nThey're gonna produce the same hashed\noutput and that's a problem, right?\n\n213\n00:11:41.000 --> 00:11:45.380\nThat is a duplication there that\nmaybe we can start using to perform\n\n214\n00:11:45.380 --> 00:11:46.890\nhashing collisions.\n\n215\n00:11:46.890 --> 00:11:51.540\nThe other thing is there are a lot of\ncommon passwords that companies spend\n\n216\n00:11:51.540 --> 00:11:56.150\na lot of money doing research and they\nfind commonalities of passwords, right?\n\n217\n00:11:56.150 --> 00:11:57.410\nWe've made the joke here,\n\n218\n00:11:57.410 --> 00:12:01.034\nI know a couple of times where\nwe say the password is 123456.\n\n219\n00:12:01.034 --> 00:12:03.392\nGotta go change\nthe password in my luggage.\n\n220\n00:12:03.392 --> 00:12:07.318\nBut wouldn't you,\nhopefully you'll believe this, but\n\n221\n00:12:07.318 --> 00:12:12.700\nwouldn't you know that is one of the most\ncommon passwords people use, right?\n\n222\n00:12:12.700 --> 00:12:13.860\nThey want simplicity.\n\n223\n00:12:13.860 --> 00:12:15.490\nPassword all lower case.\n\n224\n00:12:15.490 --> 00:12:16.540\nWell, guess what?\n\n225\n00:12:16.540 --> 00:12:21.130\nThose passwords produce fixed linked\nvalues with a different hashing functions.\n\n226\n00:12:21.130 --> 00:12:22.810\nAnd guess where they get stored?\n\n227\n00:12:22.810 --> 00:12:27.630\nThey get stored in what's know\nas a Rainbow Table, all right?\n\n228\n00:12:27.630 --> 00:12:33.320\nSo, if I have common passwords\nthat produce common harsh values,\n\n229\n00:12:33.320 --> 00:12:36.920\nthey can make their way into\nthe rainbow table, right?\n\n230\n00:12:36.920 --> 00:12:38.755\nAnd I wanna try to eliminate this,\n\n231\n00:12:38.755 --> 00:12:42.122\nI wanna eliminate that if somebody\nis using the same password.\n\n232\n00:12:42.122 --> 00:12:46.180\nOr if it's a common password, we can\nkinda add some uniqueness to it, and\n\n233\n00:12:46.180 --> 00:12:49.410\nthat's where the sorting\nfunctions come in.\n\n234\n00:12:49.410 --> 00:12:53.306\nSo imagine if I take a random value and\nI add that,\n\n235\n00:12:53.306 --> 00:12:59.591\nI put those two together with a password\nand then we run the hashing algorithm.\n\n236\n00:12:59.591 --> 00:13:03.964\nWhat you are going to see is that on\nthe outside of it, the values when they're\n\n237\n00:13:03.964 --> 00:13:08.490\nconcatenated together like that,\nwill produce different hash values.\n\n238\n00:13:08.490 --> 00:13:10.580\nNow that is good when you have\npassword duplication, but\n\n239\n00:13:10.580 --> 00:13:13.360\neven more so to try to get away from\n\n240\n00:13:13.360 --> 00:13:16.710\nthe fact that common passwords\nare typically stored in rainbow tables.\n\n241\n00:13:16.710 --> 00:13:20.490\nWhen they do password attacks, it assists\nin the computational power that it takes\n\n242\n00:13:20.490 --> 00:13:24.060\nto crack that password,\ncuz they're looking at the commonalities.\n\n243\n00:13:24.060 --> 00:13:27.150\nAnd if a commonality is found,\nput it in the table.\n\n244\n00:13:27.150 --> 00:13:30.954\nAnd we'll use it, because chances\nare we're gonna find a hashing collision,\n\n245\n00:13:30.954 --> 00:13:32.501\nright, two hashes that match.\n\n246\n00:13:32.501 --> 00:13:37.542\nBut for them in order to do something\nlike this when you are using a salt,\n\n247\n00:13:37.542 --> 00:13:40.482\nthey would have to know\nwhat the salt is and\n\n248\n00:13:40.482 --> 00:13:45.630\nput the password together in order to\nbe able to produce that hash value.\n\n249\n00:13:45.630 --> 00:13:49.320\nSo it kind of helps strengthen against\nthings like your Rainbow Tables and again,\n\n250\n00:13:49.320 --> 00:13:54.980\nwhen people are using these passwords,\nsometimes they aren't unique.\n\n251\n00:13:54.980 --> 00:13:57.650\nThey're the same passwords used over and\nover.\n\n252\n00:13:57.650 --> 00:14:00.370\nAnd that's one of the reasons we have\nto have things like password complexity\n\n253\n00:14:00.370 --> 00:14:03.310\npolicies to ensure that\nwe get a uniqueness, or\n\n254\n00:14:03.310 --> 00:14:05.040\npeople aren't reusing passwords.\n\n255\n00:14:05.040 --> 00:14:06.870\nThey're implementing complexities.\n\n256\n00:14:06.870 --> 00:14:09.570\nBut even implementing complexities.\n\n257\n00:14:09.570 --> 00:14:11.470\nYou can start to get\nthings like duplication.\n\n258\n00:14:11.470 --> 00:14:16.300\nSo if each salt value is unique, no matter\nwhat the passwords are, they're the same.\n\n259\n00:14:16.300 --> 00:14:20.333\nIt's gonna produce a different text value\nwith a goal of not being included in\n\n260\n00:14:20.333 --> 00:14:23.263\na common database that would\nbe used in a Rainbow Table.\n\n261\n00:14:23.263 --> 00:14:26.589\n&gt;&gt; Man, you wouldn't wanna see the size\nof these Rainbow Tables out there in\n\n262\n00:14:26.589 --> 00:14:27.850\nthe public domain.\n\n263\n00:14:27.850 --> 00:14:30.440\nYou just download these things and, well,\nyou walk away from your computer for\n\n264\n00:14:30.440 --> 00:14:34.770\na little while, cuz this is gonna take\na bit depending on your bandwidth speed.\n\n265\n00:14:34.770 --> 00:14:38.880\nBut, like Wes said,\nthey really to helping you as an auditor,\n\n266\n00:14:38.880 --> 00:14:43.880\nmaybe I'll put it that way, to look for\nweak passwords that an attacker,\n\n267\n00:14:43.880 --> 00:14:45.760\na threat actor, would be using or\n\n268\n00:14:45.760 --> 00:14:49.530\ndoing the exact same functionality to\nsee if they can find weak passwords.\n\n269\n00:14:49.530 --> 00:14:50.640\nYou wanna beat them to that punch.\n\n270\n00:14:50.640 --> 00:14:52.010\nRainbow Tables can help with that.\n\n271\n00:14:52.010 --> 00:14:54.550\nAnd then you can help your user\n\n272\n00:14:54.550 --> 00:14:57.440\nto create a better password\nthat will withstand that.\n\n273\n00:14:57.440 --> 00:14:58.160\n&gt;&gt; Yeah, that's right, Dan.\n\n274\n00:14:58.160 --> 00:14:59.995\nSo let's go ahead and kinda show you.\n\n275\n00:14:59.995 --> 00:15:03.535\nWhat are we really doing when we're\nadding a little bit of padding\n\n276\n00:15:03.535 --> 00:15:07.715\nto plain text information, and see, what\nis it gonna do to the encrypted output?\n\n277\n00:15:07.715 --> 00:15:10.157\nFor instance, I've got a web site\nhere that I really like to use.\n\n278\n00:15:10.157 --> 00:15:14.952\nIt's called AES encryption, and you can\nuse different AS encryption levels, so\n\n279\n00:15:14.952 --> 00:15:18.592\n256, I'm just gonna go and use 128,\njust gonna show you the point.\n\n280\n00:15:18.592 --> 00:15:22.492\nI also went ahead and\nwent to another website and\n\n281\n00:15:22.492 --> 00:15:26.530\ndid a kind of random key generation,\npseudo random key generation and\n\n282\n00:15:26.530 --> 00:15:28.290\nI went ahead and\nI plugged this key in here.\n\n283\n00:15:28.290 --> 00:15:32.540\nSo we're gonna use AES 128 bit encryption.\n\n284\n00:15:32.540 --> 00:15:35.850\nAnd we probably should be using 256,\nbut it still serves the purpose.\n\n285\n00:15:35.850 --> 00:15:37.050\nWe're gonna use a key value.\n\n286\n00:15:37.050 --> 00:15:42.000\nAnd I'm gonna say, this is my plain text.\n\n287\n00:15:43.130 --> 00:15:46.190\nAll right, and we're gonna go ahead and\nwe gonna encrypt that and\n\n288\n00:15:46.190 --> 00:15:47.870\nwe're gonna look at the output.\n\n289\n00:15:47.870 --> 00:15:49.840\nAll right, now,\nguys I really just want you to pay,\n\n290\n00:15:49.840 --> 00:15:52.510\nI don't want you to pay attention to\nthis whole big number just kinda pay\n\n291\n00:15:52.510 --> 00:15:55.840\nattention to the last four digits,\nright we wanna truly unique value.\n\n292\n00:15:55.840 --> 00:15:57.910\nWell, notice what happens\nif I'm wanna go ahead,\n\n293\n00:15:57.910 --> 00:15:59.120\nI'm wanna completely what do we got?\n\n294\n00:15:59.120 --> 00:16:02.960\nWe got like CLIQ=, right?\n\n295\n00:16:02.960 --> 00:16:04.080\nWe'll just, I'll tell you what.\n\n296\n00:16:04.080 --> 00:16:06.920\nI'm just gonna add something so\nwe make it completely unique and\n\n297\n00:16:06.920 --> 00:16:09.980\nthen I wanna re-encrypt\nthe exact same text, right?\n\n298\n00:16:09.980 --> 00:16:11.610\nSo we'll do that again.\n\n299\n00:16:11.610 --> 00:16:12.810\nAnd notice what happens, right?\n\n300\n00:16:12.810 --> 00:16:17.540\nSo now the text is back to what\nthe original encrypted value was.\n\n301\n00:16:17.540 --> 00:16:19.910\nAnd notice that it's actually different.\n\n302\n00:16:20.960 --> 00:16:22.700\nYou know why?\n&gt;&gt; Cuz you added a space.\n\n303\n00:16:22.700 --> 00:16:24.330\n&gt;&gt; That's right.\nWe don't see the space.\n\n304\n00:16:24.330 --> 00:16:27.240\nBut the encryption protocol does,\nso let me go and back the space.\n\n305\n00:16:27.240 --> 00:16:29.860\nWhich is another it lends itself\nto like caching values and\n\n306\n00:16:29.860 --> 00:16:30.780\nwhy we want to use them.\n\n307\n00:16:30.780 --> 00:16:34.630\nSee even empty space can modify the,\nthe encrypted output.\n\n308\n00:16:34.630 --> 00:16:37.890\nSo now let us go ahead and\ntry to encrypt this and you can see.\n\n309\n00:16:37.890 --> 00:16:42.511\nThere we go, that CLIQ equal,\nso that's a problem, right?\n\n310\n00:16:42.511 --> 00:16:45.751\nAnd, again, that's kind of what we're\nexplaining with the hashing algorithms,\n\n311\n00:16:45.751 --> 00:16:49.083\nnot the hashing algorithms, I'm sorry,\nthe initialization vectors which is an IV,\n\n312\n00:16:49.083 --> 00:16:51.660\nI don't even know if I said\nthat initialization vector.\n\n313\n00:16:51.660 --> 00:16:55.800\nSalt in your passwords, or if you're\ntalking about things like nuances.\n\n314\n00:16:55.800 --> 00:16:58.164\nNotice what happens if\nI just go like this.\n\n315\n00:16:58.164 --> 00:17:00.370\n123456, we'll keep it.\n\n316\n00:17:00.370 --> 00:17:02.480\nWe'll keep it just plain and simple.\n\n317\n00:17:02.480 --> 00:17:06.740\nWe're gonna add a little bit of\npadding to this and we encrypt it.\n\n318\n00:17:06.740 --> 00:17:09.210\nAll right, now notice here.\n\n319\n00:17:09.210 --> 00:17:10.940\nKinda likes the equals symbol apparently.\n\n320\n00:17:10.940 --> 00:17:14.640\n&gt;&gt; Base 64,\nit almost always ends on the equals sign.\n\n321\n00:17:14.640 --> 00:17:16.540\n&gt;&gt; Got you, PZHA, right?\n\n322\n00:17:16.540 --> 00:17:20.400\nNow, let's go ahead and let's change\nthe nuance, the one time value.\n\n323\n00:17:20.400 --> 00:17:22.060\nAnd I'll put something else in there,\nright?\n\n324\n00:17:22.060 --> 00:17:26.090\nWe'll just go ahead and keep running\nour hands across the keyboard.\n\n325\n00:17:26.090 --> 00:17:27.560\nNotice how it's changing, right?\n\n326\n00:17:27.560 --> 00:17:34.560\nSo this is basically what your salting,\nsalting for hashing values if you will.\n\n327\n00:17:34.560 --> 00:17:37.050\nBut when we talk about\ninitialization vectors for\n\n328\n00:17:37.050 --> 00:17:39.920\nmaking sure that the encrypted\noutput Is unique, right?\n\n329\n00:17:39.920 --> 00:17:44.980\nSame plain text goes into the encryption,\ndoesn't produce the same cipher text.\n\n330\n00:17:44.980 --> 00:17:46.250\nAnd we can keep doing that, right?\n\n331\n00:17:46.250 --> 00:17:49.170\nWe could add some additional characters,\nright?\n\n332\n00:17:49.170 --> 00:17:51.190\nI still have my same plain text.\n\n333\n00:17:51.190 --> 00:17:55.510\nBut because I'm adding to it, I get\nthe benefit here that I'm getting unique\n\n334\n00:17:55.510 --> 00:17:58.780\nencrypted values and\nit makes it to where it's harder, right?\n\n335\n00:17:58.780 --> 00:18:03.790\nI never say that never say never in\ncryptography or cryptanalysis, right?\n\n336\n00:18:03.790 --> 00:18:08.190\nBut it does make it more difficult to\nreverse engineer, because every time\n\n337\n00:18:08.190 --> 00:18:12.250\nyou get an output, you get a unique\ncypher text, and that's we want.\n\n338\n00:18:12.250 --> 00:18:15.420\nWe want unique values, we want to\ntry to be as random as possible and\n\n339\n00:18:15.420 --> 00:18:17.040\nwe don't want predictability.\n\n340\n00:18:17.040 --> 00:18:20.160\n&gt;&gt; Definitely some interesting\nconcepts going on with cryptography.\n\n341\n00:18:20.160 --> 00:18:24.200\nIt's a very in depth field of study,\nto be honest with you good folks.\n\n342\n00:18:24.200 --> 00:18:28.951\nSo if you're feeling like, wow,\nI feel like I need a Ph.D in physics or\n\n343\n00:18:28.951 --> 00:18:30.862\nsomething, you know what?\n\n344\n00:18:30.862 --> 00:18:32.930\nPeople that have Ph.D's in\nphysics do cryptography.\n\n345\n00:18:32.930 --> 00:18:35.100\nThey're very smart people that\nhave developed this stuff.\n\n346\n00:18:35.100 --> 00:18:38.860\nBut for us to use it, employ it Is not\nthat difficult, but we just need to know\n\n347\n00:18:38.860 --> 00:18:43.260\nthe concepts behind what's going on\nespecially as far as security goes, so\n\n348\n00:18:43.260 --> 00:18:49.440\nthat we can be doing the most\nsecure aspects of it as we can.\n\n349\n00:18:49.440 --> 00:18:52.190\nSo that being said, I'm looking at our\nclock, Wes is right, we're out of time for\n\n350\n00:18:52.190 --> 00:18:53.000\nthis episode.\n\n351\n00:18:53.000 --> 00:18:55.280\nWe're gonna have to move\nthis monkey into a part two.\n\n352\n00:18:55.280 --> 00:18:56.370\nSo definitely join back in there.\n\n353\n00:18:56.370 --> 00:18:59.060\nWe got plenty more to cover\nwhen it comes to cryptography.\n\n354\n00:18:59.060 --> 00:19:00.590\nWe hope to see you in those episodes.\n\n355\n00:19:00.590 --> 00:19:01.740\nWes, thanks for joining us today.\n\n356\n00:19:01.740 --> 00:19:02.260\n&gt;&gt; Absolutely.\n\n357\n00:19:02.260 --> 00:19:03.930\n&gt;&gt; Thank you,\ngood folks out there for watching.\n\n358\n00:19:03.930 --> 00:19:06.880\nSigning off for ITProTV,\nI've been your host, Daniel Lowrie.\n\n359\n00:19:06.880 --> 00:19:07.700\n&gt;&gt; And, I'm Wes Bryan.\n\n360\n00:19:07.700 --> 00:19:08.927\n&gt;&gt; We'll see you next time.\n\n361\n00:19:10.503 --> 00:19:16.290\n[MUSIC]\n\n362\n00:19:16.290 --> 00:19:19.471\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "216666161"
        },
        {
          "description": "Wes and Zach discuss the science of hiding data, and working with principles of encryption. Sub-topics include Elliptic Curve, Digital Signatures, the difference between Diffusion and Confusion, Ephemeral Key, Data States, and more.",
          "length": "1953",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-1-2-basic_concepts_of_cryptography_pt2-050817-PGM.00_00_11_23.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-1-2-basic_concepts_of_cryptography_pt2-050817-PGM.00_00_11_23.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-1-2-basic_concepts_of_cryptography_pt2-050817-PGM.00_00_11_23.Still001-sm.jpg",
          "title": "Basic Concepts of Cryptography Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:02.063\nWelcome to ITPRO.TV,\nI'm your host Dan Pezet-\n\n2\n00:00:02.063 --> 00:00:06.311\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.311 --> 00:00:08.344\n[MUSIC]\n\n4\n00:00:08.344 --> 00:00:12.210\n&gt;&gt; You're watching ITPRO.TV.\n\n5\n00:00:12.210 --> 00:00:16.490\n&gt;&gt; Hello and lucky you, you made that\nintelligent choice to watch ITPRO.TV,\n\n6\n00:00:16.490 --> 00:00:19.280\nhelping you learn wherever you go.\n\n7\n00:00:19.280 --> 00:00:24.658\nI'm Zach Memos, we can continue\non With CompTIA Security + and\n\n8\n00:00:24.658 --> 00:00:26.790\nour ITPro, Wes Bryan.\n\n9\n00:00:26.790 --> 00:00:28.270\nWes, thanks for being here again.\n\n10\n00:00:28.270 --> 00:00:30.520\n&gt;&gt; Absolutely,\nhaving me back for a Part 2.\n\n11\n00:00:30.520 --> 00:00:32.410\nApparently I talked way too\nmuch in the first part.\n\n12\n00:00:32.410 --> 00:00:36.950\n&gt;&gt; That's right, this is Part 2 of\nThe Basic Concepts of Cryptography,\n\n13\n00:00:36.950 --> 00:00:39.495\nnot cryptozoology, cryptography.\n\n14\n00:00:39.495 --> 00:00:40.586\n[CROSSTALK]\n&gt;&gt; That's right if they say zoology,\n\n15\n00:00:40.586 --> 00:00:41.913\nthey're in-\n&gt;&gt; [LAUGH]\n\n16\n00:00:41.913 --> 00:00:42.689\n&gt;&gt; A wrong type cuz they're not\n\n17\n00:00:42.689 --> 00:00:43.630\ngonna learn anything.\n\n18\n00:00:43.630 --> 00:00:47.006\nBut that's right, we did talk about\na few concepts in the first episode and\n\n19\n00:00:47.006 --> 00:00:49.320\nwell, that pretty much\ntook up the first episode.\n\n20\n00:00:49.320 --> 00:00:52.620\nWe were talking about things like it and\nwe're just gonna rehashing if you will,\n\n21\n00:00:52.620 --> 00:00:54.660\npardon the pun here cuz I\nknow hashing techniques and\n\n22\n00:00:54.660 --> 00:00:56.510\nfunctions are in cryptology as well.\n\n23\n00:00:56.510 --> 00:01:00.260\nBut things like symmetric algorithms or\nmodes of operation and\n\n24\n00:01:00.260 --> 00:01:02.480\nit finds how the algorithms gonna work.\n\n25\n00:01:02.480 --> 00:01:06.870\nWe talked about asymmetric\nhashing functions as well.\n\n26\n00:01:06.870 --> 00:01:12.150\nAnd we also visit a concept of these\none time patting like techniques for\n\n27\n00:01:12.150 --> 00:01:16.530\ninstance salt, initialization vectors\nknow as IVs and nuances, right?\n\n28\n00:01:16.530 --> 00:01:17.660\nNumbers you used once.\n\n29\n00:01:18.810 --> 00:01:19.640\nBut we're gonna go ahead.\n\n30\n00:01:19.640 --> 00:01:21.560\nWe're gonna pickup,\nright where we left of.\n\n31\n00:01:21.560 --> 00:01:24.532\nNow the next thing that they're gonna\ntalk about is, what is known as ECC.\n\n32\n00:01:24.532 --> 00:01:29.480\nAnd this is something known as\nthe Elliptic Curve Cryptography.\n\n33\n00:01:29.480 --> 00:01:30.713\n&gt;&gt; Elliptical curve, elliptic.\n\n34\n00:01:30.713 --> 00:01:32.160\n&gt;&gt; Elliptic curve.\n\n35\n00:01:32.160 --> 00:01:33.830\n&gt;&gt; I'll get it right eventually.\n\n36\n00:01:33.830 --> 00:01:34.360\n&gt;&gt; Yeah.\n&gt;&gt; So\n\n37\n00:01:34.360 --> 00:01:38.280\nI used to hear the acronym that I\nsometimes forget the acronym was, right?\n\n38\n00:01:38.280 --> 00:01:40.468\nBut the good thing about this,\n\n39\n00:01:40.468 --> 00:01:45.697\nif you remember is that it takes\nadvantages of algebraic math if you will.\n\n40\n00:01:45.697 --> 00:01:49.492\nAnd you don't really have to know\nmathematics behind, I dont know\n\n41\n00:01:49.492 --> 00:01:53.829\nthe mathematics behind it but keep in\nmind when we implement things like EC OR\n\n42\n00:01:53.829 --> 00:01:56.995\nECC for instance in a diffy\nhome key exchange, right?\n\n43\n00:01:56.995 --> 00:02:00.853\nThey have a group of it of\nexchange types if you will,\n\n44\n00:02:00.853 --> 00:02:04.200\nthat uses things like elliptic cryptology.\n\n45\n00:02:04.200 --> 00:02:07.389\nKeep in mind the key\nsizes can be shorter and\n\n46\n00:02:07.389 --> 00:02:13.068\nthey could be stronger than other\ntechnologies that have larger key sizes.\n\n47\n00:02:13.068 --> 00:02:17.130\nSo that's one of the good things,\nstronger keys and smaller key sizes.\n\n48\n00:02:17.130 --> 00:02:20.020\nAnd that does help with\nthe computational power.\n\n49\n00:02:20.020 --> 00:02:22.035\nCuz keep in mind,\nwhen we say key strength,\n\n50\n00:02:22.035 --> 00:02:23.787\nright, we talk about the key length.\n\n51\n00:02:23.787 --> 00:02:27.300\nThe larger the key, the more strong it is.\n\n52\n00:02:27.300 --> 00:02:30.980\nIf you will Rezillion, two things\nlike password attacks or things like\n\n53\n00:02:30.980 --> 00:02:34.810\ncracking or hacking attacks, where you can\ntry to reverse engineer the encryption.\n\n54\n00:02:34.810 --> 00:02:38.380\nKeep in mind something like\nas simple as 128 bit is\n\n55\n00:02:38.380 --> 00:02:42.430\nreally considered weak by today's day and\nage, even on AES.\n\n56\n00:02:42.430 --> 00:02:45.560\nAES being that encryption\nstandard that we use for\n\n57\n00:02:45.560 --> 00:02:49.050\ndepartment of defence top secret\nclassified documents, right.\n\n58\n00:02:49.050 --> 00:02:52.980\nI want you to think of 256, right.\n\n59\n00:02:52.980 --> 00:02:56.140\nWhen it comes to something like 128,\nif you take two to the power of 128 and\n\n60\n00:02:56.140 --> 00:03:00.790\nyou come up with a number that is so\nbig it's mind-bogglingly large.\n\n61\n00:03:00.790 --> 00:03:03.160\nOur minds can't even\ncomprehend the possibilities.\n\n62\n00:03:03.160 --> 00:03:07.740\n128 bits, that number,\nthe possibilities is so\n\n63\n00:03:07.740 --> 00:03:12.248\nlarge, that if you converted each one of\nthose possibilities into a grain of sand,\n\n64\n00:03:12.248 --> 00:03:17.350\nit would take a container that was 1.3\nbillion times the circumference of our\n\n65\n00:03:17.350 --> 00:03:21.478\nEarth to contain all the sand,\nright, it's 340 undecillion.\n\n66\n00:03:21.478 --> 00:03:26.170\nAnd that's an amazing number in its size.\n\n67\n00:03:26.170 --> 00:03:27.660\nThat's considered weak.\n\n68\n00:03:27.660 --> 00:03:31.460\nAll those possibilities are considered\nweak by Dave's Modern Computing Standards,\n\n69\n00:03:31.460 --> 00:03:33.690\nright, or it's getting there.\n\n70\n00:03:33.690 --> 00:03:35.310\nRemember, key strength is important.\n\n71\n00:03:35.310 --> 00:03:37.940\nThat's one of the great things\nabout elliptical curve.\n\n72\n00:03:37.940 --> 00:03:41.880\nElliptic curve is the fact that\nthe key lengths can be smaller.\n\n73\n00:03:41.880 --> 00:03:45.890\nSpeeds up things like computational power,\nwhen we need to encrypt and decrypt, but\n\n74\n00:03:45.890 --> 00:03:49.040\nat the same time, retain the strengths\nof larger key sizes that you\n\n75\n00:03:49.040 --> 00:03:51.290\nwould see in other implementations.\n\n76\n00:03:51.290 --> 00:03:53.480\nSo that is important.\n\n77\n00:03:53.480 --> 00:03:57.220\nNext thing, we have talked about this\nquite extensively but we'll go ahead and\n\n78\n00:03:57.220 --> 00:04:00.670\nkind of recap it, when we talk about weep.\n\n79\n00:04:00.670 --> 00:04:02.205\nWeep, I don't know what weep is, but weak.\n\n80\n00:04:02.205 --> 00:04:05.440\n[LAUGH] Deprecating-\n&gt;&gt; I'm weeping on the inside.\n\n81\n00:04:05.440 --> 00:04:06.220\n&gt;&gt; That's right.\n\n82\n00:04:06.220 --> 00:04:08.870\nWe're shedding the electronic tear,\n&gt;&gt; [LAUGH]\n\n83\n00:04:08.870 --> 00:04:09.667\n&gt;&gt; And also,\n\n84\n00:04:09.667 --> 00:04:14.282\nthey talk about things like\ndeprecated algorithms, right.\n\n85\n00:04:14.282 --> 00:04:18.843\nSo let me give you an example,\nright, we're typically using for SSL,\n\n86\n00:04:18.843 --> 00:04:19.840\nTLS exchange.\n\n87\n00:04:19.840 --> 00:04:22.547\nWe talked about HTTPS today and\neverybody thinks SSL.\n\n88\n00:04:22.547 --> 00:04:26.556\nWell, we're really not,\nwhat we shouldn't be using SSL,\n\n89\n00:04:26.556 --> 00:04:30.050\ncause SSL is considered vulnerable,\neven 1.0.\n\n90\n00:04:30.050 --> 00:04:34.290\nBut even more so, when you go in TLS\nif people say that hey we are using\n\n91\n00:04:34.290 --> 00:04:38.740\nthe Transport Layer Security,\nright, the successor to SSL.\n\n92\n00:04:38.740 --> 00:04:43.790\nIf you're using 1.0, you might see in\nyour web browser that it says secure,\n\n93\n00:04:43.790 --> 00:04:47.440\nbut what you don't understand is without\nbringing up like developer options,\n\n94\n00:04:47.440 --> 00:04:50.920\nis that you're using an obsolete\ncypher strength, right.\n\n95\n00:04:50.920 --> 00:04:55.420\nSo the cypher suite isn't strong enough\nand could be potentially compromised.\n\n96\n00:04:55.420 --> 00:04:57.560\nSo we have to keep that in mind.\n\n97\n00:04:57.560 --> 00:05:01.828\nThings like why do we use WPA2,\nWi-Fi Protected Access II,\n\n98\n00:05:01.828 --> 00:05:05.120\nif you will,\nover something like WEP, right?\n\n99\n00:05:05.120 --> 00:05:06.440\nWired Equivalent Privacy.\n\n100\n00:05:06.440 --> 00:05:10.070\nWell, Wired Equivalent Privacy is\nconsidered completely deprecated.\n\n101\n00:05:10.070 --> 00:05:12.530\nYou really shouldn't be using\nit on your networks at all.\n\n102\n00:05:12.530 --> 00:05:15.460\nAnd if you're not aware of that, then you\nmight implement that on your networks and\n\n103\n00:05:15.460 --> 00:05:18.600\nyou can cause some kind of vulnerability\nor compromise to happen on your system.\n\n104\n00:05:18.600 --> 00:05:21.540\nSo understanding these\nalgorithms is important.\n\n105\n00:05:21.540 --> 00:05:25.200\nAnd understanding that you don't\njust pick the strongest algorithm.\n\n106\n00:05:25.200 --> 00:05:25.880\nWhy do I say that?\n\n107\n00:05:25.880 --> 00:05:30.640\nWell, it's also about things like your\nresources, your computational resources.\n\n108\n00:05:30.640 --> 00:05:34.560\nLet me give you an example where,\nmaybe you're using AES, all right.\n\n109\n00:05:34.560 --> 00:05:36.115\nAES 256 bit, right.\n\n110\n00:05:36.115 --> 00:05:41.620\nSo, relatively strong cipher,\nstream cipher or block cipher, excuse me.\n\n111\n00:05:41.620 --> 00:05:46.050\nBut the point being is it takes a lot\nof computational power, all right.\n\n112\n00:05:46.050 --> 00:05:48.920\nIt takes something that's old like\nTripleDES, it's been around for\n\n113\n00:05:48.920 --> 00:05:52.280\nlike a long time, it's old it's considered\nweak you shouldn't be using it.\n\n114\n00:05:52.280 --> 00:05:57.131\nWell why is it that two processors\nprocessing TripleDES and\n\n115\n00:05:57.131 --> 00:05:59.691\nprocessing AES 256,\n\n116\n00:05:59.691 --> 00:06:04.140\nthe one with the higher encryption link,\njust done like that, why is that?\n\n117\n00:06:04.140 --> 00:06:08.030\nWhy did the old one not out\nperform the stronger one\n\n118\n00:06:08.030 --> 00:06:12.380\nbecause in Intel they\nhave AES acceleration.\n\n119\n00:06:12.380 --> 00:06:15.640\nIt's hardware existed acceleration, right?\n\n120\n00:06:15.640 --> 00:06:17.680\nSo you don't just pick the strongest one,\n\n121\n00:06:17.680 --> 00:06:20.490\nyou have to understand what is\nthe functionality you need.\n\n122\n00:06:20.490 --> 00:06:22.727\n&gt;&gt; I was just gonna ask why,\nand you answered it already.\n\n123\n00:06:22.727 --> 00:06:23.664\n&gt;&gt; Yup.\n&gt;&gt; Yeah, perfect, that's perfect.\n\n124\n00:06:23.664 --> 00:06:24.230\n&gt;&gt; And then that's why.\n\n125\n00:06:24.230 --> 00:06:26.845\nSo for instance again,\nyou can have hardware acceleration.\n\n126\n00:06:26.845 --> 00:06:28.920\n&gt;&gt; Yeah.\n&gt;&gt; Where the hardware is doing it, right?\n\n127\n00:06:28.920 --> 00:06:31.694\nIf software does it like the older,\nI was to mention of the 3DES.\n\n128\n00:06:31.694 --> 00:06:32.464\nRight, TripleDES?\n\n129\n00:06:32.464 --> 00:06:33.577\n&gt;&gt; Mm-hm, right.\n\n130\n00:06:33.577 --> 00:06:36.930\n&gt;&gt; Well, that is your CPU that's having to\ncalculate all of those instructions right.\n\n131\n00:06:36.930 --> 00:06:39.931\nDo the encryption, do the decryption, but\n\n132\n00:06:39.931 --> 00:06:45.140\nbecause there isn't any acceleration\nthe performance degrades, right.\n\n133\n00:06:45.140 --> 00:06:50.720\nSo again, we don't just pick the strongest\nkey length or key size out there, right.\n\n134\n00:06:50.720 --> 00:06:53.310\nEverybody could be doing 4096 today, but\n\n135\n00:06:53.310 --> 00:06:55.670\nyou could see that transactions\nstart to take a few seconds.\n\n136\n00:06:55.670 --> 00:06:58.619\nAnd you have to understand in e-commerce,\nseconds matter.\n\n137\n00:06:58.619 --> 00:07:00.051\n&gt;&gt; Mm-hm, absolutely.\n\n138\n00:07:00.051 --> 00:07:02.454\n&gt;&gt; Because, I don't know about you,\nZach, but faster computers get,\n\n139\n00:07:02.454 --> 00:07:03.361\nthe more impatient I get.\n\n140\n00:07:03.361 --> 00:07:04.061\n&gt;&gt; Mm-hm.\n\n141\n00:07:04.061 --> 00:07:07.560\n&gt;&gt; But if I get to a website and\nit takes a little bit to render that.\n\n142\n00:07:07.560 --> 00:07:11.600\nOr if I gotta fill our a page or fill out\na form and I click Next, and we wait.\n\n143\n00:07:12.740 --> 00:07:14.410\nWe wait and we wait.\n\n144\n00:07:14.410 --> 00:07:16.512\nIt's just seconds, but\nit could be a second that I say nah,\n\n145\n00:07:16.512 --> 00:07:18.461\nI'll go to another website\nthat outperforms, okay.\n\n146\n00:07:18.461 --> 00:07:19.252\n&gt;&gt; Right.\n&gt;&gt; So again,\n\n147\n00:07:19.252 --> 00:07:20.596\nit's not just about the strong,\n\n148\n00:07:20.596 --> 00:07:23.740\nit's about what you need to get\naccomplished that will be important.\n\n149\n00:07:23.740 --> 00:07:24.900\n&gt;&gt; Time versus dollars.\n\n150\n00:07:24.900 --> 00:07:26.050\n&gt;&gt; That's right, so\n\n151\n00:07:26.050 --> 00:07:28.650\nsome of the other things that\nthey've mentioned is key exchange.\n\n152\n00:07:28.650 --> 00:07:34.110\nAgain, when we talk about key exchange\nkeep in mind that we need to securely\n\n153\n00:07:34.110 --> 00:07:36.420\nexchange the keys that we use for\nencryption, right?\n\n154\n00:07:36.420 --> 00:07:40.262\nFor things like pre shared key, again the\nkey has, it's the same key on both sides,\n\n155\n00:07:40.262 --> 00:07:41.852\nit's symmetric key encryption.\n\n156\n00:07:41.852 --> 00:07:46.733\nThus the encryption and decryption and\nwe have to securely transmit that key.\n\n157\n00:07:46.733 --> 00:07:50.639\nBecause if somebody compromises that key,\nnot only can they encrypt your data but\n\n158\n00:07:50.639 --> 00:07:54.092\nanything that's coming across the wire,\nthat they can gain access to,\n\n159\n00:07:54.092 --> 00:07:55.355\nthey can decrypt as well.\n\n160\n00:07:55.355 --> 00:07:59.442\nSo that's why a lot of times what we do\nis we use a combination of public key\n\n161\n00:07:59.442 --> 00:08:04.400\ncryptology, or asymmetric key encryption,\nwith symmetric key encryption.\n\n162\n00:08:04.400 --> 00:08:07.110\nIf I need to securely exchange\nthat key over public wire,\n\n163\n00:08:07.110 --> 00:08:10.870\nI can just wrap it in a public key and\nI can send it to the user that needs it.\n\n164\n00:08:10.870 --> 00:08:12.960\nAnd they can use their\nprivate key to decrypt it and\n\n165\n00:08:12.960 --> 00:08:14.780\nnow they've got the symmetric key.\n\n166\n00:08:14.780 --> 00:08:17.300\nBut it was securely transmitted\nover the wire, right?\n\n167\n00:08:17.300 --> 00:08:19.750\nSo that's why we need things\nlike secure key exchange.\n\n168\n00:08:19.750 --> 00:08:22.770\nDiffie-Hellman and\nits group goes back to the 70s.\n\n169\n00:08:22.770 --> 00:08:24.780\nI believe it was 1976.\n\n170\n00:08:24.780 --> 00:08:28.345\nIt was Whitfield Diffie and Martin\nHellman, came up with public key exchange.\n\n171\n00:08:28.345 --> 00:08:31.135\nAnd then, at the end of that year,\nor a year later, 1977,\n\n172\n00:08:31.135 --> 00:08:34.975\nit's within months of each other,\nit seems like RSA.\n\n173\n00:08:34.975 --> 00:08:39.777\nRon [INAUDIBLE] Adelman\ncame up with their form of\n\n174\n00:08:39.777 --> 00:08:42.797\npublic key cryptology that typically\nuses some kind of public key exchange.\n\n175\n00:08:44.497 --> 00:08:45.603\nAll right, so\nwhat are some of the other things.?\n\n176\n00:08:45.603 --> 00:08:47.955\nAgain, remember we're just\nkind of recapping these,\n\n177\n00:08:47.955 --> 00:08:50.217\nbecause we have talked about\nthem in other episodes.\n\n178\n00:08:50.217 --> 00:08:52.214\nThe next thing was the digital signature.\n\n179\n00:08:52.214 --> 00:08:57.097\nRemember that the digital\nsignature is a way that we can\n\n180\n00:08:57.097 --> 00:09:00.077\nverify the identity if you will.\n\n181\n00:09:00.077 --> 00:09:02.567\nWe can authenticate an end point right?\n\n182\n00:09:02.567 --> 00:09:04.188\nBecause if I take, the private key, right?\n\n183\n00:09:04.188 --> 00:09:08.003\nThe private key is the part of that key\npair that nobody has access to over\n\n184\n00:09:08.003 --> 00:09:09.030\nthe wire, right?\n\n185\n00:09:09.030 --> 00:09:12.277\nStored in a safe location on my network or\nmy machine, and\n\n186\n00:09:12.277 --> 00:09:15.129\nthen you gain access to my public key,\nall right?\n\n187\n00:09:15.129 --> 00:09:19.481\nWell, if I want to send you encrypted\ninformation, you take my public key,\n\n188\n00:09:19.481 --> 00:09:23.970\nyou encrypt that information, and you\nsend it back to me and my mathematically\n\n189\n00:09:23.970 --> 00:09:28.440\naligned private key which only I have\nis to keys on the launchpad, right?\n\n190\n00:09:28.440 --> 00:09:31.180\nIt's the one that can unlocked the box,\nright?\n\n191\n00:09:31.180 --> 00:09:34.490\nCan let me decrypt the information.\n\n192\n00:09:34.490 --> 00:09:38.156\nNow, with digital signatures, remember\nthis is where it gets a little tricky.\n\n193\n00:09:38.156 --> 00:09:41.990\nIf you want to prove that I am who I say\nI am when you talk to me over a public\n\n194\n00:09:41.990 --> 00:09:45.710\nnetwork, then chances are I\nshould use a component that only\n\n195\n00:09:45.710 --> 00:09:48.840\nI should have access\nto,which is my private key.\n\n196\n00:09:48.840 --> 00:09:51.640\nRemember these keys can do\nwhichever way we want, but\n\n197\n00:09:51.640 --> 00:09:54.320\nif one encrypts, one decrypts, right?\n\n198\n00:09:54.320 --> 00:09:57.160\nAnd in the form of public\nkey encryption we encrypt\n\n199\n00:09:57.160 --> 00:10:00.040\nwith the public key because then we\ncan give everybody access to that and\n\n200\n00:10:00.040 --> 00:10:01.600\nall they can do is\nencrypt the information.\n\n201\n00:10:01.600 --> 00:10:04.240\nI don't have to worry about\nthem opening that information.\n\n202\n00:10:04.240 --> 00:10:10.190\nHowever, in digital signatures I take the\nprivate key, and I encrypt a message and\n\n203\n00:10:10.190 --> 00:10:14.740\nI send it to you, you take my public\nkey that's mathematically aligned, and\n\n204\n00:10:14.740 --> 00:10:17.730\nyou remove that encryption,\nyou can prove that it was me.\n\n205\n00:10:17.730 --> 00:10:21.790\nIt had to be me, because I'm the only one\nthat has access to the private key, so\n\n206\n00:10:21.790 --> 00:10:25.110\nthereby you can be assured\nthat I am who I say I am.\n\n207\n00:10:25.110 --> 00:10:28.030\n&gt;&gt; I've seen a lot,\nespecially the last couple of weeks,\n\n208\n00:10:28.030 --> 00:10:30.960\nwhere companies are asking you,\nare you a robot?\n\n209\n00:10:30.960 --> 00:10:34.680\nAnd they're giving you this diagram and\nthis breakdown like a picture.\n\n210\n00:10:34.680 --> 00:10:37.290\nAnd it's several pictures\nwithin a picture.\n\n211\n00:10:37.290 --> 00:10:40.160\nHow many of these pictures\nwithin this picture are assigned\n\n212\n00:10:40.160 --> 00:10:41.410\na road sign, for instance.\n\n213\n00:10:41.410 --> 00:10:42.890\n&gt;&gt; Definitely that's\na capture functionality.\n\n214\n00:10:42.890 --> 00:10:44.830\nThat's a I can't remember [INAUDIBLE].\n\n215\n00:10:44.830 --> 00:10:46.030\nIt's got a big, long name.\n\n216\n00:10:46.030 --> 00:10:46.790\nIt's Turing test.\n\n217\n00:10:46.790 --> 00:10:49.700\nIt basically tells computers from humans.\n\n218\n00:10:49.700 --> 00:10:53.690\nAnd it stops things like your robots or\nbots that go out there.\n\n219\n00:10:53.690 --> 00:10:55.870\nAnd they try to scour as much information.\n\n220\n00:10:55.870 --> 00:10:57.850\nSo yeah, it's a capture functionality too.\n\n221\n00:10:57.850 --> 00:11:02.500\nAnd that's a great way to prove\nthat a person is a human being and\n\n222\n00:11:02.500 --> 00:11:05.460\nnot just some kind of automate bot that's\njust kind of running through forms and\n\n223\n00:11:05.460 --> 00:11:06.710\nfilling them out automatically.\n\n224\n00:11:06.710 --> 00:11:09.840\nThat's a great thing to\nhave on your websites.\n\n225\n00:11:09.840 --> 00:11:11.120\nLet's see.\n\n226\n00:11:11.120 --> 00:11:13.190\nSome of the other things\nthat they talk about.\n\n227\n00:11:13.190 --> 00:11:14.540\nThis is great.\n\n228\n00:11:14.540 --> 00:11:17.060\nThe two principles of encryption.\n\n229\n00:11:17.060 --> 00:11:19.990\nI kind of joked around about\nthis when I first started\n\n230\n00:11:19.990 --> 00:11:23.550\nresearching it as a security\nstudent dor Security Plus.\n\n231\n00:11:23.550 --> 00:11:25.395\nConfusion and diffusion, right?\n\n232\n00:11:25.395 --> 00:11:26.900\n&gt;&gt; Mm-hm.\n&gt;&gt; These are the two principles\n\n233\n00:11:26.900 --> 00:11:27.720\nof encryption.\n\n234\n00:11:27.720 --> 00:11:28.745\nWell, the first one I got.\n\n235\n00:11:28.745 --> 00:11:30.330\nI\\m confused all the time.\n\n236\n00:11:30.330 --> 00:11:31.462\nJust kidding.\n\n237\n00:11:31.462 --> 00:11:33.072\n&gt;&gt; [LAUGH]\n&gt;&gt; And then I have diffusion.\n\n238\n00:11:33.072 --> 00:11:34.942\n&gt;&gt; He's not good.\n[LAUGH]\n\n239\n00:11:34.942 --> 00:11:37.084\n&gt;&gt; [LAUGH] When we talk about confusion,\n\n240\n00:11:37.084 --> 00:11:37.780\nall right.\n\n241\n00:11:37.780 --> 00:11:40.120\nI want you to think\nabout we have plane tax,\n\n242\n00:11:40.120 --> 00:11:44.530\nwe have cypher text, we have an encryption\nalgorithm and I key associated with it.\n\n243\n00:11:44.530 --> 00:11:48.520\nAs we input the plain text,\nit encrypts and it produces cypher text.\n\n244\n00:11:48.520 --> 00:11:53.160\nScrambled text that nobody can read\nunless you have the key, all right?\n\n245\n00:11:53.160 --> 00:11:57.250\nConfusion seeks to make that key and\nthe cypher text,\n\n246\n00:11:57.250 --> 00:12:01.740\nthe relationship between the two,\nas confusing as possible, why?\n\n247\n00:12:01.740 --> 00:12:03.691\nBecause if you can see relationships,\nright?\n\n248\n00:12:03.691 --> 00:12:08.276\nPeople that are crypt analysis, they make\ntheir living on running through algorithms\n\n249\n00:12:08.276 --> 00:12:11.793\nand spotting commonalities to see\nif they can reverse engineer and\n\n250\n00:12:11.793 --> 00:12:14.500\ncompromise the algorithm, right?\n\n251\n00:12:14.500 --> 00:12:16.720\nSo confusion is the process\nof taking the key, and\n\n252\n00:12:16.720 --> 00:12:18.530\nwhatever the output of\nthe cypher text is and\n\n253\n00:12:18.530 --> 00:12:22.570\nmaking their correlations as confusing\nas possible, as complex as possible.\n\n254\n00:12:24.330 --> 00:12:29.370\nThe fusion, on the other hand,\nis a principle that essentially takes\n\n255\n00:12:29.370 --> 00:12:32.740\nany modification,\nof a single bit of plain text.\n\n256\n00:12:34.450 --> 00:12:38.010\nShould have an adverse\n[INAUDIBLE] excuse me,\n\n257\n00:12:38.010 --> 00:12:41.870\nan adverse effect on\nthe output of the cypher text.\n\n258\n00:12:41.870 --> 00:12:46.990\nIn so that if I modify just\none bit of plain text,\n\n259\n00:12:46.990 --> 00:12:52.240\nthe cypher output should\nbe affected by 50%, right?\n\n260\n00:12:52.240 --> 00:12:55.530\nSo you cannot see those patterns\neven in the cypher text,\n\n261\n00:12:55.530 --> 00:12:56.790\nfrom plain text to cypher text.\n\n262\n00:12:56.790 --> 00:13:01.920\nSo, I modify one bit,\nmodifies half the cypher text and\n\n263\n00:13:01.920 --> 00:13:05.050\nmodify to bets,\nit modifies app decipher text.\n\n264\n00:13:05.050 --> 00:13:07.350\nTrying to eliminate\npredictability in patterns.\n\n265\n00:13:07.350 --> 00:13:08.650\n&gt;&gt; Wes, where is collision?\n\n266\n00:13:08.650 --> 00:13:11.280\nHow that does come into play,\nhow can we avoid it or\n\n267\n00:13:11.280 --> 00:13:13.000\ndo we even do it if we want to?\n\n268\n00:13:13.000 --> 00:13:13.560\nThat's right.\n\n269\n00:13:13.560 --> 00:13:15.240\nWell, you don't want it to happen to you.\n\n270\n00:13:15.240 --> 00:13:16.660\n&gt;&gt; No.\n&gt;&gt; And the reason I tell you that is when\n\n271\n00:13:16.660 --> 00:13:20.450\nyou are entering your password into\na system, the system really isn't\n\n272\n00:13:20.450 --> 00:13:23.100\nlooking at let's say if you have\nan English keyboard, right?\n\n273\n00:13:23.100 --> 00:13:24.570\nYou have the original English keyboard,\n\n274\n00:13:24.570 --> 00:13:29.030\nit's not looking at the letters that we\nsee that represents our password, right?\n\n275\n00:13:29.030 --> 00:13:33.044\nWhat it's doing is it's looking at a hash\nvalue of the password that stored in its\n\n276\n00:13:33.044 --> 00:13:33.644\ndatabase.\n\n277\n00:13:33.644 --> 00:13:37.914\nRemember, it's the plain text to your\npassword fed through hashing function,\n\n278\n00:13:37.914 --> 00:13:42.345\nproduces that hash value in it's that\nvalue that store in the database.\n\n279\n00:13:42.345 --> 00:13:47.090\nWell, if I can find the way to implement\nany kind of plain text on the keyboard\n\n280\n00:13:47.090 --> 00:13:50.980\nthat produces the same value, then I don't\nneed your password authenticate I can just\n\n281\n00:13:50.980 --> 00:13:55.120\npresent the hash value, that's a hashing\ncollision, that's what rainbow tables do.\n\n282\n00:13:55.120 --> 00:13:58.030\n&gt;&gt; Right.\n&gt;&gt; Again rainbow tables they load up a big\n\n283\n00:13:58.030 --> 00:14:00.530\nlarge, I mean this could be\nterabytes of information.\n\n284\n00:14:00.530 --> 00:14:03.440\nLarge databases of all these hash values.\n\n285\n00:14:03.440 --> 00:14:06.490\nAnd what they're doing is trying and\nhoping for a collision attack, right?\n\n286\n00:14:06.490 --> 00:14:09.090\nOr a collision to happen and\nit be successful, right?\n\n287\n00:14:09.090 --> 00:14:13.530\nAnd that's where it's just looking at all\nthese hash values and if it finds one that\n\n288\n00:14:13.530 --> 00:14:16.430\nmatches your password that's called\na collision, a hashing collision.\n\n289\n00:14:16.430 --> 00:14:18.200\nThey call it a collision attack.\n\n290\n00:14:18.200 --> 00:14:19.700\nSo we have to watch that.\n\n291\n00:14:19.700 --> 00:14:22.600\nThat's why we have things like key\nstretching techniques where you can\n\n292\n00:14:22.600 --> 00:14:25.200\nimplement like bcrypt inside of Unix and\n\n293\n00:14:25.200 --> 00:14:28.670\nLinux based systems where\nthere is a potential for\n\n294\n00:14:28.670 --> 00:14:32.620\npeople to store relatively weak passwords\nthat could appear in one of these tables.\n\n295\n00:14:32.620 --> 00:14:33.770\nSo what do they do?\n\n296\n00:14:33.770 --> 00:14:37.120\nThe hash value, they take and they run it\nthrough algorithms, so that it doesn't\n\n297\n00:14:37.120 --> 00:14:41.020\nmatch what's in the database and it tries\nto prevent those collision based attack.\n\n298\n00:14:41.020 --> 00:14:45.680\nSo, we do have techniques,\nsomething like key stretching,\n\n299\n00:14:45.680 --> 00:14:48.140\nif you will, or\nadding salt to passwords, right?\n\n300\n00:14:48.140 --> 00:14:52.066\nJust a random bit of information\nthat's added to your password, and\n\n301\n00:14:52.066 --> 00:14:54.785\nthen it's run through\nthat hashing function.\n\n302\n00:14:54.785 --> 00:14:58.762\nAnd in this case, the attacker would\nhave to know what the salt is,\n\n303\n00:14:58.762 --> 00:15:01.746\nalong with the password\ncan coordinate the two and\n\n304\n00:15:01.746 --> 00:15:06.576\nthen on the algorithm before they can\ncome up with the fixed cash value and\n\n305\n00:15:06.576 --> 00:15:11.512\nit makes a little bit harder for them to\ncome up with this collection attacks.\n\n306\n00:15:11.512 --> 00:15:14.140\nAll right so,\nlet's see what else do we got?\n\n307\n00:15:14.140 --> 00:15:15.410\nSession keys.\n\n308\n00:15:15.410 --> 00:15:16.870\nSession keys are interesting.\n\n309\n00:15:16.870 --> 00:15:21.850\nSession keys are ones that basically when\nyou connect for instance to a web server\n\n310\n00:15:21.850 --> 00:15:26.130\nand the communication is\ngoing on during that session.\n\n311\n00:15:26.130 --> 00:15:30.330\nOnce you disconnect from that server and\nthere's no longer any communication.\n\n312\n00:15:30.330 --> 00:15:33.130\nAny keys that you were\nusing are discarded, right?\n\n313\n00:15:33.130 --> 00:15:37.730\nSo session keys are a great way to\nstop things like replay attacks\n\n314\n00:15:37.730 --> 00:15:40.920\nin the fact that if the session\nisn't currently active and\n\n315\n00:15:40.920 --> 00:15:42.510\nsomebody's captured that information and\n\n316\n00:15:42.510 --> 00:15:46.610\nis trying to replay it back to the server\nlater as you, well, it's a session key.\n\n317\n00:15:46.610 --> 00:15:47.939\nSession keys expire, right?\n\n318\n00:15:47.939 --> 00:15:48.728\nIt's temporary.\n\n319\n00:15:48.728 --> 00:15:49.805\nIt's no longer good.\n\n320\n00:15:49.805 --> 00:15:54.100\nAnd the person won't be able to\nmasquerade, if you will, as you.\n\n321\n00:15:54.100 --> 00:15:55.425\nIs it like an ephemeral key?\n\n322\n00:15:55.425 --> 00:15:57.667\n&gt;&gt; It's exactly the same, right?\n\n323\n00:15:57.667 --> 00:16:00.810\nThere are many different temporary keys,\nright?\n\n324\n00:16:00.810 --> 00:16:02.958\nSession key is one of them,\nit could last a little bit longer.\n\n325\n00:16:02.958 --> 00:16:06.962\nEphemeral key could be your one-time\npassword, where that password is there\n\n326\n00:16:06.962 --> 00:16:10.680\njust for, you could use it that\none time and then it's discarded.\n\n327\n00:16:10.680 --> 00:16:14.300\nIt could be something like a timed\none-time password that says okay,\n\n328\n00:16:14.300 --> 00:16:15.280\nyou have to use this.\n\n329\n00:16:15.280 --> 00:16:18.980\nBut you have to use it within 45 seconds,\nor you have to use it within 15 minutes,\n\n330\n00:16:18.980 --> 00:16:20.510\nor whatever the duration is.\n\n331\n00:16:20.510 --> 00:16:24.622\nBut essentially, an ephemeral key is one\nthat is used for a very short time or\n\n332\n00:16:24.622 --> 00:16:26.176\na period of time if you will.\n\n333\n00:16:26.176 --> 00:16:29.600\nAnd then once it's done,\nit's discarded and it's never used again.\n\n334\n00:16:29.600 --> 00:16:31.604\nAgain, that helps with\nthings like replay attacks.\n\n335\n00:16:31.604 --> 00:16:35.360\nPeople have been able to eavesdrop,\ncapture your information.\n\n336\n00:16:35.360 --> 00:16:37.060\nAnd then when you're no longer using it,\n\n337\n00:16:37.060 --> 00:16:40.290\nreplay it back to the server\ntrying to appear as you.\n\n338\n00:16:40.290 --> 00:16:43.029\nSo that's a great thing to\nhave those ephemeral keys.\n\n339\n00:16:44.100 --> 00:16:46.260\nAll right,\nthen we have other things too like-\n\n340\n00:16:46.260 --> 00:16:47.680\n&gt;&gt; The data states?\n\n341\n00:16:47.680 --> 00:16:50.139\n&gt;&gt; Data states is another good one-\n&gt;&gt; That's not a state of the union.\n\n342\n00:16:50.139 --> 00:16:52.193\n&gt;&gt; That's right, [LAUGH] that's\nnot a geographical location.\n\n343\n00:16:52.193 --> 00:16:53.170\n&gt;&gt; Different states of data.\n\n344\n00:16:53.170 --> 00:16:55.660\n&gt;&gt; That's right, so\nI want you to think about it.\n\n345\n00:16:55.660 --> 00:16:59.310\nAgain, it's not really related\nto geographical location, right?\n\n346\n00:16:59.310 --> 00:17:04.330\nIf we talk about, for instance, our data\ncan be moving, being stored right now or\n\n347\n00:17:04.330 --> 00:17:07.070\nyou could be processing it, right?\n\n348\n00:17:07.070 --> 00:17:10.241\nThere are a couple of a few different\nones that I want you to be aware of.\n\n349\n00:17:10.241 --> 00:17:13.981\nIn fact, I got a little diagram here just\nto show you the different states, right?\n\n350\n00:17:13.981 --> 00:17:14.763\n&gt;&gt; Good, I like your diagram.\n\n351\n00:17:14.763 --> 00:17:18.440\n&gt;&gt; [LAUGH] We've got data-in-transit,\nall right?\n\n352\n00:17:18.440 --> 00:17:20.420\nNow, I want you to think\nabout data-in-transit.\n\n353\n00:17:20.420 --> 00:17:21.020\nWhat does that mean?\n\n354\n00:17:21.020 --> 00:17:25.178\nWell, that means, it's traversing the\nnetwork or it could be stored in a memory\n\n355\n00:17:25.178 --> 00:17:29.107\nlocation like in a system memory and\nit's waiting to be processed, right?\n\n356\n00:17:29.107 --> 00:17:32.826\nIt could be information that stored in a\nnetwork adapters buffer that's waiting to\n\n357\n00:17:32.826 --> 00:17:33.525\nbe processed.\n\n358\n00:17:33.525 --> 00:17:38.256\nSo we have to keep in mind that that type\nof data is gonna be protected with things\n\n359\n00:17:38.256 --> 00:17:42.139\nlike encryption, hashing algorithms,\npermissions, ACLs.\n\n360\n00:17:42.139 --> 00:17:46.344\nMaking sure only the people who\nare authorized to have access to it have\n\n361\n00:17:46.344 --> 00:17:50.215\naccess to it,\nversus something like data-at-rest, right?\n\n362\n00:17:50.215 --> 00:17:53.200\nData-at-rest could be things\nlike your backup data.\n\n363\n00:17:53.200 --> 00:17:56.370\nData that's sitting on a storage medium,\nit's not being used right now.\n\n364\n00:17:56.370 --> 00:17:58.630\nIt could be a system that's\nturned off if you will.\n\n365\n00:17:58.630 --> 00:18:02.420\nIt could be data that isn't being\nused currently by any applications.\n\n366\n00:18:02.420 --> 00:18:03.227\nAnd more importantly,\n\n367\n00:18:03.227 --> 00:18:05.375\nit's not being transferred over\nthe network medium, right?\n\n368\n00:18:05.375 --> 00:18:09.560\nExamples, backups,\noff-site backups, external media.\n\n369\n00:18:09.560 --> 00:18:14.300\nWe use encryption, right,\nto be able to protect this information.\n\n370\n00:18:15.380 --> 00:18:16.535\nNow, data-in-use.\n\n371\n00:18:16.535 --> 00:18:22.100\nData-in-use is a data type that's actively\nbeing processed by applications, right?\n\n372\n00:18:22.100 --> 00:18:28.450\nIt could be currently being viewed by a\nuser or being modified by a user as well.\n\n373\n00:18:28.450 --> 00:18:35.100\nAnd again, data that's in use is typically\nprotected with things like your ACLs.\n\n374\n00:18:35.100 --> 00:18:39.720\nNow, that leads us into another concept\nthat they want you to be aware of.\n\n375\n00:18:40.810 --> 00:18:44.319\nAnd they want you to be aware of what\nare known as random number generators.\n\n376\n00:18:44.319 --> 00:18:48.185\nAnd there's a couple of different kinds\nwhen it comes to number generators.\n\n377\n00:18:48.185 --> 00:18:53.390\nAnd they call out random number generators\nand psuedo random number generators.\n\n378\n00:18:53.390 --> 00:18:56.657\nI'm gonna kinda state that\nthat's the official objective.\n\n379\n00:18:56.657 --> 00:19:00.687\nBut I want you to know the standard is\ntypically true random number generators\n\n380\n00:19:00.687 --> 00:19:02.530\nversus psuedo random, right?\n\n381\n00:19:02.530 --> 00:19:03.357\n&gt;&gt; That's the TRNG.\n\n382\n00:19:03.357 --> 00:19:04.312\n&gt;&gt; That's right,\n\n383\n00:19:04.312 --> 00:19:08.755\nthe TRNG is the true random number\ngenerator versus PRNG might be something.\n\n384\n00:19:08.755 --> 00:19:12.228\nIt's a psuedo random number generator and\nthat will be the acronym you see.\n\n385\n00:19:12.228 --> 00:19:15.001\nSo what are the differences here, right?\n\n386\n00:19:15.001 --> 00:19:17.181\nWell, understand that\ninside the computing,\n\n387\n00:19:17.181 --> 00:19:19.790\nnothing happens unless\nyou program it that way.\n\n388\n00:19:19.790 --> 00:19:23.620\nWhich means, there is no random, we don't\nhave randomization inside the computing\n\n389\n00:19:23.620 --> 00:19:26.278\nunless you program it that way, right?\n\n390\n00:19:26.278 --> 00:19:29.212\nSo with a pseudo random number generator,\n\n391\n00:19:29.212 --> 00:19:31.120\nright, that's about all we\ncan get in the computing.\n\n392\n00:19:31.120 --> 00:19:32.760\nPseudo random.\n\n393\n00:19:32.760 --> 00:19:37.420\nAll right, it's not truly random, all\nright, but it is basically a random string\n\n394\n00:19:37.420 --> 00:19:42.050\nof numbers that is created via some\nkinda mathematical algorithm operation.\n\n395\n00:19:42.050 --> 00:19:43.344\nAgain, it's not truly random.\n\n396\n00:19:43.344 --> 00:19:48.307\nHowever, the number string that is\nbeing compared to a truly random string\n\n397\n00:19:48.307 --> 00:19:51.270\nappears though it's random, right?\n\n398\n00:19:51.270 --> 00:19:52.660\nSo it's not truly random.\n\n399\n00:19:52.660 --> 00:19:55.450\nAnd it's achieved through some\nkind of mathematical algorithm.\n\n400\n00:19:55.450 --> 00:20:02.440\nHowever, a true random number generator\nproduces a true random string of data.\n\n401\n00:20:02.440 --> 00:20:04.285\nAnd it's based on some kind\nof physical process, right?\n\n402\n00:20:04.285 --> 00:20:07.823\nIt could be static that's measure\nin the airwaves, ocean waves,\n\n403\n00:20:07.823 --> 00:20:09.350\nthings like thermal noise.\n\n404\n00:20:09.350 --> 00:20:13.250\nNature creates truly random patterns,\nright?\n\n405\n00:20:13.250 --> 00:20:14.500\nAnd these can get very expensive.\n\n406\n00:20:14.500 --> 00:20:17.560\nYou say, well, wait a second, how am I\ngonna harness the power of nature and\n\n407\n00:20:17.560 --> 00:20:18.810\nuse this random-\n&gt;&gt; [LAUGH]\n\n408\n00:20:18.810 --> 00:20:19.750\n&gt;&gt; Randomness if you will?\n\n409\n00:20:19.750 --> 00:20:24.774\nWell, they actually got different types\nof hardware devices, right, that can use.\n\n410\n00:20:24.774 --> 00:20:29.385\nHere's one, the Alea II true\ncompact random number generator.\n\n411\n00:20:29.385 --> 00:20:31.890\nThese are not cheap, guys.\n\n412\n00:20:31.890 --> 00:20:34.672\nLet me give you an example,\n$795 for this little thing.\n\n413\n00:20:34.672 --> 00:20:35.750\n&gt;&gt; Goodness.\n\n414\n00:20:35.750 --> 00:20:39.013\n&gt;&gt; And again, if you need true randomness,\nthis is where you're gonna go.\n\n415\n00:20:39.013 --> 00:20:41.607\nHowever, you can also do,\nthese are hardware-based,\n\n416\n00:20:41.607 --> 00:20:44.070\nyou can also do something\nlike software-based.\n\n417\n00:20:44.070 --> 00:20:47.705\nFor instance, a great website\nthat I like to call random.org.\n\n418\n00:20:47.705 --> 00:20:53.177\nAnd it will give you the chance to\ndo true random number generation or\n\n419\n00:20:53.177 --> 00:20:56.450\neven pseudo random number generation.\n\n420\n00:20:56.450 --> 00:21:00.707\nSo you can see that they're hardware-based\nas well as being software-based likewise.\n\n421\n00:21:01.860 --> 00:21:04.002\nAll right, let's see,\nwhat else do we got here too?\n\n422\n00:21:04.002 --> 00:21:08.054\nAll right, so\nthe next thing that we're gonna look at is\n\n423\n00:21:08.054 --> 00:21:11.517\nimplementation versus algorithm selection.\n\n424\n00:21:11.517 --> 00:21:14.571\nAnd what they're talking about here\nreally is a couple of concepts.\n\n425\n00:21:14.571 --> 00:21:17.716\nThey talk about what's known\nas a crypto service provider.\n\n426\n00:21:17.716 --> 00:21:22.210\nIn Microsoft land, you might hear call\na cryptographic service provider.\n\n427\n00:21:22.210 --> 00:21:24.410\nThey just kinda shorten\nup here of the objective.\n\n428\n00:21:24.410 --> 00:21:29.230\nSo crypto service provider as\nwell as crypto modules, right?\n\n429\n00:21:29.230 --> 00:21:33.925\nAnd what this does basically the crypto\nservice provider, it provides an abstract\n\n430\n00:21:33.925 --> 00:21:37.691\nlayer between the cryptographic\ncomponents and an application.\n\n431\n00:21:37.691 --> 00:21:41.634\nSo that the application itself doesn't\nhave to know anything about the cryptology\n\n432\n00:21:41.634 --> 00:21:42.600\nin the background.\n\n433\n00:21:42.600 --> 00:21:45.170\nAnd it essentially has\na module if you will or\n\n434\n00:21:45.170 --> 00:21:47.770\nan API that it can communicate with.\n\n435\n00:21:47.770 --> 00:21:50.140\nIn fact, let me show you here,\nI'll give you an example.\n\n436\n00:21:50.140 --> 00:21:53.397\nSo if you have these in Windows\ncryptographic service providers.\n\n437\n00:21:53.397 --> 00:21:57.531\nAnd if you're implementing something like\nActive Directory Certificate Services as\n\n438\n00:21:57.531 --> 00:21:59.050\npart of setting up.\n\n439\n00:21:59.050 --> 00:22:01.760\nWell, let's see if I can\ndo this here real quick.\n\n440\n00:22:01.760 --> 00:22:03.600\nNope, I don't need PowerShell here.\n\n441\n00:22:03.600 --> 00:22:04.672\nI'm gonna try that again.\n\n442\n00:22:04.672 --> 00:22:05.790\n&gt;&gt; The PowerShell.\n\n443\n00:22:05.790 --> 00:22:07.824\n&gt;&gt; So if I have a certificate authority,\n\n444\n00:22:07.824 --> 00:22:10.497\nright, and\nwe're implementing certificates,\n\n445\n00:22:10.497 --> 00:22:13.948\nwe have to have a cryptographic\nservice provider essentially.\n\n446\n00:22:13.948 --> 00:22:20.188\nAnd let's see, certificate managers here,\npolicy module and I am not seeing it.\n\n447\n00:22:20.188 --> 00:22:22.950\nIn fact, I'll tell you what,\nI know another place that we can go and\n\n448\n00:22:22.950 --> 00:22:23.637\nwe can see this.\n\n449\n00:22:23.637 --> 00:22:25.250\nIn fact,\nwe can dig down into the registry.\n\n450\n00:22:25.250 --> 00:22:27.004\nIn fact, let me go ahead and do that.\n\n451\n00:22:27.004 --> 00:22:30.034\nWe'll pull up our good old regedit,\n\n452\n00:22:30.034 --> 00:22:35.525\nbecause I do know where some are in\nthere and we can kinda see these.\n\n453\n00:22:35.525 --> 00:22:39.162\nSo for instance,\nif we kinda drill down in here,\n\n454\n00:22:39.162 --> 00:22:43.791\nwe can go to, let's see,\nwe're at HKEY_LOCAL_MACHINE.\n\n455\n00:22:43.791 --> 00:22:45.789\nLet me go ahead and\nscroll back up here and we'll find it.\n\n456\n00:22:45.789 --> 00:22:47.843\nLooks like I'm in the control set.\n\n457\n00:22:47.843 --> 00:22:51.710\nSo HKEY_LOCAL_MACHINE,\nwe're gonna be under SOFTWARE.\n\n458\n00:22:52.710 --> 00:22:57.487\nWe're gonna be under Microsoft, and\nthen there should be here in Cs.\n\n459\n00:22:57.487 --> 00:22:59.821\nWe're gonna be looking at Cryptography.\n\n460\n00:23:01.946 --> 00:23:05.690\nAnd then under Defaults and\nyou'll see Providers, right?\n\n461\n00:23:05.690 --> 00:23:10.208\nOkay, so Providers essentially\nis based on the module, right?\n\n462\n00:23:10.208 --> 00:23:13.400\nThe module could be a hardware device or\nsoftware device.\n\n463\n00:23:13.400 --> 00:23:17.036\nAnd it performs basically\nthe cryptographic functions whether it's\n\n464\n00:23:17.036 --> 00:23:19.198\nphysical or between a logical boundary.\n\n465\n00:23:19.198 --> 00:23:22.762\nAnd you can see, here are some of\nthe cryptographic service providers.\n\n466\n00:23:22.762 --> 00:23:24.619\nAnd again, you can see that Microsoft,\n\n467\n00:23:24.619 --> 00:23:27.020\nsome other than they\ncall a Crypto Provider.\n\n468\n00:23:27.020 --> 00:23:29.320\nBut you can also see\nCryptographic Provider too.\n\n469\n00:23:29.320 --> 00:23:30.820\nSo don't let that fool you.\n\n470\n00:23:30.820 --> 00:23:34.630\nAnd again, what this does is basically\nthe crytographic service provider.\n\n471\n00:23:34.630 --> 00:23:38.999\nEssentially, it's the implementation\nof the algorithm itself and\n\n472\n00:23:38.999 --> 00:23:41.190\nhere is the different standards.\n\n473\n00:23:41.190 --> 00:23:45.020\nAnd you can see some of the standards\nthat these different ones adhere to.\n\n474\n00:23:45.020 --> 00:23:46.880\nYou can see Diffie Hellman\nthat we've talked about,\n\n475\n00:23:46.880 --> 00:23:48.840\nthings like public key exchange.\n\n476\n00:23:48.840 --> 00:23:54.116\nYou can see 1.0 here and there's a whole\nbunch of different ones, RSA and AES.\n\n477\n00:23:54.116 --> 00:23:58.512\nAnd it essentially defines based on which\none we choose is how it's going to be\n\n478\n00:23:58.512 --> 00:24:02.180\nimplemented and Microsoft has\nsome of theirs that are built in.\n\n479\n00:24:02.180 --> 00:24:03.070\nYou can see it here.\n\n480\n00:24:03.070 --> 00:24:07.527\nBut there are also third-party\ncryptographic service providers as well.\n\n481\n00:24:07.527 --> 00:24:11.500\nSo know what the CSP is.\n\n482\n00:24:11.500 --> 00:24:16.306\nUnderstand it's just how the algorithm is\ngonna be implemented in the standards that\n\n483\n00:24:16.306 --> 00:24:16.848\nit uses.\n\n484\n00:24:16.848 --> 00:24:20.500\nAnd again, the CSPs are the abstract\ncomponent if you will.\n\n485\n00:24:20.500 --> 00:24:25.160\nSo that the application itself\ndoesn't have to know what\n\n486\n00:24:25.160 --> 00:24:26.889\nany of the cryptology in the background.\n\n487\n00:24:27.920 --> 00:24:29.850\nLet's see, what else do we have here.\n\n488\n00:24:29.850 --> 00:24:33.030\nFor instance, they also talk about\nanother concept, and that's PFS,\n\n489\n00:24:33.030 --> 00:24:36.280\nand that's perfect forward secrecy.\n\n490\n00:24:36.280 --> 00:24:38.000\nI'll go ahead and talk about what that is.\n\n491\n00:24:38.000 --> 00:24:41.750\nSo we've got a client and\nwe've got a server.\n\n492\n00:24:41.750 --> 00:24:44.420\nWouldn't it be nice that if we're going\nto forward information we can do,\n\n493\n00:24:44.420 --> 00:24:46.360\nwe were talking about ephemeral, right?\n\n494\n00:24:46.360 --> 00:24:51.419\nWe can do something that is set up just\nfor that session and that session only.\n\n495\n00:24:51.419 --> 00:24:54.693\nAnd the thought process is that\nif it's unique to every session,\n\n496\n00:24:54.693 --> 00:24:58.324\nthen that gives less time for\nthe attacker to capture that information,\n\n497\n00:24:58.324 --> 00:25:02.132\ntry to reverse engineer it and pass it\nback to the server in your behalf trying\n\n498\n00:25:02.132 --> 00:25:04.480\nto take you out of the communication.\n\n499\n00:25:04.480 --> 00:25:07.120\nSo how does perfect forward secrecy work,\nall right?\n\n500\n00:25:07.120 --> 00:25:08.820\nWell, let's say it starts with a server,\nright?\n\n501\n00:25:08.820 --> 00:25:13.480\nLet's say the server is gonna start the\nperfect forward secrecy if I can say that.\n\n502\n00:25:13.480 --> 00:25:18.780\nSo step one, server generates new keys,\nwe go key A and B here.\n\n503\n00:25:18.780 --> 00:25:23.280\nNext thing that happens is key A is\ngonna be sent to the client, right?\n\n504\n00:25:23.280 --> 00:25:24.790\nNow, what happens?\n\n505\n00:25:24.790 --> 00:25:29.680\nIn step two,\nafter the client receives the server key,\n\n506\n00:25:29.680 --> 00:25:32.970\nit just generates a random value,\nall right?\n\n507\n00:25:32.970 --> 00:25:36.257\nAnd it takes that key that\nthe server gave it and\n\n508\n00:25:36.257 --> 00:25:39.048\nit encrypts the random value, right?\n\n509\n00:25:39.048 --> 00:25:41.822\nWell, that produces\nan encrypted value of D.\n\n510\n00:25:41.822 --> 00:25:45.780\nAnd then it passes that back\nto the server, all right?\n\n511\n00:25:45.780 --> 00:25:49.744\nNow, the server is going to use, kinda\nlike we talk about public key cryptology,\n\n512\n00:25:49.744 --> 00:25:50.330\nremember?\n\n513\n00:25:50.330 --> 00:25:53.760\nThere was two keys that was generated,\nA is gonna do the encryption,\n\n514\n00:25:53.760 --> 00:25:56.230\nB is gonna do the decryption.\n\n515\n00:25:56.230 --> 00:26:01.744\nSo when the client takes the public key,\nencrypts the random number,\n\n516\n00:26:01.744 --> 00:26:06.897\nthe encrypted value is then sent\nback over the wire to the server.\n\n517\n00:26:06.897 --> 00:26:12.173\nAnd the server uses the matching private\nkey, two keys on the launch pad, right?\n\n518\n00:26:12.173 --> 00:26:12.751\n&gt;&gt; Yep.\n\n519\n00:26:12.751 --> 00:26:15.340\n&gt;&gt; Decrypt what the random value is.\n\n520\n00:26:15.340 --> 00:26:20.000\nSo now, we have a random value\nthat is used on both sides,\n\n521\n00:26:20.000 --> 00:26:25.940\nclient has random value C,\nserver has random value C.\n\n522\n00:26:25.940 --> 00:26:31.120\nAnybody that was out there trying to\ngather that information didn't have key B,\n\n523\n00:26:31.120 --> 00:26:32.880\nright, that only the server had.\n\n524\n00:26:32.880 --> 00:26:35.580\nSo there's no way they could encrypt it or\ndecrypt it.\n\n525\n00:26:35.580 --> 00:26:40.420\nSo now, what we have is we have\nC is gonna be used as a key with\n\n526\n00:26:40.420 --> 00:26:44.930\nwhatever the agreed upon cipher is to\nencrypt further traffic after that.\n\n527\n00:26:44.930 --> 00:26:51.170\nKeep in mind, that all of these keys,\nA, B, the random value C and\n\n528\n00:26:51.170 --> 00:26:55.280\neven the encrypted value D,\nare only going to be used for\n\n529\n00:26:55.280 --> 00:26:57.060\nthese communication-\n&gt;&gt; It's temporary.\n\n530\n00:26:57.060 --> 00:26:57.790\n&gt;&gt; Right, that's right.\n\n531\n00:26:57.790 --> 00:27:01.410\nSo session key,\nan ephemeral key if you will.\n\n532\n00:27:01.410 --> 00:27:05.030\nIt is just going to be used temporarily.\n\n533\n00:27:05.030 --> 00:27:07.960\nAll right, so and\nthe last thing that they call out,\n\n534\n00:27:07.960 --> 00:27:11.620\nthey call out what's known as\nthe security through obscurity.\n\n535\n00:27:11.620 --> 00:27:14.965\nBe careful with this, network address\ntranslation could be one of those that\n\n536\n00:27:14.965 --> 00:27:17.009\ncould be considered security\nthrough obscurity, right?\n\n537\n00:27:18.430 --> 00:27:20.240\nIf you remember network\naddress translation,\n\n538\n00:27:20.240 --> 00:27:23.040\ntakes those private IP addresses and\nallows us to\n\n539\n00:27:23.040 --> 00:27:27.350\nmap them to public IP addresses, to be\nable to send them across the Internet.\n\n540\n00:27:27.350 --> 00:27:31.862\nWell, when you're doing that, you're\nreally not truly hiding what the internal\n\n541\n00:27:31.862 --> 00:27:36.810\nprivate IP address is, because it's just\nobscured like an onion layer, right?\n\n542\n00:27:36.810 --> 00:27:39.980\nPeel back the layers and\nyou can see what that actually is.\n\n543\n00:27:39.980 --> 00:27:43.570\nSo it's not really that you're securing\nanything, it's security through obscurity.\n\n544\n00:27:43.570 --> 00:27:46.070\nLet me give you a classic example of that,\nright?\n\n545\n00:27:46.070 --> 00:27:48.581\nIf I take a key and I put it under or\n\n546\n00:27:48.581 --> 00:27:53.887\nput it over the light right outside\nof my front door, it's secure.\n\n547\n00:27:53.887 --> 00:27:58.377\nBut hopefully, thinking that a robber\ndoesn't know to look over the light or\n\n548\n00:27:58.377 --> 00:28:00.324\nto look into the carpet, right?\n\n549\n00:28:00.324 --> 00:28:04.340\nSo on its base value,\non its surface, it looks secure.\n\n550\n00:28:04.340 --> 00:28:06.030\nBut it's not, it's not truly secure.\n\n551\n00:28:06.030 --> 00:28:08.010\nIt's just obscure the fact\nthat it's actually there.\n\n552\n00:28:08.010 --> 00:28:09.800\nSo it's not truly secure.\n\n553\n00:28:09.800 --> 00:28:12.640\nSo keep in mind that security through\nobscurity just means that you don't\n\n554\n00:28:12.640 --> 00:28:14.020\nknow the fact that something is there.\n\n555\n00:28:14.020 --> 00:28:16.720\nBut with a little bit of know-how,\nyou can find it.\n\n556\n00:28:16.720 --> 00:28:19.370\nSo anybody that's experienced, right?\n\n557\n00:28:19.370 --> 00:28:21.053\nWell, a lot of times we\ntalk about something.\n\n558\n00:28:21.053 --> 00:28:24.914\nFor instance, securing your network\nsometimes can only keep the honest people\n\n559\n00:28:24.914 --> 00:28:27.410\nout, doesn't do much for the attackers.\n\n560\n00:28:27.410 --> 00:28:30.595\nYou have to make sure that you're not just\nobscuring your information that you truly\n\n561\n00:28:30.595 --> 00:28:35.085\nare keeping it safe from outside eyes,\nprying eyes if you will.\n\n562\n00:28:35.085 --> 00:28:36.895\nUnauthorized access.\n\n563\n00:28:36.895 --> 00:28:38.385\nBut let's talk real quick.\n\n564\n00:28:38.385 --> 00:28:40.775\nI know that, wow, we are running\na little bit short on time here.\n\n565\n00:28:40.775 --> 00:28:44.925\nLet's talk about a few last things,\ncommon use cases.\n\n566\n00:28:44.925 --> 00:28:47.445\nAll right,\nnow I've already kind of mentioned that\n\n567\n00:28:47.445 --> 00:28:49.735\nthey talk about low-powered devices.\n\n568\n00:28:49.735 --> 00:28:51.180\nLow-powered devices,\n\n569\n00:28:51.180 --> 00:28:54.100\nyou have to worry about the computational\npower of your encryption.\n\n570\n00:28:54.100 --> 00:28:59.120\nYes, it strengthens your encryption but\nalso it puts a burden on the device that\n\n571\n00:28:59.120 --> 00:29:01.200\nCPU that's trying to do the encryption and\ndecryption.\n\n572\n00:29:01.200 --> 00:29:05.090\nAnd if it happens to be a mobile device,\ndoes it have enough power to do that?\n\n573\n00:29:05.090 --> 00:29:07.420\nDoesn't have enough computational\npower to begin with to do that.\n\n574\n00:29:07.420 --> 00:29:11.320\nIf it's an IoT-based device, then chances\nare it's got lower computing strength and\n\n575\n00:29:11.320 --> 00:29:14.980\nit's not really gonna be do well\nwith higher encryption levels.\n\n576\n00:29:14.980 --> 00:29:17.865\nLow latency, right, delay?\n\n577\n00:29:17.865 --> 00:29:22.609\nJust strengthen your encryption, you'll\nalso lengthen the time that it takes to\n\n578\n00:29:22.609 --> 00:29:27.023\ndo the encryption and decryption process,\nwhich could increase latency.\n\n579\n00:29:27.023 --> 00:29:28.593\nFor instance, VPN communications.\n\n580\n00:29:28.593 --> 00:29:33.330\nThat's why we implement VPN concentrators,\ncuz a single VPN communication is\n\n581\n00:29:33.330 --> 00:29:37.230\nencapsulating, encrypting,\ndecapsulating and decrypting.\n\n582\n00:29:37.230 --> 00:29:38.700\nJust a single communication.\n\n583\n00:29:38.700 --> 00:29:40.600\nSo imagine the device that,\nthat's passing through,\n\n584\n00:29:40.600 --> 00:29:43.010\nhas to do all of that just for\none connection.\n\n585\n00:29:43.010 --> 00:29:44.795\nNow, multiply that connection by 1,000.\n\n586\n00:29:46.770 --> 00:29:48.400\nCan it handle it?\n\n587\n00:29:48.400 --> 00:29:49.650\nChances are probably not.\n\n588\n00:29:49.650 --> 00:29:51.420\nThat's why we have VPN concentrators,\nright?\n\n589\n00:29:51.420 --> 00:29:55.530\nSo we can scale up a lot larger and\nnot increase latency.\n\n590\n00:29:55.530 --> 00:29:56.718\nHigh resiliency.\n\n591\n00:29:56.718 --> 00:30:00.210\nAgain, resiliency, it's one of the reasons\nwe implement things like key stretching,\n\n592\n00:30:00.210 --> 00:30:05.360\nsalt, IVs, nuances to increase the\nresiliency against password attacks and\n\n593\n00:30:05.360 --> 00:30:07.010\ncracking attacks.\n\n594\n00:30:07.010 --> 00:30:09.135\nSupporting confidentiality, right?\n\n595\n00:30:09.135 --> 00:30:12.378\nWe talked about asymmetric encryption and\nsymmetric key encryption.\n\n596\n00:30:12.378 --> 00:30:14.400\nSupporting integrity.\n\n597\n00:30:14.400 --> 00:30:17.010\nWe talked about things like\ndigital certificates and\n\n598\n00:30:17.010 --> 00:30:20.180\nhashing values, hashing functions.\n\n599\n00:30:20.180 --> 00:30:23.500\nSupporting obfuscation,\nthink of things like Rock 13.\n\n600\n00:30:23.500 --> 00:30:27.650\nThink of things like the XOR process and\nsubstitution ciphers, right?\n\n601\n00:30:27.650 --> 00:30:28.640\nClassic example.\n\n602\n00:30:28.640 --> 00:30:33.080\nSupporting authentication, asymmetric\nkey encryption and digital signatures.\n\n603\n00:30:33.080 --> 00:30:36.830\nPerfect forward secrecy is\nanother way that we can do this.\n\n604\n00:30:36.830 --> 00:30:40.890\nSupporting authentication, key stretching,\nsupporting non-repudiation,\n\n605\n00:30:40.890 --> 00:30:45.510\ndigital signatures, asymmetric key\nencryption and perfect forward secrecy.\n\n606\n00:30:46.580 --> 00:30:49.540\nThe fact that if I send you a piece\nof data, I can't later say, Zack,\n\n607\n00:30:49.540 --> 00:30:50.120\nI'm sorry man.\n\n608\n00:30:50.120 --> 00:30:52.999\nYou're cuckoo for cocoa puffs,\nthat didn't come from me.\n\n609\n00:30:52.999 --> 00:30:54.131\nHe could say, no.\n\n610\n00:30:54.131 --> 00:30:57.031\nLook at the timestamp on this,\nlook at the source of the information,\n\n611\n00:30:57.031 --> 00:30:59.159\nit came from your computer and\nit came at 2:30.\n\n612\n00:30:59.159 --> 00:31:03.800\nNon-repudiation, I can't refute the fact\nlater that that data was me or sent by me.\n\n613\n00:31:03.800 --> 00:31:08.220\nSo basically, non-repudiation\nis making sure the data that\n\n614\n00:31:08.220 --> 00:31:12.559\noriginates from a user stays\nattached to that user, right?\n\n615\n00:31:12.559 --> 00:31:13.425\nWhat else?\n\n616\n00:31:13.425 --> 00:31:16.744\nResource versus security constraints.\n\n617\n00:31:16.744 --> 00:31:17.670\nKeep in mind,\n\n618\n00:31:17.670 --> 00:31:23.910\nsecurity constraints define the level of\nprivileges on a collection of resources.\n\n619\n00:31:23.910 --> 00:31:28.360\nSecurity constraints either grant or\ndeny access to that resource.\n\n620\n00:31:28.360 --> 00:31:32.370\nAll right, now, I kinda looking out here,\nI think we're gonna cut it all.\n\n621\n00:31:32.370 --> 00:31:36.270\nYeah, so again, there's a lot of\ndifferent things that we've talked\n\n622\n00:31:36.270 --> 00:31:38.289\nabout through part one and part two.\n\n623\n00:31:38.289 --> 00:31:41.440\nAnd we do have another episode\nthat we have done in the past too,\n\n624\n00:31:41.440 --> 00:31:44.650\non some of the basics or ciphers and\nthen cryptology as well.\n\n625\n00:31:44.650 --> 00:31:47.967\nI would definitely know the algorithms,\nsome of the languages,\n\n626\n00:31:47.967 --> 00:31:49.664\nthe languages that we've used.\n\n627\n00:31:49.664 --> 00:31:53.683\nKnow the jargon and definitely know some\nof the situations in which you might find\n\n628\n00:31:53.683 --> 00:31:55.576\nyourself using these technologies or\n\n629\n00:31:55.576 --> 00:32:00.240\nthese individual components, just so you\nwill be able to pass that Security+ exam.\n\n630\n00:32:00.240 --> 00:32:00.928\n&gt;&gt; Wes, thank you.\n\n631\n00:32:00.928 --> 00:32:05.615\nBasic concepts of cryptology and\nthere's more of the CompTIA Security+.\n\n632\n00:32:05.615 --> 00:32:08.787\nIf you've missed with some of\nthe episodes before, please go back and\n\n633\n00:32:08.787 --> 00:32:11.490\nwatch them again, and\nthey'll be even more coming up too.\n\n634\n00:32:11.490 --> 00:32:13.930\nSo hang on tight for that one.\n\n635\n00:32:13.930 --> 00:32:15.915\nI'm Zack Memos for ITProTV.\n\n636\n00:32:15.915 --> 00:32:16.910\n&gt;&gt; And I'm Wes Bryan.\n\n637\n00:32:16.910 --> 00:32:18.110\n&gt;&gt; And we thank you for watching.\n\n638\n00:32:18.110 --> 00:32:20.523\nCome back and see us again.\n\n639\n00:32:20.523 --> 00:32:26.447\n[MUSIC]\n\n640\n00:32:26.447 --> 00:32:30.359\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "217550123"
        },
        {
          "description": "Wes and Zach cover what are cryptography algorithms, basic characteristics, different types of cyphertext, encryption keys, difference between block & stream cyphers, symmetric & asymmetric algorithms, and more.",
          "length": "1908",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-1-cryptography_algorithms_basics-052617-PGM.00_31_33_17.Still002.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-1-cryptography_algorithms_basics-052617-PGM.00_31_33_17.Still002-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-1-cryptography_algorithms_basics-052617-PGM.00_31_33_17.Still002-sm.jpg",
          "title": "Cryptography Algorithms Basics",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:01.046\nWelcome to ITProTV.\n\n2\n00:00:01.046 --> 00:00:02.471\nI'm your host, Don Pezet.\n\n3\n00:00:02.471 --> 00:00:06.534\n[CROSSTALK]\n\n4\n00:00:06.534 --> 00:00:08.330\n[MUSIC]\n\n5\n00:00:08.330 --> 00:00:11.561\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:11.561 --> 00:00:14.406\n&gt;&gt; Thank you for\njoining us here on ITProTV.\n\n7\n00:00:14.406 --> 00:00:17.320\nHelping you learn, wherever you go.\n\n8\n00:00:17.320 --> 00:00:21.160\nI'm your host, Zach Memos,\nas we continue on with CompTIA Security+.\n\n9\n00:00:21.160 --> 00:00:25.940\nAnd today, Wes is gonna lead us into\ncryptography algorithms basics.\n\n10\n00:00:25.940 --> 00:00:26.710\nIt's exciting.\n\n11\n00:00:26.710 --> 00:00:27.690\nWes Bryan, how you doing?\n\n12\n00:00:27.690 --> 00:00:28.680\n&gt;&gt; I'm doing okay, Zach.\n\n13\n00:00:28.680 --> 00:00:29.476\nHow you doing?\nThanks for having me here.\n\n14\n00:00:29.476 --> 00:00:30.500\n&gt;&gt; Great, great.\n&gt;&gt; That's right.\n\n15\n00:00:30.500 --> 00:00:33.566\nWe're gonna be looking at some of\nthe basics of cryptography today and well,\n\n16\n00:00:33.566 --> 00:00:34.709\nthis is an important topic.\n\n17\n00:00:34.709 --> 00:00:38.710\nCuz we are talking about\nSecurity+ through this series.\n\n18\n00:00:38.710 --> 00:00:41.900\nSo we're gonna be looking at\nthings like asymmetric algorithms.\n\n19\n00:00:41.900 --> 00:00:45.310\nWe're gonna look at symmetric\nkey encryption, if you will.\n\n20\n00:00:45.310 --> 00:00:47.410\nAnd we'll just look at the basics\nof encryption as well.\n\n21\n00:00:47.410 --> 00:00:49.473\nSo that is what we're\ngonna do diving into-\n\n22\n00:00:49.473 --> 00:00:51.210\n&gt;&gt; Here's my time out.\n\n23\n00:00:51.210 --> 00:00:52.120\n&gt;&gt; Okay.\n\n24\n00:00:52.120 --> 00:00:57.590\n&gt;&gt; Not legitimately.\nWhat are, what is cryptography algorithms?\n\n25\n00:00:57.590 --> 00:00:59.140\nCan we just break that down first?\n\n26\n00:00:59.140 --> 00:01:01.290\n&gt;&gt; Most definitely, so\nwhat an algorithm is for\n\n27\n00:01:01.290 --> 00:01:05.170\nus is it's basically a mathematical\noperation that we apply data that takes\n\n28\n00:01:05.170 --> 00:01:10.060\ndata from what is known as plaintext\ninto something known as ciphertext.\n\n29\n00:01:10.060 --> 00:01:11.410\nIn fact, I got a little diagram here.\n\n30\n00:01:11.410 --> 00:01:14.150\nLet's talk about encryption and\ndecryption basics.\n\n31\n00:01:14.150 --> 00:01:17.430\nAgain an algorithm is nothing\nmore than a set of rules,\n\n32\n00:01:17.430 --> 00:01:21.690\nif you will, a set of operations\nthat is applied to data.\n\n33\n00:01:21.690 --> 00:01:23.770\nAnd you run that over the file and\n\n34\n00:01:23.770 --> 00:01:26.770\nthen what happens is we\nget an encrypted output.\n\n35\n00:01:26.770 --> 00:01:29.530\nNow you'll notice I say\na unique encrypted output.\n\n36\n00:01:29.530 --> 00:01:32.940\nWell, that's because we also\napply what is known as a key\n\n37\n00:01:32.940 --> 00:01:34.320\nto our encryption algorithm.\n\n38\n00:01:34.320 --> 00:01:37.510\nSee, the encryption algorithm is nothing\nmore than a mathematical operation.\n\n39\n00:01:37.510 --> 00:01:42.020\nAnd much smarter people than I could see\nthat algorithm and could break it down and\n\n40\n00:01:42.020 --> 00:01:43.990\nwould know how the algorithm works.\n\n41\n00:01:43.990 --> 00:01:46.300\nSo what's unique about that?\n\n42\n00:01:46.300 --> 00:01:50.230\nIf you know how the mathematical\noperations work then you could probably\n\n43\n00:01:50.230 --> 00:01:52.660\nundo those mathematical operations.\n\n44\n00:01:52.660 --> 00:01:55.800\nThe key is kind of like a modifier\nthat we apply to the algorithm,\n\n45\n00:01:55.800 --> 00:01:57.570\nthe key is unique to you and I.\n\n46\n00:01:57.570 --> 00:02:01.850\nSo that if we apply the algorithm,\nwe apply that key that only you and\n\n47\n00:02:01.850 --> 00:02:05.850\nI have access to, that's what we\nmean when we say a unique output.\n\n48\n00:02:05.850 --> 00:02:10.180\nNow notice that I've mentioned something\nhere in the diagram, notice ciphertext.\n\n49\n00:02:10.180 --> 00:02:13.660\nLet's talk a little bit about\nwhat that is coming up, okay?\n\n50\n00:02:13.660 --> 00:02:15.010\nWe have what's known as plaintext.\n\n51\n00:02:15.010 --> 00:02:18.850\nPlaintext is the data that you and\nI can read, all right?\n\n52\n00:02:18.850 --> 00:02:23.490\nIt doesn't matter who is reading\nthe document, everybody has access to it.\n\n53\n00:02:23.490 --> 00:02:25.610\nIt is in a readable format.\n\n54\n00:02:25.610 --> 00:02:28.620\nRemember that we have\nthe CIA Triad though.\n\n55\n00:02:28.620 --> 00:02:32.090\nIn security we have confidentiality,\nintegrity, and availability.\n\n56\n00:02:32.090 --> 00:02:34.770\nHow do we keep data confidential?\n\n57\n00:02:34.770 --> 00:02:39.440\nWell, we send that data, if you will,\nthat plaintext through this\n\n58\n00:02:39.440 --> 00:02:45.350\nencryption algorithm and then the output\nbecomes what is known as ciphertext.\n\n59\n00:02:45.350 --> 00:02:46.546\nNow we also, you can see,\n\n60\n00:02:46.546 --> 00:02:49.820\ntake that ciphertext and we can run\nit through that algorithm again and\n\n61\n00:02:49.820 --> 00:02:55.470\nit reverses that operation and\nthe output is what is known as plaintext.\n\n62\n00:02:55.470 --> 00:02:59.490\nNow keep in mind, that if you look,\nthe encryption part we have.\n\n63\n00:02:59.490 --> 00:03:01.108\nNotice the input I say, okay?\n\n64\n00:03:01.108 --> 00:03:05.200\nWe've got plaintext, you input it into the\nalgorithm and it becomes encrypted text.\n\n65\n00:03:05.200 --> 00:03:08.650\nThe encrypted text is how we achieve\nthe confidentiality side, right?\n\n66\n00:03:08.650 --> 00:03:11.300\nEncryption ensures that\nonly the authorized\n\n67\n00:03:11.300 --> 00:03:13.830\nviewers have access to that information.\n\n68\n00:03:13.830 --> 00:03:18.670\nNow notice that when you have ciphertext\nthat's inputted into the algorithm and\n\n69\n00:03:18.670 --> 00:03:23.360\nthe output becomes plaintext, well,\nthat's what's known as decryption.\n\n70\n00:03:23.360 --> 00:03:28.220\nSo encryption, plaintext, feed it\ninto the input, into the algorithm,\n\n71\n00:03:28.220 --> 00:03:29.700\nbecomes ciphertext.\n\n72\n00:03:29.700 --> 00:03:34.570\nIf you take that same ciphertext and\nreverse the process, right, the ciphertext\n\n73\n00:03:34.570 --> 00:03:38.680\nbecomes the input to the algorithm,\nthen the output is going to be plaintext.\n\n74\n00:03:38.680 --> 00:03:41.976\nSo we have encryption and\ndecryption, all right?\n\n75\n00:03:41.976 --> 00:03:43.315\nSo those are some of the basics.\n\n76\n00:03:43.315 --> 00:03:45.530\nNow I did mention key encryption and\n\n77\n00:03:45.530 --> 00:03:48.410\nwe have two concepts that\nwe really have to look at.\n\n78\n00:03:48.410 --> 00:03:52.900\nWe have what is known as symmetric\nkey encryption, all right?\n\n79\n00:03:52.900 --> 00:03:54.660\nWhen we talk about\nsymmetric key encryption,\n\n80\n00:03:54.660 --> 00:04:00.260\nessentially what we're saying is that\nthe same key that does the encryption,\n\n81\n00:04:00.260 --> 00:04:05.270\nright, is going to be the same key\nthat we use to decrypt the algorithm.\n\n82\n00:04:05.270 --> 00:04:07.875\nAll right, so we have to understand that\n\n83\n00:04:07.875 --> 00:04:11.475\nthe same key does the encryption is\nthe same key that does the cecryption.\n\n84\n00:04:11.475 --> 00:04:15.205\nSo it's very important to keep\nthis key protected, all right?\n\n85\n00:04:15.205 --> 00:04:18.035\nAnd that's because if somebody\nhas access to the key and\n\n86\n00:04:18.035 --> 00:04:21.765\nyou send encrypted data over the wire or\nover the network and\n\n87\n00:04:21.765 --> 00:04:25.700\nsome other person has that key,\nwell, they've got the key.\n\n88\n00:04:25.700 --> 00:04:27.030\nThey can do their own encryption.\n\n89\n00:04:27.030 --> 00:04:31.559\nSo we have to make sure that in symmetric\nkey encryption, that we do share that key,\n\n90\n00:04:31.559 --> 00:04:33.382\nif you will, in a secure manner.\n\n91\n00:04:33.382 --> 00:04:38.115\nNow that's a little bit different than\nthe next topic because the next topic is\n\n92\n00:04:38.115 --> 00:04:41.550\nwhat is known as\nasymmetric key encryption.\n\n93\n00:04:41.550 --> 00:04:44.660\nWe talk about asymmetric key encryption\nand now what we're talking about,\n\n94\n00:04:44.660 --> 00:04:46.220\nis not a single key, right?\n\n95\n00:04:46.220 --> 00:04:47.830\nNow we have what's known as a key pair.\n\n96\n00:04:47.830 --> 00:04:49.950\nSometimes you might hear\nit as key pair encryption.\n\n97\n00:04:50.950 --> 00:04:55.860\nAnd the thought process behind\nthis is you, as a user,\n\n98\n00:04:55.860 --> 00:05:00.640\nare issued a key pair, and these key\npairs are mathmatically aligned together.\n\n99\n00:05:00.640 --> 00:05:01.645\nThey work with each other.\n\n100\n00:05:01.645 --> 00:05:06.340\nAll right, so if Zach has a key pair and\nI have a key pair, all right,\n\n101\n00:05:06.340 --> 00:05:10.180\nmy keys will do nothing for\nencryption and decryption of his data.\n\n102\n00:05:10.180 --> 00:05:14.600\nHis keys will do absolutely nothing for\nencryption and decryption of my data.\n\n103\n00:05:14.600 --> 00:05:16.848\nAll right, so\nthey're mathematically aligned together.\n\n104\n00:05:16.848 --> 00:05:21.230\nOne key that does the encryption and\nwe have another key,\n\n105\n00:05:21.230 --> 00:05:23.760\nif you will, that does the decryption.\n\n106\n00:05:23.760 --> 00:05:27.072\nSo that is the difference\nbetween symmetric and\n\n107\n00:05:27.072 --> 00:05:29.984\nasymmetric key encryption, all right?\n\n108\n00:05:29.984 --> 00:05:33.032\nNow the next thing that we'll\ntalk a little bit about,\n\n109\n00:05:33.032 --> 00:05:36.820\nwe've got another type of,\nif you will, they call it encryption.\n\n110\n00:05:36.820 --> 00:05:41.680\nAnd that is something known as\na hashing function or a message digest.\n\n111\n00:05:41.680 --> 00:05:45.490\nNow this is interesting because this is\nwhat's called a one-way encryption, or\n\n112\n00:05:45.490 --> 00:05:46.750\na one-way function.\n\n113\n00:05:46.750 --> 00:05:51.570\nNow what happens here is your data,\nin fact, I gotta a little diagram here and\n\n114\n00:05:51.570 --> 00:05:53.831\nit's also a type of algorithm, right?\n\n115\n00:05:53.831 --> 00:05:58.420\nAnd what we do is we take that data and\nwe feed it through this algorithm, but\n\n116\n00:05:58.420 --> 00:06:02.840\nremember the purpose on this one is not\nto unencrypt this information, all right?\n\n117\n00:06:02.840 --> 00:06:06.031\nWhen we feed it into the hashing\nfunction what it does is,\n\n118\n00:06:06.031 --> 00:06:08.696\nit essentially produces\na fixed length value.\n\n119\n00:06:08.696 --> 00:06:12.349\nAnd when I say fixed length value,\nthe value size never changes,\n\n120\n00:06:12.349 --> 00:06:16.200\nthe value itself could change,\nbut the size never changes.\n\n121\n00:06:16.200 --> 00:06:20.270\nAnd it doesn't matter if you feed\na document in it that got a single letter\n\n122\n00:06:20.270 --> 00:06:24.600\nin it or you feed 800\ndocuments into that algorithm,\n\n123\n00:06:24.600 --> 00:06:26.980\nif that's part of the overall file.\n\n124\n00:06:26.980 --> 00:06:29.790\nIt's gonna produce the same\nfixed length value.\n\n125\n00:06:29.790 --> 00:06:30.910\nNow why would we use that?\n\n126\n00:06:30.910 --> 00:06:32.740\nWhy would we use hashing functions?\n\n127\n00:06:32.740 --> 00:06:34.800\nWell, we use it for file integrity.\n\n128\n00:06:34.800 --> 00:06:36.670\nSo far we've talked about encryption and\n\n129\n00:06:36.670 --> 00:06:41.670\ndecryption being the way that we achieve\nconfidentiality making sure that\n\n130\n00:06:41.670 --> 00:06:44.620\nauthorized users, if you will, are the\nonly ones that have access to the data.\n\n131\n00:06:44.620 --> 00:06:47.250\nUnauthorized users don't\nhave access to it.\n\n132\n00:06:47.250 --> 00:06:51.840\nWe achieve integrity by\nrunning hashing functions.\n\n133\n00:06:51.840 --> 00:06:53.730\nNow how are we doing that?\n\n134\n00:06:53.730 --> 00:06:56.530\nWell, when you run a hashing\nfunction over a document,\n\n135\n00:06:56.530 --> 00:06:59.750\nit produces that fixed length value,\nlike you see here.\n\n136\n00:06:59.750 --> 00:07:03.275\nAnd if any modifications\nare made to the data when I,\n\n137\n00:07:03.275 --> 00:07:07.080\nlet's say hand that over to Zach, and\nit's been modified let say, maliciously.\n\n138\n00:07:07.080 --> 00:07:09.750\nAll right, well,\nbefore I hand it over to Zach,\n\n139\n00:07:09.750 --> 00:07:12.330\nmy document was run through\nthe hashing algorithm.\n\n140\n00:07:12.330 --> 00:07:15.220\nI have this fixed length value,\nwe put that in the document.\n\n141\n00:07:15.220 --> 00:07:18.589\nI send it over to Zach and I tell him\nwhat the algorithm was that we are using.\n\n142\n00:07:19.620 --> 00:07:23.780\nNow if the data's maintained\nits integrity, then when Zach's\n\n143\n00:07:23.780 --> 00:07:28.130\ncomputer run that same hashing algorithm\nover that file, he should be able to\n\n144\n00:07:28.130 --> 00:07:32.020\ncompare the values and like you can see\nhere, the values should be identical.\n\n145\n00:07:32.020 --> 00:07:35.480\nNow I don't expect you guys to look\nat every single one of these letters,\n\n146\n00:07:35.480 --> 00:07:37.320\njust kind of pay attention\nto the last few here.\n\n147\n00:07:37.320 --> 00:07:38.446\nThat might help.\n\n148\n00:07:38.446 --> 00:07:42.610\nNow if that document's been modified,\nand it doesn't matter if it's a network\n\n149\n00:07:42.610 --> 00:07:46.940\ntransmission error or if it's somebody\nmaliciously modifying that information.\n\n150\n00:07:46.940 --> 00:07:49.262\nThen what happens is, same process.\n\n151\n00:07:49.262 --> 00:07:51.243\nIt's actually gonna receive that file,\n\n152\n00:07:51.243 --> 00:07:54.130\ngonna receive the value that I\ntold him he should expect, but\n\n153\n00:07:54.130 --> 00:07:57.941\nthen when he runs that same function\nacross it, he says, well, wait a second.\n\n154\n00:07:57.941 --> 00:08:00.260\nI get a different value\nthan what you've given me.\n\n155\n00:08:00.260 --> 00:08:04.491\nSo the integrity, whatever's going on,\nthe file's not the same.\n\n156\n00:08:04.491 --> 00:08:05.790\nIt's been modified.\n\n157\n00:08:05.790 --> 00:08:07.178\nAnd again,\nit doesn't have to be maliciously.\n\n158\n00:08:07.178 --> 00:08:08.441\nIt could be unintentional,\n\n159\n00:08:08.441 --> 00:08:11.830\nnon-malicious in the fact that it could\nbe a transmission error all right.\n\n160\n00:08:11.830 --> 00:08:15.080\nThis is a form also\nsometimes called a checksum.\n\n161\n00:08:15.080 --> 00:08:19.070\nAll right, now we've got a couple of\ndifferent types of ciphers that we do have\n\n162\n00:08:19.070 --> 00:08:19.980\nto talk about.\n\n163\n00:08:19.980 --> 00:08:23.629\n&gt;&gt; Now Wes I've heard about\ndifferent types of ciphers,\n\n164\n00:08:23.629 --> 00:08:26.810\nhow about the block and stream cipher.\n\n165\n00:08:26.810 --> 00:08:27.870\nCan we talk about those.\n\n166\n00:08:27.870 --> 00:08:32.080\n&gt;&gt; Definitely now they're again with there\nbeing a couple different ciphers they\n\n167\n00:08:32.080 --> 00:08:34.290\noperate a couple of different ways,\nall right.\n\n168\n00:08:34.290 --> 00:08:36.590\nSee a block cipher,\nwhat a block cipher does,\n\n169\n00:08:36.590 --> 00:08:40.130\nis a block cipher takes\na fixed amount of bits.\n\n170\n00:08:40.130 --> 00:08:45.159\nAll right, let's say 192 bits in a block,\nand yet encrypts the entire block.\n\n171\n00:08:45.159 --> 00:08:49.348\nA stream cipher on the other hand,\nit doesn't take an entire block but\n\n172\n00:08:49.348 --> 00:08:53.440\nit does a sequential encryption\nwhere it's bit by bit.\n\n173\n00:08:53.440 --> 00:08:56.330\nAll right, now there are some things\nthat you have to consider, in fact\n\n174\n00:08:56.330 --> 00:08:59.520\nsome of the consideration of block cipher\nare actually pulled up the screen here.\n\n175\n00:08:59.520 --> 00:09:01.880\nBlock ciphers all right\nthey are complex and\n\n176\n00:09:01.880 --> 00:09:04.800\nthey are a little bit slower\nin their processing power.\n\n177\n00:09:04.800 --> 00:09:07.470\nCuz you're doing block by block,\nall right.\n\n178\n00:09:07.470 --> 00:09:12.190\nStream ciphers because it's sequential,\nit's simple and it's first.\n\n179\n00:09:12.190 --> 00:09:15.950\nNow you might figure,\nwhere is the security level in this?.\n\n180\n00:09:15.950 --> 00:09:18.423\nWell they both can be secure, all right?.\n\n181\n00:09:18.423 --> 00:09:23.370\nA Stream Cipher can just be\nsecure as a Block Cipher, right?.\n\n182\n00:09:23.370 --> 00:09:27.975\nOne of the benefits to\nthe Block Cipher is the fact that,\n\n183\n00:09:27.975 --> 00:09:31.400\nyou're encrypting entire\nblocks of information.\n\n184\n00:09:31.400 --> 00:09:35.975\nAnd because of that people really have\nto look at where are those blocks be\n\n185\n00:09:35.975 --> 00:09:39.276\nencrypted right stream\ncipher with that bit by bit,\n\n186\n00:09:39.276 --> 00:09:43.196\nmight be a little bit easier if\nhe will to reverse-engineer.\n\n187\n00:09:43.196 --> 00:09:48.219\nHowever, one of the things to keep\nin mind is that stream ciphers can\n\n188\n00:09:48.219 --> 00:09:53.700\nbe a little bit more or less error prone,\nall right and let me tell you why.\n\n189\n00:09:53.700 --> 00:09:58.360\nWhen you have block cipher, let's say\nyou have 192 bit block cipher, right?\n\n190\n00:09:58.360 --> 00:10:00.540\nWhat if you data is 64 bits?\n\n191\n00:10:02.210 --> 00:10:06.510\nWe still need a 120 bits of data or\n192 bits of data right?\n\n192\n00:10:06.510 --> 00:10:09.720\nWell, what happens with the blank space?\n\n193\n00:10:09.720 --> 00:10:12.080\nWell the blank space you get padding,\nall right.\n\n194\n00:10:12.080 --> 00:10:13.684\nNow the question is,\n\n195\n00:10:13.684 --> 00:10:18.957\nwhat happens if there's one error in\na single bit of data in the block?\n\n196\n00:10:18.957 --> 00:10:20.808\nWell, the whole block's ruined, right.\n\n197\n00:10:20.808 --> 00:10:24.250\nSo block ciphers can be error prone,\nright.\n\n198\n00:10:24.250 --> 00:10:28.876\nUnlike a stream cipher, since it is\nencrypting bit by bit then if one of those\n\n199\n00:10:28.876 --> 00:10:30.825\nbits have an error in it, well,\n\n200\n00:10:30.825 --> 00:10:35.987\nthen you're only worried about the one bit\nrather than the whole block, all right?\n\n201\n00:10:35.987 --> 00:10:37.680\nSo keep that in mind, all right?\n\n202\n00:10:37.680 --> 00:10:42.070\nBlock ciphers encrypt data in blocks,\nin chunks, right?\n\n203\n00:10:42.070 --> 00:10:46.960\nIf the block doesn't have enough data\nin it, it'll be filled with padding.\n\n204\n00:10:46.960 --> 00:10:48.630\nStream ciphers.\n\n205\n00:10:48.630 --> 00:10:53.040\nSimplistic, faster, and yes, they can\nbe just as secure as block cyphers,\n\n206\n00:10:53.040 --> 00:10:57.930\nencrypt your information bit by bit and\ntend to be a little bit less error prone.\n\n207\n00:10:57.930 --> 00:11:01.170\n&gt;&gt; Well, Wes, why would you\nchoose a block over the stream?\n\n208\n00:11:01.170 --> 00:11:05.880\n&gt;&gt; Well, it really depends on the level\nof CPU strength that you have.\n\n209\n00:11:05.880 --> 00:11:09.946\nComputational power could be\na consideration, as well.\n\n210\n00:11:09.946 --> 00:11:12.417\nOne of the things to keep in mind is that,\n\n211\n00:11:12.417 --> 00:11:16.493\nbecause it does take more computational\npower for a block cipher,\n\n212\n00:11:16.493 --> 00:11:20.230\nthen you might have to have\na higher CPU strength, right?.\n\n213\n00:11:20.230 --> 00:11:24.700\nSo, you do have to understand\nthat stream ciphers can chew\n\n214\n00:11:24.700 --> 00:11:26.780\nthrough that encryption and\ndecryption process.\n\n215\n00:11:26.780 --> 00:11:28.330\nAnd, that's really what it comes down to.\n\n216\n00:11:28.330 --> 00:11:30.516\nKeep in mind, you have encryption,\nyou have decryption.\n\n217\n00:11:30.516 --> 00:11:33.117\nThere is gotta be a processor\nthat is doing the encryption and\n\n218\n00:11:33.117 --> 00:11:34.088\ndecryption right?.\n\n219\n00:11:34.088 --> 00:11:38.076\nAnd when you have large chunks of\ninformation that you to to encrypt and\n\n220\n00:11:38.076 --> 00:11:41.400\ndecrypt, then that is gonna\nslow the whole process down.\n\n221\n00:11:41.400 --> 00:11:44.260\nSo do keep that in mind.\n\n222\n00:11:44.260 --> 00:11:48.020\nAll right, so let's go ahead and\nwhat we're gonna do is we're gonna kinda\n\n223\n00:11:48.020 --> 00:11:52.612\nget into what's known as\nthe symmetric key encryption first.\n\n224\n00:11:52.612 --> 00:11:56.270\nI wanna talk about the process again and\nI get a little diagram here and\n\n225\n00:11:56.270 --> 00:11:59.580\none of the things I want you to keep in\nmind is that with symmetric key encryption\n\n226\n00:11:59.580 --> 00:12:04.580\nthe same key that does the encryption\nalso removes the encryption right?\n\n227\n00:12:04.580 --> 00:12:05.500\nDoes the decryption.\n\n228\n00:12:05.500 --> 00:12:09.500\nSo it's important that when you talk about\nsymmetric key encryption you might hear\n\n229\n00:12:09.500 --> 00:12:11.580\nthe term pre shared key encryption.\n\n230\n00:12:11.580 --> 00:12:13.100\nWhy do we call it pre share?\n\n231\n00:12:13.100 --> 00:12:17.890\nWell if both end points have the same key\nthen we gotta securely share that key,\n\n232\n00:12:17.890 --> 00:12:21.391\nbefore we start the encryption and\ndecryption process.\n\n233\n00:12:21.391 --> 00:12:23.461\nNow, so what happens is,\n\n234\n00:12:23.461 --> 00:12:28.540\nI want you to think of your data\nas needing to be put in a lockbox.\n\n235\n00:12:28.540 --> 00:12:31.400\nSo this gentleman wants to send\nencrypted information as young\n\n236\n00:12:31.400 --> 00:12:34.465\nlady here on the other\nside the communication.\n\n237\n00:12:34.465 --> 00:12:37.400\nHe takes that symmetric key puts the data\n\n238\n00:12:37.400 --> 00:12:41.870\ninside the lock box uses that\nkey to encrypt the information.\n\n239\n00:12:41.870 --> 00:12:44.927\nNext thing that happens is that\ntransmitted over the wire over\n\n240\n00:12:44.927 --> 00:12:45.642\nthe network.\n\n241\n00:12:45.642 --> 00:12:49.358\nNow, what she does is\nshe takes that same key\n\n242\n00:12:49.358 --> 00:12:54.290\nthat is been pre-shared and\nshe unlocks the box, right?\n\n243\n00:12:54.290 --> 00:12:58.080\nAnd then can remove or\ncan view the information all right?\n\n244\n00:12:58.080 --> 00:13:00.690\nSo that is symmetric key encryption and\nthere are a couple of\n\n245\n00:13:00.690 --> 00:13:05.050\ndifferent types that I want you guys\nto be able to identify on the exam.\n\n246\n00:13:05.050 --> 00:13:08.400\nAll right, so let's look at, these are\nsome of the ones we have data encryption\n\n247\n00:13:08.400 --> 00:13:13.540\nstandard, we have AES, 3DES,\nRC4, Blowfish, and Twofish.\n\n248\n00:13:13.540 --> 00:13:15.770\nWell what are we talking about here?\n\n249\n00:13:15.770 --> 00:13:16.500\nLet's go ahead.\n\n250\n00:13:16.500 --> 00:13:18.360\n&gt;&gt; One fish, two fish,\nred fish, blue fish.\n\n251\n00:13:18.360 --> 00:13:22.410\n&gt;&gt; That's right.\nIt sounds like a Dr. Seuss book here, but\n\n252\n00:13:22.410 --> 00:13:27.440\nlet's go ahead and let's talk about\nthe I'll talk about DES first, all right.\n\n253\n00:13:27.440 --> 00:13:30.360\nThis is the Data Encryption Standard,\nthis has been around for\n\n254\n00:13:30.360 --> 00:13:31.370\na long time, all right?\n\n255\n00:13:31.370 --> 00:13:33.647\nIt's been around as long\nas I have quite literally,\n\n256\n00:13:33.647 --> 00:13:35.527\nit's been around since 1977, okay?\n\n257\n00:13:35.527 --> 00:13:40.525\nSo, I want you to think about,\nlet's take a trip back in time, early 70s.\n\n258\n00:13:40.525 --> 00:13:42.285\nNot even late, mid or late 70s.\n\n259\n00:13:42.285 --> 00:13:43.735\nEarly 70s right.\n\n260\n00:13:43.735 --> 00:13:47.235\nWe have a lot of universities there\ngetting together, they're coming up with\n\n261\n00:13:47.235 --> 00:13:52.055\nthis network that would later become\nwhat is known as the ARPANET, all right.\n\n262\n00:13:52.055 --> 00:13:55.185\nThe ARPANET would then become\nthe internet, all right.\n\n263\n00:13:55.185 --> 00:13:56.285\nWell in those early days,\n\n264\n00:13:56.285 --> 00:13:59.880\nthere were like five entities that were\nreally connected to the ARPANET, right.\n\n265\n00:13:59.880 --> 00:14:03.450\nAnd there were primarily either\nthe government or some kind of university.\n\n266\n00:14:03.450 --> 00:14:08.360\nSo when those early days it wasn't really\na necessity to have high levels of\n\n267\n00:14:08.360 --> 00:14:11.540\nencryption because of the computational\npower we have on those times, right?\n\n268\n00:14:11.540 --> 00:14:15.259\nSo the Data Encryption Standard\nit was good for it's time, but\n\n269\n00:14:15.259 --> 00:14:18.221\nhere's the problem with\nit It's only 56 bits.\n\n270\n00:14:18.221 --> 00:14:20.817\nIt's a 56 bit block cipher and\n\n271\n00:14:20.817 --> 00:14:25.143\nit is not really something\nyou should be using today,\n\n272\n00:14:25.143 --> 00:14:30.645\ncuz if you get the idea,\n1977 computing versus today, right?\n\n273\n00:14:30.645 --> 00:14:31.960\nWe're in 2017.\n\n274\n00:14:31.960 --> 00:14:37.780\nWe're talking about higher amounts\nof computational capabilities today,\n\n275\n00:14:37.780 --> 00:14:40.200\nso it's very, very vulnerable.\n\n276\n00:14:40.200 --> 00:14:45.270\nIt's gone pretty much by the wayside as a\nstandard for doing encryption at all, and\n\n277\n00:14:45.270 --> 00:14:48.900\nit's very, very prone to things\nlike brute force attacks.\n\n278\n00:14:48.900 --> 00:14:51.160\nSo what do we have now?\n\n279\n00:14:51.160 --> 00:14:55.430\nWe're gonna fast forward, and I wanna\nshow you how long it's stayed a standard.\n\n280\n00:14:55.430 --> 00:15:00.923\nWe're gonna fast forward from\n1977 all the way up to 1998.\n\n281\n00:15:00.923 --> 00:15:07.070\n1998 I said we realized\nthis 56 bit block cipher\n\n282\n00:15:07.070 --> 00:15:11.060\nit's got brute force vulnerabilities but\nso we need something else.\n\n283\n00:15:11.060 --> 00:15:13.799\nSo what do they do?\nWell the next one that come out within\n\n284\n00:15:13.799 --> 00:15:18.350\nthe list here is the three DES,\ntriple DES as it sometimes call.\n\n285\n00:15:18.350 --> 00:15:23.860\nAll right, and what this does is it\nincreases the DES encryption by doing\n\n286\n00:15:23.860 --> 00:15:28.280\nthree separate DES encryption\noperations all right.\n\n287\n00:15:28.280 --> 00:15:34.210\nAnd what I mean by that is, we take\none DES key and we encrypt the data.\n\n288\n00:15:34.210 --> 00:15:37.900\nBut then we take a second key and\nwe take that encrypted data, and\n\n289\n00:15:37.900 --> 00:15:38.730\nwe encrypt it again.\n\n290\n00:15:38.730 --> 00:15:40.922\nAnd then we take a third key and\n\n291\n00:15:40.922 --> 00:15:46.116\nwe encrypt the second encryption\nhence the term Triple DES all right.\n\n292\n00:15:46.116 --> 00:15:49.854\nNow threes DES is one of those ones it has\n\n293\n00:15:49.854 --> 00:15:54.625\na 64 block size if you\nwill it's a block cipher.\n\n294\n00:15:54.625 --> 00:15:58.111\nAnd what happens is your essentially\nincreasing the key bits By\n\n295\n00:15:58.111 --> 00:16:02.402\nperforming a triple operation on it,\ncuz it has a couple of different modes.\n\n296\n00:16:02.402 --> 00:16:04.484\nIt has a one key, two key,\nand three key mode,\n\n297\n00:16:04.484 --> 00:16:08.580\nyou're pretty much gonna be using\nthree key mode when you are using.\n\n298\n00:16:08.580 --> 00:16:14.250\nOne key brings you right back to 56\nbit DES, right, that's just like DES.\n\n299\n00:16:14.250 --> 00:16:17.430\nTwo key increase it to 122 key bits and\nthen finally,\n\n300\n00:16:17.430 --> 00:16:20.690\nthe three key operation\nincreases it to 168 key bits.\n\n301\n00:16:22.612 --> 00:16:25.340\nAll right, so we have gotta talk about\nsome of the other ones in this list.\n\n302\n00:16:25.340 --> 00:16:30.737\nSo, let's go ahead and look at this list,\nwe've got AES, so what's AES?\n\n303\n00:16:30.737 --> 00:16:34.916\nAll right, well, AES is called\nthe Advanced Encryption Standard,\n\n304\n00:16:34.916 --> 00:16:39.311\nthis was actually a [LAUGH] this was\na competition that was essentially put\n\n305\n00:16:39.311 --> 00:16:44.082\nout by the National Institute for\nStandards and Technology Back in 2001.\n\n306\n00:16:44.082 --> 00:16:46.450\nThis was originally called\nthe Rijndael algorithm,\n\n307\n00:16:46.450 --> 00:16:49.560\nthey knew that they needed something\nbetter than triple DES, right.\n\n308\n00:16:49.560 --> 00:16:54.983\nTriple DES was probably, kinda like\na stop gap, it did it's job well for\n\n309\n00:16:54.983 --> 00:16:58.030\nthe time that it was presented in.\n\n310\n00:16:58.030 --> 00:17:01.530\nBut again as computational power arises,\nwell, so\n\n311\n00:17:01.530 --> 00:17:05.818\ndoes the probability that you can reverse\nengineer or crack this encryption.\n\n312\n00:17:05.818 --> 00:17:09.960\nSo they had all different competitions,\nright, in fact, Blowfish and\n\n313\n00:17:09.960 --> 00:17:12.970\nTwofisth were one of these\n\n314\n00:17:12.970 --> 00:17:16.020\nsymmetric key encryptions that were part\nof that competition and just didn't win.\n\n315\n00:17:16.020 --> 00:17:22.610\nSo when Rijndael won, NIST established it\nas the advanced encryption standard, AES.\n\n316\n00:17:22.610 --> 00:17:26.880\nThat's what we use today, in fact, it\nwas adopted in 2002 by the United States\n\n317\n00:17:26.880 --> 00:17:31.630\ngovernment and it has the DOD requirements\nfor top secret classified information.\n\n318\n00:17:32.880 --> 00:17:37.210\nAt 256 bits, okay, but keep in mind\nthat there are other key lengths\n\n319\n00:17:37.210 --> 00:17:42.720\nstill today 128 bit key length on AES is\n\n320\n00:17:42.720 --> 00:17:46.890\nstill considered safe,\nprobably not for too much longer.\n\n321\n00:17:46.890 --> 00:17:51.150\nThe DOD standard is 256 bit,\nso we have 128 bit,\n\n322\n00:17:51.150 --> 00:17:56.710\nwe have 192 bit and we have 256 bit.\n\n323\n00:17:56.710 --> 00:17:58.170\nAnd the 256 bit,\n\n324\n00:17:58.170 --> 00:18:03.030\nif you will, is the standard today for\ntop-secret classified information.\n\n325\n00:18:03.030 --> 00:18:07.330\nNext what we have here kinda hanging\noff to the side here is RC4,\n\n326\n00:18:08.560 --> 00:18:11.390\nnow RC4, we're not talking\nabout radio controlled cars or\n\n327\n00:18:11.390 --> 00:18:15.102\nanything here,\nwhat we're talking about is the R in RSA.\n\n328\n00:18:15.102 --> 00:18:18.670\nIf you've ever heard about the RSA,\nRon Rivest, Ron Rivest,\n\n329\n00:18:18.670 --> 00:18:24.250\na major security guru and\nprofessor in the security world.\n\n330\n00:18:24.250 --> 00:18:27.050\nHe came out 1987 with a stream cipher, and\n\n331\n00:18:27.050 --> 00:18:29.060\nagain you might hear it called\na couple of different things.\n\n332\n00:18:29.060 --> 00:18:33.156\nI've heard it called Rivest Code,\nRon's Code,\n\n333\n00:18:33.156 --> 00:18:36.970\neither way RC4, and yes there are RC3, 4.\n\n334\n00:18:36.970 --> 00:18:40.920\nToday if you're using any of the RC\nstandards, you really should be using RC5.\n\n335\n00:18:40.920 --> 00:18:46.410\nThis is a stream cipher and it's very,\nvery fast and simplistic, all right, so\n\n336\n00:18:46.410 --> 00:18:51.500\nthe computational power is very, very low\nin what it takes to encrypt information.\n\n337\n00:18:51.500 --> 00:18:54.800\nHowever, it's considered very weak,\nand it's insecure today,\n\n338\n00:18:54.800 --> 00:18:58.340\na lot of other technology use the RC4\nStream Cipher, like the wired equipment\n\n339\n00:18:58.340 --> 00:19:03.430\nprivacy that was issued out in 1999 by\nthe IEEE for their 802.11 standards.\n\n340\n00:19:04.820 --> 00:19:08.150\nWPA used it as well, and\nwhat they did is they wrapped and\n\n341\n00:19:08.150 --> 00:19:13.040\nRC4 screen cipher in something know as\nTKIP, the Temporal Key Integrity Protocol.\n\n342\n00:19:13.040 --> 00:19:20.170\nAnd for a time it was also used in SSL and\nTLS, however that's not the case today.\n\n343\n00:19:20.170 --> 00:19:22.120\nJust do to it's weakness, so\n\n344\n00:19:22.120 --> 00:19:26.100\nit really should be avoided today,\nthen we have Blowfish.\n\n345\n00:19:26.100 --> 00:19:30.250\nAnd Blowfish was, again, it was part of\nthe competition when the NIST came out and\n\n346\n00:19:30.250 --> 00:19:35.130\nsaid hey security gurus out there we need\nthe latest and greatest, the best thing.\n\n347\n00:19:35.130 --> 00:19:41.180\nWell Bruce Schneider, he is another one\nof these just brilliant security gurus,\n\n348\n00:19:41.180 --> 00:19:44.370\nif you ever get a chance,\nread a book called Secrets and Lies.\n\n349\n00:19:44.370 --> 00:19:45.320\nHe invented this\n\n350\n00:19:46.650 --> 00:19:51.720\nessentially as an alternative in\n1993 to DES at the time, right.\n\n351\n00:19:51.720 --> 00:19:56.155\nSo that would be, what, six years prior\nto triple DES ever being released.\n\n352\n00:19:56.155 --> 00:20:01.950\nSo this was kinda as an alternative, if\nyou will, to the data encryption standard.\n\n353\n00:20:01.950 --> 00:20:06.810\nThe next one we also have, too, the last\none on this list for the stream ciphers,\n\n354\n00:20:06.810 --> 00:20:11.280\nif you will, is what is known as,\ndid I say Twofish?\n\n355\n00:20:11.280 --> 00:20:14.820\nLet me make sure I say that right\ncuz I think I got these backwards.\n\n356\n00:20:14.820 --> 00:20:20.110\nBlowfish was the one actually that was\ninvented in 1993 by Bruce Schneider.\n\n357\n00:20:20.110 --> 00:20:24.725\nAnd again, it's a 64 bit key length,\nit was an alternative to DES, and\n\n358\n00:20:24.725 --> 00:20:29.130\nit really resembles another\nalgorithm out there called Cast 128.\n\n359\n00:20:29.130 --> 00:20:33.485\nNow Cast 128 isn't formally\ncalled out in the objectives,\n\n360\n00:20:33.485 --> 00:20:36.325\nit has been in past objectives.\n\n361\n00:20:36.325 --> 00:20:41.265\nSo I just throw that out there as to know\nthat one too, Twofish is the next one and\n\n362\n00:20:41.265 --> 00:20:46.070\nthe reason I sometimes get these confused\nis because Bruce Schneider was also part\n\n363\n00:20:46.070 --> 00:20:48.150\nof inventing Twofish, as well.\n\n364\n00:20:48.150 --> 00:20:50.398\nBut there were other people too,\nthere was a group of people,\n\n365\n00:20:50.398 --> 00:20:52.314\nNiles Ferguson was one of\nthem that was on there too.\n\n366\n00:20:52.314 --> 00:20:57.964\nThis is a block cipher as well,\nand it has different key lengths,\n\n367\n00:20:57.964 --> 00:21:04.980\nlikewise, it has the 128 bits,\nit has 192, and 256 bits, all right.\n\n368\n00:21:04.980 --> 00:21:08.763\nSo these are essentially your\nsymmetric key algorithms,\n\n369\n00:21:08.763 --> 00:21:13.314\nagain I want you to keep in mind for\nthe exam that if they happen ask you,\n\n370\n00:21:13.314 --> 00:21:16.512\nyou might get some kind of question,\nall right.\n\n371\n00:21:16.512 --> 00:21:21.210\nSome kinda question that says which of\nthese are a symmetric key encryption,\n\n372\n00:21:21.210 --> 00:21:25.140\nwhich of these might be vulnerable,\nand maybe is stronger then the other.\n\n373\n00:21:25.140 --> 00:21:29.572\nYou should be able to recognize\nthings like DES isn't as strong as\n\n374\n00:21:29.572 --> 00:21:33.080\ntriples DES and isn't as strong as AES.\n\n375\n00:21:33.080 --> 00:21:36.528\nSo know those for the exam.\n\n376\n00:21:36.528 --> 00:21:42.800\n&gt;&gt; [FOREIGN] So, how would you base which\none of these you might want to use?\n\n377\n00:21:42.800 --> 00:21:46.790\nIs it a financial situation or\nis it more of a data consideration?\n\n378\n00:21:46.790 --> 00:21:51.346\n&gt;&gt; That's an interesting question,\nit's really based on the hardware, right,\n\n379\n00:21:51.346 --> 00:21:56.040\nwhen we talk about encryption, some people\nmight think, and I did for a while too.\n\n380\n00:21:56.040 --> 00:22:01.483\nSome people might think that well, let's\njust get the strongest encryption and\n\n381\n00:22:01.483 --> 00:22:04.920\nthat's gonna be great for\nwhat we have to do.\n\n382\n00:22:04.920 --> 00:22:08.630\nBut that's not necessarily the case cuz\nyou also have to think of the devices that\n\n383\n00:22:08.630 --> 00:22:09.300\nit's running on.\n\n384\n00:22:09.300 --> 00:22:14.690\nRight, so while my gaming platform,\nwhile my server might have a great,\n\n385\n00:22:14.690 --> 00:22:19.220\njust an easy time encrypting\nsomething like AES 256 bit.\n\n386\n00:22:19.220 --> 00:22:23.270\nMy cell phone, my mobile phone's probably\ngonna bog down because the processors is\n\n387\n00:22:23.270 --> 00:22:29.360\nnot made generally, if you will,\nto have that computational power.\n\n388\n00:22:29.360 --> 00:22:32.350\nThe other thing you have to keep in mind\ntoo, give you another consideration here,\n\n389\n00:22:32.350 --> 00:22:34.610\nis like do you have hardware acceleration?\n\n390\n00:22:34.610 --> 00:22:38.580\nOne of the good things about\nIntel-based CPUs is in the chip itself,\n\n391\n00:22:38.580 --> 00:22:41.420\nthey have an AES hardware accelerator.\n\n392\n00:22:41.420 --> 00:22:45.560\nSo it helps to assist what\nit takes to encrypt and\n\n393\n00:22:45.560 --> 00:22:49.510\ndecrypt information, so\nthere might be a time when, yeah,\n\n394\n00:22:49.510 --> 00:22:54.080\nyou could see that on Intel-based chip\nAES just rocks it's not a problem.\n\n395\n00:22:55.240 --> 00:22:59.380\nBut another machines you might see\nwhere AES completely bogs down, so\n\n396\n00:22:59.380 --> 00:23:00.828\nyou really have to consider that too.\n\n397\n00:23:00.828 --> 00:23:04.916\nSo its computational power,\nthe strength that you need, and\n\n398\n00:23:04.916 --> 00:23:08.779\nagain some the things that you\njust do have to keep in mind.\n\n399\n00:23:08.779 --> 00:23:13.449\nNow the next thing I mentioned was\nasymmetric key encryption, and asymmetric\n\n400\n00:23:13.449 --> 00:23:18.680\nkey encryption is the one that we were\ntalking about that has two keys, remember?\n\n401\n00:23:18.680 --> 00:23:22.130\nIt has a key pair, in fact, let's go ahead\nand give you an example of this one.\n\n402\n00:23:22.130 --> 00:23:26.220\nI've got this pulled up on the screen,\ntoo, so if symmetric key encryption uses\n\n403\n00:23:26.220 --> 00:23:30.870\na single key to encrypt and\na single key, the same key, to decrypt.\n\n404\n00:23:30.870 --> 00:23:32.960\nAsymmetric is using two keys, all right,\n\n405\n00:23:32.960 --> 00:23:34.820\nyou might hear this called\na couple of different things.\n\n406\n00:23:34.820 --> 00:23:36.990\nYou might hear it called\nkey pairing encryption,\n\n407\n00:23:36.990 --> 00:23:40.180\nyou might also hear it called\npublic key encryption, right.\n\n408\n00:23:40.180 --> 00:23:41.322\nWhy do we call it public key?\n\n409\n00:23:41.322 --> 00:23:43.640\nAll right, well,\nthe two keys that we have,\n\n410\n00:23:43.640 --> 00:23:47.686\nwe have what are known as a private key\nand we have what's known as a public key.\n\n411\n00:23:47.686 --> 00:23:52.108\nAll right, now, I want you to think of\nthis as two keys on the launch pad.\n\n412\n00:23:52.108 --> 00:23:57.424\nOr I've got a lock box and\nI need to give Zach some information.\n\n413\n00:23:57.424 --> 00:23:59.409\nThat I don't want anybody\nelse to be able to see.\n\n414\n00:23:59.409 --> 00:24:02.581\n[COUGH] I'm gonna take one of these keys,\nand\n\n415\n00:24:02.581 --> 00:24:08.428\nI'm gonna put information in that lockbox,\nand I'm gonna lock the box, okay?\n\n416\n00:24:08.428 --> 00:24:09.876\nAnd I'm gonna pull that key out.\n\n417\n00:24:09.876 --> 00:24:11.805\nI'm gonna hand it over to Zach.\n\n418\n00:24:11.805 --> 00:24:15.576\nZach's gonna take a key\nthat only he has access to.\n\n419\n00:24:15.576 --> 00:24:19.860\nAnd he's gonna unlock that box to open\nit up and see what's inside of it.\n\n420\n00:24:19.860 --> 00:24:22.310\nThat's essentially what's going on\nwith asymmetric key encryption.\n\n421\n00:24:22.310 --> 00:24:24.487\nYou have what's known\nas the public key and\n\n422\n00:24:24.487 --> 00:24:27.037\nI want you to notice that\npublic key locks the box.\n\n423\n00:24:27.037 --> 00:24:28.188\nIt's all it does.\n\n424\n00:24:28.188 --> 00:24:30.899\nIt's not gonna unlock the box, right?\n\n425\n00:24:30.899 --> 00:24:35.155\nThe private key is called private\nbecause it's responsible for\n\n426\n00:24:35.155 --> 00:24:40.374\nunlocking all the boxes that have been\nlocked with the public key, all right?\n\n427\n00:24:40.374 --> 00:24:42.521\nNow, why do we call that a private key?\n\n428\n00:24:42.521 --> 00:24:47.251\nIt's because if anybody gains\naccess to this key, all right?\n\n429\n00:24:47.251 --> 00:24:52.012\nThat means they can unencrypt any piece\nof data that you send over the wire if\n\n430\n00:24:52.012 --> 00:24:54.140\nthey can capture it, all right?\n\n431\n00:24:54.140 --> 00:24:57.752\nSo public key encryption,\nwhy is the public key called public?\n\n432\n00:24:57.752 --> 00:25:00.500\nWell, I don't care who has\naccess to the public key.\n\n433\n00:25:00.500 --> 00:25:04.562\nI can throw the, proverbially if you will,\njust throw a whole bunch of the public\n\n434\n00:25:04.562 --> 00:25:07.336\nkeys all over the floor, and\nanybody can pick them up.\n\n435\n00:25:07.336 --> 00:25:09.969\nSay, well, that doesn't seem too secure.\n\n436\n00:25:09.969 --> 00:25:13.592\nWell it is, because the public key\nis only encrypting information,\n\n437\n00:25:13.592 --> 00:25:15.222\nit does nothing to decrypt it.\n\n438\n00:25:15.222 --> 00:25:17.227\nSo who cares who has it, all right?\n\n439\n00:25:17.227 --> 00:25:20.584\nSo what is the pro,\nhow's this process work, all right?\n\n440\n00:25:20.584 --> 00:25:22.792\nWell, we transmit the public key.\n\n441\n00:25:22.792 --> 00:25:27.609\nThese keys are mathematically aligned\ntogether like I told you earlier, and\n\n442\n00:25:27.609 --> 00:25:31.330\nthey only work in combination\nwith each other, all right?\n\n443\n00:25:31.330 --> 00:25:32.514\nSo what we do is,\n\n444\n00:25:32.514 --> 00:25:38.619\nlet's say that this young lady wants to\nsend this gentleman encrypted information.\n\n445\n00:25:38.619 --> 00:25:42.323\nWell, she first obtains his public key,\nall right?\n\n446\n00:25:42.323 --> 00:25:45.265\nThat's usually presented in\nsome form of certificate.\n\n447\n00:25:45.265 --> 00:25:49.462\nThen what she does is she\ntakes that public key of his,\n\n448\n00:25:49.462 --> 00:25:51.901\nand she locks the box, right?\n\n449\n00:25:51.901 --> 00:25:53.898\nTwo keys on the box, remember that.\n\n450\n00:25:53.898 --> 00:25:59.006\nAnd then she transmits the securely\nlocked box back to this gentleman.\n\n451\n00:25:59.006 --> 00:26:04.280\nNow, what he does is he takes that\nprivate key that only he has access to,\n\n452\n00:26:04.280 --> 00:26:06.618\nand he unlocks the box, right?\n\n453\n00:26:06.618 --> 00:26:08.996\nNow he's decrypted the information.\n\n454\n00:26:08.996 --> 00:26:12.415\nBut he's done it with his association.\n\n455\n00:26:12.415 --> 00:26:15.539\nA public key and a private key, all right?\n\n456\n00:26:15.539 --> 00:26:21.644\nSo this essentially is the public key\nencryption or asymmetric encryption.\n\n457\n00:26:21.644 --> 00:26:26.692\nNow we got a few algorithms that I\nkind of wanna look at here, all right?\n\n458\n00:26:26.692 --> 00:26:29.033\nAnd you'll see a few of them here.\n\n459\n00:26:29.033 --> 00:26:31.503\nRSA, I kind of already\nmentioned RSA before.\n\n460\n00:26:31.503 --> 00:26:36.271\nRSA laboratories, they are made up of\na whole bunch of people, but the three\n\n461\n00:26:36.271 --> 00:26:41.356\npeople that started it, each one of their\nnames is a letter in this acronym here.\n\n462\n00:26:41.356 --> 00:26:44.127\nR for Ron Rivest, S for Eddie Shamir,\n\n463\n00:26:44.127 --> 00:26:48.039\nI don't know if I have that right,\nand then Adelman.\n\n464\n00:26:48.039 --> 00:26:52.133\nSo it's Rivest, Shamir,\nAdleman, the three guys,\n\n465\n00:26:52.133 --> 00:26:55.523\nthree gurus if you will,\nthat started this.\n\n466\n00:26:55.523 --> 00:27:02.015\nRSA was, guess what, invented back in\n1997, so it's been around for a while.\n\n467\n00:27:02.015 --> 00:27:06.254\nIt is a public key,\nasymmetric key encryption.\n\n468\n00:27:06.254 --> 00:27:08.498\nNow, we've got an earlier one here,\ntoo and\n\n469\n00:27:08.498 --> 00:27:10.988\nthis is called the digital\nsignature algorithm.\n\n470\n00:27:10.988 --> 00:27:15.632\nThis was introduced by\nthe National Institute for Security,\n\n471\n00:27:15.632 --> 00:27:20.015\nor Standards and Technology,\nif you will, in 1991.\n\n472\n00:27:20.015 --> 00:27:22.964\nNow we also got some other ones\nthat we need to talk about.\n\n473\n00:27:22.964 --> 00:27:25.377\nWe got what's known as Diffie-Hellman.\n\n474\n00:27:25.377 --> 00:27:30.634\nNow Diffie-Hellman, this algorithm\nalso came out in 1997, and it started\n\n475\n00:27:30.634 --> 00:27:35.908\nby two gurus, one named Whitfield Diffie,\nthe other one called Marty Hellman.\n\n476\n00:27:35.908 --> 00:27:40.088\nAnd what they did is found out a way\nto do public key encryption, but\n\n477\n00:27:40.088 --> 00:27:44.718\nalso how to securely exchange keys over\na public network in a manner that,\n\n478\n00:27:44.718 --> 00:27:47.854\nif somebody was out there\neavesdropping on them,\n\n479\n00:27:47.854 --> 00:27:51.159\nthey couldn't derive what the key was,\nall right?\n\n480\n00:27:51.159 --> 00:27:54.217\nSo it's perfect for\nwhat's known as public key exchange.\n\n481\n00:27:54.217 --> 00:27:59.205\nNow I got a diagram if I could find\nit here because Diffie-Hellman has\n\n482\n00:27:59.205 --> 00:28:01.442\na series of groups if you will.\n\n483\n00:28:01.442 --> 00:28:06.269\nAnd these are modifications to\nthe original DH standard, all right?\n\n484\n00:28:06.269 --> 00:28:09.596\nAnd as you see, you can see in\nthe numbers, the higher the number,\n\n485\n00:28:09.596 --> 00:28:12.997\nthe better the encryption is,\nthe higher the level of encryption.\n\n486\n00:28:12.997 --> 00:28:16.547\nSo today we'll be using\nthe Diffie-Hellman Group 19 and\n\n487\n00:28:16.547 --> 00:28:19.320\n20 with something known as elliptic curve.\n\n488\n00:28:19.320 --> 00:28:23.725\nNow elliptic curve, ECC,\nnot error correcting code but\n\n489\n00:28:23.725 --> 00:28:29.247\nECC in this standpoint is what's\nknown as elliptic curve cryptology.\n\n490\n00:28:29.247 --> 00:28:34.961\nEssentially using algebraic technologies\nin order to encrypt your information.\n\n491\n00:28:34.961 --> 00:28:40.444\nNow one of the great things about your,\nlet me get back to my diagram here,\n\n492\n00:28:40.444 --> 00:28:44.866\none of the great things about\nelliptic curve is the fact that\n\n493\n00:28:44.866 --> 00:28:49.306\nyou get better encryption with\nsmaller key sizes, right?\n\n494\n00:28:49.306 --> 00:28:52.522\nThis is back to your question\nearlier there, Zack, which said,\n\n495\n00:28:52.522 --> 00:28:53.874\nwhich one might we choose?\n\n496\n00:28:53.874 --> 00:28:57.679\nWell, you might wanna choose,\nyou'll say, but\n\n497\n00:28:57.679 --> 00:29:01.583\nwhy don't I just choose\na 2048 bit key length?\n\n498\n00:29:01.583 --> 00:29:05.469\nWell, that's great, but understand,\nthe more you increase that key length,\n\n499\n00:29:05.469 --> 00:29:09.142\nthe harder it is to encrypt and\ndecrypt your information, it takes longer.\n\n500\n00:29:09.142 --> 00:29:13.834\nWell, the great thing about elliptic curve\nis the fact that you get an exponential\n\n501\n00:29:13.834 --> 00:29:18.322\nincrease of the computational power\nthat it takes to reverse the encryption,\n\n502\n00:29:18.322 --> 00:29:19.891\nwith a smaller key length.\n\n503\n00:29:19.891 --> 00:29:25.751\nSo, it's very, very good for things,\nlike, mobile devices if you will.\n\n504\n00:29:25.751 --> 00:29:28.252\nAnd you can see that there\nare different types of Diffie-Hellmans.\n\n505\n00:29:28.252 --> 00:29:32.182\nYou'll see, in fact let me get\nback over to the groups, right?\n\n506\n00:29:32.182 --> 00:29:36.214\nDon't let this fool you, in fact I\ndon't even have this mentioned in here.\n\n507\n00:29:36.214 --> 00:29:38.049\nBut I'll Now go ahead and\nmention in many ways.\n\n508\n00:29:38.049 --> 00:29:42.381\nYou'll see DHE, and\nthat's Diffie-Hellman Exchange, right?\n\n509\n00:29:42.381 --> 00:29:44.250\nThat's the key exchange I was telling you.\n\n510\n00:29:44.250 --> 00:29:46.987\nBut then what they do is,\nthey add modifiers to it.\n\n511\n00:29:46.987 --> 00:29:49.839\nYou'll see ECDHE.\n\n512\n00:29:49.839 --> 00:29:52.238\nGuys, don't let it confuse you,\n\n513\n00:29:52.238 --> 00:29:57.715\nit's elliptic curve Diffie-Hellman\nExchange if you will, or encryption.\n\n514\n00:29:57.715 --> 00:29:59.627\nAll right, so\nthose are a couple of the different kinds.\n\n515\n00:29:59.627 --> 00:30:01.470\nLast one I wanna mention is PGP, and\n\n516\n00:30:01.470 --> 00:30:04.308\nI know we're getting close\nto the end of this episode.\n\n517\n00:30:04.308 --> 00:30:08.117\nWe're probably gonna have to go into\na part two, cuz I've talked a lot but\n\n518\n00:30:08.117 --> 00:30:12.124\nlet me go ahead and finish this last one\nas part of asymmetric key encryption.\n\n519\n00:30:12.124 --> 00:30:15.958\nAnd that's PGP, pretty good privacy.\n\n520\n00:30:15.958 --> 00:30:18.783\nThis is used for\nconfidentiality and authentication.\n\n521\n00:30:18.783 --> 00:30:23.661\nIt combines that hashing function that\nwe talked about with data compression,\n\n522\n00:30:23.661 --> 00:30:27.022\nsymmetric key encryption and\npublic key encryption.\n\n523\n00:30:27.022 --> 00:30:31.431\nAnd the keys, if you will,\nare bound to the user name and email.\n\n524\n00:30:31.431 --> 00:30:35.346\nThe GPG is what's known as\nthe GNU privacy guard, and\n\n525\n00:30:35.346 --> 00:30:40.045\nit's based on OpenPGP,\nan open source platform, if you will,\n\n526\n00:30:40.045 --> 00:30:45.460\nthat's basically the open-source or\nfree implementation of OpenPGP.\n\n527\n00:30:45.460 --> 00:30:49.503\nGNU, GNU Public License,\nwe're talking about open source software,\n\n528\n00:30:49.503 --> 00:30:53.094\nsomething that you would see\ninside of your next based systems.\n\n529\n00:30:53.094 --> 00:30:56.285\nWell, there's so\nmuch more we do wanna go over, and\n\n530\n00:30:56.285 --> 00:30:59.984\nthat pretty obvious as we continue\nwith the cryptography and\n\n531\n00:30:59.984 --> 00:31:03.044\nalgorithm basics inside\nof CompTIA Security+.\n\n532\n00:31:03.044 --> 00:31:03.756\nGreat job, Wes.\n\n533\n00:31:03.756 --> 00:31:05.525\n&gt;&gt; Thank you.\n&gt;&gt; Do you wanna leave us with before we\n\n534\n00:31:05.525 --> 00:31:06.061\nsay goodbye?\n\n535\n00:31:06.061 --> 00:31:09.208\n&gt;&gt; No, you're the last thing I\njust might say is that remember,\n\n536\n00:31:09.208 --> 00:31:12.063\nyou don't always just pick\nthe strongest encryption.\n\n537\n00:31:12.063 --> 00:31:14.991\nYou have to consider things like the\ndevices that are gonna do the encryption\n\n538\n00:31:14.991 --> 00:31:16.742\nand decryption in the computational power.\n\n539\n00:31:16.742 --> 00:31:18.771\nSo definitely study up on them, and\n\n540\n00:31:18.771 --> 00:31:21.282\nremember it's not just\na one size fits all.\n\n541\n00:31:21.282 --> 00:31:22.114\n&gt;&gt; Fantastic.\n\n542\n00:31:22.114 --> 00:31:26.814\nWell, we wanna thank you for watching this\nepisode, and number two is coming up.\n\n543\n00:31:26.814 --> 00:31:28.722\nAnd thank you for watching ITProTV.\n\n544\n00:31:28.722 --> 00:31:30.819\nYou know an IT pro is always learning?\n\n545\n00:31:30.819 --> 00:31:31.587\nThey are.\n\n546\n00:31:31.587 --> 00:31:32.450\nI'm Zach Memos.\n\n547\n00:31:32.450 --> 00:31:33.332\n&gt;&gt; And I'm Wes Bryan.\n\n548\n00:31:33.332 --> 00:31:36.403\n&gt;&gt; And we'll see you soon.\n\n549\n00:31:36.403 --> 00:31:42.359\n[MUSIC]\n\n550\n00:31:42.359 --> 00:31:45.719\n&gt;&gt; Thank you for watching ITPRO.TV.\n\n",
          "vimeoId": "219677029"
        },
        {
          "description": "Wes and Zach go over cypher modes & what they are, hashing algorithms, key stretching algorithms, what a Hashing Collision is, obfuscation, substitution cyphers, and deciding what are the best applications for your systems.",
          "length": "2007",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-2-cryptography_algorithms_basics_pt2-052617-PGM.00_33_12_26.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-2-cryptography_algorithms_basics_pt2-052617-PGM.00_33_12_26.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-2-cryptography_algorithms_basics_pt2-052617-PGM.00_33_12_26.Still001-sm.jpg",
          "title": "Cryptography Algorithms Basics Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.039 --> 00:00:02.718\nWelcome to ITPROTV I'm\nyour host Don Pezet.\n\n2\n00:00:02.718 --> 00:00:06.239\n[CROSSTALK]\n\n3\n00:00:06.239 --> 00:00:08.198\n[MUSIC]\n\n4\n00:00:08.198 --> 00:00:11.904\n&gt;&gt; You're watching ITPROTV.\n\n5\n00:00:11.904 --> 00:00:12.962\n&gt;&gt; Hello again and\n\n6\n00:00:12.962 --> 00:00:18.400\nthank you for joining us on ITProTV\nhelping you learn wherever you go.\n\n7\n00:00:18.400 --> 00:00:23.900\nMy name is Zack Memos and I'm your host\nas we continue with CompTIA Security+ and\n\n8\n00:00:23.900 --> 00:00:28.220\nalgorithms, and cryptography or\ncryptography algorithms basics.\n\n9\n00:00:28.220 --> 00:00:29.015\nThis is part two,\n\n10\n00:00:29.015 --> 00:00:32.540\nwe have a part one that you absolutely\nmust see if you haven't already.\n\n11\n00:00:32.540 --> 00:00:35.805\nWes Bryan right over here, he's the man,\nhe's the myth, he's the legend and\n\n12\n00:00:35.805 --> 00:00:37.660\nhe's putting it all together for us.\n\n13\n00:00:37.660 --> 00:00:41.560\nYou know Wes, on the first episode\nwe were talking about ciphers,\n\n14\n00:00:41.560 --> 00:00:43.700\nwe talked about block,\nwe talked about stream.\n\n15\n00:00:43.700 --> 00:00:46.020\nCan we talk about asymmetric and\nsymmetric?\n\n16\n00:00:46.020 --> 00:00:46.980\n&gt;&gt; Some of the considerations?\n\n17\n00:00:46.980 --> 00:00:50.150\n&gt;&gt; Yeah, yeah.\n&gt;&gt; Sure yeah, why not, so we did finish\n\n18\n00:00:50.150 --> 00:00:54.720\noff, and I know I was running a little bit\nshort on time on the first part of this.\n\n19\n00:00:54.720 --> 00:00:58.330\nWe did talk about symmetric key encryption\nand asymmetric key encryption and\n\n20\n00:00:58.330 --> 00:01:02.320\nwe kinda wanna, again, just kinda round\noff the two and kinda compare each other.\n\n21\n00:01:02.320 --> 00:01:05.560\nSo I do have a little bit of information\nhere in a diagram, let's go ahead and\n\n22\n00:01:05.560 --> 00:01:06.380\ntalk about these.\n\n23\n00:01:06.380 --> 00:01:10.200\nSo remember that symmetric key encryption,\nthis is a single key for\n\n24\n00:01:10.200 --> 00:01:14.390\nthe encryption and decryption and\nit must be securely transmitted.\n\n25\n00:01:14.390 --> 00:01:17.880\nAgain, because if somebody\ngets access to that key, well,\n\n26\n00:01:17.880 --> 00:01:21.630\nthey could do encryption but\nthey can also decrypt your information.\n\n27\n00:01:21.630 --> 00:01:25.370\nKeep in mind that it's a faster process\nthan asymmetric key encryption and\n\n28\n00:01:25.370 --> 00:01:29.500\nit requires lower computational power,\nif you will.\n\n29\n00:01:29.500 --> 00:01:32.240\nWhen it comes to asymmetric key\nencryption, keep in mind there's\n\n30\n00:01:32.240 --> 00:01:35.360\na different key for encryption than\nthere is for decryption, right.\n\n31\n00:01:35.360 --> 00:01:37.550\nWe have a public key and\nwe have a private key,\n\n32\n00:01:37.550 --> 00:01:41.760\npublic key is what encrypts the\ninformation as we send it across the wire.\n\n33\n00:01:41.760 --> 00:01:47.190\nAnd the private key is what decrypts the\ninformation, now when it comes down to it,\n\n34\n00:01:47.190 --> 00:01:51.740\nthe keys really could, one or the other\ncould do encryption or decryption.\n\n35\n00:01:51.740 --> 00:01:57.080\nCuz again, they work to inten, they work\nas a pair, but the way we use it for\n\n36\n00:01:57.080 --> 00:02:01.280\npublic key encryption is the fact that\nthe public key does the encryption so\n\n37\n00:02:01.280 --> 00:02:03.240\nthat we can give anybody access to that.\n\n38\n00:02:03.240 --> 00:02:09.540\nAnd the private key stays private so only\nthe person that had the public key will\n\n39\n00:02:09.540 --> 00:02:14.090\nhave the private key that matches that,\nbut the execution is a little bit slower.\n\n40\n00:02:14.090 --> 00:02:17.061\nNow I do wanna talk briefly and\nthey don't call it out right here.\n\n41\n00:02:17.061 --> 00:02:18.195\nBut I wanna go ahead and\n\n42\n00:02:18.195 --> 00:02:22.275\ntalk just briefly about another concept\nwhen it comes to public key encryption.\n\n43\n00:02:22.275 --> 00:02:27.044\nBecause of the fact that we can, like I\nsaid, the key pair works together, but\n\n44\n00:02:27.044 --> 00:02:30.511\nthe way we do it to encrypt\nour information, if you will,\n\n45\n00:02:30.511 --> 00:02:33.619\nis to allow the public key\nto do the encryption, and\n\n46\n00:02:33.619 --> 00:02:37.130\nwe store that private key and\nwe keep it secure.\n\n47\n00:02:37.130 --> 00:02:42.510\nNow, imagine a way that you\ncould prove I am who I say I am.\n\n48\n00:02:42.510 --> 00:02:44.140\nNow how could we do that?\n\n49\n00:02:44.140 --> 00:02:47.300\nWell that's through something\nknown as a digital signature.\n\n50\n00:02:47.300 --> 00:02:51.290\nAll right, and a digital signature kinda\nreverses the way we think of public\n\n51\n00:02:51.290 --> 00:02:52.810\nkey encryption, all right.\n\n52\n00:02:52.810 --> 00:02:56.040\n&gt;&gt; Is that the DSA you're talking about or\nis it different?\n\n53\n00:02:56.040 --> 00:02:58.340\n&gt;&gt; DSA was the digital\nsignature algorithm and\n\n54\n00:02:58.340 --> 00:02:59.510\nthat was-\n&gt;&gt; Right.\n\n55\n00:02:59.510 --> 00:03:02.640\n&gt;&gt; One of the earlier standards, but\nwe can do this, believe it or not,\n\n56\n00:03:02.640 --> 00:03:04.090\nwith any-\n&gt;&gt; Okay.\n\n57\n00:03:04.090 --> 00:03:09.010\n&gt;&gt; Any of the public key, or asymmetric\nkey algorithms, but what we're gonna\n\n58\n00:03:09.010 --> 00:03:12.080\ndo is we're gonna change our mindset\nbecause this is gonna be used for\n\n59\n00:03:12.080 --> 00:03:13.280\na different purpose.\n\n60\n00:03:13.280 --> 00:03:19.130\nThis is gonna be used for,\nit can be used for [LAUGH] authentication.\n\n61\n00:03:19.130 --> 00:03:24.500\nIt could be done for authenticity of\norigin, and what I mean by that is,\n\n62\n00:03:24.500 --> 00:03:28.400\nhow could you prove that I\nam who I say I am right?\n\n63\n00:03:28.400 --> 00:03:32.860\nWell I could type in a user name and\npassword, or I could hand you\n\n64\n00:03:32.860 --> 00:03:38.790\nan encrypted piece of information that\nI've encrypted with my keys right.\n\n65\n00:03:38.790 --> 00:03:43.050\nAnd I should only have access\nto one of those keys right?\n\n66\n00:03:43.050 --> 00:03:48.510\nThat's the private key,all right, now how\ndo you know that that actually is me?\n\n67\n00:03:48.510 --> 00:03:52.600\nWell imagine the private key cuz it's\nstored in a secure location on my computer\n\n68\n00:03:52.600 --> 00:03:54.570\nand this time I kinda\nreversed the process.\n\n69\n00:03:54.570 --> 00:03:57.852\nI say you know what, I'm gonna take the\nprivate key, that only I have access to,\n\n70\n00:03:57.852 --> 00:04:00.677\nnobody else has access to, and\nI'm gonna encrypt the information.\n\n71\n00:04:00.677 --> 00:04:05.251\nWe're kinda gonna reverse the process,\nand then I'm gonna take that encrypted\n\n72\n00:04:05.251 --> 00:04:07.951\ninformation and\nI'm gonna pass it over to you.\n\n73\n00:04:07.951 --> 00:04:12.862\nAnd to prove I am who I say I am,\nif it truly is me, you should be able to\n\n74\n00:04:12.862 --> 00:04:18.230\ndecrypt it with something that matches\nthe encryption on my private key.\n\n75\n00:04:18.230 --> 00:04:19.650\nAnd what would that be?\n\n76\n00:04:19.650 --> 00:04:21.690\nWell that would be the public key, so\n\n77\n00:04:21.690 --> 00:04:25.565\nit's interesting that we can\nreverse this process, and\n\n78\n00:04:25.565 --> 00:04:30.860\ndo what's known as a digital signature\nby me taking my private key.\n\n79\n00:04:30.860 --> 00:04:34.170\nIn fact, let me show you here, so\nI got a little bit of a diagram.\n\n80\n00:04:35.530 --> 00:04:38.082\nImagine me taking this private\nkey this time, right, now,\n\n81\n00:04:38.082 --> 00:04:39.542\nI'm not sharing the private key.\n\n82\n00:04:39.542 --> 00:04:41.984\nNobody has access to that private key,\n\n83\n00:04:41.984 --> 00:04:46.206\nwhich means I'm the only one that\nshould have access to it, right.\n\n84\n00:04:46.206 --> 00:04:48.170\nWell here's another thing I\nwant you to keep in mind.\n\n85\n00:04:48.170 --> 00:04:52.902\nThe fact that these are mathematically\naligned, if I encrypt something with\n\n86\n00:04:52.902 --> 00:04:57.118\na private key and I send it over\nthe wire to you, the only other key that\n\n87\n00:04:57.118 --> 00:05:00.943\nshould reverse that encryption\nis my associated public key.\n\n88\n00:05:00.943 --> 00:05:05.715\nZack's public key wouldn't do anything,\nall right, so digital signatures\n\n89\n00:05:05.715 --> 00:05:09.633\nare a way that you could prove\nthe person is who they say they are.\n\n90\n00:05:09.633 --> 00:05:14.266\nBecause if my public key\nreverses the encryption,\n\n91\n00:05:14.266 --> 00:05:19.330\nit has to be my private key\nthat did the encryption.\n\n92\n00:05:19.330 --> 00:05:23.220\nAnd only I have access to that,\nright nobody else has access to that.\n\n93\n00:05:23.220 --> 00:05:26.920\nSo that's what's known as a digital\nsignature, we can, and it's only done for\n\n94\n00:05:26.920 --> 00:05:29.710\nthat purpose, that you can prove\n\n95\n00:05:29.710 --> 00:05:33.430\nthe origin of the communication came from\nexactly who you were expecting to, right.\n\n96\n00:05:33.430 --> 00:05:36.160\nNow we do other things, too,\nwe can combine it with hash functions and\n\n97\n00:05:36.160 --> 00:05:39.880\nwe can not only prove the origin\nof a piece of information.\n\n98\n00:05:39.880 --> 00:05:42.740\nWe can combine it with a hashing function,\nthat means that if I\n\n99\n00:05:42.740 --> 00:05:46.660\nhand you that piece of data, the data\nonce you've removed the encryption,\n\n100\n00:05:46.660 --> 00:05:49.650\nyou can look at the hashing algorithm and\nyou can say all right.\n\n101\n00:05:49.650 --> 00:05:51.970\nDo these hashing algorithms\nmatch what I'm expecting?\n\n102\n00:05:51.970 --> 00:05:54.810\nAnd if they do, now you've also\ngot integrity of the information,\n\n103\n00:05:54.810 --> 00:05:57.960\nit's the way we do things\nlike code signing.\n\n104\n00:05:57.960 --> 00:06:01.000\nFor instance,\nlike drivers inside of Windows,\n\n105\n00:06:01.000 --> 00:06:04.370\nI need to be able to prove who\nthe publisher of that driver was, right.\n\n106\n00:06:04.370 --> 00:06:07.095\nSo what they do is they\ntake that information,\n\n107\n00:06:07.095 --> 00:06:09.490\nthey digitally sign it\nwith their private key.\n\n108\n00:06:09.490 --> 00:06:10.541\nIt's encrypted and\n\n109\n00:06:10.541 --> 00:06:14.876\ninside of that encryption is a hash value\nof all the components within that driver.\n\n110\n00:06:14.876 --> 00:06:18.665\nAnd I pass it over to whoever the end\nuser is and they can take my public key,\n\n111\n00:06:18.665 --> 00:06:23.084\nremove that encryption so it proves that I\nmust have been the software manufacturer.\n\n112\n00:06:23.084 --> 00:06:27.354\nCuz it was my matching private key that\ndid the encryption, but then inside of\n\n113\n00:06:27.354 --> 00:06:32.149\nthat document we can see here's these hash\nvalues, let me compare the values to what\n\n114\n00:06:32.149 --> 00:06:36.512\nyou told me now that I know you are the\nsoftware publisher that I should expect.\n\n115\n00:06:36.512 --> 00:06:40.240\nAnd if those values match then I know\nnot only cuz I prove who you are,\n\n116\n00:06:40.240 --> 00:06:43.774\nI can also prove that the drivers\nthat you gave me have maintained\n\n117\n00:06:43.774 --> 00:06:46.805\ntheir integrity and\naren't gonna corrupt my system.\n\n118\n00:06:46.805 --> 00:06:50.363\nSo, that's a digital signature, it's\nnot really in the exam objectives, but\n\n119\n00:06:50.363 --> 00:06:52.156\nI did wanna take sometime to mention it.\n\n120\n00:06:52.156 --> 00:06:56.388\nBecause the keys are mathematically\naligned, and again, keep in mind,\n\n121\n00:06:56.388 --> 00:07:00.893\nif I encrypt something it's only gonna be\nwhatever the matching key is to my key\n\n122\n00:07:00.893 --> 00:07:03.060\npair that removes that encryption.\n\n123\n00:07:03.060 --> 00:07:08.630\nSo that would be a digital signature, now\n\n124\n00:07:08.630 --> 00:07:12.130\nan algorithm encrypts information,\nall right.\n\n125\n00:07:12.130 --> 00:07:15.950\nBut what we need to sometimes do is\n\n126\n00:07:15.950 --> 00:07:21.220\ntell the algorithm exactly how\nto encrypt the information.\n\n127\n00:07:21.220 --> 00:07:24.820\nAnd that's through something known\nas modes of operation, all right.\n\n128\n00:07:24.820 --> 00:07:25.690\n&gt;&gt; Cipher modes.\n\n129\n00:07:25.690 --> 00:07:27.910\n&gt;&gt; Cipher modes, very good, on the money.\n\n130\n00:07:27.910 --> 00:07:29.660\nYou might hear it called\nmodes of operation,\n\n131\n00:07:29.660 --> 00:07:31.520\nyou might hear it called cipher modes.\n\n132\n00:07:31.520 --> 00:07:34.520\nAnd there are a few of them that\nthey call out on comp t as exam\n\n133\n00:07:34.520 --> 00:07:36.110\nthat we want you guys to be aware of.\n\n134\n00:07:36.110 --> 00:07:38.736\nAnd I've got a little list here,\nall right, let's go ahead and\n\n135\n00:07:38.736 --> 00:07:40.840\nlet's walk through each one of these,\nall right.\n\n136\n00:07:40.840 --> 00:07:46.903\nThe first one is what's known as CBC, CBC\nis the cypher block chaining, all right.\n\n137\n00:07:46.903 --> 00:07:49.918\nAnd what this does is it\nuses initialization vector,\n\n138\n00:07:49.918 --> 00:07:52.760\nlet's stop right there just for\na second, okay.\n\n139\n00:07:52.760 --> 00:07:56.180\nLet's understand what\ninitialization vector is, remember,\n\n140\n00:07:56.180 --> 00:07:57.521\nthink about it this way.\n\n141\n00:07:57.521 --> 00:08:03.612\nIf you have two identical pieces of\nplain text, identical in every way.\n\n142\n00:08:03.612 --> 00:08:08.240\nAnd I use the same mathematical\nfunction to encrypt it, guess what?\n\n143\n00:08:08.240 --> 00:08:11.200\nThey're gonna produce\nidentical ciphertexts.\n\n144\n00:08:11.200 --> 00:08:14.539\nSame data, same algorithm,\nthe output's gonna be identical.\n\n145\n00:08:14.539 --> 00:08:22.105\nWe don't want patterns,\nwe don't want similarity in encryption.\n\n146\n00:08:22.105 --> 00:08:25.468\nWe want it to be as random as possible\nbecause if there are things that\n\n147\n00:08:25.468 --> 00:08:29.244\nare similar, then that means somebody\ncould do an statistical analysis and\n\n148\n00:08:29.244 --> 00:08:33.020\nstart guessing the pattern and start\nto reverse engineer the encryption and\n\n149\n00:08:33.020 --> 00:08:34.800\nbefore you know it, it's broken.\n\n150\n00:08:36.240 --> 00:08:41.050\nSo what an initialization vector does,\nis it puts this random one-time value\n\n151\n00:08:41.050 --> 00:08:45.000\nat the front of every single\ndifferent piece of encrypted data.\n\n152\n00:08:45.000 --> 00:08:49.470\nAnd the point is,\nif I have a unique value placed\n\n153\n00:08:49.470 --> 00:08:54.650\nin front of the same plaintext, however\nthe initialization vector is different.\n\n154\n00:08:54.650 --> 00:08:58.070\nThat ensures that we never have\na duplication in our cipher text, right?\n\n155\n00:08:58.070 --> 00:09:01.840\nBecause we got a unique value\nthat's attached to our plain text.\n\n156\n00:09:01.840 --> 00:09:04.830\nAnd that value is gonna\nchange every single time.\n\n157\n00:09:04.830 --> 00:09:06.670\nSo it keeps all of the cipher text,\n\n158\n00:09:06.670 --> 00:09:10.360\nwell at least that's the goal, keeps\nall of the cipher text always unique.\n\n159\n00:09:10.360 --> 00:09:14.190\nRegardless, if it is the same plaintext\ngoing into the algorithm cuz we have\n\n160\n00:09:14.190 --> 00:09:15.600\na unique value.\n\n161\n00:09:15.600 --> 00:09:21.380\nSo Cipher Block Chaining uses\ninitialization vector and\n\n162\n00:09:21.380 --> 00:09:24.489\nyou have to keep in mind that\nwhat it does is it kind of\n\n163\n00:09:27.260 --> 00:09:30.450\ntakes the cipher text and\n\n164\n00:09:30.450 --> 00:09:35.840\nthen puts that into the next block of\ninformation and then that's encrypted.\n\n165\n00:09:35.840 --> 00:09:39.356\nAnd that encrypted information is\nplaced into the next block of text and\n\n166\n00:09:39.356 --> 00:09:40.653\nthen that's encrypted.\n\n167\n00:09:40.653 --> 00:09:45.120\nSo, that's why they call it a chain and\nwe'll see that here in a second coming up.\n\n168\n00:09:45.120 --> 00:09:50.020\nThe other one that we have here is\nan older one and it is very vulnerable.\n\n169\n00:09:50.020 --> 00:09:54.310\nThat's called electronic code block and\nagain, this is a mode of operation if you\n\n170\n00:09:54.310 --> 00:09:59.820\nwill, for block ciphers and it supports\na separate key encryption for each block.\n\n171\n00:09:59.820 --> 00:10:03.810\nThe other one is called,\nin the objectives they say CTM, and\n\n172\n00:10:03.810 --> 00:10:07.590\nI think this is a typo, and\nI'll definitely put some notes\n\n173\n00:10:07.590 --> 00:10:11.300\nthat you guys can check out just in\ncase I happen to be wrong on this one.\n\n174\n00:10:11.300 --> 00:10:16.210\nBut they say CTM and I really believe\nthat they're going for counter mode, but\n\n175\n00:10:16.210 --> 00:10:19.220\ncounter mode's acronym is actually CTR,\nall right?\n\n176\n00:10:19.220 --> 00:10:23.845\nAnd counter mode what it does is takes\nthat kinda like initialization vector\n\n177\n00:10:23.845 --> 00:10:27.688\na one time value it's a nuance\nif you will, a number used once.\n\n178\n00:10:27.688 --> 00:10:30.048\nAnd it adds a counter, if you will,\n\n179\n00:10:30.048 --> 00:10:36.200\nas it initialization vector then that\ncounter changes as it encrypts the text.\n\n180\n00:10:36.200 --> 00:10:41.550\nThe last one here is GCM and\nthat is Galois/Counter Mode.\n\n181\n00:10:41.550 --> 00:10:44.410\nAnd what this is, this is a mode\nof operation, if you will, for\n\n182\n00:10:44.410 --> 00:10:50.150\nsymmetric key block ciphers that's\nalso used as a form of authentication.\n\n183\n00:10:50.150 --> 00:10:50.890\nNow let's go ahead.\n\n184\n00:10:50.890 --> 00:10:53.100\nAnd that's a lot of information.\n\n185\n00:10:53.100 --> 00:10:55.292\nProbably not helping you out.\n\n186\n00:10:55.292 --> 00:10:58.766\nWell, hopefully it's helping you\nunderstand what the acronyms are.\n\n187\n00:10:58.766 --> 00:10:59.860\nLet's go a little bit farther.\n\n188\n00:10:59.860 --> 00:11:01.990\nLet's take Electronic Codebook and\n\n189\n00:11:01.990 --> 00:11:05.140\nlet's kinda understand what's\nhappening here, all right?\n\n190\n00:11:05.140 --> 00:11:08.280\nI have plain text,\ninitialization vector, right?\n\n191\n00:11:08.280 --> 00:11:11.794\nThat's patting,\nthat's added to the plaintext and\n\n192\n00:11:11.794 --> 00:11:16.485\nthen we run it to the block cipher,\nremember plaintext to cipher text.\n\n193\n00:11:16.485 --> 00:11:19.755\nBut it does it on an individual\nblock-by-block basis and\n\n194\n00:11:19.755 --> 00:11:21.878\nthere's a problem with that.\n\n195\n00:11:21.878 --> 00:11:25.880\nWhat you can end up doing is you\ncan have identical plaintext that\n\n196\n00:11:25.880 --> 00:11:30.560\ngo into this block and you could start\nto see identical ciphertext, right?\n\n197\n00:11:30.560 --> 00:11:33.905\nSo, again, you could start\nto see some similarities, so\n\n198\n00:11:33.905 --> 00:11:35.375\nyou gotta be careful with this one, right?\n\n199\n00:11:35.375 --> 00:11:37.895\nAnd it is one of the most basic.\n\n200\n00:11:37.895 --> 00:11:41.445\nUnlike something like\nCipher Block Chaining\n\n201\n00:11:41.445 --> 00:11:43.995\nwhere we start with that\ninitialization vector, right?\n\n202\n00:11:43.995 --> 00:11:46.105\nThat padding to our plaintext.\n\n203\n00:11:46.105 --> 00:11:51.635\nWe run it through the block cipher,\nthen the cipher text comes out and we turn\n\n204\n00:11:51.635 --> 00:11:57.440\naround and we feed that cipher text as the\ninitialization vector for the next block.\n\n205\n00:11:57.440 --> 00:12:01.813\nAnd then we run the cipher, and then that\nblock cipher text is fed into the next\n\n206\n00:12:01.813 --> 00:12:04.978\nblock of information as\nthe initialization vector, so\n\n207\n00:12:04.978 --> 00:12:07.761\nthat's why they call it\nCipher Block Chaining.\n\n208\n00:12:07.761 --> 00:12:11.567\nYou're taking that block's\nencrypted output and using it for\n\n209\n00:12:11.567 --> 00:12:16.480\nthe next block's initialization vector,\nnext vector, next IV.\n\n210\n00:12:16.480 --> 00:12:20.490\nNow this one you gonna be careful\nwith because while it is good,\n\n211\n00:12:20.490 --> 00:12:26.140\nit can cause some errors really\nin the decryption process.\n\n212\n00:12:26.140 --> 00:12:29.910\nBecause what happens if,\njust theoretically,\n\n213\n00:12:29.910 --> 00:12:35.160\nif we have plaintext initialization vector\nfed to the algorithm we have cipher text,\n\n214\n00:12:35.160 --> 00:12:38.920\nbut there's an error in that cipher text,\nsomewhere there is an error.\n\n215\n00:12:38.920 --> 00:12:41.840\nRemember we talked about block\nciphers being prone to errors.\n\n216\n00:12:41.840 --> 00:12:46.020\nAnd we feed that cipher text with\nthat error into the next block, and\n\n217\n00:12:46.020 --> 00:12:47.150\nit encrypts.\n\n218\n00:12:47.150 --> 00:12:50.330\nAnd then we feed the encrypted\nerror into the next block.\n\n219\n00:12:50.330 --> 00:12:55.310\nSo the decryption relies on each\nprevious block being error free,\n\n220\n00:12:55.310 --> 00:12:57.610\nso again you can run into that.\n\n221\n00:12:58.850 --> 00:13:00.840\nNow last one is the counter mode.\n\n222\n00:13:00.840 --> 00:13:04.660\nAll right, counter mode takes a nuance,\na number used once.\n\n223\n00:13:04.660 --> 00:13:08.220\nAnd what it does is it\napplies a sequential counter.\n\n224\n00:13:08.220 --> 00:13:10.800\nAnd that is run to the block cipher.\n\n225\n00:13:10.800 --> 00:13:14.420\nAnd then the plaintext\nbecomes your cipher text.\n\n226\n00:13:14.420 --> 00:13:18.060\nAnd the purpose here is to try\nto protect that counter so\n\n227\n00:13:18.060 --> 00:13:19.670\nwe can't reverse engineer it.\n\n228\n00:13:19.670 --> 00:13:22.930\nAnd then the next block if you will,\nhas an increment counter.\n\n229\n00:13:22.930 --> 00:13:25.740\nAnd one of the big things\nis just to remember that,\n\n230\n00:13:25.740 --> 00:13:29.270\nwhen they are implementing this\nis that you have enough sequence,\n\n231\n00:13:29.270 --> 00:13:32.310\nsequential numerical values,\nin the counter.\n\n232\n00:13:32.310 --> 00:13:33.670\nSo that you don't repeat it.\n\n233\n00:13:33.670 --> 00:13:37.380\nRemember, every time you repetition\nthere's a potential that you could reverse\n\n234\n00:13:37.380 --> 00:13:39.270\nengineer this information.\n\n235\n00:13:39.270 --> 00:13:41.380\nSo that's your counter mode.\n\n236\n00:13:41.380 --> 00:13:43.860\nAnd again,\nthese are applied to thinks like AES.\n\n237\n00:13:43.860 --> 00:13:47.140\nYou might see things like AES CBC, right?\n\n238\n00:13:47.140 --> 00:13:50.830\nAdvanced Encryption Standard with\nCipher Block Chaining, right?\n\n239\n00:13:50.830 --> 00:13:54.379\nThat's a common one there, so\nthose are the modes of operation.\n\n240\n00:13:55.750 --> 00:13:57.340\nAll right, so let's go ahead.\n\n241\n00:13:57.340 --> 00:14:02.150\nLet's talk about the next\ntype of cryptology basic.\n\n242\n00:14:02.150 --> 00:14:05.250\nAnd we've kind of mentioned this before,\nbut we wanna kinda go back over it then we\n\n243\n00:14:05.250 --> 00:14:09.450\nwanna talk about some of the families\nof hashing algorithms, right?\n\n244\n00:14:09.450 --> 00:14:13.520\nSo we talked about how we keep\nour information confidential\n\n245\n00:14:13.520 --> 00:14:14.190\nthrough encryption.\n\n246\n00:14:14.190 --> 00:14:15.730\nRight?\nAnd there's encryption processes that\n\n247\n00:14:15.730 --> 00:14:16.540\nwe talked about.\n\n248\n00:14:16.540 --> 00:14:18.450\nThat's the C in the CIA triad, right?\n\n249\n00:14:18.450 --> 00:14:22.220\nThe principles of security say\nconfidentiality, integrity and\n\n250\n00:14:22.220 --> 00:14:23.620\navailability, right?\n\n251\n00:14:23.620 --> 00:14:26.170\nWell, how do we maintain\nthe integrity of the information?\n\n252\n00:14:26.170 --> 00:14:29.920\nIntegrity means that, if I sent a piece\nof information from myself to Zach,\n\n253\n00:14:29.920 --> 00:14:34.830\nZach knows without a shadow of a doubt\nthat not a single punctuation mark\n\n254\n00:14:34.830 --> 00:14:38.380\nhas been changed, maliciously or\nthrough transmission errors.\n\n255\n00:14:38.380 --> 00:14:41.230\nSo the way we do this is,\n\n256\n00:14:41.230 --> 00:14:45.810\nis we run this piece of data through\nsomething known as a hashing function.\n\n257\n00:14:45.810 --> 00:14:48.610\nIn fact, let me give you an example here.\n\n258\n00:14:48.610 --> 00:14:53.190\nSo these two ladies, they need to send\ninformation, and this young lady over\n\n259\n00:14:53.190 --> 00:14:57.530\nhere wants to make sure that\nthe data isn't modified in any way.\n\n260\n00:14:57.530 --> 00:15:00.429\nSo, what happens, all right,\nwe take the file,\n\n261\n00:15:00.429 --> 00:15:04.546\nwe run it to the hashing function and\nit produces a fixed length value.\n\n262\n00:15:04.546 --> 00:15:07.840\nAll right, now,\nif you use that same hashing function,\n\n263\n00:15:09.050 --> 00:15:12.060\nthe fixed length value will\nalways stay the same length.\n\n264\n00:15:12.060 --> 00:15:13.860\nNow, the value could change, and\n\n265\n00:15:13.860 --> 00:15:16.790\nthat's where we can find out if\nthere's integrity that's been lost.\n\n266\n00:15:16.790 --> 00:15:20.480\nBut the value always stays\nthe same fixed length.\n\n267\n00:15:20.480 --> 00:15:23.500\nAnd what I mean by that is it doesn't\nmatter if you have a document\n\n268\n00:15:23.500 --> 00:15:26.920\nthat's 800 pages long or even a document\nthat's got one character in it.\n\n269\n00:15:26.920 --> 00:15:30.540\nYou wrote through a hashing\nfunction the length of that\n\n270\n00:15:30.540 --> 00:15:33.360\noutput is gonna be the same, okay?\n\n271\n00:15:33.360 --> 00:15:36.340\nNow which means the reason\nthey call it one-way\n\n272\n00:15:36.340 --> 00:15:39.720\nfunction is because it doesn't matter\nhow much data goes into the function,\n\n273\n00:15:39.720 --> 00:15:41.500\nit's gonna produce the same fixed length.\n\n274\n00:15:41.500 --> 00:15:45.110\nIt means you shouldn't be able to deduce\nthe information that was thrown into\n\n275\n00:15:45.110 --> 00:15:45.970\nthe algorithm, right?\n\n276\n00:15:45.970 --> 00:15:48.020\nBecause it doesn't how much it is or\nhow little it is.\n\n277\n00:15:48.020 --> 00:15:51.220\nSo it's theoretically unfeasible.\n\n278\n00:15:51.220 --> 00:15:54.071\nNever say never in cryptology,\nright, or cryptography, excuse me.\n\n279\n00:15:54.071 --> 00:15:58.811\nIt's mathematically infeasible that\nyou could figure out what the data is.\n\n280\n00:15:58.811 --> 00:16:02.791\nSo what she does is she runs that\nfile through that hashing algorithm.\n\n281\n00:16:02.791 --> 00:16:09.098\nAnd then the file itself is transmitted\nto this young lady with the hash value.\n\n282\n00:16:09.098 --> 00:16:10.778\nAnd I have to tell her or these lady,\n\n283\n00:16:10.778 --> 00:16:14.150\nshe has to know what the hashing\nfunction was that produced that value.\n\n284\n00:16:14.150 --> 00:16:15.014\nSo you have to use the same function.\n\n285\n00:16:15.014 --> 00:16:18.894\nAnd then what she can do is she can run\nthe same process on the other side,\n\n286\n00:16:18.894 --> 00:16:21.881\ntake that file,\nrun it through the hashing function.\n\n287\n00:16:21.881 --> 00:16:24.660\nAnd what she does is she\ncompares the values.\n\n288\n00:16:24.660 --> 00:16:30.710\nNow, if the two values matched, she knows\nthat the data hasn't been modified.\n\n289\n00:16:30.710 --> 00:16:34.220\nHowever, if the data doesn't match,\ntypically it's discarded, right?\n\n290\n00:16:34.220 --> 00:16:38.500\nWe even do this, these are called\nchecksums as well in certain areas, too.\n\n291\n00:16:38.500 --> 00:16:40.910\nWe have them in network\ncommunications likewise.\n\n292\n00:16:40.910 --> 00:16:44.750\nSo when a piece of information is checked,\nfor instance,\n\n293\n00:16:44.750 --> 00:16:48.670\na frame is checked, we check that frame\nof data that the switch is passing.\n\n294\n00:16:48.670 --> 00:16:52.205\nAnd if that checksum doesn't match what's\nexpected, the data is discarded, and\n\n295\n00:16:52.205 --> 00:16:54.440\nthere's a request for\nre-transmission, right?\n\n296\n00:16:54.440 --> 00:16:56.320\nSo we don't have this\njust in cryptography.\n\n297\n00:16:56.320 --> 00:17:00.805\nWe also have this to ensure that\nthe data that is passing across\n\n298\n00:17:00.805 --> 00:17:04.438\nour networks is received\nin an uncorrupt manner.\n\n299\n00:17:04.438 --> 00:17:08.252\nIf it's received in a corrupt manner,\nit's rejected, and there's a recall for\n\n300\n00:17:08.252 --> 00:17:09.423\nthat same information.\n\n301\n00:17:09.423 --> 00:17:12.377\nNow let's talk about\nthe actual hashing functions.\n\n302\n00:17:12.377 --> 00:17:16.430\nThere's a couple of families\nof algorithms here.\n\n303\n00:17:16.430 --> 00:17:22.500\nAnd I want you to understand that when we\ntalk about these hashing algorithms, this\n\n304\n00:17:22.500 --> 00:17:27.730\nwhole side, this whole family, MD Family,\n[LAUGH] really shouldn't be used today.\n\n305\n00:17:27.730 --> 00:17:32.250\nBecause it was introduced back\nin 1992 by Ron Rivest, right?\n\n306\n00:17:32.250 --> 00:17:34.730\nWe talked about the RC stream cipher.\n\n307\n00:17:34.730 --> 00:17:37.860\nWell, this was first\nstarted back by Ron Rivest.\n\n308\n00:17:37.860 --> 00:17:41.750\nIt could be used for basic file integrity.\n\n309\n00:17:41.750 --> 00:17:45.200\nI can use it just for that,\nbut there's a problem with it.\n\n310\n00:17:45.200 --> 00:17:48.490\nIt's susceptible to what's\nknown as hashing collisions.\n\n311\n00:17:48.490 --> 00:17:53.163\nSee, a hashing collision is when\nI run a random string of text\n\n312\n00:17:53.163 --> 00:17:55.464\nthrough a hashing function.\n\n313\n00:17:55.464 --> 00:17:59.995\nAnd it produces the exact same value\nas the file you ran through the hashing\n\n314\n00:17:59.995 --> 00:18:01.321\nalgorithm, right?\n\n315\n00:18:01.321 --> 00:18:06.575\nLet me give you another example of where\nwe use these hashing algorithms, right?\n\n316\n00:18:06.575 --> 00:18:11.000\nNot necessarily, maybe the same type,\nbut like your passwords.\n\n317\n00:18:11.000 --> 00:18:13.090\nThe passwords that are on your,\nfor instance,\n\n318\n00:18:13.090 --> 00:18:15.410\nWindows machines,\nthey're stored in a database.\n\n319\n00:18:15.410 --> 00:18:18.010\nBut it's not the actual alphanumeric\n\n320\n00:18:18.010 --> 00:18:22.325\ncombination that you see in the ASCII\ncharacters on the keyboard, right?\n\n321\n00:18:22.325 --> 00:18:26.836\nIt's, you typed your password and\na hashing function produced a hash, and\n\n322\n00:18:26.836 --> 00:18:29.033\nthat hash is stored in the database.\n\n323\n00:18:29.033 --> 00:18:33.362\nWell, if I can produce any kind of\nrandom text, any kind of random string,\n\n324\n00:18:33.362 --> 00:18:36.822\nthere's a potential that it\ncould produce the same value.\n\n325\n00:18:36.822 --> 00:18:40.210\nAnd at that point, I don't need your\npassword, cuz I got the hash value.\n\n326\n00:18:40.210 --> 00:18:43.065\nThat's what the system's seeing,\nthat's called a hashing collision, right?\n\n327\n00:18:43.065 --> 00:18:44.804\nAnd we'll come back to that in a second,\n\n328\n00:18:44.804 --> 00:18:46.914\ncuz there's another thing\nwe gotta talk about.\n\n329\n00:18:48.020 --> 00:18:52.231\nSo Message Digest 5 is, 4 and\n2 don't even worry about that.\n\n330\n00:18:52.231 --> 00:18:57.336\nEven Message Digest 5 is considered\nobsolete or vulnerable today, all right?\n\n331\n00:18:57.336 --> 00:18:59.808\nSo that brings us into\nthe Secure Hashing Algorithm.\n\n332\n00:18:59.808 --> 00:19:04.910\nAnd the Secure Hashing Algorithm\nwas the successor to the earlier\n\n333\n00:19:04.910 --> 00:19:09.189\nMessage Digest 5, SHA-0,\nthis is a retro naming.\n\n334\n00:19:09.189 --> 00:19:14.182\nIn fact, you might've seen,\nthey call it SHA-0, but\n\n335\n00:19:14.182 --> 00:19:18.144\nmore often than not, it's just called SHA.\n\n336\n00:19:18.144 --> 00:19:21.720\nSHA is, I don't even think it was\never released to market because of\n\n337\n00:19:21.720 --> 00:19:23.307\nthe vulnerabilities it has.\n\n338\n00:19:23.307 --> 00:19:25.567\nIt was 160-bit hashing function.\n\n339\n00:19:25.567 --> 00:19:29.418\nSHA1 as well,\nwhat actually hit the market was 160 bits,\n\n340\n00:19:29.418 --> 00:19:33.577\nit's considered vulnerable today,\nyou shouldn't be using it.\n\n341\n00:19:33.577 --> 00:19:40.840\nNow, SHA2, understand, is a family\nthat's a suite of SHA technologies.\n\n342\n00:19:40.840 --> 00:19:44.185\nThat's the next generation, if you will,\nin Secure Hashing Algorithm.\n\n343\n00:19:44.185 --> 00:19:47.212\nAnd there's some different bit lengths\nthat I want you to be aware of.\n\n344\n00:19:47.212 --> 00:19:53.230\nThere's 224, 256, 384 and 512.\n\n345\n00:19:53.230 --> 00:19:57.830\nKeep in mind as you increase the length,\nright, it gets harder and\n\n346\n00:19:57.830 --> 00:20:02.200\nharder to do what's known as\nhashing collisions, all right?\n\n347\n00:20:02.200 --> 00:20:04.830\nLet's see, l got an example of this here.\n\n348\n00:20:04.830 --> 00:20:08.490\nLet me kinda show you, let's see,\ndo l have, yeah, all right.\n\n349\n00:20:08.490 --> 00:20:09.905\nSo let me give you an example,\n\n350\n00:20:09.905 --> 00:20:14.120\nthese are some hashing algorithms that I\nwrote to kinda see what the complexity is\n\n351\n00:20:14.120 --> 00:20:19.020\nbehind it that I did on a simple\nbit of text that's, This is me.\n\n352\n00:20:19.020 --> 00:20:21.080\nIn fact, if you take the quotes off,\nyou can go out, and\n\n353\n00:20:21.080 --> 00:20:23.150\nyou could find hash calculators online.\n\n354\n00:20:23.150 --> 00:20:25.570\nAnd you can verify these exact values.\n\n355\n00:20:25.570 --> 00:20:30.180\nYou can do this at home when you wanna\nkinda a proof of concept, right?\n\n356\n00:20:30.180 --> 00:20:33.890\nGo out to the website, go out to the\nInternet, and find a hashing calculator.\n\n357\n00:20:33.890 --> 00:20:40.758\nAnd run This is me, no quotes, with MD2\n128 Bit, and it produces this value.\n\n358\n00:20:40.758 --> 00:20:44.171\nNow, notice that these 128 Bit varieties,\n\n359\n00:20:44.171 --> 00:20:48.366\nthey don't change the length\nof the fixed value, right?\n\n360\n00:20:48.366 --> 00:20:53.110\nAnd they're very small, but\nnotice the size difference, the change,\n\n361\n00:20:53.110 --> 00:20:56.164\nwhen we bump up to 168 Bit SHA-1, right?\n\n362\n00:20:56.164 --> 00:20:58.001\nNotice that size difference.\n\n363\n00:20:58.001 --> 00:21:01.825\nSo you could see the hash value length is\na lot greater, which means it's a little\n\n364\n00:21:01.825 --> 00:21:04.875\nbit harder, if you will,\nto have a hashing collision, right?\n\n365\n00:21:04.875 --> 00:21:10.108\nBasically, where you could exploit it.\n\n366\n00:21:10.108 --> 00:21:14.638\nNow look what happens\nwhen we go from SHA-160\n\n367\n00:21:14.638 --> 00:21:18.842\na 160 bits to SHA-2 and its 256 bits.\n\n368\n00:21:18.842 --> 00:21:20.939\nIn fact, my head's kinda covering it up,\nthere we go.\n\n369\n00:21:20.939 --> 00:21:23.466\nAll right, notice the size different here.\n\n370\n00:21:23.466 --> 00:21:27.336\nWe're talking about a lot, lot stronger.\n\n371\n00:21:27.336 --> 00:21:32.125\nLook what happens when we bump\nup to 328 bit and then finally,\n\n372\n00:21:32.125 --> 00:21:36.035\nI can't even get it on the screen here,\n512 bit.\n\n373\n00:21:36.035 --> 00:21:37.676\nLook at the values.\n\n374\n00:21:37.676 --> 00:21:42.248\nAll right, the amount of combinations\nthat this is when we talk\n\n375\n00:21:42.248 --> 00:21:46.748\nabout SHA-2 is just astronomical,\nwhen we say 512 bit.\n\n376\n00:21:46.748 --> 00:21:51.946\nI'm gonna give you an example of\nan analogy for 128 bit, right?\n\n377\n00:21:51.946 --> 00:21:54.747\nEverything in binary's two\nto the powers of whatever.\n\n378\n00:21:54.747 --> 00:21:58.882\nIn a hundred and twenty-eight bits,\nthe possibilities,\n\n379\n00:21:58.882 --> 00:22:03.107\ntwo to the power of a hundred and\ntwenty-eight, all right?\n\n380\n00:22:03.107 --> 00:22:08.132\nJust at a hundred and twenty-eight bits,\nif you took all of those possibilities and\n\n381\n00:22:08.132 --> 00:22:12.377\nturned them into a grain of sand,\nat a hundred and twenty-eight bits,\n\n382\n00:22:12.377 --> 00:22:15.307\ntwo to the power of a hundred and\ntwenty-eight.\n\n383\n00:22:15.307 --> 00:22:20.173\nYou would need a container that is 1.3\nbillion times the circumference of our\n\n384\n00:22:20.173 --> 00:22:24.094\nearth to contain all of the sand\nthat each one of those individual\n\n385\n00:22:24.094 --> 00:22:25.778\ncombinations would make.\n\n386\n00:22:25.778 --> 00:22:30.134\nYou take the little BBs that are shot in\nBB guns and you stack them side by side,\n\n387\n00:22:30.134 --> 00:22:33.503\nit would form a line that would\ngo to the nearest black hole.\n\n388\n00:22:33.503 --> 00:22:37.609\nWrap around, come back and we'd still\nhave more possibilities, all right?\n\n389\n00:22:37.609 --> 00:22:42.824\nThat's at 128 bit, just to kinda give\nyou an idea compared to 512 bit.\n\n390\n00:22:42.824 --> 00:22:44.142\nI don't even have an analogy for that one.\n\n391\n00:22:44.142 --> 00:22:45.082\nIt's just mind-boggling.\n\n392\n00:22:45.082 --> 00:22:46.227\n&gt;&gt; [LAUGH]\n&gt;&gt; The first one is mind-boggling.\n\n393\n00:22:46.227 --> 00:22:49.118\n128 bits-\n&gt;&gt; [CROSSTALK] I've been to a black hole,\n\n394\n00:22:49.118 --> 00:22:50.295\nit wasn't that big of a deal.\n\n395\n00:22:50.295 --> 00:22:53.277\n&gt;&gt; Yeah, [LAUGH] and he returned and\nlived to tell the tale.\n\n396\n00:22:53.277 --> 00:22:57.551\nAgain, 128 bits,\nwe're talking 340 undecillion,\n\n397\n00:22:57.551 --> 00:22:59.906\nyes, that is actually a number.\n\n398\n00:22:59.906 --> 00:23:00.925\n&gt;&gt; Undecillion?\n&gt;&gt; That's right,\n\n399\n00:23:00.925 --> 00:23:02.274\nit's 12 place values above a billion.\n\n400\n00:23:02.274 --> 00:23:04.970\nSo yeah, it's just insane.\n\n401\n00:23:04.970 --> 00:23:07.831\nSo the higher bit levels in SHA-2\n\n402\n00:23:07.831 --> 00:23:12.375\nare gonna produce a little\nbit more secure algorithm.\n\n403\n00:23:12.375 --> 00:23:15.103\nAll right, couple of things that we\nalso gotta talk about that I wanna\n\n404\n00:23:15.103 --> 00:23:15.772\nfinish up here.\n\n405\n00:23:15.772 --> 00:23:19.547\nHMAC, now MAC is a little bit different.\n\n406\n00:23:19.547 --> 00:23:25.116\nHMAC is something known as the hashed\nmessage authentication code.\n\n407\n00:23:25.116 --> 00:23:29.877\nMAC, a message authentication code, is a\nchecksum that we put inside of the end of\n\n408\n00:23:29.877 --> 00:23:31.883\na piece of data and we send it over.\n\n409\n00:23:31.883 --> 00:23:36.655\nAnd just like a hashing value, the\nrecipient can check that value, all right?\n\n410\n00:23:36.655 --> 00:23:41.595\nHashed MAC, if you will,\nis a basically stronger than a mat because\n\n411\n00:23:41.595 --> 00:23:45.758\nit adds a hashing function\nby essentially concatenating\n\n412\n00:23:45.758 --> 00:23:51.250\nthe message itself with the secret key and\nhashing both of them.\n\n413\n00:23:51.250 --> 00:23:54.413\nKeep in mind that the strength is\ndetermined by the strength in the hashing\n\n414\n00:23:54.413 --> 00:23:56.413\nalgorithm and\nthe strength of the secret key.\n\n415\n00:23:56.413 --> 00:23:59.031\nYou'll notice that there\nare a couple of different kinds.\n\n416\n00:23:59.031 --> 00:24:03.248\nYou'll see HMAC-MD5 and HMAC-SHA.\n\n417\n00:24:03.248 --> 00:24:07.538\nSo pay attention, though, SHA would\nobviously be stronger than Message Digest\n\n418\n00:24:07.538 --> 00:24:11.511\n5 They do mention one other hashing\nalgorithm that I don't have a slide for\n\n419\n00:24:11.511 --> 00:24:14.662\nthat I just wanna mention,\nagain, cuz it's on the exam and\n\n420\n00:24:14.662 --> 00:24:17.360\nthat's something known as RIPEMD.\n\n421\n00:24:17.360 --> 00:24:20.780\nRIPEMD is the,\nboy this a bid old long name,\n\n422\n00:24:20.780 --> 00:24:23.720\nRace Integrity Primitives\nEvaluation Message Digest.\n\n423\n00:24:23.720 --> 00:24:25.840\nDo not try to say that ten times fast and\n\n424\n00:24:25.840 --> 00:24:29.760\ndon't expect that actual name to be\nrequired knowledge for the exam.\n\n425\n00:24:29.760 --> 00:24:35.520\n128, 160, 256, and 320-bit keylinks,\n\n426\n00:24:35.520 --> 00:24:40.920\na 128-bit keylink is\nvulnerable to collisions.\n\n427\n00:24:40.920 --> 00:24:45.651\nAll right, so last things that we've\nkinda gotta take care of here is\n\n428\n00:24:45.651 --> 00:24:49.176\nsomething known as\nkey-stretching algorithms.\n\n429\n00:24:49.176 --> 00:24:52.760\nAnd key-stretching algorithms\nare an interesting concept.\n\n430\n00:24:52.760 --> 00:24:58.190\nYour password, I told you, is a hash value\nthat's stored inside of your computer.\n\n431\n00:24:58.190 --> 00:24:59.370\nIt's essentially a key.\n\n432\n00:24:59.370 --> 00:25:03.290\nAll right, you might hear the term\nPSK pre shared key, it's a password.\n\n433\n00:25:03.290 --> 00:25:04.600\nThat's what a pre shared key is.\n\n434\n00:25:04.600 --> 00:25:05.600\nYou say well wait a second.\n\n435\n00:25:05.600 --> 00:25:06.650\nI didn't share anything.\n\n436\n00:25:06.650 --> 00:25:07.470\nWell yes you did.\n\n437\n00:25:07.470 --> 00:25:10.270\nWhen you typed in your password,\nyou now know your password and\n\n438\n00:25:10.270 --> 00:25:14.360\nthe security authentication system that\nstores that password, knows it as well.\n\n439\n00:25:14.360 --> 00:25:15.852\nIt's pretty shared, right?.\n\n440\n00:25:15.852 --> 00:25:19.805\nBut there's a problem in the database\nin which those keys are stored a lot of\n\n441\n00:25:19.805 --> 00:25:23.220\ntimes people like to use these\ncommon passwords, all right?.\n\n442\n00:25:23.220 --> 00:25:28.040\nAnd the problem is common passwords\nlike that, and even weak passwords.\n\n443\n00:25:28.040 --> 00:25:33.010\nGet's stored in attack mechanism\nknown as rainbow tables.\n\n444\n00:25:33.010 --> 00:25:36.838\nAll right now rainbow tables\nis a series of hash values and\n\n445\n00:25:36.838 --> 00:25:41.145\nwhat it does is essentially it\nassist the computational power,\n\n446\n00:25:41.145 --> 00:25:44.300\nthat it takes to cause\nthe hashing collision.\n\n447\n00:25:44.300 --> 00:25:48.129\nWell if we have common passwords in\na table used to collect passwords\n\n448\n00:25:48.129 --> 00:25:52.695\nthen that bit makes, all of those values,\nall of those passwords that are stored\n\n449\n00:25:52.695 --> 00:25:56.140\non our local machines,\nsusceptible to collision attacks.\n\n450\n00:25:56.140 --> 00:25:58.230\nWhich means people could break and\nget into your system.\n\n451\n00:25:59.270 --> 00:26:05.495\nSo a key stretching algorithm takes that\nhash value and makes it longer, right?\n\n452\n00:26:05.495 --> 00:26:11.215\nAnd what the goal here is,\nis to keep the new value once you run\n\n453\n00:26:11.215 --> 00:26:16.575\nthe hashing your key if you will to this\nstretching algorithm is to make it so\n\n454\n00:26:16.575 --> 00:26:19.295\nit's not found in those tables, right?\n\n455\n00:26:19.295 --> 00:26:24.490\nIt increases it's resiliency if you\nwill to pass well based attacks, and\n\n456\n00:26:24.490 --> 00:26:27.660\nthere are a couple of kinds I\nwant you to be familiar with.\n\n457\n00:26:27.660 --> 00:26:28.960\nThere's bcrypt.\n\n458\n00:26:28.960 --> 00:26:32.406\nAnd bcrypt is in your NIUX based systems\nif you will, Unix and Linux, and\n\n459\n00:26:32.406 --> 00:26:34.560\nit's a password hashing function.\n\n460\n00:26:34.560 --> 00:26:37.611\nAnd what it does is it adds\na little bit of padding,\n\n461\n00:26:37.611 --> 00:26:41.974\nif you will to the passwords and\nthen encrypts it with blowfish the other\n\n462\n00:26:41.974 --> 00:26:45.410\nasymmetric key encryption\nthat we were talking about?\n\n463\n00:26:45.410 --> 00:26:49.150\nThere's also another one called PB,\nnot peanut butter and jelly.\n\n464\n00:26:49.150 --> 00:26:52.550\nI know that's where it\nsounded like we were going.\n\n465\n00:26:52.550 --> 00:26:57.142\nPBKDF2 and what that does is that adds\npadding with a minimum of 64 bits and\n\n466\n00:26:57.142 --> 00:26:58.670\nit hashes the password.\n\n467\n00:26:58.670 --> 00:27:01.640\nThis is actually used in things like WPA2,\n\n468\n00:27:01.640 --> 00:27:05.120\nyou iOS Apple based\ndevices as well as Cisco.\n\n469\n00:27:06.140 --> 00:27:09.355\nAll right last couple of things here,\n\n470\n00:27:09.355 --> 00:27:13.180\nI keep saying that I\nsound like Colombo here.\n\n471\n00:27:13.180 --> 00:27:18.100\nObfuscation, now obfuscation really isn't\nabout encrypting the information as it\n\n472\n00:27:18.100 --> 00:27:20.710\nis about obscuring the data.\n\n473\n00:27:20.710 --> 00:27:23.910\nAnd we got some basic\nobfuscation techniques.\n\n474\n00:27:23.910 --> 00:27:25.001\nAn XOR function,\n\n475\n00:27:25.001 --> 00:27:29.470\nknow that the XOR function is\na way that you can obfuscate data.\n\n476\n00:27:29.470 --> 00:27:33.760\nYou also have things like, for\ninstance, ROT13, all right?\n\n477\n00:27:33.760 --> 00:27:36.660\nROT anything, if you will,\nis rotate, all right?\n\n478\n00:27:36.660 --> 00:27:40.990\nI want you to think of\nthe Captain Crunch decoder ring, right?\n\n479\n00:27:40.990 --> 00:27:45.422\nAnd you'd have a code and you would have\nto find out how many places you would turn\n\n480\n00:27:45.422 --> 00:27:48.610\nthe dial on the ring to matchup\nto the letter, all right?\n\n481\n00:27:48.610 --> 00:27:52.020\nWell, that's essentially what ROT is,\nrotating, right?\n\n482\n00:27:52.020 --> 00:27:57.100\nRotate 13 is an example of\na common obfuscation technique.\n\n483\n00:27:57.100 --> 00:27:58.620\nIn fact, let me kinda show you here.\n\n484\n00:27:58.620 --> 00:28:00.660\nSo let's take the alphabet here.\n\n485\n00:28:00.660 --> 00:28:02.490\nWe're gonna apply, let's say, a ROT13.\n\n486\n00:28:02.490 --> 00:28:06.150\nNow my math is absolutely horrible here,\nlet alone my spelling.\n\n487\n00:28:06.150 --> 00:28:10.440\nSo I'm gonna actually use a little\nbit of assistance on this one.\n\n488\n00:28:10.440 --> 00:28:14.160\nSo I've got a website that I wanna pass\non to you guys I think it's great.\n\n489\n00:28:14.160 --> 00:28:16.050\nIt might help you learn this concept.\n\n490\n00:28:16.050 --> 00:28:17.630\nSo let's take something.\n\n491\n00:28:17.630 --> 00:28:21.510\nI'm gonna copy this and let's take\nsomething like Zach's name, right?\n\n492\n00:28:21.510 --> 00:28:24.560\nAnd we're gonna do obfuscation\non Zack's name all right.\n\n493\n00:28:24.560 --> 00:28:25.560\nSo what are we doing?\n\n494\n00:28:25.560 --> 00:28:28.677\nWell I want you to take the first\nletter of his name Z and\n\n495\n00:28:28.677 --> 00:28:32.370\nwe start over here and\nsequentially we rotate it 13, right?\n\n496\n00:28:32.370 --> 00:28:35.460\nAnd if I do my math I\nbelieve that's M right?\n\n497\n00:28:35.460 --> 00:28:40.884\nAnd that's counting all right from Z to A,\n1, 2, 3,\n\n498\n00:28:40.884 --> 00:28:47.220\n4, 5, 6, 7, 8, 9, 10, 11,12, 13 right, M.\n\n499\n00:28:47.220 --> 00:28:52.202\nNow if we wanna do obfuscation,\nwhat if I say something like Zach\n\n500\n00:28:52.202 --> 00:28:56.940\nis the greatest, all right,\nhow would we obfuscate that?\n\n501\n00:28:56.940 --> 00:28:58.913\nWell we would take each letter and\n\n502\n00:28:58.913 --> 00:29:02.230\nwe would rotate the letter\n13 places in the alphabet.\n\n503\n00:29:02.230 --> 00:29:04.699\nSo for instance,\nif I did that in something like this,\n\n504\n00:29:04.699 --> 00:29:08.245\nwe've got a great website here that does\nallows you to do all different types of\n\n505\n00:29:08.245 --> 00:29:09.964\nrotates right down the road through,\n\n506\n00:29:09.964 --> 00:29:14.010\nI love this website cuz it makes it easier\nfor my math and spelling abilities here.\n\n507\n00:29:14.010 --> 00:29:16.270\nBut if you'll see,\nremember we started with M here,\n\n508\n00:29:16.270 --> 00:29:19.160\nmaybe you'll see that down there, that\nit's kind of already doing this for me,\n\n509\n00:29:19.160 --> 00:29:21.520\nand I'll zoom in on this guys,\nI know it's kinda hard to see.\n\n510\n00:29:21.520 --> 00:29:26.900\nBut if I do Zack is\nthe the greatest right.\n\n511\n00:29:26.900 --> 00:29:28.780\nSo here is our plain text.\n\n512\n00:29:30.130 --> 00:29:33.700\nHere is our obfuscation algorithm,\nif you will.\n\n513\n00:29:33.700 --> 00:29:37.175\nI know it's not that complex,\nbut we're rotating 13.\n\n514\n00:29:37.175 --> 00:29:42.330\nThen the output is\nobscured by rotating 13.\n\n515\n00:29:42.330 --> 00:29:43.480\nNow, we can verify.\n\n516\n00:29:43.480 --> 00:29:48.270\nThis is one of the things I like about\nROT13 is that we can verify that\n\n517\n00:29:48.270 --> 00:29:49.851\nvalue is valid right.\n\n518\n00:29:49.851 --> 00:29:52.715\nSo I'm gonna take that\ncompletely out all right.\n\n519\n00:29:52.715 --> 00:29:59.110\nNow I copied our obscured value,\nour obfuscated data.\n\n520\n00:29:59.110 --> 00:30:03.860\nAnd what happens if I put that back\ninto the top and we rotate 13?\n\n521\n00:30:03.860 --> 00:30:06.544\nWell, I come out with\nthe original message right.\n\n522\n00:30:06.544 --> 00:30:08.088\n&gt;&gt; I'm in love with this one.\n\n523\n00:30:08.088 --> 00:30:10.668\nThis is great.\n&gt;&gt; Absolutely so this is ROT13 and\n\n524\n00:30:10.668 --> 00:30:15.030\nagain it's just another\nform of obfuscation.\n\n525\n00:30:15.030 --> 00:30:17.850\nNow you also have things\nlike substitution ciphers.\n\n526\n00:30:17.850 --> 00:30:20.975\nAnd substitution cipher\nmight be something where,\n\n527\n00:30:20.975 --> 00:30:24.525\ngoing back to our alphabet here,\nwhere we basically take,\n\n528\n00:30:24.525 --> 00:30:28.870\nlet's say, the alphabet here, and\nwe apply our own jumbled alphabet.\n\n529\n00:30:28.870 --> 00:30:31.660\nAll the same characters,\nright but they're all jumbled up.\n\n530\n00:30:31.660 --> 00:30:35.981\nAnd that becomes our substitution\ncipher so substitution cipher again,\n\n531\n00:30:35.981 --> 00:30:40.511\njust gives you the ability for instances\nfor example, to say use the alphabet\n\n532\n00:30:40.511 --> 00:30:45.130\ninstead of that A, B, C, D we might have\nyou know in fact i might have one here.\n\n533\n00:30:45.130 --> 00:30:47.530\nAll right so\nhere's your substitution cipher right?\n\n534\n00:30:47.530 --> 00:30:51.930\nNotice that the cipher is\nthe scrambled output, right?\n\n535\n00:30:51.930 --> 00:30:54.280\nPlain text would be your normal alphabet.\n\n536\n00:30:54.280 --> 00:30:58.680\nThe cipher would be the substitution,\nif you will, right?\n\n537\n00:30:58.680 --> 00:31:01.801\nThat would be the scrambling\nof the letters, and\n\n538\n00:31:01.801 --> 00:31:04.857\nthen the output becomes\nyour obfuscated data.\n\n539\n00:31:04.857 --> 00:31:09.450\nSo XOR functions, ROT13 and\nsubstitution ciphers.\n\n540\n00:31:09.450 --> 00:31:14.179\nNot a way to encrypt your information so\nit doesn't provide confidentiality but\n\n541\n00:31:14.179 --> 00:31:17.460\nit does do a moderate amount\nof hiding the information.\n\n542\n00:31:17.460 --> 00:31:21.870\nJust understand it's not a substitution\nif you will, for encryption.\n\n543\n00:31:21.870 --> 00:31:24.410\n&gt;&gt; Wes, I love the way you teach,\nyou make everything so\n\n544\n00:31:24.410 --> 00:31:25.630\nunderstandable you really do.\n\n545\n00:31:25.630 --> 00:31:29.870\nI'm not being facetious, now this is part\ntwo, end of part two, of cryptography,\n\n546\n00:31:29.870 --> 00:31:31.060\nalgorithms basics.\n\n547\n00:31:31.060 --> 00:31:31.730\nWe had a part one.\n\n548\n00:31:31.730 --> 00:31:33.790\nIf you missed that,\nyou wanna check it out.\n\n549\n00:31:33.790 --> 00:31:36.032\nDo you wanna put a little bow on\neverything for us here real quick?\n\n550\n00:31:36.032 --> 00:31:39.690\n&gt;&gt; Yeah, again, I think it always\ncomes back to just remember.\n\n551\n00:31:39.690 --> 00:31:42.660\nThere's no one size fits all.\n\n552\n00:31:42.660 --> 00:31:46.770\nPay attention to the amount,\nlevel of encryption you need.\n\n553\n00:31:46.770 --> 00:31:52.940\nIt would be nice to say, hey let's just\napply 4096 bit keys to everything but\n\n554\n00:31:52.940 --> 00:31:57.550\nkeep in mind you have to take into\nconsideration the hardware that you have.\n\n555\n00:31:57.550 --> 00:32:01.690\nMobile devices they're not gonna have\nthe computational power as traditional\n\n556\n00:32:01.690 --> 00:32:03.820\nworkstation or much lesser server.\n\n557\n00:32:03.820 --> 00:32:06.880\nSo servers can handle higher\nlevels of encryption.\n\n558\n00:32:06.880 --> 00:32:10.932\nYou also have to think into mind if\nthere's acceleration cuz you might say,\n\n559\n00:32:10.932 --> 00:32:12.418\nwell, Triple DES and AES.\n\n560\n00:32:12.418 --> 00:32:16.800\nWell, Triple DES is a relatively weak,\nvery weak, algorithm considered to AES.\n\n561\n00:32:16.800 --> 00:32:19.439\nBut you might find systems like,\nlet's say,\n\n562\n00:32:19.439 --> 00:32:23.636\nnon-Intel based chips that don't\nhave hardware acceleration for AES,\n\n563\n00:32:23.636 --> 00:32:27.710\nthat Triple DES actually performs\nslower than AES did on that machine.\n\n564\n00:32:27.710 --> 00:32:29.710\nWhy?\n\n565\n00:32:29.710 --> 00:32:31.660\nBecause it did one over the other.\n\n566\n00:32:31.660 --> 00:32:35.090\nThe Intel system is not using\nAES acceleration in that fact,\n\n567\n00:32:35.090 --> 00:32:36.810\nso it's gonna actually slow down.\n\n568\n00:32:36.810 --> 00:32:39.920\nSo you might see that algorithms,\neven though they're weaker on\n\n569\n00:32:39.920 --> 00:32:43.900\ncertain platforms, actually perform\nslower than stronger algorithms.\n\n570\n00:32:43.900 --> 00:32:47.682\nSo just do your research, and\nunderstand what it is you need to encrypt,\n\n571\n00:32:47.682 --> 00:32:51.220\nthe level of encryption you need,\nmaybe for compliance purposes.\n\n572\n00:32:51.220 --> 00:32:55.539\nAnd then also consider the hardware you\nhave because it always takes a CPU to do\n\n573\n00:32:55.539 --> 00:32:57.210\nencryption and decryption.\n\n574\n00:32:57.210 --> 00:32:58.180\n&gt;&gt; Wes, marvelous.\n\n575\n00:32:58.180 --> 00:33:01.440\nCompTIA Security Plus would not\nbe the same without you, sir.\n\n576\n00:33:01.440 --> 00:33:03.702\nAnd you wanna make sure\nyou catch everything in\n\n577\n00:33:03.702 --> 00:33:05.390\nthe CompTIA Security+ Library.\n\n578\n00:33:05.390 --> 00:33:11.390\nAnd, by the way, thank you for watching\nITProTV, an ITPRO is always learning.\n\n579\n00:33:11.390 --> 00:33:12.280\nI'm Zach Memos.\n\n580\n00:33:12.280 --> 00:33:13.260\n&gt;&gt; And I\"m Wes Bryan.\n\n581\n00:33:13.260 --> 00:33:15.628\n&gt;&gt; We'll see you soon.\n\n582\n00:33:15.628 --> 00:33:21.452\n[MUSIC]\n\n583\n00:33:21.452 --> 00:33:25.028\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "219677433"
        },
        {
          "description": "In this show, Cherokee and Wes take a look at concepts such as hash algorithms including MD5, SHA, HMAC, and RIPEMD. They also look additional obfuscation methods such as key stretching algorithms, XORing, using ROT ciphers and substitution ciphers.",
          "length": "1829",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-3-cryptography_algorithms_basics_pt3-042117-PGM.00_30_15_12.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-3-cryptography_algorithms_basics_pt3-042117-PGM.00_30_15_12.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-2-3-cryptography_algorithms_basics_pt3-042117-PGM.00_30_15_12.Still001-sm.jpg",
          "title": "Cryptography Algorithms Basics Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:03.494\nWelcome to ITProTV,\nI'm your host Don [CROSSTALK]\n\n2\n00:00:03.494 --> 00:00:04.960\n&gt;&gt; Coming at you live,\n\n3\n00:00:04.960 --> 00:00:07.120\nfrom San Francisco [CROSSTALK]\n\n4\n00:00:07.120 --> 00:00:08.218\n[MUSIC]\n\n5\n00:00:08.218 --> 00:00:11.813\n&gt;&gt; You're watching ITProTV.\n\n6\n00:00:11.813 --> 00:00:15.290\n&gt;&gt; Welcome ladies and gentlemen\nto your CompTIA Security+ series.\n\n7\n00:00:15.290 --> 00:00:17.210\nI'm your show host, Cherokee Boose.\n\n8\n00:00:17.210 --> 00:00:20.790\nSo far we've looked at different\ntypes of cryptography algorithms,\n\n9\n00:00:20.790 --> 00:00:23.980\nsuch as symmetric encryption,\nasymmetric encryption.\n\n10\n00:00:23.980 --> 00:00:27.640\nIn this show, we're really going to\nbe focusing on hashing algorithms and\n\n11\n00:00:27.640 --> 00:00:30.130\ndifferent types of obfuscation techniques.\n\n12\n00:00:30.130 --> 00:00:32.605\nAnd with us today in studios,\nwe have Mr. Wes Bryan.\n\n13\n00:00:32.605 --> 00:00:34.230\nThank you for joining us, Wes.\n\n14\n00:00:34.230 --> 00:00:35.810\n&gt;&gt; Hey, thank you for\nhaving me back, Cherokee.\n\n15\n00:00:35.810 --> 00:00:39.220\nYep, that's right, we're going to work\non another mini-series here for sure.\n\n16\n00:00:39.220 --> 00:00:42.090\nBut there's a lot of stuff to talk to,\nor talk about if you will.\n\n17\n00:00:42.090 --> 00:00:45.140\nThere's a lot of things that we have\nto kinda understand when we look at our\n\n18\n00:00:45.140 --> 00:00:46.360\nequiptology basics.\n\n19\n00:00:46.360 --> 00:00:50.660\nAnd like Cherokee mentioned,\nwe're gonna start looking at some of\n\n20\n00:00:50.660 --> 00:00:55.610\nthe various ways that we can maintain the\nI, if you will, inside of the CIA triad.\n\n21\n00:00:55.610 --> 00:00:58.770\nRemember the CIA triad\nare the principles of security.\n\n22\n00:00:58.770 --> 00:01:02.790\nAnd that is the confidentiality,\nintegrity, and availability.\n\n23\n00:01:02.790 --> 00:01:07.080\nWe've kind of talked about confidentiality\nso far in the fact that we've mentioned\n\n24\n00:01:07.080 --> 00:01:10.200\nsome of those encryption algorithms\nthat Cherokee's already mentioned.\n\n25\n00:01:10.200 --> 00:01:15.100\nWe wanna remember that that is just making\nsure that only the authorized viewers\n\n26\n00:01:15.100 --> 00:01:17.840\nare the ones that can actually\nconsumer view the data.\n\n27\n00:01:17.840 --> 00:01:19.350\nAvailability.\n\n28\n00:01:19.350 --> 00:01:23.330\nAvailability is that the authorized users\nactually have access to that information.\n\n29\n00:01:23.330 --> 00:01:28.290\nBut now we're gonna take a turn, if you\nwill, into the integrity part of it.\n\n30\n00:01:28.290 --> 00:01:31.880\nWe're gonna talk about hashing functions.\n\n31\n00:01:31.880 --> 00:01:37.312\nNow, we kinda mentioned hashing functions\nand algorithms, if you will, before.\n\n32\n00:01:37.312 --> 00:01:42.490\nIt is a way to verify your file integrity\nand we use these in so many different ways\n\n33\n00:01:42.490 --> 00:01:47.460\nand they are really built into a lot\nof different technologies that we have.\n\n34\n00:01:47.460 --> 00:01:49.340\nSo, for instance, let's just take.\n\n35\n00:01:49.340 --> 00:01:53.480\nLet's take some basics, right,\nlet's take like our CRC32 value,\n\n36\n00:01:53.480 --> 00:01:55.990\nright, the cyclic redundancy check 32.\n\n37\n00:01:55.990 --> 00:01:58.430\nWell if you look at\nnetwork communications and\n\n38\n00:01:58.430 --> 00:02:00.600\nwe look at frames at the data link layer,\nright?\n\n39\n00:02:00.600 --> 00:02:01.680\nRemember the OSI model?\n\n40\n00:02:01.680 --> 00:02:05.500\nThat seven layer model and at layer\ntwo is where the switching happens?\n\n41\n00:02:05.500 --> 00:02:09.126\nAnd remember at the end of the frame\nwe have this little checksum and\n\n42\n00:02:09.126 --> 00:02:10.049\nwhat does it do?\n\n43\n00:02:10.049 --> 00:02:13.499\nIt's a hashing function that has\nbeen basically performed across\n\n44\n00:02:13.499 --> 00:02:14.430\nthe whole frame.\n\n45\n00:02:14.430 --> 00:02:17.982\nSo that if I send that frame\nover an ethernet based network,\n\n46\n00:02:17.982 --> 00:02:20.267\nlet's say to Cherokee's computer.\n\n47\n00:02:20.267 --> 00:02:23.712\nHer computer is gonna look at that frame,\nwhere actually it's the switch, honestly,\n\n48\n00:02:23.712 --> 00:02:26.930\nlet's be honest, cuz it's a store and\nforward method that we use today.\n\n49\n00:02:26.930 --> 00:02:28.780\nThe switch will store that information.\n\n50\n00:02:28.780 --> 00:02:31.830\nCheck that CRC32 checksum at the end.\n\n51\n00:02:31.830 --> 00:02:34.770\nMakes sure that the frame has\nmaintained its integrity and\n\n52\n00:02:34.770 --> 00:02:36.470\nsend them to the destination.\n\n53\n00:02:36.470 --> 00:02:39.700\nIt's the way we verify that\nour communications don't have\n\n54\n00:02:39.700 --> 00:02:41.480\ntransmission errors, right?\n\n55\n00:02:41.480 --> 00:02:43.310\nWe have checksums in things like, for\n\n56\n00:02:43.310 --> 00:02:46.030\ninstance, transmission control protocol,\nright?\n\n57\n00:02:46.030 --> 00:02:50.110\nTransmission control protocol is\na connection oriented service, and\n\n58\n00:02:50.110 --> 00:02:54.120\nif we send that information over the wire,\nand the checksum is inspected, and\n\n59\n00:02:54.120 --> 00:02:57.700\nit's not what the expected checksum is,\nit's considered bad, right?\n\n60\n00:02:57.700 --> 00:02:59.270\nAnd it is discarded.\n\n61\n00:02:59.270 --> 00:03:02.130\nAnd then, what does transmission\ncontrol protocol do, right?\n\n62\n00:03:02.130 --> 00:03:05.810\nWell, it's helping us get those packets\nacross the wire in a timely manner,\n\n63\n00:03:05.810 --> 00:03:10.780\ncalls back to the source and says, hey,\nthat was a bad packet of information, or\n\n64\n00:03:10.780 --> 00:03:12.010\na bad datagram, if you will.\n\n65\n00:03:12.010 --> 00:03:16.055\nBad Segment,\nre-send that packet again, right?\n\n66\n00:03:16.055 --> 00:03:20.975\nSo this isn't something that is\nreally just unique to security world,\n\n67\n00:03:20.975 --> 00:03:21.555\nif you will.\n\n68\n00:03:21.555 --> 00:03:25.105\nAgain it can be also about availability I\nguess if you talk about a connection or\n\n69\n00:03:25.105 --> 00:03:27.000\ninstant service and communications.\n\n70\n00:03:27.000 --> 00:03:30.490\nBut it is really about\nthe integrity of our information.\n\n71\n00:03:30.490 --> 00:03:34.220\nAnd they call out a few\ndifferent ones on the exam.\n\n72\n00:03:34.220 --> 00:03:38.420\nThere are all kinds of hashing\nalgorithms that have been out there.\n\n73\n00:03:38.420 --> 00:03:40.930\nSome of them we're not even\nreally talking about in here.\n\n74\n00:03:40.930 --> 00:03:45.130\nBut let's go ahead and\ntalk about two of the common families.\n\n75\n00:03:45.130 --> 00:03:46.450\nHashing algorithms, and\n\n76\n00:03:46.450 --> 00:03:48.910\nreally let's just kind of recap\nwhat the hashing function is doing.\n\n77\n00:03:48.910 --> 00:03:51.040\nI've got a little diagram here, right?\n\n78\n00:03:51.040 --> 00:03:55.950\nAnd if we've got a couple of people\nin an office and they want to verify\n\n79\n00:03:55.950 --> 00:03:59.620\nthat a file that they're sending has\nmaintained it's integrity right.\n\n80\n00:03:59.620 --> 00:04:03.520\nWe take that file and\nwe run it through a message digest right,\n\n81\n00:04:03.520 --> 00:04:06.830\na hashing algorithm and\nit produces a fixed link value.\n\n82\n00:04:06.830 --> 00:04:09.570\nThat fixed link value is\nattached to the document and\n\n83\n00:04:09.570 --> 00:04:12.420\nthe document is sent over the wire right.\n\n84\n00:04:12.420 --> 00:04:15.220\nWell when she receives that\ndocument what it she gonna do?\n\n85\n00:04:15.220 --> 00:04:20.720\nWell, she's gonna take her computer if you\nwill Is gonna take that same document.\n\n86\n00:04:20.720 --> 00:04:24.880\nIt's gonna say okay let\nme calculate a value.\n\n87\n00:04:24.880 --> 00:04:27.180\nI don't even care what the value is.\n\n88\n00:04:27.180 --> 00:04:29.780\nLet me find out what the value is.\n\n89\n00:04:29.780 --> 00:04:32.180\nSo, it's not biased, right?\n\n90\n00:04:32.180 --> 00:04:35.760\nAnd then I'm gonna take\nthe value that I found, right?\n\n91\n00:04:36.810 --> 00:04:41.820\nAnd what we'll do is if those\nvalues match that data is\n\n92\n00:04:41.820 --> 00:04:47.380\nconsidered to be as to maintain its\nintegrity, we process the information.\n\n93\n00:04:47.380 --> 00:04:52.480\nHowever if she calculates or her computer\nor whatever the program or technology,\n\n94\n00:04:52.480 --> 00:04:57.300\nbecause remember networks do this too,\ncalculates that value and\n\n95\n00:04:57.300 --> 00:05:00.710\nthe value that's attached\nto it doesn't match.\n\n96\n00:05:00.710 --> 00:05:03.670\nNow, we've got a problem,\nwe've got some kind of integrity,\n\n97\n00:05:03.670 --> 00:05:09.600\nwhen we have hash value mismatch,\nsomething has gone wrong with the data.\n\n98\n00:05:09.600 --> 00:05:11.990\nNow in the case of network communications,\n\n99\n00:05:11.990 --> 00:05:15.190\nit could be just a simple network\ntransmission error, right?\n\n100\n00:05:15.190 --> 00:05:21.460\nBut in the case of a manipulous,\nor malicious manipulation, right?\n\n101\n00:05:21.460 --> 00:05:25.390\nAn unauthorized access or\nmodifying of the data.\n\n102\n00:05:25.390 --> 00:05:28.550\nThis lets us know that\nsomething has changed, right?\n\n103\n00:05:28.550 --> 00:05:31.290\nAnd it can be a very simplistic change.\n\n104\n00:05:31.290 --> 00:05:35.090\nVery simplistic changes, can change\nthe entire value of the document.\n\n105\n00:05:35.090 --> 00:05:39.780\nSo for instance I've got a little Mac,\nthis is on my Mac here,\n\n106\n00:05:39.780 --> 00:05:40.650\ncalled Quick Cache.\n\n107\n00:05:40.650 --> 00:05:45.460\nAnd it's a real cool little program that\nyou can download and I believe it's free.\n\n108\n00:05:45.460 --> 00:05:46.760\nSo if you're out there and\nyou're studying and\n\n109\n00:05:46.760 --> 00:05:48.410\nyou want to kind of see how this works.\n\n110\n00:05:48.410 --> 00:05:50.640\nSo let's just take, what I'm gonna do.\n\n111\n00:05:50.640 --> 00:05:52.400\nIs we're just gonna do text hashing,\nright?\n\n112\n00:05:52.400 --> 00:05:53.760\nWe're just gonna do the text itself.\n\n113\n00:05:53.760 --> 00:05:57.513\nAnd I'm gonna say okay, this is my text.\n\n114\n00:05:57.513 --> 00:06:00.740\nAll right, and then I can pick, and\n\n115\n00:06:00.740 --> 00:06:03.600\nwe'll talk about some of these\nhashing algorithms here in a sec.\n\n116\n00:06:03.600 --> 00:06:05.870\nAnd I won't leave you\nguys in the dark on this.\n\n117\n00:06:05.870 --> 00:06:09.360\nBut we'll take one that we'll talk\nabout why you really shouldn't use it.\n\n118\n00:06:09.360 --> 00:06:11.110\nJust basic SHA-1, right?\n\n119\n00:06:11.110 --> 00:06:14.460\nAnd then what we do,\nis it calculates a value, right?\n\n120\n00:06:14.460 --> 00:06:17.210\nNotice that this is a fixed-length value.\n\n121\n00:06:17.210 --> 00:06:22.030\nNow, I also said one time, that it is,\nregardless of what data goes into it,\n\n122\n00:06:22.030 --> 00:06:24.740\nit always produces the same\nfixed length value.\n\n123\n00:06:24.740 --> 00:06:28.300\nMight not be identical value,\nbut it's the same fixed length.\n\n124\n00:06:28.300 --> 00:06:29.670\nLet me show you what I mean here.\n\n125\n00:06:29.670 --> 00:06:31.430\nNotice how much text is there?\n\n126\n00:06:31.430 --> 00:06:35.550\nIf I turn around and I add a whole\nbunch of other stuff to this.\n\n127\n00:06:35.550 --> 00:06:38.540\nNotice that the value\nlength didn't change.\n\n128\n00:06:38.540 --> 00:06:39.330\n&gt;&gt; It's pretty cool.\n\n129\n00:06:39.330 --> 00:06:43.940\nI mean, you can see that variable length\ninput but your fixed output there.\n\n130\n00:06:43.940 --> 00:06:44.720\n&gt;&gt; Absolutely.\n\n131\n00:06:44.720 --> 00:06:49.680\nSo this is a very good way,\nvery simplistic way that we can actually\n\n132\n00:06:51.130 --> 00:06:53.350\ncheck the integrity of a file, right?\n\n133\n00:06:53.350 --> 00:06:54.900\nSo if I do something like this.\n\n134\n00:06:54.900 --> 00:06:59.790\nWe say this is my text, all right.\n\n135\n00:06:59.790 --> 00:07:03.059\nNotice the value of it here and we're just\ngonna pay attention there is no way I\n\n136\n00:07:03.059 --> 00:07:05.977\nwould expect you guys to really\nremember that whole entire line, but\n\n137\n00:07:05.977 --> 00:07:08.930\nlet's just take the last four\nbits of that information.\n\n138\n00:07:08.930 --> 00:07:11.580\nWe're less four values notice.\n\n139\n00:07:11.580 --> 00:07:12.830\nD47B.\n\n140\n00:07:12.830 --> 00:07:17.160\nLook what happens when I\nadd a single blank space.\n\n141\n00:07:17.160 --> 00:07:18.230\nRight?\n\n142\n00:07:18.230 --> 00:07:21.440\nNotice the last four digits,\nit's not the same, right?\n\n143\n00:07:21.440 --> 00:07:24.240\nSo, a minor modification like that,\n\n144\n00:07:24.240 --> 00:07:28.940\na minor transmission error,\ncan completely change the value.\n\n145\n00:07:28.940 --> 00:07:34.020\nAnd back to the point when I was saying\nthat she is gonna check this value It can\n\n146\n00:07:34.020 --> 00:07:38.230\nbe as simple as a small\nvariation of the text.\n\n147\n00:07:38.230 --> 00:07:41.780\n&gt;&gt; Sure, we're expecting that\nparticular hash value to be unique.\n\n148\n00:07:41.780 --> 00:07:43.210\nThat's what it's for, right?\n\n149\n00:07:43.210 --> 00:07:44.270\n&gt;&gt; Absolutely.\n\n150\n00:07:44.270 --> 00:07:48.240\nNow here the problem that you\nrun in with these hash values.\n\n151\n00:07:48.240 --> 00:07:48.910\nAll right.\n\n152\n00:07:48.910 --> 00:07:51.260\nEven with CRC 32, so 32-bit value.\n\n153\n00:07:51.260 --> 00:07:52.800\nIt has many flaws.\n\n154\n00:07:52.800 --> 00:07:54.558\nThey can have flaws in them.\n\n155\n00:07:54.558 --> 00:07:59.490\nAnd one of the biggest flaws that they can\nhave is the fact that the text itself or\n\n156\n00:07:59.490 --> 00:08:03.629\nthat value We can do things like\nhashing collisions, all right?\n\n157\n00:08:03.629 --> 00:08:08.667\nIf I can find some kind of string of data,\nright?\n\n158\n00:08:08.667 --> 00:08:12.701\nWhether this is my text or not,\nthat produces that same value, and\n\n159\n00:08:12.701 --> 00:08:17.670\nI can modify the text and still produce\nthat same value, you'd be none the wiser,\n\n160\n00:08:17.670 --> 00:08:22.160\nthat because the hashing values match,\nthat the text has been modified.\n\n161\n00:08:22.160 --> 00:08:24.940\nThat's what we call hashing collisions,\nright?\n\n162\n00:08:24.940 --> 00:08:27.310\nSo for instance,\nyour passwords are hashed, and\n\n163\n00:08:27.310 --> 00:08:31.816\nthey're stored in a special\nspot within your computer.\n\n164\n00:08:31.816 --> 00:08:36.690\nLike for instance,\nyour password are hash and then\n\n165\n00:08:36.690 --> 00:08:40.120\nstored in what's known as a SAM file in\nWindows, it's part of the registry, right?\n\n166\n00:08:40.120 --> 00:08:40.650\nAnd then I use,\n\n167\n00:08:40.650 --> 00:08:45.120\nI believe the technology they use to\nencrypt it today is called Siskey, right.\n\n168\n00:08:45.120 --> 00:08:49.610\nSo it is an encrypted text, but\nunderstand that those hash values,\n\n169\n00:08:49.610 --> 00:08:54.220\nif i can find some kind of character\nstring that produces the same hash value.\n\n170\n00:08:54.220 --> 00:08:57.170\nWell, then I can present it to\nan authentication system and\n\n171\n00:08:57.170 --> 00:08:58.170\nI don't need your password.\n\n172\n00:08:58.170 --> 00:09:01.730\nI don't need the actual characters\nthat we see on the keyboard,\n\n173\n00:09:01.730 --> 00:09:06.460\nso that's why we try to use\nstronger hash functions.\n\n174\n00:09:06.460 --> 00:09:09.070\n&gt;&gt; And sometimes you even hear\nthe term salting the hash, and\n\n175\n00:09:09.070 --> 00:09:14.120\nthat simply means we are inserting\nrandom characters within that password\n\n176\n00:09:14.120 --> 00:09:18.850\nto kind of obfuscate further to prevent\nagainst like rainbow table attacks.\n\n177\n00:09:18.850 --> 00:09:19.640\n&gt;&gt; Most definitely and\n\n178\n00:09:19.640 --> 00:09:23.400\nthat's why in a lot of those encryption\nalgorithms we implement the you said salt.\n\n179\n00:09:23.400 --> 00:09:24.882\nIt's a form of padding, right?\n\n180\n00:09:24.882 --> 00:09:26.480\nPadding we do.\nInitialization vectors\n\n181\n00:09:26.480 --> 00:09:27.410\nare a form of padding.\n\n182\n00:09:27.410 --> 00:09:29.000\n&gt;&gt; Exactly.\n&gt;&gt; Because of the fact that you don't\n\n183\n00:09:29.000 --> 00:09:32.100\nwant, two identical pieces of plain text\n\n184\n00:09:32.100 --> 00:09:36.530\nare going to produce the same kind of\nif you're using identical algorithms.\n\n185\n00:09:36.530 --> 00:09:40.120\nBut if I use a varying padding or\na varying salt, or\n\n186\n00:09:40.120 --> 00:09:43.970\na nuance with a counter to that and\nit changes throughout,\n\n187\n00:09:43.970 --> 00:09:47.400\nthen what happens is the cypher\nchecks will always be unique.\n\n188\n00:09:47.400 --> 00:09:49.080\nAnd, essentially, that's what we want.\n\n189\n00:09:49.080 --> 00:09:50.290\nNow, let me go ahead and show you.\n\n190\n00:09:50.290 --> 00:09:54.390\nI've got kind of the family of hashing\nalgorithms that they talk about.\n\n191\n00:09:54.390 --> 00:09:57.120\nAnd I kind of want to mention\nthem each individually here.\n\n192\n00:09:57.120 --> 00:09:59.250\nSo let's go ahead and\ntake a look at my screen.\n\n193\n00:09:59.250 --> 00:10:02.780\nYou have an MD family and\nyou have SHA family.\n\n194\n00:10:02.780 --> 00:10:04.970\nMD is Message Digest.\n\n195\n00:10:04.970 --> 00:10:08.770\nAnd really, most of your message\ndigest should be avoided today.\n\n196\n00:10:08.770 --> 00:10:12.350\nFor instance, you can still see it coupled\ninside of things, like as a choice inside\n\n197\n00:10:12.350 --> 00:10:16.400\nof IPsec, cuz of all the other\nthings that are added to it, right?\n\n198\n00:10:16.400 --> 00:10:19.499\nLayered defense or\nlayered encryption, if you will.\n\n199\n00:10:19.499 --> 00:10:22.486\nBut we have MD2, 4, and 5.\n\n200\n00:10:22.486 --> 00:10:24.036\nMD5, believe it or not,\n\n201\n00:10:24.036 --> 00:10:28.940\nwhen we talked about the RC String Cypher,\nwe mentioned that was Ron Rives.\n\n202\n00:10:28.940 --> 00:10:32.036\nWell, Ron Rives is the one that\ninvented the Message Digest.\n\n203\n00:10:32.036 --> 00:10:34.812\nIt was introduced in 1992.\n\n204\n00:10:34.812 --> 00:10:39.314\nIt can be used for basic file integrity\nchecks, and basic check sums,\n\n205\n00:10:39.314 --> 00:10:42.790\nhowever keep in mind that\nit is very vulnerable.\n\n206\n00:10:42.790 --> 00:10:46.370\nSo I could if I wanted to,\nI could use an MD5.\n\n207\n00:10:46.370 --> 00:10:48.720\nright?\nIf you see, this is my text.\n\n208\n00:10:48.720 --> 00:10:51.590\nAnd I could just do basic\nfile verification with it.\n\n209\n00:10:51.590 --> 00:10:54.100\nBut the problem is, with the collisions,\n\n210\n00:10:54.100 --> 00:10:57.350\nit's not really something that I\nwould trust being used, all right?\n\n211\n00:10:58.380 --> 00:11:00.820\nAnd again, the earlier variance as well.\n\n212\n00:11:00.820 --> 00:11:02.700\nI just put them in here for\nsake of completion.\n\n213\n00:11:02.700 --> 00:11:05.510\nThere was a two, four, and five.\n\n214\n00:11:05.510 --> 00:11:10.600\nAgain, five has been compromised for\nfairly long time now.\n\n215\n00:11:10.600 --> 00:11:13.850\nWhich lends itself to the SHA family,\nall right?\n\n216\n00:11:13.850 --> 00:11:15.780\nNow what are we talking about\nwhen we say SHA family?\n\n217\n00:11:15.780 --> 00:11:18.180\nWe're talking about\nthe Secure Hashing Algorithm.\n\n218\n00:11:18.180 --> 00:11:21.280\nAnd the Secure Hashing Algorithm's\nactually been around for a while, and\n\n219\n00:11:21.280 --> 00:11:25.090\nit was one of those things that kind\nof sought to replace, if you will,\n\n220\n00:11:25.090 --> 00:11:27.830\nMD5 but there's a problem.\n\n221\n00:11:27.830 --> 00:11:29.902\nThe very first SHA that came out,\n\n222\n00:11:29.902 --> 00:11:35.159\nI could probably be correct by going SHA-0\nhere even though it's just called SHA.\n\n223\n00:11:35.159 --> 00:11:40.086\nThat was actually a retronaming,\nbecause of the fact that when they came\n\n224\n00:11:40.086 --> 00:11:44.144\nout with SHA 1,\nthey decided to call this SHA-0, okay.\n\n225\n00:11:44.144 --> 00:11:50.391\nSHA-0 was introduced and\nalmost immediately withdrawn, all right?\n\n226\n00:11:50.391 --> 00:11:53.070\nAnd that's because they had some\nvulnerabilities that they said,\n\n227\n00:11:53.070 --> 00:11:54.250\njust no don't implement it.\n\n228\n00:11:54.250 --> 00:11:58.660\nSo SHA by itself, SHA-0,\nwhatever you would call it.\n\n229\n00:11:58.660 --> 00:12:01.250\nYou could hear both, should never be used.\n\n230\n00:12:01.250 --> 00:12:03.760\nIn fact, it wasn't even implemented.\n\n231\n00:12:03.760 --> 00:12:05.790\nThen we get into SHA1, all right?\n\n232\n00:12:05.790 --> 00:12:09.330\nAnd SHA1, it was around for a little bit.\n\n233\n00:12:09.330 --> 00:12:13.560\nIt's 160 bits in hash value.\n\n234\n00:12:13.560 --> 00:12:15.940\nBut it also has problems, right?\n\n235\n00:12:15.940 --> 00:12:19.360\nAgain, it's susceptible to\ncollision attacks as well.\n\n236\n00:12:19.360 --> 00:12:21.510\nSo, we really shouldn't be using it.\n\n237\n00:12:21.510 --> 00:12:27.970\nSHA2, now SHA2 is actually\na family the internet itself\n\n238\n00:12:29.470 --> 00:12:33.660\nof hashing algorithm if you will, because\nthey were different bit lengths and\n\n239\n00:12:33.660 --> 00:12:36.580\nthey couple this with all\ndifferent type of bit length.\n\n240\n00:12:36.580 --> 00:12:38.130\nSo I'm just gonna mention\na couple of them here,\n\n241\n00:12:38.130 --> 00:12:41.140\nbecause there's actually\nsix of them in total.\n\n242\n00:12:41.140 --> 00:12:42.500\nI mentioned four of them here.\n\n243\n00:12:42.500 --> 00:12:47.450\nJust so you know the bit lays go to 224,\n256, 384, and 512.\n\n244\n00:12:47.450 --> 00:12:50.920\nThey do have some variance that\nare like for instance 224,\n\n245\n00:12:50.920 --> 00:12:54.730\n512 implementation, I wouldn't\nworry about those for the exam, but\n\n246\n00:12:54.730 --> 00:12:58.410\nyou can see the bit lengths a lot larger,\nright?\n\n247\n00:12:58.410 --> 00:13:03.270\nMeaning that our output of our values\nis gonna be a much greater strength and\n\n248\n00:13:03.270 --> 00:13:04.591\nlonger if you will.\n\n249\n00:13:04.591 --> 00:13:07.501\nSHA 3,\nit's not even called out by the exam.\n\n250\n00:13:07.501 --> 00:13:10.094\nI just wanted to put up here for\nthe sake of completeness,\n\n251\n00:13:10.094 --> 00:13:13.615\nit's not something you should see on\nthe exam because it does differ enough.\n\n252\n00:13:13.615 --> 00:13:17.055\nIt still uses the same character lengths,\nbut it does differ enough that it's\n\n253\n00:13:17.055 --> 00:13:20.205\nslightly different than the overall\nSecure Hashing Algorithm.\n\n254\n00:13:21.512 --> 00:13:24.342\nThe one that you're really gonna see\nimplemented more than anything today is\n\n255\n00:13:24.342 --> 00:13:26.982\ngonna be SHA2 and some variant of it.\n\n256\n00:13:26.982 --> 00:13:31.791\nKeep in mind that 226 is where it starts,\nversus 160 where the old SHA was.\n\n257\n00:13:31.791 --> 00:13:37.332\nYou might even see them\ncalled SHA 128 SHA 224,\n\n258\n00:13:37.332 --> 00:13:41.038\nSHA 256, 384, SHA 512.\n\n259\n00:13:41.038 --> 00:13:45.833\nAnd again, that's actually a good naming\nconvention, because with MD2, 4, and 5,\n\n260\n00:13:45.833 --> 00:13:47.990\nI can't tell you what the bit length is.\n\n261\n00:13:47.990 --> 00:13:51.390\nI think MD5 was,\nI wanna say it was 128 bit.\n\n262\n00:13:51.390 --> 00:13:52.780\nI might be a little bit off on that one.\n\n263\n00:13:52.780 --> 00:13:56.154\nBut at least with some of the some\nof the SHA names you can find out\n\n264\n00:13:56.154 --> 00:13:58.390\nthat the bit length, was it 128 bits?\n\n265\n00:13:58.390 --> 00:14:00.471\nYeah, I couldn't remember\nthere was was 56 or\n\n266\n00:14:00.471 --> 00:14:03.636\nthere was 128 couple the other old\nones I think they were like 56 bit.\n\n267\n00:14:03.636 --> 00:14:06.364\nBut, so let's see, all right?\n\n268\n00:14:06.364 --> 00:14:07.573\nLet me give you an example, all right?\n\n269\n00:14:07.573 --> 00:14:10.634\nSo let's look at the MD family, all right?\n\n270\n00:14:10.634 --> 00:14:14.888\nSo I took this message without the quotes,\nright?\n\n271\n00:14:14.888 --> 00:14:18.050\nI just got it in quotes, so\nyou can see it's the text, right?\n\n272\n00:14:18.050 --> 00:14:22.050\nThis is me and\nI did exactly what you just saw us do,\n\n273\n00:14:22.050 --> 00:14:24.638\nwe did a text hash on it, right?\n\n274\n00:14:24.638 --> 00:14:27.732\nWell, you will notice MD2, MD4, and\n\n275\n00:14:27.732 --> 00:14:32.102\nMD5, they really don't look\nmuch different, right?\n\n276\n00:14:32.102 --> 00:14:35.980\n&gt;&gt; Yeah, you can see that fixed output\nthere if you're just looking at that\n\n277\n00:14:35.980 --> 00:14:40.001\nfixed value, I wouldn't be able to\ndiscern the difference between them.\n\n278\n00:14:40.001 --> 00:14:41.126\n&gt;&gt; And I've done it a couple of times.\n\n279\n00:14:41.126 --> 00:14:42.243\n&gt;&gt; [LAUGH]\n&gt;&gt; And I was like, wow,\n\n280\n00:14:42.243 --> 00:14:43.270\nthat's interesting.\n\n281\n00:14:43.270 --> 00:14:44.280\nIt didn't change much.\n\n282\n00:14:44.280 --> 00:14:45.540\nSo what is the problem here?\n\n283\n00:14:45.540 --> 00:14:48.460\nThe problem is some of\nthe things that we don't see.\n\n284\n00:14:48.460 --> 00:14:51.140\nAnd that's some of the stuff that\nthey don't really want you to\n\n285\n00:14:51.140 --> 00:14:54.470\nknow the inner workings, like Cherokee's\nmentioned that quite a few times now.\n\n286\n00:14:54.470 --> 00:14:58.240\nThey just want you to understand that\nunder the hood, doesn't matter the bit\n\n287\n00:14:58.240 --> 00:15:01.494\nlength, there's other things that\nthis is very susceptible to.\n\n288\n00:15:01.494 --> 00:15:08.541\nNow, I want you to see what happens when\nwe change this to SHA 160, all right.\n\n289\n00:15:08.541 --> 00:15:10.398\nDid I say SHA 160?\n&gt;&gt; So we're talking the same input-\n\n290\n00:15:10.398 --> 00:15:10.950\n&gt;&gt; That's right.\n\n291\n00:15:10.950 --> 00:15:14.281\n&gt;&gt; Now you're going to see a different\nfixed output depending on our hashing\n\n292\n00:15:14.281 --> 00:15:15.170\nalgorithm.\n\n293\n00:15:15.170 --> 00:15:15.880\n&gt;&gt; Most definitely.\n\n294\n00:15:15.880 --> 00:15:19.260\nSo just like Cherokee said, this is\nme went into the hashing algorithm,\n\n295\n00:15:19.260 --> 00:15:22.220\nthe output is a little bit stronger.\n\n296\n00:15:22.220 --> 00:15:26.355\nHowever, this has a proof\nof concept If you will,\n\n297\n00:15:26.355 --> 00:15:32.165\nthat basically it is susceptible\nto collision attacks.\n\n298\n00:15:32.165 --> 00:15:34.075\nBut here's one that I\nreally want you to see.\n\n299\n00:15:34.075 --> 00:15:35.915\nThis is one that I really like.\n\n300\n00:15:35.915 --> 00:15:37.875\nMy head's kind of covering\nit up a little bit.\n\n301\n00:15:37.875 --> 00:15:46.020\nBut notice the difference in length\nbetween 160 bit and 256 bits.\n\n302\n00:15:46.020 --> 00:15:49.254\n&gt;&gt; That just looks like more work for\nthe attacker to go down that list.\n\n303\n00:15:49.254 --> 00:15:52.279\n&gt;&gt; Absolutely, so\nif I have a lot more randomness than this,\n\n304\n00:15:52.279 --> 00:15:56.541\nit's gonna take a lot more guessing on the\nkeyboard even if it is automated through\n\n305\n00:15:56.541 --> 00:15:59.843\nsoftware like rainbow tables to\nperform a hashing collision.\n\n306\n00:15:59.843 --> 00:16:02.529\nBecause that value in length is so great.\n\n307\n00:16:02.529 --> 00:16:03.988\nIf you will.\n\n308\n00:16:03.988 --> 00:16:06.927\nBut now, let's go even farther than that,\nall right.\n\n309\n00:16:06.927 --> 00:16:10.998\nLet's go ahead and I can't even get this,\nI don't know if I can get this all on\n\n310\n00:16:10.998 --> 00:16:14.410\nthe screen here without\nreducing the size a little bit.\n\n311\n00:16:14.410 --> 00:16:18.380\nNotice the difference even then\nfrom bumping up from 256 to 384.\n\n312\n00:16:18.380 --> 00:16:25.556\nNow the hash value gets even\nfarther in length than that.\n\n313\n00:16:25.556 --> 00:16:29.890\nAnd last but not the least,\nin this one's kinda interesting is 512.\n\n314\n00:16:29.890 --> 00:16:35.510\nLook at 512 compared to\nwhere we went from in 160.\n\n315\n00:16:35.510 --> 00:16:41.740\n160 bits down to 512 bits.\n\n316\n00:16:41.740 --> 00:16:44.420\nYou can see there is a lot of difference.\n\n317\n00:16:44.420 --> 00:16:48.206\nLet me also show you for instance,\nlet me switch over to my Linux box here.\n\n318\n00:16:48.206 --> 00:16:53.600\nBecause they've got some shasum utilities\nin there that kind of show this too.\n\n319\n00:16:53.600 --> 00:16:56.310\nSo let me go ahead and get logged into my\n\n320\n00:16:56.310 --> 00:17:00.020\nmachine here because you guys need\nto see how bad I type a password.\n\n321\n00:17:00.020 --> 00:17:02.229\nAll right, we'll clear this up,\nand we're gonna do a sha1sum.\n\n322\n00:17:02.229 --> 00:17:04.990\nAnd you know what?\n\n323\n00:17:04.990 --> 00:17:06.910\nWhere am I?\n\n324\n00:17:06.910 --> 00:17:08.230\nI am right here.\n\n325\n00:17:08.230 --> 00:17:09.370\nOkay, I got a file here.\n\n326\n00:17:09.370 --> 00:17:12.570\nSo, you can see that,\nI got a file in here.\n\n327\n00:17:12.570 --> 00:17:15.040\nIt's called File1.txt, right?\n\n328\n00:17:15.040 --> 00:17:18.713\nAnd if I run shaw1sum and\nI do my file here,\n\n329\n00:17:18.713 --> 00:17:22.740\nyou'll see the value\nthat it kinda produces.\n\n330\n00:17:22.740 --> 00:17:24.770\nNotice the length of the value there.\n\n331\n00:17:24.770 --> 00:17:30.670\nNow watch what happens when I\ngo from 160 bits to 256 bits.\n\n332\n00:17:30.670 --> 00:17:34.056\nSo for instance, if I do that same thing,\nbut now I do shawsum.\n\n333\n00:17:34.056 --> 00:17:39.516\nNo excuse me, sha256sum,\nand I do that same file,\n\n334\n00:17:39.516 --> 00:17:43.400\nnotice the difference in length.\n\n335\n00:17:43.400 --> 00:17:50.530\nYou can see that there's a lot stronger in\nthe bit length overall it's a lot larger.\n\n336\n00:17:50.530 --> 00:17:53.587\nAnd that lends itself to being\na little bit more complex,\n\n337\n00:17:53.587 --> 00:17:57.358\nbeing a little bit harder, if you will,\nactually a lot of bit harder.\n\n338\n00:17:57.358 --> 00:18:01.940\nTo do those kinda hashing\ncollision attacks.\n\n339\n00:18:01.940 --> 00:18:06.390\nSo those are some of the things\nthat I want you to keep in mind\n\n340\n00:18:06.390 --> 00:18:08.820\nwhen it comes to the hashing algorithms.\n\n341\n00:18:08.820 --> 00:18:13.430\nThere are some other ones that I want you\nto keep in mind too, and that is RIPEMD.\n\n342\n00:18:13.430 --> 00:18:18.190\n&gt;&gt; And that one, that's a crazy acronym.\n\n343\n00:18:18.190 --> 00:18:22.170\nIt's like an acronym inside an acronym,\nyou've got race.\n\n344\n00:18:22.170 --> 00:18:26.460\n&gt;&gt; They call that a recursive acronym,\nlike GNU public licensing,\n\n345\n00:18:26.460 --> 00:18:29.960\nthey call the GPL but\nit stands for GNU public license.\n\n346\n00:18:29.960 --> 00:18:35.340\nIt is race integrity primitives\nevaluation message digest.\n\n347\n00:18:35.340 --> 00:18:41.720\nIt's a very long one and it comes in a few\ndifferent flavors, if you will, or sizes.\n\n348\n00:18:41.720 --> 00:18:45.390\nAnd it comes in a 128 variant.\n\n349\n00:18:45.390 --> 00:18:51.670\nThe 128 variant should be completely just\navoided because like Message Digest 5,\n\n350\n00:18:51.670 --> 00:18:57.110\nit does have the possibility for\ncollisions.\n\n351\n00:18:58.920 --> 00:19:01.150\nThe other one, too,\nyou do want to mention.\n\n352\n00:19:01.150 --> 00:19:02.850\nWe had somebody mention in the chat room,\nand\n\n353\n00:19:02.850 --> 00:19:04.920\nI do want to kind of step back with SHA-1.\n\n354\n00:19:04.920 --> 00:19:07.505\nBecause they mentioned that it\nis theoretically possible for\n\n355\n00:19:07.505 --> 00:19:09.580\nSHA-1 to have hashing collisions.\n\n356\n00:19:09.580 --> 00:19:13.100\nThat's why we say you should use 256 and\nabove.\n\n357\n00:19:13.100 --> 00:19:16.030\nI believe it was Google that did\nthe proof of concept that they were\n\n358\n00:19:16.030 --> 00:19:18.270\nable to perform once.\n\n359\n00:19:18.270 --> 00:19:20.890\nA hashing collision on SHA-160.\n\n360\n00:19:20.890 --> 00:19:22.970\nI think it was Google that did that.\n\n361\n00:19:22.970 --> 00:19:25.970\nBut, so understand that it's\ntechnically been compromised.\n\n362\n00:19:25.970 --> 00:19:29.135\nAnd that's why I said SHA-2,\nif I remember right,\n\n363\n00:19:29.135 --> 00:19:31.800\nSHA-2 is what I said is most\nlikely gonna be implemented.\n\n364\n00:19:31.800 --> 00:19:35.910\nAnd really, some of the higher bit links\nare what you should be implementing.\n\n365\n00:19:35.910 --> 00:19:39.020\nSo great participation out\nthere in the chat room.\n\n366\n00:19:39.020 --> 00:19:42.970\nAgain, remember, with RIPEMD,\none of the most common ones is the 160.\n\n367\n00:19:42.970 --> 00:19:46.870\nBut there, again, any time you talk\nabout 160, you run into the fact that.\n\n368\n00:19:46.870 --> 00:19:50.820\nIt could be theoretically possible\nto do a collision attack against it.\n\n369\n00:19:50.820 --> 00:19:55.330\nThey do have a 256 and, I believe,\nanother one of 320 as well.\n\n370\n00:19:55.330 --> 00:19:59.670\nAll right, so that is some of\nyour hashing algorithms, and\n\n371\n00:19:59.670 --> 00:20:03.170\nwe want you to be aware\nof them on the exam.\n\n372\n00:20:03.170 --> 00:20:06.180\nKeep in mind that they're\nabout the file integrity.\n\n373\n00:20:06.180 --> 00:20:08.010\nStay away from Message Digest 5.\n\n374\n00:20:08.010 --> 00:20:12.410\nIf you're using them, today you\nshould be using the SHA-2 family.\n\n375\n00:20:12.410 --> 00:20:17.680\nKeep in mind that the SHA-2 family starts\nat 224, goes all the way up to 512.\n\n376\n00:20:17.680 --> 00:20:22.290\nSHA-3, like I said, I put it out there\nit's essentially different enough\n\n377\n00:20:22.290 --> 00:20:27.040\nthat it's really different than the whole\nsecure hashing algorithm family.\n\n378\n00:20:27.040 --> 00:20:29.720\nSo I don't expect to see\nthat one on the test.\n\n379\n00:20:29.720 --> 00:20:32.630\nThe last one that they kind of call out.\n\n380\n00:20:32.630 --> 00:20:35.840\nWhen it comes to hashing algorithms,\n\n381\n00:20:35.840 --> 00:20:38.550\nwe have what is known as\na message authentication code.\n\n382\n00:20:38.550 --> 00:20:41.800\nAnd message authentication codes are kind\nof sent across the wire, if you will.\n\n383\n00:20:41.800 --> 00:20:45.179\nKind of like our are, if you will.\n\n384\n00:20:45.179 --> 00:20:49.130\nAnd, there are some weaknesses\nwith message authentication code.\n\n385\n00:20:49.130 --> 00:20:53.780\nAnd essentially what a hashed or\nhashing message authentication code is,\n\n386\n00:20:53.780 --> 00:20:56.890\nis what it does it takes\nthe regular mark and\n\n387\n00:20:56.890 --> 00:21:00.120\nit adds a hashing function\ncombined with the secret key.\n\n388\n00:21:00.120 --> 00:21:03.490\nIf you will and then hashes both of those.\n\n389\n00:21:03.490 --> 00:21:07.820\nSo it takes if you will,\nthe message the secret key and\n\n390\n00:21:07.820 --> 00:21:13.160\nthen hashes all of that and that becomes\nthe hashed message authentication code.\n\n391\n00:21:13.160 --> 00:21:15.930\nYou can see variance of this as well.\n\n392\n00:21:15.930 --> 00:21:18.130\nYou could see it inside\nof things like IPsec.\n\n393\n00:21:18.130 --> 00:21:20.100\nI know you can find it in there, as well.\n\n394\n00:21:20.100 --> 00:21:23.433\nYou can find things like HMAC-MD5,\nHMAC-SHA-1,\n\n395\n00:21:23.433 --> 00:21:27.380\nHMAC-SHA-2, so\nyou do see variance, as well.\n\n396\n00:21:27.380 --> 00:21:30.770\nKeep in mind those different\nhashing algorithms.\n\n397\n00:21:32.060 --> 00:21:33.600\nAll right-\n&gt;&gt; So Wes is there anything else that\n\n398\n00:21:33.600 --> 00:21:37.920\nwe can do to really obfuscate or make it a\nlittle more difficult for those attackers?\n\n399\n00:21:37.920 --> 00:21:42.830\n&gt;&gt; Very good, so imagine an instance\nwhere we're actually storing passwords.\n\n400\n00:21:42.830 --> 00:21:46.390\nWe had some people,\nour viewers in the chat room, talk about,\n\n401\n00:21:46.390 --> 00:21:50.860\nwell if I'm storing the password and\nit's just a hash value.\n\n402\n00:21:50.860 --> 00:21:53.080\nCouldn't I just present the hash\nvalue to the system and\n\n403\n00:21:53.080 --> 00:21:54.460\nit would be just like the password?\n\n404\n00:21:54.460 --> 00:21:55.520\n&gt;&gt; Well yes, yes you can.\n\n405\n00:21:55.520 --> 00:21:57.750\n[LAUGH]\n&gt;&gt; You're absolutely correct, yes you can.\n\n406\n00:21:57.750 --> 00:22:02.825\nAnd that's what a hashing collision attack\nis Cherokee mentioned rainbow table,\n\n407\n00:22:02.825 --> 00:22:05.625\ntrying to get that\nhashing collision right.\n\n408\n00:22:05.625 --> 00:22:07.405\nThat's essentially what they're doing.\n\n409\n00:22:07.405 --> 00:22:09.975\nBecause if I know what your hash\nvalue is I can present that to,\n\n410\n00:22:09.975 --> 00:22:13.985\nI don't need to know the password or a\npass phrase to the authenticating system.\n\n411\n00:22:13.985 --> 00:22:19.152\nSo imagine the ability to take\nthat hash value as it sits and\n\n412\n00:22:19.152 --> 00:22:23.378\nadd some randomness,\nadd some strength to it.\n\n413\n00:22:23.378 --> 00:22:26.040\nAnd that's what is known\nas key stretching.\n\n414\n00:22:26.040 --> 00:22:31.460\nKey stretching essentially takes your weak\npasswords, or your weak keys if you will.\n\n415\n00:22:31.460 --> 00:22:35.930\nAnd increases the difficulty it\ntakes to attack that hash value or\n\n416\n00:22:35.930 --> 00:22:39.200\nessentially the key or password.\n\n417\n00:22:39.200 --> 00:22:42.930\nAnd what happens is the key is fed\ninto the algorithm if you will,\n\n418\n00:22:42.930 --> 00:22:45.810\nthat just basically produces and\nenhanced key.\n\n419\n00:22:45.810 --> 00:22:50.324\nSome of the examples of this, we had\na great mention already in the chat room,\n\n420\n00:22:50.324 --> 00:22:54.915\nso if you guys are with us out there,\nsomebody mentioned earlier the PBKDF2.\n\n421\n00:22:54.915 --> 00:23:00.460\nAnd this adds assault with a minimum\nof 64 bits and hashes the password.\n\n422\n00:23:00.460 --> 00:23:03.120\nAgain, to produce a stronger hash value.\n\n423\n00:23:04.280 --> 00:23:08.080\nThis is used commonly\nin things like WPA 2,\n\n424\n00:23:08.080 --> 00:23:12.920\nApple's iOS performs this,\nyour CISCO devices do this as well.\n\n425\n00:23:12.920 --> 00:23:17.521\nYou also have one inside of the based\nsystems, Unix, Linux, if you will.\n\n426\n00:23:17.521 --> 00:23:21.880\nAnd their files are stored in kind of\nlike a shadow file, the password are,\n\n427\n00:23:21.880 --> 00:23:23.290\nthe password hashes are.\n\n428\n00:23:23.290 --> 00:23:25.830\nAnd they use a technology called bcrypt.\n\n429\n00:23:25.830 --> 00:23:29.430\nAnd bcrypt, if you will,\nis basically a password hashing function.\n\n430\n00:23:29.430 --> 00:23:31.170\nAnd again, it salts the password.\n\n431\n00:23:31.170 --> 00:23:35.170\nCherokee's already mentioned salt, right,\nadds a few extra bits if you will, and\n\n432\n00:23:35.170 --> 00:23:37.750\nthen turns around and\nencrypts it with Blowfish.\n\n433\n00:23:38.870 --> 00:23:39.970\nPretty cool?\n\n434\n00:23:39.970 --> 00:23:44.415\nSo it really does strengthen\nthe password itself.\n\n435\n00:23:44.415 --> 00:23:48.149\nSo that's what they call key stretching-\n&gt;&gt; Adding those layers of complexity.\n\n436\n00:23:48.149 --> 00:23:51.128\n&gt;&gt; Most definitely, cuz remember,\nthe more complexity and\n\n437\n00:23:51.128 --> 00:23:54.774\nrandomness we get, the harder it is\nto try to reverse engineer whatever\n\n438\n00:23:54.774 --> 00:23:56.990\nthe technology is that we're looking at.\n\n439\n00:23:58.080 --> 00:24:01.110\nAll right,\nthey call out a couple of things, too.\n\n440\n00:24:01.110 --> 00:24:05.711\nThey call out some obfuscation techniques\nand I actually said that right.\n\n441\n00:24:05.711 --> 00:24:09.272\nIt's only taken me about ten\nepisodes to get that right.\n\n442\n00:24:09.272 --> 00:24:11.456\nAnd this isn't really about,\n\n443\n00:24:11.456 --> 00:24:16.580\nagain it's more about masking the data\nthan it is really encrypting it.\n\n444\n00:24:16.580 --> 00:24:19.516\nKeep in mind that happens with\nnetwork address translation.\n\n445\n00:24:19.516 --> 00:24:22.689\nA lot of people think it's a security\nimplementation that hides your internal\n\n446\n00:24:22.689 --> 00:24:23.760\narchitecture.\n\n447\n00:24:23.760 --> 00:24:28.110\nIP addressing scheme and technically,\nit just obfuscates it, right?\n\n448\n00:24:28.110 --> 00:24:29.315\nThere's still a layer there,\nthat we could pull back.\n\n449\n00:24:29.315 --> 00:24:33.343\n&gt;&gt; I like to call those security\nenhancements or security features.\n\n450\n00:24:33.343 --> 00:24:34.678\n&gt;&gt; That's right, yes, exactly.\n\n451\n00:24:34.678 --> 00:24:37.019\n[LAUGH]\n&gt;&gt; [LAUGH] That is a non-technical term.\n\n452\n00:24:37.019 --> 00:24:38.684\nThat is a Cherokee term, FYI.\n\n453\n00:24:38.684 --> 00:24:43.382\n[LAUGH]\n&gt;&gt; There are some combinations of this.\n\n454\n00:24:43.382 --> 00:24:46.711\nThere's x ooling is an example of one.\n\n455\n00:24:46.711 --> 00:24:50.130\nOther examples are things like\nsubstitution ciphers as well.\n\n456\n00:24:50.130 --> 00:24:55.583\nWhen we talk about a substitution\ncipher they call out things like rot13.\n\n457\n00:24:55.583 --> 00:24:59.416\nAnd let me show you an example of\nsomething like, for instances,\n\n458\n00:24:59.416 --> 00:25:00.790\nlike a rot13.\n\n459\n00:25:00.790 --> 00:25:05.290\nI have a website up here\nthat I like to go to a lot.\n\n460\n00:25:05.290 --> 00:25:07.676\nAnd what it does it I want\nyou to think of rot13,\n\n461\n00:25:07.676 --> 00:25:11.460\nin fact let me kinda go back to my diagram\nhere and don't worry about the blue,\n\n462\n00:25:11.460 --> 00:25:14.633\nwe're gonna talk about substitution\nciphers in a second here.\n\n463\n00:25:14.633 --> 00:25:19.560\nBut imagine if we're talking about in\nfact let me, I'll just leave it this way.\n\n464\n00:25:19.560 --> 00:25:23.020\nKeep in mind that we have our alphabet,\nright and if I say rot13,\n\n465\n00:25:23.020 --> 00:25:28.150\nthen what I mean is whatever\nletter you have in plain text.\n\n466\n00:25:28.150 --> 00:25:31.830\nThe 13th letter after that is\ngonna substitute it, right.\n\n467\n00:25:31.830 --> 00:25:35.927\nAnd then the next letter in whatever\nyour message is, we're gonna rotate 13.\n\n468\n00:25:35.927 --> 00:25:40.021\nSo if we did something like a rot 3,\nright, and the letter was an A, and\n\n469\n00:25:40.021 --> 00:25:41.860\nwe rotate three.\n\n470\n00:25:41.860 --> 00:25:45.410\nOne, two, three and A becomes a D Right?\n\n471\n00:25:45.410 --> 00:25:48.115\nOr in this aspect,\nlet's say that if we do rot 13 and\n\n472\n00:25:48.115 --> 00:25:51.318\nlet's say we're gonna use\nsomething like Cherokee's name.\n\n473\n00:25:51.318 --> 00:25:53.570\nAll right, I'll put Cherokee\non the spot here, all right?\n\n474\n00:25:53.570 --> 00:25:56.130\nAnd we use Cherokee's name all right?\n\n475\n00:25:56.130 --> 00:25:59.854\nWell if we do a right 13,\nher name in plain text right?\n\n476\n00:25:59.854 --> 00:26:02.950\nStarts with a C,\nwe go 13 letters up right?\n\n477\n00:26:02.950 --> 00:26:07.620\nRot 13, that means the next letter\nis gonna be the letter P right?\n\n478\n00:26:07.620 --> 00:26:10.913\nAnd then the next letter\nof her name is a H, and\n\n479\n00:26:10.913 --> 00:26:14.743\nif we do 13 letters up on\nthe letter H it becomes a K.\n\n480\n00:26:14.743 --> 00:26:17.959\nSo again, understand, we're not\nactually encrypting the information,\n\n481\n00:26:17.959 --> 00:26:20.470\nwe're just kinda hiding it a little bit,\nif you will.\n\n482\n00:26:20.470 --> 00:26:22.310\n&gt;&gt; And it's really cool how people even,\n\n483\n00:26:22.310 --> 00:26:26.158\nif you think about humans in general, and\nthen trying to conceal their messages,\n\n484\n00:26:26.158 --> 00:26:28.416\nthey came up with these\nsubstitution methods.\n\n485\n00:26:28.416 --> 00:26:32.686\nWhere we even see like transposition,\nwhere you're swapping the letters out So\n\n486\n00:26:32.686 --> 00:26:35.574\nthat there are different\ntechniques that one can use,\n\n487\n00:26:35.574 --> 00:26:38.589\nto really obfuscate their information,\nand actually,\n\n488\n00:26:38.589 --> 00:26:42.294\nsomeone in the chat here just posted\nsecurity through obscurity, and\n\n489\n00:26:42.294 --> 00:26:46.550\nthat's the technical term that I was\njust joking about a few minutes ago.\n\n490\n00:26:46.550 --> 00:26:49.975\n&gt;&gt; Yeah, and that's what Don,\none of our other hosts here, talks about,\n\n491\n00:26:49.975 --> 00:26:52.408\nwhen he talks about network\naddress translation.\n\n492\n00:26:52.408 --> 00:26:55.214\nThat's exactly what he said there\nis security through obscurity,\n\n493\n00:26:55.214 --> 00:26:58.658\nyou're not really hiding anything, because\nagain people have the technical know\n\n494\n00:26:58.658 --> 00:27:01.330\nhow could definitely find what\nit is that they're looking for.\n\n495\n00:27:01.330 --> 00:27:04.918\nSo again, keep in mind this is not a\nmethod that you wanna send top secret data\n\n496\n00:27:04.918 --> 00:27:06.504\nover a public wire with, right?\n\n497\n00:27:06.504 --> 00:27:07.890\nThat's not what we're saying here.\n\n498\n00:27:07.890 --> 00:27:09.890\nLet me give you an example\nhere too at rot13 and\n\n499\n00:27:09.890 --> 00:27:11.042\nI can make it a little bit easier.\n\n500\n00:27:11.042 --> 00:27:13.324\nI'm gonna go ahead and\npick on Cherokee here again.\n\n501\n00:27:13.324 --> 00:27:14.720\n&gt;&gt; [LAUGH]\n&gt;&gt; All right.\n\n502\n00:27:14.720 --> 00:27:19.263\nAnd if I do a rot13 you can start\nto see what we were talking about.\n\n503\n00:27:19.263 --> 00:27:20.810\nAnd I meant it a little bit different.\n\n504\n00:27:20.810 --> 00:27:23.750\nWhat I was talking about in F,\nK, and H, that's actually rot3.\n\n505\n00:27:23.750 --> 00:27:25.800\nSo that kinda gives us\nthe basic principle.\n\n506\n00:27:25.800 --> 00:27:27.263\nAnd I love this website,\ncuz I can change it.\n\n507\n00:27:27.263 --> 00:27:30.017\nAnd you can see if we rotate-\n&gt;&gt; So that's the cipher text?\n\n508\n00:27:30.017 --> 00:27:35.069\n&gt;&gt; That's right, exactly so the ROT here\nis the obfuscation and then the cypher\n\n509\n00:27:35.069 --> 00:27:40.683\ntech output becomes, after we have rotated\n13, in this case we're doing a ROT3.\n\n510\n00:27:40.683 --> 00:27:44.108\nLet me go back to ROT13 because that's\nwhat they are calling out on the exam.\n\n511\n00:27:44.108 --> 00:27:47.199\nIf you take Cherokee's name and\n\n512\n00:27:47.199 --> 00:27:53.170\nyou run it through a ROT13 it\nbecomes PUREBXRR, all right.\n\n513\n00:27:53.170 --> 00:27:54.980\nAnd what's kinda interesting\nif you think about it.\n\n514\n00:27:56.110 --> 00:28:01.140\nThere's 26 letters in\nthe English alphabet and\n\n515\n00:28:01.140 --> 00:28:06.690\nif I take what has been rotated\n13 times and I copy that.\n\n516\n00:28:06.690 --> 00:28:11.020\nAnd I put that as the input to our cipher.\n\n517\n00:28:11.020 --> 00:28:12.480\nNotice what happens.\n\n518\n00:28:12.480 --> 00:28:16.115\nIt basically re, it gives us the,\nit reverses it, right,\n\n519\n00:28:16.115 --> 00:28:18.241\nit gives us the original message.\n\n520\n00:28:18.241 --> 00:28:19.970\nSo, that is an example.\n\n521\n00:28:19.970 --> 00:28:21.840\nI did have a diagram here.\n\n522\n00:28:21.840 --> 00:28:24.222\nAnd this one was about\nsimple substitutions.\n\n523\n00:28:24.222 --> 00:28:27.700\nYou do have Substitution ciphers\nthat I wanted to kinda mention here.\n\n524\n00:28:27.700 --> 00:28:31.823\nAnd a substitution cipher's where you\njust basically take your plain text and\n\n525\n00:28:31.823 --> 00:28:36.147\nas example, right, you substitute it\nwith a different letter pattern, right?\n\n526\n00:28:36.147 --> 00:28:37.690\nThat might be your cipher if you will.\n\n527\n00:28:37.690 --> 00:28:41.200\nSo an A is actually a U,\nB is actually an H.\n\n528\n00:28:41.200 --> 00:28:46.780\nSo again, don't think about it as actual\nencryption, as it is just trying to,\n\n529\n00:28:46.780 --> 00:28:51.630\nand again like our chat room says,\nobscure what the information is.\n\n530\n00:28:51.630 --> 00:28:56.440\nSo just know the obfuscation techniques,\nlike an XOR, ROT13, and\n\n531\n00:28:56.440 --> 00:28:59.060\nthere are substitution cyphers out there.\n\n532\n00:28:59.060 --> 00:29:01.957\nKeep in mind that it is not always\nwhen it comes to encryption,\n\n533\n00:29:01.957 --> 00:29:04.757\nwhen it comes to cryptology and\nwhat you're gonna choose.\n\n534\n00:29:04.757 --> 00:29:06.806\nIt is not a one-size-fits all, and\n\n535\n00:29:06.806 --> 00:29:11.569\nagain it doesn't necessarily mean that you\ntake and say okay, I want AES 256, and\n\n536\n00:29:11.569 --> 00:29:14.900\nI want that coupled with\nCounter Mode Cipher, right?\n\n537\n00:29:14.900 --> 00:29:19.091\nYou really have to look at what the needs\nare of your company, or whatever the needs\n\n538\n00:29:19.091 --> 00:29:23.285\nof the security architecture is to make\nsure that you implement the right choice,\n\n539\n00:29:23.285 --> 00:29:27.333\nand that that choice performs the level\nof security that you need on your data.\n\n540\n00:29:27.333 --> 00:29:29.581\n&gt;&gt; So those Ciphers,\neven the most rudimentary form,\n\n541\n00:29:29.581 --> 00:29:30.920\nthey are a form of encryption.\n\n542\n00:29:30.920 --> 00:29:35.170\nBut like what we were talking about in\nour show, it can get really complex.\n\n543\n00:29:35.170 --> 00:29:39.219\nSo, like we had mentioned throughout this\nlittle mini-series we have going here,\n\n544\n00:29:39.219 --> 00:29:41.499\nluckily what we've covered\nin this episode and\n\n545\n00:29:41.499 --> 00:29:44.078\nthe objectives is what you\nneed to know for that exam.\n\n546\n00:29:44.078 --> 00:29:45.386\nBut I think we are finished.\n\n547\n00:29:45.386 --> 00:29:46.810\nWes do you have any final thoughts?\n\n548\n00:29:46.810 --> 00:29:48.008\n&gt;&gt; No ma'am I think that's all.\n\n549\n00:29:48.008 --> 00:29:51.373\nAgain just kinda keep in mind, that when\nit comes to your choice again you can't\n\n550\n00:29:51.373 --> 00:29:53.849\njust pick the latest and\ngreatest or the strongest right?\n\n551\n00:29:53.849 --> 00:29:55.390\nBecause there are drawbacks.\n\n552\n00:29:55.390 --> 00:29:58.470\nThere are goods, pros, and\ncons with every choice that you make, but\n\n553\n00:29:58.470 --> 00:30:03.180\nit should be something that you\nshould be aware of from the exam and\n\n554\n00:30:03.180 --> 00:30:05.060\nin your daily security endeavors.\n\n555\n00:30:05.060 --> 00:30:06.972\n&gt;&gt; Well, thank you for joining us,\nWes, and thank you for\n\n556\n00:30:06.972 --> 00:30:08.161\njoining us ladies and gentlemen.\n\n557\n00:30:08.161 --> 00:30:11.020\nBut stay tuned,\nwe have more information headed your way.\n\n558\n00:30:11.020 --> 00:30:12.560\nFor this show,\nwe'll go ahead and sign out.\n\n559\n00:30:12.560 --> 00:30:14.001\nRemember, I'm Cherokee Boose.\n\n560\n00:30:14.001 --> 00:30:14.840\n&gt;&gt; And I'm Wes Bryan.\n\n561\n00:30:14.840 --> 00:30:17.130\n&gt;&gt; See you next time here at ITProTV.\n\n562\n00:30:17.130 --> 00:30:23.908\n[MUSIC]\n\n563\n00:30:23.908 --> 00:30:27.196\n&gt;&gt; Thank you for watching ITPRO.TV\n\n",
          "vimeoId": "214665005"
        },
        {
          "description": "In this episode, Daniel and Wes explore wireless security for the Security+ exam. Here they cover cryptographic protocols like WEP, WPA/WPA2, and TKIP. They also look at authentication protocols like EAP, PEAP, IEEE 802.1x, and RADIUS.",
          "length": "1556",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-3-wireless_security-050417-PGM.00_25_42_03.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-3-wireless_security-050417-PGM.00_25_42_03.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-3-wireless_security-050417-PGM.00_25_42_03.Still001-sm.jpg",
          "title": "Wireless Security",
          "transcript": "WEBVTT\n\n1\n00:00:00.280 --> 00:00:01.230\nWelcome to ITProTV.\n\n2\n00:00:01.230 --> 00:00:06.521\nI'm your host Don Pezet-\n&gt;&gt; [CROSSTALK]\n\n3\n00:00:06.521 --> 00:00:08.442\n&gt;&gt; [MUSIC]\n\n4\n00:00:08.442 --> 00:00:12.326\n&gt;&gt; You're watching ITProTV.\n\n5\n00:00:12.326 --> 00:00:12.950\n&gt;&gt; All right, greetings everyone!\n\n6\n00:00:12.950 --> 00:00:16.130\nAnd welcome to another\ngreat episode of ITProTV.\n\n7\n00:00:16.130 --> 00:00:18.090\nI'm your host, Daniel Lowrie and\n\n8\n00:00:18.090 --> 00:00:22.080\nin today's episode we are continuing\non more on our Security Plus series.\n\n9\n00:00:22.080 --> 00:00:25.320\nAnd of course joining us in the studio\nagain, our good friend, Mr. Wes Bryan.\n\n10\n00:00:25.320 --> 00:00:26.130\nWes, welcome back, man.\n\n11\n00:00:26.130 --> 00:00:26.890\nWe're glad to have you again.\n\n12\n00:00:26.890 --> 00:00:28.170\n&gt;&gt; Hey, man.\nThanks for having me back.\n\n13\n00:00:28.170 --> 00:00:30.400\nYeah, we get to get back\nin some of the fun stuff.\n\n14\n00:00:30.400 --> 00:00:33.290\nWe're going to be talking about\nwireless security in this episode.\n\n15\n00:00:33.290 --> 00:00:36.490\nAnd I tell you, yeah, you can say\nit already, Dan it's like, yeah,\n\n16\n00:00:36.490 --> 00:00:37.643\nwhat can we do with this?\n\n17\n00:00:37.643 --> 00:00:39.110\nWireless security is important.\n\n18\n00:00:39.110 --> 00:00:42.210\nIf you think about it,\na lot of our devices, more and\n\n19\n00:00:42.210 --> 00:00:46.180\nmore and more of these devices\nare becoming, or are wireless if you will.\n\n20\n00:00:46.180 --> 00:00:47.480\nThey don't just become wireless.\n\n21\n00:00:47.480 --> 00:00:49.138\n&gt;&gt; [LAUGH]\n&gt;&gt; They're made that way.\n\n22\n00:00:49.138 --> 00:00:52.926\nBut for instance, CISCO, I believe CISCO\nmade a prediction a couple of years ago.\n\n23\n00:00:52.926 --> 00:00:58.148\nI think it's a little outdated prediction\nthat said by the end of 2017 this year,\n\n24\n00:00:58.148 --> 00:01:02.937\nthere should be upwards of 50 billion\nTCPIP based devices on networks across\n\n25\n00:01:02.937 --> 00:01:03.680\nthe world.\n\n26\n00:01:03.680 --> 00:01:08.150\nAnd I wouldn't be surprised if a good\nmajority of those are wireless devices.\n\n27\n00:01:08.150 --> 00:01:12.220\nSo it is important, it is important\nthat we secure wireless infrastructure,\n\n28\n00:01:12.220 --> 00:01:13.980\nbecause I want you to think about it.\n\n29\n00:01:13.980 --> 00:01:16.340\nWhen we talk about wired infrastructure,\n\n30\n00:01:16.340 --> 00:01:18.840\nif we're running something\nlike a Cat cable.\n\n31\n00:01:18.840 --> 00:01:20.570\nThat's within our building,\n\n32\n00:01:20.570 --> 00:01:24.610\nsomebody has to have physical\naccess to our network in order to\n\n33\n00:01:24.610 --> 00:01:28.790\ngain access to the information that is\ntraversing the wire within the network.\n\n34\n00:01:30.010 --> 00:01:34.470\nWireless isn't necessarily that way, now\nI have to have proximity to your network,\n\n35\n00:01:34.470 --> 00:01:37.650\nbut I certainly don't have to\nbe inside of your building\n\n36\n00:01:37.650 --> 00:01:41.360\nto potentially take advantage of the fact\nthat you're using unbounded media.\n\n37\n00:01:41.360 --> 00:01:44.970\nThere's data that's emanating off\nof wireless devices whether you're\n\n38\n00:01:44.970 --> 00:01:45.940\ncommunicating or not.\n\n39\n00:01:45.940 --> 00:01:49.450\nAnd somebody,\nif they have the skills, could be\n\n40\n00:01:49.450 --> 00:01:52.720\nout there scraping that information and\npotentially eavesdropping on it.\n\n41\n00:01:52.720 --> 00:01:56.430\nPotentially maybe even modifying it,\nif you will.\n\n42\n00:01:56.430 --> 00:02:00.170\nOr, what's worse, maybe they even\nbring your whole network down.\n\n43\n00:02:00.170 --> 00:02:03.780\nSo, we do have to worry about wireless\nsecurity because of the fact that it's\n\n44\n00:02:03.780 --> 00:02:09.500\na little bit easier to gain access,\nunlike a wired connection.\n\n45\n00:02:09.500 --> 00:02:12.700\nSo, that's what we're going\nto talk about here today.\n\n46\n00:02:12.700 --> 00:02:14.890\nSo, let me go ahead and start off.\n\n47\n00:02:14.890 --> 00:02:18.270\nI've got a wireless access\npoint interface pulled up here.\n\n48\n00:02:18.270 --> 00:02:20.530\nAnd this is one of the links,\nthis access point.\n\n49\n00:02:20.530 --> 00:02:25.156\nAnd when we get into things like wireless,\nwe have the ability to use security.\n\n50\n00:02:25.156 --> 00:02:27.400\nNow I'm going to kind of go\nout of order on this one, Dan,\n\n51\n00:02:27.400 --> 00:02:31.010\nbecause right away on a lot\nof these access points,\n\n52\n00:02:31.010 --> 00:02:34.200\nyou get confronted with\nthis Wi-Fi Protected Setup.\n\n53\n00:02:34.200 --> 00:02:35.430\nWi-Fi Protected Setup,\n\n54\n00:02:35.430 --> 00:02:37.670\nin our exam objectives,\nis a little bit lower in the list.\n\n55\n00:02:37.670 --> 00:02:40.370\nBut it's good to go ahead and\ntalk about it now because a lot\n\n56\n00:02:40.370 --> 00:02:43.530\nof times it's the first thing\nthat you're confronted with, WPS.\n\n57\n00:02:44.610 --> 00:02:46.250\nSo what is Wi-Fi Protected Setup?\n\n58\n00:02:46.250 --> 00:02:49.670\nWell, Wi-Fi Protected Setup is,\n\n59\n00:02:49.670 --> 00:02:53.350\nit's really more about convenience\nthan it is anything else.\n\n60\n00:02:53.350 --> 00:02:56.650\nAnd any time we talk about convenience,\nwe come and\n\n61\n00:02:56.650 --> 00:02:58.920\nwe talk about there's\na reduction of security.\n\n62\n00:02:58.920 --> 00:03:04.150\nAnd Wi-Fi Protected Setup certainly\nisn't an exception to the rule.\n\n63\n00:03:04.150 --> 00:03:07.280\nIt had a good intent,\nthe intention was good behind it.\n\n64\n00:03:07.280 --> 00:03:10.830\nIt said, let's let the average end\nuser that maybe doesn't know a lot\n\n65\n00:03:10.830 --> 00:03:11.940\nabout security,\n\n66\n00:03:11.940 --> 00:03:16.800\nwe'll give them a simplistic way that they\ncan set up their wireless access point.\n\n67\n00:03:16.800 --> 00:03:19.000\nThey can connect to it with\ntheir wireless device, and\n\n68\n00:03:19.000 --> 00:03:20.640\nthey really don't have to do much.\n\n69\n00:03:20.640 --> 00:03:23.480\nIt could be a push button implementation.\n\n70\n00:03:23.480 --> 00:03:26.710\nIn fact, if we hover over\nthis little icon right here,\n\n71\n00:03:26.710 --> 00:03:30.990\nyou can see that it's trying to convince\nme to go ahead and push on that icon.\n\n72\n00:03:30.990 --> 00:03:35.460\nAnd that's one of the modes that WPS\nsupports, it supports a PIN mode.\n\n73\n00:03:35.460 --> 00:03:38.400\nThis is another common one where\nyou have an eight digit code.\n\n74\n00:03:38.400 --> 00:03:41.090\nAnd it's usually printed on\nthe back of the, like, for\n\n75\n00:03:41.090 --> 00:03:44.020\ninstance the wireless router,\nthe wireless access point.\n\n76\n00:03:44.020 --> 00:03:48.520\nAnd you put that code into the client\nsettings, the device, the station,\n\n77\n00:03:48.520 --> 00:03:51.180\nthat's going to connect to\nthe wireless access point.\n\n78\n00:03:51.180 --> 00:03:52.680\nBut you also have push button mode.\n\n79\n00:03:52.680 --> 00:03:56.380\nThe push button mode just means\nthat if I click this button,\n\n80\n00:03:56.380 --> 00:03:59.370\nwhat we can do is we can make it\nmore of an automated approach.\n\n81\n00:03:59.370 --> 00:04:03.250\nIt's pretty streamlined and automated\nanyways, but this makes it even easier.\n\n82\n00:04:04.470 --> 00:04:09.208\nThey also have NFC, near field\ncommunication, that you can use.\n\n83\n00:04:09.208 --> 00:04:12.786\nAnd they also, in the standard,\nthey had another one,\n\n84\n00:04:12.786 --> 00:04:17.138\nreally it's been deprecated now,\nand that was the USB based mode.\n\n85\n00:04:17.138 --> 00:04:21.993\nSo why is Wi-Fi Protected Setup one of\nthese things that we kind of want to\n\n86\n00:04:21.993 --> 00:04:22.560\navoid?\n\n87\n00:04:22.560 --> 00:04:27.240\nAnd that's really the flaw in it is\nhow it does it's authentication.\n\n88\n00:04:27.240 --> 00:04:29.284\nIt's an eight digit code, but\n\n89\n00:04:29.284 --> 00:04:34.460\nthe way it authenticates it actually\nbreaks it down into four numbers each.\n\n90\n00:04:34.460 --> 00:04:37.500\nIf you think about that,\nI think there's like 11,000 possibilities,\n\n91\n00:04:37.500 --> 00:04:38.984\nif you look at two to the power of four.\n\n92\n00:04:38.984 --> 00:04:42.116\nSo there's not a lot of combinations,\nand even worse than that, when you're,\n\n93\n00:04:42.116 --> 00:04:45.156\nif somebody was trying to brute force\nattack this, and keep telling you, no,\n\n94\n00:04:45.156 --> 00:04:49.500\nyou're wrong, no, you're wrong, okay,\nyou've got the first four, you're right.\n\n95\n00:04:49.500 --> 00:04:52.230\nWell great, thank you, I don't have to\nworry about it, let's just bookmark those\n\n96\n00:04:52.230 --> 00:04:55.500\nfor the site, and we can start working\non the second portion of the PIN.\n\n97\n00:04:55.500 --> 00:04:59.160\nSo be careful with Wi-Fi Protected Setup.\n\n98\n00:04:59.160 --> 00:05:05.900\nMost firmwares today allow you, if you\ndo a firmware update, to disable it.\n\n99\n00:05:05.900 --> 00:05:10.770\nHowever, pay attention to your\naccess point, because of the fact\n\n100\n00:05:10.770 --> 00:05:15.010\nthat if you do disable it, sometimes in\nthe interface, it says you've disabled it.\n\n101\n00:05:15.010 --> 00:05:16.020\nLet me show you what I mean here.\n\n102\n00:05:16.020 --> 00:05:20.360\nSo if I say you know what, I'm going\nto do a manual implementation, and\n\n103\n00:05:20.360 --> 00:05:22.660\nI'm going to make sure that it's disabled.\n\n104\n00:05:24.250 --> 00:05:25.660\nMake sure that that's the fact.\n\n105\n00:05:25.660 --> 00:05:29.140\nI've actually seen it where in\nolder firmware you disable it and\n\n106\n00:05:29.140 --> 00:05:32.740\nunderneath you do a wireless\nanalyzer on your network.\n\n107\n00:05:32.740 --> 00:05:34.180\nAnd sure enough it's in the background and\n\n108\n00:05:34.180 --> 00:05:37.640\nit's still presenting itself as\nan authentication mechanism.\n\n109\n00:05:37.640 --> 00:05:40.110\nYou're like,\nwait a second I thought I turned that off.\n\n110\n00:05:40.110 --> 00:05:41.910\nA lot of your vendors have patched this.\n\n111\n00:05:41.910 --> 00:05:43.570\nThey realize that there's a vulnerability.\n\n112\n00:05:43.570 --> 00:05:47.770\nI think the vulnerability goes back to,\nit was introduced in 2006, and I'd want to\n\n113\n00:05:47.770 --> 00:05:51.870\nsay it was in that year or a year after\nthat they found the vulnerability.\n\n114\n00:05:51.870 --> 00:05:53.610\nSo they found it fairly quickly.\n\n115\n00:05:53.610 --> 00:05:58.220\nEnsure that your firmware is up to date,\ncheck the firmware.\n\n116\n00:05:58.220 --> 00:06:00.260\nLike for instance, I'm on an E8350 here.\n\n117\n00:06:00.260 --> 00:06:03.420\nMake sure if you see something like this,\nand\n\n118\n00:06:03.420 --> 00:06:06.670\nyou know it's an older device,\nand it says 1.0.0.\n\n119\n00:06:06.670 --> 00:06:08.970\nChances are there's a firmware update and\nyou need to implement it.\n\n120\n00:06:08.970 --> 00:06:12.330\nThat's one of the things\nthat can help you.\n\n121\n00:06:12.330 --> 00:06:15.080\nBut what if we do go for a manual process?\n\n122\n00:06:15.080 --> 00:06:18.060\nSo if I say, okay,\nI want to do a manual process and\n\n123\n00:06:18.060 --> 00:06:20.420\nI want to get into wireless security.\n\n124\n00:06:20.420 --> 00:06:23.970\nWell, wireless security mode is turned\noff on both of these networks, but\n\n125\n00:06:23.970 --> 00:06:27.090\nlook what happens if we\ndecide to enable it.\n\n126\n00:06:27.090 --> 00:06:30.560\nAll different kinds of options.\n\n127\n00:06:30.560 --> 00:06:32.618\nAnd that's what we want to\ntalk about in this episode.\n\n128\n00:06:32.618 --> 00:06:35.790\nWe want to talk about some\nof the options you have.\n\n129\n00:06:35.790 --> 00:06:38.650\nAnd with those options you have a series\nof cryptographic protocols that\n\n130\n00:06:38.650 --> 00:06:42.260\nthey call out on this exam.\n\n131\n00:06:42.260 --> 00:06:45.310\nThey don't specifically call out WEP,\nhowever we have talked in\n\n132\n00:06:45.310 --> 00:06:49.900\nother episode about using unsecure\ncryptographic protocols in WEP.\n\n133\n00:06:49.900 --> 00:06:52.250\nWEP has a lot of problems.\n\n134\n00:06:52.250 --> 00:06:56.710\nIt was a first introduction to\nthe 802.11 standard that said, hey,\n\n135\n00:06:56.710 --> 00:06:58.723\nwe need some kind of security.\n\n136\n00:06:58.723 --> 00:07:01.280\nBut this kind of security is really\n\n137\n00:07:01.280 --> 00:07:03.880\npulling the blinds down in\nthe windows around your house.\n\n138\n00:07:03.880 --> 00:07:04.570\nIf you think about it,\n\n139\n00:07:04.570 --> 00:07:08.800\nall that does is keeps people from\ncasually looking inside of your house.\n\n140\n00:07:08.800 --> 00:07:12.350\nIt does nothing really to stop them\nfrom actually getting into your house.\n\n141\n00:07:12.350 --> 00:07:14.120\nAnd they called it\nWired Equivalent Privacy.\n\n142\n00:07:14.120 --> 00:07:17.470\nNow we've also talked about\nthe fact that you really don't\n\n143\n00:07:17.470 --> 00:07:21.210\nhave any privacy on a wired network\nunless you're implementing encryption.\n\n144\n00:07:21.210 --> 00:07:22.900\nSo it was a problem.\n\n145\n00:07:24.270 --> 00:07:25.260\nSo they came out with WPA.\n\n146\n00:07:25.260 --> 00:07:30.000\nWPA is the Wi-fi Protected Access,\nand this was the successor, and\n\n147\n00:07:30.000 --> 00:07:33.500\nit really wasn't the end all in security.\n\n148\n00:07:33.500 --> 00:07:37.880\nThey knew that WEP had problems,\nthey knew that it was very vulnerable.\n\n149\n00:07:37.880 --> 00:07:40.230\nIn fact, let me kind of show you\nsome of the problems with it.\n\n150\n00:07:40.230 --> 00:07:44.630\nIf you look at a WEP frame,\na WEP frame uses, first of all,\n\n151\n00:07:44.630 --> 00:07:47.540\na very weak stream cipher.\n\n152\n00:07:47.540 --> 00:07:52.410\nThis is the RC4 Stream Cipher, Ron Rivest\nor Rivest Cipher or Rivest Code,\n\n153\n00:07:52.410 --> 00:07:54.019\nRon's code if you will.\n\n154\n00:07:54.019 --> 00:07:56.817\nAnd it's known to have vulnerabilities.\n\n155\n00:07:56.817 --> 00:07:59.939\nIt has other vulnerabilities in the fact\nthat it uses an initialization vector\n\n156\n00:07:59.939 --> 00:08:02.032\nthat's kind of like a one time nuance,\nif you will.\n\n157\n00:08:02.032 --> 00:08:05.852\nIt's added to every piece of ciphertext or\nplain text to make sure that\n\n158\n00:08:05.852 --> 00:08:10.069\nwhen the encrypted ciphertext comes out,\nwe don't have any duplications.\n\n159\n00:08:10.069 --> 00:08:13.958\nAny time you got a duplication in\ncryptology, you have some kind of pattern\n\n160\n00:08:13.958 --> 00:08:17.740\nand people like to do statistical\nanalysis and kinda reverse engineer.\n\n161\n00:08:17.740 --> 00:08:19.760\nSo the problem is with 24 Bits,\n\n162\n00:08:19.760 --> 00:08:23.700\nwe're talking about just under\n17 million possibilities.\n\n163\n00:08:23.700 --> 00:08:28.067\nAnd by modern computing standards it only\ntakes about 50% of those possibilities.\n\n164\n00:08:28.067 --> 00:08:33.050\nYou start see duplicates modern technology\ncan crack it really within the time that\n\n165\n00:08:33.050 --> 00:08:36.269\nit takes to play a song,\nyou can crack it fairly fast.\n\n166\n00:08:36.269 --> 00:08:40.675\nOther problems with it was this CRC\n32-bit value, that's a CRC just a cyclic\n\n167\n00:08:40.675 --> 00:08:44.638\nredundancy check, it's like a checksum,\nit had some issues as well.\n\n168\n00:08:44.638 --> 00:08:53.250\nSo, we wanna stay away from WEP however\nWPA did something kinda interesting.\n\n169\n00:08:53.250 --> 00:08:57.193\nWhat it did is that it introduced\nsomething known as TKIP okay now don't let\n\n170\n00:08:57.193 --> 00:09:01.200\nthe acronym fool you here guys it's\nthe temporal key integrity protocol and\n\n171\n00:09:01.200 --> 00:09:05.470\nI know that sounds completely complex,\nbut let's just break down the acronym.\n\n172\n00:09:05.470 --> 00:09:07.360\nTemporal, what does that mean?\n\n173\n00:09:07.360 --> 00:09:10.584\nSomething isn't going to last for\na long time, it's gonna change.\n\n174\n00:09:10.584 --> 00:09:14.670\nKey, temporal key, so\nwe've got a key that's going to change.\n\n175\n00:09:14.670 --> 00:09:18.737\nIntegrity protocol,\nmaintaining the integrity of the key.\n\n176\n00:09:18.737 --> 00:09:19.900\nSo what they did,\n\n177\n00:09:19.900 --> 00:09:24.900\nIs they took pretty much the same WEP\nprotocol using the RC4 stream cipher.\n\n178\n00:09:24.900 --> 00:09:28.680\nAnd what they do is every frame\nthat goes over a wireless network\n\n179\n00:09:28.680 --> 00:09:30.330\nis encrypted with a new key.\n\n180\n00:09:30.330 --> 00:09:34.760\nThat's essentially what it does, it just\nencrypt it, now it's still using WEP,\n\n181\n00:09:34.760 --> 00:09:39.540\nstill using the RC4 stream cipher,\nso it has problems, right.\n\n182\n00:09:39.540 --> 00:09:42.000\nSo that's what WPA introduced.\n\n183\n00:09:42.000 --> 00:09:47.520\nIt introduced this temporal key integrity\nprotocol and said hey, since WEP has\n\n184\n00:09:47.520 --> 00:09:52.160\na static key, gives the hackers all the\ntime they need to try to crack that key.\n\n185\n00:09:52.160 --> 00:09:55.490\nWhat happens if we constantly\nare changing the key?\n\n186\n00:09:55.490 --> 00:09:58.435\nWell that means if the hacker\nhappens to reverse engineer key one.\n\n187\n00:09:58.435 --> 00:10:01.519\nThat's okay because the next frame that\ncomes across that wireless network has got\n\n188\n00:10:01.519 --> 00:10:03.620\na completely different key.\n\n189\n00:10:03.620 --> 00:10:04.950\nAnd then so on and so forth.\n\n190\n00:10:04.950 --> 00:10:06.900\nSo that was the thought process before.\n\n191\n00:10:06.900 --> 00:10:12.600\nCisco, actually had one that was kinda\nlike a stopgap between WEP if you will and\n\n192\n00:10:12.600 --> 00:10:14.487\nwhat was coming out next.\n\n193\n00:10:14.487 --> 00:10:18.411\nThey had LEAP which is called light weight\nextensible authentication protocol and\n\n194\n00:10:18.411 --> 00:10:21.450\nthey did kinda the same thing or\nit was re-generating web keys.\n\n195\n00:10:21.450 --> 00:10:24.100\nSo again, you don't have to worry\nabout that for the exam, but\n\n196\n00:10:24.100 --> 00:10:25.704\njust kind of a little history on that.\n\n197\n00:10:25.704 --> 00:10:29.067\nSo, we definitely have to worry about WPA.\n\n198\n00:10:29.067 --> 00:10:33.575\nWPA is, it is stronger,\nif you will, than WEP, but\n\n199\n00:10:33.575 --> 00:10:38.405\nagain it is known to have\nsome vulnerabilities as well.\n\n200\n00:10:38.405 --> 00:10:45.686\nAnd that's why we want to use something\nlike for instance, let's see here, WPA2.\n\n201\n00:10:45.686 --> 00:10:50.310\nOkay, now WPA2, this comes along and\n\n202\n00:10:50.310 --> 00:10:54.220\nreally what happens,\nlet me just back up for a second on WPA.\n\n203\n00:10:54.220 --> 00:10:58.523\nThe Wi-Fi Alliance is a consortium of\nwireless manufacturers that promotes Wi-fi\n\n204\n00:10:58.523 --> 00:10:59.700\nstandards, right.\n\n205\n00:10:59.700 --> 00:11:03.645\nThey went to the IEEE and said, hey,\nyou gotta do something with WEP.\n\n206\n00:11:03.645 --> 00:11:06.530\nThey said, well, we are right,\nwe're gonna fix something.\n\n207\n00:11:06.530 --> 00:11:07.644\nThey said, well, we need something now.\n\n208\n00:11:07.644 --> 00:11:09.818\nThey said, well,\nwe haven't finished the standard but\n\n209\n00:11:09.818 --> 00:11:11.956\nwe do have a subset of\nthe features that are functional.\n\n210\n00:11:11.956 --> 00:11:13.460\nYou can go ahead and take those.\n\n211\n00:11:13.460 --> 00:11:14.610\nThey said, great.\n\n212\n00:11:14.610 --> 00:11:17.430\nThey release that as\nWiFi Protected Access, that's WPA.\n\n213\n00:11:18.560 --> 00:11:22.790\nHowever, the IEEE continues\nto ratify the standard and\n\n214\n00:11:22.790 --> 00:11:28.912\nthey release what's known as 802.11i,\nright, it's an IEEE standard.\n\n215\n00:11:28.912 --> 00:11:32.821\nWell, when the WiFi Alliance got access\nto that, they said well, we already got\n\n216\n00:11:32.821 --> 00:11:37.205\nthe marketing name, everybody recognizes\nWPA, so we'll just call this WPA2, right?\n\n217\n00:11:37.205 --> 00:11:40.203\nWPA the sequel, and\nagain it's a marketing name.\n\n218\n00:11:40.203 --> 00:11:46.303\nHowever, keep in mind that for the exam\nWPA2 and 802.11i, they're the same, right?\n\n219\n00:11:46.303 --> 00:11:48.997\nIt's just the IEEE standardization, right?\n\n220\n00:11:48.997 --> 00:11:53.007\n802 standards that we talk\nabout with LANs if you will.\n\n221\n00:11:53.007 --> 00:11:56.690\nAnd then the WiFi Alliance marketing name.\n\n222\n00:11:56.690 --> 00:11:57.874\nSo what does this do?\n\n223\n00:11:57.874 --> 00:12:05.346\nWell it's interesting because WPA2\ngets rid of the RC4 stream cipher.\n\n224\n00:12:05.346 --> 00:12:07.420\nSo what do we have access to now?\n\n225\n00:12:07.420 --> 00:12:13.990\nWell with WPA2 what we end up\ngetting access to is AES encryption.\n\n226\n00:12:13.990 --> 00:12:16.901\nNow we're using what basically\nthe military uses for\n\n227\n00:12:16.901 --> 00:12:18.782\ntop secret documentation right?\n\n228\n00:12:18.782 --> 00:12:20.670\n256 bit encryption.\n\n229\n00:12:20.670 --> 00:12:22.420\n&gt;&gt; So pretty secure at this point.\n\n230\n00:12:22.420 --> 00:12:23.133\n&gt;&gt; Yeah that's right.\n\n231\n00:12:23.133 --> 00:12:25.894\n&gt;&gt; The vulnerabilities\nthat we had with WPA and\n\n232\n00:12:25.894 --> 00:12:30.521\nWEP are starting to now go by the wayside\nbecause AES if I'm not mistaken,\n\n233\n00:12:30.521 --> 00:12:33.296\nit still has not been decrypted, correct?\n\n234\n00:12:33.296 --> 00:12:35.091\n&gt;&gt; No, it hasn't.\n\n235\n00:12:35.091 --> 00:12:36.240\nIt has not.\n\n236\n00:12:36.240 --> 00:12:38.389\nWe talk about 256,\nit hasn't been cracked at all.\n\n237\n00:12:38.389 --> 00:12:42.818\nThey have 128-bit and it still hasn't been\nencrypted, or it, excuse me cracked yet,\n\n238\n00:12:42.818 --> 00:12:45.362\nbut they say it's becoming more and\nmore feasible.\n\n239\n00:12:45.362 --> 00:12:48.565\nSo they're encouraging people\nto move to what the DOD uses for\n\n240\n00:12:48.565 --> 00:12:50.300\ntheir classified information.\n\n241\n00:12:50.300 --> 00:12:51.556\n&gt;&gt; If it's good enough for\nthe government, right?\n\n242\n00:12:51.556 --> 00:12:55.060\n&gt;&gt; That's right, so that's 256 bit,\nand it hasn't been compromised yet.\n\n243\n00:12:55.060 --> 00:12:57.900\nSo that's one of the things\nthat we have access to.\n\n244\n00:12:57.900 --> 00:13:01.840\nNow the problem is there were\nsome faults with TKIP and\n\n245\n00:13:02.900 --> 00:13:04.690\nthey realized that they're\ngonna need to replace this.\n\n246\n00:13:04.690 --> 00:13:09.247\nSo what we do is,\nnow that we have access to AES encryption,\n\n247\n00:13:09.247 --> 00:13:13.090\nthey replaced TKIP with\nsomething known as CCMP.\n\n248\n00:13:13.090 --> 00:13:15.810\nAnd CCMP guys, you don't have to\nremember this for the exam, but\n\n249\n00:13:15.810 --> 00:13:17.358\nI'll help you out with the acronym.\n\n250\n00:13:17.358 --> 00:13:22.810\nThat is counter-mode cypherblock chaining\nmessage authentication protocol.\n\n251\n00:13:22.810 --> 00:13:24.780\nDo not try to say that ten times fast.\n\n252\n00:13:24.780 --> 00:13:27.876\n[LAUGH] Do not worry about that name for\nthe exam, but\n\n253\n00:13:27.876 --> 00:13:31.053\nwhat that means is basically\nit's replacing TKIP.\n\n254\n00:13:31.053 --> 00:13:34.520\nTKIP again,\nis considered vulnerable today.\n\n255\n00:13:34.520 --> 00:13:38.444\nSo today what we have\nin implementing WPA2,\n\n256\n00:13:38.444 --> 00:13:42.792\nis we have access to AES and\nwe have access to CCMP.\n\n257\n00:13:42.792 --> 00:13:45.533\nAll right, so\nthat's our encryption protocols.\n\n258\n00:13:45.533 --> 00:13:48.750\nKnow why you would choose\none over the other.\n\n259\n00:13:48.750 --> 00:13:51.470\nHowever, we also have additional\n\n260\n00:13:51.470 --> 00:13:54.880\nauthentication protocols that we're\ngonna need to take a look at.\n\n261\n00:13:54.880 --> 00:13:56.311\nSo let's go ahead and do that.\n\n262\n00:13:56.311 --> 00:13:59.221\nLet's take a look at the authentication\nprotocols that are associated\n\n263\n00:13:59.221 --> 00:14:02.680\nwith the cryptographic protocols that\nwe use on our wireless networks.\n\n264\n00:14:02.680 --> 00:14:03.547\nAnd as you can see Dan,\n\n265\n00:14:03.547 --> 00:14:06.211\nwe've got a lot of choices when it\ncomes to authentication methods.\n\n266\n00:14:06.211 --> 00:14:07.946\n&gt;&gt; Going back on more of\nthat vegetable soup, or\n\n267\n00:14:07.946 --> 00:14:10.102\nalphabet soup you keep talking\nabout most definitely.\n\n268\n00:14:10.102 --> 00:14:10.845\nA little bit of an acronym.\n\n269\n00:14:10.845 --> 00:14:11.507\n&gt;&gt; Yes they do.\n\n270\n00:14:11.507 --> 00:14:12.152\n&gt;&gt; [LAUGH]\n&gt;&gt; So\n\n271\n00:14:12.152 --> 00:14:15.320\nthey've given us plenty here when\nit comes to wireless security.\n\n272\n00:14:15.320 --> 00:14:16.347\nSo let's go ahead and\n\n273\n00:14:16.347 --> 00:14:20.122\njust kinda walk through the list and\nkinda identify what these protocols are.\n\n274\n00:14:20.122 --> 00:14:23.541\nThe very first one we have is really\nit isn't an authentication protocol,\n\n275\n00:14:23.541 --> 00:14:26.190\nI know that they put it\nin the list that's EAP.\n\n276\n00:14:26.190 --> 00:14:30.080\nIt's the Extensible Authentication\nProtocol, but it's more of a framework.\n\n277\n00:14:30.080 --> 00:14:33.190\nUnderstand that EAP by itself\ndoes absolutely nothing.\n\n278\n00:14:33.190 --> 00:14:36.340\nBut what it does is it takes\nthe functionality of PPP and\n\n279\n00:14:36.340 --> 00:14:40.120\nit wraps it in a frame where they call\nit extensible because what you can do,\n\n280\n00:14:40.120 --> 00:14:44.450\nis you can add authentication flavors\nif you will, authentication methods.\n\n281\n00:14:44.450 --> 00:14:48.665\nSometimes they call them EAP methods or\nEAP types you might hear.\n\n282\n00:14:48.665 --> 00:14:50.630\nAnd there's a bunch of\nthem that are out there.\n\n283\n00:14:50.630 --> 00:14:54.480\nI'm gonna go ahead and I'm gonna skip over\nPEAP here, and we'll come back to that one\n\n284\n00:14:54.480 --> 00:14:57.250\nin a second cuz I wanna talk\nabout the EAP types there.\n\n285\n00:14:57.250 --> 00:15:00.290\nNow the first one see is the EAP-FAST,\nall right?\n\n286\n00:15:00.290 --> 00:15:05.100\nAnd when we talk about EAP-FAST,\nthis is actually a Cisco proprietary one.\n\n287\n00:15:05.100 --> 00:15:08.958\nIt actually stands for\nflexible authentication via secure tunnel.\n\n288\n00:15:08.958 --> 00:15:10.069\n&gt;&gt; So, it's not just it's quicker.\n\n289\n00:15:10.069 --> 00:15:10.714\n&gt;&gt; That's right.\n\n290\n00:15:10.714 --> 00:15:12.054\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH] Exactly.\n\n291\n00:15:12.054 --> 00:15:13.235\n&gt;&gt; It's not like Usain Bolt of EAP.\n\n292\n00:15:13.235 --> 00:15:14.280\n&gt;&gt; That's right.\n\n293\n00:15:14.280 --> 00:15:18.530\nAnd what this did is, this was developed,\nI kinda mentioned LEAP, right?\n\n294\n00:15:18.530 --> 00:15:24.984\nAnd that was a little kind of\na solution to temporarily replace WEP.\n\n295\n00:15:24.984 --> 00:15:30.250\nWell FAST,\nEAP-FAST was their replacement for LEAP.\n\n296\n00:15:30.250 --> 00:15:35.460\nAnd essentially what it does is it\nrequires a Cisco software module,\n\n297\n00:15:35.460 --> 00:15:38.000\nbut it's pretty much supported\nin Vista and beyond.\n\n298\n00:15:38.000 --> 00:15:41.127\nWhen it comes to your Windows systems,\nand in Mac OS,\n\n299\n00:15:41.127 --> 00:15:44.958\nthey started support for\nthis back in 10.4.8, and above.\n\n300\n00:15:44.958 --> 00:15:49.179\nSo a lot of support for it, and one of\nthe things that it does is it provides,\n\n301\n00:15:49.179 --> 00:15:52.732\nit's basically their proprietary\nsession authentication,\n\n302\n00:15:52.732 --> 00:15:56.700\nbasically for wireless networks and\npoint to point communications.\n\n303\n00:15:56.700 --> 00:16:00.764\nNext one the list is very important,\nbecause while we use it here in wireless,\n\n304\n00:16:00.764 --> 00:16:03.330\nwe also use it for other things, as well.\n\n305\n00:16:03.330 --> 00:16:07.150\nThis is EAP-TLS and\nthat's transport layer security.\n\n306\n00:16:07.150 --> 00:16:11.230\nThe good thing about EAP-TLS is not only\ncan we use as wireless authentication\n\n307\n00:16:11.230 --> 00:16:14.470\nmethod by exchanging certificates,\ninside of a wireless network,\n\n308\n00:16:14.470 --> 00:16:17.030\nit's used for\ncertificate based authentication.\n\n309\n00:16:17.030 --> 00:16:19.234\nTokens, smart card authentication as well.\n\n310\n00:16:19.234 --> 00:16:22.731\nSo it's actually kinda robust,\nit's not just used here just for\n\n311\n00:16:22.731 --> 00:16:27.620\nthe purposes of wireless networks, but it\ncan be used amongst many other things too.\n\n312\n00:16:27.620 --> 00:16:32.000\nSo I would also remember for your exam\nthat EAP-TLS, not only in a wireless\n\n313\n00:16:32.000 --> 00:16:36.060\nscenario that they might throw at you but\nthey ask you which of these protocols\n\n314\n00:16:36.060 --> 00:16:40.855\nallows you to perform certificate based\nauthentication or implement smart cards.\n\n315\n00:16:40.855 --> 00:16:43.870\nEAP-TLS, that's gonna be\nwhere the money's at.\n\n316\n00:16:43.870 --> 00:16:45.770\nThe next one takes it\na little bit farther, and\n\n317\n00:16:45.770 --> 00:16:48.560\nI'm going to, when we say EAP-TTLS, right,\n\n318\n00:16:48.560 --> 00:16:52.285\nwhat's the extra T about, is that\nthe double your flavor, double your fun?\n\n319\n00:16:52.285 --> 00:16:56.140\n&gt;&gt; [LAUGH] But\nthat's what's called tunnelled TLS.\n\n320\n00:16:56.140 --> 00:16:59.510\nAnd I wanna compare these to PEAP as well,\nright?\n\n321\n00:16:59.510 --> 00:17:02.240\nSo, tunnelled TLS is where, see,\n\n322\n00:17:02.240 --> 00:17:05.630\nthese authentication protocols\nthat we've talked about so far.\n\n323\n00:17:05.630 --> 00:17:08.560\nWhat they do is they allow\nyou to authenticate, but\n\n324\n00:17:08.560 --> 00:17:13.190\nthey really don't do much to protect the\nauthentication mechanism itself, right,\n\n325\n00:17:13.190 --> 00:17:14.130\nthe method if you will.\n\n326\n00:17:14.130 --> 00:17:17.890\nSo imagine a way that we can,\nfrom endpoint to endpoint,\n\n327\n00:17:17.890 --> 00:17:22.810\nwe can establish an encrypted tunnel\nbefore anything goes on, right?\n\n328\n00:17:22.810 --> 00:17:24.540\nAnd that's what Tunnel TLS does.\n\n329\n00:17:24.540 --> 00:17:29.340\nIt allows you the ability to create\nthe encrypted tunnel, and then we send\n\n330\n00:17:29.340 --> 00:17:32.140\nthe authentication information\nthrough that encrypted tunnel, right?\n\n331\n00:17:32.140 --> 00:17:35.970\nSo people can't eavesdrop\non the information EAP,\n\n332\n00:17:35.970 --> 00:17:38.410\ncuz it's established\nthe secure tunnel first.\n\n333\n00:17:38.410 --> 00:17:40.900\nAnd that's what protected EAP is.\n\n334\n00:17:40.900 --> 00:17:44.040\nProtected extensible authentication\ndoes the same thing.\n\n335\n00:17:44.040 --> 00:17:48.720\nIt allows you to create an encrypted\ntunnel between endpoints\n\n336\n00:17:48.720 --> 00:17:51.090\nbefore you ever send\nthe authentication information.\n\n337\n00:17:51.090 --> 00:17:55.094\nSo again, kind of just adding to\nthe security levels, if you will,\n\n338\n00:17:55.094 --> 00:17:59.117\nof your already authenticated\ninformation that you're sending.\n\n339\n00:17:59.117 --> 00:18:00.072\n&gt;&gt; I thought you just had a stutter.\n\n340\n00:18:00.072 --> 00:18:00.902\nThat's right.\n\n341\n00:18:00.902 --> 00:18:02.154\n[LAUGH]\n&gt;&gt; [LAUGH]\n\n342\n00:18:02.154 --> 00:18:02.987\n&gt;&gt; That's exactly what it is.\n\n343\n00:18:02.987 --> 00:18:06.745\nLet me give you some of the scenarios\nwhere you might see some of these, too,\n\n344\n00:18:06.745 --> 00:18:08.530\nthings like dial up remote access.\n\n345\n00:18:08.530 --> 00:18:11.430\nCuz I know we're talking in the context\nof wireless communications,\n\n346\n00:18:11.430 --> 00:18:14.920\nbut you could see these scenarios\nwhere you're using EAP TLS for\n\n347\n00:18:14.920 --> 00:18:17.020\nthings like your dial up\nremote access connections.\n\n348\n00:18:17.020 --> 00:18:21.350\nWe can use that also for\nthings like VPN remote access.\n\n349\n00:18:21.350 --> 00:18:30.200\nPEAP, one of its common implementations is\nPEAP with MS Chat Version 2 is out there.\n\n350\n00:18:30.200 --> 00:18:32.306\nAgain, we also have 802.1x.\n\n351\n00:18:32.306 --> 00:18:35.664\nNow, 802.1x,\nthis is an interesting technology.\n\n352\n00:18:35.664 --> 00:18:40.690\n802.1x is actually what known\nas port based authentication.\n\n353\n00:18:40.690 --> 00:18:42.419\nAnd there's a lot of\ncomplexities behind it.\n\n354\n00:18:42.419 --> 00:18:46.070\nAnd I wanna kinda talk about method.\n\n355\n00:18:46.070 --> 00:18:47.340\nRight, they call out methods and\n\n356\n00:18:47.340 --> 00:18:50.890\none of the things they call out amongst\nsome of the things we talked about like\n\n357\n00:18:50.890 --> 00:18:56.130\nWPS is they call out PSK\nversus enterprise versus open.\n\n358\n00:18:56.130 --> 00:18:58.320\nWhat the heck does that mean?\n\n359\n00:18:58.320 --> 00:19:04.206\nWell, in a basic WPA, WPA2 implementation,\nlet's say at a home environment.\n\n360\n00:19:04.206 --> 00:19:07.540\nYou're using what's known as PSK,\nright, it's Pre Shared Key.\n\n361\n00:19:07.540 --> 00:19:10.290\nThat's all that means,\nit means it's a password essentially.\n\n362\n00:19:10.290 --> 00:19:14.254\nAnd you have to know the password and put\nit into the client settings on your device\n\n363\n00:19:14.254 --> 00:19:16.781\nto be able to connect to\nthe wireless access point.\n\n364\n00:19:16.781 --> 00:19:18.170\n&gt;&gt; Riddle me this, Batman.\n\n365\n00:19:18.170 --> 00:19:22.390\nPet peeve of mine, right,\nthey call it PSK, Pre Shared Key.\n\n366\n00:19:22.390 --> 00:19:25.930\nTech people are like, okay, we understand,\nbasically it means a password.\n\n367\n00:19:25.930 --> 00:19:26.983\nCall the stinking thing a password, right.\n\n368\n00:19:26.983 --> 00:19:27.687\n&gt;&gt; That's exactly what it is.\n\n369\n00:19:27.687 --> 00:19:31.150\n&gt;&gt; Call it a wireless pass phrase or\npassword, whatever, make it easy.\n\n370\n00:19:31.150 --> 00:19:33.410\nI don't know why they do this,\ncall it a pre-shared key.\n\n371\n00:19:33.410 --> 00:19:35.150\nYes, technically that's what it is.\n\n372\n00:19:35.150 --> 00:19:39.410\nBut do we need to indulge in that, or\ncan we just make it easy for each other?\n\n373\n00:19:39.410 --> 00:19:42.460\n&gt;&gt; It's one of the things that we teach\nin A+ about communication, right,\n\n374\n00:19:42.460 --> 00:19:43.440\nno technical jargon.\n\n375\n00:19:43.440 --> 00:19:44.040\n&gt;&gt; That's right.\n&gt;&gt; And\n\n376\n00:19:44.040 --> 00:19:46.070\nthat's what we're here\nto do here at ITProTV,\n\n377\n00:19:46.070 --> 00:19:47.630\nkinda take some of the jargon out.\n\n378\n00:19:47.630 --> 00:19:50.790\nA pre-shared key, just like Dan said,\nit's a password we share between two\n\n379\n00:19:50.790 --> 00:19:55.050\nendpoints that they use to authenticate\namongst each other, right.\n\n380\n00:19:55.050 --> 00:19:58.680\nGreat for home environments, but\nnot in an enterprise environment.\n\n381\n00:19:58.680 --> 00:20:02.380\nThat's why they also have WPA and\nWPA2 enterprise.\n\n382\n00:20:02.380 --> 00:20:05.496\nAnd that's where 802.1X comes in.\n\n383\n00:20:05.496 --> 00:20:11.440\nAll right, 802.1X is nothing more than\nthe IEEE's port based authentication.\n\n384\n00:20:11.440 --> 00:20:15.640\nAnd what we mean by that very basically\nbefore we get into some of the components.\n\n385\n00:20:15.640 --> 00:20:17.550\nBefore you authenticate, guess what?\n\n386\n00:20:17.550 --> 00:20:21.030\nThe Port State?\nClosed, you don't communicate.\n\n387\n00:20:21.030 --> 00:20:22.650\nAfter the authentication happens and\n\n388\n00:20:22.650 --> 00:20:26.840\ntypically over what's known as EAPOL,\nEAP over LAN, right?\n\n389\n00:20:26.840 --> 00:20:28.850\nOnce we authentication happens,\nif it's successful,\n\n390\n00:20:28.850 --> 00:20:30.230\nguess what happens to the port?\n\n391\n00:20:30.230 --> 00:20:32.800\nIt turns back on and\nyou connect to the network, right?\n\n392\n00:20:32.800 --> 00:20:33.550\nCase dismissed.\n\n393\n00:20:33.550 --> 00:20:36.718\nBut there are a lot of components that\nwe want you to kind of be aware of,\n\n394\n00:20:36.718 --> 00:20:38.947\nbecause EAP or\nexcuse me non-EAP, I'm sorry.\n\n395\n00:20:38.947 --> 00:20:46.190\n802.1x is usually is used in\ncombination with Radius, all right?\n\n396\n00:20:46.190 --> 00:20:50.292\nSo what we have here is we\nhave a few different devices.\n\n397\n00:20:50.292 --> 00:20:52.890\nAll right, I want you to know\nthat the wireless client, right,\n\n398\n00:20:52.890 --> 00:20:54.190\nthat's what's known as a supplicant.\n\n399\n00:20:54.190 --> 00:20:56.508\nThere's three components of 802.1x.\n\n400\n00:20:56.508 --> 00:20:59.480\nYou have what's known as a supplicant,\nan authenticator and\n\n401\n00:20:59.480 --> 00:21:01.620\nan authentication server, right?\n\n402\n00:21:01.620 --> 00:21:04.340\nSo the supplicant is\njust any wireless device.\n\n403\n00:21:04.340 --> 00:21:06.190\nAgain, like Dan says, technical jargon,\n\n404\n00:21:06.190 --> 00:21:10.990\nit's just any wireless device that wants\nto make connection to that network.\n\n405\n00:21:10.990 --> 00:21:16.480\nThe authenticator is an 802.1x\nenabled device, right?\n\n406\n00:21:16.480 --> 00:21:20.430\nAnd it doesn't, even though we are talking\nabout wireless, let's understand\n\n407\n00:21:20.430 --> 00:21:25.360\nthat this is also 802.3 based networks\nas well as 802.11 based networks.\n\n408\n00:21:25.360 --> 00:21:28.710\nSo it works on wired and wireless,\nwhether it's wired ethernet or\n\n409\n00:21:28.710 --> 00:21:30.980\ntalking to your wireless communications.\n\n410\n00:21:30.980 --> 00:21:32.120\nThe concept is the same.\n\n411\n00:21:32.120 --> 00:21:37.250\nThe authenticator, what it does is while\nyou are authenticating it closes that port\n\n412\n00:21:37.250 --> 00:21:41.600\ndown and it says let me go ahead and let\nme talk to the authentication server and\n\n413\n00:21:41.600 --> 00:21:44.670\nsee if you're even\nallowed to authenticate.\n\n414\n00:21:44.670 --> 00:21:48.750\nSo as we go through the authentication\nprocess that we've already talked\n\n415\n00:21:48.750 --> 00:21:51.980\nabout in other episodes about\nthe Radius communications, right?\n\n416\n00:21:51.980 --> 00:21:55.890\nI just want you to know that\nthe authenticator is actually kind of like\n\n417\n00:21:55.890 --> 00:21:56.990\nthe middle man, right?\n\n418\n00:21:56.990 --> 00:22:01.650\nAnd it is passing, it is closing down the\nport as your authentication passes through\n\n419\n00:22:01.650 --> 00:22:05.720\nit so you can't get in, and it passes your\nauthentication back to the Radius server,\n\n420\n00:22:05.720 --> 00:22:08.030\nthe authentication server, right?\n\n421\n00:22:08.030 --> 00:22:11.070\nSo, this communication,\nremember the three components.\n\n422\n00:22:11.070 --> 00:22:12.650\nSupplicant, right?\n\n423\n00:22:12.650 --> 00:22:15.160\nYour Authenticator, and\nyour Authentication Server.\n\n424\n00:22:15.160 --> 00:22:19.240\nAgain 802.x is one of those methods\nthat just really is about port-based\n\n425\n00:22:19.240 --> 00:22:19.980\nauthentication.\n\n426\n00:22:21.500 --> 00:22:24.970\nAll right, Dan, let's see I've got one\nmore that we need to talk about, and\n\n427\n00:22:24.970 --> 00:22:29.410\nthat's something known, maybe you guys\nhave seen this if you've ever gone to\n\n428\n00:22:29.410 --> 00:22:33.040\na convention hall,\nif you've gone to a hotel.\n\n429\n00:22:33.040 --> 00:22:35.410\nIf you've gone to something\nlike a coffee shop.\n\n430\n00:22:35.410 --> 00:22:38.320\nPublic places where you're going to\nsign in to their wireless network.\n\n431\n00:22:38.320 --> 00:22:41.390\nAnd that's something\nknown as captive portal.\n\n432\n00:22:41.390 --> 00:22:45.981\nAll right, when we look at the captive\nportal, it's really nothing more then,\n\n433\n00:22:45.981 --> 00:22:50.302\na lot of times it's a web application,\nand it's used in public networks and\n\n434\n00:22:50.302 --> 00:22:53.870\nit requires the user typically\nto do a couple of things.\n\n435\n00:22:53.870 --> 00:22:56.720\nFirst, we need some visualization and\nyou need to read some information and\n\n436\n00:22:56.720 --> 00:23:01.650\nprobably agree to like an AUP,\nan acceptable use policy.\n\n437\n00:23:02.740 --> 00:23:06.900\nThe next thing that you need to do is,\nsometimes, enter a password, right?\n\n438\n00:23:06.900 --> 00:23:08.470\nAnd once you meet that criteria,\n\n439\n00:23:08.470 --> 00:23:11.390\nwhat happens is it allows\nyou access to the internet.\n\n440\n00:23:11.390 --> 00:23:13.208\nKeep in mind that you see these inside.\n\n441\n00:23:13.208 --> 00:23:16.308\nThings like your airports,\nthings like your coffee shops,\n\n442\n00:23:16.308 --> 00:23:19.380\nthings like your hotels and\nconvention centers.\n\n443\n00:23:19.380 --> 00:23:23.160\nIf you ever want a chance to potentially,\non your own network, if you want to try to\n\n444\n00:23:23.160 --> 00:23:26.970\nimplement a captive portal, check out\nour PFSense episodes that we have.\n\n445\n00:23:26.970 --> 00:23:31.680\nOur PFSense series if you will.\n\n446\n00:23:31.680 --> 00:23:34.610\nInside of PFSense they allow you\nthe ability to setup a captive\n\n447\n00:23:34.610 --> 00:23:37.260\nportal that says any of your guests\nthat are gonna connect to your network,\n\n448\n00:23:37.260 --> 00:23:38.830\nthey have to enter that password.\n\n449\n00:23:38.830 --> 00:23:42.060\nAnd typically inside of\nsome kind of web browser.\n\n450\n00:23:42.060 --> 00:23:43.534\nYou can see this sometimes\ntoo in guest networks, right.\n\n451\n00:23:43.534 --> 00:23:47.460\nJust general guest networks where\na web application opens up, you enter\n\n452\n00:23:47.460 --> 00:23:52.326\nthe password, you don't gain access to the\ninternal network, that wouldn't be good.\n\n453\n00:23:52.326 --> 00:23:54.790\n[LAUGH] But you at least get\nredirected out to the Internet so\n\n454\n00:23:54.790 --> 00:23:57.430\nyou can make some kind of\nbasic Internet connection.\n\n455\n00:23:57.430 --> 00:24:02.400\nSo, that's a great way to give users\naccess to the Internet without giving them\n\n456\n00:24:02.400 --> 00:24:04.020\naccess to your internal networks.\n\n457\n00:24:04.020 --> 00:24:07.650\nNow, I know there are a lot of different\nconcepts that we've talked about.\n\n458\n00:24:07.650 --> 00:24:11.310\nKnow some of the basic scenarios in\nwhich you would use these protocols,\n\n459\n00:24:11.310 --> 00:24:14.010\nlike for\ninstance the authentication methods.\n\n460\n00:24:14.010 --> 00:24:16.960\nIf I want a higher level of protection,\n\n461\n00:24:16.960 --> 00:24:19.910\nthen chances are I'm going\nto use something like Peep.\n\n462\n00:24:19.910 --> 00:24:22.610\nAgain keep in mind that Peep is\nused in something like Comcha or\n\n463\n00:24:22.610 --> 00:24:26.550\nin connection with\nMSCHAPv2 a lot of times.\n\n464\n00:24:26.550 --> 00:24:31.075\nOne of the most common methods\nthat we have today is EAP-TLS.\n\n465\n00:24:31.075 --> 00:24:35.030\nKnow the scenarios in which you would\nthat, certificate based authentication.\n\n466\n00:24:35.030 --> 00:24:40.210\nAs well as, for instance, things like\nsmart card authentication and tokens.\n\n467\n00:24:40.210 --> 00:24:41.460\n&gt;&gt; All right, Wesley.\n\n468\n00:24:41.460 --> 00:24:44.250\nLot's going on when it comes\nto wireless protocols,\n\n469\n00:24:44.250 --> 00:24:47.250\nwireless access points,\njust wireless in general.\n\n470\n00:24:47.250 --> 00:24:48.747\nIt is a wireless world that\nwe're starting to live in.\n\n471\n00:24:48.747 --> 00:24:50.430\nI say start, we're there.\n\n472\n00:24:50.430 --> 00:24:51.750\nWe're in a wireless world.\n\n473\n00:24:51.750 --> 00:24:54.910\nNo one likes to plug in a cable, no one\nlikes dragging things and being tethered.\n\n474\n00:24:54.910 --> 00:24:58.070\nBeing connected to a bench somewhere,\nright?\n\n475\n00:24:58.070 --> 00:24:59.060\nWe liked our freedom.\n\n476\n00:24:59.060 --> 00:25:00.630\nWe like being able to walk around.\n\n477\n00:25:00.630 --> 00:25:01.844\nEverybody's got a smartphone.\n\n478\n00:25:01.844 --> 00:25:02.464\nWell, most people do.\n\n479\n00:25:02.464 --> 00:25:05.380\nAnd most people have a wireless\ndevice of some sort.\n\n480\n00:25:05.380 --> 00:25:06.780\nAnd it's very very nice.\n\n481\n00:25:06.780 --> 00:25:11.840\nBut, if we're gonna live in that world, we\nhave to learn how to secure it correctly,\n\n482\n00:25:11.840 --> 00:25:13.940\nespecially if it's\na corporate type environment.\n\n483\n00:25:13.940 --> 00:25:14.850\nEven your home networks,\n\n484\n00:25:14.850 --> 00:25:17.890\nyou don't want people accessing\nyour home wireless networks.\n\n485\n00:25:17.890 --> 00:25:21.040\nAnd, potentially,\naccessing your personal information.\n\n486\n00:25:21.040 --> 00:25:24.930\nSo let's do our due diligence,\nlearn about these security techniques and\n\n487\n00:25:24.930 --> 00:25:29.245\nprotocols and things to help us stay out\nof the woods when it comes to wireless.\n\n488\n00:25:29.245 --> 00:25:32.380\nWes, you're doing a great job\nof showing us what we can do.\n\n489\n00:25:32.380 --> 00:25:34.770\nWe do thank you for that, and\nwe do thank our audience for watching.\n\n490\n00:25:34.770 --> 00:25:38.130\nBut looking at the clock, looks like\nwe're about out of time for this episode.\n\n491\n00:25:38.130 --> 00:25:41.010\nSo signing off for ITProTV,\nI've been your host Daniel Lowrie.\n\n492\n00:25:41.010 --> 00:25:42.474\n&gt;&gt; And I'm Wes Bryan.\n&gt;&gt; And we'll see you next time.\n\n493\n00:25:42.474 --> 00:25:50.291\n[MUSIC]\n\n494\n00:25:50.291 --> 00:25:52.862\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "216502319"
        },
        {
          "description": "In this show Wes and Cherokee begin discussing public key infrastructure. Learn the basic design of a Certificate Authority hierarchy and learn terms such as CRL, OCSP and more!",
          "length": "1601",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-public_key_infrastructure-RESHOOT-041817-PGM.00_26_27_14.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-public_key_infrastructure-RESHOOT-041817-PGM.00_26_27_14.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-public_key_infrastructure-RESHOOT-041817-PGM.00_26_27_14.Still001-sm.jpg",
          "title": "Public Key Infrastructure",
          "transcript": "WEBVTT\n\n1\n00:00:01.170 --> 00:00:06.486\nWelcome to ITProTV,\nI'm your host Don- [CROSSTALK]\n\n2\n00:00:06.486 --> 00:00:09.030\n[MUSIC]\n\n3\n00:00:09.030 --> 00:00:11.010\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:12.170 --> 00:00:15.450\n&gt;&gt; Welcome ladies and gentlemen\nto your CompTIA Security+ series.\n\n5\n00:00:15.450 --> 00:00:17.580\nI'm your show host, Cherokee Boose.\n\n6\n00:00:17.580 --> 00:00:21.240\nIn this episode, we'll be looking at all\nthings public key infrastructure, and\n\n7\n00:00:21.240 --> 00:00:23.890\nwith us today in studio we have Mr.\nWes Bryan.\n\n8\n00:00:23.890 --> 00:00:24.870\nThank you for joining us, Wes.\n\n9\n00:00:24.870 --> 00:00:26.410\n&gt;&gt; Hey, thanks for\nhaving me back, Cherokee.\n\n10\n00:00:26.410 --> 00:00:30.350\nThat's right, we're going to be looking at\na PKI, or a Public Key Infrastructure as\n\n11\n00:00:30.350 --> 00:00:34.850\nmiss Cherokee points out, and\nIt is a very, very important component\n\n12\n00:00:34.850 --> 00:00:37.910\ninside of our networks in keeping our\nnetworks and communication secure.\n\n13\n00:00:37.910 --> 00:00:41.190\nSo, it is definitely something that\nyou're gonna have to be aware of for\n\n14\n00:00:41.190 --> 00:00:42.460\nyour Security Plus exam.\n\n15\n00:00:42.460 --> 00:00:44.050\nBut it's also something\nthat you should be very,\n\n16\n00:00:44.050 --> 00:00:48.210\nvery familiar with when it comes\nto just real world application.\n\n17\n00:00:48.210 --> 00:00:50.980\nAll right, so when we talk about public\nkey infrastructure, what we're talking\n\n18\n00:00:50.980 --> 00:00:56.970\nabout is a way to implement things\nlike public e-cryptology if you will,\n\n19\n00:00:56.970 --> 00:01:00.670\nkey pair encryption, asymmetric\nkey encryption as its also called.\n\n20\n00:01:00.670 --> 00:01:03.360\nAnd what we're gonna do is we're gonna\nlook through some of the components and\n\n21\n00:01:03.360 --> 00:01:04.370\nhow we implement this.\n\n22\n00:01:04.370 --> 00:01:08.580\nSo, let's say, we'll go right ahead and\nstart off right away with talking about,\n\n23\n00:01:08.580 --> 00:01:10.070\nwell, key pairs, right?\n\n24\n00:01:10.070 --> 00:01:13.530\nI've got a little diagram here, and when\nwe talk about public key infrastructure,\n\n25\n00:01:13.530 --> 00:01:18.370\nwe're talking about a way to implement,\ndistribute, manage and\n\n26\n00:01:18.370 --> 00:01:22.570\nmaintain certificates for things like\ncertificate-based authentication,\n\n27\n00:01:22.570 --> 00:01:23.460\nand key pair encryption.\n\n28\n00:01:23.460 --> 00:01:25.970\nSo, when we look at a certificate,\n\n29\n00:01:25.970 --> 00:01:29.360\na certificate is issued by something\nknown as a certificate authority.\n\n30\n00:01:29.360 --> 00:01:32.980\nInside of that certificate\ncontains a key pair.\n\n31\n00:01:32.980 --> 00:01:36.150\nThe key pair are basically\nmathematically aligned,\n\n32\n00:01:36.150 --> 00:01:39.760\nthese keys are used in conjunction\nwith each other, all right?\n\n33\n00:01:39.760 --> 00:01:42.700\nNow, they can Perform\na couple of functions,\n\n34\n00:01:42.700 --> 00:01:46.620\nthey can do encryption and\nthey can also do decryption.\n\n35\n00:01:46.620 --> 00:01:49.699\nNow, when we look at our cryptology\nbasics in another episode,\n\n36\n00:01:49.699 --> 00:01:53.577\nwe'll talk a little bit more about how\nthe encryption and the decryption happens\n\n37\n00:01:53.577 --> 00:01:57.362\nbecause what we really want to focus on\nhere is the public info structure side.\n\n38\n00:01:57.362 --> 00:02:01.507\nAnd just understanding that\nwhen the key pair is issued via\n\n39\n00:02:01.507 --> 00:02:04.805\na certificate to an end-user or\na machine, or\n\n40\n00:02:04.805 --> 00:02:08.910\na few other types of devices\nthat there is a public key.\n\n41\n00:02:08.910 --> 00:02:12.370\nAnd the public key in that certificate,\nreally the certificate is\n\n42\n00:02:12.370 --> 00:02:15.920\nthe way from then on how we\ncan distribute a public key.\n\n43\n00:02:15.920 --> 00:02:19.860\nSee, when we first get the certificate and\nwe distribute it to the endpoint or\n\n44\n00:02:19.860 --> 00:02:23.680\nthe user if you will,\nboth keys are in that certificate.\n\n45\n00:02:23.680 --> 00:02:28.630\nHowever, once the certificate is\ninstalled, typically on a machine.\n\n46\n00:02:28.630 --> 00:02:31.580\nThe private key, all right,\nthe private key is one that's called\n\n47\n00:02:31.580 --> 00:02:34.200\nthe private key because it's\nnever shared with anybody.\n\n48\n00:02:34.200 --> 00:02:38.320\nAnd then, from then on the public key is\ngoing to be shared to encrypt data and\n\n49\n00:02:38.320 --> 00:02:40.400\nit's shared via the certificate.\n\n50\n00:02:40.400 --> 00:02:44.080\nAll right, now,\nIf we look at some other components.\n\n51\n00:02:44.080 --> 00:02:46.860\nLet's talk about certificates in general.\n\n52\n00:02:46.860 --> 00:02:49.400\nWho are certificates issued by,\nif you will?\n\n53\n00:02:49.400 --> 00:02:53.900\nCertificates are issued by something\nknown as a certificate authority.\n\n54\n00:02:53.900 --> 00:02:58.200\nRight now, certificate authorities again\nare those machines that are set up with\n\n55\n00:02:58.200 --> 00:03:02.760\na PKI-based service, a cryptographic\nservice and again, they're responsible for\n\n56\n00:03:02.760 --> 00:03:06.710\nissuing certificates to other\nentities within our networks.\n\n57\n00:03:06.710 --> 00:03:10.210\nNow, they do form what's known\nas a hierarchy, all right?\n\n58\n00:03:10.210 --> 00:03:13.810\nAnd we have what are known as root\ncertificate authorities, all right?\n\n59\n00:03:13.810 --> 00:03:15.250\nI want you to think of things like DNS,\n\n60\n00:03:15.250 --> 00:03:17.120\nmaybe you're familiar with\nthe DNS hierarchy, right?\n\n61\n00:03:17.120 --> 00:03:18.960\nWe have the root DNS servers, right?\n\n62\n00:03:18.960 --> 00:03:20.680\nThe top part of the hierarchy and\n\n63\n00:03:20.680 --> 00:03:23.950\nthey're in charge of all the top\nlevel domains below them.\n\n64\n00:03:23.950 --> 00:03:28.690\nWell, I want you to think of almost like\nthe concept here, that we've got a root CA\n\n65\n00:03:28.690 --> 00:03:34.540\nand it forms the highest part of what's\nknown as a chain of trust, all right.\n\n66\n00:03:34.540 --> 00:03:38.610\nNow, this CA, the certificate authority,\n\n67\n00:03:38.610 --> 00:03:42.150\nsometimes it's called an offline\nCA as well and we'll get to that,\n\n68\n00:03:42.150 --> 00:03:45.530\nwhy we would want this to maybe\nbe offline here in a second.\n\n69\n00:03:45.530 --> 00:03:48.500\nThen, we have what are known\nas intermediate CAs.\n\n70\n00:03:48.500 --> 00:03:49.740\nNow, I put some other,\n\n71\n00:03:49.740 --> 00:03:53.340\nsome of the common names that we\nalso will hear them called too.\n\n72\n00:03:53.340 --> 00:03:55.610\nNot only will you hear them\ncalled intermediate again,\n\n73\n00:03:55.610 --> 00:03:58.940\ncuz they're not the top part of\nthe hierarchy, they're a lower level, but\n\n74\n00:03:58.940 --> 00:04:02.310\nthey're also called things like\nsubordinate CAs and why is that?\n\n75\n00:04:02.310 --> 00:04:05.070\nWell, they're subordinate to a higher\npart of the hierarchy if you will.\n\n76\n00:04:05.070 --> 00:04:10.160\nSo, these subordinate CAs if you will,\nbeing the second step in the hierarchy,\n\n77\n00:04:10.160 --> 00:04:12.560\nare subordinate to the root CAs.\n\n78\n00:04:12.560 --> 00:04:16.300\nThey're also called online CAs\nbecause typically they're online and\n\n79\n00:04:16.300 --> 00:04:20.240\nthey're doing what is known as issuing the\ncertificates to our different endpoints.\n\n80\n00:04:20.240 --> 00:04:25.500\nNow, when I say endpoints I mean users,\nwe can have user based certificates.\n\n81\n00:04:25.500 --> 00:04:28.790\nWe can have workstation or\ncomputer based certificates.\n\n82\n00:04:28.790 --> 00:04:33.220\nWe can also have things like for instance,\nwe can have network devices, right?\n\n83\n00:04:33.220 --> 00:04:40.100\nWhen we want to verify a network device's\nidentity, we can do identity verification.\n\n84\n00:04:40.100 --> 00:04:43.670\nThere's certificates, as well,\non our network devices.\n\n85\n00:04:43.670 --> 00:04:44.650\n&gt;&gt; So, what your saying, West,\n\n86\n00:04:44.650 --> 00:04:50.410\nis that our CAs are gonna be kind of like\nan issuer of a form of authentication, so\n\n87\n00:04:50.410 --> 00:04:56.490\nthey're verifying our identities, whether\nit be computers, users, or software.\n\n88\n00:04:56.490 --> 00:05:01.760\nAnd, what we're doing here is, especially\nin situations like mutual authentication.\n\n89\n00:05:01.760 --> 00:05:03.150\nThe user goes to log on, but\n\n90\n00:05:03.150 --> 00:05:06.080\nthen how do they trust that that server\nis sending legitimate information.\n\n91\n00:05:06.080 --> 00:05:07.630\nWell, this is that perfect solution.\n\n92\n00:05:07.630 --> 00:05:12.520\n&gt;&gt; Absolutely, and\nthat's where we have to check the servers,\n\n93\n00:05:12.520 --> 00:05:15.410\nif I present a drivers license\nto let's say law enforcement, or\n\n94\n00:05:15.410 --> 00:05:18.480\nmaybe I'm going up to the bank,\nwanna get access to my resources,\n\n95\n00:05:18.480 --> 00:05:22.080\nwhich is my money or\nlack therefor depending on the day, right?\n\n96\n00:05:22.080 --> 00:05:26.060\nI have to present my driver's\nlicense to the banking teller or\n\n97\n00:05:26.060 --> 00:05:27.460\nthe clerk if you will, right?\n\n98\n00:05:27.460 --> 00:05:30.900\nAnd why does he or\nshe trust that driver's license?\n\n99\n00:05:30.900 --> 00:05:34.400\nWell, they trust the authority that\nissued a driver's license, right?\n\n100\n00:05:34.400 --> 00:05:36.620\nSo, in my case we live here in Florida.\n\n101\n00:05:36.620 --> 00:05:40.500\nI have a Florida driver's license, right,\nand I had to go through series of checks\n\n102\n00:05:40.500 --> 00:05:43.700\nand balances in order to\nget my driver's license.\n\n103\n00:05:43.700 --> 00:05:48.510\nOnce I had satisfied whatever\nthe criteria were for one\n\n104\n00:05:48.510 --> 00:05:52.420\ngetting the license The State of Florida\nissued me that driver's license and\n\n105\n00:05:52.420 --> 00:05:56.530\nnow I can present that as\na form of identification.\n\n106\n00:05:56.530 --> 00:05:58.880\nSo, when I go up to a bank and\n\n107\n00:05:58.880 --> 00:06:02.610\nI need to get access to my money,\nI present my driver's license.\n\n108\n00:06:02.610 --> 00:06:05.730\nThey verify the information within\nthe driver's license and they trust and\n\n109\n00:06:05.730 --> 00:06:10.100\ngive me access to my banking information\nbecause they trust the authority that\n\n110\n00:06:10.100 --> 00:06:13.630\nissued that certificate, or in this case,\nthe driver's license, right?\n\n111\n00:06:13.630 --> 00:06:15.240\nSame thing with our military out there.\n\n112\n00:06:15.240 --> 00:06:19.300\nIf you guys, maybe some of you come from\nthe military that are watching right now,\n\n113\n00:06:19.300 --> 00:06:22.090\nyou have your common access card,\nyour CAC card and\n\n114\n00:06:22.090 --> 00:06:24.430\nthat has identifying\ninformation in it as well.\n\n115\n00:06:24.430 --> 00:06:26.530\nWell, why is that let's say an MP or\n\n116\n00:06:26.530 --> 00:06:30.380\nwherever you're going throughout a base,\nif you present that common access card.\n\n117\n00:06:30.380 --> 00:06:32.470\nWhy is it that it's trusted?\n\n118\n00:06:32.470 --> 00:06:36.480\nWell, they trust the Department of\nDefense, the authority if you will,\n\n119\n00:06:36.480 --> 00:06:40.260\nthe United States government that\nissued that common access card.\n\n120\n00:06:40.260 --> 00:06:43.810\nSo again, you have to understand that\nthis is all about a trust model and\n\n121\n00:06:43.810 --> 00:06:46.000\nwe have a series of\nauthorities that we trust and\n\n122\n00:06:46.000 --> 00:06:50.120\nits what allows us to secure\ne-commerce worldwide.\n\n123\n00:06:50.120 --> 00:06:54.890\nLet me give you a real-world\nexample of a root server here.\n\n124\n00:06:54.890 --> 00:06:56.660\nI'm on Google's website right here.\n\n125\n00:06:56.660 --> 00:07:02.310\nAnd it's interesting that you can see that\nwe're doing HTTPS here and it says secure.\n\n126\n00:07:02.310 --> 00:07:04.310\nWell, how do I know that it's secure?\n\n127\n00:07:04.310 --> 00:07:08.180\nWell, there's actually a certificate\nthat's been presented to the web browser\n\n128\n00:07:08.180 --> 00:07:10.800\nfrom Google's web server that says, here.\n\n129\n00:07:10.800 --> 00:07:13.250\nWe're Google, you can trust us.\n\n130\n00:07:13.250 --> 00:07:16.410\nWell how is it that my browser\nactually trusted this?\n\n131\n00:07:16.410 --> 00:07:18.530\n&gt;&gt; How do we know this\nis really happening?\n\n132\n00:07:18.530 --> 00:07:21.260\n&gt;&gt; That's right, how is it that\nthis isn't a hackers website?\n\n133\n00:07:22.460 --> 00:07:24.810\nWell we had to go through\nan inspection process.\n\n134\n00:07:24.810 --> 00:07:29.530\nAnd in that inspection process we can see\nthings like root certificate authorities,\n\n135\n00:07:29.530 --> 00:07:31.650\nCAs as they're called and\neven intermediate CAs.\n\n136\n00:07:31.650 --> 00:07:33.380\nLet me show you what I mean.\n\n137\n00:07:33.380 --> 00:07:36.120\nIf we drop back down to\nour developer options,\n\n138\n00:07:36.120 --> 00:07:39.660\nand every browser renders this\na little bit different and\n\n139\n00:07:39.660 --> 00:07:43.060\nhow you find this information can\nbe a little different as well.\n\n140\n00:07:43.060 --> 00:07:46.100\n&gt;&gt; I think you chose the most\ndifficult browser to demonstrate here.\n\n141\n00:07:46.100 --> 00:07:49.680\n&gt;&gt; Most, yeah, and let me show you what\nI mean, too, or what Cherokee means.\n\n142\n00:07:49.680 --> 00:07:52.896\nIt used to be very easy, right,\nand all we have to do, and\n\n143\n00:07:52.896 --> 00:07:56.450\nCherokee I know you remember this,\nwe can just click secure and\n\n144\n00:07:56.450 --> 00:08:00.340\nit would just give us certificate\nbased information right here.\n\n145\n00:08:00.340 --> 00:08:03.740\nWell, today they just say well,\nyour information is private.\n\n146\n00:08:03.740 --> 00:08:05.237\nWell, the browser trusted.\n\n147\n00:08:05.237 --> 00:08:07.140\nHow do you know that you can trust it?\n\n148\n00:08:07.140 --> 00:08:12.261\nWell, you can dig a little bit deeper\nhere, and we can go over here for instance\n\n149\n00:08:12.261 --> 00:08:18.200\nto the little ellipses button, go to\nMore Tools, and then Developers Options.\n\n150\n00:08:18.200 --> 00:08:23.147\nAnd in this drop down list right here\nyou'll see that there's Security, right?\n\n151\n00:08:23.147 --> 00:08:24.557\nIs it in there?\nNo, it's not in there.\n\n152\n00:08:26.499 --> 00:08:28.830\n&gt;&gt; Security is right to\nthe left of the arrows.\n\n153\n00:08:28.830 --> 00:08:29.720\n&gt;&gt; Yes yes yes, and you know,\n\n154\n00:08:29.720 --> 00:08:33.410\nit should be, it,\nlet me show you where it defaults to.\n\n155\n00:08:33.410 --> 00:08:36.640\nIt's going to default to elements,\nand all this crazy information.\n\n156\n00:08:36.640 --> 00:08:38.200\nAnd that's why security\nwasn't in the list,\n\n157\n00:08:38.200 --> 00:08:39.860\nbecause it was at the top of the list.\n\n158\n00:08:39.860 --> 00:08:43.280\nBut now, When you choose Security,\nI kinda did this before hand,\n\n159\n00:08:43.280 --> 00:08:46.800\nbecause I've been looking a lot at these\ncertificates in preparing for the show.\n\n160\n00:08:46.800 --> 00:08:50.650\nNotice there is this View\ncertificate button right here.\n\n161\n00:08:50.650 --> 00:08:55.990\nAnd then when we do that, we can see at a\nquick glance some basic information here.\n\n162\n00:08:55.990 --> 00:08:57.920\n&gt;&gt; Kinda looks like your\nhierarchical model Wes.\n\n163\n00:08:57.920 --> 00:08:58.650\n&gt;&gt; Most definitely.\n\n164\n00:08:58.650 --> 00:08:59.530\nSo what do we have here?\n\n165\n00:08:59.530 --> 00:09:03.380\nWe've got the host in this case it's\nthe web server that's saying hey yeah,\n\n166\n00:09:03.380 --> 00:09:05.530\nyou can trust us we're Google.\n\n167\n00:09:05.530 --> 00:09:07.310\nWell how do I know you can trust us?\n\n168\n00:09:07.310 --> 00:09:08.650\nWe're Google, what does that mean to me?\n\n169\n00:09:08.650 --> 00:09:12.060\nWell, the web browser actually looked at\nthe certificate and says, well I don't\n\n170\n00:09:12.060 --> 00:09:17.170\nknow if I trust Google, but let me figure\nout who issued Google their certificate.\n\n171\n00:09:17.170 --> 00:09:19.860\nWell this is kind of interesting because\nGoogle is big enough that they're also\n\n172\n00:09:19.860 --> 00:09:21.200\na certificate authority as well.\n\n173\n00:09:21.200 --> 00:09:26.100\nSo This is Google's Internet authority\nthat intermediate CA, right?\n\n174\n00:09:26.100 --> 00:09:30.560\nAnd basically Google saying you can trust\nus because we told you can trust us.\n\n175\n00:09:30.560 --> 00:09:33.910\nHowever, one of the things that I kind of\ncommend Google and some other companies\n\n176\n00:09:33.910 --> 00:09:38.870\nthat have become their own certificate\nauthorities, a lot of times above\n\n177\n00:09:38.870 --> 00:09:43.450\nwherever they're endorsing themselves,\nyou see a third-party endorsement as well.\n\n178\n00:09:43.450 --> 00:09:47.380\nIn this case it's GeoTrust Global CA,\nright?\n\n179\n00:09:47.380 --> 00:09:51.410\nThis is what is known as the root CA.\n\n180\n00:09:51.410 --> 00:09:58.970\nNow, that being said, what goes into\nwhat type of CAs are these called?\n\n181\n00:09:58.970 --> 00:10:01.900\nWell these are actually\nwhat are called public CAs,\n\n182\n00:10:01.900 --> 00:10:03.420\ncuz there is a little bit\nof a difference here.\n\n183\n00:10:03.420 --> 00:10:05.930\nWe have private CAs and\nwe have public CAs.\n\n184\n00:10:05.930 --> 00:10:09.240\nIn a public CA, let's say that\nI wanted the public, the world,\n\n185\n00:10:09.240 --> 00:10:13.190\nin this case I'm visiting\nGoogle's web browser,\n\n186\n00:10:13.190 --> 00:10:18.000\nI want the users that publicly have\naccess to this website, to trust this.\n\n187\n00:10:18.000 --> 00:10:19.170\n&gt;&gt; The people of the Internet.\n\n188\n00:10:19.170 --> 00:10:21.400\n&gt;&gt; The people of the Internet,\nvery good, well put.\n\n189\n00:10:21.400 --> 00:10:27.040\nSo if we have, we want a trust for\nthe public-facing side of the Internet,\n\n190\n00:10:27.040 --> 00:10:29.900\nthen what we have to do is\ngo to an external source,\n\n191\n00:10:29.900 --> 00:10:35.130\nan external third-party source,\nthat their entire business is based on\n\n192\n00:10:35.130 --> 00:10:39.690\na trust model and issuing out\ncertificates of trust if you will.\n\n193\n00:10:39.690 --> 00:10:43.990\n&gt;&gt; So when we go to these third parties,\nWes, we're kind of having them vouch for\n\n194\n00:10:43.990 --> 00:10:44.600\nour identity.\n\n195\n00:10:44.600 --> 00:10:48.070\nSo we may have to present some\nkind of identifying information.\n\n196\n00:10:48.070 --> 00:10:53.120\nDriver's license, any kind of tax\ninformation, address, fax number,\n\n197\n00:10:53.120 --> 00:10:56.920\nif anyone still uses fax today, but they\nhave different levels of assurance there,\n\n198\n00:10:56.920 --> 00:10:59.560\ndepending on what kind of\ncertificate you're trying to obtain.\n\n199\n00:10:59.560 --> 00:11:02.300\n&gt;&gt; Most definitely, and we'll get into\nthat too because that's coming up.\n\n200\n00:11:02.300 --> 00:11:06.410\nThat's part of domain validation, and\nit is, there are different levels of trust\n\n201\n00:11:06.410 --> 00:11:09.080\nAnd probably different\nlevels of price points too.\n\n202\n00:11:09.080 --> 00:11:11.630\nAnd speaking of price point,\nwhat if I wanted to or\n\n203\n00:11:11.630 --> 00:11:15.240\nwhat if Cherokee wanted to bring\nup her own web server, right?\n\n204\n00:11:15.240 --> 00:11:19.070\nAnd maybe give security advice,\ninfosec type information.\n\n205\n00:11:19.070 --> 00:11:23.530\nBut we wanna know that it's Cherokee's\nsite or in this case maybe my site.\n\n206\n00:11:23.530 --> 00:11:25.030\nI have to go to one of\nthese third-parties.\n\n207\n00:11:25.030 --> 00:11:27.220\nIn fact, if we go back to my screen here,\n\n208\n00:11:27.220 --> 00:11:31.160\nI can actually bump right on over\nto a company like GeoTrust, right?\n\n209\n00:11:31.160 --> 00:11:35.820\nAnd I can do things like, for instance,\nif their little pop-up menu will go away.\n\n210\n00:11:35.820 --> 00:11:38.600\nI can buy things like SSL certificates,\nright?\n\n211\n00:11:38.600 --> 00:11:40.990\nI can buy things like\nSigning Products if I want.\n\n212\n00:11:40.990 --> 00:11:46.286\nIf I have the money, I can provide\nthings like Enterprise based SSLs and\n\n213\n00:11:46.286 --> 00:11:49.770\nbuy ten certificates if you\nwill if that's what I need.\n\n214\n00:11:49.770 --> 00:11:51.150\nAnd they have different types.\n\n215\n00:11:51.150 --> 00:11:54.430\nAll different types and\nall different price points depending on\n\n216\n00:11:54.430 --> 00:11:59.020\nwhat it is that you need to accomplish\nas far as your trust model goes and\n\n217\n00:11:59.020 --> 00:12:02.730\nhaving people on the outside\nlooking back in, giving them\n\n218\n00:12:02.730 --> 00:12:07.910\nthe ability to trust that the website that\nyou present to them, is your website.\n\n219\n00:12:07.910 --> 00:12:09.840\n&gt;&gt; Wes, what if I don't have that money?\n\n220\n00:12:09.840 --> 00:12:14.065\nAnd what if I really don't want to\nvalidate the people of the Internet?\n\n221\n00:12:14.065 --> 00:12:16.825\nWhat if I just want to have\nsomething set up internally,\n\n222\n00:12:16.825 --> 00:12:18.255\nis there a solution for that?\n\n223\n00:12:18.255 --> 00:12:19.135\n&gt;&gt; Most definitely,\n\n224\n00:12:19.135 --> 00:12:23.045\nnow this is where we talk about what's\nknown are private CAs, right, and\n\n225\n00:12:23.045 --> 00:12:27.750\nif I have something like, for instance,\na Windows Server operating system, right?\n\n226\n00:12:27.750 --> 00:12:30.010\nI can set up in an Active Directory, and\n\n227\n00:12:30.010 --> 00:12:33.550\nit's not contingent on Active Directory\nbut that's the most common implementation.\n\n228\n00:12:33.550 --> 00:12:36.430\nI mean come one, let's face it, if you're\nin an enterprise and you've got a Windows\n\n229\n00:12:36.430 --> 00:12:40.980\nbased software, you're typically gonna be\nimplementing an Active Directory solution.\n\n230\n00:12:40.980 --> 00:12:43.560\nHowever, just for conversation purposes,\n\n231\n00:12:43.560 --> 00:12:46.510\nunderstand you don't need\nActive Directory to implement it.\n\n232\n00:12:46.510 --> 00:12:48.090\nBut let's say that's what I have, right?\n\n233\n00:12:48.090 --> 00:12:52.260\nI have a Windows domain inside of my\nenterprise network and I need to have some\n\n234\n00:12:52.260 --> 00:12:56.800\ntype of certificate-based authentication,\nbut like Cherokee, back to your question,\n\n235\n00:12:56.800 --> 00:13:00.490\nis I don't care if the outside\ntrusts it or not, right?\n\n236\n00:13:00.490 --> 00:13:03.040\nIt's only for the internal purposes.\n\n237\n00:13:03.040 --> 00:13:06.290\nWell, that's when we set up\nwhat's known as a private PKI,\n\n238\n00:13:06.290 --> 00:13:09.650\na private based public key infrastructure.\n\n239\n00:13:09.650 --> 00:13:12.080\nNow, I want you to understand that\nthe concepts are just the same.\n\n240\n00:13:12.080 --> 00:13:13.860\nIt's where the trust lies, right?\n\n241\n00:13:13.860 --> 00:13:16.725\nIf we go to a public CA,\nand we purchase, right,\n\n242\n00:13:16.725 --> 00:13:21.615\nthey're gonna endorse their\ngiving you that trust, right?\n\n243\n00:13:21.615 --> 00:13:23.955\nGiving others that trust,\nthey're gonna endorse that.\n\n244\n00:13:23.955 --> 00:13:28.035\nAnd they're gonna back that up that\nif malicious activities happen,\n\n245\n00:13:28.035 --> 00:13:32.505\nwell of course, you as the owner of that\ncertificate are going to be responsible.\n\n246\n00:13:32.505 --> 00:13:35.420\nBut they're also gonna endorse it,\nand ensure it, and back it up.\n\n247\n00:13:35.420 --> 00:13:39.194\nBut that's a lot to go through if I only\nneed to present a certificate let's say to\n\n248\n00:13:39.194 --> 00:13:41.932\ndo certificate based\nauthentication within my network.\n\n249\n00:13:41.932 --> 00:13:46.758\nSo in that case what I do is I bring\nup a public excuse me a private PKI all\n\n250\n00:13:46.758 --> 00:13:50.480\nthe same components,\nall the same concepts.\n\n251\n00:13:50.480 --> 00:13:52.450\nBut they're not trusted\nby the outside world.\n\n252\n00:13:52.450 --> 00:13:53.370\nAnd then in this way,\n\n253\n00:13:53.370 --> 00:13:57.290\nwhat I can do is I can ensure that my\ninternal company can use things like\n\n254\n00:13:57.290 --> 00:14:01.010\ncertificate based authentication,\npublic key encryption if you will.\n\n255\n00:14:01.010 --> 00:14:03.100\nAnd we distribute public and private keys.\n\n256\n00:14:03.100 --> 00:14:04.940\nWe can do things like code signing.\n\n257\n00:14:04.940 --> 00:14:06.270\nThere's another thing, for instance,\n\n258\n00:14:06.270 --> 00:14:10.500\nwe might have application development\ngoing on inside of our network, right?\n\n259\n00:14:11.580 --> 00:14:15.898\nIf i want that application, to be pushed\nout to the public world, well guess what?\n\n260\n00:14:15.898 --> 00:14:17.448\nI have to go to a public C.A and\n\n261\n00:14:17.448 --> 00:14:20.410\nwhat i have to do is get\na code signing certificate.\n\n262\n00:14:20.410 --> 00:14:23.020\nAnd we have to digitally sign,\nwith the certificate,\n\n263\n00:14:23.020 --> 00:14:26.900\nthat's issued to us,\nthe application that we're using, right.\n\n264\n00:14:26.900 --> 00:14:29.830\nAnd then we have to submit that\napplication out there to the different\n\n265\n00:14:29.830 --> 00:14:35.960\nvarious application stores if you will\nIn order for it to be trusted worldwide.\n\n266\n00:14:35.960 --> 00:14:37.980\nBut if I'm doing internal\napplication development,\n\n267\n00:14:37.980 --> 00:14:39.350\nI don't need to go through that process.\n\n268\n00:14:39.350 --> 00:14:43.700\nWhat I need to do is est up the PKI,\nissue a code signing certificate,\n\n269\n00:14:43.700 --> 00:14:48.280\ncode sign my application, and\njust distribute it to the employees.\n\n270\n00:14:48.280 --> 00:14:51.640\nAgain, I'm not worried if\nthe outside can be trusted or not.\n\n271\n00:14:51.640 --> 00:14:52.990\nSo a couple of different models.\n\n272\n00:14:52.990 --> 00:14:55.720\nKeep in mind the concepts are the same.\n\n273\n00:14:55.720 --> 00:14:58.840\nIt's just where does the trust lie?\n\n274\n00:14:58.840 --> 00:15:02.220\nIf it's a private PKI, the trust\nlies only within your organization.\n\n275\n00:15:02.220 --> 00:15:04.400\nIt's not gonna be trusted\nby the outside world.\n\n276\n00:15:04.400 --> 00:15:07.340\nSo for instance, if Cherokee's got\na company that she works for and\n\n277\n00:15:07.340 --> 00:15:08.980\nI got a company that I work for.\n\n278\n00:15:08.980 --> 00:15:13.066\nAnd we both bring PKIs up, private PKIs,\nmy certificates aren't gonna be trusted by\n\n279\n00:15:13.066 --> 00:15:16.316\nher network and her certificate\nare gonna be trusted by my network.\n\n280\n00:15:16.316 --> 00:15:21.561\nHowever if we both put public\nfacing web server in a DMZ and\n\n281\n00:15:21.561 --> 00:15:29.080\nwe go to a public CA and we both get\ncertificates on our public facing website.\n\n282\n00:15:29.080 --> 00:15:32.700\nNow they are gonna be trusted by\nthe various web browser out there\n\n283\n00:15:32.700 --> 00:15:34.230\namongst in the internet.\n\n284\n00:15:34.230 --> 00:15:37.640\nAnd speaking of the trust they have\namongst the Internet if you will,\n\n285\n00:15:37.640 --> 00:15:39.220\nwhere does that information get stored?\n\n286\n00:15:39.220 --> 00:15:43.650\nWhy is it that my computer really even\ntrusts a certificate that is being\n\n287\n00:15:43.650 --> 00:15:44.740\npresented to it?\n\n288\n00:15:44.740 --> 00:15:48.745\nWell, that's where you have on\nyour certain, your machines,\n\n289\n00:15:48.745 --> 00:15:51.721\nwhat's known as a certificate store,\nright?\n\n290\n00:15:51.721 --> 00:15:55.228\nA certificate store is just a place\nwhere we store, essentially,\n\n291\n00:15:55.228 --> 00:15:59.350\npublic certificates that we\ntrust out there on the Internet.\n\n292\n00:15:59.350 --> 00:16:02.732\nAnd they are baked into your\noperating systems by default.\n\n293\n00:16:02.732 --> 00:16:03.910\nI'm on a Windows 10 machine.\n\n294\n00:16:03.910 --> 00:16:06.250\nLet me show you where you could\nactually see that information on\n\n295\n00:16:06.250 --> 00:16:07.170\na Windows 10 machine.\n\n296\n00:16:07.170 --> 00:16:10.990\nIf I drop down to the Cortana\nsearch engine here, and\n\n297\n00:16:10.990 --> 00:16:14.910\nI bring up an MMC,\nMicrosoft Management Console, right?\n\n298\n00:16:14.910 --> 00:16:18.130\nI can actually see what the local\ncertificate store is here.\n\n299\n00:16:18.130 --> 00:16:21.030\nWe'll do a little Ctrl+M and\nwe'll add our Snap-in.\n\n300\n00:16:21.030 --> 00:16:25.330\nAnd notice that my Snap-in that I'm\nadding, it's called Certificates, right?\n\n301\n00:16:25.330 --> 00:16:26.040\nHow convenient.\n\n302\n00:16:26.040 --> 00:16:28.700\nIf I wanna view the certificates store\nthey give me a snap in that's called\n\n303\n00:16:28.700 --> 00:16:29.880\ncertificates.\n\n304\n00:16:29.880 --> 00:16:32.440\nMakes it kind of obvious\nas to what that's gonna do.\n\n305\n00:16:32.440 --> 00:16:37.000\nBut I do have, as long as I don't get\nclick happy [LAUGH], now when I hit add,\n\n306\n00:16:37.000 --> 00:16:38.440\nI actually have a couple of options.\n\n307\n00:16:38.440 --> 00:16:40.270\nAnd this is what I want to talk about.\n\n308\n00:16:40.270 --> 00:16:40.980\nRight?\n\n309\n00:16:40.980 --> 00:16:42.520\nWho can get certificates?\n\n310\n00:16:42.520 --> 00:16:45.920\nWell, in this case,\nthink about who logs into a machine.\n\n311\n00:16:45.920 --> 00:16:47.660\nRight?\nWell, the user logs into the machine, so\n\n312\n00:16:47.660 --> 00:16:50.120\na user can have a certificate.\n\n313\n00:16:50.120 --> 00:16:52.910\nBut the machine itself can\nalso have a certificate.\n\n314\n00:16:52.910 --> 00:16:56.330\nFor instance, if we're doing IP set\ncommunications and we want to make it\n\n315\n00:16:56.330 --> 00:17:00.050\nabout as secure as we can, we can do\ncertificate-based authentication and\n\n316\n00:17:00.050 --> 00:17:02.700\nthen I have to issue\na certificate to the machine, or\n\n317\n00:17:02.700 --> 00:17:05.260\nin this case,\nwhat's called a computer account.\n\n318\n00:17:05.260 --> 00:17:07.920\nBut you can also authenticate\neven services as well.\n\n319\n00:17:07.920 --> 00:17:10.830\nBut these are two of the primary\nones that we really wanna look at,\n\n320\n00:17:10.830 --> 00:17:12.160\nat least at the security plus level.\n\n321\n00:17:12.160 --> 00:17:14.310\nAs you go on to more advanced studies,\n\n322\n00:17:14.310 --> 00:17:17.210\nyou're gonna learn all different things\nthat you can do with these certificates.\n\n323\n00:17:17.210 --> 00:17:20.590\nBut for this purpose, I'm gonna go ahead\nand I'm gonna choose the computer account.\n\n324\n00:17:21.780 --> 00:17:25.890\nAnd I'm gonna choose next, and\nwe'll choose finish, all right.\n\n325\n00:17:25.890 --> 00:17:28.980\nAnd that, let me make sure\nthat did add that, all right.\n\n326\n00:17:28.980 --> 00:17:31.780\nAnd adds the certificate to our snap-in,\nand\n\n327\n00:17:31.780 --> 00:17:34.270\nyou can notice that it\nsays local computer.\n\n328\n00:17:34.270 --> 00:17:37.090\nAnd we'll choose OK, all right.\n\n329\n00:17:37.090 --> 00:17:41.290\nNow that we have that snap in in place\nyou'll see that I have Certificates and\n\n330\n00:17:41.290 --> 00:17:45.810\nnotice that if it was user it would say\nthe user, local user here or in this\n\n331\n00:17:45.810 --> 00:17:49.970\ncase it says Local Computer and I'm gonna\ngo ahead and I'm gonna expand this out and\n\n332\n00:17:49.970 --> 00:17:54.600\nI want you to notice that there are a\nquite a few different locations in here.\n\n333\n00:17:54.600 --> 00:17:57.700\nSome of these we're concerned about,\nsome on them, eh, maybe not so\n\n334\n00:17:57.700 --> 00:18:02.440\nmuch that we are concerned with, but the\nones that I really wanna talk about is,\n\n335\n00:18:02.440 --> 00:18:09.030\nwhy is it that when my, in this case, my\nweb browser goes to a website out there,\n\n336\n00:18:09.030 --> 00:18:13.310\nit says, okay, I trust,\nin this case, GeoTrust.\n\n337\n00:18:13.310 --> 00:18:16.010\nI know it's a little redundant\nin the name, I trust that.\n\n338\n00:18:16.010 --> 00:18:20.800\nWell that's because your web browser\nactually looked at this certificate store\n\n339\n00:18:20.800 --> 00:18:24.280\nand looked in\nTrusted Root Certification Authorities.\n\n340\n00:18:24.280 --> 00:18:26.300\nSo I'm gonna mess this\nup every time cuz I'm so\n\n341\n00:18:26.300 --> 00:18:29.680\nused to saying certificate authority.\n\n342\n00:18:29.680 --> 00:18:31.150\nAnd this one always catches me up.\n\n343\n00:18:31.150 --> 00:18:34.850\nIt's just semantics here but\nthey say certification authority.\n\n344\n00:18:34.850 --> 00:18:37.240\nAnd if I expand this out and\nchoose certificate.\n\n345\n00:18:37.240 --> 00:18:41.920\nYou're gonna see that there's quite a few\ncertificates that are here already, right?\n\n346\n00:18:41.920 --> 00:18:46.960\nAnd these are the top of the hierarchy,\nright?\n\n347\n00:18:46.960 --> 00:18:51.930\nAnd these are the ones that Microsoft\nhave known to already trust.\n\n348\n00:18:51.930 --> 00:18:58.760\nSo they're already included, if you will,\ninside of our local certificate store.\n\n349\n00:18:58.760 --> 00:19:03.140\n&gt;&gt; And so Wes, we have some really great\nactivity going on in the chat today.\n\n350\n00:19:03.140 --> 00:19:06.610\nAnd they're also using some shortcuts\nthat you can use in your run line\n\n351\n00:19:06.610 --> 00:19:08.660\nto go ahead and pull up this store.\n\n352\n00:19:08.660 --> 00:19:10.920\nAnd then just shortcuts\nto that MMC as well.\n\n353\n00:19:10.920 --> 00:19:14.660\nSo guys, just know that there are little\ndetails there that you can check out.\n\n354\n00:19:14.660 --> 00:19:16.530\nIt's pretty cool that the way\nthat they've integrated this\n\n355\n00:19:16.530 --> 00:19:17.470\nall into the operating system.\n\n356\n00:19:17.470 --> 00:19:22.060\n&gt;&gt; Most definitely and I tell you,\nI appreciate six different ways to get to\n\n357\n00:19:22.060 --> 00:19:25.100\none thing and\nAs much as it does sound like a joke,\n\n358\n00:19:25.100 --> 00:19:29.430\nI'm serious, because I will tell you that\nMurphy's Law states that the one way.\n\n359\n00:19:29.430 --> 00:19:30.690\nYou see, and I just did MMC.\n\n360\n00:19:30.690 --> 00:19:35.580\nAnd if we do something like certlm.msc,\nanother great way to do this, right?\n\n361\n00:19:35.580 --> 00:19:37.160\nI can do certsrv.\n\n362\n00:19:37.160 --> 00:19:39.600\nAnd let me see if certsrv is still here.\n\n363\n00:19:39.600 --> 00:19:41.430\nCertsrv used to be one that was in here.\n\n364\n00:19:41.430 --> 00:19:43.595\nAnd I can do certsrv.\n\n365\n00:19:43.595 --> 00:19:47.190\n&gt;&gt; .msc, I think,\nmaybe it's not there anymore but\n\n366\n00:19:47.190 --> 00:19:50.260\nit used to be or mgr maybe it is.\n\n367\n00:19:50.260 --> 00:19:51.120\n&gt;&gt; Which one.\n\n368\n00:19:51.120 --> 00:19:56.480\n&gt;&gt; That's it, there it is, assertmgr.msc\nagain is another one that you'll see\n\n369\n00:19:56.480 --> 00:19:58.400\npretty much does the exact same thing.\n\n370\n00:19:58.400 --> 00:20:00.440\nSo couple different ways\nthat I've done it as well.\n\n371\n00:20:00.440 --> 00:20:02.130\nWe also got another way in the chat room.\n\n372\n00:20:02.130 --> 00:20:05.280\nAnd that is a good point for the exam.\n\n373\n00:20:05.280 --> 00:20:07.680\nThat's why I'm glad it\nwas mentioned because\n\n374\n00:20:09.110 --> 00:20:12.730\nyou have to prove that you've been\nin some of these locations before.\n\n375\n00:20:12.730 --> 00:20:16.290\nAnd like I said, Murphy's law states that\nthe one way you know how to get there most\n\n376\n00:20:16.290 --> 00:20:20.260\nlikely might not be the way that they\ntell you to get there on the exam.\n\n377\n00:20:20.260 --> 00:20:23.580\nSo definitely know that and\nespecially if it's a text based answer.\n\n378\n00:20:23.580 --> 00:20:25.550\nIf it's a text based answer.\n\n379\n00:20:25.550 --> 00:20:28.530\nYou'll just have to know,\nthat that's how you get there.\n\n380\n00:20:28.530 --> 00:20:30.930\nSo you can see that these\nare the root authorities, right?\n\n381\n00:20:30.930 --> 00:20:34.520\nThese are the certificate authorities\nthat we trust by default, right?\n\n382\n00:20:34.520 --> 00:20:36.000\nVeriSign is one that's in there.\n\n383\n00:20:36.000 --> 00:20:37.920\n&gt;&gt; See a lot of trust-type names, too.\n\n384\n00:20:37.920 --> 00:20:39.520\n&gt;&gt; Lot of trust names.\n\n385\n00:20:39.520 --> 00:20:42.810\nAnd that's a great point, just because\nof the fact that it's all about trust,\n\n386\n00:20:42.810 --> 00:20:43.690\nthis is a trust model.\n\n387\n00:20:45.040 --> 00:20:48.410\nSo these are our route authorities, right?\n\n388\n00:20:48.410 --> 00:20:52.900\nLet me give you an example of some of the\ndifferent things that you can use these\n\n389\n00:20:52.900 --> 00:20:57.030\ncertificates for, because they do call\nout a bunch of different ones, right?\n\n390\n00:20:57.030 --> 00:21:00.690\nBut I can use this for\nuser's machines and computers,\n\n391\n00:21:00.690 --> 00:21:04.180\nnetwork devices,\nstorage area networks, right?\n\n392\n00:21:04.180 --> 00:21:05.520\nApplications, right?\n\n393\n00:21:05.520 --> 00:21:07.378\nNow, what they call out as code designing,\nbut\n\n394\n00:21:07.378 --> 00:21:09.240\nI want you to know it's the same thing,\nright?\n\n395\n00:21:09.240 --> 00:21:10.590\nYour application is a piece of code.\n\n396\n00:21:10.590 --> 00:21:12.190\nLet me show you what I mean here.\n\n397\n00:21:12.190 --> 00:21:16.190\nOne of the ones that I really like is\nthe Microsoft Root Authority, right?\n\n398\n00:21:16.190 --> 00:21:19.980\nWhen you download a Microsoft product,\nand it installs,\n\n399\n00:21:19.980 --> 00:21:23.525\nand it doesn't give you a lot of\nhassle about the installation process,\n\n400\n00:21:23.525 --> 00:21:26.745\nit's because it's a Microsoft\nbased binary, right?\n\n401\n00:21:26.745 --> 00:21:29.095\nIt's gone through a various\nrigorous process and\n\n402\n00:21:29.095 --> 00:21:31.535\ntesting just like things their drivers do.\n\n403\n00:21:31.535 --> 00:21:34.925\nThey go through things like the Windows\nhardware quality assurance labs.\n\n404\n00:21:34.925 --> 00:21:38.715\nWell, Microsoft puts certain\nproducts through a rigorous test and\n\n405\n00:21:38.715 --> 00:21:40.810\nthen digitally signs them.\n\n406\n00:21:40.810 --> 00:21:42.610\nAnd we trust them by default.\n\n407\n00:21:42.610 --> 00:21:44.470\nLet me show you some of\nthe different options.\n\n408\n00:21:44.470 --> 00:21:48.470\nIf you just right-click on the root\nauthority, and you choose Properties,\n\n409\n00:21:48.470 --> 00:21:53.110\nyou'll get a whole bunch of potentially,\nand I'm not gonna actually enable these.\n\n410\n00:21:53.110 --> 00:21:55.580\nI'm only doing this so\nwe can scroll through here.\n\n411\n00:21:55.580 --> 00:21:58.440\nBut look at some of\nthe different options you have,\n\n412\n00:21:58.440 --> 00:22:02.580\nwhen it comes to the purposes\nof a certificate, right?\n\n413\n00:22:02.580 --> 00:22:05.620\nYou could see things like server\nauthentication and client authentication.\n\n414\n00:22:05.620 --> 00:22:06.250\nIn fact.\n&gt;&gt; Pretty cool.\n\n415\n00:22:06.250 --> 00:22:08.030\n&gt;&gt; We're gonna look at\nGoogle's certificate and\n\n416\n00:22:08.030 --> 00:22:11.360\nyou can actually see this in the key\nusage statement that's right there\n\n417\n00:22:11.360 --> 00:22:15.350\nstamped into the certificate that\nGoogle is presenting the web browser.\n\n418\n00:22:15.350 --> 00:22:17.110\nSo for instance, secure emails, right?\n\n419\n00:22:17.110 --> 00:22:21.580\nWe talked about S Mime, well, S Mime\nis based on public ecryptology, right?\n\n420\n00:22:21.580 --> 00:22:24.199\nAnd public key infrastructure if you will.\n\n421\n00:22:24.199 --> 00:22:25.487\n&gt;&gt; Using certificates.\n\n422\n00:22:25.487 --> 00:22:29.480\n&gt;&gt; That's right, time stamping,\nIP Sec, we talked about IP Sec,\n\n423\n00:22:29.480 --> 00:22:32.190\nwe can use that a way in\nencrypting file system,\n\n424\n00:22:32.190 --> 00:22:36.325\nEFS right we can use this as EFS and\nI am talking about.\n\n425\n00:22:36.325 --> 00:22:38.685\nAll certificates can be used for\nthese different purposes.\n\n426\n00:22:38.685 --> 00:22:40.585\nSome of them are specific to Microsoft but\nfor\n\n427\n00:22:40.585 --> 00:22:43.665\nthe most part,\nwe can do a lot of different things here.\n\n428\n00:22:43.665 --> 00:22:46.465\nDigital Rights, if you're doing DRM,\nDigital Rights Management.\n\n429\n00:22:46.465 --> 00:22:50.155\nFor instance, inside Active Directory\nthere's Active Directory RMS, right,\n\n430\n00:22:50.155 --> 00:22:52.230\nrequires certificates as well.\n\n431\n00:22:52.230 --> 00:22:54.430\nI didn't see, did I pass it?\n\n432\n00:22:54.430 --> 00:22:55.620\nYeah, it's the third one on the list.\n\n433\n00:22:55.620 --> 00:22:58.160\nBoy, I'm glad it wasn't a snake,\nI'd have been bit.\n\n434\n00:22:58.160 --> 00:22:59.600\nCode signing, right?\n\n435\n00:22:59.600 --> 00:23:01.260\nWhat does code signing do for us?\n\n436\n00:23:01.260 --> 00:23:03.680\nWell, let me kind of show\nyou what code signing is.\n\n437\n00:23:03.680 --> 00:23:06.950\nIf an application has been\nsigned with a code, and in fact,\n\n438\n00:23:06.950 --> 00:23:09.710\nlet me just cancel that, minimize it,\nwe'll get back to it in a second.\n\n439\n00:23:09.710 --> 00:23:12.750\nSo for instance, I've got an open\nsource piece of software here.\n\n440\n00:23:12.750 --> 00:23:14.360\nMaybe you've recognized this, maybe not.\n\n441\n00:23:14.360 --> 00:23:16.070\nIt's called Notepad++.\n\n442\n00:23:16.070 --> 00:23:17.600\nI trust this application.\n\n443\n00:23:17.600 --> 00:23:21.210\nCherokee, I'm sure you've probably used\nit once or twice in your history here.\n\n444\n00:23:21.210 --> 00:23:26.535\nBut I trust it, how does the operating\nsystem know that it should trust it.\n\n445\n00:23:26.535 --> 00:23:28.345\nWell, I don't know, let's find out.\n\n446\n00:23:28.345 --> 00:23:31.585\nAll right, understand that it does\ntake an administrative effort, yeah,\n\n447\n00:23:31.585 --> 00:23:34.385\nor privilege if you will,\nto install this application.\n\n448\n00:23:34.385 --> 00:23:37.385\nBut notice the User Account Control\ncomes up right away and\n\n449\n00:23:37.385 --> 00:23:40.735\nsays, are you sure you trust this?\n\n450\n00:23:40.735 --> 00:23:44.925\nWell again, I'm downloading from\ntrusted installation sources, right?\n\n451\n00:23:44.925 --> 00:23:49.070\nBut the machine is doing something\na little bit more than that.\n\n452\n00:23:49.070 --> 00:23:54.856\nNotice that it tells me,\nVerified publisher: Notepad++.\n\n453\n00:23:54.856 --> 00:23:56.254\nHow's it verified?\n\n454\n00:23:56.254 --> 00:24:01.150\nWell, look at this little task link,\nif I choose show details, all right?\n\n455\n00:24:01.150 --> 00:24:04.910\nIt says show information about\npublisher's certificate.\n\n456\n00:24:04.910 --> 00:24:07.260\nRemember we talked about code signing,\nright?\n\n457\n00:24:07.260 --> 00:24:09.991\nWell, if I show the information,\nguess what?\n\n458\n00:24:09.991 --> 00:24:13.141\nBoy, we get a certificate that's\nfollowing the same format,\n\n459\n00:24:13.141 --> 00:24:14.695\nindustry wide standard here.\n\n460\n00:24:14.695 --> 00:24:17.160\nAnd if I look at the details, right?\n\n461\n00:24:18.380 --> 00:24:21.710\nActually it's probably right here, yeah,\nthere we go it's right there on the list.\n\n462\n00:24:21.710 --> 00:24:24.440\nThe certificate is intended for\nthe following purposes.\n\n463\n00:24:24.440 --> 00:24:27.980\nIt ensures software came from\nthe software publisher and\n\n464\n00:24:27.980 --> 00:24:30.810\nit protects the software from alteration.\n\n465\n00:24:30.810 --> 00:24:37.280\nSo not only are we using this as a\nauthentication or proof of origin, right?\n\n466\n00:24:37.280 --> 00:24:39.840\nWe're also using it as a way to\n\n467\n00:24:41.400 --> 00:24:45.330\nverify that the integrity of\nthe application has been maintained.\n\n468\n00:24:45.330 --> 00:24:47.380\nSo certificates are very,\n\n469\n00:24:47.380 --> 00:24:51.960\nvery good when it comes to providing\nwho the identity of the publisher.\n\n470\n00:24:51.960 --> 00:24:54.910\nAnd then also providing\na way that we could do\n\n471\n00:24:54.910 --> 00:24:57.970\nhashing algorithms on it\nto verify the integrity.\n\n472\n00:24:57.970 --> 00:25:03.620\nSo we get that middle part if\nyou will of the CIA triad.\n\n473\n00:25:03.620 --> 00:25:06.190\n&gt;&gt; Yeah, it can kind of give us\na little bit of relief there,\n\n474\n00:25:06.190 --> 00:25:09.080\nknowing that this publisher took\nthose extra steps to go ahead and\n\n475\n00:25:09.080 --> 00:25:11.910\nbecome authenticated and\nproviding us that integrity as well.\n\n476\n00:25:11.910 --> 00:25:12.630\nPretty cool, Wes.\n\n477\n00:25:12.630 --> 00:25:17.490\n&gt;&gt; Absolutely, so\nat this point my computer trusts it.\n\n478\n00:25:17.490 --> 00:25:19.970\nMy computer says based\non this certificate, and\n\n479\n00:25:19.970 --> 00:25:23.380\nif we can check out my computer\njust one more time there,\n\n480\n00:25:23.380 --> 00:25:28.370\nyou'll see that it says ensures this\nsoftware came from the software publisher.\n\n481\n00:25:28.370 --> 00:25:33.190\nIn this case, the verified, oop,\na little bit outside there.\n\n482\n00:25:33.190 --> 00:25:37.570\nThe verified publisher just happens\nto be Notepad++ and the makers of it.\n\n483\n00:25:37.570 --> 00:25:41.900\nAnd it also verifies in this case\nwhere it's gonna be installed, right?\n\n484\n00:25:41.900 --> 00:25:46.765\nSo keep in mind that when you install\nany application that basically,\n\n485\n00:25:46.765 --> 00:25:48.908\nyou can verify the publisher,\n\n486\n00:25:48.908 --> 00:25:53.772\nit means it's had one of these\ncertificates in their internal PKI, or\n\n487\n00:25:53.772 --> 00:25:59.230\nin this case it's a public certificate\nthat has been issued by an external CA.\n\n488\n00:25:59.230 --> 00:26:02.927\nSo that when I download this\napplication and I then run it,\n\n489\n00:26:02.927 --> 00:26:06.632\nI can verify that it didn't\ncome from hacker come lately.\n\n490\n00:26:06.632 --> 00:26:10.628\nAnd it doesn't have all the bugs and\nthe malicious code, if you will,\n\n491\n00:26:10.628 --> 00:26:14.510\nembedded in it, and we can verify\nthat it is what we expected to see.\n\n492\n00:26:15.550 --> 00:26:17.250\n&gt;&gt; All right, Wes.\nThat was a lot of information.\n\n493\n00:26:17.250 --> 00:26:18.740\nBut, ladies and gentlemen, stay tuned.\n\n494\n00:26:18.740 --> 00:26:22.070\nWe have so much more to cover\nhere with our PKI infrastructure.\n\n495\n00:26:22.070 --> 00:26:24.390\nFor this show, though,\nwe'll go ahead and sign out.\n\n496\n00:26:24.390 --> 00:26:25.720\nI'm your host, Cherokee Boose.\n\n497\n00:26:25.720 --> 00:26:26.374\n&gt;&gt; And I'm Wes Bryan.\n\n498\n00:26:26.374 --> 00:26:29.632\n&gt;&gt; Se you next time here at ITProTV.\n\n499\n00:26:29.632 --> 00:26:35.688\n[MUSIC]\n\n500\n00:26:35.688 --> 00:26:38.509\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "214509254"
        },
        {
          "description": "In this show Cherokee and Wes continue discussing Public Key Infrastructure. First, they examine components for validation followed by additional concepts such as certificate pinning, key escrow and wildcards. Next, they look at different levels of validation and certificate formats.",
          "length": "1927",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-2-public_key_infrastructure_pt2-041817-PGM.00_31_53_06.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-2-public_key_infrastructure_pt2-041817-PGM.00_31_53_06.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-2-public_key_infrastructure_pt2-041817-PGM.00_31_53_06.Still001-sm.jpg",
          "title": "Public Key Infrastructure Part 2",
          "transcript": "WEBVTT\n\n1\n00:00:00.029 --> 00:00:02.759\nWelcome to ITProTV, I'm your host Don.\n\n2\n00:00:02.759 --> 00:00:10.580\n[CROSSTALK]\n&gt;&gt; You're watching ITProTV.\n\n3\n00:00:10.580 --> 00:00:14.132\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n4\n00:00:14.132 --> 00:00:15.762\nI'm your show host Cherokee Boose.\n\n5\n00:00:15.762 --> 00:00:18.045\nThis episode is\na continuation where Wes and\n\n6\n00:00:18.045 --> 00:00:21.140\nI were previously discussing\npublic key infrastructure.\n\n7\n00:00:21.140 --> 00:00:24.164\nAnd back in studios today we have Mr.\nWes Bryan himself.\n\n8\n00:00:24.164 --> 00:00:25.660\nThank you for joining us, Wes.\n\n9\n00:00:25.660 --> 00:00:27.044\n&gt;&gt; Hey Cherokee,\nthanks for having me back.\n\n10\n00:00:27.044 --> 00:00:29.760\nThat's right,\nwe are continuing right where we left off.\n\n11\n00:00:29.760 --> 00:00:32.050\nAnd in the first part,\nwe were talking about, well,\n\n12\n00:00:32.050 --> 00:00:33.540\nkind of a few different things.\n\n13\n00:00:33.540 --> 00:00:36.360\nWhy do we even implement\na PKI to begin with?\n\n14\n00:00:36.360 --> 00:00:39.240\nRemember it's about certificates and\ncertificate management.\n\n15\n00:00:39.240 --> 00:00:42.600\nAnd we can use our certificates for\nall different kinds of things.\n\n16\n00:00:42.600 --> 00:00:44.080\nBut primarily for\n\n17\n00:00:44.080 --> 00:00:47.985\nthings like identification and\nverifying things like integrity.\n\n18\n00:00:47.985 --> 00:00:51.685\nWhether it becomes the integrity of our\napplications or whether it be verification\n\n19\n00:00:51.685 --> 00:00:56.475\nor authentication of our entities like for\ninstance users, machines if you will.\n\n20\n00:00:56.475 --> 00:01:00.580\nStorage systems out there like SANS if\nyou will, and many different things.\n\n21\n00:01:00.580 --> 00:01:03.550\nAnd one of the thing that we had\ntalked about in the first episode,\n\n22\n00:01:03.550 --> 00:01:06.500\nwe talked a little bit about the\ncertificate authorities, right, the CAs.\n\n23\n00:01:06.500 --> 00:01:09.990\nAnd remember that the certificates\nauthorities are responsible for issuing\n\n24\n00:01:09.990 --> 00:01:15.190\nthe certificates that we are gonna use for\nwhatever the purpose is that we use them.\n\n25\n00:01:15.190 --> 00:01:19.130\nAnd I wanted to start off by talking\na little bit more about those CAs and\n\n26\n00:01:19.130 --> 00:01:21.630\nwhy we would have more than one CA.\n\n27\n00:01:21.630 --> 00:01:26.120\nOr what's known as a multi-tiered\nhierarchical implementation.\n\n28\n00:01:26.120 --> 00:01:28.660\nAll right, so\nif we can go to my slide here.\n\n29\n00:01:28.660 --> 00:01:30.766\nRemember, we talked about the root CA.\n\n30\n00:01:30.766 --> 00:01:35.172\nAnd I kind of showed a Google certificate,\nwe talked about GeoTrust, right,\n\n31\n00:01:35.172 --> 00:01:39.800\nas being up there, Verisign, Go Daddy,\na lot of these are the top level root CAs.\n\n32\n00:01:39.800 --> 00:01:43.134\nYou could have a root CA inside\nof your internal environment\n\n33\n00:01:43.134 --> 00:01:47.450\nif you're not worried about a public\ntrust with your certificates.\n\n34\n00:01:47.450 --> 00:01:50.710\nBasically meaning it's gonna do code\nsigning for inside of your network, or\n\n35\n00:01:50.710 --> 00:01:53.800\nit's gonna identify your users or your\nmachines within inside of your networks.\n\n36\n00:01:53.800 --> 00:01:56.220\nSame thing, we still have a root CA.\n\n37\n00:01:56.220 --> 00:01:56.940\nJust remember,\n\n38\n00:01:56.940 --> 00:02:01.330\npublic versus private depends on who you\nneed to trust the certificates, okay?\n\n39\n00:02:01.330 --> 00:02:05.090\nNow, the root CA is also\nsometimes called an offline CA.\n\n40\n00:02:05.090 --> 00:02:06.910\nAnd I wanna talk a little bit about that.\n\n41\n00:02:06.910 --> 00:02:11.900\nAnd that kind of lends itself to why a lot\nof times we use intermediate CAs as well.\n\n42\n00:02:11.900 --> 00:02:16.440\nAll right, when we look at the whole\nentire hierarchy, all right,\n\n43\n00:02:16.440 --> 00:02:20.790\nlet's say for instance I've\ngot a web server out there and\n\n44\n00:02:20.790 --> 00:02:22.840\nwe want you to be able to access it,\nright?\n\n45\n00:02:22.840 --> 00:02:27.510\nAnd it's called demo.itpro.tv, right?\n\n46\n00:02:27.510 --> 00:02:28.550\nWell, remember,\n\n47\n00:02:28.550 --> 00:02:33.320\nwe can potentially be issued\na certificate by an intermediate CA.\n\n48\n00:02:33.320 --> 00:02:37.773\nAnd what happens is the root CA\ncreates what's known as a self-signed\n\n49\n00:02:37.773 --> 00:02:39.200\ncertificate, right?\n\n50\n00:02:39.200 --> 00:02:42.260\nIf you're the highest part of\nthe hierarchy, who endorses you?\n\n51\n00:02:43.300 --> 00:02:44.250\nNobody, right?\n\n52\n00:02:44.250 --> 00:02:49.540\nSo, the roots create what's known as a\nself-signed certificate that then endorses\n\n53\n00:02:49.540 --> 00:02:52.360\nlower or intermediate entities after that.\n\n54\n00:02:52.360 --> 00:02:55.610\nIn this case,\nwe're gonna talk about the secondary CA.\n\n55\n00:02:55.610 --> 00:02:57.720\nI'm using a lot of different terms here,\n\n56\n00:02:57.720 --> 00:03:00.806\nguys, that are really synonymous\nwith each other, right?\n\n57\n00:03:00.806 --> 00:03:04.876\nIntermediate CA,\nsubordinate CA, secondary CA.\n\n58\n00:03:04.876 --> 00:03:08.570\nRemember, it's this next part\nof the hierarchy, all right?\n\n59\n00:03:08.570 --> 00:03:13.112\nAnd in this case,\nthe root endorses the secondary CA.\n\n60\n00:03:13.112 --> 00:03:17.493\nThe secondary CA, or the intermediate CA,\ncertificate authority,\n\n61\n00:03:17.493 --> 00:03:22.393\nis what's issuing the certificates,\nin this case, to endorse the website,\n\n62\n00:03:22.393 --> 00:03:27.830\nverifying that you know that when you come\nto demo.it.pro.tv that you can trust it.\n\n63\n00:03:27.830 --> 00:03:30.750\nNow this is a chain of\ntrust if you will and\n\n64\n00:03:30.750 --> 00:03:34.910\nthe problem here is,\nthe potential problem.\n\n65\n00:03:34.910 --> 00:03:38.770\nWhat happens if a root\nCA gets compromised?\n\n66\n00:03:38.770 --> 00:03:42.649\nLet's say hacker come lately\ncomes in here and compromises.\n\n67\n00:03:43.700 --> 00:03:48.450\nAnd puts lines on my diagram,\nthe root CA, all right?\n\n68\n00:03:48.450 --> 00:03:49.980\nWell, here's a problem.\n\n69\n00:03:49.980 --> 00:03:56.000\nOnce the root CA has been compromised,\nthe problem is, in this chain of trust,\n\n70\n00:03:56.000 --> 00:04:00.560\nif I trust the chain from here back up,\nguess what happens?\n\n71\n00:04:00.560 --> 00:04:05.860\nIf it's compromised, that means it's\ncompromised from here, all the way down.\n\n72\n00:04:05.860 --> 00:04:06.840\nYes, that's right.\n\n73\n00:04:06.840 --> 00:04:07.680\nAll the way down.\n\n74\n00:04:07.680 --> 00:04:12.120\nAnd it's gonna propagate\nback down to demo.itpro.tv.\n\n75\n00:04:12.120 --> 00:04:16.258\nThis is why we typically implement\nthings like secondary CAs,\n\n76\n00:04:16.258 --> 00:04:19.080\nright, our subordinate CAs, all right?\n\n77\n00:04:19.080 --> 00:04:20.900\nAnd here's why.\n\n78\n00:04:20.900 --> 00:04:26.070\nBecause if we issue, let's say,\nlet's go back to this diagram.\n\n79\n00:04:26.070 --> 00:04:32.080\nIf we issue a certificate to a secondary\nCA, and lets take that same example but\n\n80\n00:04:32.080 --> 00:04:36.190\nlet's say this time the secondary\nCA gets compromised.\n\n81\n00:04:36.190 --> 00:04:38.370\nWell it is still a pain,\ndon't get me wrong,\n\n82\n00:04:38.370 --> 00:04:41.560\nany compromise of your CA is going\nto cause you nightmares, right?\n\n83\n00:04:41.560 --> 00:04:42.510\nYou never want this to happen.\n\n84\n00:04:42.510 --> 00:04:47.350\nBut, I guess ease is relative\nto who's implementing it.\n\n85\n00:04:47.350 --> 00:04:51.374\nIt would be easier if we\nonly have to invalidate,\n\n86\n00:04:51.374 --> 00:04:55.920\nright, from the secondary or\nthe intermediate below it, right?\n\n87\n00:04:55.920 --> 00:04:59.080\nBecause then what we can do\nis when it comes down to it,\n\n88\n00:04:59.080 --> 00:05:01.820\nwe can bring another secondary online.\n\n89\n00:05:01.820 --> 00:05:06.842\nWe can endorse it, and yes,\nthis whole entire process might\n\n90\n00:05:06.842 --> 00:05:11.382\nbe compromised,\nif I can get my slide to do what I want.\n\n91\n00:05:11.382 --> 00:05:15.340\nBut notice that,\nwe now have another CA that is in line,\n\n92\n00:05:15.340 --> 00:05:20.142\nthat can do what we want with it,\nstart issuing out certificates and\n\n93\n00:05:20.142 --> 00:05:23.660\nwe can start our certificate chain again.\n\n94\n00:05:23.660 --> 00:05:28.745\nHowever, if we only have a single root CA,\nthen problem lies in the fact that if\n\n95\n00:05:28.745 --> 00:05:34.780\nthat root gets compromised, remember\neverything below it's compromised.\n\n96\n00:05:34.780 --> 00:05:40.480\n&gt;&gt; And Wes, we can also an additional\nsecondary CA depending on our budget and\n\n97\n00:05:40.480 --> 00:05:44.445\nthe size of our organization so that if\none of those machines were compromised.\n\n98\n00:05:44.445 --> 00:05:49.595\nLet's say we only generated 20 different\ncertificates from that root CA.\n\n99\n00:05:49.595 --> 00:05:53.683\nMaybe we had four subordinates, so each\none of them would get five certificates,\n\n100\n00:05:53.683 --> 00:05:55.530\nbreaking it up into those segments.\n\n101\n00:05:55.530 --> 00:05:59.116\nWhere one machine was compromised and\nwe only had to revoke five of those\n\n102\n00:05:59.116 --> 00:06:03.870\ncertificates, it's really mitigating\nthe overall potential of that loss there.\n\n103\n00:06:03.870 --> 00:06:07.070\n&gt;&gt; Right, you could implement\na third party or hierarchy.\n\n104\n00:06:07.070 --> 00:06:09.309\nIn implementing a third party or\nhierarchy, and\n\n105\n00:06:09.309 --> 00:06:11.340\nthere's different reasons to do that too.\n\n106\n00:06:11.340 --> 00:06:13.490\nWhy might I break this up like this?\n\n107\n00:06:13.490 --> 00:06:18.150\nMaybe your certificate model, if you will,\nis broken up by region, right?\n\n108\n00:06:18.150 --> 00:06:21.040\nMaybe you have intermediate CAs,\nyou have your root CA, right,\n\n109\n00:06:21.040 --> 00:06:25.360\nfor your entire organization, but\nyou have maybe some intermediate CAs\n\n110\n00:06:25.360 --> 00:06:28.630\nthat issue out, let's say,\ncertificates to the United States.\n\n111\n00:06:28.630 --> 00:06:29.804\nIf you're global, right, United States.\n\n112\n00:06:29.804 --> 00:06:34.082\nMaybe you've got companies in Japan,\nso you've got intermediate CAs\n\n113\n00:06:34.082 --> 00:06:39.080\nthat are issuing certificates to users and\ndevices inside of Japan, right?\n\n114\n00:06:39.080 --> 00:06:45.190\nSo you, it really is also not just\nabout the protection of the root,\n\n115\n00:06:45.190 --> 00:06:48.880\nbut it can also be based on how you\nare implementing your certificate.\n\n116\n00:06:48.880 --> 00:06:52.980\nMaybe you have intermediate CAs,\none that just does network devices.\n\n117\n00:06:52.980 --> 00:06:57.890\nOne that just does code signing,\none that just does users and groups,\n\n118\n00:06:57.890 --> 00:06:59.480\nright, or users, if you will.\n\n119\n00:06:59.480 --> 00:07:03.496\nThen if one of those intermediate CAs\ngets exposed, it's only that group of\n\n120\n00:07:03.496 --> 00:07:07.218\ncertificates, like Cherokee says,\nthat you have to revoke, okay?\n\n121\n00:07:07.218 --> 00:07:11.849\nSo keep that in mind, that's why we use\na hierarchical model like that having\n\n122\n00:07:11.849 --> 00:07:13.496\nmore than just one root CA.\n\n123\n00:07:13.496 --> 00:07:16.168\nNow, maybe you're a small company, and\n\n124\n00:07:16.168 --> 00:07:21.000\nbudget doesn't warrant implementing\nall of this extra infrastructure.\n\n125\n00:07:21.000 --> 00:07:25.810\nWell, then you can do what's known as\na single-tier PKI and that's a root.\n\n126\n00:07:25.810 --> 00:07:28.260\nAnd the root issues all\ncertificates to all devices.\n\n127\n00:07:28.260 --> 00:07:31.700\nHowever, keep in mind if\nthe root is compromised,\n\n128\n00:07:31.700 --> 00:07:32.930\nthen you have to revoke, right?\n\n129\n00:07:32.930 --> 00:07:36.920\nWe have to invalidate all of the\ncertificates below it because they can no\n\n130\n00:07:36.920 --> 00:07:42.190\nlonger be trusted if the authority that\nissued them can't be trusted, right?\n\n131\n00:07:42.190 --> 00:07:46.282\nAnd that brings us back to why this\nis called an offline CA, all right?\n\n132\n00:07:46.282 --> 00:07:50.702\nThe root CA is also called an offline\nCA cuz you have to keep it protected,\n\n133\n00:07:50.702 --> 00:07:52.301\nall right, at all costs.\n\n134\n00:07:52.301 --> 00:07:55.997\nA lot of times what will happen\nis a root CA you'll issue,\n\n135\n00:07:55.997 --> 00:07:59.540\nin fact if we can bring\nup the slide again here.\n\n136\n00:07:59.540 --> 00:08:02.940\nA lot of times what will\nhappen is the root CA\n\n137\n00:08:02.940 --> 00:08:04.860\nmight not even be plugged\ninto the network.\n\n138\n00:08:04.860 --> 00:08:08.530\nYou might bring the root CA online,\nif you will.\n\n139\n00:08:08.530 --> 00:08:12.000\nAnd what I mean as online I don't mean\nconnected to a network, I mean turned on.\n\n140\n00:08:12.000 --> 00:08:16.770\nAnd you issue a certificate\nto the secondary CA, right?\n\n141\n00:08:16.770 --> 00:08:21.480\nAnd you export it maybe via USB,\nout the and\n\n142\n00:08:21.480 --> 00:08:25.450\ncarry its sneakernet and\nyou import it into the secondary CA.\n\n143\n00:08:25.450 --> 00:08:27.990\nAnd then once that secondary CA is there,\n\n144\n00:08:27.990 --> 00:08:34.010\nit now becomes the issuing CA Right,\nthat's doing all of the work for\n\n145\n00:08:34.010 --> 00:08:38.970\nus, issuing all the certificates out,\nand we literally take that root offline.\n\n146\n00:08:38.970 --> 00:08:44.250\nAnd when I mean offline, not just\nlack of network connection, right?\n\n147\n00:08:44.250 --> 00:08:48.040\nWe're talking no power,\nwe power it down, right?\n\n148\n00:08:48.040 --> 00:08:49.410\nGraceful shut down.\n\n149\n00:08:49.410 --> 00:08:52.350\nAnd even more so,\nmaybe even pull the hard drive out.\n\n150\n00:08:52.350 --> 00:08:53.970\nRight, in physical security, Cherokee and\n\n151\n00:08:53.970 --> 00:08:57.370\nI explained how safes were\nsomething that we need.\n\n152\n00:08:57.370 --> 00:09:00.330\nRight, we take that hard drive and\nwe put that hard drive in that safe and\n\n153\n00:09:00.330 --> 00:09:03.990\nwe lock it up, and it's next to our on\nsite backups, right, we protect it.\n\n154\n00:09:03.990 --> 00:09:06.140\nThat's why they call it an offline CA, and\n\n155\n00:09:06.140 --> 00:09:10.160\nthat's because your root CA, being the\nhighest part of the hierarchy, remember,\n\n156\n00:09:10.160 --> 00:09:13.310\nif it gets compromised,\neverything is lost.\n\n157\n00:09:13.310 --> 00:09:15.240\nI'll give you an example, all right?\n\n158\n00:09:15.240 --> 00:09:17.810\nIn fact,\nwe were just talking about it to some\n\n159\n00:09:17.810 --> 00:09:19.910\nof our great viewers out\nthere in the chatroom.\n\n160\n00:09:19.910 --> 00:09:23.950\nThere was a Public CA that\nhad been attacked, and\n\n161\n00:09:23.950 --> 00:09:26.450\nthe private key had been stolen.\n\n162\n00:09:26.450 --> 00:09:27.780\nWhich means they were issuing,\n\n163\n00:09:27.780 --> 00:09:31.090\nthe attacker was issuing out\na lot of bogus certificates.\n\n164\n00:09:32.240 --> 00:09:35.230\nThe problem is they\ndidn't come forward and\n\n165\n00:09:35.230 --> 00:09:40.200\nsay right away, well two companies\nactually got compromised, right?\n\n166\n00:09:40.200 --> 00:09:41.980\nOne company tried to sweep\nit under the carpet and\n\n167\n00:09:41.980 --> 00:09:45.160\nsaid hey let's try to fix\nthis before anybody knows.\n\n168\n00:09:45.160 --> 00:09:46.300\nThe world found out about it.\n\n169\n00:09:46.300 --> 00:09:48.040\nThey violated that trust model.\n\n170\n00:09:48.040 --> 00:09:50.390\nWhen you violate that model of trust and\n\n171\n00:09:50.390 --> 00:09:54.130\nyou as a public CA can no longer be\ntrusted, your company's out of business.\n\n172\n00:09:54.130 --> 00:09:56.390\nAnother company and\nagain we'll keep the names out of it.\n\n173\n00:09:56.390 --> 00:09:57.420\nYou guys do the research.\n\n174\n00:09:57.420 --> 00:09:59.170\nIt's over the last four years or so.\n\n175\n00:09:59.170 --> 00:10:02.230\nAnother company,\nthey knew they've been hacked.\n\n176\n00:10:02.230 --> 00:10:04.720\nThey didn't know what had happened.\n\n177\n00:10:04.720 --> 00:10:08.770\nAnd instantly they called all\ntheir customers right away says we\n\n178\n00:10:08.770 --> 00:10:10.400\ndon't know what happened.\n\n179\n00:10:10.400 --> 00:10:13.540\nInvalidate our certificates revoke\nthem don't trust them right now.\n\n180\n00:10:13.540 --> 00:10:14.960\n&gt;&gt; We're not gonna sweep it under the rug.\n\n181\n00:10:14.960 --> 00:10:16.910\n&gt;&gt; That's right they did\ntheir due diligence right.\n\n182\n00:10:16.910 --> 00:10:17.680\n&gt;&gt; Exactly.\n\n183\n00:10:17.680 --> 00:10:20.370\n&gt;&gt; They figured out\neventually what happened but\n\n184\n00:10:20.370 --> 00:10:23.890\nuntil they can figure out what happened\nthey told every body right away.\n\n185\n00:10:23.890 --> 00:10:26.460\nYou need to stop trusting these\ncertificates because there's a potential\n\n186\n00:10:26.460 --> 00:10:28.690\nthat they could be fraudulent.\n\n187\n00:10:28.690 --> 00:10:30.810\nThat company still exists, right?\n\n188\n00:10:30.810 --> 00:10:34.550\nBecause while it was a violation of the\ntrust, it wasn't done on their part and\n\n189\n00:10:34.550 --> 00:10:37.360\nthey did due diligence\nto solve the problem.\n\n190\n00:10:37.360 --> 00:10:40.480\nAll right, so\nunderstand that when we talk about\n\n191\n00:10:40.480 --> 00:10:43.380\nnot only your route any CA is\na problem if it's compromise.\n\n192\n00:10:43.380 --> 00:10:48.100\nBut when your route CA's compromised it\ncould be the difference between the life\n\n193\n00:10:48.100 --> 00:10:52.640\nand the death of your company, and\nespecially on an external level.\n\n194\n00:10:52.640 --> 00:10:53.670\nSo do you keep that in mind.\n\n195\n00:10:55.012 --> 00:10:57.800\nAll right, so you know there's\nbeen a lot of talk about CA's,\n\n196\n00:10:57.800 --> 00:10:59.320\nI tell you what guys let's go ahead and\n\n197\n00:10:59.320 --> 00:11:02.810\nlet's actually put some of this\ninformation that where talking about.\n\n198\n00:11:02.810 --> 00:11:04.580\nIt's kinda see an action.\n\n199\n00:11:04.580 --> 00:11:06.690\nSo I've got a Windows 12 server here.\n\n200\n00:11:06.690 --> 00:11:09.980\nAnd what we're gonna do is we're\nactually gonna bring this online.\n\n201\n00:11:09.980 --> 00:11:10.990\nAnd we're gonna make it a root CA.\n\n202\n00:11:10.990 --> 00:11:14.840\nSo I'm gonna go up to our manage.\n\n203\n00:11:14.840 --> 00:11:16.220\nWe're in our server manager,\nby the way, and\n\n204\n00:11:16.220 --> 00:11:19.050\nwe're gonna go to our add roles and\nfeatures.\n\n205\n00:11:19.050 --> 00:11:21.770\nAnd Windows, or Microsoft if you will,\n\n206\n00:11:21.770 --> 00:11:26.000\nhas a great service inside\nof Active Directory.\n\n207\n00:11:26.000 --> 00:11:27.210\nThat's kinda interesting,\n\n208\n00:11:27.210 --> 00:11:30.960\nyou don't need Active Directory but\nit's really a great thing.\n\n209\n00:11:30.960 --> 00:11:33.480\nEnterprise level if you've\ngot a Windows server\n\n210\n00:11:33.480 --> 00:11:35.090\nchances are you're gonna\nhave Active Directory.\n\n211\n00:11:35.090 --> 00:11:37.860\nAnd that's called\nActive Directory Certificate Services.\n\n212\n00:11:37.860 --> 00:11:39.150\nSo, we're gonna go ahead and\n\n213\n00:11:39.150 --> 00:11:44.840\nwe're gonna we made sure that we're\ngonna choose Next in our intro here.\n\n214\n00:11:44.840 --> 00:11:48.270\nThis is going to be a role\nbased feature installation.\n\n215\n00:11:48.270 --> 00:11:51.240\nBy the way, guys,\nI'm using the practice labs here.\n\n216\n00:11:51.240 --> 00:11:53.540\nAnd this is the security\nplus practice labs.\n\n217\n00:11:53.540 --> 00:11:56.940\nSo you guys out there, our viewers,\nremember you have access to these labs.\n\n218\n00:11:56.940 --> 00:12:00.860\nSo you can be dong the same thing at\nhome as we're doing it here as well.\n\n219\n00:12:00.860 --> 00:12:05.610\nAnd we'll choose Next, we're gonna make\nsure that this is the sever that we want,\n\n220\n00:12:05.610 --> 00:12:09.260\nremember Server Manager allows you to\naggregate multiple severs together.\n\n221\n00:12:09.260 --> 00:12:12.750\nWe'll choose Next, and\nwhat I want, thank goodness for\n\n222\n00:12:12.750 --> 00:12:15.810\nme cuz I can find it really easy,\nit's at the top of the list and\n\n223\n00:12:15.810 --> 00:12:18.260\nthat's Active Directory\nCertificate Services.\n\n224\n00:12:18.260 --> 00:12:21.010\nYou might see the acronym\nfrom time to time, AD CS,\n\n225\n00:12:21.010 --> 00:12:23.690\nunderstand that the CS is what\nthey're talking about as the PKI.\n\n226\n00:12:23.690 --> 00:12:27.050\nThis is Microsoft implementation\nof a private PKI.\n\n227\n00:12:27.050 --> 00:12:30.550\nAnd we'll go ahead and\nadd the extra features that we need, and\n\n228\n00:12:30.550 --> 00:12:31.170\nwe'll choose next.\n\n229\n00:12:32.200 --> 00:12:34.270\nAnd I know I kinda went\na little bit faster,\n\n230\n00:12:34.270 --> 00:12:36.590\nthere's no extra features that we need.\n\n231\n00:12:36.590 --> 00:12:39.590\nOther than the ones that\nwere included when I clicked\n\n232\n00:12:39.590 --> 00:12:41.170\nActive Directory Certificate Services.\n\n233\n00:12:43.940 --> 00:12:45.580\nAnd we'll choose Next,\nand we'll choose Next.\n\n234\n00:12:45.580 --> 00:12:47.350\nAnd it's gonna ask us what we want to do.\n\n235\n00:12:47.350 --> 00:12:50.090\nNow, if this was a, let me kind\nof step back here for a second.\n\n236\n00:12:50.090 --> 00:12:54.490\nBecause if this was\na single-tier hierarchy,\n\n237\n00:12:54.490 --> 00:12:57.930\nor PKI,\nI might have the certificate authority and\n\n238\n00:12:57.930 --> 00:13:03.210\ndo the certificate Enrollment web service,\nor web enrollment here.\n\n239\n00:13:03.210 --> 00:13:07.580\nBecause I might want our users to be able\nto visit a website and do web enrollment.\n\n240\n00:13:07.580 --> 00:13:11.840\nWe're also gonna implement an intermediate\nCA so we'll see that, and you know what?\n\n241\n00:13:11.840 --> 00:13:12.940\nI'll tell you what.\n\n242\n00:13:12.940 --> 00:13:15.650\nWe'll go ahead and\nwe'll do it on this single machine anyway.\n\n243\n00:13:15.650 --> 00:13:16.760\nI like having the web enrollment.\n\n244\n00:13:16.760 --> 00:13:18.470\nMakes it easier on your end users.\n\n245\n00:13:18.470 --> 00:13:19.230\nAnd we'll choose Next.\n\n246\n00:13:20.650 --> 00:13:23.180\nAnd we'll choose Next again.\n\n247\n00:13:23.180 --> 00:13:29.250\nAnd it's gonna install IIS cuz remember\nyour users can now go to a website and\n\n248\n00:13:29.250 --> 00:13:32.190\ndo a certificate request and\nthat's gonna be important when we get\n\n249\n00:13:32.190 --> 00:13:34.486\ninto things like a certificate\nsigning request coming up.\n\n250\n00:13:34.486 --> 00:13:35.190\nAnd we'll choose Next.\n\n251\n00:13:35.190 --> 00:13:38.550\nAnd we'll choose Install.\n\n252\n00:13:38.550 --> 00:13:42.580\nNow what this will do is obviously it's\ngonna go through the install process.\n\n253\n00:13:42.580 --> 00:13:45.450\nNow as it goes through the install\nprocess let's just kind of recap\n\n254\n00:13:45.450 --> 00:13:46.940\nwhat we have done.\n\n255\n00:13:46.940 --> 00:13:50.300\nWe have installed the Active Directory\nCertificate Services Service\n\n256\n00:13:50.300 --> 00:13:51.870\non this machine, right?\n\n257\n00:13:51.870 --> 00:13:55.870\nThis is going to make this\nmachine a certificate authority.\n\n258\n00:13:55.870 --> 00:13:59.200\nHowever, there are some\npost installation options\n\n259\n00:13:59.200 --> 00:14:02.550\nthat we've got to make sure\nthat we take care of, right?\n\n260\n00:14:02.550 --> 00:14:06.730\nOne of the things that we have to do is we\ngotta figure out what kind of CA is this,\n\n261\n00:14:06.730 --> 00:14:09.010\nright, well we said well it's\na Certificate Authority.\n\n262\n00:14:09.010 --> 00:14:12.340\nWell if you're using\na Certificate Authority here in Windows,\n\n263\n00:14:12.340 --> 00:14:14.470\nyou can integrate it into\nyour Active Directory,\n\n264\n00:14:14.470 --> 00:14:16.200\nwhich is the cases that\nwe're gonna do here.\n\n265\n00:14:16.200 --> 00:14:19.100\nOr you can make it a stand\nalone Certificate Authority.\n\n266\n00:14:19.100 --> 00:14:22.020\nAnd that's one of the great things about\nActive Directory Certificate Services\n\n267\n00:14:22.020 --> 00:14:24.840\nis the fact that You don't\nhave to have Active Directory.\n\n268\n00:14:24.840 --> 00:14:28.000\nYou can install Active Directory\ncertificate services and\n\n269\n00:14:28.000 --> 00:14:29.140\nmake it a standalone CA.\n\n270\n00:14:29.140 --> 00:14:33.590\nAnd it stands alone, right,\nit's aside from your active directory.\n\n271\n00:14:34.860 --> 00:14:36.700\nAll right, so\nwe'll give it just a few more minutes.\n\n272\n00:14:36.700 --> 00:14:40.600\nShouldn't take too long here as it\ngoes through the prerequisites.\n\n273\n00:14:40.600 --> 00:14:42.490\nNow one thing I'll mention too.\n\n274\n00:14:42.490 --> 00:14:47.450\nWhen you create a certificate of authority\nhere, I want you to keep in mind that\n\n275\n00:14:47.450 --> 00:14:51.480\nonce you have brought the CA online,\nyou can't change the computer's name.\n\n276\n00:14:51.480 --> 00:14:54.660\nAll right, and\nlet me just make that clear, right?\n\n277\n00:14:54.660 --> 00:14:57.710\nIf we say this is the route authority\n\n278\n00:14:57.710 --> 00:15:01.240\nit's gonna have that information\nin the certificate all right.\n\n279\n00:15:01.240 --> 00:15:03.990\nAnd you can't change the name\nright cuz if I change the name and\n\n280\n00:15:03.990 --> 00:15:08.520\nif I say hi I'm Wes Bryan and\nI present a driver's license fee that\n\n281\n00:15:08.520 --> 00:15:12.460\nsays Cherokee Boose besides the picture\nthey gonna see doesn't match.\n\n282\n00:15:12.460 --> 00:15:16.230\nWait a second you said your name is Wes\nBryan but when you present a certificate\n\n283\n00:15:16.230 --> 00:15:19.320\nor in this case the driver's license\nto me the name doesn't match.\n\n284\n00:15:19.320 --> 00:15:20.680\nNo, that's invalid.\n\n285\n00:15:20.680 --> 00:15:21.920\nSo you have to keep that in mind.\n\n286\n00:15:21.920 --> 00:15:24.660\nTake that into consideration when\nyou are gonna bring a certificate\n\n287\n00:15:24.660 --> 00:15:26.030\nauthority online.\n\n288\n00:15:26.030 --> 00:15:27.900\n&gt;&gt; Pretty cool.\nWe can't be too wishy washy about our\n\n289\n00:15:27.900 --> 00:15:29.580\nnames when we're the one's vouching for\nsomeone.\n\n290\n00:15:29.580 --> 00:15:30.220\nRight, Wes?\n\n291\n00:15:30.220 --> 00:15:32.190\n&gt;&gt; That's right.\n&gt;&gt; And if we look at this,\n\n292\n00:15:32.190 --> 00:15:33.880\nwhat you've showed us here\n&gt;&gt; It's here in the operating system,\n\n293\n00:15:33.880 --> 00:15:35.520\nyou didn't have to do out and\ndownload anything.\n\n294\n00:15:35.520 --> 00:15:39.220\nIt was just a role that you implemented\nthrough their features on demand model,\n\n295\n00:15:39.220 --> 00:15:42.340\nand it was integrated right into\nthe operating system without having to pay\n\n296\n00:15:42.340 --> 00:15:43.310\nan additional fees.\n\n297\n00:15:43.310 --> 00:15:44.220\nSo it's pretty cool.\n\n298\n00:15:44.220 --> 00:15:47.450\n&gt;&gt; It is and\nthat's one of the reasons why I like it.\n\n299\n00:15:47.450 --> 00:15:49.032\nI like the Windows server here.\n\n300\n00:15:49.032 --> 00:15:52.773\nNow, so it's letting me know that hey,\nwe've got this.\n\n301\n00:15:52.773 --> 00:15:56.451\nThe role has been successfully installed.\n\n302\n00:15:56.451 --> 00:15:58.238\nBut it isn't configured, right?\n\n303\n00:15:58.238 --> 00:16:00.247\nIt's like,\nagain like I've said in the past.\n\n304\n00:16:00.247 --> 00:16:02.948\nIt's installing a light switch, but\nwe never turn the light switch on, right?\n\n305\n00:16:02.948 --> 00:16:04.230\nWe actually have to use it now.\n\n306\n00:16:04.230 --> 00:16:07.560\nSo let's go ahead, and\nlet's do some configurations here.\n\n307\n00:16:07.560 --> 00:16:11.320\nWe'll configure Active Directory\nCertificate Services, all right.\n\n308\n00:16:11.320 --> 00:16:13.470\nAnd there are a couple of stipulations.\n\n309\n00:16:13.470 --> 00:16:17.800\nIf you're doing Standalone certificate\nauthority, you have to be a local admin.\n\n310\n00:16:17.800 --> 00:16:21.650\nAny of the other options here, except for\nthe Online Responder and web enrollment,\n\n311\n00:16:21.650 --> 00:16:24.270\nyou have to be Enterprise admin level.\n\n312\n00:16:24.270 --> 00:16:27.450\nI'm not worried about that,\nI do have the privileges here.\n\n313\n00:16:27.450 --> 00:16:30.430\nAnd we're going to go ahead, and we're\ngoing to choose Certificate Authority.\n\n314\n00:16:30.430 --> 00:16:33.520\nAnd it takes a second, and\nit's going to check to make sure\n\n315\n00:16:33.520 --> 00:16:35.700\nof any prerequisites here\nthat might need to be done.\n\n316\n00:16:37.170 --> 00:16:40.130\nAnd I'm also gonna do\nthe Certificate Authority web enrollment,\n\n317\n00:16:40.130 --> 00:16:42.850\nwhich did require IIS.\n\n318\n00:16:42.850 --> 00:16:45.760\nAll right, now this is this\ncertificate authority, okay.\n\n319\n00:16:45.760 --> 00:16:50.480\nIt's asking me at this point, do I wanna\nintegrate this with our Active Directory?\n\n320\n00:16:50.480 --> 00:16:55.000\nIn this case, I'm going to, or\nwe don't have to have Active Directory.\n\n321\n00:16:55.000 --> 00:16:58.160\nAnd again, Cherokee,\nI think it was you that mentioned earlier.\n\n322\n00:16:58.160 --> 00:17:01.790\nThat said hey, what if the budget doesn't\nallow for a multi-hierarchy, right?\n\n323\n00:17:01.790 --> 00:17:06.020\nMaybe we just do a single Standalone CA,\nwe don't have Active Directory.\n\n324\n00:17:06.020 --> 00:17:09.840\nAll right, but in this case,\nwe're gonna do the Enterprise-level CA.\n\n325\n00:17:09.840 --> 00:17:11.750\nAnd we'll go ahead and\nwe will choose Next.\n\n326\n00:17:13.760 --> 00:17:16.610\nAll right,\nnow here's where we make the choice,\n\n327\n00:17:16.610 --> 00:17:20.240\nof what part of the hierarchy is this.\n\n328\n00:17:20.240 --> 00:17:23.130\nIn this case,\nwe're gonna do a Root CA, right?\n\n329\n00:17:23.130 --> 00:17:24.150\nUnderstand what it says.\n\n330\n00:17:24.150 --> 00:17:25.740\nThe Root CA must be the first and\n\n331\n00:17:25.740 --> 00:17:30.700\nmay be the only CAs configured\nIn the hierarchy, right?\n\n332\n00:17:30.700 --> 00:17:34.470\nThe Root CA is the top, or\nthis could be a Subordinate CA.\n\n333\n00:17:34.470 --> 00:17:37.740\nWe're not quite there yet, we're not\ngonna make it an Intermediate CA,\n\n334\n00:17:37.740 --> 00:17:39.690\nas they called out on the exam objectives.\n\n335\n00:17:39.690 --> 00:17:41.440\nWe'll do that coming up in a second.\n\n336\n00:17:41.440 --> 00:17:49.210\nWe'll choose Next, and now, if we happen\nto have maybe a hardware issue on our CA.\n\n337\n00:17:49.210 --> 00:17:54.840\nOur root CA before, and we had to bring\nit back off, take it offline completely.\n\n338\n00:17:54.840 --> 00:17:57.550\nWe could import the root\nCA certificate here.\n\n339\n00:17:57.550 --> 00:17:59.660\nWe're actually going to\ncreate a new private key.\n\n340\n00:17:59.660 --> 00:18:02.500\nOops, as I say, that I changed the option.\n\n341\n00:18:02.500 --> 00:18:03.270\nAnd we'll choose Next.\n\n342\n00:18:04.400 --> 00:18:10.160\nAll right, now they have various CSPs,\ncryptographic service providers, right?\n\n343\n00:18:10.160 --> 00:18:11.650\nAnd all the different kinds.\n\n344\n00:18:11.650 --> 00:18:17.370\nAnd then you can see, Elliptical Curve\nDigital Signature Algorithms, Microsoft.\n\n345\n00:18:17.370 --> 00:18:19.590\nI'm just gonna keep my\nMicrosoft default here.\n\n346\n00:18:19.590 --> 00:18:23.560\nBut you can see that Microsoft doesn't\njust include their own proprietary\n\n347\n00:18:23.560 --> 00:18:24.320\nimplementations.\n\n348\n00:18:24.320 --> 00:18:27.580\nThey also include some of\nthe industry-wide standards there as well.\n\n349\n00:18:27.580 --> 00:18:29.400\n&gt;&gt; But the thing is,\nthere may be other solutions out there.\n\n350\n00:18:29.400 --> 00:18:30.450\n&gt;&gt; Most definitely.\n\n351\n00:18:30.450 --> 00:18:34.080\nBut I'm gonna go ahead, and\nI'll just keep the storage key provider.\n\n352\n00:18:34.080 --> 00:18:36.570\nAnd here's another thing we\nalso have to keep in mind.\n\n353\n00:18:36.570 --> 00:18:38.870\nIs the key length, all right?\n\n354\n00:18:38.870 --> 00:18:42.740\nYour root key, you generally\nwant to be a little bit stronger\n\n355\n00:18:42.740 --> 00:18:44.040\nthen what your subordinate keys are.\n\n356\n00:18:44.040 --> 00:18:48.690\nThat's gonna be up to you, cuz remember,\nwe can extend this all the way up to 4096.\n\n357\n00:18:48.690 --> 00:18:52.391\nYou have to keep in mind,\nthat that's gonna Increase\n\n358\n00:18:52.391 --> 00:18:55.965\nthe computational power that it\ntakes to use these certificates.\n\n359\n00:18:55.965 --> 00:18:59.605\nAnytime you increase the bit length,\nyes, you increase the security.\n\n360\n00:18:59.605 --> 00:19:01.370\nBut remember, security and\nconvenience here.\n\n361\n00:19:01.370 --> 00:19:03.115\n&gt;&gt; That trade-off.\n&gt;&gt; We always talk about, absolutely,\n\n362\n00:19:03.115 --> 00:19:03.905\nalways a trade-off.\n\n363\n00:19:03.905 --> 00:19:07.575\nAnd there's gonna be more computational\npower, for using a key size of 4096.\n\n364\n00:19:07.575 --> 00:19:09.320\nSo I'm gonna go ahead.\n\n365\n00:19:09.320 --> 00:19:14.990\nAnd, I'm going to go ahead and\njust do the basic, 2048.\n\n366\n00:19:14.990 --> 00:19:22.400\nAll right, we'll just go ahead and\nkeep the names, and the validity period.\n\n367\n00:19:22.400 --> 00:19:25.960\nThere's different models and\ndifferent thought processes on this.\n\n368\n00:19:25.960 --> 00:19:27.120\nSo for instance-\n&gt;&gt; Yeah,\n\n369\n00:19:27.120 --> 00:19:31.800\nyou can back and forth with people's\nperspective on how they feel about this.\n\n370\n00:19:31.800 --> 00:19:35.200\n&gt;&gt; That's right, so let's kinda talk\nabout what that perspective means.\n\n371\n00:19:35.200 --> 00:19:39.379\nIf my certificate lasts longer,\nright, it's less maintenance.\n\n372\n00:19:39.379 --> 00:19:43.390\nBecause I don't have to reissue or\nrenew keys once it expires,\n\n373\n00:19:43.390 --> 00:19:45.065\nbecause it lasts longer.\n\n374\n00:19:45.065 --> 00:19:49.560\nBut that administrative convenience\nkind of trumps, if you will, or\n\n375\n00:19:49.560 --> 00:19:54.860\nnot trumps, but causes a problem when\nit comes to security-wise, right?\n\n376\n00:19:54.860 --> 00:19:58.460\nBecause it also gives longer time for\nthe potential for\n\n377\n00:19:58.460 --> 00:20:00.330\nan attack against the certificate.\n\n378\n00:20:00.330 --> 00:20:03.585\nSo again, you kinda weigh,\nyou gotta pick and chose here.\n\n379\n00:20:03.585 --> 00:20:04.495\nYou might-\n&gt;&gt; Yeah, if we get\n\n380\n00:20:04.495 --> 00:20:08.715\ncompromised in year one, we might get\nto year three before we recognize that.\n\n381\n00:20:08.715 --> 00:20:11.345\n&gt;&gt; Definitely, so your roots.\n\n382\n00:20:11.345 --> 00:20:14.865\nAnd the other thing is, you don't want\nyour root CA expiring at the same time\n\n383\n00:20:14.865 --> 00:20:17.055\nyour intermediate CAs are expiring.\n\n384\n00:20:17.055 --> 00:20:22.780\nSo, I might set this,\nlet's say, ten years, right?\n\n385\n00:20:22.780 --> 00:20:25.700\nAnd my intermediate CAs,\nI might put at five years.\n\n386\n00:20:25.700 --> 00:20:28.780\nAnd my certificates that I\nissue out might be a year.\n\n387\n00:20:28.780 --> 00:20:30.340\nNow that might be too much, right?\n\n388\n00:20:30.340 --> 00:20:32.340\nYou might have your root CAs at five,\n\n389\n00:20:32.340 --> 00:20:35.960\nmaybe your subordinate CAs are at\na couple years, or a year.\n\n390\n00:20:35.960 --> 00:20:41.700\nMaybe the certificates that you're issuing\nout might expire after six months.\n\n391\n00:20:41.700 --> 00:20:43.010\nAgain, keep in mind,\n\n392\n00:20:43.010 --> 00:20:45.470\nthe faster they expire,\ntypically a little bit more secure.\n\n393\n00:20:45.470 --> 00:20:49.390\nBut more maintenance that's involved,\nto upkeep the certificate infrastructure.\n\n394\n00:20:50.470 --> 00:20:53.610\nAnd we'll choose Next, and\nwe will configure this.\n\n395\n00:20:53.610 --> 00:20:57.369\nAnd now it's going to look at\nall these options that we used,\n\n396\n00:20:57.369 --> 00:21:00.450\nin order to bring this root CA online.\n\n397\n00:21:00.450 --> 00:21:05.380\nIt's gonna generate that self-signed\ncertificate that's gonna be the highest\n\n398\n00:21:05.380 --> 00:21:06.816\npart of the hierarchy.\n\n399\n00:21:06.816 --> 00:21:09.452\nAnd in a second here, we should see, yep.\n\n400\n00:21:09.452 --> 00:21:12.675\nIt looks like we have\nconfiguration succeeded, and\n\n401\n00:21:12.675 --> 00:21:15.180\nthat's what we wanna see here.\n\n402\n00:21:15.180 --> 00:21:18.247\nSo we'll go ahead and\nchoose Close on this, all right.\n\n403\n00:21:18.247 --> 00:21:21.520\nAnd the quick heads-up menu and\nserver manager lets me know that\n\n404\n00:21:21.520 --> 00:21:24.380\nActive Directory Certificate Services\nis installed.\n\n405\n00:21:25.620 --> 00:21:28.743\nAnd let's go ahead, we'll open up Tools.\n\n406\n00:21:28.743 --> 00:21:31.992\nAnd there should be, towards the top here,\nCertificate Authority.\n\n407\n00:21:31.992 --> 00:21:33.571\nThis is our CertServ console.\n\n408\n00:21:33.571 --> 00:21:37.230\nAll right, so we'll go ahead and\nchose that, I think I chose it.\n\n409\n00:21:38.540 --> 00:21:39.570\nTry again, maybe I didn't.\n\n410\n00:21:42.990 --> 00:21:43.820\nIt's in the background.\n\n411\n00:21:43.820 --> 00:21:46.840\nIt's not a pop-up, it's a pop-under.\n\n412\n00:21:46.840 --> 00:21:48.445\n&gt;&gt; You gotta love when that happens.\n\n413\n00:21:48.445 --> 00:21:49.340\n&gt;&gt; [LAUGH].\n&gt;&gt; There we go.\n\n414\n00:21:49.340 --> 00:21:52.070\nAll right, so now what I have is,\nthis is our cert server.\n\n415\n00:21:52.070 --> 00:21:54.040\nThis is our certificate of authority,\nright?\n\n416\n00:21:54.040 --> 00:21:58.280\nWe can see the name of the server,\nand that's what we wanna see.\n\n417\n00:21:58.280 --> 00:22:02.660\nWe can see our green checkmark here\nnext to our server, means it's online,\n\n418\n00:22:02.660 --> 00:22:03.220\nit's ready to go.\n\n419\n00:22:03.220 --> 00:22:08.450\nAnd now we have the ability to do\nthings like issue certificates,\n\n420\n00:22:08.450 --> 00:22:09.730\nrevoke certificates.\n\n421\n00:22:09.730 --> 00:22:11.630\nAnd we'll talk a little\nbit more about that.\n\n422\n00:22:11.630 --> 00:22:13.090\nBut what I really wanna look at is,\n\n423\n00:22:13.090 --> 00:22:16.400\nif I right-click on the certificate\nserver itself and choose Properties.\n\n424\n00:22:18.440 --> 00:22:22.551\nAnd once those properties come up,\nis this another pop-under?\n\n425\n00:22:22.551 --> 00:22:25.282\nOr maybe I didn't,\nmaybe I didn't choose the right option,\n\n426\n00:22:25.282 --> 00:22:27.420\nlet's try that again here.\n\n427\n00:22:27.420 --> 00:22:30.180\nChoose Properties there,\nthere it is, okay.\n\n428\n00:22:30.180 --> 00:22:31.640\nAnd this is what I wanna see, right?\n\n429\n00:22:31.640 --> 00:22:35.850\nCA certificate, and\nyou can see that it is number zero.\n\n430\n00:22:35.850 --> 00:22:38.390\nAnd let me choose View Certificate.\n\n431\n00:22:38.390 --> 00:22:42.290\nNotice that the intended purpose,\n\n432\n00:22:42.290 --> 00:22:46.630\nall issuance policies,\nall application policies right?\n\n433\n00:22:46.630 --> 00:22:49.818\nIssued to, this is the self-signed\ncertificate, right?\n\n434\n00:22:49.818 --> 00:22:53.950\nIssued to PRACTICELABS, and\nit's the name of this computer, and\n\n435\n00:22:53.950 --> 00:22:58.560\nit's issued by itself, all right?\n\n436\n00:22:58.560 --> 00:23:03.472\nIf we look at that certificate path,\nthat certificate chain, there is no chain.\n\n437\n00:23:03.472 --> 00:23:08.480\nWe're the first link, we're what's\nknown as the trust anchor, right?\n\n438\n00:23:08.480 --> 00:23:10.840\nWe have a trust model like this,\nwe have a trust anchor,\n\n439\n00:23:10.840 --> 00:23:14.120\nis that first portion of that hierarchy.\n\n440\n00:23:14.120 --> 00:23:17.580\nThis would be the example\nof the trust anchor.\n\n441\n00:23:18.680 --> 00:23:24.600\nAll right, so that gets us, that gets\nour root CA, now our root CA is online.\n\n442\n00:23:24.600 --> 00:23:28.250\nAll right, let me go ahead and\nclose down properly, the dialog box there,\n\n443\n00:23:28.250 --> 00:23:30.530\nand close that down.\n\n444\n00:23:30.530 --> 00:23:34.680\nNow, what if we wanted to bring something\nlike an intermediate CA online?\n\n445\n00:23:34.680 --> 00:23:38.930\nAll right, well, let's go ahead, and\nlet's see about how we can do that.\n\n446\n00:23:38.930 --> 00:23:41.730\nWes, our chat is super active this\nmorning, which is really great.\n\n447\n00:23:41.730 --> 00:23:43.210\nAnd we got a couple of\ncomments in the chat.\n\n448\n00:23:43.210 --> 00:23:46.023\nAnd one of them says, look,\nif we're gonna be bringing that on,\n\n449\n00:23:46.023 --> 00:23:48.287\nif we're talking about\nthe validity period there?\n\n450\n00:23:48.287 --> 00:23:51.170\nI know everyone has their\nown opinions with this.\n\n451\n00:23:51.170 --> 00:23:52.744\nAnd these are really great points.\n\n452\n00:23:52.744 --> 00:23:56.343\nIf we take that online, the root CA\noffline, then we could extend that\n\n453\n00:23:56.343 --> 00:23:59.702\nvalidity period because there's\nless of a risk for compromise.\n\n454\n00:23:59.702 --> 00:24:03.552\nAs well as if those certificate\nkeys are stored in an HSM,\n\n455\n00:24:03.552 --> 00:24:08.861\nan actual dedicated piece of encryption\nhardware to store that information.\n\n456\n00:24:08.861 --> 00:24:12.691\n&gt;&gt; Most definitely, and you know what's\ninteresting too is that I have seen where\n\n457\n00:24:12.691 --> 00:24:16.690\nsome of the recommendations have been\n&gt;&gt; Whatever your root CA is,\n\n458\n00:24:16.690 --> 00:24:19.910\nmake sure that its validity period is\ntwice as long as your intermediate CA.\n\n459\n00:24:19.910 --> 00:24:21.720\nWhatever the choice might be.\n\n460\n00:24:21.720 --> 00:24:25.860\nSo, again you don't want a root CA\ncertificate that's expiring at the same\n\n461\n00:24:25.860 --> 00:24:31.040\ntime your intermediate CAs are expiring,\nat the same time your users and machines.\n\n462\n00:24:31.040 --> 00:24:34.350\nBecause then you have to renew a potential\nfor hundreds, if not thousands,\n\n463\n00:24:34.350 --> 00:24:35.300\nof different certificates.\n\n464\n00:24:35.300 --> 00:24:39.130\nBut if you stagger it out like that,\nthe maintenance makes it a lot easier.\n\n465\n00:24:39.130 --> 00:24:40.990\nAll right, so we're gonna go ahead and\n\n466\n00:24:40.990 --> 00:24:45.050\nwhat we're gonna do is we're\ngonna bring up our next machine.\n\n467\n00:24:45.050 --> 00:24:50.360\nAnd we'll go ahead and get an intermediate\nCA brought online here as well.\n\n468\n00:24:51.560 --> 00:24:53.710\nAll right, so same thing as before,\n\n469\n00:24:53.710 --> 00:24:57.560\nwe're gonna go ahead we're\ngonna use our Server Manager.\n\n470\n00:24:57.560 --> 00:25:02.115\nAnd we will oops, we will have some\nkind of script that's not loading.\n\n471\n00:25:02.115 --> 00:25:06.370\n[LAUGH] We'll choose Add Roles and\nFeatures that's the key logger that's on\n\n472\n00:25:06.370 --> 00:25:09.410\nthe intermediate [INAUDIBLE]\n&gt;&gt; [LAUGH]\n\n473\n00:25:09.410 --> 00:25:11.300\n&gt;&gt; [LAUGH] And we'll go ahead and\n\n474\n00:25:11.300 --> 00:25:12.725\nwe'll choose Next and\n\n475\n00:25:12.725 --> 00:25:15.735\nagain,this is gonna be a lot of\nthe same thing that you seen before.\n\n476\n00:25:15.735 --> 00:25:19.890\nIt bring that up a little bit,\nso you guys could see that.\n\n477\n00:25:19.890 --> 00:25:21.970\nOkay all right, we'll choose next.\n\n478\n00:25:21.970 --> 00:25:23.270\nAnd again, we're gonna do the same thing.\n\n479\n00:25:23.270 --> 00:25:26.060\nWe're gonna do\nActive Directory Certificate Services and\n\n480\n00:25:26.060 --> 00:25:29.880\nwe'll choose Add the necessary features.\n\n481\n00:25:29.880 --> 00:25:33.380\nAnd we'll choose Next and then this time\nwhat I'm gonna do is I'm just going,\n\n482\n00:25:33.380 --> 00:25:38.560\ngo ahead and make this a certification\nauthority and we'll choose install.\n\n483\n00:25:38.560 --> 00:25:40.450\nNow again, that's gonna take a little bit.\n\n484\n00:25:40.450 --> 00:25:42.250\nWe're gonna go ahead and\nwe'll let that install.\n\n485\n00:25:42.250 --> 00:25:45.450\nAnd what I'd like to do is while that's\ninstalling, I wanna talk about a couple\n\n486\n00:25:45.450 --> 00:25:50.280\nmore things that we have to be aware\nof when it comes to our certificates.\n\n487\n00:25:50.280 --> 00:25:52.510\nI'm gonna go ahead and\nI'm gonna bump back over to GeoTrust.\n\n488\n00:25:52.510 --> 00:25:55.020\nRemember we brought up\ntheir website earlier,\n\n489\n00:25:55.020 --> 00:25:57.340\nthey talk about things like OIDs right?\n\n490\n00:25:57.340 --> 00:25:59.110\nThis is an object identifier and\n\n491\n00:25:59.110 --> 00:26:03.040\nobject identifiers can actually be\nseen inside of the certificate.\n\n492\n00:26:03.040 --> 00:26:06.130\nSo if I bring up for\ninstance GeoTrust certificate here.\n\n493\n00:26:08.160 --> 00:26:10.930\nAnd we choose the details, we kinda\nlook at some of these details here so\n\n494\n00:26:10.930 --> 00:26:13.940\nyou guys can see what is involved\nin the information that's inside of\n\n495\n00:26:13.940 --> 00:26:15.350\nthe certificate.\n\n496\n00:26:15.350 --> 00:26:18.730\nAnd what I'm looking for, we can see\nthings like serial numbers, right.\n\n497\n00:26:18.730 --> 00:26:21.280\nSerial numbers are how we\nidentify the certificate.\n\n498\n00:26:21.280 --> 00:26:25.151\nAnd it's also how we identify whether\nthe certificate has been revoked or not in\n\n499\n00:26:25.151 --> 00:26:28.964\nsomething known as acrylic, which we'll\nlook at maybe not in this episode but\n\n500\n00:26:28.964 --> 00:26:30.895\nmaybe in the next episode, all right.\n\n501\n00:26:30.895 --> 00:26:34.507\nBut what I'm looking at, and\nhere you can see the issue or name here,\n\n502\n00:26:34.507 --> 00:26:36.790\nthe serial number, the version.\n\n503\n00:26:36.790 --> 00:26:38.950\nWhat type of encryption,\nthe signature algorithm,\n\n504\n00:26:38.950 --> 00:26:43.430\nso we can see that the SHA-256\nrelatively strong with RSA encryption.\n\n505\n00:26:43.430 --> 00:26:46.940\nWe can see the validity period, right\nremember just like a driver's license,\n\n506\n00:26:46.940 --> 00:26:50.810\nit has a validity period as well, right.\n\n507\n00:26:50.810 --> 00:26:53.650\nSome of the info, we could see that\nthe key size, kinda like what we seen\n\n508\n00:26:53.650 --> 00:26:58.610\nwhen we were bringing our root\nCA online and Windows here.\n\n509\n00:26:58.610 --> 00:27:01.480\nWe can see what the key usage is for,\nright?\n\n510\n00:27:01.480 --> 00:27:06.270\nWe got if the certificate has to define\nhow's certificate is gonna be used.\n\n511\n00:27:06.270 --> 00:27:10.020\nBut then I start to get some of\nthis crazy, crazy numbers, right?\n\n512\n00:27:10.020 --> 00:27:14.776\nWe've also seen this and\nthings like SNMP traps, right O IDs.\n\n513\n00:27:14.776 --> 00:27:17.590\n&gt;&gt; I will tell you that this little\nsection right here can be pretty useful.\n\n514\n00:27:17.590 --> 00:27:19.890\nEspecially when you're in PowerShell and\nyou're looking for\n\n515\n00:27:19.890 --> 00:27:21.360\nthat really long thumbprint.\n\n516\n00:27:21.360 --> 00:27:25.320\nAnd man, I am like the worst typist ever,\nso if I can just copy and\n\n517\n00:27:25.320 --> 00:27:28.290\npaste that and put it into PowerShell\nthen it's really pretty awesome.\n\n518\n00:27:28.290 --> 00:27:32.530\n&gt;&gt; It definitely, because when you look\nat it, what does 1.3.6.,and I'm not gonna\n\n519\n00:27:32.530 --> 00:27:35.310\nbore you guys with that whole\nentire long number, right.\n\n520\n00:27:35.310 --> 00:27:38.970\nBut this is a hierarchy, and\nit is a format that you can see.\n\n521\n00:27:38.970 --> 00:27:44.420\nFor instance, portions of this\nare designated from INA versus ISO,\n\n522\n00:27:44.420 --> 00:27:47.360\nthe International Organization\nof Standardization,\n\n523\n00:27:47.360 --> 00:27:50.740\nversus a Identify company portion.\n\n524\n00:27:50.740 --> 00:27:54.040\nBut these OIDs are strings\nthat how that define\n\n525\n00:27:54.040 --> 00:27:56.180\ndifferent attributes of the certificate.\n\n526\n00:27:56.180 --> 00:28:00.394\nSo for instance, you can see, remember\nwhen we were looking like at Microsoft's\n\n527\n00:28:00.394 --> 00:28:02.520\nroot authorization certificate?\n\n528\n00:28:02.520 --> 00:28:06.450\nAnd we looked at some of the key uses just\nfor it, why would we use the certificate?\n\n529\n00:28:06.450 --> 00:28:11.000\nAnd one of them was certificate\nauthentication and client authentication.\n\n530\n00:28:11.000 --> 00:28:14.180\nWell, we see that as humanly readable.\n\n531\n00:28:14.180 --> 00:28:18.590\nHowever, you can make it not so\nhuman readable, if you use the OIDs and\n\n532\n00:28:18.590 --> 00:28:21.950\nthat's what they're talking about\nright here, the object identifiers.\n\n533\n00:28:21.950 --> 00:28:24.085\nSo we do want you to be aware of those.\n\n534\n00:28:24.085 --> 00:28:26.765\nLet's see if there's any other kind of\n\n535\n00:28:26.765 --> 00:28:28.425\ngreat information that\nwe can look in here.\n\n536\n00:28:28.425 --> 00:28:29.355\nAll good information, but\n\n537\n00:28:29.355 --> 00:28:32.525\nsome of the information I'm not\ngonna talk about right now.\n\n538\n00:28:32.525 --> 00:28:37.201\nYou can also verify that the certificate\nhas maintained its integrity,\n\n539\n00:28:37.201 --> 00:28:40.430\nbecause it's got a couple\nof fingerprints here.\n\n540\n00:28:40.430 --> 00:28:42.688\n&gt;&gt; I think I just said thumbprints\na few seconds ago, but\n\n541\n00:28:42.688 --> 00:28:44.258\nthat's what I was talking about it.\n\n542\n00:28:44.258 --> 00:28:46.346\n[LAUGH]\n&gt;&gt; Yeah, yeah exactly same thing.\n\n543\n00:28:46.346 --> 00:28:50.003\nSome people call them thumbprints,\nsome people him fingerprints\n\n544\n00:28:50.003 --> 00:28:53.396\nin fact I know in your defense\nwhen you implement them inside or\n\n545\n00:28:53.396 --> 00:28:56.681\nwhen you have to copy them inside\na PowerShell and add them.\n\n546\n00:28:56.681 --> 00:29:00.523\nThey add them by their where\nthe parameter is, thumprint I believe so\n\n547\n00:29:00.523 --> 00:29:04.510\nsame thing right, just different word for\nthe same exact thing right.\n\n548\n00:29:04.510 --> 00:29:09.540\nSo if I wanna verify that this certificate\nhasn't been modified in any way,\n\n549\n00:29:09.540 --> 00:29:11.160\nis still maintained it's integrity.\n\n550\n00:29:11.160 --> 00:29:14.900\nI can always find out what the hashing\nalgorithm is on it the value,\n\n551\n00:29:14.900 --> 00:29:18.460\nand then I can perform my own hash and I\ncan find out and compare those values and\n\n552\n00:29:18.460 --> 00:29:19.520\nif they match.\n\n553\n00:29:19.520 --> 00:29:22.390\nThen we know that this certificate\nhas maintained its integrity.\n\n554\n00:29:22.390 --> 00:29:23.860\nI know we're running close here,\n\n555\n00:29:23.860 --> 00:29:27.010\nso what we're gonna do is,\nlet's bump back over to our, oops!\n\n556\n00:29:27.010 --> 00:29:30.200\nOne of these servers our Windows server,\n\n557\n00:29:30.200 --> 00:29:33.935\ndoes look like we're gonna go ahead and\nconfigure list.\n\n558\n00:29:33.935 --> 00:29:37.425\nIt's finished, so good timing on our\npart I swear, I planned it that way.\n\n559\n00:29:37.425 --> 00:29:38.409\n&gt;&gt; You didn't plan that.\n\n560\n00:29:38.409 --> 00:29:39.700\n&gt;&gt; [LAUGH]\n&gt;&gt; [LAUGH]\n\n561\n00:29:39.700 --> 00:29:40.625\n&gt;&gt; Just computing\n\n562\n00:29:40.625 --> 00:29:43.086\ndoesn't always go the way\nyou want it to [LAUGH].\n\n563\n00:29:43.086 --> 00:29:44.585\nWe'll go ahead and choose next.\n\n564\n00:29:44.585 --> 00:29:46.045\nAnd like I said on this one,\n\n565\n00:29:46.045 --> 00:29:49.635\nI'm only gonna make this\na certificate authority, right?\n\n566\n00:29:49.635 --> 00:29:52.515\nWhat I really should do,\nis if I'm doing online web enrollment,\n\n567\n00:29:52.515 --> 00:29:55.225\nI should do it from this intermediate\nCA and not from the root,\n\n568\n00:29:55.225 --> 00:29:59.580\nbut I went ahead and just added it to\nthe root there for demonstration purposes.\n\n569\n00:29:59.580 --> 00:30:02.260\nAgain this is gonna be in\nEnterprise CA because we're\n\n570\n00:30:02.260 --> 00:30:04.770\nintegrating it with our\nActive Directory here.\n\n571\n00:30:04.770 --> 00:30:11.060\nWe'll choose Next but, this is gonna\nbe a Subordinate CA, all right?\n\n572\n00:30:11.060 --> 00:30:14.690\nNow Subordinate CA, we'll go ahead and\nchoose Next, all right.\n\n573\n00:30:14.690 --> 00:30:17.980\nAnd it's gonna have its\nown private key as well.\n\n574\n00:30:17.980 --> 00:30:21.040\nWe'll choose Next and\nwe're gonna use all the defaults here,\n\n575\n00:30:21.040 --> 00:30:23.820\njust like we did in the first one, right?\n\n576\n00:30:23.820 --> 00:30:28.200\nAnd now here is what, the last thing\nI wanted to get to, all right?\n\n577\n00:30:28.200 --> 00:30:30.980\nAnd we'll show you probably in the next\nepisode a little bit of what this looks\n\n578\n00:30:30.980 --> 00:30:33.830\nlike, this is called a CSR.\n\n579\n00:30:33.830 --> 00:30:37.960\nIn order to request a certificate\nfrom a certificate authority,\n\n580\n00:30:37.960 --> 00:30:40.870\nyou need what's known as\na certificate signing request, right.\n\n581\n00:30:40.870 --> 00:30:43.642\nAnd these can be like for\ninstance, just plain text requests,\n\n582\n00:30:43.642 --> 00:30:46.902\nI say plain text, we can't read them,\nit depends on how you format them.\n\n583\n00:30:46.902 --> 00:30:51.730\nBut its really just a text based file that\nyou send to the certificate authority in\n\n584\n00:30:51.730 --> 00:30:55.100\norder to request a certificate from it.\n\n585\n00:30:55.100 --> 00:30:59.999\nAll right, now we gotta be careful because\none of the things that says is, you must\n\n586\n00:30:59.999 --> 00:31:04.827\nmanually get this certificate back from\nthe parent to make this CA operational,\n\n587\n00:31:04.827 --> 00:31:05.329\nright?\n\n588\n00:31:05.329 --> 00:31:08.370\nRemember I told you, there might be\na little sneaker net involved in this.\n\n589\n00:31:08.370 --> 00:31:12.500\nAll right, so you can see they're\nwarning you, and we'll choose Next, and\n\n590\n00:31:12.500 --> 00:31:15.269\nNext, and we'll let this configure.\n\n591\n00:31:16.920 --> 00:31:21.220\nAlright and so\nlet me know to complete this installation.\n\n592\n00:31:21.220 --> 00:31:23.160\nI need to take that request,\n\n593\n00:31:23.160 --> 00:31:27.220\nI need to send it over to the root CA,\nit needs to issue a certificate, and\n\n594\n00:31:27.220 --> 00:31:32.440\nI need to import it back into this machine\nto bring this intermediate CA online and\n\n595\n00:31:32.440 --> 00:31:35.490\nhave it be authoritative,\nif you will, inside of our PKI.\n\n596\n00:31:36.520 --> 00:31:40.080\n&gt;&gt; All right Wes, we are getting\nclose to that time, but thank you for\n\n597\n00:31:40.080 --> 00:31:40.780\njoining us today.\n\n598\n00:31:40.780 --> 00:31:43.740\nAnd helping us navigate\nthrough a sea of PKI, but\n\n599\n00:31:43.740 --> 00:31:45.310\nwe're not out of the woods just yet.\n\n600\n00:31:45.310 --> 00:31:48.250\nSo, we have more information headed\nyour way, ladies and gentlemen.\n\n601\n00:31:48.250 --> 00:31:49.980\nFor this show,\nwe're gonna go ahead and sign out.\n\n602\n00:31:49.980 --> 00:31:51.840\nRemember, I'm your host Cherokee Boose.\n\n603\n00:31:51.840 --> 00:31:52.690\n&gt;&gt; And I'm Wes Bryan.\n\n604\n00:31:52.690 --> 00:31:55.827\n&gt;&gt; See you next time here at ITProTV.\n\n605\n00:31:55.827 --> 00:32:01.886\n[MUSIC]\n\n606\n00:32:01.886 --> 00:32:03.720\n&gt;&gt; Thank you for watching ITPro TV.\n\n",
          "vimeoId": "214509515"
        },
        {
          "description": "In this show, Cherokee and Wes continue to examine the different ways certificates can be used.  Wes explains how to structure a Certificate Authority depending on your organizations need.",
          "length": "1302",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-3-public_key_infrastructure_pt3-041817-PGM.00_21_28_00.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-3-public_key_infrastructure_pt3-041817-PGM.00_21_28_00.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-3-public_key_infrastructure_pt3-041817-PGM.00_21_28_00.Still001-sm.jpg",
          "title": "Public Key Infrastructure Part 3",
          "transcript": "WEBVTT\n\n1\n00:00:00.008 --> 00:00:06.274\nWelcome to ITPro.TV, I'm your host-\n&gt;&gt; [CROSSTALK]\n\n2\n00:00:06.274 --> 00:00:08.277\n[MUSIC]\n\n3\n00:00:08.277 --> 00:00:11.012\n&gt;&gt; You're watching ITPro.TV.\n\n4\n00:00:12.240 --> 00:00:14.710\n&gt;&gt; Welcome to your\nCompTIA Security+ series.\n\n5\n00:00:14.710 --> 00:00:16.570\nI'm your show host, Cherokee Boose.\n\n6\n00:00:16.570 --> 00:00:19.810\nThis is actually a part three where\nwe will continue to look at public\n\n7\n00:00:19.810 --> 00:00:21.060\nkey infrastructure.\n\n8\n00:00:21.060 --> 00:00:23.900\nWith us today in studio,\nwe have Mr. Wes Bryan.\n\n9\n00:00:23.900 --> 00:00:25.150\nThank you for joining us, Wes.\n\n10\n00:00:25.150 --> 00:00:26.440\n&gt;&gt; Hey, thanks for\nhaving me back, Cherokee.\n\n11\n00:00:26.440 --> 00:00:27.860\nThat's right, I talked so\n\n12\n00:00:27.860 --> 00:00:30.680\nmuch in the first two parts that we\nhave to come back with a part three.\n\n13\n00:00:30.680 --> 00:00:33.900\nSo, this is PKI, the trilogy.\n\n14\n00:00:33.900 --> 00:00:37.710\nJust kidding, all kidding aside guys, we\nare look at public key infrastructure, and\n\n15\n00:00:37.710 --> 00:00:41.140\nvarious parts, and components\nwithin public key infrastructure.\n\n16\n00:00:41.140 --> 00:00:44.250\nAnd one of the things that we left\noff with in the last episode was\n\n17\n00:00:44.250 --> 00:00:47.310\na demonstration on how we bring\nup a root certificate server.\n\n18\n00:00:47.310 --> 00:00:50.245\nWe looked at the self-sign certificate,\nand\n\n19\n00:00:50.245 --> 00:00:53.640\nwe talked a little bit about\nthat certificate chain.\n\n20\n00:00:53.640 --> 00:00:56.432\nWell, it really isn't a chain if\nyou only have one certificate,\n\n21\n00:00:56.432 --> 00:00:57.880\nit is the highest part of the hierarchy.\n\n22\n00:00:57.880 --> 00:01:02.170\nSo now we wanna put in another\nlayer of the hierarchy, right?\n\n23\n00:01:02.170 --> 00:01:06.860\nAt the end of the episode,\nwe got the subordinate CA ready to go\n\n24\n00:01:06.860 --> 00:01:12.020\nminus submitting the certificate\nrequest to the CA itself,\n\n25\n00:01:12.020 --> 00:01:13.350\nand then issuing that certificate.\n\n26\n00:01:13.350 --> 00:01:16.680\nSo let's go ahead and\nthat's where we're gonna start out.\n\n27\n00:01:16.680 --> 00:01:18.930\nNow, I want you to keep in mind\nthat what we're doing here is for\n\n28\n00:01:18.930 --> 00:01:19.913\ndemonstration purposes.\n\n29\n00:01:19.913 --> 00:01:23.121\nAnytime you're talking about\nyour certificate authorities,\n\n30\n00:01:23.121 --> 00:01:26.209\nyou really shouldn't be issuing\ncertificate authorities,\n\n31\n00:01:26.209 --> 00:01:29.720\ntheir certificates over a network,\nright, not over the wire.\n\n32\n00:01:29.720 --> 00:01:33.950\nBecause the fact that the whole reason we\ndo certificate-based authentication is so\n\n33\n00:01:33.950 --> 00:01:37.110\nthat we can prevent things like\nman-in-the-middle attacks.\n\n34\n00:01:37.110 --> 00:01:40.840\nWell, if you're taking the very component\nthat your using to prevent those, and\n\n35\n00:01:40.840 --> 00:01:44.249\nyou're putting them across the wire,\nyou're making yourself instantly\n\n36\n00:01:44.249 --> 00:01:46.970\nsusceptible to a very,\nvery bad security vulnerability.\n\n37\n00:01:46.970 --> 00:01:48.848\nSo understand that we're doing this, so\n\n38\n00:01:48.848 --> 00:01:52.497\nyou can understand the components, but\nwhen you bring a subordinate CA online,\n\n39\n00:01:52.497 --> 00:01:56.094\nwhat's gonna usually happen is you're\ngonna take that certificate request,\n\n40\n00:01:56.094 --> 00:01:59.120\nwhich is a file, and\nI'm gonna show it to you here in a second.\n\n41\n00:01:59.120 --> 00:02:03.080\nWe put it on a thumb drive,\nwe sneakernet it over to our root server.\n\n42\n00:02:03.080 --> 00:02:06.690\nWe issue the request, if you will,\nwe submit the request.\n\n43\n00:02:06.690 --> 00:02:12.620\nWe get our certificate issued by the root,\nand all of that happens via sneakernet.\n\n44\n00:02:12.620 --> 00:02:15.820\nSo just keep that in mind, this is for\ndemonstration purposes only.\n\n45\n00:02:15.820 --> 00:02:19.080\nMost likely, almost likely,\nit's not the way you're gonna do it inside\n\n46\n00:02:19.080 --> 00:02:21.360\nof a corporate environment for\nsecurity purposes.\n\n47\n00:02:21.360 --> 00:02:23.520\nSo let's go ahead and\nlet's dive right back in.\n\n48\n00:02:23.520 --> 00:02:26.420\nThis is our server that we\nhad in the last episode.\n\n49\n00:02:26.420 --> 00:02:28.060\nGot a whole bunch of red going on here.\n\n50\n00:02:28.060 --> 00:02:31.880\nWe've got some certain services that\nhaven't started up yet, but that's okay.\n\n51\n00:02:31.880 --> 00:02:35.020\nProbably, one of the services is,\nwell, certificate services, right?\n\n52\n00:02:35.020 --> 00:02:37.610\nWe can't bring it online if we\nhaven't finished the process.\n\n53\n00:02:37.610 --> 00:02:40.935\nSo, what we did is we created\na certificate request.\n\n54\n00:02:40.935 --> 00:02:44.618\nNow, that certificate request is\ndumped right here on the root here.\n\n55\n00:02:44.618 --> 00:02:49.426\nAnd you can see this crazy, old,\nlong name here, and the .rig,\n\n56\n00:02:49.426 --> 00:02:51.970\nright, that is a request format.\n\n57\n00:02:51.970 --> 00:02:54.350\nSo, what actually is this?\n\n58\n00:02:54.350 --> 00:02:57.290\nWell, I don't know, let's go ahead and\nsee if we can take a look and\n\n59\n00:02:57.290 --> 00:02:59.890\nfind out what this is, all right?\n\n60\n00:02:59.890 --> 00:03:03.640\nWell, this is essentially,\nwhat the request looks like, right?\n\n61\n00:03:03.640 --> 00:03:07.812\nThis is like a PEM format, right,\nin between a begin and an end,\n\n62\n00:03:07.812 --> 00:03:12.299\nthe certificate, PEM format would\nalso say begin new certificate,\n\n63\n00:03:12.299 --> 00:03:14.100\nend certificate, right?\n\n64\n00:03:14.100 --> 00:03:16.860\nSo it's just a bunch of\ngarbled information, right?\n\n65\n00:03:16.860 --> 00:03:20.370\nWe can't read this, but your certificate\nauthority can read it, right?\n\n66\n00:03:20.370 --> 00:03:25.159\nSo let's go ahead and\nlet's just kinda minimize that.\n\n67\n00:03:25.159 --> 00:03:28.790\nAnd what we're gonna do is we're gonna\nfire up our good old Internet Explorer.\n\n68\n00:03:28.790 --> 00:03:32.555\nAnd I actually in the first part, you\nmight remember I set up a web enrollment,\n\n69\n00:03:32.555 --> 00:03:35.250\nit makes it a little bit easier for\ndemonstration purposes.\n\n70\n00:03:35.250 --> 00:03:40.350\nKeep in mind, I cannot stress this enough,\nyou are not gonna do a CA online,\n\n71\n00:03:40.350 --> 00:03:44.990\nweb enrollment certificate request, just\nbecause of the very nature of the attack\n\n72\n00:03:44.990 --> 00:03:48.080\nthat you're basically\nexposing yourself to.\n\n73\n00:03:48.080 --> 00:03:52.676\nAll right, so let's go ahead, and we're\ngonna get to our Web Enrollment page.\n\n74\n00:03:52.676 --> 00:03:58.460\nIf I remember it, it's gonna be http,\nand then it will be plab.\n\n75\n00:03:58.460 --> 00:04:03.080\nAnd that's DCO1, oops,\nforward slashes and URLs.\n\n76\n00:04:03.080 --> 00:04:08.602\nAnd it will be certserv,\nif I remember right.\n\n77\n00:04:08.602 --> 00:04:11.190\nAnd it's gonna require me to authenticate.\n\n78\n00:04:11.190 --> 00:04:12.350\nAnd we'll go ahead and do that.\n\n79\n00:04:12.350 --> 00:04:17.450\nWe'll authenticate in this case as\nthe administrator over the domain.\n\n80\n00:04:17.450 --> 00:04:19.600\nAnd hopefully,\nI have typed my password right.\n\n81\n00:04:19.600 --> 00:04:24.650\nOkay, so here's where we can\nrequest the certificate, right?\n\n82\n00:04:24.650 --> 00:04:27.010\nWe can view the status of\na pending certificate.\n\n83\n00:04:27.010 --> 00:04:31.720\nIf I make a certificate request\nto the authority here as a user,\n\n84\n00:04:31.720 --> 00:04:34.520\nI might find that it's pending,\nthe review of an administrator,\n\n85\n00:04:34.520 --> 00:04:36.980\nmaking sure that we've met\nthe necessary checks and\n\n86\n00:04:36.980 --> 00:04:40.860\nbalances to even have a certificate\nissued to us within our domain, right?\n\n87\n00:04:40.860 --> 00:04:43.546\nBut in this case, we're gonna go ahead and\nrequest a certificate.\n\n88\n00:04:43.546 --> 00:04:48.350\nNow, I could request a user certificate,\nbut that's not what we need, right?\n\n89\n00:04:48.350 --> 00:04:52.760\nWe need a specific machine certificate,\nbut\n\n90\n00:04:52.760 --> 00:04:57.410\nI said specific machine certificate,\nthis is a subordinate CA, right,\n\n91\n00:04:57.410 --> 00:05:00.506\nthis is not like a regular work station\nwhere you're just gonna issue it, and\n\n92\n00:05:00.506 --> 00:05:03.800\nsome users gonna sit down to it,\nstart working with that machine.\n\n93\n00:05:03.800 --> 00:05:07.110\nSo we're gonna do an advanced request,\nall right?\n\n94\n00:05:07.110 --> 00:05:09.920\nNow, we've got a couple of different\nformats out there that we can do, right?\n\n95\n00:05:09.920 --> 00:05:14.580\nThis is the public key cryptology service,\nor standard if you will, #10 here.\n\n96\n00:05:14.580 --> 00:05:21.101\nOr we can do PKS, or\nexcuse me, PKCS #7, all right?\n\n97\n00:05:21.101 --> 00:05:21.617\n&gt;&gt; That base 64.\n\n98\n00:05:21.617 --> 00:05:25.982\n&gt;&gt; I'll talk a little bit, right,\ntalk about those formats coming up and\n\n99\n00:05:25.982 --> 00:05:28.775\nwe can use again base 64-encoded.\n\n100\n00:05:28.775 --> 00:05:33.582\nYou could use binary formats too, the\nproblem with binary formats, if I would\n\n101\n00:05:33.582 --> 00:05:36.762\nhave opened that file, it'd just look\nlike a bunch of garbled information.\n\n102\n00:05:36.762 --> 00:05:38.201\nI wouldn't be able to actually view it.\n\n103\n00:05:38.201 --> 00:05:42.152\nIf its base 64-encoded in\nlike ASCII characters,\n\n104\n00:05:42.152 --> 00:05:45.832\nthat's why we can see\nthe letters if you will.\n\n105\n00:05:45.832 --> 00:05:48.992\nBut I'll go ahead and\nwe're gonna submit a request.\n\n106\n00:05:48.992 --> 00:05:50.192\nSo how do we do that?\n\n107\n00:05:50.192 --> 00:05:53.846\nWell, we just really,\nit's fairly easy in this aspect.\n\n108\n00:05:53.846 --> 00:05:55.692\nLet me go ahead and\nsee if I can bring up that file.\n\n109\n00:05:55.692 --> 00:05:58.925\nNow, I need all of this file,\nright, so I'm gonna go ahead and\n\n110\n00:05:58.925 --> 00:06:01.016\nnot modify it, that's not gonna help.\n\n111\n00:06:01.016 --> 00:06:04.613\nAnd we're gonna do a Ctrl+A,\nand we're just gonna copy this.\n\n112\n00:06:04.613 --> 00:06:11.300\nAnd we're gonna go ahead, and we will\npaste that inside of this field here.\n\n113\n00:06:11.300 --> 00:06:13.290\nAnd we'll choose the down arrow.\n\n114\n00:06:13.290 --> 00:06:16.700\nAnd you'll notice that,\nwhat kind of certificate template, right,\n\n115\n00:06:16.700 --> 00:06:17.950\nwhat are we using this for.\n\n116\n00:06:17.950 --> 00:06:21.160\nRemember key usage could be server\nauthentication, in this case,\n\n117\n00:06:21.160 --> 00:06:23.882\nit is a certificate authority\nauthentication, right?\n\n118\n00:06:23.882 --> 00:06:25.267\nIt could be administrator, EFS,\n\n119\n00:06:25.267 --> 00:06:27.550\nsome of those other options\nthat we've talked about.\n\n120\n00:06:27.550 --> 00:06:30.079\nSo we're gonna do\nSubordinate Certification Authority.\n\n121\n00:06:32.235 --> 00:06:35.631\nAll right, and\nwe're gonna choose Submit, all right?\n\n122\n00:06:35.631 --> 00:06:38.812\nNow it's asking me, you really wanna\nsend this information over the Internet,\n\n123\n00:06:38.812 --> 00:06:41.080\nit might be possible for\nothers to see that information.\n\n124\n00:06:41.080 --> 00:06:42.137\nThis is why I told you,\n\n125\n00:06:42.137 --> 00:06:45.498\nyou will not be doing it this way\ninside of your corporate environment.\n\n126\n00:06:45.498 --> 00:06:49.713\nBut since I am in a virtualized\nenvironment, I am not gonna fly to London\n\n127\n00:06:49.713 --> 00:06:53.410\nwith a USB drive, and\nplug it into the CA, and then fly back.\n\n128\n00:06:53.410 --> 00:06:55.862\nWe only have 30 minutes and\nI don't have a warp drive.\n\n129\n00:06:55.862 --> 00:06:58.578\n&gt;&gt; [LAUGH]\n&gt;&gt; So we'll go ahead and say yes to that,\n\n130\n00:06:58.578 --> 00:06:59.640\nall right.\n\n131\n00:06:59.640 --> 00:07:03.960\nAnd let me go ahead and clear that out,\nI believe it's been submitted.\n\n132\n00:07:03.960 --> 00:07:06.540\nAll right,\nlooks like we have submitted it.\n\n133\n00:07:06.540 --> 00:07:08.579\nAnd let's go ahead and hit our back arrow.\n\n134\n00:07:09.640 --> 00:07:14.080\nAnd we'll get back to\nour first part there.\n\n135\n00:07:15.310 --> 00:07:17.390\nAnd now, we can do things like for\ninstance,\n\n136\n00:07:17.390 --> 00:07:21.100\nviewing the status of a pending\ncertificate request, right?\n\n137\n00:07:21.100 --> 00:07:22.830\nAnd I don't have one.\n\n138\n00:07:22.830 --> 00:07:26.190\nSo let me try that again, maybe it didn't\ntake it, let's try it one more time.\n\n139\n00:07:27.310 --> 00:07:29.470\nAll right, we'll request a certificate.\n\n140\n00:07:29.470 --> 00:07:34.527\nI might have made just a slight\nmistake there, make sure here.\n\n141\n00:07:34.527 --> 00:07:40.651\nAll right, sometimes what happens\nis it's the browser itself,\n\n142\n00:07:40.651 --> 00:07:46.886\nand it might be the fact that with\nenhanced security configuration\n\n143\n00:07:46.886 --> 00:07:53.257\nthat it did not like that,\nlet's see here, let's try that again.\n\n144\n00:07:53.257 --> 00:07:55.896\nWe'll go ahead and submit that.\n\n145\n00:07:55.896 --> 00:08:00.487\nAll right and when we do it gives\nus the option whether we wanna use\n\n146\n00:08:00.487 --> 00:08:04.480\nthe DER formats or\nwe wanna use Base 64 encoded.\n\n147\n00:08:04.480 --> 00:08:07.540\nRemember with DER,\nit's gonna be the base binary file.\n\n148\n00:08:07.540 --> 00:08:10.050\nAnd it allows us to actually\ndownload the certificate.\n\n149\n00:08:10.050 --> 00:08:12.714\nNow, this next part,\nagain I can't stress enough,\n\n150\n00:08:12.714 --> 00:08:16.760\nt/ypically you are not gonna\ndo this over the wire right?\n\n151\n00:08:16.760 --> 00:08:19.020\nBut we'll go ahead and\nwe'll download the certificate.\n\n152\n00:08:19.020 --> 00:08:21.170\nAnd I'm gonna go ahead and Save As here.\n\n153\n00:08:21.170 --> 00:08:22.960\nSo we can kinda see that.\n\n154\n00:08:22.960 --> 00:08:26.960\nWe will let's see here,\nlet's just save it at the root.\n\n155\n00:08:26.960 --> 00:08:28.750\nAnd we'll choose Save.\n\n156\n00:08:28.750 --> 00:08:33.560\nNow, that means that if we look\nback at our root authority right?\n\n157\n00:08:33.560 --> 00:08:36.440\nSo we just switch back over to our\nroot certification authority or\n\n158\n00:08:36.440 --> 00:08:37.880\ncertificate authority?\n\n159\n00:08:37.880 --> 00:08:40.920\nWe can look at issued\ncertificates here and\n\n160\n00:08:40.920 --> 00:08:44.785\nI can see that we have some\ncertificates that have been issued.\n\n161\n00:08:45.945 --> 00:08:48.595\nNow, let's go ahead and\nlet's install that certificate.\n\n162\n00:08:48.595 --> 00:08:52.835\nAnd let's open the folder,\nwe saved it there in the root.\n\n163\n00:08:52.835 --> 00:08:57.820\nAnd if we look at the Properties of\nthis certificate, we will see, for\n\n164\n00:08:57.820 --> 00:09:01.570\ninstance, the cer format as well,\nindustry wide standards.\n\n165\n00:09:01.570 --> 00:09:04.770\nSome of the other formats that you\nmight see, for instance, are CRT,\n\n166\n00:09:04.770 --> 00:09:07.720\nMicrosoft implements that here as well.\n\n167\n00:09:07.720 --> 00:09:10.170\nBut we'll go ahead,\nwe'll choose OK to this.\n\n168\n00:09:10.170 --> 00:09:13.810\nAnd if we right click on this certificate,\nnot rename it,\n\n169\n00:09:13.810 --> 00:09:17.140\nright click on this certificate,\nwe can actually open it too.\n\n170\n00:09:19.050 --> 00:09:24.130\nAnd one of the things I want you to see\nhere, is that it says, this certification\n\n171\n00:09:24.130 --> 00:09:28.896\ninformation cannot be verified up to\na trusted certification authority.\n\n172\n00:09:28.896 --> 00:09:30.324\nWhy not?\n\n173\n00:09:32.240 --> 00:09:34.477\nWell, I want you to notice something.\n\n174\n00:09:34.477 --> 00:09:36.624\nNotice, Practicelabs.\n\n175\n00:09:36.624 --> 00:09:41.490\nPracticelabs.plab.dco1.ca isn't in\n\n176\n00:09:41.490 --> 00:09:47.150\nmy trusted certification root authorities\ninside of the certificate store.\n\n177\n00:09:47.150 --> 00:09:48.980\nSo my computer's looking at this and\n\n178\n00:09:48.980 --> 00:09:52.480\nsaying, I don't know who that root CA is,\nand I don't trust it.\n\n179\n00:09:52.480 --> 00:09:57.510\nSo in order for this validation to\nhappen unless to trust the root CA\n\n180\n00:09:57.510 --> 00:10:00.800\nwe have to take the root CA's certificate,\nexport it and\n\n181\n00:10:00.800 --> 00:10:06.790\nthen import it into the trusted route\nCA location in the certificate sort.\n\n182\n00:10:06.790 --> 00:10:09.980\nBut let's go ahead, and what we're\ngonna do is we're gonna go ahead, and\n\n183\n00:10:09.980 --> 00:10:11.390\nwe're going to install this certificate.\n\n184\n00:10:12.440 --> 00:10:14.090\nAnd to install this,\n\n185\n00:10:14.090 --> 00:10:16.680\nI'm going to let Windows make up\nits mind where it wants to install.\n\n186\n00:10:16.680 --> 00:10:18.000\nThis is for the local machine.\n\n187\n00:10:18.000 --> 00:10:18.940\nWe'll choose Next.\n\n188\n00:10:20.870 --> 00:10:26.380\nAnd for this Windows already understands\nwhat this is and where it should go.\n\n189\n00:10:26.380 --> 00:10:30.130\nSo I'm gonna go ahead, you could override\nthat but I'm no gonna override it.\n\n190\n00:10:30.130 --> 00:10:32.190\nI'm gonna go ahead and choose Next.\n\n191\n00:10:32.190 --> 00:10:33.250\nAnd then, choose Finish.\n\n192\n00:10:35.140 --> 00:10:37.940\nAnd wait here a second,\nwe'll choose OK to that.\n\n193\n00:10:37.940 --> 00:10:41.960\nTakes a little bit, it could take a little\nbit of time to do the installation here.\n\n194\n00:10:41.960 --> 00:10:45.420\nAnd I want you to understand,\nthat when we do the installs like this,\n\n195\n00:10:45.420 --> 00:10:47.810\nthis isn't something to be taken lightly.\n\n196\n00:10:47.810 --> 00:10:53.220\nYou're manipulating a trust model and\nyou have to ensure that you entrust or\n\n197\n00:10:53.220 --> 00:10:55.940\nyou trust the certificate\nthat's being installed here.\n\n198\n00:10:57.640 --> 00:11:02.830\nAnd I did not see a successful install so,\nand\n\n199\n00:11:02.830 --> 00:11:07.590\nas I hide that,\n&gt;&gt; But we can go back and double check.\n\n200\n00:11:07.590 --> 00:11:09.820\n&gt;&gt; Yes, we're gonna have to go back and\ndouble check on that.\n\n201\n00:11:09.820 --> 00:11:13.520\nAnd just make sure that it did install.\n\n202\n00:11:13.520 --> 00:11:17.000\nUsually, what you see is\na successful installation here.\n\n203\n00:11:18.940 --> 00:11:20.550\n&gt;&gt; And we've disconnected.\n\n204\n00:11:20.550 --> 00:11:21.740\n&gt;&gt; And we've disconnected.\n\n205\n00:11:21.740 --> 00:11:23.010\nWe'll connect one more time.\n\n206\n00:11:23.010 --> 00:11:24.265\nWe'll try this again here.\n\n207\n00:11:24.265 --> 00:11:30.443\nAnd I did not see\na successful install on that.\n\n208\n00:11:30.443 --> 00:11:34.606\nSo, the great thing about it is when\nif it doesn't happen the first time,\n\n209\n00:11:34.606 --> 00:11:36.770\nwe'll let it happen the second time.\n\n210\n00:11:36.770 --> 00:11:39.860\nI might have chosen Cancel.\n\n211\n00:11:43.390 --> 00:11:44.680\nAnd there we go.\n\n212\n00:11:44.680 --> 00:11:47.880\nWe get the install of the certificate,\nand that's what I was looking for.\n\n213\n00:11:47.880 --> 00:11:49.190\nThe import was successful.\n\n214\n00:11:49.190 --> 00:11:53.800\nIf you don't see that, then you don't have\na successful install of the certificate.\n\n215\n00:11:53.800 --> 00:11:56.250\nNow, the next thing that I'm\ngonna do is again, remember,\n\n216\n00:11:56.250 --> 00:11:58.840\nthat certificate isn't trusted yet.\n\n217\n00:11:58.840 --> 00:12:02.870\nSo, for instance,\nif I go up to Tools on this machine and\n\n218\n00:12:02.870 --> 00:12:09.590\nI go to Certificate Authority,\nand I expand this out.\n\n219\n00:12:09.590 --> 00:12:11.520\nNotice that we have our domain member.\n\n220\n00:12:11.520 --> 00:12:15.446\nAnd I look at the Properties,\nnotice it was stopped.\n\n221\n00:12:15.446 --> 00:12:16.537\nI have to restart the service, and\n\n222\n00:12:16.537 --> 00:12:18.390\nit doesn't look like it's\ngiving me that chain of trust.\n\n223\n00:12:18.390 --> 00:12:21.730\nSo let's go ahead,\nlet's switch over to our DC real quick.\n\n224\n00:12:21.730 --> 00:12:26.069\nAnd we're gonna do something,\nwe're gonna help that chain of trust.\n\n225\n00:12:27.960 --> 00:12:31.930\nSo, I'm looking at the Properties or\nthe issued certificates.\n\n226\n00:12:31.930 --> 00:12:34.490\nAnd that's not really\nwhere I wanted to go.\n\n227\n00:12:34.490 --> 00:12:35.750\nLet me go ahead and close this down.\n\n228\n00:12:35.750 --> 00:12:40.853\nAnd via the MMC that we looked at\nearlier for the local machine.\n\n229\n00:12:40.853 --> 00:12:43.317\nIf I look in its personal certificates,\n\n230\n00:12:43.317 --> 00:12:46.150\nI'll actually find\nthe CA certificate here.\n\n231\n00:12:46.150 --> 00:12:49.540\nAnd all I have to really do,\nI could just right-click on it.\n\n232\n00:12:49.540 --> 00:12:54.430\nI can choose Export, and\nit starts the Certificate Export Wizard.\n\n233\n00:12:54.430 --> 00:12:56.030\nAnd we can choose Next.\n\n234\n00:12:56.030 --> 00:12:59.120\nAnd I don't need the private key\non this one, so I'm gonna say, No,\n\n235\n00:12:59.120 --> 00:13:00.840\ndon't export the private key.\n\n236\n00:13:00.840 --> 00:13:02.740\nYou might do that for key archival, but\n\n237\n00:13:02.740 --> 00:13:07.460\nyou certainly shouldn't, you don't need\nit when we talk about verifying the root.\n\n238\n00:13:07.460 --> 00:13:08.310\nWe'll choose Next.\n\n239\n00:13:08.310 --> 00:13:11.250\nAnd then it gives us a various\nformats that we can use.\n\n240\n00:13:11.250 --> 00:13:16.160\nDER, and you can see the CER extensions,\nBase-64.\n\n241\n00:13:16.160 --> 00:13:19.564\nWe can also use the PKSCS standard,\nagain, number 7.\n\n242\n00:13:19.564 --> 00:13:27.150\nWith a P7B, that just means exports\nthe public key but not the private key.\n\n243\n00:13:27.150 --> 00:13:30.128\nIt has happen to be a PKCS number 12 or\n\n244\n00:13:30.128 --> 00:13:35.163\nthe extension there would have\nbeen I had to write this one down.\n\n245\n00:13:35.163 --> 00:13:39.699\nWould have been P12.P12, that would\nhave said export the public key and\n\n246\n00:13:39.699 --> 00:13:40.760\nthe private key.\n\n247\n00:13:40.760 --> 00:13:43.100\nWe don't need that for\nthis case right here.\n\n248\n00:13:43.100 --> 00:13:46.300\n&gt;&gt; But it is important to pay attention\nto what format you are exporting it.\n\n249\n00:13:46.300 --> 00:13:48.760\nBecause when you're setting up\n\n250\n00:13:48.760 --> 00:13:52.250\nthings like different types of trust\nwithin servers in the environment.\n\n251\n00:13:53.520 --> 00:13:55.715\nYeah, I've had that situation\nfail on me a few times.\n\n252\n00:13:55.715 --> 00:13:57.410\n&gt;&gt; [LAUGH] Yeah,\nyou gotta know those formats.\n\n253\n00:13:57.410 --> 00:13:58.735\n&gt;&gt; Pay attention, yes, pay attention.\n\n254\n00:13:58.735 --> 00:14:02.680\n&gt;&gt; Definitely, so let's go ahead, and\nwe're just gonna export this out.\n\n255\n00:14:02.680 --> 00:14:07.850\nAnd we're gonna choose a file name,\nI'll just call it Root.\n\n256\n00:14:07.850 --> 00:14:11.970\nAnd I'm actually going to, tell you what,\nI'll just put it on the desktop for now.\n\n257\n00:14:11.970 --> 00:14:15.860\nAnd we'll choose Save and\nthen choose Next and Finish.\n\n258\n00:14:15.860 --> 00:14:19.960\nLike I said this is where you\nshould have your trusty USB drive.\n\n259\n00:14:19.960 --> 00:14:25.210\nYou should not be doing this\nover any kind of network wire.\n\n260\n00:14:25.210 --> 00:14:29.850\nAnd I'll go ahead and we're gonna\nmove this over to the other server.\n\n261\n00:14:29.850 --> 00:14:34.888\nSo we'll do //, and\nwe will do what is that,\n\n262\n00:14:34.888 --> 00:14:42.485\nplabdm01, I believe is the name,\ndmo1/, and we'll do c$.\n\n263\n00:14:42.485 --> 00:14:48.045\nAnd we'll bring up that certificate and\nwe'll go ahead and put it right there.\n\n264\n00:14:48.045 --> 00:14:51.965\nNow, what we're doing here is we're gonna\nswitch back over to our other machine,\n\n265\n00:14:51.965 --> 00:14:55.355\nour subordinate CA that wasn't\ntrusting the root here.\n\n266\n00:14:55.355 --> 00:14:59.169\nAnd what we're gonna do is I went\nahead and put that on C drive.\n\n267\n00:15:00.310 --> 00:15:01.180\nAnd we're gonna go ahead and\n\n268\n00:15:01.180 --> 00:15:06.130\nwe're gonna import that root certificate,\nthat we just copied over.\n\n269\n00:15:06.130 --> 00:15:11.060\nLike I said guys, you should not be doing\nthis over the Internet by any means,\n\n270\n00:15:11.060 --> 00:15:12.770\nor any network.\n\n271\n00:15:12.770 --> 00:15:13.320\n&gt;&gt; The interwebs.\n\n272\n00:15:13.320 --> 00:15:15.300\n&gt;&gt; The interwebs, there we go.\n\n273\n00:15:15.300 --> 00:15:17.660\nWe'll choose certificate install.\n\n274\n00:15:17.660 --> 00:15:21.830\nAnd this is gonna import that certificate,\nand I'm actually gonna kinda override it.\n\n275\n00:15:21.830 --> 00:15:25.520\nI'm gonna say place all this\ncertificate in the following store.\n\n276\n00:15:25.520 --> 00:15:30.510\nAnd I'm gonna put it in the Trusted\nRoot Certification Authorities location.\n\n277\n00:15:30.510 --> 00:15:34.240\nAnd we'll go ahead and\nchoose Next on that, and then Finish.\n\n278\n00:15:35.310 --> 00:15:41.093\nNow we're gonna go ahead, and\nwe're gonna open up our, close that.\n\n279\n00:15:45.164 --> 00:15:51.109\nLet me see here, double-check there's our,\nlooks like that is still working.\n\n280\n00:15:51.109 --> 00:15:52.814\nLet me go ahead and\n\n281\n00:15:52.814 --> 00:15:58.282\nopen up our certification\nauthority one more time here.\n\n282\n00:15:58.282 --> 00:16:05.980\nAnd looks like we should be able to\nstart the service here, and there we go.\n\n283\n00:16:05.980 --> 00:16:10.100\nIt's gonna ask us if we want to install\nthat root certificate and there it is.\n\n284\n00:16:10.100 --> 00:16:13.074\nI can install it.\nThat should, Active Directory will need to\n\n285\n00:16:13.074 --> 00:16:18.020\nrerun the configuration, can not, okay,\nso we'll go ahead and choose OK to that.\n\n286\n00:16:20.390 --> 00:16:23.490\nAnd let's see if we can start it yet.\n\n287\n00:16:23.490 --> 00:16:24.806\nIt might not start.\n\n288\n00:16:24.806 --> 00:16:27.430\nIt's giving me a hard time.\n\n289\n00:16:27.430 --> 00:16:30.806\nOkay, it looks like it\ndid not install here.\n\n290\n00:16:30.806 --> 00:16:34.830\n&gt;&gt; All right, Wes,\nI notice that this service isn't starting.\n\n291\n00:16:34.830 --> 00:16:37.320\nIs it because we're in\nan untrusted state right now?\n\n292\n00:16:37.320 --> 00:16:39.871\n&gt;&gt; That's right.\nEverything revolves around a model\n\n293\n00:16:39.871 --> 00:16:40.503\nof trust.\n\n294\n00:16:40.503 --> 00:16:43.640\nAnd like you've seen,\nwhen we issued that certificate,\n\n295\n00:16:43.640 --> 00:16:45.570\nit didn't trust the root, right?\n\n296\n00:16:45.570 --> 00:16:48.570\nSo we have to make sure that we have\nthe certificate chain in place, and\n\n297\n00:16:48.570 --> 00:16:50.340\nthere's a couple different ways\nthat you can do this, right?\n\n298\n00:16:50.340 --> 00:16:53.970\nI could have downloaded the whole entire\ncertificate chain, or you can, and\n\n299\n00:16:53.970 --> 00:16:58.070\nsince this is really only two in the\nchain, I could take the root certificate\n\n300\n00:16:58.070 --> 00:17:02.080\nand I can import it into the trusted\nroot certification store.\n\n301\n00:17:02.080 --> 00:17:03.620\nAnd then it becomes a trusted state.\n\n302\n00:17:03.620 --> 00:17:04.700\nSo let's go ahead and do that.\n\n303\n00:17:04.700 --> 00:17:07.240\nYou can see the screen here again,\nremember,\n\n304\n00:17:07.240 --> 00:17:12.640\nwe try to right-click and\nstart the service, and it's going to fail.\n\n305\n00:17:12.640 --> 00:17:14.792\nOr we could do something like this, right?\n\n306\n00:17:14.792 --> 00:17:18.430\nWe could just go ahead and open up an MMC.\n\n307\n00:17:18.430 --> 00:17:19.810\nLike I said, you can also download,\n\n308\n00:17:19.810 --> 00:17:22.710\nthis is part of the downloading\nthe certificate.\n\n309\n00:17:22.710 --> 00:17:26.080\nYou just download the whole\nentire chain as well.\n\n310\n00:17:26.080 --> 00:17:28.210\nOr we could go to certificates, right?\n\n311\n00:17:28.210 --> 00:17:32.940\nAnd I've already exported remember\nexported the public key of the certificate\n\n312\n00:17:32.940 --> 00:17:36.150\nauthority and again we'll choose Next.\n\n313\n00:17:36.150 --> 00:17:39.990\nAgain this is gonna be the local computer\ncuz it is the certificate authority,\n\n314\n00:17:39.990 --> 00:17:45.330\nthe subordinate authority that we\nwanna import, the root CA certificate.\n\n315\n00:17:45.330 --> 00:17:48.160\nAll right, and we'll go ahead and\nlet's see here,\n\n316\n00:17:48.160 --> 00:17:52.490\nlet's find out if that certificate\nis in the trusted root store.\n\n317\n00:17:52.490 --> 00:17:54.790\nAnd you'll notice that\nthere is nothing in here.\n\n318\n00:17:54.790 --> 00:17:59.310\nWe're not seeing anything in here that\nsays PLABs, so that is missing and\n\n319\n00:17:59.310 --> 00:18:02.830\nthat's why that service will not start up.\n\n320\n00:18:02.830 --> 00:18:06.670\nAll right, so we'll go ahead and\nI went ahead and like you see,\n\n321\n00:18:06.670 --> 00:18:09.860\nimported that certificate or\nexported that certificate.\n\n322\n00:18:09.860 --> 00:18:11.820\nAnd here's the root certificate.\n\n323\n00:18:11.820 --> 00:18:14.180\nAnd we'll go ahead and what we're gonna\ndo is we're gonna right click on it.\n\n324\n00:18:14.180 --> 00:18:16.620\nWe're gonna choose Install Certificate,\nand\n\n325\n00:18:16.620 --> 00:18:19.749\nI'm gonna change it to the local\nmachine here, and we'll choose Next.\n\n326\n00:18:21.460 --> 00:18:22.280\nAnd it's gonna say,\n\n327\n00:18:22.280 --> 00:18:26.220\nAutomatically select the certificate\nstore based on the certificate type.\n\n328\n00:18:26.220 --> 00:18:28.910\nI'm gonna go ahead and show you guys,\nI'm gonna override that.\n\n329\n00:18:28.910 --> 00:18:30.200\nA lot of the times, or most of the times,\n\n330\n00:18:30.200 --> 00:18:32.680\nwhat I'll do is I'll just let\nWindows make the decision.\n\n331\n00:18:32.680 --> 00:18:36.380\nBut I kind of wanna show you that we can\nbrowse and we could override that and\n\n332\n00:18:36.380 --> 00:18:38.520\nwe could manually put this\nwhere we wanna put it.\n\n333\n00:18:38.520 --> 00:18:41.500\nBut I wanna make sure that it gets\ninto that trusted root certification\n\n334\n00:18:41.500 --> 00:18:45.250\nauthorities location, and we'll choose OK.\n\n335\n00:18:45.250 --> 00:18:48.530\nAnd then we'll choose Next and\nthen we'll choose Finish.\n\n336\n00:18:48.530 --> 00:18:49.691\nAnd we'll wait a second, and\n\n337\n00:18:49.691 --> 00:18:52.633\nhopefully what we're gonna see is\nthat the import is successful, right?\n\n338\n00:18:52.633 --> 00:18:56.270\nYou gotta get that,\nmake sure that that's there.\n\n339\n00:18:56.270 --> 00:18:58.940\nAnd I always do a double verification,\nlike for\n\n340\n00:18:58.940 --> 00:19:03.510\ninstance I'll go back to the MMC again.\n\n341\n00:19:03.510 --> 00:19:07.730\nAnd when we launch that up, go ahead and\nwe'll add that certificate.\n\n342\n00:19:07.730 --> 00:19:08.720\nSnap in again.\n\n343\n00:19:08.720 --> 00:19:12.110\nAnd, yes, it'll be the local computer and\nwe're just kind of doing a verification so\n\n344\n00:19:12.110 --> 00:19:16.180\nI can show you that the root CA\ncertificate is now in there.\n\n345\n00:19:16.180 --> 00:19:22.010\nWe'll go back to trusted root\ncertification authorities.\n\n346\n00:19:22.010 --> 00:19:24.918\nRemember this is where we\nare looking right here.\n\n347\n00:19:24.918 --> 00:19:27.420\nWe'll choose Certificates and\nthen, sure enough,\n\n348\n00:19:27.420 --> 00:19:30.200\nI do see that the root\nCA certificate is there.\n\n349\n00:19:30.200 --> 00:19:33.771\nSo hopefully, that's gonna provide\nus that trusted state that we want.\n\n350\n00:19:33.771 --> 00:19:37.710\nWe'll go ahead and\nclose down all these extra dialogue boxes.\n\n351\n00:19:37.710 --> 00:19:42.210\nAnd then we will right-click,\nchoose All Tasks, and start the service.\n\n352\n00:19:42.210 --> 00:19:46.490\nAnd we'll let it find out, hey,\ndo I actually trust that certificate?\n\n353\n00:19:46.490 --> 00:19:49.890\nAnd sure enough,\nwe now have a subordinate CA, right?\n\n354\n00:19:49.890 --> 00:19:53.920\nWe have our intermediate CA,\nand it has a certificate.\n\n355\n00:19:53.920 --> 00:19:58.470\nIf we choose Properties, we view its\ncertificate, no longer do we have that\n\n356\n00:19:58.470 --> 00:20:01.640\nlittle red X on there, that says,\nwhoa, whoa, wait a second.\n\n357\n00:20:01.640 --> 00:20:05.229\nWe don't know what CA you're talking\nabout, because now it's looking down in\n\n358\n00:20:05.229 --> 00:20:09.210\nthat certificate store, and it says,\nyeah, I find that root certificate, right?\n\n359\n00:20:09.210 --> 00:20:10.300\n&gt;&gt; I know who's vouching for you.\n\n360\n00:20:10.300 --> 00:20:13.940\n&gt;&gt; That's exactly it, and\nnow we can verify that our intermediate CA\n\n361\n00:20:13.940 --> 00:20:17.700\nis ready to be now in our\ntwo-tiered hierarchy.\n\n362\n00:20:17.700 --> 00:20:19.870\nIt's ready to be the issuing CA.\n\n363\n00:20:19.870 --> 00:20:20.370\nAnd remember,\n\n364\n00:20:20.370 --> 00:20:25.260\nwe call the intermediate CA an issuing CA\ncuz it's really gonna be the workhorse.\n\n365\n00:20:25.260 --> 00:20:30.960\nAnd now we can, if we want, depending on\nhow many intermediate CAs we have, in this\n\n366\n00:20:30.960 --> 00:20:36.670\npoint what we would do is we'd take this\nCA right now and we would shut it down.\n\n367\n00:20:36.670 --> 00:20:38.910\nAnd it becomes the offline CA.\n\n368\n00:20:38.910 --> 00:20:42.530\nWhere this CA stays online and\nstarts to become the workhorse.\n\n369\n00:20:42.530 --> 00:20:43.490\nAnd really, they are.\n\n370\n00:20:43.490 --> 00:20:45.821\nThe intermediate CAs and the issuing CAs,\n\n371\n00:20:45.821 --> 00:20:48.421\nthey're the workhorses\nof your internal PKI.\n\n372\n00:20:48.421 --> 00:20:51.894\nCuz they're the ones that are responsible\nfor making sure that your users,\n\n373\n00:20:51.894 --> 00:20:55.692\nyour machines, your storage networks,\nnetwork devices all have the appropriate\n\n374\n00:20:55.692 --> 00:20:58.800\ncertificates and that they're\ntrusted throughout your network.\n\n375\n00:20:59.810 --> 00:21:01.630\n&gt;&gt; All right, Wes, we are short on time.\n\n376\n00:21:01.630 --> 00:21:03.690\nAnd I know that we have\na little bit to cover, still.\n\n377\n00:21:03.690 --> 00:21:05.860\nDo you want to go ahead and\nsave that for another episode?\n\n378\n00:21:05.860 --> 00:21:06.730\n&gt;&gt; That sounds good,\n\n379\n00:21:06.730 --> 00:21:11.130\nI think that I can fit enough,\nPKI is its own beast in and of itself.\n\n380\n00:21:11.130 --> 00:21:13.630\nWe could probably talk about this for\nthe week.\n\n381\n00:21:13.630 --> 00:21:16.670\nHowever, keep in mind, high-level\noverview for Security Plus, but yeah,\n\n382\n00:21:16.670 --> 00:21:18.370\nI think we have another episode coming.\n\n383\n00:21:18.370 --> 00:21:19.960\n&gt;&gt; Perfect, thank you so\nmuch for joining us.\n\n384\n00:21:19.960 --> 00:21:22.700\nAnd thank you ladies and gentlemen for\nbeing with us today as well.\n\n385\n00:21:22.700 --> 00:21:25.980\nFor this show we'll go ahead and sign out,\nremember I'm your host Cherokee Boose.\n\n386\n00:21:25.980 --> 00:21:26.780\n&gt;&gt; And I'm Wes Bryan.\n\n387\n00:21:26.780 --> 00:21:28.026\n&gt;&gt; See you next time here at ITProTV.\n\n388\n00:21:28.026 --> 00:21:35.743\n[MUSIC]\n\n389\n00:21:35.743 --> 00:21:38.324\n&gt;&gt; Thank you for watching ITProTV.\n\n",
          "vimeoId": "214509936"
        },
        {
          "description": "In this show, Cherokee and Wes continue to explain PKI. Wes also demonstrates how create and configure a Root CA. He also sets up a subordinate s CA in Windows Server 2012.",
          "length": "1789",
          "thumbnail": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-4-public_key_infrastructure_pt4-042017-PGM.00_29_35_08.Still001.png",
          "thumbnailMed": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-4-public_key_infrastructure_pt4-042017-PGM.00_29_35_08.Still001-med.jpg",
          "thumbnailSm": "https://itprotv-image-bucket.s3.amazonaws.com/comptia-secplussy501/comptia-secplussy0501-6-4-4-public_key_infrastructure_pt4-042017-PGM.00_29_35_08.Still001-sm.jpg",
          "title": "Public Key Infrastructure Part 4",
          "transcript": "WEBVTT\n\n1\n00:00:00.270 --> 00:00:06.469\nWelcome to ITProTV, I'm your host-\n&gt;&gt; [CROSSTALK]\n\n2\n00:00:06.469 --> 00:00:08.373\n[MUSIC]\n\n3\n00:00:08.373 --> 00:00:11.972\n&gt;&gt; You're watching ITProTV.\n\n4\n00:00:11.972 --> 00:00:15.800\n&gt;&gt; Welcome ladies and gentlemen,\nto your CompTIA Security+ series.\n\n5\n00:00:15.800 --> 00:00:17.790\nI'm your show host, Cherokee Boose.\n\n6\n00:00:17.790 --> 00:00:21.190\nNow it seems like we, what else could we\nhave left with public key infrastructure?\n\n7\n00:00:21.190 --> 00:00:22.840\nWell, there's actually a lot left.\n\n8\n00:00:22.840 --> 00:00:25.680\nAnd with us today, to help cover\nthe information, is Wes Bryan.\n\n9\n00:00:25.680 --> 00:00:26.670\nThank you for joining us, Wes.\n\n10\n00:00:26.670 --> 00:00:28.070\n&gt;&gt; Hey, Cherokee,\nthanks for having me back.\n\n11\n00:00:28.070 --> 00:00:32.200\nYes, that's right, I've talked ourselves\nright into a small miniseries here on PKI.\n\n12\n00:00:32.200 --> 00:00:35.900\nBut there are a few things that we have\nleft, that we wanna kind of tie off.\n\n13\n00:00:35.900 --> 00:00:38.000\nEspecially when it comes to\nthe objectives for the exam.\n\n14\n00:00:38.000 --> 00:00:39.900\nAnd also just for\nyour real-world knowledge.\n\n15\n00:00:39.900 --> 00:00:42.500\nBecause we've been talking,\nover the last few\n\n16\n00:00:42.500 --> 00:00:46.670\nparts of this series that we're running\nhere, about some of the components.\n\n17\n00:00:46.670 --> 00:00:48.420\nThings like our certificate authorities.\n\n18\n00:00:48.420 --> 00:00:50.840\nWe've talked about\nthe hierarchy that we have.\n\n19\n00:00:50.840 --> 00:00:53.970\nFor instance, the root certificate\nauthority if you will, or\n\n20\n00:00:53.970 --> 00:00:55.510\ncertification authority.\n\n21\n00:00:55.510 --> 00:00:59.500\nWe've talked about how that that\nCA is typically an offline CA.\n\n22\n00:00:59.500 --> 00:01:03.310\nWe've also talked about some other\nsubordinate CAs below it, and\n\n23\n00:01:03.310 --> 00:01:04.190\nthen that hierarchy.\n\n24\n00:01:04.190 --> 00:01:05.970\nThen we've talked a little\nbit about the certificates.\n\n25\n00:01:05.970 --> 00:01:09.170\nNow, one of the things that I wanna\nkind of mention is how, let's say,\n\n26\n00:01:09.170 --> 00:01:10.480\nif we're gonna issue certificates.\n\n27\n00:01:10.480 --> 00:01:13.800\nRemember, we can issue them out to\nall different kinds of things, right,\n\n28\n00:01:13.800 --> 00:01:14.580\nentities if you will.\n\n29\n00:01:16.500 --> 00:01:18.630\nWe can issue them out to users,\nwe can issue them out to machines.\n\n30\n00:01:18.630 --> 00:01:22.010\nMachines can be more of\nan automated approach.\n\n31\n00:01:22.010 --> 00:01:24.010\nI say automated,\nit's not completely automated.\n\n32\n00:01:24.010 --> 00:01:28.830\nBut you do have things like the network\ndevice enrollment protocols out there.\n\n33\n00:01:28.830 --> 00:01:33.580\nThat allow devices, if you will, to go\nahead and enroll on their own behalf.\n\n34\n00:01:33.580 --> 00:01:36.780\nYou've seen that we also had to enroll for\n\n35\n00:01:36.780 --> 00:01:39.530\na certificate to bring\nthe subordinate CA online.\n\n36\n00:01:39.530 --> 00:01:41.950\nSo there was a little bit of\ninteraction that went on there.\n\n37\n00:01:41.950 --> 00:01:44.050\nBut what is a user gonna go through?\n\n38\n00:01:44.050 --> 00:01:46.040\nSo let's kinda just talk\nabout that process here.\n\n39\n00:01:46.040 --> 00:01:48.570\nIn fact, I got a little diagram,\nif we can take a look at that.\n\n40\n00:01:48.570 --> 00:01:51.750\nSo if this gentleman is\ngoing to get a certificate,\n\n41\n00:01:51.750 --> 00:01:54.740\none of the first things that has to\nhappen is identification, all right?\n\n42\n00:01:54.740 --> 00:01:56.150\nKeep in mind that identification and\n\n43\n00:01:56.150 --> 00:02:00.800\nauthentication are separate,\ndifferent concepts, if you will.\n\n44\n00:02:00.800 --> 00:02:04.810\nRemember that identification\nis proving who the user is.\n\n45\n00:02:04.810 --> 00:02:08.160\nRemember, authentication is just\na validation of credentials.\n\n46\n00:02:08.160 --> 00:02:12.070\nThe authentication, in and of itself,\ndoesn't prove that the user that has that\n\n47\n00:02:12.070 --> 00:02:15.680\nauthentication information is actually\nthe person that should have those, right?\n\n48\n00:02:15.680 --> 00:02:18.420\nSo, for instance,\nif Cherokee left herself logged in and\n\n49\n00:02:18.420 --> 00:02:22.310\nI happen to grab some\npasswords however I could.\n\n50\n00:02:22.310 --> 00:02:24.430\nI can turn around and\nlog in as Cherokee, right?\n\n51\n00:02:24.430 --> 00:02:27.190\nI'm authenticating against the system,\nthat is authentication.\n\n52\n00:02:27.190 --> 00:02:30.750\nBut it doesn't prove that it's me,\nthat should have those credentials.\n\n53\n00:02:30.750 --> 00:02:32.052\nSo the first thing we have to do,\n\n54\n00:02:32.052 --> 00:02:36.710\nif we're gonna do the certificate-based\nauthentication, we're gonna use the PKI.\n\n55\n00:02:36.710 --> 00:02:39.560\nWe have make sure that we\nidentify the end user, right?\n\n56\n00:02:39.560 --> 00:02:41.580\nWe have to go to whatever process is, and\n\n57\n00:02:41.580 --> 00:02:43.840\nyour company could have\ndone different processes.\n\n58\n00:02:43.840 --> 00:02:47.430\nThen once the user is identified,\nand we're gonna issue a certificate,\n\n59\n00:02:47.430 --> 00:02:49.790\nnext thing comes is registration, right?\n\n60\n00:02:49.790 --> 00:02:53.960\nWe talked about certificate-signing\nrequests that have to be issued out.\n\n61\n00:02:53.960 --> 00:02:57.970\nOnce that happens, once all the checks and\nbalances, we have identified the person,\n\n62\n00:02:57.970 --> 00:02:59.580\nthey've gone through the registration.\n\n63\n00:02:59.580 --> 00:03:01.510\nThen what we have is an issuance.\n\n64\n00:03:01.510 --> 00:03:03.950\nNow, keep in mind that when\nwe issue the certificate,\n\n65\n00:03:03.950 --> 00:03:07.300\nthat doesn't mean that the user\ncan use it right away.\n\n66\n00:03:07.300 --> 00:03:10.190\nRight, when you issue the certificate it\nactually goes into the database, right?\n\n67\n00:03:10.190 --> 00:03:13.610\nA protected location on\nthe certificate authority within its,\n\n68\n00:03:13.610 --> 00:03:15.800\nlet's say on its hard drive.\n\n69\n00:03:15.800 --> 00:03:19.440\nBut then we gotta go to\nthe distribution part.\n\n70\n00:03:19.440 --> 00:03:22.900\nNow keep in mind, that some of\nthe things that we've done over the past\n\n71\n00:03:22.900 --> 00:03:27.260\nportions of this PKI journey that\nwe're on, have been over the wire.\n\n72\n00:03:27.260 --> 00:03:30.220\nAnd you do have things like, for\ninstance, your web enrollments.\n\n73\n00:03:30.220 --> 00:03:33.850\nYou've seen us login, well, kinda login,\n\n74\n00:03:33.850 --> 00:03:37.710\nwe have to login to issue the certificate,\nbut we've used a web browser, right?\n\n75\n00:03:37.710 --> 00:03:40.950\nWe've used Internet Explorer to\nconnect to the web enrollment page.\n\n76\n00:03:40.950 --> 00:03:44.190\nAnd we've requested the certificate, and\nthen we've downloaded it from there.\n\n77\n00:03:44.190 --> 00:03:46.050\nSo that could be a method of distribution.\n\n78\n00:03:46.050 --> 00:03:49.050\nKeep in mind,\nthat if it is things like CAs, in general,\n\n79\n00:03:49.050 --> 00:03:50.610\nthat you're bringing online?\n\n80\n00:03:50.610 --> 00:03:53.360\nYou typically don't wanna be\ndoing this over the wire.\n\n81\n00:03:53.360 --> 00:03:56.780\nAnd moreso, if you are doing\nthings like web enrollment?\n\n82\n00:03:56.780 --> 00:04:00.820\nYou're gonna take one of the certificates\nand you're gonna assign it, if you will,\n\n83\n00:04:00.820 --> 00:04:04.810\nto whatever your server is that's\nallowing you to do the web enrollment.\n\n84\n00:04:04.810 --> 00:04:07.560\nSo you can have SSL or TLS encryption, so\n\n85\n00:04:07.560 --> 00:04:10.530\nthat you make sure that there's no\nman-in-the-middle attacks on those.\n\n86\n00:04:10.530 --> 00:04:12.290\nSo once the distribution has happened,\n\n87\n00:04:12.290 --> 00:04:16.120\nhowever you get the certificate\nto the end point, or the user.\n\n88\n00:04:16.120 --> 00:04:17.440\nThen we have the installation.\n\n89\n00:04:17.440 --> 00:04:22.160\nAnd the installation is where you find\nthat that certificate has been installed\n\n90\n00:04:22.160 --> 00:04:26.000\nto the local certificate store,\non the machine that the person is using.\n\n91\n00:04:26.000 --> 00:04:30.240\nIn fact, if we kinda jump over here to,\nI got a Windows server here.\n\n92\n00:04:30.240 --> 00:04:33.210\nRemember, we kind of looked at the MMC,\n\n93\n00:04:33.210 --> 00:04:38.400\nwhere we could see the different\ncertificates that are on the machine.\n\n94\n00:04:38.400 --> 00:04:43.064\nAnd if I add a snap-in,\nthe certificate snap-in to this, and\n\n95\n00:04:43.064 --> 00:04:45.180\nwe'll go ahead and do that.\n\n96\n00:04:45.180 --> 00:04:46.960\nWe'll choose certificate snap-in.\n\n97\n00:04:46.960 --> 00:04:51.090\nRemember that I do have the option that I\ncan do a user account, service account,\n\n98\n00:04:51.090 --> 00:04:51.940\nor computer account.\n\n99\n00:04:51.940 --> 00:04:54.990\nIn this case If we install it to a user,\n\n100\n00:04:54.990 --> 00:04:57.030\nit's going to go into\nthe user's trusted store.\n\n101\n00:04:58.070 --> 00:04:59.940\nAnd we'll choose OK.\n\n102\n00:04:59.940 --> 00:05:04.120\nAnd if we expand this out, remember that\nthe user also has these same locations.\n\n103\n00:05:04.120 --> 00:05:06.870\nIncluding things like the trusted\nroot certification authority.\n\n104\n00:05:06.870 --> 00:05:08.120\nI always get that messed up.\n\n105\n00:05:08.120 --> 00:05:10.260\nI always want to say root\ncertificate authority.\n\n106\n00:05:10.260 --> 00:05:13.810\nBut again, it's spelled out full here,\ncertification authority.\n\n107\n00:05:13.810 --> 00:05:16.220\nBut the user certificates\nare going to be down here,\n\n108\n00:05:16.220 --> 00:05:18.870\ninside of the personal location.\n\n109\n00:05:18.870 --> 00:05:22.120\nIn fact, you can see that\nthe administrator has a certificate\n\n110\n00:05:22.120 --> 00:05:23.650\nissued to them.\n\n111\n00:05:23.650 --> 00:05:26.670\nAll right, and I could actually,\nif I wanted to select the certificate,\n\n112\n00:05:26.670 --> 00:05:29.830\nI could right-click on it,\nI could choose Properties.\n\n113\n00:05:29.830 --> 00:05:32.250\nActually I can just open it and view it.\n\n114\n00:05:32.250 --> 00:05:34.520\nI'm gonna try that again there,\nthere we go, all right.\n\n115\n00:05:34.520 --> 00:05:37.043\nAnd we can see the details\nof the certificate,\n\n116\n00:05:37.043 --> 00:05:40.160\nand who it was issued from,\nand who it was issued, or to.\n\n117\n00:05:40.160 --> 00:05:42.780\nAnd who it was issued by.\n\n118\n00:05:42.780 --> 00:05:46.290\nSo keep in mind, that there is that\nprocess that you have to go through,\n\n119\n00:05:46.290 --> 00:05:48.650\nwhen it comes to getting a certificate.\n\n120\n00:05:48.650 --> 00:05:50.370\nRemember it does require a certificate.\n\n121\n00:05:50.370 --> 00:05:52.680\nIt's a CSR, Certificate Signing Request.\n\n122\n00:05:52.680 --> 00:05:55.730\nAnd then we have to go through that\nprocess to actually get it installed\n\n123\n00:05:55.730 --> 00:05:58.390\non the end-user's machine so\nthat they can use it.\n\n124\n00:05:59.730 --> 00:06:02.425\nAll right, so some of the other\nthings that we wanna talk about, too,\n\n125\n00:06:02.425 --> 00:06:04.425\nare things like chain validation.\n\n126\n00:06:04.425 --> 00:06:08.585\nAnd we've kinda mentioned this,\nthat we have to trust this hierarchy.\n\n127\n00:06:08.585 --> 00:06:12.755\nAnd any certificate that you\nmight look at out there that is,\n\n128\n00:06:12.755 --> 00:06:15.645\nespecially when we talk about\nthings like public access.\n\n129\n00:06:15.645 --> 00:06:20.199\nYou'll see that there is a path that\nleads all the way back up to the root.\n\n130\n00:06:21.430 --> 00:06:25.540\nSo, for instance, we've been kind of\nusing Google's certificate here, and\n\n131\n00:06:25.540 --> 00:06:27.420\na couple of different ones there.\n\n132\n00:06:27.420 --> 00:06:31.810\nAnd if I bring up that certificate here,\nand we can take a look at it.\n\n133\n00:06:31.810 --> 00:06:34.450\nAgain, remember,\nyou can see that hierarchy, right?\n\n134\n00:06:34.450 --> 00:06:37.640\nAnd this is what's known as\ncertificate chain validation.\n\n135\n00:06:37.640 --> 00:06:43.130\nIf the host, let's say Google, this is a\ncertificate that was issued to my company.\n\n136\n00:06:43.130 --> 00:06:47.970\nObviously, I don't own Google, but\nit starts out with whatever the host is.\n\n137\n00:06:47.970 --> 00:06:50.480\nAnd then, when the host presents\nthe certificate back to the web browser.\n\n138\n00:06:50.480 --> 00:06:52.670\nThe web browser then goes and says, hey.\n\n139\n00:06:52.670 --> 00:06:55.740\nWell, let's check out who\nissued you your certificate.\n\n140\n00:06:55.740 --> 00:06:58.360\nIn this case, Google,\nwho issued you your certificate?\n\n141\n00:06:58.360 --> 00:07:01.680\nAnd we can see, in this case, Google's big\nenough, just like some other companies,\n\n142\n00:07:01.680 --> 00:07:04.530\nthat they are their own\ncertificate authority.\n\n143\n00:07:04.530 --> 00:07:08.250\nAnd we gonna verify, well okay,\nlet's look Google's certificate, and\n\n144\n00:07:08.250 --> 00:07:10.650\nlet's see where Google\ngot their certificate.\n\n145\n00:07:10.650 --> 00:07:14.490\nSo we can see, even the CA's\ncertificate that's been issued, right?\n\n146\n00:07:14.490 --> 00:07:16.820\nAnd all the way back up to the root.\n\n147\n00:07:16.820 --> 00:07:19.230\nAgain, this is what known as\ncertificate chain validation,\n\n148\n00:07:19.230 --> 00:07:22.770\nwe're validating that chain\nof trust if you will.\n\n149\n00:07:22.770 --> 00:07:26.650\nNow, some of the other things that go on\nwhen you do a certificate chain validation\n\n150\n00:07:26.650 --> 00:07:29.970\nis, you have to inspect\nwhat is known as a CRL.\n\n151\n00:07:30.970 --> 00:07:32.860\nAll right, now the CRL,\nwhat does that stand for?\n\n152\n00:07:32.860 --> 00:07:35.530\nThat is another acronym in\nthe alphabet soup world, right?\n\n153\n00:07:35.530 --> 00:07:39.020\nThat is the certificate replication list,\nall right.\n\n154\n00:07:39.020 --> 00:07:41.430\nRemember, that if you\npresent a driver's license.\n\n155\n00:07:41.430 --> 00:07:45.440\nAgain, let's say for instance,\nlaw enforcement, right?\n\n156\n00:07:45.440 --> 00:07:47.740\nWhat do they check on your license,\nand actually for anybody?\n\n157\n00:07:47.740 --> 00:07:51.660\nA bank is one that I use, cuz I don't want\nyou to think it's always law enforcement\n\n158\n00:07:51.660 --> 00:07:53.000\nthat we are presenting your IDs to.\n\n159\n00:07:53.000 --> 00:07:55.300\nBut it's a commonality,\nthat sometimes it has to happen.\n\n160\n00:07:55.300 --> 00:07:57.580\nWhat is the law enforcement\nofficer is gonna do?\n\n161\n00:07:57.580 --> 00:08:02.770\nFirst of all, they have to find out Is\nyour license within its validity period?\n\n162\n00:08:02.770 --> 00:08:07.076\nRight, it hasn't expired cuz an expired\nlicense isn't even good as a form of\n\n163\n00:08:07.076 --> 00:08:08.930\nidentification.\n\n164\n00:08:08.930 --> 00:08:10.000\nWell guess what?\n\n165\n00:08:10.000 --> 00:08:13.310\nCertificates aren't valid, if you will,\n\n166\n00:08:13.310 --> 00:08:16.730\na valid form of proving identity,\nif they've expired.\n\n167\n00:08:16.730 --> 00:08:18.710\nSo we can actually look\nat that information, and\n\n168\n00:08:18.710 --> 00:08:21.670\nwe can see in the certificate right here.\n\n169\n00:08:21.670 --> 00:08:25.710\nThat hey,\nit is valid from this time to this time.\n\n170\n00:08:25.710 --> 00:08:29.712\nIn fact you can see it's not\nvalid before May 21, 2002.\n\n171\n00:08:29.712 --> 00:08:31.327\nSo we're pretty good on that one.\n\n172\n00:08:31.327 --> 00:08:33.200\nWe're a little bit past that date.\n\n173\n00:08:33.200 --> 00:08:37.030\nBut you can see that it expires and\nit lets you know.\n\n174\n00:08:37.030 --> 00:08:43.041\nNot valid after, in this case,\nMay 21st 2000 or 2022, all right.\n\n175\n00:08:43.041 --> 00:08:45.040\nSo that's the first thing\nthat we have to validate.\n\n176\n00:08:45.040 --> 00:08:49.030\nWe have to validate is\nthe certificate within its lifecycle.\n\n177\n00:08:49.030 --> 00:08:51.030\nBut the next thing we do\nis we have to check and\n\n178\n00:08:51.030 --> 00:08:55.310\nmake sure has this certificate,\nhas it been revoked?\n\n179\n00:08:55.310 --> 00:08:57.330\nHas it been suspended for any reason?\n\n180\n00:08:57.330 --> 00:09:00.190\nRight, because I can present\na driver's license to a bank and\n\n181\n00:09:00.190 --> 00:09:04.160\nit's within, or in this case,\nI will use the law enforcement analogy.\n\n182\n00:09:04.160 --> 00:09:08.590\nI could present a drivers license to an\nofficer of the law and they can say, he or\n\n183\n00:09:08.590 --> 00:09:12.040\nshe could say, yeah it isn't suspended, or\n\n184\n00:09:12.040 --> 00:09:16.540\nit's valid within its life time,\nright, but it's suspended.\n\n185\n00:09:16.540 --> 00:09:18.960\nNow that means the date\non the driver's license.\n\n186\n00:09:18.960 --> 00:09:21.800\nWe haven't gone past the expiration date,\nbut\n\n187\n00:09:21.800 --> 00:09:24.170\nthe validity of the driver's\nlicense has changed.\n\n188\n00:09:24.170 --> 00:09:28.150\nBecause now, it's under the suspended\nstate regardless of what the lifetime is.\n\n189\n00:09:28.150 --> 00:09:34.520\nSo we have to do things like checking\nwhat is known as the CRL, or the crill.\n\n190\n00:09:34.520 --> 00:09:37.427\n&gt;&gt; All right, Wes, so\nwhat are we actually gonna be looking for\n\n191\n00:09:37.427 --> 00:09:38.625\nwhen we examine the CRL?\n\n192\n00:09:38.625 --> 00:09:39.906\n&gt;&gt; One of the things that we look for\n\n193\n00:09:39.906 --> 00:09:42.390\nis to make sure that the certificate\nitself is valid, right?\n\n194\n00:09:42.390 --> 00:09:45.510\nWhen we make mention of things like\nlaw enforcement officers, and again,\n\n195\n00:09:45.510 --> 00:09:50.300\nyou're presenting your driver's license to\nthem, and the expiry date is still good,\n\n196\n00:09:50.300 --> 00:09:53.340\nwe're still before that, well,\nthey also check their database, right?\n\n197\n00:09:53.340 --> 00:09:56.527\nAnd they go through a process of finding\nout has it been suspended, right?\n\n198\n00:09:56.527 --> 00:09:57.893\nAre you driving on a suspended license?\n\n199\n00:09:57.893 --> 00:10:00.730\nSo certificates,\nwhen they're presented to you,\n\n200\n00:10:00.730 --> 00:10:04.410\ncould be going through a process\nthat is known as revoking, right?\n\n201\n00:10:04.410 --> 00:10:06.930\nAnd there's a few different reasons\nwhy you might revoke a certificate.\n\n202\n00:10:06.930 --> 00:10:08.280\nLet me show you what\nI'm talking about here.\n\n203\n00:10:08.280 --> 00:10:13.192\nSo I'm on my server here.\n\n204\n00:10:13.192 --> 00:10:15.366\nAnd let me go ahead and\nswitch over to that server here,\n\n205\n00:10:15.366 --> 00:10:17.518\nI connected to the wrong machine,\nand get logged in.\n\n206\n00:10:17.518 --> 00:10:21.516\nAnd we'll go ahead and\nwhat we'll do is we'll publish,\n\n207\n00:10:21.516 --> 00:10:26.870\nwe'll do what's known as publishing\nthe certificate revocation list.\n\n208\n00:10:26.870 --> 00:10:30.429\nLet me go ahead and\nbring up server manager here and\n\n209\n00:10:30.429 --> 00:10:33.660\nwe'll get into our certificate authority.\n\n210\n00:10:33.660 --> 00:10:39.780\nAll right, and you'll see in here that\nwe have a series of containers, right?\n\n211\n00:10:39.780 --> 00:10:41.940\nWe have certificates that are issued.\n\n212\n00:10:41.940 --> 00:10:46.545\nIf a user goes through\na registration process and\n\n213\n00:10:46.545 --> 00:10:49.920\nrequests a certificate,\nI might have a pending request in here.\n\n214\n00:10:49.920 --> 00:10:51.900\nAnd you could see right now I\ndon't have any items to show.\n\n215\n00:10:51.900 --> 00:10:54.980\nBut I could have a pending request\nin here and I then I would have to\n\n216\n00:10:54.980 --> 00:10:58.514\nissue the certificate,\nif it's something like a subordinate,\n\n217\n00:10:58.514 --> 00:11:02.480\na CA, if it happens to be a network\ndevice, this might happen automatically.\n\n218\n00:11:02.480 --> 00:11:05.994\nBut what I really worried about\nis this container right here,\n\n219\n00:11:05.994 --> 00:11:08.235\nnotice it says revoked certificates.\n\n220\n00:11:08.235 --> 00:11:11.254\nNow a certificate can be revoked,\nall right?\n\n221\n00:11:11.254 --> 00:11:15.150\nAnd when a certificate is revoked,\nit is no longer valid.\n\n222\n00:11:15.150 --> 00:11:18.709\nThere's no way to reinstate a certificate.\n\n223\n00:11:18.709 --> 00:11:20.470\nNow why is it revoked?\n\n224\n00:11:20.470 --> 00:11:22.710\nWell, there might be\na few different reasons.\n\n225\n00:11:22.710 --> 00:11:24.680\nAs you can see we have revocation reasons.\n\n226\n00:11:24.680 --> 00:11:28.110\nI gave you just kinda couple of examples\nof what might happen, all right?\n\n227\n00:11:28.110 --> 00:11:30.440\nKey compromise,\nthis is one a major ones, right?\n\n228\n00:11:30.440 --> 00:11:34.882\nImagine a certificate that has now maybe\neven been compromised in the fact that\n\n229\n00:11:34.882 --> 00:11:38.460\nit's in the wrong hands and\nsomebody might be using it.\n\n230\n00:11:38.460 --> 00:11:40.750\nYou don't want somebody presenting\na certificate to you and\n\n231\n00:11:40.750 --> 00:11:43.740\nyou putting in your banking information,\nif it happens to be a hacker that's\n\n232\n00:11:43.740 --> 00:11:47.610\ncompromised the key that goes to that\ncertificate that's associated with it.\n\n233\n00:11:47.610 --> 00:11:51.520\nSo that's one of the reasons\nyou could revoke a certificate.\n\n234\n00:11:51.520 --> 00:11:53.640\nI did another one as a cease of operation.\n\n235\n00:11:53.640 --> 00:11:55.060\nMaybe we happen to bring a machine down.\n\n236\n00:11:55.060 --> 00:11:56.497\nIt doesn't happen a lot, but\n\n237\n00:11:56.497 --> 00:12:00.017\nthere are a few different reasons in\nwhich you could do this, all right?\n\n238\n00:12:00.017 --> 00:12:03.645\nWell in the database, right, the CRL,\n\n239\n00:12:03.645 --> 00:12:08.248\nthe crill,\ncontains these revoke certificates.\n\n240\n00:12:08.248 --> 00:12:12.154\nAnd in fact, if we right-click on our\nRevoke Certificates container and\n\n241\n00:12:12.154 --> 00:12:16.420\nchoose publish, it's gonna ask me,\nwhat do we want to do, all right?\n\n242\n00:12:16.420 --> 00:12:21.109\nDo we want to publish the new CRL and the\nCRL is the whole entire list, all right.\n\n243\n00:12:21.109 --> 00:12:25.237\nBut here's one of the drawbacks\nto checking a full\n\n244\n00:12:25.237 --> 00:12:28.110\ncertificate revocation list.\n\n245\n00:12:28.110 --> 00:12:29.580\nThey don't always get published, right?\n\n246\n00:12:29.580 --> 00:12:32.513\nThey don't published daily, they might\nnot even get published every three days.\n\n247\n00:12:32.513 --> 00:12:35.740\nIt could be 5 to 10 days, 5 to 15 days.\n\n248\n00:12:35.740 --> 00:12:39.260\nNow what happens if a key gets\ncompromised and it's within\n\n249\n00:12:39.260 --> 00:12:43.410\nthat 5 to 15 days that they aren't\npublishing certificate revocation list.\n\n250\n00:12:43.410 --> 00:12:46.550\nAll right, that could be a problem and\nthat's why they have delta CRLs.\n\n251\n00:12:46.550 --> 00:12:50.250\nDelta CRL is like you see is\nan abbreviation of a CRL that just says\n\n252\n00:12:50.250 --> 00:12:54.846\npublish what's changed since the last time\na full CRL has been published, all right?\n\n253\n00:12:54.846 --> 00:12:59.010\nAnd that is like I said, one of\nthe draw backs to the CRL all right?\n\n254\n00:12:59.010 --> 00:13:03.940\nNow I can see that once we've done that,\nwe should be able\n\n255\n00:13:03.940 --> 00:13:08.520\nto view the properties of the certificate\nrevocation list, all right?\n\n256\n00:13:08.520 --> 00:13:12.640\nAnd this is what your\nbrowsers are going to do.\n\n257\n00:13:12.640 --> 00:13:14.654\nWhen they check that chain validation,\n\n258\n00:13:14.654 --> 00:13:16.971\nthey're gonna look at\nwhat's known as a CDP.\n\n259\n00:13:16.971 --> 00:13:20.020\nAnd I don't think you really have to worry\nabout the CDP on the security plus exam.\n\n260\n00:13:20.020 --> 00:13:21.880\nBut let's just understand what it is.\n\n261\n00:13:21.880 --> 00:13:24.320\nA CRL Distribution Point.\n\n262\n00:13:24.320 --> 00:13:26.440\nWhen I check the CRL, where do I go?\n\n263\n00:13:26.440 --> 00:13:27.740\nCherokee, do you have the CRL?\n\n264\n00:13:27.740 --> 00:13:28.990\nNo, maybe not, right?\n\n265\n00:13:28.990 --> 00:13:30.460\nSo you gotta find it.\n\n266\n00:13:30.460 --> 00:13:32.190\nAnd they also publish that information.\n\n267\n00:13:32.190 --> 00:13:35.760\nIt says that when this certificate is\npresented to you, in that certificate is\n\n268\n00:13:35.760 --> 00:13:40.320\nthe information that points you over to\nwhere that Certificate Revocation List is.\n\n269\n00:13:40.320 --> 00:13:44.670\nAnd your computer goes through\nthe process of viewing the CRL, right?\n\n270\n00:13:44.670 --> 00:13:46.520\nAnd we can do that right here, right?\n\n271\n00:13:46.520 --> 00:13:51.510\nI can say, view the CRL and\nwe can find out the information\n\n272\n00:13:51.510 --> 00:13:55.170\nabout the revocation list itself and\nwhat's on the list.\n\n273\n00:13:55.170 --> 00:13:56.730\nNow you asked a good question.\n\n274\n00:13:56.730 --> 00:13:58.580\nWhat's in that list?\n\n275\n00:13:58.580 --> 00:14:00.850\nCherokee there, and\nthis is what's in the list.\n\n276\n00:14:00.850 --> 00:14:04.440\nThe serial numbers with the certificates\nthat are no longer trusted, right?\n\n277\n00:14:04.440 --> 00:14:08.510\nWe don't want these certificates\nbeing presented to us and being\n\n278\n00:14:08.510 --> 00:14:13.300\nused as a valid form of authentication,\nor identification if you will, because of\n\n279\n00:14:13.300 --> 00:14:16.550\nthe fact that one's been compromised and\none no longer exists, right?\n\n280\n00:14:16.550 --> 00:14:17.967\nYou don't want certificates around there.\n\n281\n00:14:17.967 --> 00:14:20.105\nSo that is a little bit about the CRL.\n\n282\n00:14:20.105 --> 00:14:25.224\nAnd every time your computer, it goes\nto a website that has HTTPS in it, it\n\n283\n00:14:25.224 --> 00:14:31.257\nis going through that process of checking\nthe CRL, the Certificate Revocation List,\n\n284\n00:14:31.257 --> 00:14:36.570\nto find out if the certificate that's\nbeing presented to it Is valid or not.\n\n285\n00:14:36.570 --> 00:14:41.890\n&gt;&gt; All right Wes, that was a little\nintense as far as being manually intense.\n\n286\n00:14:41.890 --> 00:14:44.020\nIs there a more automated process for\n\n287\n00:14:44.020 --> 00:14:48.110\nus to really check and\nvalidate those certificate life cycles?\n\n288\n00:14:48.110 --> 00:14:50.470\n&gt;&gt; That's a good question,\nbecause these CRLs,\n\n289\n00:14:50.470 --> 00:14:54.960\nI gave you an example of one that had\ntwo certs in it that had been revoked.\n\n290\n00:14:54.960 --> 00:14:59.506\nWhat if you have a Certificate\nRevocation List, which you can,\n\n291\n00:14:59.506 --> 00:15:02.547\nthat's coming from one of these root CAs?\n\n292\n00:15:02.547 --> 00:15:07.435\nIt could have 1,000, it could have\n10,000 serial numbers in there.\n\n293\n00:15:07.435 --> 00:15:08.185\nAnd what are you doing?\n\n294\n00:15:08.185 --> 00:15:11.645\nYou're taking the serial number of the\ncertificate that's being presented to you\n\n295\n00:15:11.645 --> 00:15:14.415\nand you're comparing it to the list\nto find out which one is which.\n\n296\n00:15:14.415 --> 00:15:16.175\nLet me show you what I mean here, right.\n\n297\n00:15:16.175 --> 00:15:21.470\nSo let's say we go to HTTPS and\nit's demo.ITProTv.\n\n298\n00:15:21.470 --> 00:15:25.230\nWell, we're gonna look at the CDP,\nthat distribution point that points us\n\n299\n00:15:25.230 --> 00:15:28.140\nto the CRL, and\nour computer's gonna inspect it.\n\n300\n00:15:28.140 --> 00:15:33.820\nAnd like I said, there could be\na lot of these serial numbers.\n\n301\n00:15:33.820 --> 00:15:35.128\nSo they also have something else.\n\n302\n00:15:35.128 --> 00:15:39.200\nThey have a protocol that can\nhelp assist in checking the CRL.\n\n303\n00:15:39.200 --> 00:15:43.107\nAnd that's something known as OSCP,\n\n304\n00:15:43.107 --> 00:15:48.243\nThat is\nthe Online Certificate Status Protocol.\n\n305\n00:15:48.243 --> 00:15:52.082\nI always get it mixed up there, but that\nis the Online Certificate Status Protocol.\n\n306\n00:15:52.082 --> 00:15:54.374\nNow understand in the methods\nthat I'm gonna show you,\n\n307\n00:15:54.374 --> 00:15:55.750\nyou're still checking the CRL.\n\n308\n00:15:55.750 --> 00:15:58.020\nThat's just the way certificate works.\n\n309\n00:15:58.020 --> 00:15:59.512\nSomebody's got to check the CRL.\n\n310\n00:15:59.512 --> 00:16:04.319\nIn this In this method, it's you doing\nthe work, you are finding the certificate,\n\n311\n00:16:04.319 --> 00:16:08.590\nwhen I say you, it's your computer and\nit goes to the serial numbers.\n\n312\n00:16:08.590 --> 00:16:12.960\nHowever OCSP works a little bit different.\n\n313\n00:16:12.960 --> 00:16:16.400\nNow, what we have is what is\nknown as an OCSP server, and\n\n314\n00:16:16.400 --> 00:16:17.890\nit's going to check the CRL.\n\n315\n00:16:17.890 --> 00:16:22.980\nYou're gonna look to the same, same\nthings goes on, we go to that website,\n\n316\n00:16:22.980 --> 00:16:29.050\nwe find out where the CRL is but\nwe also find a pointer to the OCSP server.\n\n317\n00:16:29.050 --> 00:16:31.630\nAnd we can go to the OCSP server.\n\n318\n00:16:31.630 --> 00:16:35.350\nNow this is kind of interesting because\nthe OCSP server downloads the CRL\n\n319\n00:16:35.350 --> 00:16:39.190\non your behalf and it checks the OCSP for\n\n320\n00:16:39.190 --> 00:16:43.150\na specific serial number,\nthe one you're looking for.\n\n321\n00:16:43.150 --> 00:16:47.840\nSo that saves your computer the burden of\n\n322\n00:16:47.840 --> 00:16:51.760\nhaving to go through every single one\nof the serial numbers in that list.\n\n323\n00:16:51.760 --> 00:16:54.580\nNow understand,\nnotice in this process, guess what?\n\n324\n00:16:54.580 --> 00:16:56.140\nSomebody's still checking the CRL.\n\n325\n00:16:56.140 --> 00:16:58.240\nBut it's a little bit different\nhere because now we're looking for\n\n326\n00:16:58.240 --> 00:17:02.610\na specific serial number and\nwe don't have to check the CRL.\n\n327\n00:17:02.610 --> 00:17:05.320\nSomebody else is doing it on our behalf.\n\n328\n00:17:05.320 --> 00:17:09.310\nNow, if you have a high\nlevel certificate authority\n\n329\n00:17:09.310 --> 00:17:13.070\nthat is constantly being checked, right,\nthat could take a little bit, right?\n\n330\n00:17:13.070 --> 00:17:17.190\nEven if you are talking using OCSP,\nthat could take a little bit.\n\n331\n00:17:17.190 --> 00:17:20.350\nSo they also have what's\nknown as OCSP Stapling.\n\n332\n00:17:20.350 --> 00:17:23.520\nAnd this is about who is\nchecking the CRL again.\n\n333\n00:17:23.520 --> 00:17:27.480\nNow, this time what we're gonna do is\nwe're gonna burden the web server, right?\n\n334\n00:17:27.480 --> 00:17:31.300\nNotice the lines here,\nI'm still going to the same website.\n\n335\n00:17:31.300 --> 00:17:34.330\nI still have to check the CRL,\nbut this time, when we go,\n\n336\n00:17:34.330 --> 00:17:38.810\nthe web server is going\nto check the OCSP server.\n\n337\n00:17:38.810 --> 00:17:40.630\nIt's gonna make the request for you.\n\n338\n00:17:40.630 --> 00:17:44.930\nAnd what the OCSP server is gonna do,\nis it's gonna download the CRL, and\n\n339\n00:17:44.930 --> 00:17:48.750\nit's gonna cache digitally\nsigned responses from the CA.\n\n340\n00:17:48.750 --> 00:17:51.840\nAnd it's gonna bake those\nright into the TLS handshake.\n\n341\n00:17:51.840 --> 00:17:55.370\nSo that you are already,\nyou've already validated\n\n342\n00:17:55.370 --> 00:17:59.820\nthrough the certificate authority what\nthe state of that certificate is, and\n\n343\n00:17:59.820 --> 00:18:01.190\nyou didn't have to do it.\n\n344\n00:18:01.190 --> 00:18:05.800\nAnd the other thing is it basically\njust burdens the website.\n\n345\n00:18:05.800 --> 00:18:09.710\nSo a couple of different ways that you\ncan do this, again, keep in mind all\n\n346\n00:18:09.710 --> 00:18:14.090\nthree of these methods, somebody is still\nchecking the certificate revocation list.\n\n347\n00:18:14.090 --> 00:18:17.410\nIt's just who is checking\nthe certificate revocation list.\n\n348\n00:18:17.410 --> 00:18:18.110\nIt's no different,\n\n349\n00:18:18.110 --> 00:18:23.860\nwe gonna find out if the certificate\nis presented to us, if it is valid.\n\n350\n00:18:23.860 --> 00:18:27.220\nNow that brings us to another concept,\nand that's validation methods.\n\n351\n00:18:27.220 --> 00:18:31.120\nValidation methods are really\nabout a level of trust.\n\n352\n00:18:31.120 --> 00:18:34.650\nAnd we have a few different types or\nlevels, if you will,\n\n353\n00:18:34.650 --> 00:18:36.420\nof validation methods.\n\n354\n00:18:36.420 --> 00:18:40.850\nAnd I've got them on the screen here,\nthere are three different kinds,\n\n355\n00:18:40.850 --> 00:18:41.520\nthere is what?\n\n356\n00:18:41.520 --> 00:18:44.810\nAnd you might hear, oops,\nI put some text on the screen there.\n\n357\n00:18:44.810 --> 00:18:49.540\nYou might hear these called DV, OV,\nand EV, and what they stand for\n\n358\n00:18:49.540 --> 00:18:54.460\nis Domain Validation, Organizational\nValidation, and Extended Validation.\n\n359\n00:18:54.460 --> 00:18:56.624\nWhen we talk about Domain Validation,\n\n360\n00:18:56.624 --> 00:19:00.173\nthese are ones that shouldn't\nreally be used for e-commerce.\n\n361\n00:19:00.173 --> 00:19:05.350\nAnd what that means is it\nverifies the domain name itself.\n\n362\n00:19:05.350 --> 00:19:10.650\nThe problem is it doesn't verify the\norganization that owns the domain name.\n\n363\n00:19:10.650 --> 00:19:12.060\nSo you have to be careful with that one,\n\n364\n00:19:12.060 --> 00:19:14.650\nthat's the least amount of trust,\nif you will.\n\n365\n00:19:14.650 --> 00:19:19.093\n&gt;&gt; So, Wes, what we're really looking at\nhere is basically just different levels of\n\n366\n00:19:19.093 --> 00:19:21.129\nthat validation for organizations.\n\n367\n00:19:21.129 --> 00:19:24.911\nSo if I didn't want to go through that\nentire rigorous process to have that\n\n368\n00:19:24.911 --> 00:19:28.876\nextended validation, and I just wanted\nto setup something, I don't know,\n\n369\n00:19:28.876 --> 00:19:32.260\nmaybe to share my recipes with the world,\nand had a website.\n\n370\n00:19:32.260 --> 00:19:34.840\nThen that's something a little\nmore attainable than really\n\n371\n00:19:34.840 --> 00:19:36.920\ngoing through that really rigid process.\n\n372\n00:19:36.920 --> 00:19:40.190\n&gt;&gt; That's a great example,\nbecause what you didn't say is e-commerce.\n\n373\n00:19:40.190 --> 00:19:42.590\nSo that would be a perfect example of\nwhere'd you use Domain Valdiation,\n\n374\n00:19:42.590 --> 00:19:46.620\ncuz I just wanna verify that\nthe website is who the website says.\n\n375\n00:19:46.620 --> 00:19:49.580\nBut if I'm gonna go through e-commerce,\nI also want to verify the company\n\n376\n00:19:49.580 --> 00:19:52.580\non the other end that owns the website\nthat's presenting the certificate to me.\n\n377\n00:19:52.580 --> 00:19:54.695\nAnd that's where we get to\nOrganizational Validation.\n\n378\n00:19:54.695 --> 00:19:59.570\nAnd Organizational Validation means\nI can verify that it is Google.\n\n379\n00:19:59.570 --> 00:20:02.380\nNow we're gonna talk about Google here\nbecause they go above and beyond,\n\n380\n00:20:02.380 --> 00:20:05.150\nlike a lot of the major companies and\nthey actually do Extended Validation.\n\n381\n00:20:05.150 --> 00:20:09.950\nBut Organizational Validation just\nmeans that I know when that company\n\n382\n00:20:09.950 --> 00:20:14.910\npresents that web certificate or\nSSL certificate, TLS certificate,\n\n383\n00:20:14.910 --> 00:20:19.890\nthat it is exactly who\nthe organization says they are.\n\n384\n00:20:19.890 --> 00:20:22.163\nRight, they've gone through\nthose checks and balances.\n\n385\n00:20:22.163 --> 00:20:28.550\nNow, the last one is probably\nthe most rigorous process.\n\n386\n00:20:28.550 --> 00:20:35.290\nAnd it offers just about, if you will, the\nhighest level of trust out there, right?\n\n387\n00:20:35.290 --> 00:20:39.450\nNot only does it provide\norganizational information, but\n\n388\n00:20:39.450 --> 00:20:45.280\nthey have to go through a lot more\nstrict processes to get this right?\n\n389\n00:20:45.280 --> 00:20:49.070\nThey have to do things like get a signed\ncopy of the extended validation subscriber\n\n390\n00:20:49.070 --> 00:20:51.310\nagreement, an authorization form.\n\n391\n00:20:51.310 --> 00:20:56.590\nA letter from a CPA, as well as things\nlike a letter from a notary right?\n\n392\n00:20:56.590 --> 00:20:59.900\nSo that's when we not only\nprove the organization, but\n\n393\n00:20:59.900 --> 00:21:01.610\nwe know its physical location,\n\n394\n00:21:01.610 --> 00:21:06.020\nwe know what administrators that we have\nto get a hold of if something happens.\n\n395\n00:21:06.020 --> 00:21:11.620\nAnd this is typically where you see\nthose green business names, if you will.\n\n396\n00:21:11.620 --> 00:21:14.910\nLike I said, everybody does this\na little bit different, but again,\n\n397\n00:21:14.910 --> 00:21:17.660\nif I was to go to, GeoTrust is one.\n\n398\n00:21:17.660 --> 00:21:19.480\nSo if we can bring up my web browser here.\n\n399\n00:21:19.480 --> 00:21:22.670\nLet's go back to GeoTrust like\nwe did earlier in this series.\n\n400\n00:21:22.670 --> 00:21:28.350\nAnd notice that right here, GeoTrust has\ntheir name in green right here with https.\n\n401\n00:21:28.350 --> 00:21:30.192\nThat's what's known as\nExtended Validation.\n\n402\n00:21:30.192 --> 00:21:34.000\nAll right, now,\nnot only is GeoTrust a root\n\n403\n00:21:34.000 --> 00:21:37.370\ncertificate authority out there on\nthe Internet, you would hope so, right?\n\n404\n00:21:37.370 --> 00:21:39.770\nBut remember, the process.\n\n405\n00:21:39.770 --> 00:21:42.540\nThe reason they call it Extended\nValidation is they have gone through\n\n406\n00:21:42.540 --> 00:21:43.670\na pretty rigorous process.\n\n407\n00:21:43.670 --> 00:21:47.310\nA lot of forms they have to fill out, a\nlot of identities that they have to prove\n\n408\n00:21:47.310 --> 00:21:50.470\nbefore they ever get\nthis level of validation.\n\n409\n00:21:50.470 --> 00:21:52.440\nSo we do want you to be\naware of that as well.\n\n410\n00:21:53.710 --> 00:21:55.680\nAll right Cherokee,\nI know I'm running close on time.\n\n411\n00:21:55.680 --> 00:21:57.570\nGotta couple of extra,\n\n412\n00:21:57.570 --> 00:22:01.532\njust additional concepts that I kind\nof wanna throw out there, all right?\n\n413\n00:22:01.532 --> 00:22:05.700\nWe've kinda talked about stapling,\nalready, with the OCSP,\n\n414\n00:22:05.700 --> 00:22:08.030\nbut I also wanna talk about pinning.\n\n415\n00:22:08.030 --> 00:22:12.890\nPinning is a way to ensure\na trust between the host and\n\n416\n00:22:12.890 --> 00:22:16.158\nthe entity that's\npresenting the certificate.\n\n417\n00:22:16.158 --> 00:22:19.300\nAll right, so typically what happens\nis you go through the certificate chain\n\n418\n00:22:19.300 --> 00:22:20.120\nvalidation.\n\n419\n00:22:20.120 --> 00:22:24.680\nLet's go to Google for instance,\nin fact, I'll go ahead and\n\n420\n00:22:24.680 --> 00:22:26.510\nbring that back up here real quick.\n\n421\n00:22:26.510 --> 00:22:29.250\nSo we we look at that certificate, right?\n\n422\n00:22:29.250 --> 00:22:34.410\nWe go through the chain validation and\nmy certificate is then checked against\n\n423\n00:22:34.410 --> 00:22:39.190\nwhoever the intermediate or subordinate\nCA, which is then check through GeoTrust.\n\n424\n00:22:39.190 --> 00:22:43.800\nCertificate pinning says,\nI don't care about that hierarchy.\n\n425\n00:22:43.800 --> 00:22:46.980\nI want you to trust this certificate and\nthis certificate only, right?\n\n426\n00:22:46.980 --> 00:22:50.350\nSo when I go to Google my computer\ngoes through this process.\n\n427\n00:22:50.350 --> 00:22:53.980\nBut let's take something like\nMicrosoft's updates all right?\n\n428\n00:22:53.980 --> 00:22:59.910\nMicrosoft doesn't care when your computer\ngoes to a Windows Update or a Microsoft\n\n429\n00:22:59.910 --> 00:23:03.830\ntype update if it's other products,\nthey don't need the chain validation.\n\n430\n00:23:03.830 --> 00:23:06.970\nThey say you trust Microsoft's\ncertificate, nobody else's right,\n\n431\n00:23:06.970 --> 00:23:10.890\nI don't care issued it above that\nthis is Microsoft's certificate.\n\n432\n00:23:10.890 --> 00:23:14.670\nAnd Windows update on your computer is\ngoing to trust that certificate and\n\n433\n00:23:14.670 --> 00:23:17.165\nit doesn't have to go through\nthat chain validation process.\n\n434\n00:23:17.165 --> 00:23:19.780\nThat's called,\nan example of certificate pinning.\n\n435\n00:23:21.030 --> 00:23:24.570\nThe other thing that we have too,\nare things like, for instance Wild Cards.\n\n436\n00:23:24.570 --> 00:23:27.950\nAlright, and a Wild Card Certificate\nis a very interesting concept.\n\n437\n00:23:27.950 --> 00:23:32.390\nBecause of the fact that,\nwhat if you want a certificate to be,\n\n438\n00:23:32.390 --> 00:23:37.670\nto not only, let's say endorse one domain,\n\n439\n00:23:37.670 --> 00:23:43.620\nbut you want it to affect, if you will,\nor endorse, multiple subdomains.\n\n440\n00:23:43.620 --> 00:23:45.680\nWell, you can issue\na wildcard certificate.\n\n441\n00:23:45.680 --> 00:23:51.371\nLike, so for instance,\nwe have www.itpro.tv, right?\n\n442\n00:23:51.371 --> 00:23:56.640\nNow, if we wanted to, we would buy\nanother certificate for, let's say, demo.\n\n443\n00:23:58.220 --> 00:24:00.314\nRight, oops, if I could spell demo.\n\n444\n00:24:00.314 --> 00:24:05.199\n[LAUGH] demo.itpro.tv, right?\n\n445\n00:24:05.199 --> 00:24:08.680\nWell, now, I've got two\ncertificates that I have to buy.\n\n446\n00:24:08.680 --> 00:24:10.925\nBut if we get a Wildcard Certificate,\n\n447\n00:24:10.925 --> 00:24:15.830\nwe can do something like this where\nit's an asterisk symbol, right?\n\n448\n00:24:15.830 --> 00:24:21.460\nAnd we could do, *itpro.tv,\nand that type of certificate,\n\n449\n00:24:21.460 --> 00:24:25.830\nit's a common thing where it now\nincludes things like www.itpro.tv.\n\n450\n00:24:25.830 --> 00:24:32.116\nIt would include the sub\ndomain demo.itpro.tv,\n\n451\n00:24:32.116 --> 00:24:39.146\nand if we branched out,\nwe could do an east.itpro.tv.\n\n452\n00:24:39.146 --> 00:24:44.032\nAnd again and so forth, not to\noverwhelm you here with redundancy, but\n\n453\n00:24:44.032 --> 00:24:48.360\nnotice that it would allow it\nto propagate the subdomains too.\n\n454\n00:24:48.360 --> 00:24:51.880\nAnd I think WordPress is one\nthat I've got an example of.\n\n455\n00:24:51.880 --> 00:24:55.620\nSo let me show you an example, if I go\nover to WordPress this just happens to be\n\n456\n00:24:55.620 --> 00:25:00.480\na WordPress site and, oops, cancel that.\n\n457\n00:25:00.480 --> 00:25:02.910\nI don't know what I'm doing here,\nthere we go.\n\n458\n00:25:02.910 --> 00:25:03.769\nTry that again, here.\n\n459\n00:25:03.769 --> 00:25:08.886\n[LAUGH] And if I have actually figured out\nhow to get the certificate pulled back up,\n\n460\n00:25:08.886 --> 00:25:12.060\nI can show you an example of a wildcard.\n\n461\n00:25:12.060 --> 00:25:15.310\nNotice WordPress here,\nthis is a wildcard certificate, right?\n\n462\n00:25:15.310 --> 00:25:19.432\nNotice that it says, *.wordpress.com, so\n\n463\n00:25:19.432 --> 00:25:24.950\nthis certificate would propagate\nto subdomains as well.\n\n464\n00:25:24.950 --> 00:25:28.070\nAnd that's something that we\ndefinitely want you to be aware of.\n\n465\n00:25:29.140 --> 00:25:30.310\nLast thing I wanna talk,\n\n466\n00:25:30.310 --> 00:25:33.450\nwell, I got a couple of things that\nI also wanna talk about as well.\n\n467\n00:25:33.450 --> 00:25:34.788\n&gt;&gt; Do we have time for our formats?\n\n468\n00:25:34.788 --> 00:25:37.740\n&gt;&gt; Yeah,\nwe'll go a little bit long on this one.\n\n469\n00:25:37.740 --> 00:25:40.400\nWe'll go ahead and wrap it up, so we don't\nhave to go into a part five on this one.\n\n470\n00:25:40.400 --> 00:25:44.418\n&gt;&gt; [LAUGH]\n&gt;&gt; Guys, I wanna talk about a key escrow,\n\n471\n00:25:44.418 --> 00:25:48.142\nkey escrows are really for\nkey recovery, right?\n\n472\n00:25:48.142 --> 00:25:52.643\nAnd this says that you are gonna trust\nyour private key to a third party,\n\n473\n00:25:52.643 --> 00:25:56.920\nso that if something happens and\nyou need to recover that key.\n\n474\n00:25:56.920 --> 00:26:00.161\nYou have the ability to go to that third\nparty and you can recover the key.\n\n475\n00:26:00.161 --> 00:26:05.660\nNow, you also have what's known\nas an MNM of N control concept.\n\n476\n00:26:05.660 --> 00:26:09.850\nAnd we do have to keep that in mind, that\nbasically what that means is that's how\n\n477\n00:26:09.850 --> 00:26:15.470\nmany people are responsible\nparties with the key, would be N.\n\n478\n00:26:15.470 --> 00:26:19.800\nAnd how of those responsible parties\ndoes it take to rebuild the key, so\n\n479\n00:26:19.800 --> 00:26:21.570\nthat would be your M, right?\n\n480\n00:26:21.570 --> 00:26:27.400\nAgain, N is how many responsible parties\ndo I have that have a portion of the key\n\n481\n00:26:27.400 --> 00:26:31.712\nversus M, is how many of those people\n[COUGH] does it take to rebuild the key.\n\n482\n00:26:31.712 --> 00:26:34.030\nSo, do keep in mind the basics as well,\n\n483\n00:26:34.030 --> 00:26:38.360\nit's just key escrows, I'm going for\nkey recovery purposes.\n\n484\n00:26:38.360 --> 00:26:41.500\nWe're gonna go head and we're gonna\nallocate that to a third party and then if\n\n485\n00:26:41.500 --> 00:26:45.280\nwe need to rebuild the key, we can rebuild\nit and you will pay a price for that.\n\n486\n00:26:46.450 --> 00:26:49.443\nAll right, so last thing and I promise,\n\n487\n00:26:49.443 --> 00:26:53.770\n[LAUGH] we will bring this one to\nan end that I wanna talk about,\n\n488\n00:26:53.770 --> 00:26:57.620\nare some of the certificate\nformats that you'll see out there.\n\n489\n00:26:57.620 --> 00:27:02.031\nAnd I've got a few of them here\non our screen, we have DER, okay?\n\n490\n00:27:02.031 --> 00:27:05.409\nAnd I always say DER, I keep thinking\nof the DIR command inside of Windows.\n\n491\n00:27:05.409 --> 00:27:06.030\n&gt;&gt; [LAUGH] Yes.\n\n492\n00:27:06.030 --> 00:27:08.058\n&gt;&gt; This is not a directory command but\nthis is D-E-R.\n\n493\n00:27:08.058 --> 00:27:11.040\n&gt;&gt; D-E-R [LAUGH]\n&gt;&gt; That's right, well, actually, DER and\n\n494\n00:27:11.040 --> 00:27:13.180\nPEM, they're just about the same format.\n\n495\n00:27:13.180 --> 00:27:18.950\nThis is the binary form, you'll see\nextensions like .DER, .CER, if you will.\n\n496\n00:27:19.950 --> 00:27:25.480\nPEM is a base64 encoded, in ASCII file.\n\n497\n00:27:25.480 --> 00:27:32.064\nIt has extensions like .CER, .CRT for\ninside a Windows, .PEM, .key.\n\n498\n00:27:32.064 --> 00:27:35.620\nAnd this uses plain text if you will and\nanchor lines,\n\n499\n00:27:35.620 --> 00:27:40.220\nthat's where we see the big begin\ncertificate and end certificate.\n\n500\n00:27:40.220 --> 00:27:43.350\nAnd we see the encrypted\ninformation in between it.\n\n501\n00:27:43.350 --> 00:27:48.348\nYou also have the extension PFX,\nas well as, and I mentioned CER.\n\n502\n00:27:48.348 --> 00:27:53.385\nNow, these last couple of ones,\nP12 and P7B, these really,\n\n503\n00:27:53.385 --> 00:27:58.040\nit's, do you need the private\nkey included, right?\n\n504\n00:27:58.040 --> 00:28:01.597\nThese formats, when you look at,\nfor instance, P12,\n\n505\n00:28:01.597 --> 00:28:05.022\nthat's actually used by\nwhat's known as PKCS#12.\n\n506\n00:28:05.022 --> 00:28:09.465\nAnd this is a base64 encoded file,\nand it contains,\n\n507\n00:28:09.465 --> 00:28:13.340\nboth the private and\nthe public key, alright?\n\n508\n00:28:13.340 --> 00:28:17.040\nAnd again,\nthe extension could be PFX or P12.\n\n509\n00:28:17.040 --> 00:28:23.160\nYou also have the P7B, and a P7B file\nextension is used by the PKCS#7.\n\n510\n00:28:23.160 --> 00:28:25.780\nAnd this is when you need\nto export the public key.\n\n511\n00:28:25.780 --> 00:28:31.310\nSo for instance, when we needed to\n[COUGH] export the Root CA Certificate.\n\n512\n00:28:31.310 --> 00:28:35.730\nAnd I wanted to maybe embed that in the\ntrusted root certification authorities on\n\n513\n00:28:35.730 --> 00:28:38.140\na Windows machine, so\nit trusts my root CA.\n\n514\n00:28:38.140 --> 00:28:41.388\nI don't want it to have the private key,\nit doesn't need that, so\n\n515\n00:28:41.388 --> 00:28:43.070\nI'm not gonna use P12, right?\n\n516\n00:28:43.070 --> 00:28:46.460\nWe're gonna use the P7B because\nit exports the public key.\n\n517\n00:28:46.460 --> 00:28:50.109\nAnd that's what I have to have in that\ntrusted root certification authority\n\n518\n00:28:50.109 --> 00:28:53.766\nsection, in order to trust a certificate\nthat has been issued by that root.\n\n519\n00:28:53.766 --> 00:28:57.890\nSo a few of the difference formats,\njust be aware of them.\n\n520\n00:28:57.890 --> 00:29:03.380\nI would say on the exam, know which ones\nyou might see and some of their usages.\n\n521\n00:29:03.380 --> 00:29:05.670\nI would definitely pay\nattention to the P7B and\n\n522\n00:29:05.670 --> 00:29:09.080\nthe P12, cuz it might be something\nthat they ask you on the exam.\n\n523\n00:29:09.080 --> 00:29:12.520\nWhere they say you need to export the\nprivate key, as well as the public key.\n\n524\n00:29:12.520 --> 00:29:15.340\nOr in a scenario where you\nneed to support, you need to\n\n525\n00:29:15.340 --> 00:29:18.670\nexport the public key, but it's important\nthat you don't have the private key.\n\n526\n00:29:18.670 --> 00:29:20.453\nIn that case you're gonna use the P7B.\n\n527\n00:29:20.453 --> 00:29:24.177\n&gt;&gt; All right, Wes, we have covered\na lot of information in this particular\n\n528\n00:29:24.177 --> 00:29:27.310\nminiseries here, but\nI think that's about it for PKI.\n\n529\n00:29:27.310 --> 00:29:30.310\nSo thank you so much, and thank you\nladies and gentlemen for tuning in.\n\n530\n00:29:30.310 --> 00:29:31.910\nFor this show,\nwe'll go ahead and sign out.\n\n531\n00:29:31.910 --> 00:29:33.500\nRemember, I'm your host, Cherokee Boose.\n\n532\n00:29:33.500 --> 00:29:34.450\n&gt;&gt; And I'm Wes Bryan.\n\n533\n00:29:34.450 --> 00:29:39.859\n&gt;&gt; See you next time, here at ITPro.TV.\n\n534\n00:29:39.859 --> 00:29:43.248\n[MUSIC]\n\n535\n00:29:43.248 --> 00:29:45.725\n&gt;&gt; Thank you for watching ITPro.TV.\n\n",
          "vimeoId": "214510222"
        }
      ],
      "title": "Cryptography and PKI"
    }
  ],
  "url": "security-updated-2017",
  "vLab": false
}
